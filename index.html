<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Ittai Abraham</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at December 19, 2019 01:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=18781">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/12/18/abel-in-jerusalem-sunday-january-12-2020-and-other-events/">Abel in Jerusalem – SUNDAY, January 12, 2020, and other events</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I would like to report on <del>seven</del> eight mathematical events taking place in Jerusalem, the Tel Aviv area, and Haifa in the next few weeks. (Probably I missed quite a few other mathematical events, feel free to update in the comment section.)</p>
<p>1. <a href="https://mathematics.huji.ac.il/event/abel-jerusalem">Abel in Jerusalem: Sunday, January 12, 2020, 09:45-19:00</a>, featuring: <strong>Christopher Hacon, Ulrike Tillmann, Claire Voisin, and François Labourie</strong>.</p>
<p>2. <a href="http://ias.huji.ac.il/SchoolCSE4">Winter School: The Mathematics of Quantum computing</a> (starting  Dec. 15, 2019, <a href="https://docs.google.com/document/d/1OcFzE1PHxBN4l87sOQB033FZLTgY934GHxnpVKi3NaM/edit">program</a>): The Rabin lecture by <strong>Boaz Barak</strong> Monday Dec 16 14:00 CS building;  and also including <strong>a panel/debate on quantum supremacy</strong> moderated by <strong>Sandy Irani</strong>, Dec. 19 , 2019 16:00 CS building. (I am one of the seven panelists and for an introduction to my stance, see <a href="https://sites.google.com/view/tau-theory-fest/home">this post</a>.) There are great videotaped lectures! <span style="color: #ff6600;">Important massage</span>: Most lectures are in IIAS, at Feldman building. In the first days the lecture rooms were completely full but from today some seats are available!</p>
<p>3. <a href="https://sites.google.com/view/tau-theory-fest/home">TAU Theory Fest  December 29, 2019  – January, 3, 2020.</a> Great line of speakers, and various workshops.</p>
<p>4. <a href="https://sites.google.com/view/boolean-functions/home">Boolean function day, Friday, January 3, 2020,</a> featuring <strong>Esty Kelman, Noam Lifschitz, Renan Gross, Ohad Klein, and Naomi Kirshner</strong>.</p>
<p>5. <a href="https://mathematics.huji.ac.il/node/92491">Zabrodsky’s lecture, <strong>Paul Seidel</strong>, December 19, 23, 24 2019, The Hebrew University of Jerusalem.</a> (See <a href="https://gilkalai.wordpress.com/2019/12/14/old-lecture-notes-by-alex-zabrodsky/">this previous post</a>.)</p>
<p>6. <a href="https://mathematics.huji.ac.il/node/96554">Dvoretzky’s lectures, <strong>Sylvia Serfaty</strong>,  January 15,16, 2020, the Hebrew University of Jerusalem</a>. (See this post about <a href="https://gilkalai.wordpress.com/2008/12/26/lior-aryeh-and-michael/">Aryeh Dvoretzky</a>.)</p>
<p>7. <a href="https://cms-math.net.technion.ac.il/prof-sergei-tabachnikov/">Distinguished lectures by <strong>Sergey Tabachnikov</strong>, January, 6, 8, 9 the Technion.</a></p>
<p>8. <a href="http://u.math.biu.ac.il/~schiff/wrkshpam25.html?fbclid=IwAR1kxSI4W9M1wCS0ebNUzF3d200d4QnYRRIlml4Y6bobjhn9fECgpufp44c">The Twenty-fifth Israeli Mini-Workshop in Applied and Computational Mathematics</a>, Wednesday December 25. Bar-Ilan University. Great line of speakers.</p>
<h2>Abel In Jerusalem, Sunday, January 12, 2020.</h2>
<p>The Einstein Institute of mathematics is happy to host the Abel in Jerusalem Conference. The location of the conference in Manchester House, Lecture Hall 2. Each year the Abel Committee holds a symposium where members of the Abel Committee and some of the world’s top mathematicians will be speaking. “Abel in Jerusalem” will be the 10th one-day conference with lectures aimed at a mathematically educated and interested audience, with the objective of increasing public awareness of mathematics and of the Abel Prize.</p>
<p>The day starts (09:40) with opening remarks by <strong>Hans Petter Graver</strong>, President of the Norwegian Academy of Science and Letters, followed by lectures by  <strong>Christopher Hacon</strong> (University of Utah) 10:00-11:00; <strong>Ulrike Tillmann</strong> (Oxford University) 11:30-12:30; <strong>Claire Voisin</strong> (Collège de France) 14:30-15:30; and <strong>François Labourie</strong> (Université Côte d’Azur) 16:00-17:00. Participation, including lunch, and reception at the King David Hotel is free but registration is needed. Organizers: <strong>Gil Kalai</strong> and <strong>Tamar Ziegler</strong>; For more detail <a href="https://mathematics.huji.ac.il/event/abel-jerusalem">see this page</a>. If you are interested in attending please <a href="https://forms.gle/fEL7KgQxE8hHtb9q8" target="_blank" rel="noopener" title="">register here</a>.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/abelinj.png"><img src="https://gilkalai.files.wordpress.com/2019/12/abelinj.png?w=640" alt="" class="alignnone size-full wp-image-18866" /></a></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/12/18/abel-in-jerusalem-sunday-january-12-2020-and-other-events/"><span class="datestr">at December 18, 2019 06:08 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.08066">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.08066">Putting Ridesharing to the Test: Efficient and Scalable Solutions and the Power of Dynamic Vehicle Relocation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Danassis:Panayiotis.html">Panayiotis Danassis</a>, Marija Sakota, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filos=Ratsikas:Aris.html">Aris Filos-Ratsikas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Faltings:Boi.html">Boi Faltings</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.08066">PDF</a><br /><b>Abstract: </b>Ridesharing is a coordination problem in its core. Traditionally it has been
solved in a centralized manner by ridesharing platforms. Yet, to truly allow
for scalable solutions, we needs to shift from traditional approaches, to
multi-agent systems, ideally run on-device. In this paper, we show that a
recently proposed heuristic (ALMA), which exhibits such properties, offers an
efficient, end-to-end solution for the ridesharing problem. Moreover, by
utilizing simple relocation schemes we significantly improve QoS metrics, by up
to 50%.
</p>
<p>To demonstrate the latter, we perform a systematic evaluation of a diverse
set of algorithms for the ridesharing problem, which is, to the best of our
knowledge, one of the largest and most comprehensive to date. Our evaluation
setting is specifically designed to resemble reality as closely as possible. In
particular, we evaluate 12 different algorithms over 12 metrics related to
global efficiency, complexity, passenger, driver, and platform incentives.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.08066"><span class="datestr">at December 18, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.08045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.08045">On the I/O complexity of hybrid algorithms for Integer Multiplication</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stefani:Lorenzo_De.html">Lorenzo De Stefani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.08045">PDF</a><br /><b>Abstract: </b>Almost asymptotically tight lower bounds are derived for the I/O complexity
$IO\left(n,M\right)$ of a general class of hybrid algorithms computing the
product of two integers, each represented with $n$ digits in a given base $s$,
in a two-level storage hierarchy with $M$ words of fast memory, with different
digits stored in different memory words. The considered hybrid algorithm
combine the Toom-Cook-$k$ (or Toom-$k$) fast integer multiplication approach
with computational complexity $\Theta\left(c_kn^{\log_k
\left(2k-1\right)}\right)$, and "standard" integer multiplication algorithms
which compute $\Omega\left(n^2\right)$ digit multiplications.
</p>
<p>We present an $\Omega\left(\left(n/\max\{M,n_0\}\right)^{\log_k
\left(2k-1\right)}\left(\max\{1,n_0/M\}\right)^2M\right)$ lower bound for the
I/O complexity a class of "uniform, non-stationary" hybrid algorithms when
executed in a two-level storage hierarchy with $M$ words of fast memory, where
$n_0$ denotes the threshold size of sub-problems which are computed using
standard algorithms with algebraic complexity $\Omega\left(n^2\right)$.
</p>
<p>The lower bound is derived for the more general class of "non-uniform,
non-stationary" hybrid algorithms which allow recursive calls to have a
different structure, even when they refer to the multiplication of integers of
the same size and in the same recursive level including those where the value
of $k$ is allowed to vary with the level of recursion. As some hybrid
algorithms from this class execute a number of I/O operations that is within a
$O\left(k^2\right)$ multiplicative term of the corresponding lower bounds, the
proposed lower bounds are almost asymptotically tight and indeed tight for
constant values of $k$.
</p>
<p>Extensions of the lower bounds for a parallel model with $P$ processors are
also discussed.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.08045"><span class="datestr">at December 18, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.08032">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.08032">Monotone 3-Sat-(2,2) is NP-complete</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=ouml=cker:Janosch.html">Janosch Döcker</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.08032">PDF</a><br /><b>Abstract: </b>We show that Monotone 3-Sat remains NP-complete if (i) each clause contains
exactly three distinct variables, (ii) each clause is unique, i.e., there are
no duplicates of the same clause, and (iii), amongst the clauses, each variable
appears unnegated exactly twice and negated exactly twice. Darmann and D\"ocker
[6] recently showed that this variant of Monotone 3-Sat is either trivial or
NP-complete. In the first part of the paper, we construct an unsatisfiable
instance which answers one of their open questions (Challenge 1) and places the
problem in the latter category.
</p>
<p>Then, we adapt gadgets used in the construction to (1) sketch two reductions
that establish NP-completeness in a more direct way, and (2), to show that
$\forall\exists$ 3-SAT remains $\Pi_2^P$-complete for quantified Boolean
formulas with the following properties: (a) each clause is monotone (i.e., no
clause contains an unnegated and a negated variable) and contains exactly three
distinct variables, (b) each universal variable appears exactly once unnegated
and exactly once negated, (c) each existential variable appears exactly twice
unnegated and exactly twice negated, and (d) the number of universal and
existential variables is equal. Furthermore, we show that the variant where (b)
is replaced with (b') each universal variable appears exactly twice unnegated
and exactly twice negated, and where (a), (c) and (d) are unchanged, is
$\Pi_2^P$-complete as well. Thereby, we improve upon two recent results by
D\"ocker et al. [8] that establish $\Pi_2^P$-completeness of these variants in
the non-monotone setting.
</p>
<p>We also discuss a special case of Monotone 3-Sat-(2,2) that corresponds to a
variant of Not-All-Equal Sat, and we show that all such instances are
satisfiable.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.08032"><span class="datestr">at December 18, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.07992">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.07992">The Power of Programs over Monoids in J</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grosshans:Nathan.html">Nathan Grosshans</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.07992">PDF</a><br /><b>Abstract: </b>The model of programs over (finite) monoids, introduced by Barrington and
Th{\'e}rien, gives an interesting way to characterise the circuit complexity
class $\mathsf{NC^1}$ and its subclasses and showcases deep connections with
algebraic automata theory. In this article, we investigate the computational
power of programs over monoids in $\mathbf{J}$, a small variety of finite
aperiodic monoids. First, we give a fine hierarchy within the class of
languages recognised by programs over monoids from $\mathbf{J}$, based on the
length of programs but also some parametrisation of $\mathbf{J}$. Second, and
most importantly, we make progress in understanding what regular languages can
be recognised by programs over monoids in $\mathbf{J}$. We show that those
programs actually can recognise all languages from a class of restricted
dot-depth one languages, using a non-trivial trick, and conjecture that this
class suffices to characterise the regular languages recognised by programs
over monoids in $\mathbf{J}$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.07992"><span class="datestr">at December 18, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.07957">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.07957">Approximating MIS over equilateral $B_1$-VPG graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lahiri:Abhiruk.html">Abhiruk Lahiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukherjee:Joydeep.html">Joydeep Mukherjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Subramanian:C=_R=.html">C. R. Subramanian</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.07957">PDF</a><br /><b>Abstract: </b>We present an approximation algorithm for the maximum independent set (MIS)
problem over the class of equilateral $B_1$-VPG graphs. These are intersection
graphs of $L$-shaped planar objects % (and their rotations by multiples of
$90^o$) with both arms of each object being equal. We obtain a $36(\log
2d)$-approximate algorithm running in $O(n(\log n)^2)$ time for this problem,
where $d$ is the ratio $d_{max}/d_{min}$ and $d_{max}$ and $d_{min}$ denote
respectively the maximum and minimum length of any arm in the input equilateral
$L$-representation of the graph. In particular, we obtain $O(1)$-factor
approximation of MIS for $B_1$-VPG -graphs for which the ratio $d$ is bounded
by a constant. % formed by unit length $L$-shapes. In fact, algorithm can be
generalized to an $O(n(\log n)^2)$ time and a $36(\log 2d_x)(\log
2d_y)$-approximate MIS algorithm over arbitrary $B_1$-VPG graphs. Here, $d_x$
and $d_y$ denote respectively the analogues of $d$ when restricted to only
horizontal and vertical arms of members of the input. This is an improvement
over the previously best $n^\epsilon$-approximate algorithm \cite{FoxP} (for
some fixed $\epsilon&gt;0$), unless the ratio $d$ is exponentially large in $n$.
In particular, $O(1)$-approximation of MIS is achieved for graphs with
$\max\{d_x,d_y\}=O(1)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.07957"><span class="datestr">at December 18, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.07820">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.07820">Balancing the Tradeoff Between Clustering Value and Interpretability</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saisubramanian:Sandhya.html">Sandhya Saisubramanian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galhotra:Sainyam.html">Sainyam Galhotra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zilberstein:Shlomo.html">Shlomo Zilberstein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.07820">PDF</a><br /><b>Abstract: </b>Graph clustering groups entities -- the vertices of a graph -- based on their
similarity, typically using a complex distance function over a large number of
features. Successful integration of clustering approaches in automated
decision-support systems hinges on the interpretability of the resulting
clusters. This paper addresses the problem of generating interpretable
clusters, given features of interest that signify interpretability to an
end-user, by optimizing interpretability in addition to common clustering
objectives. We propose a $\beta$-interpretable clustering algorithm that
ensures that at least $\beta$ fraction of nodes in each cluster share the same
feature value. The tunable parameter $\beta$ is user-specified. We also present
a more efficient algorithm for scenarios with $\beta\!=\!1$ and analyze the
theoretical guarantees of the two algorithms. Finally, we empirically
demonstrate the benefits of our approaches in generating interpretable clusters
using four real-world datasets. The interpretability of the clusters is
complemented by generating simple explanations denoting the feature values of
the nodes in the clusters, using frequent pattern mining.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.07820"><span class="datestr">at December 18, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.07673">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.07673">Finding the Mode of a Kernel Density Estimate</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Jasper_C=_H=.html">Jasper C. H. Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Christopher.html">Christopher Musco</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Jeff_M=.html">Jeff M. Phillips</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tai:Wai_Ming.html">Wai Ming Tai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.07673">PDF</a><br /><b>Abstract: </b>Given points $p_1, \dots, p_n$ in $\mathbb{R}^d$, how do we find a point $x$
which maximizes $\frac{1}{n} \sum_{i=1}^n e^{-\|p_i - x\|^2}$? In other words,
how do we find the maximizing point, or mode of a Gaussian kernel density
estimation (KDE) centered at $p_1, \dots, p_n$? Given the power of KDEs in
representing probability distributions and other continuous functions, the
basic mode finding problem is widely applicable. However, it is poorly
understood algorithmically. Few provable algorithms are known, so practitioners
rely on heuristics like the "mean-shift" algorithm, which are not guaranteed to
find a global optimum. We address this challenge by providing fast and provably
accurate approximation algorithms for mode finding in both the low and high
dimensional settings. For low dimension $d$, our main contribution is to reduce
the mode finding problem to a solving a small number of systems of polynomial
inequalities. For high dimension $d$, we prove the first dimensionality
reduction result for KDE mode finding, which allows for reduction to the low
dimensional case. Our result leverages Johnson-Lindenstrauss random projection,
Kirszbraun's classic extension theorem, and perhaps surprisingly, the
mean-shift heuristic for mode finding.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.07673"><span class="datestr">at December 18, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.07629">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.07629">Learning Mixtures of Linear Regressions in Subexponential Time via Fourier Moments</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Sitan.html">Sitan Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.07629">PDF</a><br /><b>Abstract: </b>We consider the problem of learning a mixture of linear regressions (MLRs).
An MLR is specified by $k$ nonnegative mixing weights $p_1, \ldots, p_k$
summing to $1$, and $k$ unknown regressors $w_1,...,w_k\in\mathbb{R}^d$. A
sample from the MLR is drawn by sampling $i$ with probability $p_i$, then
outputting $(x, y)$ where $y = \langle x, w_i \rangle + \eta$, where
$\eta\sim\mathcal{N}(0,\varsigma^2)$ for noise rate $\varsigma$. Mixtures of
linear regressions are a popular generative model and have been studied
extensively in machine learning and theoretical computer science. However, all
previous algorithms for learning the parameters of an MLR require running time
and sample complexity scaling exponentially with $k$.
</p>
<p>In this paper, we give the first algorithm for learning an MLR that runs in
time which is sub-exponential in $k$. Specifically, we give an algorithm which
runs in time $\widetilde{O}(d)\cdot\exp(\widetilde{O}(\sqrt{k}))$ and outputs
the parameters of the MLR to high accuracy, even in the presence of nontrivial
regression noise. We demonstrate a new method that we call "Fourier moment
descent" which uses univariate density estimation and low-degree moments of the
Fourier transform of suitable univariate projections of the MLR to iteratively
refine our estimate of the parameters. To the best of our knowledge, these
techniques have never been used in the context of high dimensional distribution
learning, and may be of independent interest. We also show that our techniques
can be used to give a sub-exponential time algorithm for learning mixtures of
hyperplanes, a natural hard instance of the subspace clustering problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.07629"><span class="datestr">at December 18, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.07600">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.07600">Trapezoidal Sketch: A Sketch Structure for Frequency Estimation of Data Streams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ning.html">Ning Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhaoxin.html">Zhaoxin Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Wan.html">Wan Du</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Alex_X=.html">Alex X. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Rui.html">Rui Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuan:Xin.html">Xin Yuan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.07600">PDF</a><br /><b>Abstract: </b>The sketch is one of the typical and widely used data structures for
estimating the frequencies of items in data streams. However, since the counter
sizes in the traditional rectangular-structure sketch (rstructure sketch) are
the same, it is hard to achieve small space usage, high capacity (i.e., the
maximum counter size of the sketch), and high estimation accuracy
simultaneously. Moreover, when considering the high skewness of data streams,
this will become even worse [15]. Therefore, in this paper, we firstly propose
the trapezoidal-structure sketch (t-structure sketch). In the t-structure
sketch, different from the r-structure sketch, the counter sizes in different
layers are different. Based on this innovation, the low space usage and high
capacity can be achieved simultaneously in the t-structure sketch. Then, based
on the basic t-structure sketch, we propose the space saving t-structure sketch
and the capacity improvement t-structure sketch, and analyze the properties of
these two t-structure sketches. Finally, considering the estimation accuracy in
the original version of the t-structure sketch is slightly worse than that in
the r-structure sketch, we propose the probabilistic based estimation error
reducing algorithm to improve the estimation accuracy in t-structure sketch.
Compared with the CM sketch, CU sketch, C sketch, and A sketch, the simulation
results show that the performances on space usage, capacity, and estimation
accuracy are improved successfully by t-structure sketch.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.07600"><span class="datestr">at December 18, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1912.07599">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1912.07599">Game Theory based Joint Task Offloading and Resources Allocation Algorithm for Mobile Edge Computing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yan:Jianen.html">Jianen Yan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Ning.html">Ning Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhaoxin.html">Zhaoxin Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Alex_X=.html">Alex X. Liu</a>, Jose Fernan Martinez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuan:Xin.html">Xin Yuan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1912.07599">PDF</a><br /><b>Abstract: </b>Mobile edge computing (MEC) has emerged for reducing energy consumption and
latency by allowing mobile users to offload computationally intensive tasks to
the MEC server. Due to the spectrum reuse in small cell network, the inter-cell
interference has a great effect on MEC performances. In this paper, for
reducing the energy consumption and latency of MEC, we propose a game theory
based approach to join task offloading decision and resources allocation
together in the MEC system. In this algorithm, the offloading decision, the CPU
capacity adjustment, the transmission power control, and the network
interference management of mobile users are regarded as a game. In this game,
based on the best response strategy, each mobile user makes their own utility
maximum rather than the utility of the whole system. We prove that this game is
an exact potential game and the Nash equilibrium (NE) of this game exists. For
reaching the NE, the best response approach is applied. We calculate the best
response of these three variables. Moreover, we investigate the properties of
this algorithm, including the convergence, the computational complexity, and
the Price of anarchy (PoA). The theoretical analysis shows that the inter-cell
interference affects on the performances of MEC greatly. The NE of this game is
Pareto efficiency. Finally, we evaluate the performances of this algorithm by
simulation. The simulation results illustrate that this algorithm is effective
in improving the performances of the multi-user MEC system.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1912.07599"><span class="datestr">at December 18, 2019 11:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/17/faculty-position-in-algorithms-and-complexity-at-university-of-edinburgh-apply-by-january-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/17/faculty-position-in-algorithms-and-complexity-at-university-of-edinburgh-apply-by-january-31-2020/">Faculty Position in Algorithms and Complexity at University of Edinburgh (apply by January 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The School of Informatics at the University of Edinburgh invites applicants for Lecturer (“Assistant Professor”), and Reader (“Associate Professor”) in Algorithms and Complexity for Optimisation.</p>
<p>For a full advert for the post, and how to apply, please see the link below.</p>
<p>Website: <a href="https://www.vacancies.ed.ac.uk/pls/corehrrecruit/erq_jobspec_version_4.jobspec?p_id=050688">https://www.vacancies.ed.ac.uk/pls/corehrrecruit/erq_jobspec_version_4.jobspec?p_id=050688</a><br />
Email: kousha@inf.ed.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/17/faculty-position-in-algorithms-and-complexity-at-university-of-edinburgh-apply-by-january-31-2020/"><span class="datestr">at December 17, 2019 06:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16469">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/12/15/an-ancient-conjecture-on-primes/">An Ancient Conjecture on Primes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>After 50 years we still are baffled by the primes.</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/12/hartmaniswhiteboard-1.png"><img src="https://rjlipton.files.wordpress.com/2019/12/hartmaniswhiteboard-1.png?w=134&amp;h=200" alt="" width="134" class="alignright wp-image-16473" height="200" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cornell faculty album <a href="https://digital.library.cornell.edu/catalog/ss:547397">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Juris Hartmanis needs no introduction. But we can note this long <a href="https://www.youtube.com/watch?v=AxbKu7MrqA4">interview</a> last February by the Heidelberg Laureate Foundation. His sister, Astrid Ivask, was a <a href="https://www.worldliteraturetoday.org/blog/literary-tributes/tribute-astrid-ivask-literary-light">world</a>–<a href="https://en.wikipedia.org/wiki/Astrid_Ivask">recognized</a> poet.</p>
<p>
Today Ken and I wish to discuss one of his old conjectures.</p>
<p>
We have previously discussed one of his conjectures <a href="https://rjlipton.wordpress.com/2009/02/24/a-conjecture-of-hartmanis/">here</a>. The conjecture we are interested in his one made in his joint <a href="https://ecommons.cornell.edu/handle/1813/5864">paper</a> with Herbert Shank titled, “On the Recognition of Primes by Automata.”</p>
<p>
Shank once wrote a paper <a href="https://www.cambridge.org/core/journals/journal-of-symbolic-logic/article/on-the-undecidability-of-finite-planar-cubic-graphs1/84518469D4AF1774ADE070EBA56601C9">On the undecidability of finite planar cubic graphs</a> with Solomon Garfunkel. I, Dick, liked this paper because it honestly pointed out that a predecessor paper by them was erroneous:</p>
<blockquote><p><b> </b> <em> In the March, 1971 issue of this Journal (JSL) a paper of ours was published purporting to prove the hereditary undecidability of the first-order theory of finite planar graphs. The proof presented there contains an error which is unfortunately “unfixable” by the methods of that paper. The theorem however is true and we demonstrate here a generalization to finite cubic (exactly three edges at each vertex) planar graphs. The method involves coding the halting problem for a Turing machine into the theory of these graphs by considering special printouts of computations. Let us first consider a discussion of the aforementioned mistake and see what can be learned from it <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /> </em>
</p></blockquote>
<p>
</p><p></p><h2> The Primality Space Conjecture </h2><p></p>
<p></p><p>
Hartmanis and Shank (HS) asked the following conjecture—over fifty years ago—about testing whether an integer is a prime number: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++01%2C11%2C101%2C111%2C1101%2C1011%2C10001%2C+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  01,11,101,111,1101,1011,10001, \dots " class="latex" title="\displaystyle  01,11,101,111,1101,1011,10001, \dots " /></p>
<p>We’ve written them in binary notation with the ones’ place first—just the way to give numbers on the input tape of a Turing machine. No error in their Turing representation here—just their brilliant conjecture connecting space to number theory: Suppose that primality is computed in space <img src="https://s0.wp.com/latex.php?latex=%7BS%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(n)}" class="latex" title="{S(n)}" />. Then 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28n%29+%5Cge+cn%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S(n) \ge cn, " class="latex" title="\displaystyle  S(n) \ge cn, " /></p>
<p>for some <img src="https://s0.wp.com/latex.php?latex=%7Bc%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c&gt;0}" class="latex" title="{c&gt;0}" />. That is, any primality test must take linear space. </p>
<p>
As usual, space is the measure of how much storage the algorithm must use. The input tape is read-only and does count against the storage bound. The famous AKS primality test showed that whether a given <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit number <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is prime can be determined in <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^{O(1)}}" class="latex" title="{n^{O(1)}}" /> time but did not improve the linear upper bound on space, which HS showed by trivial means: Try all possible divisors between <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{x}}" class="latex" title="{\sqrt{x}}" />. The arithmetic and loop for this method can all be conducted in <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n)}" class="latex" title="{O(n)}" /> space.</p>
<p>
What is some intuition for this conjecture? Why insist the space be <em>linear</em> when <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B1-%5Cepsilon%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^{1-\epsilon}}" class="latex" title="{n^{1-\epsilon}}" /> space is plenty—given that polynomial time could still be equal to logspace? Well, suppose <img src="https://s0.wp.com/latex.php?latex=%7BS%28n%29+%5Cll+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(n) \ll n}" class="latex" title="{S(n) \ll n}" /> and consider the integers <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> from <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{n-1}}" class="latex" title="{2^{n-1}}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n}" class="latex" title="{2^n}" />, that is all having <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> bits in binary notation. The number of machine configurations apart from the content <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> of the input tape is at most:</p>
<ul>
<li>
<img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28S%28n%29%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{O(S(n))}}" class="latex" title="{2^{O(S(n))}}" /> possible contents of the <img src="https://s0.wp.com/latex.php?latex=%7BS%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(n)}" class="latex" title="{S(n)}" /> worktape cells, times <p></p>
</li><li>
<img src="https://s0.wp.com/latex.php?latex=%7Bn%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n+1}" class="latex" title="{n+1}" /> input head positions, times <img src="https://s0.wp.com/latex.php?latex=%7BS%28n%29%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(n)+1}" class="latex" title="{S(n)+1}" /> or so worktape head positions, times <p></p>
</li><li>
the finite number of states.
</li></ul>
<p>
This is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cll+N+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ll N = 2^n}" class="latex" title="{\ll N = 2^n}" />. In fact, it is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cll+%5Cfrac%7BN%7D%7Bn%7D+%3D+%5Cfrac%7BN%7D%7B%5Cln+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ll \frac{N}{n} = \frac{N}{\ln N}}" class="latex" title="{\ll \frac{N}{n} = \frac{N}{\ln N}}" /> which is asymptotically the number of those <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> that are prime according to the Prime Number Theorem. This means that the vast majority of prime numbers have <em>no</em> worktape configuration that is unique to their accepting computation, not even close. Thus each configuration would be shared with many other primes—and most would be shared with many non-primes as well. Whereas many non-primes are composite for the same reason—such as all strings beginning with <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> being even—the intuition is that each prime has its distinct track of reasons that ought not to come together with other primes.</p>
<p>
</p><p></p><h2> Less Space </h2><p></p>
<p></p><p>
The HS paper notes that since the set of primes is not regular, it needs at least order-of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5Clog%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log\log(n)}" class="latex" title="{\log\log(n)}" /> space. This is a weak lower bound. </p>
<p>
Both the bound and the above intuition become sharper if we require that the input tape be <em>one-way</em> as well as read-only: its head cannot go left to re-read lower-order bits. Every non-regular language requires order-of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log(n)}" class="latex" title="{\log(n)}" /> space by such 1-way machines. </p>
<p>
If we write the prime numbers in unary notation—that is, <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%5Em+%3A+m+%5Ctext%7B+is+prime%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0^m : m \text{ is prime}\}}" class="latex" title="{\{0^m : m \text{ is prime}\}}" />—then we can prove they cannot be recognized by a machine <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> in <img src="https://s0.wp.com/latex.php?latex=%7Bo%28%5Clog+m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{o(\log m)}" class="latex" title="{o(\log m)}" /> space. Having the input tape be unary makes the whole computation depend on the configuration of <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> as described above. In consequence, <img src="https://s0.wp.com/latex.php?latex=%7BL%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L(M)}" class="latex" title="{L(M)}" /> has infinite arithmetic progressions of accepted strings. But by the celebrated theorem of Gustav Dirichlet, each such progression contains infinitely many primes as well as infinitely-many non-primes.  </p>
<p>
Scaling back from unary to binary seems to scale the space up to linear, so perhaps this result supports the HS conjecture. HS make related observations about log space and the density of the primes in the paper.  On the other hand, polynomial time could still be equal to logspace (with two-way input tape), which would make their conjecture wrong. </p>
<p>
</p><p></p><h2> Another Prime Conjecture </h2><p></p>
<p></p><p>
We believe that the HS conjecture is hard, is related to some interesting questions, and could be false. That is, there might be some way to check that a number is prime in <img src="https://s0.wp.com/latex.php?latex=%7Bo%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{o(n)}" class="latex" title="{o(n)}" /> space. Proving lower bounds on space remains, after many decades, hopeless.</p>
<p>
Here is a related conjecture. Using the same binary representation as above—where <img src="https://s0.wp.com/latex.php?latex=%7B1011%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1011}" class="latex" title="{1011}" /> is 13 and <img src="https://s0.wp.com/latex.php?latex=%7B10001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{10001}" class="latex" title="{10001}" /> is 17—Jeffrey Shallit has <a href="https://cs.uwaterloo.ca/~shallit/Talks/bc4.pdf">asked</a> whether we can determine whether a given finite automaton accepts <i>some</i> input so that it is a prime number. We believe it is still open. Let’s assume for the moment that it is true. Then we can solve some open questions in number theory related to primes. This problem unlike the HS is worth some money. For example, the above would pay 50 British pounds—about $66.62. </p>
<p>
Jeff points out that if the above is decidable then one can solve the famous problem: Are there any Fermat primes that are not known? Recall a Fermat prime is one of the form 	 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%5E%7B2%5E%7B%5Cell%7D%7D+%2B+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  2^{2^{\ell}} + 1. " class="latex" title="\displaystyle  2^{2^{\ell}} + 1. " /></p>
<p>The largest one known is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++2%5E%7B2%5E%7B4%7D%7D+%2B+1+%3D+65%2C%5C%21537.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  2^{2^{4}} + 1 = 65,\!537." class="latex" title="\displaystyle  2^{2^{4}} + 1 = 65,\!537." /></p>
<p>All such primes match the regular expression <img src="https://s0.wp.com/latex.php?latex=%7B10%5E%2A1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{10^*1}" class="latex" title="{10^*1}" /> in binary notation, which is easy for a finite automaton to recognize. This expression matches numbers of the form <img src="https://s0.wp.com/latex.php?latex=%7B2%5Ek+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^k + 1}" class="latex" title="{2^k + 1}" />, but as we discussed <a href="https://rjlipton.wordpress.com/2018/06/01/almost-fermat-primes/">here</a>, they can be prime only when <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> is a power of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Why are simple complexity questions about primes so hard? Why indeed?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/12/15/an-ancient-conjecture-on-primes/"><span class="datestr">at December 15, 2019 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2019-12-15-asynchrony-uncommitted-lower-bound/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2019-12-15-asynchrony-uncommitted-lower-bound/">The FLP Impossibility, Asynchronous Consensus Lower Bound via Uncommitted Configurations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Ittai Abraham</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this third post, we conclude with the celebrated Fischer, Lynch, and Paterson impossibility result from 1985. It is the fundamental lower bound for consensus in the asynchronous model. Theorem 1 (FLP85): Any protocol $\mathcal{P}$ solving consensus in the asynchronous model that is resilient to even just one crash failure...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2019-12-15-asynchrony-uncommitted-lower-bound/"><span class="datestr">at December 15, 2019 05:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2019-12-15-synchrony-uncommitted-lower-bound/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2019-12-15-synchrony-uncommitted-lower-bound/">Synchronous Consensus Lower Bound via Uncommitted Configurations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Ittai Abraham</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this second post, we show the fundamental lower bound on the number of rounds for consensus protocols in the synchronous model. Theorem 1: Any protocol solving consensus in the synchronous model that is resilient to $t$ crash failures must have an execution with at least $t+1$ rounds. Bad news:...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2019-12-15-synchrony-uncommitted-lower-bound/"><span class="datestr">at December 15, 2019 05:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2019-12-15-consensus-model-for-FLP/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2019-12-15-consensus-model-for-FLP/">Consensus Lower Bounds via Uncommitted Configurations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Ittai Abraham</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this series of three posts, we discuss two of the most important consensus lower bounds: Lamport, Fischer [1982]: any protocol solving consensus in the synchronous model that is resilient to $t$ crash failures must have an execution with at least $t+1$ rounds. Fischer, Lynch, and Patterson [1983, 1985]: any...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2019-12-15-consensus-model-for-FLP/"><span class="datestr">at December 15, 2019 05:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/12/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/12/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://www.theguardian.com/education/2019/dec/01/lib-dems-brexit-brain-drain-eu-academics">Figures show 11,000 academics have left UK universities in the three years since the Brexit referendum</a>.</p>
  </li>
  <li>
    <p><a href="https://www.latimes.com/california/story/2019-12-02/american-computer-expert-arrested-north-korea-talk-cryptocurrency">US arrests an American computer scientist for giving a talk at a conference</a> (<a href="https://mathstodon.xyz/@11011110/103242730915859586"></a>). It was in North Korea, on cryptocurrency, but from the story doesn’t appear to have covered anything that isn’t widely known elsewhere.</p>
  </li>
  <li>
    <p>Mathematicians get riled up about mandatory diversity statements and recommendations that above-average contributions to diversity be used as a hard filter for all faculty job candidates (<a href="https://mathstodon.xyz/@11011110/103248639071738786"></a>, <a href="https://www.insidehighered.com/news/2019/11/19/mathematician-comes-out-against-mandatory-diversity-statements-while-others-say-they">via</a>, <a href="https://mathstodon.xyz/@pkra/103237286846736065">via2</a>, <a href="https://cybre.space/@zardoz/103310868212435260">via3</a>): <a href="https://www.ams.org/journals/notices/201911/rnoti-p1778.pdf">Abigail Thompson sees mandated loyalty to political positions (such as prioritizing diversity) as anti-academic freedom</a>, kicking off the debate. <a href="https://ilaba.wordpress.com/2019/12/01/diversity-statements/">Izabella Laba disagrees but prefers institutional action to lip-service statements of good intentions</a> and argues that unrealistic expectations on faculty (like that they all be simultaneously outstanding in teaching, research, and now also diversity) can backfire by favoring the kind of male faculty member who takes advantage of an unpaid wife as his assistant. <a href="https://www.ams.org/journals/notices/202001/rnoti-o1.pdf">Many others weigh in</a> in the letters to the editor of the <em>Notices</em>.</p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/5-Ways-to-Welcome-Women-to/247541">Five ways to welcome women to computer science</a> (<a href="https://mathstodon.xyz/@11011110/103256355399857427"></a>).</p>
  </li>
  <li>
    <p><a href="https://theaggie.org/2019/12/05/yuval-peres-math-professor-with-series-of-sexual-misconduct-allegations-levied-against-him-gives-lecture-at-uc-davis/">Davis student newspaper provides thorough roundup of sexual harassment charges against Yuval Peres</a> (<a href="https://mathstodon.xyz/@11011110/103259258824223410"></a>). They missed the <a href="https://en.wikipedia.org/wiki/Wikipedia:Sockpuppet_investigations/Pedantisch/Archive">side drama of sockpuppets and meatpuppets cleaning this from his Wikipedia article</a>, though, or maybe omitted it for lack of evidence connecting it to Peres himself. This is sad. Why would someone with so much to give to the field be so self-destructive and so destructive of the lives and careers of others around him?</p>
  </li>
  <li>
    <p>More stupid commercial journal publisher tricks (<a href="https://mathstodon.xyz/@11011110/103264128297632805"></a>): Wiley won’t honor my institutional subscription unless I enable third-party cookies in my browser. So I can</p>

    <ol>
      <li>
        <p>decrease my browser security on all sites,</p>
      </li>
      <li>
        <p>not read papers by László Babai on J. Graph Theory,</p>
      </li>
      <li>
        <p>ask my librarian for a copy, making much more work and delay for all but maybe letting the publisher know how much negative value-added they’re providing, or</p>
      </li>
      <li>
        <p>become a pirate.</p>
      </li>
    </ol>

    <p><a href="https://en.wikipedia.org/wiki/Sci-Hub">Sci-Hub</a> to the rescue! Yo ho!</p>

    <p>Also while I’m picking on Wiley, how did <a href="https://doi.org/10.1002/cpe.5484">He et al., “A polynomial‐time algorithm for simple undirected graph isomorphism”</a> ever pass peer review for their journal <em>Concurrency and Computation, Practice and Experience</em>, or even a basic sanity check that it has a coherent topic that fits the mission of the journal?</p>
  </li>
  <li>
    <p><a href="https://blogs.scientificamerican.com/roots-of-unity/the-surprising-link-between-recreational-math-and-undecidability/">The surprising link between recreational math and undecidability</a> (<a href="https://mathstodon.xyz/@11011110/103267941967518229"></a>). Evelyn Lamb describes how a seemingly isolated fact about Fibonacci numbers () led to Matiyasevich’s solution to Hilbert’s 10th problem, that there is no general algorithm for solving Diophantine equations.</p>
  </li>
  <li>
    <p><a href="https://www.maureeneppstein.com/mve_journal/?p=2028">My mother has a new book of poetry coming out</a> (<a href="https://mathstodon.xyz/@11011110/103273857130169711"></a>). I think this is her fifth, after Earthward (Finishing Line Press, 2014), Rogue Wave at Glass Beach (March Street Press, 2009), Quickening (March Street Press, 2007), and A Place Called Home (Monday Press, 1995).</p>
  </li>
  <li>
    <p><a href="https://commons.wikimedia.org/wiki/File:Osculating_circles_of_the_Archimedean_spiral.svg">This image by Adam Majewski</a> (<a href="https://mathstodon.xyz/@11011110/103279309793264877"></a>) shows the osculating circles of an Archimedean spiral. The spiral itself is not shown, but you can see it anyway, where the circles become dense.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/archimedean-osculation.svg" alt="Osculating circles of the Archimedean spiral" /></p>

    <p>It is not unusual that the circles nest. By the <a href="https://en.wikipedia.org/wiki/Tait%E2%80%93Kneser_theorem">Tait–Kneser theorem</a> this happens whenever the curvature along a curve is monotonic. And on most smooth curves, the curvature is monotonic except at a small number of points called vertices.</p>
  </li>
  <li>
    <p><a href="http://chalkdustmagazine.com/front-page-banner/constructing-the-cover-of-issue-10/">Chalkdust magazine provides a compass-and-straightedge construction for the girih pattern on the cover of a recent issue</a> (<a href="https://mathstodon.xyz/@11011110/103284659404495472"></a>).</p>
  </li>
  <li>
    <p><a href="https://twitter.com/textfiles/status/1204428311553642496">How archive.org preserves the history of the web, and why you should care</a> (<a href="https://mathstodon.xyz/@11011110/103291205125122328"></a>, <a href="https://news.ycombinator.com/item?id=21764592">via</a>). Meanwhile, <a href="https://modsandmembersblog.wordpress.com/2019/12/08/verizon-yahoo-bad-form/">Verizon sabotages efforts to archive Yahoo Groups content, in the face of their plans to shut much of it down</a> (<a href="https://news.ycombinator.com/item?id=21737696">via</a>, <a href="https://boingboing.net/2019/12/08/oath-makes-you-swear-2.html">via2</a>).</p>
  </li>
  <li>
    <p><a href="https://randomascii.wordpress.com/2019/12/08/on2-again-now-in-wmi/"> in Windows Management Instrumentation</a> (<a href="https://mathstodon.xyz/@11011110/103299014968956821"></a>, <a href="https://news.ycombinator.com/item?id=21743424">via</a>). This is why understanding algorithm analysis is important: even when the constant factors are very small (here, a nine-instruction loop), quadratic time can mean significant delays. The post also introduces “Dawson’s first law of computing:  is the sweet spot of badly scaling algorithms: fast enough to make it into production, but slow enough to make things fall down once it gets there.”</p>
  </li>
  <li>
    <p>Two recently-posted geometry puzzles (neither of which I have seriously attempted to answer (<a href="https://mathstodon.xyz/@11011110/103304781327067493"></a>):</p>

    <ol>
      <li>
        <p><a href="https://discrete-notes.github.io/polygon%20problem">If you expand a convex polygon along one coordinate axis while leaving the other coordinate unchanged, can the original polygon always fit into the expanded copy (perhaps with some rotation or translation)?</a></p>
      </li>
      <li>
        <p><a href="https://fivethirtyeight.com/features/can-you-solve-a-particularly-prismatic-puzzle/">How many different integer rectangular cuboids have (ignoring units) volume = surface area?</a></p>
      </li>
    </ol>
  </li>
  <li>
    <p><a href="http://math.ucr.edu/home/baez/permutations/">John Baez collects more than you wanted to know about the statistics of random permutations</a> (<a href="https://mathstodon.xyz/@11011110/103310641851251562"></a>). The really pretty ones are Part 3 puzzle 8: What is the probability that a chosen element of an -element permutation lies in a cycle of length ? And part 6 puzzle 7 (don’t ask me how the numbering works): What is the expected number of -cycles in a random -element permutation?</p>
  </li>
  <li>
    <p><a href="https://wild.maths.org/folding-fractions">Folding fractions</a> (<a href="https://mathstodon.xyz/@11011110/103314218243317735"></a>). There’s a standard compass-and-straightedge construction for dividing a line segment evenly into a given number of smaller segments, and origami folding constructions are (depending on the model of what is allowed) at least as powerful, so it shouldn’t be surprising that you can fold arbitrary even subdivisions of the side of an origami square. But this construction of  from  by Kazuo Haga is particularly elegant.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/12/15/linkage.html"><span class="datestr">at December 15, 2019 03:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/182">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/182">TR19-182 |  The Limitations of Few Qubits: One-way and Two-way Quantum Finite Automata and the Group Word Problem | 

	Zachary Remscrim</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The two-way finite automaton with quantum and classical states (2QCFA), defined by Ambainis and Watrous, is a model of quantum computation whose quantum part is extremely limited; however, as they showed, 2QCFA are surprisingly powerful: a 2QCFA with only a single-qubit can recognize the language $L_{pal}=\{w \in \{a,b\}^*:w \text{ is a palindrome}\}$ with bounded-error in expected exponential time. We prove that their result essentially cannot be improved upon: a 2QCFA (of any finite size) cannot recognize $L_{pal}$ with bounded-error in expected time $2^{o(n)}$, on inputs of length $n$. To our knowledge, this is the first example of a language that can be recognized with bounded-error by a 2QCFA in exponential time but not in subexponential time. A key tool in our result is a generalization to 2QCFA of a technical lemma that was used by Dwork and Stockmeyer to prove a lower bound on the expected running time of any two-way probabilistic finite automaton that recognizes a non-regular language with bounded-error. 

Furthermore, we prove strong lower bounds on the expected running time of any 2QCFA that recognizes a group word problem with bounded-error. In a recent paper, we showed that 2QCFA can recognize, with bounded-error, a broad class of group word problems in expected exponential time, and a more narrow class of group word problems in expected polynomial time. As a consequence, we can now exhibit a large family of natural languages that can be recognized with bounded-error by a 2QCFA in expected exponential time, but not in expected subexponential time. Moreover, we obtain significant progress towards a precise classification of those group word problems that can be recognized with bounded-error in expected polynomial time by a 2QCFA.

We also consider the one-way measure-once quantum finite automaton (1QFA), defined by Moore and Crutchfield, as well as a natural generalization to one-way measure-once finite automata with quantum and classical states (1QCFA). We precisely classify those groups whose word problem may be recognized with positive one-sided error (for both the bounded-error and unbounded-error cases) by a 1QFA or 1QCFA with any particular number of quantum states and any particular number of classical states; we also obtain partial results in the negative one-sided error case. As an immediate corollary, we show that allowing a 1QFA or 1QCFA to have even a single additional quantum or classical state enlarges the class of languages that may be recognized with positive one-sided error (of either type).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/182"><span class="datestr">at December 15, 2019 06:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/181">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/181">TR19-181 |  A Separator Theorem for Hypergraphs and a CSP-SAT Algorithm | 

	Navid Talebanfard, 

	Michal Koucky, 

	Vojtech Rodl</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that for every $r \ge 2$ there exists $\epsilon_r &gt; 0$ such that any $r$-uniform hypergraph on $m$ edges with bounded vertex degree has a set of at most $(\frac{1}{2} - \epsilon_r)m$ edges the removal of which breaks the hypergraph into connected components with at most $m/2$ edges. We use this to give a satisfiability algorithm for $n$-variable $(d, k)$-CSPs in which every variable appears in at most $r$ constraints in time $d^{(1 - \epsilon_r)n}$ where $\epsilon_r$ depends only on $r$, provided that $k$ is small enough as a function of $m$. We will also show that unsatisfiable $(2, k)$-CSPs with variable frequency $r$ can be refuted in tree-like resolution in size $2^{(1 - \epsilon_r)n}$. Furthermore for Tseitin formulas on graphs with degree at most $k$ (which are $(2, k)$-CSPs) we give a deterministic algorithm finding such a refutation.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/181"><span class="datestr">at December 13, 2019 02:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-7376087648863245436">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/12/why-is-there-no-all-encompassing-term.html">Why is there no all-encompassing term for a course on Models of Computation?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In my <a href="https://blog.computationalcomplexity.org/2019/12/what-do-you-call-your-ugrad-non.html">last blog post</a> I asked my readers to leave comments saying what the name of the course that has some of Regular Languages, Context Free Languages  Decideability, P, NP (any maybe other stuff) in it.  I suspected there would be many different names and their were. I was able to put all but 6 into 4 equivalence classes. So that's 10 names. Thats a lot  especially compared to<br />
<br />
(Introduction to) Algorithms<br />
<br />
and<br />
<br />
(Introduction to) Cryptography<br />
<br />
which I suspect have far fewer names. One commenter pointed out that the reason for the many different names is that there are many versions of the course. That's not quite an explanation since there are also many different versions of Cryptography---at UMCP  crypto is cross listed in THREE departments (CS, Math, EE) and its taught by 6 or so different people who don't talk to each other (I am one of them). I think Algorithms is more uniform across colleges.<br />
<br />
I think that terms Algorithms and Cryptography are both rather broad and can accommodate many versions of the courses, whereas no term seems to be agreed upon to encompass the DFA etc course.<br />
Even saying DFA etc is not quite right since some of the courses spend little or even no time on DFA's.<br />
<br />
Below is a list of all the names I got and some comments. Note that some schools appear twice since they have two courses along these lines.<br />
<br />
-----------------------------------------<br />
TITLE: (Introduction to) Theory of Computation:<br />
<br />
Swarthmore:                                            Theory of Computation<br />
<br />
UCSD:                                                     Theory of Computation<br />
<br />
Saint Michaels:                                        Theory of Computation<br />
<br />
Univ of Washington: Introduction to the Theory of Computation<br />
<br />
Waterloo:                  Introduction to the Theory of Computing<br />
<br />
COMMENT: Theory of Computation could have been the term that encompasses all of these courses. I speculate that it didn't catch on since it sounds too much like computability theory which is only one part of the course.<br />
<br />
------------------------<br />
TITLE: Formal Languages and XXX<br />
<br />
CMU:                                                Formal Languages, Automata, and Computability<br />
<br />
Florida Tech:                                    Formal Languages and Automata Theory<br />
<br />
UC-Irvine:                                        Formal Languages and Automata Theory<br />
<br />
Univ of Chicago:    Introduction to Formal Languages<br />
<br />
University of Bucharest:                 Formal Language and Automata<br />
<br />
TU Darmstadt:                                Formal Foundations of CS I: Automata, Formal Languages, and Decidability<br />
<br />
TUK Germany:                               Formal Languages and Computability<br />
<br />
COMMENT: The title makes it sound like they don't cover P and NP. I do not know if thats true; however, I speculate that, it could never be the encompassing term.<br />
<br />
Spell Check things Automata and Computability are not words, but I've googled them and they seem to be words.<br />
<br />
--------------------------<br />
TITLE: Computability/Decidability and Complexity/Intractability<br />
<br />
Reed College: Computability and Complexity<br />
<br />
Caltech:          Decidability and Intractability<br />
<br />
COMMENT: The title makes it sound like they don't cover regular or context free languages. I do not know if that's true; however, I speculate that, since the terms sound that way, they never caught on as the general term.<br />
<br />
Spellecheck thinks that neither Decidability nor Decideability is a word. Google seems to say that I should leave out the e, so I will.<br />
<br />
------------------------------<br />
TITLE:  Blah MODELS Blah<br />
<br />
Tel-Aviv (a long time ago) Computational Models<br />
<br />
UIUC:                               Algorithms and Models of Computation (also has some algorithms in it)<br />
<br />
Waterloo:                                                   Models of Computation (enriched version)<br />
<br />
COMMENT: Models of Computation sounds like a good name for the course! Too bad it didn't catch on.  It would also be able to withstand changes in the content like more on parallelism or more on communication complexity.<br />
<br />
------------------------------<br />
TITLE: MISC<br />
<br />
CMU:                                          Great Ideas in Theoretical Computer Science<br />
<br />
UCLouvain (Belgium)                Calculabilite (Computability)<br />
<br />
Moscow Inst. of  Phy. and Tech.: Mathematical logic and Theory of Algorithms<br />
<br />
Portland State University:            Computational Structures<br />
<br />
Germany:                                     Informatik III (Not all of Germany)<br />
<br />
Univ of Chicago:                         Introduction to Complexity<br />
<br />
COMMENT: All of these terms are to narrow to have served as a general term.<br />
<div>
<br /></div>
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/12/why-is-there-no-all-encompassing-term.html"><span class="datestr">at December 12, 2019 08:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/12/postdoc-at-university-of-illinois-at-chicago-apply-by-december-31-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/12/postdoc-at-university-of-illinois-at-chicago-apply-by-december-31-2019/">Postdoc at University of Illinois at Chicago (apply by December 31, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The MSCS department has an opening for a 3-year postdoc in the “Foundations of Data Science” under its newly received TRIPODS grant.</p>
<p>All areas of TCS related to data science (broadly interpreted) will be considered. The position carries a teaching load of 1 graduate course per year and a competitive salary.</p>
<p>For more information on UIC’s TRIPODS center, visit: <a href="https://tripods.uic.edu/">https://tripods.uic.edu/</a></p>
<p>Website: <a href="https://www.mathjobs.org/jobs/jobs/15259">https://www.mathjobs.org/jobs/jobs/15259</a><br />
Email: lreyzin@uic.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/12/postdoc-at-university-of-illinois-at-chicago-apply-by-december-31-2019/"><span class="datestr">at December 12, 2019 05:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/12/faculty-position-in-quantum-information-at-harvard-university-apply-by-december-15-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/12/faculty-position-in-quantum-information-at-harvard-university-apply-by-december-15-2019/">Faculty position in Quantum Information at Harvard University (apply by December 15, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Harvard Quantum Initiative, Departments of Physics, Chemistry and the SEAS areas of Computer Science and Electrical Engineering seek to appoint a tenure-track professor in the broad theoretical domain of quantum information. Areas of interest may include but are not limited to quantum algorithms, communication, complexity, control, and the physics of quantum information systems.</p>
<p>Website: <a href="https://academicpositions.harvard.edu/postings/9396">https://academicpositions.harvard.edu/postings/9396</a><br />
Email: cploucha@fas.harvard.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/12/faculty-position-in-quantum-information-at-harvard-university-apply-by-december-15-2019/"><span class="datestr">at December 12, 2019 03:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/12/faculty-at-iowa-state-university-apply-by-january-13-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/12/faculty-at-iowa-state-university-apply-by-january-13-2020/">Faculty at Iowa State University (apply by January 13, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at Iowa State University seeks applicants for a faculty position at the rank of tenure-track Assistant Professor or tenured Associate Professor. We are specifically looking for experts in artificial intelligence, AI decision theory, foundations of machine learning, algorithmic foundations for data science, and algorithmic game theory.</p>
<p>Website: <a href="https://isu.wd1.myworkdayjobs.com/en-US/IowaStateJobs/job/Ames-IA/Assistant-or-Associate-Professor-of-Computer-Science_R1252">https://isu.wd1.myworkdayjobs.com/en-US/IowaStateJobs/job/Ames-IA/Assistant-or-Associate-Professor-of-Computer-Science_R1252</a><br />
Email: mkcrum@iastate.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/12/faculty-at-iowa-state-university-apply-by-january-13-2020/"><span class="datestr">at December 12, 2019 03:16 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/12/postdoc-at-the-chinese-university-of-hong-kong-apply-by-january-15-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/12/postdoc-at-the-chinese-university-of-hong-kong-apply-by-january-15-2020/">Postdoc at The Chinese University of Hong Kong (apply by January 15, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Institute of Theoretical Computer Science and Communications at CUHK is offering positions for postdoctoral fellows whose expertise is in complexity theory, algorithms, information theory, coding theory, cryptography, and other theoretical topics in related areas. The position is for 12 months, renewable for another 12 months subject to satisfactory progress.</p>
<p>Website: <a href="http://www.itcsc.cuhk.edu.hk/Openings.html">http://www.itcsc.cuhk.edu.hk/Openings.html</a><br />
Email: itcsc@cuhk.edu.hk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/12/postdoc-at-the-chinese-university-of-hong-kong-apply-by-january-15-2020/"><span class="datestr">at December 12, 2019 06:49 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/09/tenure-track-faculty-at-university-of-illinois-at-chicago-apply-by-january-13-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/09/tenure-track-faculty-at-university-of-illinois-at-chicago-apply-by-january-13-2020/">Tenure-Track Faculty at University of Illinois at Chicago (apply by January 13, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Mathematics (MSCS) department at UIC is looking for a tenure-track assistant professor to join the “Mathematical Computer Science” group. All areas of theoretical computer science will be considered.</p>
<p>You can learn more about our TCS group on <a href="https://theory.cs.uic.edu/.">https://theory.cs.uic.edu/.</a></p>
<p>Website: <a href="http://mathjobs.org/jobs/jobs/15229">http://mathjobs.org/jobs/jobs/15229</a><br />
Email: lreyzin@uic.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/09/tenure-track-faculty-at-university-of-illinois-at-chicago-apply-by-january-13-2020/"><span class="datestr">at December 09, 2019 09:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1541">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/12/09/quantum-dna-sequencing-the-ultimate-hardness-hypothesis/">Quantum DNA sequencing &amp; the ultimate hardness hypothesis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Longest common subsequence (LCS) and edit distance (ED) are fundamental similarity measures of interest to genomic applications (insertions/deletions/substitutions are a pretty good proxy for both mutations and read errors). The fastest known algorithms for computing the LCS/ED between two <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" />-character strings run in nearly quadratic time. Breakthroughs in fine-grained complexity <a href="https://arxiv.org/abs/1412.0348">[BI18]</a><a href="https://arxiv.org/abs/1511.06022">[AHWW16]</a> from the last few years provide some nice formal barriers further progress: in particular, substantially faster algorithms would refute <em>NC-SETH</em>, the hypothesis that given an NC circuit with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> input bits,  deciding if the circuit has any satisfying assignment requires <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%281-o%281%29%29n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="2^{(1-o(1))n}" class="latex" title="2^{(1-o(1))n}" /> time. (Note that this is a weaker, aka safer, hypothesis than the standard SETH.)</p>
<p> </p>
<h2>Quantum algorithms for edit distance?</h2>
<p>One way to try to circumvent the computational barriers is by approximation algorithms (see my <a href="https://theorydish.blog/2018/07/20/approximating-edit-distance/">blog post</a>). A different approach is to go with quantum algorithms: Grover’s search can solve NC-SAT in <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="2^{n/2}" class="latex" title="2^{n/2}" /> time. Even those of us less skeptic than <a href="https://gilkalai.wordpress.com/2019/11/13/gils-collegial-quantum-supremacy-skepticism-faq/">Gil Kalai</a> can probably agree that quadratic quantum speedups won’t be practical anytime soon. But in theory, I find the question of whether we can design subquadratic quantum algorithms for edit distance very interesting (see also <a href="https://arxiv.org/abs/1804.04178">[BEG+18]</a>).</p>
<p>Alas, even with the power of quantum computers we don’t know any truly subquadratic algorithms for computing LCS/ED. On the other hand, it is not clear how to rule out even linear-time algorithms. A few weeks ago, Buhrman, Patro, and Speelman, posted a <a href="https://arxiv.org/abs/1911.05686">paper</a> that gives a <img src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n^{3/2}" class="latex" title="n^{3/2}" /> quantum <em>query complexity </em>lower bound for LCS/ED.</p>
<blockquote><p>Open Problem: Close the <img src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n^{3/2}" class="latex" title="n^{3/2}" /> vs <img src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n^2" class="latex" title="n^2" /> gap for quantum query complexity of ED/LCS.</p></blockquote>
<p>What is “query complexity” of ED/LCS? Buhrman et al. consider the following query model: In LCS, we want a <strong>maximum monotone matching</strong> between the characters of the two strings, where we can match two characters if they’re identical. Now suppose that in the query complexity problem we still want to find a maximum monotone matching, but instead of the character-equality graph (which is a union of disjoint cliques), we have an arbitrary bipartite graph, and <strong>given a pair of vertices, the oracle tells you if there is an edge between them</strong>.</p>
<p>This model may seem a bit counter-intuitive at first since the graphs may not correspond to any pair of strings; and indeed other models have been considered before <a href="https://dl.acm.org/citation.cfm?id=321922">[UAH76]</a><a href="https://arxiv.org/abs/1005.4033">[AKO10]</a>. But it turns out that this model is well-motivated by the NC-SETH lower bound (see discussion below).</p>
<p> </p>
<h2>The ultimate hardness hypothesis</h2>
<p>What does the <img src="https://s0.wp.com/latex.php?latex=n%5E%7B3%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n^{3/2}" class="latex" title="n^{3/2}" /> query complexity lower bound mean for algorithms on actual strings? Instead of a black box oracle, our algorithms have access to an NC-circuit that implements it. Intuitively, we don’t know how to do very much with white box circuits, so it seems plausible to hypothesize that the running time will be lower bound by the query complexity. In some sense, this is a special case of the following <em>ultimate hardness hypothesis </em>that unifies a lot of the computational hardness assumptions that we like to assume but have no idea how to prove (e.g. P!=NP, P!=BQP, NC-SETH, FP!=PPAD, etc):</p>
<blockquote><p>[Ultimate Hardness Hypothesis] For every problem, the white-box computational complexity is lower bounded by the black-box query complexity.”</p></blockquote>
<p>In communication complexity similar statements are known and are called simulation/lifting theorems (see e.g. <a href="https://theory.stanford.edu/~mika/thesis.pdf">Mika’s thesis</a>). For computational complexity, there are obvious counter examples such as “decide if the oracle can be implemented by a small circuit”. So it only makes sense to continue to assume the ultimate hardness hypothesis for “reasonable problems” instead of “every problem”.</p>
<p>But Burhman et al. identify the following variant of the ultimate hardness hypothesis which I find very interesting. It is defined with respect to a function <img src="https://s0.wp.com/latex.php?latex=T%3A%5C%7B0%2C1%5C%7D%5E%7B2%5En%7D+%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T:\{0,1\}^{2^n} \rightarrow \{0,1\}" class="latex" title="T:\{0,1\}^{2^n} \rightarrow \{0,1\}" /> which takes as input the truth-table of a circuit and outputs True or False. Roughly, they hypothesize that:</p>
<blockquote><p>[Burhman et al.-QSETH, paraphrased] For <em>every</em> <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" />, deciding if <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" /> is true or false is as hard whether we’re given the actual circuit, or only the guarantee that the oracle is implemented by a small circuit”</p></blockquote>
<p>At a first read, I thought that arguments a-la impossibility of obfuscation <a href="https://www.iacr.org/archive/crypto2001/21390001.pdf">[BGI+01]</a> should refute this hypothesis, but a few weeks later I still don’t know how to prove it. Do you?</p>
<p> </p>
<h2>A tip for the upcoming holidays</h2>
<p>During my postdoc, I worked on the quantum query complexity of ED/LCS with Shalev Ben-David, Rolando La Placa, and John Wright. I was a bit bummed to find out that we got scooped by Buhrman et al, but I know of at least 3 other groups that were also scooped by the same paper, so at least we’re in good company <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" alt="🙂" style="height: 1em;" class="wp-smiley" /></p>
<p>At the time, a fellow postdoc from Psychology asked me what I was working on. I resisted the temptation to try to explain the various quantum variants of NC-SETH, and instead told him I was working on “DNA sequencing with quantum computers”. His reaction was priceless. Regardless of what you’re actually working on, try this line during the holidays when your relatives ask you about your work.</p>
<p> </p></div>







<p class="date">
by aviad.rubinstein <a href="https://theorydish.blog/2019/12/09/quantum-dna-sequencing-the-ultimate-hardness-hypothesis/"><span class="datestr">at December 09, 2019 06:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-693865784966232415">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/12/what-do-you-call-your-ugrad-non.html">What do you call your ugrad non-algorithms theory course?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I am in the process of reviewing<br />
<br />
<i>                     What can be computed: A Practical Guide to the Theory of Computation</i><br />
<i>                     by John MacCormick</i><br />
<br />
<br />
and I need YOUR help for the first SENTENCE.  I began by saying<br />
<br />
<br />
                    This is a text book for a course on <i>Formal Language Theory</i><br />
<i><br /></i>
but then I realized that this is not what we call the course at UMCP. Then I got to thinking: what do other schools call it? I have the following so far:<br />
<br />
UMCP: Elementary Theory of Computation<br />
<br />
Harvard: Introduction to Theory of Computation<br />
<br />
MIT: Automata, Computability, and, Complexity<br />
<br />
Clark: Automata Theory<br />
<br />
(My spellcheck does not think Automata is a word. Also Computability. Usually I listen to my spellcheckers, but I checked and YES, I spelled them right.)<br />
<br />
For some other schools I either hit a place I needed an account, or I just got titles without a description so I could not be sure.<br />
<br />This is where YOU come in!<br />
<br />
Please leave comments with your school and the title of the course at your school that covers a reasonable overlap with: Regular Sets, Context Free Sets, Decidable and Undecidble and r.e. sets, P, NP, perhaps other complexity classes, and NP-completeness. Its FINE if your answer is one of the above ones, or one of the other comments--- I plan to later set this up as a pigeonhole principle problem.<br />
<br />
I suspect that courses in algorithms are called <i>Algorithms </i>or <i>Introduction to Algorithms.</i><br />
<i><br /></i>
I suspect that courses in cryptography are called <i>Cryptography </i><i> </i>or <i>Intro to Cryptography.</i><br />
<br />
<br />
Why does the non-algorithm, non-crypto theory course have more names?<br />
<br />
<br />
<br />
<br />
<i><br /></i>
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/12/what-do-you-call-your-ugrad-non.html"><span class="datestr">at December 09, 2019 04:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16454">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/12/08/hctor-garcia-molina-1953-2019/">Héctor Garcia-Molina, 1953–2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>We all lost a great person</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/12/29-11-19-molina.jpg"><img src="https://rjlipton.files.wordpress.com/2019/12/29-11-19-molina.jpg?w=165&amp;h=180" alt="" width="165" class="alignright wp-image-16456" height="180" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Mexican NotiCyTI <a href="https://noticyti.com/politica-cyt-i/742-muere-h%C3%A9ctor-garc%C3%ADa-molina,-el-mexicano-que-contribuy%C3%B3-al-estrellato-de-google-y-cisco.html">obit</a></font></td>
</tr>
</tbody>
</table>
<p>
Héctor Garcia-Molina <a href="https://news.stanford.edu/2019/12/06/hector-garcia-molina-influential-computer-scientist-database-expert-dies-65/">died</a> just before Thanksgiving. He was a computer scientist and Professor in both the Departments of Computer Science and Electrical Engineering at Stanford University.</p>
<p>
Today Ken and I write in sadness about his passing and to express some personal appreciations.<br />
<span id="more-16454"></span></p>
<p>
We at GLL have talked about him before. See <a href="https://rjlipton.wordpress.com/2015/03/08/lint-for-math/">this</a> for his story about the fun of using an IBM mainframe for teaching. Or see <a href="https://rjlipton.wordpress.com/2011/11/03/whos-afraid-of-arrows-paradox/">this</a> for a story about Héctor and meetings.</p>
<p>
I, Dick, had the pleasure to have worked with him, while we were both faculty at Princeton in the 1980’s and beyond.</p>
<p>
</p><p></p><h2> His Clock </h2><p></p>
<p></p><p>
Héctor was the chair of the Stanford Computer Science Department from January 2001 to December 2004. Stanford then rotated the chair so all took their turn. I know that he “hated” being an administrator in general. But of course being a team player he took his turn. </p>
<p>
One way to see his real feelings about being a chair was to look at the clock his students constructed for him. The clock was a digital timer that counted down the seconds that remained in his term as the chair. It started at roughly 126227808. I am sure he did fine, but the clock was a statement. </p>
<p>
</p><p></p><h2> His Worst Paper </h2><p></p>
<p></p><p>
While Héctor was at Princeton we worked together on a project—the <a href="https://rjlipton.wordpress.com/2010/05/20/sorting-out-chess-endgames/">MMM</a> project. It led to one of his least cited papers—a 1984 <a href="https://ieeexplore.ieee.org/document/1676454">paper</a> with me and Jacobo Valdes. OK, it has 48 citations according to IEEE. The idea of the project was to use memory rather than processors to speed up computations. He was a joy to work with: he was careful, and thoughtful, and just fun to work with on any project. </p>
<p>
We did write a second <a href="https://books.google.com/books?id=AMrcBwAAQBAJ&amp;pg=PA565&amp;lpg=PA565&amp;dq=The+Massive+Memory+Machine+Project&amp;source=bl&amp;ots=_QFT07G56P&amp;sig=ACfU3U0-KV060yO3PHRllCnj3Y5o10BX-w&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj7o67o-abmAhXHwFkKHRfzDs4Q6AEwDXoECAkQAQ#v=onepage&amp;q=The Massive Memory Machine Project&amp;f=false">paper</a> with Richard Cullingford instead of Valdes, which Héctor presented at a meeting on knowledge-based management systems. The above Google Books link goes to the end with a <a href="https://books.google.com/books?id=AMrcBwAAQBAJ&amp;pg=PA565&amp;lpg=PA565&amp;dq=The+Massive+Memory+Machine+Project&amp;source=bl&amp;ots=_QFT07G56P&amp;sig=ACfU3U0-KV060yO3PHRllCnj3Y5o10BX-w&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj7o67o-abmAhXHwFkKHRfzDs4Q6AEwDXoECAkQAQ#v=onepage&amp;q=The Massive Memory Machine Project&amp;f=false">discussion</a> in which a simple issue was raised—we paraphrase:</p>
<blockquote><p><b> </b> <em> Won’t it take forever just to write all zeros to the memory? </em>
</p></blockquote>
<p></p><p>
Héctor had a scientist’s answer: the project was still not at the prototype stage so he didn’t know. He said the project should be viewed as a scientific experiment to find out. Maybe he also had an inkling that what was coming was a decade of breakthroughs in CPU design and parallel/pipeline processing after all. </p>
<p>
</p><p></p><h2> His Predictions </h2><p></p>
<p></p><p>
Héctor was unparalleled at seeing the future. I always thought that one of his abilities, one that set him apart, was his ability to predict directions of research. This allowed him, and his students, to write early papers in research areas before they became hot. This is one of the talents that made him so amazing.</p>
<p>
I recall way before the world wide web was created he had students working on adding links to documents. I recall a talk by one of his students at Princeton that discussed what we now call URLs. One question that was raised during the talk was: How were the links going to be created? There was a lively discussion about this. Could they be created automatically? If not why would people take the time to create the links? Indeed.</p>
<p>
Héctor saw that links would be created. That people would take the effort to create them. I must admit that he was right, and he saw the future better than most. I wish I had a fraction of his ability to see directions like he did.</p>
<p>
</p><p></p><h2> Guiding Students </h2><p></p>
<p></p><p>
Héctor told me that when he first got to Stanford the fund managers and investors roamed the halls. They would ask anyone they could if they had an idea for a company or a startup. It was a constant issue that Héctor had to deal with. They were continually trying to steal away students. </p>
<p>
He told me he felt like he was the head of an abbey and was always having to protect his charges within the walls.</p>
<p>
When the impetus came from within it was different. Of course, Héctor was the advisor of Sergey Brin at the time he and Larry Page conceived Google. Brin and Page found that their search engine prototypes were so good the dataflow was constantly straining Stanford’s machines. They needed to scrounge for more disks and processors to mount their servers. Héctor already oversaw the Stanford Digital Libraries Project and he <a href="https://www.cnbc.com/2018/09/04/8-surprising-facts-you-might-not-know-about-googles-early-days.html">arranged</a> for funds to purchase spare parts for the data servers. </p>
<p>
It is interesting that in this 2001 <a href="https://sigmod.org/publications/interviews/pdf/hector-final1.pdf">interview</a> in the <em>SIGMOD Record</em>, Héctor did not have a high opinion of the industrial side of his area:</p>
<blockquote><p><b> </b> <em> Again, I don’t think industry really does very much research. They come up with an idea and they try to sell it. If it was a good idea, maybe they will make money. Even if it was a bad idea, if they have good marketing people, they might still make money and we never know … I don’t think they have an advantage over [academics] in testing the ideas and evaluating them and performing measurements and really understanding what are the right techniques. </em>
</p></blockquote>
<p></p><p>
In the same interview, he had sage advice for students after completing their PhDs and during the tenure process, mainly on the side of not trying to play the system but focus on doing what you love.</p>
<p>
</p><p></p><h2> Stanford Home Team </h2><p></p>
<p></p><p>
Héctor had been a graduate student at Stanford. So his return there as a professor was a kind of homecoming. He was a home-team player in many senses. One of them is shown by this photo:</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/12/hector-garcia-molina-sports.jpg"><img src="https://rjlipton.files.wordpress.com/2019/12/hector-garcia-molina-sports.jpg?w=300&amp;h=200" alt="" width="300" class="aligncenter size-medium wp-image-16457" height="200" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Stanford University obituary <a href="https://news.stanford.edu/2019/12/06/hector-garcia-molina-influential-computer-scientist-database-expert-dies-65/">source</a></font>
</td>
</tr>
</tbody></table>
<p>
He was a registered Stanford sports photographer. He also taught a course at Stanford on photography. We don’t know if he had special insights on detecting “deepfake” photos and videos. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Our condolences go to all his family. Héctor you will be missed. You are missed. </p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/12/08/hctor-garcia-molina-1953-2019/"><span class="datestr">at December 08, 2019 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/08/assistant-professor-position-tenure-track-at-hse-university-moscow-apply-by-january-12-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/08/assistant-professor-position-tenure-track-at-hse-university-moscow-apply-by-january-12-2020/">Assistant Professor Position (Tenure Track) at HSE University, Moscow (apply by January 12, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>HSE University, Faculty of Computer Science invites applications for full-time, tenure-track positions of Assistant Professor in all areas of computer science including but not limited to programming language theory, software engineering, system programming, algorithms, computation complexity, bioinformatics, artificial intelligence, and machine learning, etc.</p>
<p>Website: <a href="https://iri.hse.ru/computer_science2020">https://iri.hse.ru/computer_science2020</a><br />
Email: s.karapetyan@hse.ru</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/08/assistant-professor-position-tenure-track-at-hse-university-moscow-apply-by-january-12-2020/"><span class="datestr">at December 08, 2019 07:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/180">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/180">TR19-180 |  Covering Codes for Insertions and Deletions | 

	Andreas Lenz, 

	Cyrus Rashtchian, 

	Paul Siegel, 

	Eitan Yaakobi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A covering code is a set of codewords with the property that the union of balls, suitably defined, around these codewords covers an entire space. Generally, the goal is to find the covering code with the minimum size codebook. While most prior work on covering codes has focused on the Hamming metric, we consider the problem of designing covering codes defined in terms of  insertions and  deletions. First, we provide new sphere-covering lower bounds on the minimum possible size of such codes. Then, we provide new existential upper bounds on the size of optimal covering codes for a single insertion or a single deletion that are tight up to a constant factor. Finally, we derive improved upper bounds for covering codes using $R\geq 2$ insertions or deletions. We prove that codes exist with density that is only a factor $O(R \log R)$ larger than the lower bounds for all fixed $R$. In particular, our upper bounds have an optimal dependence on the word length, and we achieve asymptotic density matching the best known bounds for Hamming distance covering codes.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/180"><span class="datestr">at December 08, 2019 09:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/07/postdoctoral-fellowship-at-bocconi-university-apply-by-december-15-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/07/postdoctoral-fellowship-at-bocconi-university-apply-by-december-15-2019/">Postdoctoral Fellowship at Bocconi University (apply by December 15, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Two postdoctoral positions, each for one year renewable to a second, are available to work in Luca Trevisan’s group at Bocconi University on topics related to average-case analysis of algorithms, approximation algorithms, and combinatorial constructions.</p>
<p>The positions have a very competitive salary and relocation benefits. Funding for travel is available.</p>
<p>Website: <a href="https://www.unibocconi.eu/wps/wcm/connect/3ecc85da-ac66-46ac-9db7-09ac0ef9b715/Call-2ADR-01B1-Bidsa-Erc.pdf?MOD=AJPERES&amp;CVID=mUjaHAv">https://www.unibocconi.eu/wps/wcm/connect/3ecc85da-ac66-46ac-9db7-09ac0ef9b715/Call-2ADR-01B1-Bidsa-Erc.pdf?MOD=AJPERES&amp;CVID=mUjaHAv</a><br />
Email: L.Trevisan@unibocconi.it</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/07/postdoctoral-fellowship-at-bocconi-university-apply-by-december-15-2019/"><span class="datestr">at December 07, 2019 11:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4279">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/12/07/postdoc-position-at-bocconi/">Postdoc Position at Bocconi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I am recruiting for two postdoctoral positions, each for one year renewable to a second, to work with me at Bocconi University on topics related to average-case analysis of algorithms, approximation algorithms, and combinatorial constructions. </p>
<p>The positions have a very competitive salary and relocation benefits. Funding for travel is available.</p>
<p>Application information is at <a href="https://www.unibocconi.eu/wps/wcm/connect/3ecc85da-ac66-46ac-9db7-09ac0ef9b715/Call-2ADR-01B1-Bidsa-Erc.pdf?MOD=AJPERES&amp;CVID=mUjaHAv">this link</a>. The deadline  is <b>December 15</b>. If you apply, please also send me an email (L.Trevisan at unibocconi.it) to let me know.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/12/07/postdoc-position-at-bocconi/"><span class="datestr">at December 07, 2019 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/179">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/179">TR19-179 |  Towards Optimal Separations between Quantum and Randomized Query Complexities | 

	Avishay Tal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The query model offers a concrete setting where quantum algorithms are provably superior to randomized algorithms. Beautiful results by Bernstein-Vazirani, Simon,  Aaronson, and others presented partial Boolean functions that can be computed by quantum algorithms making much fewer queries compared to their randomized analogs. To date, separations of $O(1)$ vs. $\sqrt{N}$ between quantum and randomized query complexities remain the state-of-the-art (where $N$ is the input length), leaving open the question of whether $O(1)$ vs. $N^{1/2+\Omega(1)}$ separations are possible?

We answer this question in the affirmative. Our separating problem is a variant of the Aaronson-Ambainis $k$-fold Forrelation problem. We show that our variant:
(1) Can be solved by a quantum algorithm making $2^{O(k)}$ queries to the inputs.
(2) Requires at least $\tilde{\Omega}(N^{2(k-1)/(3k-1)})$ queries for any randomized algorithm.

For any constant $\varepsilon&gt;0$, this gives a  $O(1)$  vs. $N^{2/3-\varepsilon}$ separation between the quantum and randomized query complexities of partial Boolean functions. 

Our proof is Fourier analytical and uses new bounds on the Fourier spectrum of classical decision trees, which could be of independent interest. 

Looking forward, we conjecture that the Fourier bounds could be further improved in a precise manner, and show that such conjectured bounds imply optimal $O(1)$ vs. $N^{1-\varepsilon}$ separations between the quantum and randomized query complexities of partial Boolean functions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/179"><span class="datestr">at December 07, 2019 02:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/07/tenure-track-faculty-at-university-of-michigan-apply-by-january-1-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/07/tenure-track-faculty-at-university-of-michigan-apply-by-january-1-2020/">Tenure-track faculty at University of Michigan (apply by January 1, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Computer Science and Engineering at the University of Michigan currently invites applications for multiple tenure-track and teaching faculty (lecturer) positions. We seek exceptional candidates at all levels in all areas across computer science and computer engineering. We also have a targeted search for an endowed professorship in theoretical computer science (the Fischer Chair).</p>
<p>Website: <a href="https://cse.engin.umich.edu/about/faculty-hiring/">https://cse.engin.umich.edu/about/faculty-hiring/</a><br />
Email: kuipers@umich.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/07/tenure-track-faculty-at-university-of-michigan-apply-by-january-1-2020/"><span class="datestr">at December 07, 2019 03:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/178">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/178">TR19-178 |  Almost Tight Lower Bounds on Regular Resolution Refutations of Tseitin Formulas for All Constant-Degree Graphs | 

	Dmitry Itsykson, 

	Artur Riazanov, 

	Petr Smirnov, 

	Danil Sagunov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that the size of any regular resolution refutation of Tseitin formula $T(G,c)$ based on a graph $G$ is at least $2^{\Omega(tw(G)/\log n)}$, where $n$ is the number of vertices in $G$ and $tw(G)$ is the treewidth of $G$. For constant degree graphs there is known upper bound $2^{O(tw(G))}$ [AR11, GTT18], so our lower bound is tight up to a logarithmic factor in the exponent.

In order to prove this result we show that any regular resolution proof of Tseitin formula $T(G,c)$ of size $S$ can be converted to a read-once branching program computing satisfiable Tseitin formula $T(G,c')$ of size $S^{O(\log n)}$. Then we show that any read-once branching program computing satisfiable Tseitin formula $T(G,c')$ has size at least $2^{\Omega(tw(G))}$; the latter improves the recent result of Glinskih and Itsykson [GI19].</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/178"><span class="datestr">at December 07, 2019 01:51 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/12/06/faculty-at-george-washington-university-apply-by-january-9-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/12/06/faculty-at-george-washington-university-apply-by-january-9-2020/">Faculty at George Washington University (apply by January 9, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at The George Washington University invites applications for two tenure track positions at the Assistant, Associate or Full Professor level, beginning as early as Fall 2020. One position focuses on Machine Learning and related areas; the other position welcomes all areas of theoretical and applied computer science.</p>
<p>Website: <a href="https://www.gwu.jobs/postings/72053">https://www.gwu.jobs/postings/72053</a><br />
Email: cssearch@gwu.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/12/06/faculty-at-george-washington-university-apply-by-january-9-2020/"><span class="datestr">at December 06, 2019 09:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2019-12-06-dce-the-three-scalability-bottlenecks-of-state-machine-replication/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2019-12-06-dce-the-three-scalability-bottlenecks-of-state-machine-replication/">Data, Consensus, Execution: Three Scalability Bottlenecks for State Machine Replication</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Ittai Abraham</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
If anyone asks you: how can I scale my State Machine Replication (Blockchain) system? You should answer back with a question: what is your bottleneck? Is it Data, Consensus or Execution? Data: Shipping the commands to all the replicas. For example, if a block contains 1MB of commands, then you...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2019-12-06-dce-the-three-scalability-bottlenecks-of-state-machine-replication/"><span class="datestr">at December 06, 2019 05:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/177">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/177">TR19-177 |  Pseudo-deterministic Streaming | 

	Shafi Goldwasser, 

	Ofer Grossman, 

	Sidhanth Mohanty, 

	David Woodruff</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A pseudo-deterministic algorithm is a (randomized) algorithm which, when run multiple times on the same input, with high probability outputs the same result on all executions. Classic streaming algorithms, such as those for finding heavy hitters, approximate counting, $\ell_2$ approximation, finding a nonzero entry in a vector (for turnstile algorithms) are not pseudo-deterministic. For example, in the instance of finding a nonzero entry in a vector, for any known low-space algorithm $A$, there exists a stream $x$ so that running $A$ twice on $x$ (using different randomness) would with high probability result in two different entries as the output.

In this work, we study whether it is inherent that these algorithms output different values on different executions. That is, we ask whether these problems have low-memory pseudo-deterministic algorithms. For instance, we show that there is no low-memory pseudo-deterministic algorithm for finding a nonzero entry in a vector (given in a turnstile fashion), and also that there is no low-dimensional pseudo-deterministic sketching algorithm for $\ell_2$ norm estimation.  We also exhibit problems which do have low memory pseudo-deterministic algorithms but no low memory deterministic algorithm, such as outputting a nonzero row of a matrix, or outputting a basis for the row-span of a matrix.

We also investigate multi-pseudo-deterministic algorithms: algorithms which with high probability output one of a few options. We show the first lower bounds for such algorithms. This implies that there are streaming problems such that every low space algorithm for the problem must have inputs where there are many valid outputs, all with a significant probability of being outputted.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/177"><span class="datestr">at December 06, 2019 02:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1227">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1227">News for November 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>We hit the mother-lode of property testing papers this month. Stick with us, as we cover 10 (!) papers that appeared online in November.</p>



<p>EDIT: We actually have 11 papers, check out <em>Optimal Adaptive Detection of Monotone Patterns</em> at the bottom.</p>



<p><strong>Testing noisy linear functions for sparsity</strong>, by Xue Chen, Anindya De, and Rocco A. Servedio (<a href="https://arxiv.org/abs/1911.00911">arXiv</a>). Given samples from a noisy linear model \(y = w\cdot x + \mathrm{noise}\), test whether \(w\) is \(k\)-sparse, or far from being \(k\)-sparse. This is a property testing version of the celebrated sparse recovery problem, whose sample complexity is well-known to be \(O(k\log n)\), where the data lies in \(\mathbb{R}^n\). This paper shows that the testing version of the problem can be solved (tolerantly) with a number of samples independent of \(n\), assuming technical conditions: the distribution of coordinates of \(x\) are i.i.d. and non-Gaussian, and the noise distribution is known to the algorithm. Surprisingly, all these conditions are needed, otherwise the dependence on \(n\) is \(\tilde \Omega(\log n)\), essentially the same as the recovery problem.</p>



<p><strong>Pan-Private Uniformity Testing</strong>, by Kareem Amin, Matthew Joseph, Jieming Mao (<a href="https://arxiv.org/abs/1911.01452">arXiv</a>). Differentially private distribution testing has now seen significant study, in both the local and central models of privacy. This paper studies a distribution testing in the pan-private model, which is intermediate: the algorithm receives samples one by one in the clear, but it must maintain a differentially private internal state at all time steps. The sample complexity turns out to be qualitatively intermediate to the two other models: testing uniformity over \([k]\) requires \(\Theta(\sqrt{k})\) samples in the central model, \(\Theta(k)\) samples in the local model, and this paper shows that \(\Theta(k^{2/3})\) samples are necessary and sufficient in the pan-private model.</p>



<p><strong>Almost Optimal Testers for Concise Representations</strong>, by Nader Bshouty (<a href="https://eccc.weizmann.ac.il/report/2019/156/">ECCC</a>). This work gives a unified approach for testing for a plethora of different classes which possess some sort of <em>sparsity</em>. These classes include \(k\)-juntas, \(k\)-linear functions, \(k\)-terms, various types of DNFs, decision lists, functions with bounded Fourier degree, and much more. </p>



<p><strong>Unified Sample-Optimal Property Estimation in Near-Linear Time</strong>, by Yi Hao and Alon Orlitsky (<a href="https://arxiv.org/abs/1911.03105">arXiv</a>). This paper presents a unified approach for estimating several distribution properties with both near-optimal time and sample complexity, based on piecewise-polynomial approximation. Some applications include estimators for Shannon entropy, power sums, distance to uniformity,  normalized support size, and normalized support coverage. More generally, results hold for all Lipschitz properties, and consequences include high-confidence property estimation (outperforming the “median trick”) and differentially private property estimation.</p>



<p><strong>Testing linear-invariant properties</strong>, by Jonathan Tidor and Yufei Zhao (<a href="https://arxiv.org/abs/1911.06793">arXiv</a>). This paper studies property testing of functions which are in a formal sense, definable by restrictions to subspaces of bounded degree. This class of functions is a broad generalization of testing whether a function is linear, or a degree-\(d\) polynomial (for constant \(d\)). The algorithm is the oblivious one, which simply repeatedly takes random restrictions and tests whether the property is satisfied or not (similar to the classic linearity test of BLR, along with many others). </p>



<p><strong>Approximating the Distance to Monotonicity of Boolean Functions</strong>, by Ramesh Krishnan S. Pallavoor, Sofya Raskhodnikova, Erik Waingarten (<a href="https://eccc.weizmann.ac.il/report/2019/163/">ECCC</a>). This paper studies the following fundamental question in tolerant testing: given a Boolean function on the hypercube, test whether it is \(\varepsilon’\)-close or \(\varepsilon\)-far from monotone. It is shown that there is a non-adaptive polynomial query algorithm which can solve this problem for \(\varepsilon’ = \varepsilon/\tilde \Theta(\sqrt{n})\), implying an algorithm which can approximate distance to monotonicity up to a multiplicative \(\tilde O(\sqrt{n})\) (addressing an <a href="https://ptreview.sublinear.info/?p=250">open problem</a> by Sesh). They also give a lower bound demonstrating that improving this approximating factor significantly would necessitate exponentially-many queries. Interestingly, this is proved for the (easier) erasure-resilient model, and also implies lower bounds for tolerant testing of unateness and juntas.</p>



<p><strong>Testing Properties of Multiple Distributions with Few Samples</strong>, by Maryam Aliakbarpour and Sandeep Silwal (<a href="https://arxiv.org/abs/1911.07324">arXiv</a>). This paper introduces a new model for distribution testing. Generally, we are given \(n\) samples from a distribution which is either (say) uniform or far from uniform, and we wish to test which is the case. The authors here study the problem where we are given a <em>single sample</em> from \(n\) different distributions which are either all uniform or far from uniform, and we wish to test which is the case. By additionally assuming a structural condition in the latter case (it is argued that <em>some</em> structural condition is necessary), they give sample-optimal algorithms for testing uniformity, identity, and closeness.</p>



<p><strong>Random Restrictions of High-Dimensional Distributions and Uniformity Testing with Subcube Conditioning</strong>, by Clément L. Canonne, Xi Chen, Gautam Kamath, Amit Levi, and Erik Waingarten (<a href="https://eccc.weizmann.ac.il/report/2019/165/">ECCC</a>, <a href="https://arxiv.org/abs/1911.07357">arXiv</a>). By now, it is well-known that testing uniformity over the \(n\)-dimensional hypercube requires \(\Omega(2^{n/2})\) samples — the curse of dimensionality quickly makes this problem intractable. One option is to assume that the distribution is product, which causes the complexity to drop to \(O(\sqrt{n})\). This paper instead assumes one has stronger access to the distribution — namely, one can receive samples conditioned on being from some subcube of the domain. With this, the paper shows that the complexity drops to the near-optimal \(\tilde O(\sqrt{n})\) samples. The related problem of testing whether a distribution is either uniform or has large mean is also considered. </p>



<p><strong>Property Testing of LP-Type Problems</strong>, by Rogers Epstein, Sandeep Silwal (<a href="https://arxiv.org/abs/1911.08320">arXiv</a>). An LP-Type problem (also known as a generalized linear program) is an optimization problem sharing some properties with linear programs. More formally, they consist of a set of constraints \(S\) and a function \(\varphi\) which maps subsets of \(S\) to some totally ordered set, such that \(\varphi\) possesses monotonicity and locality properties. This paper considers the problem of testing whether \(\varphi(S) \leq k\), or whether at least an \(\varepsilon\)-fraction of constraints in \(S\) must be removed for \(\varphi(S) \leq k\) to hold. This paper gives an algorithm with query complexity \(O(\delta/\varepsilon)\), where \(\delta\) is a dimension measure of the problem. This is applied to testing problems for linear separability, smallest enclosing ball, smallest intersecting ball, smallest volume annulus. The authors also provide lower bounds for some of these problems as well.</p>



<p><strong>Near-Optimal Algorithm for Distribution-Free Junta Testing</strong>, by Xiaojin Zhang (<a href="https://arxiv.org/abs/1911.10833">arXiv</a>). This paper presents an (adaptive) algorithm for testing juntas, in the distribution-free model with one-sided error. The query complexity is \(\tilde O(k/\varepsilon)\), which is nearly optimal. Algorithms with this sample complexity were previously known under the uniform distribution, or with two-sided error, but this is the first paper to achieve it in the distribution-free model with one-sided error.</p>



<p><strong>Optimal Adaptive Detection of Monotone Patterns</strong>, by Omri Ben-Eliezer, Shoham Letzter, Erik Waingarten (<a href="https://arxiv.org/abs/1911.01169">arXiv</a>). Consider the problem of testing whether a function has no monotone increasing subsequences of length \(k\), versus being \(\varepsilon\)-far from having this property. Note that this is a generalization of testing whether a function is monotone (decreasing), which corresponds to the case \(k = 2\). This work shows that the adaptive sample complexity of this problem is \(O_{k,\varepsilon}(\log n)\), matching the lower bound for monotonicity testing. This is in comparison to the non-adaptive sample complexity, which is \(O_{k,\varepsilon}((\log n)^{\lfloor \log_2 k\rfloor})\). In fact, the main result provides a certificate of being far, in the form of a monotone increasing subsequence of length \(k\).</p></div>







<p class="date">
by Gautam Kamath <a href="https://ptreview.sublinear.info/?p=1227"><span class="datestr">at December 06, 2019 04:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7588">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/12/05/deep-double-descent/">Deep Double Descent (cross-posted on OpenAI blog)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>By Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya Sutskever</em></p>



<p><em>This is a lightly edited and expanded version of the following post on the <a href="https://openai.com/blog/deep-double-descent/">OpenAI blog</a> about the following <a href="http://mltheory.org/deep.pdf">paper</a>. While I usually don’t advertise my own papers on this blog, I thought this might be of interest to theorists, and a good follow up to <a href="https://windowsontheory.org/2019/11/15/puzzles-of-modern-machine-learning/">my prior post</a>. I promise not to make a habit out of it. –Boaz</em></p>



<p><strong>TL;DR:</strong>   <a href="http://mltheory.org/deep.pdf">Our paper</a> shows that <a href="https://arxiv.org/abs/1812.11118" target="_blank" rel="noreferrer noopener">double descent</a> occurs in conventional modern deep learning settings: visual classification in the presence of label noise (CIFAR 10, CIFAR 100) and machine translation (IWSLT’14 and WMT’14). As we increase the number of parameters in a neural network, initially the test error decreases, then increases, and then, just as the model is able to fit the train set, it undergoes a second descent, again decreasing as the number of parameters increases. This behavior also extends over train epochs, where a single model undergoes double-descent in test error over the course of training. Surprisingly (at least to us!), we show these phenomenon can lead to a regime where “<em><strong>more data hurts</strong></em>”—training a deep network on a larger train set actually performs worse.</p>



<h2>Introduction</h2>



<p>Open a statistics textbook and you are likely to see warnings against the danger of “overfitting”: If you are trying to find a good classifier or regressor for a given set of labeled examples, you would be well-advised to steer clear of having so many parameters in your model that you are able to completely fit the training data, because you risk not generalizing to new data.</p>



<p>The canonical example for this is polynomial regression. Suppose that we get <em>n</em> samples of the form <em>(x, p(x)+noise)</em> where <em>x</em> is a real number and <em>p(x)</em> is a cubic (i.e. degree 3) polynomial. If we try to fit the samples with a degree 1 polynomial—-a linear function, then we would get many points wrong. If we try to fit it with just the right degree, we would get a very good predictor. However, as the degree grows, we get worse till the degree is large enough to fit all the noisy training points, at which point the regressor is terrible, as shown in this figure:</p>



<figure class="wp-block-image"><img src="https://lh4.googleusercontent.com/H4f4ST5B9RnLX1ski6HEI7RBV5gqvk7WGiFR0qf6Savafmep6i08RYlpF5sgtq9oVqQ6ZkuglvCn0PTMQ_uaK3XStJlSskTSM6I52SyCZ91FeAcphq11MKa56wsfnDAG6GuruTT3" alt="" /></figure>



<p>It seems that the higher the degree, the worse things are, but what happens if we go <em>even higher</em>? It seems like a crazy idea—-why would we increase the degree beyond the number of samples? But it corresponds to the practice of having many more  parameters than training samples in modern deep learning. Just like in deep learning, when the degree is larger than the number of samples, there is more than one polynomial that fits the data– but we choose a specific one: the one found running gradient descent.</p>



<p>Here is what happens if we do this for degree 1000, fitting a polynomial using gradient descent (see <a href="https://colab.research.google.com/drive/1oMuUz3_BOENSoaOVOymLoB2mHeYBex8S">this notebook</a>):</p>



<figure class="wp-block-image"><img src="https://lh6.googleusercontent.com/DjQoPWG5gCueu_sAORKtrhNrrWY35OU3y-RXKJx0AZxIofVzZo-psP-JFsr_a4v20pWhH7EFfFPozckotWzvKypEebkPRJmdSa3vuy39ABdp2PqtqMr7dPX1PTDfMT362n4dGzVG" alt="" /></figure>



<p>We still fit all the training points, but now we do so in a more controlled way which actually tracks quite closely the ground truth. We see that despite what we learn in statistics textbooks, sometimes overfitting is not that bad, as long as you go “all in” rather than “barely overfitting” the data. That is, overfitting doesn’t hurt us if we take the number of parameters to be much larger than what is needed to just fit the training set — and in fact, as we see in deep learning, larger models are often better.</p>



<p>The above is not a novel observation. <a href="https://arxiv.org/abs/1812.11118">Belkin et al </a>called this phenomenon <strong><em>“double descent”</em></strong> and this goes back to <a href="http://www.ki.tu-berlin.de/fileadmin/fg135/publikationen/opper/Op01.pdf">even</a> <a href="https://arxiv.org/abs/1710.03667">earlier</a> <a href="https://arxiv.org/abs/1809.09349">works</a><a href="http://www.ki.tu-berlin.de/fileadmin/fg135/publikationen/opper/Op03b.pdf"> </a>. In this <a href="http://mltheory.org/deep.pdf">new paper</a> we (Preetum Nakkiran, Gal Kaplun, Yamini Bansal, Tristan Yang, Boaz Barak, and Ilya Sutskever) extend the prior works and report on a variety of experiments showing that “double descent” is widely prevalent across several modern deep neural networks and for several natural tasks such as image recognition (for the CIFAR 10 and CIFAR 100 datasets) and language translation (for IWSLT’14 and WMT’14 datasets).  As we increase the number of parameters in a neural network, initially the test error decreases, then increases, and then, just as the model is able to fit the train set, it undergoes a <em>second descent,</em> again decreasing as the number of parameters increases.  Moreover, double descent also extends beyond number of parameters to other measures of “complexity” such as the number of training epochs of the algorithm. </p>



<p>The take-away from our work (and the prior works it builds on) is that neither the classical statisticians’ conventional wisdom that <strong><em>“too large models are worse”</em></strong> nor the modern ML paradigm that <strong><em>“bigger models are always better”</em></strong><em> </em>always hold. Rather it all depends on whether you are on the first or second descent.  Further more, these insights also allow us to generate natural settings in which even the age-old adage of <strong><em>“more data is always better”</em></strong> is violated!</p>



<p>In the rest of this blog post we present a few sample results from this recent paper.</p>



<h3 id="modelwisedoubledescent">Model-wise Double Descent</h3>



<p>We observed many cases in which, just like in the polynomial interpolation example above, the test error undergoes a “double descent” as we increase the complexity of the model. The figure below demonstrates one such example: we plot the test error as a function of the complexity of the model for ResNet18 networks. The complexity of the model is the width of the layers, and the dataset is CIFAR10 with 15% label noise. Notice that the peak in test error occurs around the “interpolation threshold”: when the models are just barely large enough to fit the train set. In all cases we’ve observed, changes which affect the interpolation threshold (such as changing the optimization algorithm, changing the number of train samples, or varying the amount of label noise) also affect the location of the test error peak correspondingly. </p>



<p>We found the double descent phenomena is most prominent in settings with added label noise— without it, the peak is much smaller and easy to miss. But adding label noise amplifies this general behavior and allows us to investigate it easily.</p>



<figure class="wp-block-image"><img src="https://lh4.googleusercontent.com/tFWTvNkFwG8Ljx8zp9X3Ul6aUZT9YmkwcNk07g6_EFUklZoBUd9MqApBEojLzOp9N7yndveLwg5A7uj_vxpGVofQ2QCe-bbMAguQB38cK4NhRfXBp-SWMDQUt9x44r6d_fMur7NO" alt="" /></figure>



<p></p>



<h3 id="samplewisenonmonotonicity">Sample-Wise Nonmonotonicity</h3>



<p>Using the model-wise double descent phenomenon we can obtain examples where training on <strong>more data actually hurts</strong>. To see this, let’s look at the effect of increasing the number of train samples on the test error vs. model size graph. The below plot shows Transformers trained on a language-translation task (with no added label noise):</p>



<figure class="wp-block-image"><img src="https://lh5.googleusercontent.com/YkuZGjuWGKoCcl1gNbQfaKO-96hX9ShcVZ_Dj0KlKddRZhgpMGtzs427zPuC9QwHOOKgmuV5E0aEKOU3zwhwpGmdiWwDDDBIk7hroJZfRLa7kXSThzwTDZoNSM8I2M9OfWxIW5X_" alt="" /></figure>



<p>On the one hand, (as expected) increasing the number of samples generally shifts the curve downwards towards lower test error. On the other hand, it also shifts the curve to the right: since more samples require larger models to fit, the interpolation threshold (and hence, the peak in test error) shifts to the right. For intermediate model sizes, these two effects combine, and we see that <strong>training on 4.5x more samples actually hurts test performance.</strong></p>



<h3 id="epochwisedoubledescent">Epoch-Wise Double Descent</h3>



<p><strong>There is a regime where training longer reverses overfitting.</strong> Let’s look closer at the experiment from the “Model-wise Double Descent” section, and plot Test Error as a function of both model-size and number of optimization steps. In the plot below to the right, each column tracks the Test Error of a given model over the course of training. The top horizontal dotted-line corresponds to the double-descent of the first figure. But we can also see that for a fixed large model, as training proceeds test error goes down, then up and down again—we call this phenomenon “epoch-wise double-descent.”</p>



<figure class="wp-block-image"><img src="https://lh3.googleusercontent.com/SCP6M-txj9ax5g9cR9Ry27X2nF1sEJbpsfC9FiME5umNm-BxcHHBmhseuuWEm3mHMzo_0o5q-92ETcaU0OEXnhTmv_7MpOREaaeIMs7zbL9P5aFeqkXMYh8O8VN4FdASnAu0HOPI" alt="" /></figure>



<p>Moreover, if we plot the Train error of the same models and the corresponding interpolation contour (dotted line) we see that it exactly matches the ridge of high test error (on the right).</p>



<p><strong>In general, the peak of test error appears systematically when models are just barely able to fit the train set.</strong></p>



<p>Our intuition is that for models at the interpolation threshold, there is effectively only one model that fits the train data, and forcing it to fit even slightly-noisy or mis-specified labels will destroy its global structure. That is, there are no “good models”, which both interpolate the train set, and perform well on the test set. However in the over-parameterized regime, there are many models that fit the train set, and there exist “good models” which both interpolate the train set and perform well on the distribution. Moreover, the implicit bias of SGD leads it to such “good” models, for reasons we don’t yet understand.</p>



<p>The above intuition is theoretically justified for linear models, via a series of recent works including [<a href="https://arxiv.org/abs/1903.08560">Hastie et al.</a>] and [<a href="https://arxiv.org/abs/1908.05355">Mei-Montanari</a>]. We leave fully understanding the mechanisms behind double descent in deep neural networks as an important open question.</p>



<p></p>



<hr class="wp-block-separator" />



<h2>Commentary: Experiments for Theory</h2>



<p>The experiments above are especially interesting (in our opinion) because of how they can inform ML theory: any theory of ML must be consistent with “double descent.” In particular, one ambitious hope for what it means to “theoretically explain ML” is to prove a theorem of the form:</p>



<p class="has-text-align-center">“If the distribution satisfies property X and architecture/initialization satisfies property Y, then SGD trained on ‘n’ samples, for T steps, will have small test error with high probability”</p>



<p>For values of X, Y, n, T, “small” and “high” that are used in practice.</p>



<p>However, these experiments show that these properties are likely more subtle than we may have hoped for, and must be non-monotonic in certain natural parameters.</p>



<p>This rules out even certain natural “conditional conjectures” that we may have hoped for, for example the conjecture that</p>



<p class="has-text-align-center">“If SGD on a width W network works for learning from ‘n’ samples from distribution D, then SGD on a width W+1 network will work at least as well”</p>



<p>Or the conjecture</p>



<p class="has-text-align-center">“If SGD on a certain network and distribution works for learning with ‘n’ samples, then it will work at least as well with n+1 samples”</p>



<p>It also appears to conflict with a “2-phase” view of the trajectory of SGD, as an initial “learning phase” and then an “overfitting phase” — in particular, because the overfitting is sometimes reversed (at least, as measured by test error) by further training.</p>



<p>Finally, the fact that these phenomena are not specific to neural networks, but appear to hold fairly universally for natural learning methods (linear/kernel regression, decision trees, random features) gives us hope that there is a deeper phenomenon at work, and we are yet to find the right abstraction.</p>



<p></p>



<p></p>



<p></p>



<p><em>We especially thank Mikhail Belkin and Christopher Olah for helpful discussions throughout this work.</em> <em>The polynomial example is inspired in part by experiments in [<a href="https://arxiv.org/abs/1903.09139">Muthukumar et al.</a>]</em>.</p>



<p></p></div>







<p class="date">
by preetum <a href="https://windowsontheory.org/2019/12/05/deep-double-descent/"><span class="datestr">at December 05, 2019 05:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
