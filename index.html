<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="https://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/3722233/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="http://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at October 05, 2021 03:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://nisheethvishnoi.wordpress.com/?p=123">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/nisheeth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://nisheethvishnoi.wordpress.com/2021/10/04/focs-2021-best-paper-awards/">FOCS 2021 Best Paper Awards</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>On behalf of the FOCS 2021 PC, I am delighted to announce the Best Paper Awards.</p>



<p><strong>Best paper: </strong></p>



<p>Nutan Limaye, Srikanth Srinivasan and Sébastien Tavenas. <em>Superpolynomial Lower Bounds Against Low-Depth Algebraic Circuits</em></p>



<p></p>



<p>This paper makes a fundamental advance by proving super-polynomial lower bounds against algebraic circuits of arbitrary constant depth. </p>



<p>Paper: <a href="https://eccc.weizmann.ac.il/report/2021/081/" rel="nofollow">https://eccc.weizmann.ac.il/report/2021/081/</a></p>



<p></p>



<p><strong>Machtey Award for Best Student Paper:</strong></p>



<p>Xiao Mao. <em>Breaking the Cubic Barrier for (Unweighted) Tree Edit Distance</em><a href="https://twitter.com/NisheethVishnoi"><br /></a><br />This paper shows how, unlike the weighted case, the unweighted tree edit distance problem has a sub-cubic time algorithm. </p>



<p>Paper: <a href="https://t.co/G8yw1EZwuR?amp=1" target="_blank" rel="noreferrer noopener">https://arxiv.org/abs/2106.02026</a></p>



<p></p>



<p>Congratulations to the winners and see you all in Denver from Feb 7-10, 2022!<a href="https://twitter.com/NisheethVishnoi/status/1445099200274960390/photo/1"></a></p></div>







<p class="date">
by nisheethvishnoi <a href="https://nisheethvishnoi.wordpress.com/2021/10/04/focs-2021-best-paper-awards/"><span class="datestr">at October 04, 2021 06:58 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/10/04/five-tenure-track-faculty-positions-in-cs-at-the-university-of-virginia-at-university-of-virginia-apply-by-december-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/10/04/five-tenure-track-faculty-positions-in-cs-at-the-university-of-virginia-at-university-of-virginia-apply-by-december-1-2021/">Five Tenure-Track Faculty Positions in CS at the University of Virginia at University of Virginia  (apply by December 1, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Computer Science Department at the University of Virginia seeks 5 tenured or tenure-track faculty at all ranks, with Theory as one of our core targeted areas. Review of applications begins 12/1/2021.</p>
<p>Website: <a href="https://uva.wd1.myworkdayjobs.com/en-US/UVAJobs/job/Charlottesville-VA/Open-Rank-Faculty-Position-in-Computer-Science_R0028993">https://uva.wd1.myworkdayjobs.com/en-US/UVAJobs/job/Charlottesville-VA/Open-Rank-Faculty-Position-in-Computer-Science_R0028993</a><br />
Email: selbaum@virginia.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/10/04/five-tenure-track-faculty-positions-in-cs-at-the-university-of-virginia-at-university-of-virginia-apply-by-december-1-2021/"><span class="datestr">at October 04, 2021 06:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2021-10-04-crusader-agreement-with-dollars-slash-leq-1-slash-3$-error-is-impossible-for-$n-slash-leq-3f$-if-the-adversary-can-simulate/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2021-10-04-crusader-agreement-with-dollars-slash-leq-1-slash-3$-error-is-impossible-for-$n-slash-leq-3f$-if-the-adversary-can-simulate/">Crusader Agreement with $\leq 1/3$ Error is Impossible for $n\leq 3f$ if the Adversary can Simulate</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The classic FLM lower bound says that in Synchrony, Byzantine Agreement is impossible when $n \leq 3f$. We discussed this important bound in a previous post. In this post we strengthen the FLM lower bound in two important ways: Maybe randomization allows circumventing the FLM lower bound? No! Even allowing...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2021-10-04-crusader-agreement-with-dollars-slash-leq-1-slash-3$-error-is-impossible-for-$n-slash-leq-3f$-if-the-adversary-can-simulate/"><span class="datestr">at October 04, 2021 02:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-989853369577969981">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2021/10/how-have-computers-changed-society.html">How have computers changed society? Harry Lewis (with co-authors) have a book out on that.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> (Disclosure - Harry Lewis was my PhD advisor.)</p><p><br /></p><p>It seems like just a few weeks ago I I blogged about a book of Harry Lewis's that was recently available (see <a href="https://blog.computationalcomplexity.org/2021/08/what-are-most-important-46-papers-in.html">here</a>).  And now I am blogging about another one. Writing two books in two years seems hard! I can only think of one other computer scientist who has done that recently (see <a href="https://www.amazon.com/Mathematical-Muffin-Morsels-Problem-Mathematics-ebook/dp/B08BJ4G2Z1/ref=sr_1_2?dchild=1&amp;keywords=gasarch&amp;qid=1626492618&amp;sr=8-2">here</a> and <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279729/ref=sr_1_2?dchild=1&amp;keywords=gasarch+point&amp;qid=1626492655&amp;sr=8-2">here</a>).</p><p><br /></p><p>In 2008 Abelson, Ledeen, and Lewis wrote </p><p><i>Blown to Bits: Your Life, Liberty, and Happiness after the Digital Explosion</i></p><p>which I reviewed in SIGACT news, see <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/bitsbook.pdf">here</a></p><p><br /></p><p>Both computers and society have changed since 2008. Hence an update was needed. </p><p>In 2021 Adelson, Ledeen, Lewis, and Seltzer wrote a second edition.</p><p><br /></p><p>Should you buy the new version if you bought the old version? </p><p>1) Not my problem- I got them both for free since I reviewed them. </p><p>2) Not your problem- The second edition is available free-on-line <a href="https://www.bitsbook.com/thebook/">here</a>. Is that a link to some dark corner of the dark web? No, its the formal webpage about the book. So the book is available free-on-line legally, if you care (and even if you don't care). </p><p>3) If you like paper, the book is on amazon. (If you don't like paper, the book is still on amazon). </p><p><br /></p><p>I reviewed it in SIGACT news. A non-paywalled link: <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/b2bits2.pdf">here</a> (is that link legal? I have no idea.) </p><p>In this post I'll just mention two things that changed since the last book</p><p>1) Shared Music and pirating were an issue back in 2008.  It does not seem to be anymore since there is now a variety of services that seem to make pirating not worth it: itunes, streaming services, and some bands give it away for free and ask you to pay what its worth. Movies are still struggling with this issue. </p><p>2) AI systems that reinforce existing bias is a new problem.</p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2021/10/how-have-computers-changed-society.html"><span class="datestr">at October 04, 2021 04:19 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00562">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00562">Computational Complexity of Deciding Provability in Linear Logic and its Fragments</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Florian Chudigiewitsch <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00562">PDF</a><br /><b>Abstract: </b>Linear logic was conceived in 1987 by Girard and, in contrast to classical
logic, restricts the usage of the structural inference rules of weakening and
contraction. With this, atoms of the logic are no longer interpreted as truth,
but as information or resources. This interpretation makes linear logic a
useful tool for formalisation in mathematics and computer science. Linear logic
has, for example, found applications in proof theory, quantum logic, and the
theory of programming languages. A central problem of the logic is the question
whether a given list of formulas is provable with the calculus. In the research
regarding the complexity of this problem, some results were achieved, but other
questions are still open. To present these questions and give new perspectives,
this thesis consists of three main parts which build on each other: We present
the syntax, proof theory, and various approaches to a semantics for linear
logic. Here already, we will meet some open research questions. We present the
current state of the complexity-theoretic characterization of the most
important fragments of linear logic. Here, further research problems are
presented and it becomes apparent that until now, the results have all made use
of different approaches. We prove an original complexity characterization of a
fragment of the logic and present ideas for a new, structural approach to the
examination of provability in linear logic.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00562"><span class="datestr">at October 04, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00548">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00548">Spirality and Rectilinear Planarity Testing of Independent-Parallel SP-Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Didimo:Walter.html">Walter Didimo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaufmann:Michael.html">Michael Kaufmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liotta:Giuseppe.html">Giuseppe Liotta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ortali:Giacomo.html">Giacomo Ortali</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00548">PDF</a><br /><b>Abstract: </b>We study the long-standing open problem of efficiently testing rectilinear
planarity of series-parallel graphs (SP-graphs) in the variable embedding
setting. A key ingredient behind the design of a linear-time testing algorithm
for SP-graphs of vertex-degree at most three is that one can restrict the
attention to a constant number of ``rectilinear shapes'' for each series or
parallel component. To formally describe these shapes the notion of spirality
can be used. This key ingredient no longer holds for SP-graphs with vertices of
degree four, as we prove a logarithmic lower bound on the spirality of their
components. The bound holds even for the independent-parallel SP-graphs, in
which no two parallel components share a pole. Nonetheless, by studying the
spirality properties of the independent-parallel SP-graphs, we are able to
design a linear-time rectilinear planarity testing algorithm for this graph
family.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00548"><span class="datestr">at October 04, 2021 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00504">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00504">Adwords with Unknown Budgets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Udwani:Rajan.html">Rajan Udwani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00504">PDF</a><br /><b>Abstract: </b>Motivated by applications in automated budget optimization, we consider the
Adwords problem of Mehta et al. (2005) with unknown advertiser budgets. In this
setting, the budget of an advertiser is revealed to the algorithm only when it
is exceeded. An algorithm that is oblivious to budgets gives an Ad platform the
flexibility to adjust budgets in real-time which, we argue, has tangible
benefits. Prominent online algorithms for the Adwords problem critically rely
on knowledge of budgets. We give the first budget oblivious algorithm for
Adwords with competitive ratio guarantee of at least $0.522$ (better than
greedy) against an offline algorithm that knows bids and budgets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00504"><span class="datestr">at October 04, 2021 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00495">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00495">Fixed-Parameter Algorithms for Longest Heapable Subsequence and Maximum Binary Tree</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekaran:Karthekeyan.html">Karthekeyan Chandrasekaran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grigorescu:Elena.html">Elena Grigorescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Istrate:Gabriel.html">Gabriel Istrate</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulkarni:Shubhang.html">Shubhang Kulkarni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Young=San.html">Young-San Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Minshen.html">Minshen Zhu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00495">PDF</a><br /><b>Abstract: </b>A heapable sequence is a sequence of numbers that can be arranged in a
"min-heap data structure". Finding a longest heapable subsequence of a given
sequence was proposed by Byers, Heeringa, Mitzenmacher, and Zervas (ANALCO
2011) as a generalization of the well-studied longest increasing subsequence
problem and its complexity still remains open. An equivalent formulation of the
longest heapable subsequence problem is that of finding a maximum-sized binary
tree in a given permutation directed acyclic graph (permutation DAG). In this
work, we study parameterized algorithms for both longest heapable subsequence
as well as maximum-sized binary tree. We show the following results:
</p>
<p>1. The longest heapable subsequence problem can be solved in
$k^{O(\log{k})}n$ time, where $k$ is the number of distinct values in the input
sequence. We introduce the "alphabet size" as a new parameter in the study of
computational problems in permutation DAGs. Our result on longest heapable
subsequence implies that the maximum-sized binary tree problem in a given
permutation DAG is fixed-parameter tractable when parameterized by the alphabet
size.
</p>
<p>2. We show that the alphabet size with respect to a fixed topological
ordering can be computed in polynomial time, admits a min-max relation, and has
a polyhedral description.
</p>
<p>3. We design a fixed-parameter algorithm with run-time $w^{O(w)}n$ for the
maximum-sized binary tree problem in undirected graphs when parameterized by
treewidth $w$.
</p>
<p>Our results make progress towards understanding the complexity of the longest
heapable subsequence and maximum-sized binary tree in permutation DAGs from the
perspective of parameterized algorithms. We believe that the parameter alphabet
size that we introduce is likely to be useful in the context of optimization
problems defined over permutation DAGs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00495"><span class="datestr">at October 04, 2021 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00391">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00391">Online Primal-Dual Algorithms with Predictions for Packing Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thang:Nguyen_Kim.html">Nguyen Kim Thang</a>, Christoph Durr <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00391">PDF</a><br /><b>Abstract: </b>The domain of online algorithms with predictions has been extensively studied
for different applications such as scheduling, caching (paging), clustering,
ski rental, etc. Recently, Bamas et al., aiming for an unified method, have
provided a primal-dual framework for linear covering problems. They extended
the online primal-dual method by incorporating predictions in order to achieve
a performance beyond the worst-case case analysis. In this paper, we consider
this research line and present a framework to design algorithms with
predictions for non-linear packing problems. We illustrate the applicability of
our framework in submodular maximization and in particular ad-auction
maximization in which the optimal bound is given and supporting experiments are
provided.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00391"><span class="datestr">at October 04, 2021 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00287">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00287">Whole Sampling Generation of Scale-Free Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stamatelatos:Giorgos.html">Giorgos Stamatelatos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Efraimidis:Pavlos_S=.html">Pavlos S. Efraimidis</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00287">PDF</a><br /><b>Abstract: </b>This paper presents the development of a new class of algorithms that
accurately implement the preferential attachment mechanism of the
Barab\'asi-Albert (BA) model to generate scale-free graphs. Contrary to
existing approximate preferential attachment schemes, our methods are exact in
terms of the proportionality of the vertex selection probabilities to their
degree and run in linear time with respect to the order of the generated graph.
Our algorithms are based on a principle of random sampling which is called
whole sampling and is a new perspective for the study of preferential
attachment. We show that they obey the definition of the original BA model that
generates scale-free graphs and discuss their higher-order properties. Finally,
we extend our analytical presentation with computer experiments that focus on
the degree distribution and several measures surrounding the local clustering
coefficient.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00287"><span class="datestr">at October 04, 2021 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00254">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00254">The Complexity of Learning Approval-Based Multiwinner Voting Rules</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Caragiannis:Ioannis.html">Ioannis Caragiannis</a>, Karl Fehrs <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00254">PDF</a><br /><b>Abstract: </b>We study the PAC learnability of multiwinner voting, focusing on the class of
approval-based committee scoring (ABCS) rules. These are voting rules applied
on profiles with approval ballots, where each voter approves some of the
candidates. ABCS rules adapt positional scoring rules in single-winner voting
by assuming that each committee of $k$ candidates collects from each voter a
score, that depends on the size of the voter's ballot and on the size of its
intersection with the committee. Then, committees of maximum score are the
winning ones. Our goal is to learn a target rule (i.e., to learn the
corresponding scoring function) using information about the winning committees
of a small number of sampled profiles. Despite the existence of exponentially
many outcomes compared to single-winner elections, we show that the sample
complexity is still low: a polynomial number of samples carries enough
information for learning the target committee with high confidence and
accuracy. Unfortunately, even simple tasks that need to be solved for learning
from these samples are intractable. We prove that deciding whether there exists
some ABCS rule that makes a given committee winning in a given profile is a
computationally hard problem. Our results extend to the class of sequential
Thiele rules, which have received attention due to their simplicity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00254"><span class="datestr">at October 04, 2021 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00074">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00074">Near-Optimal Distance Oracles for Vertex-Labeled Planar Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Evald:Jacob.html">Jacob Evald</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fredslund=Hansen:Viktor.html">Viktor Fredslund-Hansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wulff=Nilsen:Christian.html">Christian Wulff-Nilsen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00074">PDF</a><br /><b>Abstract: </b>Given an undirected $n$-vertex planar graph $G=(V,E,\omega)$ with
non-negative edge weight function $\omega:E\rightarrow \mathbb R$ and given an
assigned label to each vertex, a vertex-labeled distance oracle is a data
structure which for any query consisting of a vertex $u$ and a label $\lambda$
reports the shortest path distance from $u$ to the nearest vertex with label
$\lambda$. We show that if there is a distance oracle for undirected $n$-vertex
planar graphs with non-negative edge weights using $s(n)$ space and with query
time $q(n)$, then there is a vertex-labeled distance oracle with
$\tilde{O}(s(n))$ space and $\tilde{O}(q(n))$ query time. Using the
state-of-the-art distance oracle of Long and Pettie, our construction produces
a vertex-labeled distance oracle using $n^{1+o(1)}$ space and query time
$\tilde O(1)$ at one extreme, $\tilde O(n)$ space and $n^{o(1)}$ query time at
the other extreme, as well as such oracles for the full tradeoff between space
and query time obtained in their paper. This is the first non-trivial exact
vertex-labeled distance oracle for planar graphs and, to our knowledge, for any
interesting graph class other than trees.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00074"><span class="datestr">at October 04, 2021 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00072">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00072">Inequality and Inequity in Network-based Ranking and Recommendation Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esp=iacute=n=Noboa:Lisette.html">Lisette Espín-Noboa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wagner:Claudia.html">Claudia Wagner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Strohmaier:Markus.html">Markus Strohmaier</a>, Fariba Karimi <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00072">PDF</a><br /><b>Abstract: </b>Though algorithms promise many benefits including efficiency, objectivity and
accuracy, they may also introduce or amplify biases. Here we study two
well-known algorithms, namely PageRank and Who-to-Follow (WTF), and show under
which circumstances their ranks produce inequality and inequity when applied to
directed social networks. To this end, we propose a directed network model with
preferential attachment and homophily (DPAH) and demonstrate the influence of
network structure on the rank distributions of these algorithms. Our main
findings suggest that (i) inequality is positively correlated with inequity,
(ii) inequality is driven by the interplay between preferential attachment,
homophily, node activity and edge density, and (iii) inequity is mainly driven
by homophily. In particular, these two algorithms amplify, replicate and reduce
inequity in top ranks when majorities are homophilic, neutral and heterophilic,
respectively. Moreover, when inequity is amplified, minorities may improve
their visibility in the rank by connecting strategically in the network. For
instance, by increasing their homophily when majorities are also homophilic.
These findings shed light on social and algorithmic mechanisms that hinder
equality and equity in network-based ranking and recommendation algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00072"><span class="datestr">at October 04, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2110.00058">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2110.00058">Rectangular Spiral Galaxies are Still Hard</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Demaine:Erik_D=.html">Erik D. Demaine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=ouml=ffler:Maarten.html">Maarten Löffler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Christiane.html">Christiane Schmidt</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2110.00058">PDF</a><br /><b>Abstract: </b>Spiral Galaxies is a pencil-and-paper puzzle played on a grid of unit
squares: given a set of points called centers, the goal is to partition the
grid into polyominoes such that each polyomino contains exactly one center and
is $180^\circ$ rotationally symmetric about its center. We show that this
puzzle is NP-complete even if the polyominoes are restricted to be (a)
rectangles of arbitrary size or (b) 1$\times$1, 1$\times$3, and 3$\times$1
rectangles. The proof for the latter variant also implies NP-completeness of
finding a non-crossing matching in modified grid graphs where edges connect
vertices of distance $2$. Moreover, we prove NP-completeness of the design
problem of minimizing the number of centers such that there exist a set of
Spiral Galaxies that exactly cover a given shape.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2110.00058"><span class="datestr">at October 04, 2021 10:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/10/02/generating-fibbinary-numbers">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/10/02/generating-fibbinary-numbers.html">Generating fibbinary numbers, three ways</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I just added to Wikipedia two articles on the <a href="https://en.wikipedia.org/wiki/Jordan%E2%80%93P%C3%B3lya_number">Jordan–Pólya numbers</a> and <a href="https://en.wikipedia.org/wiki/Fibbinary_number">fibbinary numbers</a>, two integer sequences used in <a href="https://11011110.github.io/blog/2021/09/24/which-integer-sequences.html">my recent paper on Egyptian fractions</a>. Jordan–Pólya numbers are the products of factorials, while the fibbinary numbers are the ones with binary representations having no two consecutive 1’s. The OEIS page on the fibbinary numbers, <a href="https://oeis.org/A003714">A003714</a>, lists many ways of generating this sequence algorithmically, of which most are boring or slow (generate all binary numbers and test which ones belong to the sequence; you can test if a variable <code class="language-plaintext highlighter-rouge">x</code> is fibbinary by checking that <code class="language-plaintext highlighter-rouge">x&amp;(x&gt;&gt;1)</code> is zero). I thought it might be interesting to highlight two of those methods that are a little more clever and generate these numbers in small numbers of operations.</p>

<p>Some functional languages, and in part Python even though it’s mostly not functional, have a notion of a stream, a potentially infinite sequence of values generated by a coroutine. In Python, you can program these using <a href="https://www.python.org/dev/peps/pep-0255/">simple generators</a> and the <code class="language-plaintext highlighter-rouge">yield</code> keyword. I wrote here long ago about <a href="https://11011110.github.io/blog/2011/10/02/generating-permutations-with.html">methods for using generators recursively</a>: a generator can call itself, manipulate the resulting sequence of values, and pass them on to its output. It’s actually a very old idea, used for instance to generate <a href="https://en.wikipedia.org/wiki/Regular_number">regular numbers</a> by Dijkstra <a href="http://web.cecs.pdx.edu/~black/AdvancedProgramming/Lectures/Smalltalk%20II/Dijkstra%20on%20Hamming%27s%20Problem.pdf">in his 1976 book <em>A Discipline of Programming</em></a>. Reinhard Zumkeller used the same idea to generate the fibbinary numbers in Haskell, based on the observation that the sequence of positive fibbinary numbers can be generated, starting from the number 1, by two operations, doubling smaller values or replacing a smaller value \(x\) with \(4x+1\). Here is is, translated into Python:</p>

<figure class="highlight"><pre><code class="language-python"><span class="kn">from</span> <span class="nn">heapq</span> <span class="kn">import</span> <span class="n">merge</span>

<span class="k">def</span> <span class="nf">affine</span><span class="p">(</span><span class="n">stream</span><span class="p">,</span><span class="n">a</span><span class="p">,</span><span class="n">b</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">stream</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">x</span><span class="o">*</span><span class="n">a</span><span class="o">+</span><span class="n">b</span>

<span class="k">def</span> <span class="nf">fibbinary</span><span class="p">():</span>
    <span class="k">yield</span> <span class="mi">1</span>
    <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">merge</span><span class="p">(</span><span class="n">affine</span><span class="p">(</span><span class="n">fibbinary</span><span class="p">(),</span><span class="mi">2</span><span class="p">,</span><span class="mi">0</span><span class="p">),</span><span class="n">affine</span><span class="p">(</span><span class="n">fibbinary</span><span class="p">(),</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">)):</span>
        <span class="k">yield</span> <span class="n">x</span></code></pre></figure>

<p>It’s elegant, but has a couple of minor flaws. First, it omits the number \(0\), and while it can be modified to include \(0\), the modifications make the code messier. But second, it takes more than a constant amount of time per element to generate each sequence element. A fibbinary number \(x\) has to be generated from a sequence of smaller elements by repeated doubling and quadrupling, and that takes \(\log x\) steps per element. Even if we assume those steps to take constant time each, generating the first \(n\) elements in this way takes time \(\Theta(n\log n)\). It’s better than the \(\Theta(n^{\log_\varphi 2})\approx n^{1.44}\) that you would get from generate-and-test, but still not as good as we might hope for. One way to fix this would be to memoize the generator, so that the recursive calls look at a stored copy of the sequence generated by the outer call rather than generating the same sequence redundantly, but this again makes the code messier and also takes more storage than necessary.</p>

<p>Instead, Jörg Arndt observed that you can generate each fibbinary number directly from the previous one by a process closely resembling binary addition. Adding one to a binary number sets the first available bit from zero to one, and zeros out all the smaller bits; here, a bit is available if it is already zero. Finding the next fibbinary number does the same thing, but with a different definition of availability: a bit is available if both it and the next larger bit are zero. We can find the available bit using binary addition on a modified word that fills in bits whose neighbor is nonzero. Using this idea, we can generate the fibbinary numbers in a constant number of bitwise binary word-level operations per number. Here it is again in Python, translated from Arndt’s C++ and simplified based on <a href="https://mathstodon.xyz/@efroach76/107037399683569338">a comment by efroach76</a>:</p>

<figure class="highlight"><pre><code class="language-python"><span class="k">def</span> <span class="nf">fibbinary</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">x</span>
        <span class="n">y</span> <span class="o">=</span> <span class="o">~</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;&gt;</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">x</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span> <span class="o">&amp;</span> <span class="n">y</span></code></pre></figure>

<p>It’s even possible to use the same idea to generate the fibbinary numbers in a constant amortized number of bit-level operations per number, although this ends up being a little less efficient in practice because high-level languages end up translating all these bit operations into word operations anyway.</p>

<figure class="highlight"><pre><code class="language-python"><span class="k">def</span> <span class="nf">fibbinary</span><span class="p">():</span>
    <span class="n">x</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="k">yield</span> <span class="n">x</span>
        <span class="n">y</span> <span class="o">=</span> <span class="mi">1</span>
        <span class="k">while</span> <span class="n">x</span> <span class="o">&amp;</span> <span class="p">(</span><span class="n">y</span> <span class="o">|</span> <span class="p">(</span><span class="n">y</span><span class="o">&lt;&lt;</span><span class="mi">1</span><span class="p">))</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">&amp;=~</span> <span class="n">y</span>
            <span class="n">y</span> <span class="o">&lt;&lt;=</span> <span class="mi">1</span>
        <span class="n">x</span> <span class="o">|=</span> <span class="n">y</span></code></pre></figure>

<p>The inner loop ends immediately at fibbinary numbers whose successor is odd (at positions given by the ones of the <a href="https://en.wikipedia.org/wiki/Fibonacci_word">Fibonacci word</a>), whose fraction of the total is \(1-1/\varphi\approx 0.382\), where \(\varphi\) is the golden ratio. It ends in two steps for the remaining values when their next bit is odd, in the same proportion, and so on. So the average number of steps for the inner loop adds in a geometric series to \(O(1)\).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107034017632258123">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/10/02/generating-fibbinary-numbers.html"><span class="datestr">at October 02, 2021 01:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/10/02/postdoc-at-irif-paris-france-apply-by-november-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/10/02/postdoc-at-irif-paris-france-apply-by-november-1-2021/">postdoc at IRIF, Paris, France (apply by November 1, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>IRIF, Paris, France, is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science.</p>
<p>IRIF is a joint laboratory of the CNRS (French National Center for Scientific Research) and Université de Paris; see <a href="https://www.irif.fr/en/informations/presentation">https://www.irif.fr/en/informations/presentation</a> .</p>
<p>Knowledge of French is not required; applications can be sent either in French or in English.</p>
<p>Website: <a href="https://www.irif.fr/postes/postdoc">https://www.irif.fr/postes/postdoc</a><br />
Email: postdoc-advice@irif.fr</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/10/02/postdoc-at-irif-paris-france-apply-by-november-1-2021/"><span class="datestr">at October 02, 2021 07:50 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/142">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/142">TR21-142 |  Mixing of 3-term progressions in Quasirandom Groups  | 

	Amey Bhangale, 

	Prahladh Harsha, 

	Sourya Roy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this note, we show the mixing of three-term progressions $(x, xg, xg^2)$ in every finite quasirandom group, fully answering a question of Gowers. More precisely, we show that for any $D$-quasirandom group $G$ and any three sets $A_1, A_2, A_3 \subset G$, we have
\[ \left|\Pr_{x,y\sim G}\left[ x \in A_1, xy \in A_2, xy^2 \in A_3\right] - \prod_{i=1}^3 \Pr_{x\sim G}\left[x \in A_i\right] \right| \leq \left(\frac{2}{\sqrt{D}}\right)^{\frac14}.\] 
Prior to this, Tao answered this question when the underlying quasirandom group is $\mathrm{SL}_{d}(\mathbb{F}_q)$. Subsequently, Peluse extended the result to all nonabelian finite simple groups. In this work, we show that a slight modification of Peluse's argument is sufficient to fully resolve Gower's quasirandom conjecture for 3-term progressions. Surprisingly, unlike the proofs of Tao and Peluse, our proof is elementary and only uses basic facts from nonabelian Fourier analysis.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/142"><span class="datestr">at October 01, 2021 04:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blog.simons.berkeley.edu/?p=595">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/simons.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blog.simons.berkeley.edu/2021/09/theory-at-the-institute-and-beyond-september-2021/">Theory at the Institute and Beyond, September 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>by <a href="https://simons.berkeley.edu/people/prasad-raghavendra">Prasad Raghavendra</a> (Simons Institute)</p>



<p><img src="https://simons.berkeley.edu/sites/default/files/news/_prasad_and_algebraic_circuit_complexity_v4.png" style="margin: 5px; float: right; width: 328px; height: 219px;" alt="" />Being in one of the talks in the Simons Institute auditorium, witnessing live and lively interaction with the speaker, feels like the closest thing to normal since the start of the pandemic. There is a sense of tangible joy among the participants just to be sharing the same physical space, let alone the fantastic environs of the Institute. The renewed energy is all there to witness in the programs this semester on <a href="https://simons.berkeley.edu/programs/si2021"><u>Computational Complexity of Statistical Inference</u></a> (CCSI) and <a href="https://simons.berkeley.edu/programs/gmos2021"><u>Geometric Methods in Optimization and Sampling</u></a> (GMOS), both of which are now in full swing. Although masking is maintained, it doesn’t seem to change the quintessential Simons program experience even a little bit. I am referring, of course, to the constant feeling of missing out on all the incredibly interesting activities going on, much of which one is unable to fit into their schedule.</p>



<p>At least some of the palpable energy can be attributed to over 40 postdocs and research fellows who have arrived at the Institute this semester, many of whom will stay on for a year or two. This extraordinary group of young researchers covers the whole gamut of topics, ranging from cryptography, quantum computing, and fairness to machine learning, data structures, algorithms, and complexity theory. Each of these postdocs and fellows gave a 10-minute presentation at the “Meet the Fellows’’ welcome event that the Institute held on September 8 and 9. Check out their <a href="https://simons.berkeley.edu/events/meet-fellows-welcome-event-wednesday-schedule"><u>talks</u></a> for glimpses of the cutting edge in all these subfields of theory.</p>



<p><strong>An advance in algebraic circuit complexity</strong><br />
	This time around, there is some good news from the front lines on circuit complexity, one of the most challenging arenas within theoretical computer science.</p>



<p>An algebraic circuit consists of gates, each of which carries out either addition or multiplication over some field, say real numbers. The depth of the circuit is the length of the longest path from the output to one of its inputs. Naturally, an algebraic circuit computes a polynomial over its inputs.</p>



<p>In the world of Boolean circuits with AND/OR/NOT gates, lower bounds against constant depth circuits, aka AC0 circuit lower bounds, have been known since the 1980s and are one of the most influential results in complexity theory. For general algebraic circuits over a large field (say reals), even superpolynomial lower bounds for depth three circuits had remained elusive. In a <a href="https://eccc.weizmann.ac.il/report/2021/081/">remarkable paper</a>, Nutan Limaye, Srikanth Srinivasan, and Sébastien Tavenas have obtained the first superpolynomial lower bounds against general algebraic circuits of all constant depths over fields of characteristic zero (say reals). Furthermore, the lower-bound result is shown for a simple polynomial known as “iterated matrix multiplication” whose input consists of \(d\) matrices \(X_1,\ldots,X_d\) of dimension \(n \times n\), and the goal is to compute a fixed entry of their product \(X_1 \cdot X_2 \cdots X_d\). The same work also obtains a depth hierarchy theorem for algebraic circuits showing that for every depth <em>D</em>, there is an explicit polynomial that can be computed by a depth <em>D</em> circuit of size <em>s</em>, but requires circuits of size superpolynomial in <em>s</em> if the depth is <em>D</em>-1.</p>



<p><strong>Remarkable work of Matthew Brennan</strong><br /> The theory community suffered a terrible loss this year with the tragic and untimely passing of one of our rising stars, Matthew Brennan. While still a graduate student at MIT, Matthew almost single-handedly pushed forward an ambitious research program at the intersection of computational complexity and statistics. Here we will try to give a glimpse of Matthew’s extensive body of research.</p>



<span id="more-595"></span>



<p></p>



<p>To set the context, traditionally the field of computational complexity has been concerned with characterizing how much memory or computational power is needed, while statistics sheds light on how much data are needed. The interplay between computational and statistical resources and their underlying trade-offs is only recently coming into focus.</p>



<p>Many statistical estimation tasks exhibit information-computation gaps wherein the accuracy obtained by efficient algorithms is strictly worse than the estimate that one could in principle extract from the data if there were no computational limitations. In other problems, there is an apparent trade-off between the number of samples needed for an estimation task and the computational power of the estimation algorithm.</p>



<p>Identifying and rigorously establishing the presence of these information-computation trade-offs is a fundamental challenge that has drawn much interest in theoretical computer science and statistics. To rigorously establish an information-computation gap, one would need to prove lower bounds against efficient algorithms for statistical estimation problems.</p>



<p>Here on, there are two routes that one could take. First, one can prove limitations for specific classes of algorithms like MCMC, spectral methods, semidefinite programming, statistical queries, and so on. This approach has been highly successful, yielding precise lower bounds in many models and numerous relations discovered between the models.</p>



<p>Alternatively, one can take the grander route: assume the intractability of a well-studied computational problem and use <em>reductions</em> to establish hardness of the statistical estimation problem at hand. In a seminal work, Berthet and Rigollet showed a reduction from the planted clique problem to the sparse principal component analysis (sparse PCA), thereby establishing the presence of an information-computation gap for a version of sparse PCA.</p>



<p>In its most canonical setup, the input to the sparse PCA problem consists of samples from a \(d\)-dimensional Gaussian with covariance \(\Sigma = I_d + \theta vv^T\), where \(v\) is a \(k\)-sparse unit vector and \(\theta\) denotes the signal strength. A simple hypothesis testing variant of the problem asks to distinguish \(n\) samples drawn from this spiked covariance matrix and \(n\) samples drawn from the standard Gaussian distribution.</p>



<p>Notice that statistical estimation problems like sparse PCA are most interesting when their inputs are drawn from some natural distribution like the Gaussian distribution. Therefore, a reduction from a hard problem <em>A</em> to a statistical estimation problem <em>B</em> will not only have to map instances of <em>A</em> to instances of <em>B</em>, but also have to produce the right distribution over instances of <em>B</em>. For example, ideally a reduction from planted clique to sparse PCA must map instances of planted clique (random graphs with cliques) to random vectors drawn from an appropriate Gaussian measure. How could a reduction ever do this, one might ask.</p>



<p>In fact, this is why one might decide not to take the grand route of using reductions to understand the complexity of statistical problems. While reductions have been exceptionally successful in establishing tight hardness results for <em>NP</em>-complete optimization problems, building a similar web of reductions for statistical problems like sparse PCA seemed hopeless to me. Not for Matthew, who courageously took this challenge head-on and succeeded!</p>



<p>Despite efforts following the seminal work of Berthet and Rigollet, showing a tight hardness result for sparse PCA in its most canonical Gaussian setup seemed out of reach. In a series of works, Matthew and coauthors developed a set of simple reduction tools that when put together led to a tight characterization of the complexity of the sparse PCA problem in its most canonical setup, over the entire range of parameters!</p>



<p>More recently, Matthew and his advisor, Guy Bresler, proposed a generalized planted clique conjecture referred to as “secret leakage planted clique” that can serve as a starting point for a web of reductions encompassing a variety of problems such as tensor PCA, robust sparse mean estimation, and semirandom community recovery. Not only have these works developed a set of useful reduction techniques for statistical problems, but most importantly, they have demonstrated that reductions can indeed be harnessed toward tight hardness results for statistical problems. Matthew was a recipient of the best student paper award at the Conference on Learning Theory (COLT) on two separate occasions for this line of work.</p>



<p>Matthew’s work is one of the central themes of this semester’s program on Computational Complexity of Statistical Inference. His work has laid the foundations of a theory of reductions for statistical problems, something for us to build on over the coming years. While his ideas are ever present this semester, his presence at the program is sorely missed.</p></div>







<p class="date">
by 1737780 <a href="https://blog.simons.berkeley.edu/2021/09/theory-at-the-institute-and-beyond-september-2021/"><span class="datestr">at October 01, 2021 03:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/09/30/phd-student-at-university-of-bergen-norway-apply-by-november-14-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/09/30/phd-student-at-university-of-bergen-norway-apply-by-november-14-2021/">PhD Student at University of Bergen (Norway) (apply by November 14, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>3-year PhD student position in the field of Symbolic Algorithms (extension to 4 years if teaching). Salary: 491,200 NOK per year (approx 48,000 EUR per year) before taxes. Applicants should have a MSc. degree (or obtain a MSc. degree before 31/01/2022) and a strong background in some relevant subfield of TCS, such as algorithms, graph theory, combinatorics, automata theory, type theory, etc.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/212570/phd-research-fellow-in-informatics-symbolic-algorithms">https://www.jobbnorge.no/en/available-jobs/job/212570/phd-research-fellow-in-informatics-symbolic-algorithms</a><br />
Email: mateus.oliveira@uib.no</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/09/30/phd-student-at-university-of-bergen-norway-apply-by-november-14-2021/"><span class="datestr">at September 30, 2021 09:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/09/30/postdoc-at-university-of-bergen-norway-apply-by-november-14-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/09/30/postdoc-at-university-of-bergen-norway-apply-by-november-14-2021/">Postdoc at University of Bergen (Norway) (apply by November 14, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>3-year postdoc position in the field of Symbolic Algorithms. Salary: 535,500 NOK per year (approx. 52,500 EUR per year) before taxes. Applicants should have a Ph.D. degree (or obtain a Ph.D. degree before 31/01/2022) and a strong publication record in some relevant subfield of TCS, such as algorithms, graph theory, combinatorics, automata theory, type theory, etc.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/212553/postdoctoral-research-fellow-position-within-informatics-symbolic-algorithms">https://www.jobbnorge.no/en/available-jobs/job/212553/postdoctoral-research-fellow-position-within-informatics-symbolic-algorithms</a><br />
Email: mateus.oliveira@uib.no</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/09/30/postdoc-at-university-of-bergen-norway-apply-by-november-14-2021/"><span class="datestr">at September 30, 2021 09:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8844632344201187395">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2021/09/being-chair.html">Being the Chair</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>If you have Netflix and interested in the academic world, I recommend <a href="https://www.netflix.com/title/81206259">The Chair</a>, a six-episode dramatic series starring Sandra Oh as a new English department chair at a "lower tier ivy league university". The series takes many artistic liberties and compresses much in a short time period but gets much about academics right such as the tension between faculty and the administration with the chair caught in the middle, the need to create majors that attract students, faculty past their prime teaching the same courses in the same way for decades, faculty who get themselves in a hole and keep digging, alumni donors controlling academic decisions, pressure to build a diverse faculty, faculty feeling under appreciated and getting outside offers, and a wonderful exposition of how the field has changed over the past thirty years given to someone who had dropped out before finishing their PhD to take on a different career.</p><p>When I served as department chair at Georgia Tech, I dealt with most if not all of these issues above, though not at the same time. I had some challenges that today's English department doesn't face: how to handle enrollments that more than doubled while barely able to hire more faculty than were departing, not that I would trade in a second for the existential crisis that English departments are going through. </p><p>When I left Georgia Tech after seven years, I had outlasted every other current chair in the Colleges of Computing, Science and Engineering. Not sure what this says about me or about Georgia Tech.</p><p>Being chair is the most challenging job in academia. The faculty technically report to you but you aren't their boss in any traditional sense--they came to academia because of the freedom to work on what they want and they won't give it up. It's virtually impossible to fire anyone with tenure. The joke goes that a chair needs two umbrellas, one to block stuff coming from the administration going to the faculty and the other to block the stuff from the faculty from going to the administration. Since I left it has gotten much uglier in the University System of Georgia which has no mask or vaccine mandates and glad I'm not the chair to deal with that.</p><p>This all sounds like I'm discouraging of becoming a department chair and it certainly isn't a job for anyone but it can be a very rewarding job. You can help shape the future of the department by the faculty you hire and the vision you set and create an environment that helps your faculty and students succeed. </p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2021/09/being-chair.html"><span class="datestr">at September 30, 2021 02:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/09/30/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/09/30/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://www.insidehighered.com/news/2021/09/15/pearson-sues-former-partner-chegg-copyright-infringement">Textbook company Pearson sues Chegg for copyright infringement, for selling solutions to textbook homework problems</a> (<a href="https://mathstodon.xyz/@11011110/106945803113477254">\(\mathbb{M}\)</a>). On the one hand, for-profit cheater-enablers like Chegg are a cancer on higher education. On the other, the solution to a problem is generally a concept, not a text, and should not be something that can be locked up under copyright. So I don’t know who to root for?</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/news/2021/09/13/future-academic-conference"><em>Inside Higher Ed</em> on the future of academic conferences</a> (<a href="https://mathstodon.xyz/@11011110/106951348197294218">\(\mathbb{M}\)</a>). A significant fraction of academics surveyed said that they still felt unsafe going to physical conferences, and with the carbon footprint and reduced expenses of virtual but greater interactivity of physical meetings, some mix of both seems likely going forward. However, trying to mix both in one conference (especially for conferences with many parallel small talks or panels) seems difficult and expensive.</p>
  </li>
  <li>
    <p><a href="https://www.kennethmoreland.com/color-advice/">Color map advice for scientific visualization</a> (<a href="https://mathstodon.xyz/@11011110/106955479284414863">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=28579720">via</a>).</p>
  </li>
  <li>
    <p>Three sets of talk slides from recent talks (<a href="https://mathstodon.xyz/@11011110/106962519567502209">\(\mathbb{M}\)</a>):</p>

    <ul>
      <li>
        <p><a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-WG-21-slides.pdf">The graphs of stably matchable pairs, <em>WG 2021</em></a></p>
      </li>
      <li>
        <p><a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-WADS-21-slides.pdf">A stronger lower bound on parametric minimum spanning trees, <em>WADS 2021</em></a></p>
      </li>
      <li>
        <p><a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-GD-21-slides.pdf">Limitations on realistic hyperbolic graph drawing, <em>GD 2021</em></a></p>
      </li>
    </ul>

    <p>Unfortunately I don’t have links to recordings of the talks.</p>
  </li>
  <li>
    <p>I thought for sure I had posted before about <a href="https://www.thisiscolossal.com/2017/09/bold-new-geometric-cake-designs-by-dinara-kasko/">Dinara Kasko’s 3d-printed geometric food designs</a> (<a href="https://mathstodon.xyz/@11011110/106968564827718278">\(\mathbb{M}\)</a>, <a href="https://culturainquieta.com/es/arte/diseno/item/12643-la-reposteria-matematica-de-la-arquitecta-dinara-kasko.html">see also</a>, <a href="https://dinarakasko.com/">home page</a>), but grep tells me that if I ever did, it wasn’t with her name.</p>
  </li>
  <li>
    <p>The <a href="https://zbmath.org/">zbMATH</a> mathematics review database was broken for a day (<a href="https://mathstodon.xyz/@11011110/106971763813682368">\(\mathbb{M}\)</a>), unable to show the old scans of printed reviews, but fortunately it got better.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=-p7C5FrgAzU">Twelve threads</a> (<a href="https://mathstodon.xyz/@11011110/106982013693223792">\(\mathbb{M}\)</a>). Vi Hart’s latest video mixes up discussions of the nature of social media, the philosophy of mathematical creativity, an exploration of symmetry, and an investigation of the spot patterns of 8-sided dice (which turn out not to all be the same) and how to visualize them.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@mathcination/106905943747555880">Visualization of Poncelet’s porism</a>, calculated with difficulty by mathcination from Cayley’s criteria. It would have been easier to calculate a regular hendecagram and then perturb it by a projective transformation, but that wasn’t the point.</p>
  </li>
  <li>
    <p>I recently saw a link to <a href="https://www.w3.org/TR/MathML3/chapter1.html">Chapter 1 of the MathML 3.0 spec</a> (<a href="https://mathstodon.xyz/@11011110/107002528612296323">\(\mathbb{M}\)</a>), using as an example the quadratic formula in both layout markup and content markup. Its totally unwieldy non-human-readable expansion obscures the fact that the MathML authors didn’t even get the math right: their content markup silently replaces the plus-minus sign, by which the correct formula represents both solutions, with an addition operation, giving only one of the two. Time to re-link my old <a href="https://11011110.github.io/blog/2015/08/04/mathml-considered-harmful.html">anti-MathML rant</a>?</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2021/09/hacer-origami-sculptures/">Giant origami animals in Midtown Manhattan</a> (<a href="https://mathstodon.xyz/@11011110/107007549470942566">\(\mathbb{M}\)</a>). But now I want to know if they were really each fabricated from a single uncut square sheet of steel. And if so, how did they get the corners so crisp?</p>
  </li>
  <li>
    <p><a href="https://www.getty.edu/publications/virtuallibrary/pdf/9780892363353.pdf"><em>The Topkapı Scroll – Geometry and Ornament in Islamic Architecture</em>, by Harvard professor Gülru Necipoğlu</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107017227413204703">\(\mathbb{M}\)</a>).</span> One of many beautiful art books free for download from the <a href="https://www.getty.edu/publications/virtuallibrary/">Getty Virtual Library</a>.</p>
  </li>
  <li>
    <p><a href="http://www.formulas.it/formulog/wp-content/uploads/2014/12/sierpinski-aplimat.pdf">Sierpiński triangles in stone, on medieval floors in Rome</a> (<a href="https://mathstodon.xyz/@11011110/107021612310283993">\(\mathbb{M}\)</a>), Elisa Conversano and Laura Tedeschini Lalli. See also Kim Williams, “<a href="https://doi.org/10.1007%2Fbf03024339">The pavements of the Cosmati</a>”. The <a href="https://commons.wikimedia.org/wiki/Category:Sierpi%C5%84ski_triangles_in_Cosmatesque_pavements">collection of images of these on Wikimedia commons</a> is a little sad — Conversano and Tedeschini Lalli, and Williams, have a lot more.</p>
  </li>
  <li>
    <p>Every invertible function computable both ways in polynomial time has polynomial-size reversible logic circuits, using extra “dummy” values that are zero on both input and output (<a href="https://mathstodon.xyz/@11011110/107024956502298623">\(\mathbb{M}\)</a>): See Jacopini, Mentrasti, &amp; Sontacchi, “<a href="https://doi.org/10.1137/0403020">Reversible turing machines and polynomial time reversibly computable functions</a>”, SIAM J. Disc. Math. 1990.</p>

    <p><em>Theorem:</em> No circuit of reversible gates of arity less than \(n\), without dummy values, can compute \(n\)-bit 2’s-complement negation.</p>

    <p><em>Proof:</em> Each gate performs an even permutation on the \(2^n\) inputs, but negation is an odd permutation. \(\Box\)</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/09/30/linkage.html"><span class="datestr">at September 30, 2021 11:57 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2021-09-30-distributed-consensus-made-simple-for-real-this-time/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2021-09-30-distributed-consensus-made-simple-for-real-this-time/">Distributed consensus made simple (for real this time!)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Multi-Paxos is the de facto solution for deciding a log of commands to execute on a replicated state machine, yet it’s famously difficult to understand, motivating the switch to ‘simpler’ consensus protocols such as Raft. The conventional wisdom is that the best way to use Paxos (aka Synod, or single-shot...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2021-09-30-distributed-consensus-made-simple-for-real-this-time/"><span class="datestr">at September 30, 2021 07:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19166">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/">Baby Steps</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><font color="#0044cc"><br />
<em>You don’t have to see the whole staircase, just take the first step—Martin Luther King, Jr.</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/viazovska/" rel="attachment wp-att-19168"><img width="195" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/Viazovska.jpg?resize=195%2C150&amp;ssl=1" class="alignright wp-image-19168" height="150" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Still from her IHES <a href="https://www.youtube.com/watch?v=xALXm2XHDWc">lecture</a></font></td>
</tr>
</tbody>
</table>
<p>
Maryna Viazovska was the first person to prove an exact bound on sphere packing in a dimension higher than 3. She <a href="https://arxiv.org/pdf/1603.04246.pdf">achieved</a> this for dimension 8 in 2016 by making an improvement of <b>0.00001</b> over one previous <a href="https://annals.math.princeton.edu/wp-content/uploads/annals-v157-n2-p09.pdf">paper</a> by Henry Cohn and Noam Elkies. This also led to the <a href="https://arxiv.org/pdf/1603.06518.pdf">solution</a> in dimension 24, joint with Cohn and Abhinav Kumar, Stephen Miller, and Danylo Radchenko.</p>
<p>
Today we talk about partial progress—baby steps—and its relation to solving conjectures.</p>
<p>
This post is a continuation of our recent <a href="https://rjlipton.wpcomstaging.com/2021/08/10/p-vs-np-proof-claims/">thoughts</a> about how those who claim to have solved a major problem almost always claim to have solved the whole thing in one large leap. We’ve thought about declaring a rule that any claim on a major open problem, at least about complexity lower bounds, must first be a <em>partial result</em>. We will give concrete suggestions in that direction at the end. But on reflection, we’ll curb the dogmatics a little.</p>
<p>
In her 2016 <em>Quanta</em> <a href="https://www.quantamagazine.org/sphere-packing-solved-in-higher-dimensions-20160330">article</a> on Viazovska’s breakthrough, Erica Klarreich quotes Peter Sarnak:</p>
<blockquote><p><b> </b> <em> “It’s stunningly simple, as all great things are. You just start reading the paper and you know this is correct.” </em>
</p></blockquote>
<p>
We hasten to add that the paper’s correctness is evident amid the context that others had established over the previous two decades, going back at least to Thomas Hales’s voluminous proof of Johannes Kepler’s conjecture for dimension 3. To quote Klarreich:</p>
<blockquote><p><b> </b> <em> Researchers have known for more than a decade what the missing ingredient in the proof [of optimality for dimensions 8 and 24] should be—an “auxiliary” function that can calculate the largest allowable sphere density—but they couldn’t find the right function. … [F]inding the right modular form allowed Viazovska to prove [the case of 8] in a mere 23 pages. </em>
</p></blockquote>
<p>
Thus Viazovska brought in a new tool to the problem, <em>modular forms</em>, which had already proved their merit in resolving the Fermat conjecture. But she still needed to choose the right modular form among many candidates. Klarreich quotes her as saying it is difficult even just to explain how she knew which one to use. This brings us back to the challenge of explaining—or debunking—the flash of insight that claimers claim to have. At least in this case, per Sarnak’s quote, the proof was in the pudding.</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/cohnexcerpt/" rel="attachment wp-att-19169"><img width="460" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/CohnExcerpt.jpg?resize=460%2C174&amp;ssl=1" class="aligncenter size-full wp-image-19169" height="174" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">From Cohn’s 2017 <i>AMS Notices</i> <a href="https://www.ams.org/publications/journals/notices/201702/rnoti-p102.pdf">article</a></font>
</td>
</tr>
</tbody></table>
<p>
To complete the mixing of our original message, the examples we chose happen to involve improvements by tiny amounts. We’ve even understated Viazovska’s above: reckoned against a later <a href="https://annals.math.princeton.edu/2009/170-3/p01">paper</a> by Cohn and Elkies, her improvement was </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0.000000000000000000000000000001.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  0.000000000000000000000000000001. " class="latex" /></p>
<p>
The recent <a href="https://rjlipton.wpcomstaging.com/2020/10/26/a-vast-and-tiny-breakthrough/">post</a> where we discussed the phrase “the proof is in the pudding” involves a number with six more <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0}" class="latex" />s than that. These are <b>not</b> what we mean by “baby steps.” But let us tell our next story, which also involves Cohn.</p>
<p>
</p><p></p><h2> Steps Toward Matrix Multiplication </h2><p></p>
<p></p><p>
We have <a href="https://rjlipton.wpcomstaging.com/2011/11/29/a-breakthrough-on-matrix-product/">covered</a> <a href="https://rjlipton.wpcomstaging.com/2011/12/03/the-meaning-of-omega/">other</a> <a href="https://rjlipton.wpcomstaging.com/2012/02/01/a-brief-history-of-matrix-product/">work</a> on the exponent <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\omega}" class="latex" /> of matrix product. This means the infimum of all <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{e}" class="latex" /> such that any two <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n \times n}" class="latex" /> matrices can be multiplied in <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Ee%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{O(n^e)}" class="latex" /> unit operations. In 1990, Don Coppersmith and Shmuel Winograd <a href="https://www.sciencedirect.com/science/article/pii/S0747717108800132">brought</a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\omega}" class="latex" /> down below <img src="https://s0.wp.com/latex.php?latex=%7B2.375477%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2.375477}" class="latex" />. The current best bound <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega+%3C+2.37286%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\omega &lt; 2.37286}" class="latex" /> is from a SODA 2021 <a href="https://arxiv.org/abs/2010.05846">paper</a> by Josh Alman and Virginia Williams; its abstract highlights the improvement by <img src="https://s0.wp.com/latex.php?latex=%7B0.00001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0.00001}" class="latex" /> from the previous best.</p>
<p>
In 2005, however, Cohn wrote a <a href="https://arxiv.org/pdf/math/0511460.pdf">paper</a> with Robert Kleinberg, Balazs Szegedy, and Christopher Umans on ideas for taking <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\omega}" class="latex" /> all the way down to <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" /> in one jump. This diverges from both the reading of “baby step” as “tiny improvement” and our idea meaning limited-but-definite partial progress. Their strategy for the full jump has come in and out of clouds since then. But their paper has motivated the subsequent partial progress in several ways. We have <a href="https://rjlipton.wpcomstaging.com/2010/03/27/fast-matrix-products-and-other-amazing-results/">mentioned</a> this paper <a href="https://rjlipton.wpcomstaging.com/2021/04/30/test-of-time/">several</a> <a href="https://rjlipton.wpcomstaging.com/2012/06/22/cricket-400-and-complexity-theory/">times</a>, notably <a href="https://rjlipton.wpcomstaging.com/2018/08/30/limits-on-matrix-multiplication/">here</a>. </p>
<p>
The objective need not be <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" /> versus <img src="https://s0.wp.com/latex.php?latex=%7B2.372...%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2.372...}" class="latex" />, however. There is a notable milepost just above <img src="https://s0.wp.com/latex.php?latex=%7B2.30%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2.30}" class="latex" />. It comes from a STOC 2015 <a href="https://arxiv.org/abs/1411.5414">paper</a> by Andris Ambainis, Yuval Flimus, and François Le Gall. It shows that a wide class of techniques of the kind used since 1990 cannot achieve better than <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega+%3C+2.3078%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\omega &lt; 2.3078}" class="latex" />. </p>
<p>
Other recent <a href="https://drops.dagstuhl.de/opus/volltexte/2018/8360/pdf/LIPIcs-ITCS-2018-25.pdf">work</a> by Alman and Williams shows both a dimension along which the road down to <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" /> may still be open but other limits in other directions. Even their new <img src="https://s0.wp.com/latex.php?latex=%7B0.00001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0.00001}" class="latex" /> improvement has new ideas that may be exploited more generally. This is a feature of partial progress that contrasts with what we said <a href="https://rjlipton.wpcomstaging.com/2021/08/10/p-vs-np-proof-claims/">recently</a> about not learning much from whole-jump attempts: partial progress always shows a higher learning curve.</p>
<p>
</p><p></p><h2> Some Partial Progress Objectives </h2><p></p>
<p></p><p>
Cohn also has a page of informal <a href="http://math.mit.edu/~cohn/Thoughts/">thoughts</a> on how to perform research, including <a href="https://math.mit.edu/~cohn/Thoughts/advice.html">advice</a> for those who claim to have solved some open problem. We want to add this advice:</p>
<blockquote><p><b> </b> <em> Make sure ahead of time that your advance really covers the intermediate ground it jumps through. Even better, walk back your claim a little so that it proves something only a step or so beyond previous knowledge. </em>
</p></blockquote>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/steps/" rel="attachment wp-att-19171"><img width="270" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/steps.png?resize=270%2C186&amp;ssl=1" class="aligncenter size-full wp-image-19171" height="186" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://www.kimaverycoaching.com/baby-steps/">source</a> (not <a href="https://www.warehouse3b.top/ProductDetail.aspx?iid=151594314&amp;pr=30.99">this</a>)</font>
</td>
</tr>
</tbody></table>
<p>
Here are a few examples of such things to prove in complexity theory:</p>
<p></p><p></p>
<ul>
<li>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P \neq NP}}" class="latex" />: The claim is that SAT requires exponential time. <p></p>
</li><li>
<b>A Baby Step</b>: Prove SAT cannot be done in linear time. Or that it cannot be done in <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n^2}" class="latex" /> time.
</li></ul>
<p><br /></p>
<ul>
<li>
<b>Circuit Lower Bounds</b>: The claim is that some concrete problem in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" /> requires super-polynomial size general circuits. <p></p>
</li><li>
<b>A Baby Step</b>: Prove that some concrete problem cannot be done in a linear size boolean circuit–or one of size <img src="https://s0.wp.com/latex.php?latex=%7B6n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{6n}" class="latex" />.
</li></ul>
<p><br /></p>
<ul>
<li>
<b>Factoring</b>: The claim is that factoring a general number <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N}" class="latex" /> requires super-polynomial time in the bit-length of <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N}" class="latex" />. <p></p>
</li><li>
<b>A Baby Step</b>: Prove that factoring cannot be done in linear time. Or not in quadratic time. See <a href="https://math.mit.edu/~cohn/Thoughts/factoring.html">this</a>.
</li></ul>
<p><br /></p>
<ul>
<li>
<b>Graph Isomorphism</b>: The claim is that there is polynomial-time algorithm to tell whether two graphs are isomorphic. <p></p>
</li><li>
<b>A Baby Step</b>: Prove the case where the graphs have degree a fixed constant.
</li></ul>
<p>
This is an example of a baby step that is already done. Note: it was not an easy step. It is a famous result of Eugene Luks—see his 1982 <a href="https://www.sciencedirect.com/science/article/pii/0022000082900095">paper</a>. </p>
<p></p><p><br />
We could go deeper into known computational complexity issues to find more. The idea applies to problems from mathematics in general. Here is one:</p>
<p></p><p></p>
<ul>
<li>
<b>Riemann Hypothesis”</b> The <a href="https://en.wikipedia.org/wiki/Riemann_hypothesis">claim</a> is of course that 	<p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bn%3D1%7D%5E%7B%5Cinfty%7D+%5Cfrac%7B1%7D%7Bn%5Es%7D+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \sum_{n=1}^{\infty} \frac{1}{n^s} = 0 " class="latex" /></p>
<p>only happens for negative even integers and for <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{s}" class="latex" /> with real part <img src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1/2}" class="latex" />. The latter are the zeroes in the <i>critical strip</i> where the real part is between <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" />. The sum is convergent for real part <img src="https://s0.wp.com/latex.php?latex=%7B%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{&gt; 1}" class="latex" /> and its analytic continuation for other <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{s}" class="latex" /> is understood.</p>
</li><li>
<b>A Baby Step</b>: Prove that it is impossible for just two zeroes to be off the half line. Or that only a finite number can be off the half line.
</li></ul>
<p></p><p><br />
We invite readers to add more favorite math examples in comments, or others from complexity theory.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What are some additional first steps? </p>
<p>
Have we also—unintendedly but effectively—made a case for the value of tiny improvements? At least when they are conceptual improvements?</p>
<p>
Here is the answer to the puzzle in the previous <a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/">post</a>: Barbara wins. She forces the sum of every row to be <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0}" class="latex" />. Alan makes an entry <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" />, she then makes an entry in the same row <img src="https://s0.wp.com/latex.php?latex=%7B-x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{-x}" class="latex" />. This works since 1986 is even. This makes the matrix singular, since the matrix times the all <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> vector is <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0}" class="latex" />.</p>
<p></p><p><br />
[inserted “in dimension 8” at top, added note on “analytic continuation” for Riemann, other tweaks]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/"><span class="datestr">at September 30, 2021 06:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/09/29/postdoc-at-cwi-apply-by-october-31-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/09/29/postdoc-at-cwi-apply-by-october-31-2021/">Postdoc at CWI (apply by October 31, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A 2-year postdoctoral position is available at CWI in the area of discrete and continuous optimization under the supervision of Daniel Dadush. Candidates with interests in theoretical aspects of integer programming &amp; linear programming, as well as discrepancy theory should apply. No teaching requirement. The starting date is flexible.</p>
<p>Website: <a href="https://www.cwi.nl/jobs/vacancies/894611">https://www.cwi.nl/jobs/vacancies/894611</a><br />
Email: dadush@cwi.nl</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/09/29/postdoc-at-cwi-apply-by-october-31-2021/"><span class="datestr">at September 29, 2021 04:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2021-09-29-the-round-complexity-of-reliable-broadcast/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2021-09-29-the-round-complexity-of-reliable-broadcast/">The round complexity of Reliable Broadcast</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Reliable Broadcast is an important building block of many Asynchronous protocols. There is a broadcaster that has some input value, $v$, and a non-faulty party that terminates needs to output a value. Reliable Broadcast is defined via two properties: Validity: If the broadcaster is non-faulty then eventually all non-faulty parties...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2021-09-29-the-round-complexity-of-reliable-broadcast/"><span class="datestr">at September 29, 2021 10:05 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/141">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/141">TR21-141 |  On the (im)possibility of branch-and-bound search-to-decision reductions for approximate optimization | 

	Alexander Golovnev, 

	Siyao Guo, 

	Spencer Peters, 

	Noah Stephens-Davidowitz</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study a natural and quite general model of branch-and-bound algorithms. In this model, an algorithm attempts to minimize (or maximize) a function $f : D \to \mathbb{R}_{\geq 0}$ by making oracle queries to a heuristic $h_f$ satisfying 
\[
    \min_{x \in S} f(x) \leq h_f(S) \leq \gamma \cdot \min_{x \in S} f(x)
\]
for some $\gamma \geq 1$ and any subset $S$ in some allowed class of subsets $\mathcal{S}$ of the domain $D$. We show tight upper and lower bounds on the number of queries $q$ needed to find even a $\gamma'$-approximate minimizer for quite large $\gamma'$ in a number of interesting settings, as follows.

- For arbitrary functions $f : \{0,1\}^n \to \mathbb{R}_{\geq 0}$, where $\mathcal{S}$ contains all subsets of the domain, we show that no branch-and-bound algorithm can achieve $\gamma' \approx\gamma^{n/\log q}$, while a simple greedy algorithm achieves essentially $\gamma^{n/\log q}$.

- For a large class of MAX-CSPs, where $\mathcal{S} := \{ S_w\}$ contains each set of assignments to the variables induced by a partial assignment $w$, we show that no branch-and-bound algorithm can do significantly better than essentially a random guess, even for  $\gamma \approx 1+\sqrt{\log(q)/n}$.

- For the Traveling Salesperson Problem (TSP), where $\mathcal{S} := \{S_p\}$ contains each set of tours extending a path $p$, we show that no branch-and-bound algorithm can achieve $\gamma' \approx (\gamma-1) n/\log q$. We also prove a nearly matching upper bound in our model. 

Behind these results is a "useless oracle lemma," which allows us to argue that under certain conditions the heuristic $h_f$ is "useless," and which might be of independent interest.

We also note two alternative interpretations of our model and results. If we interpret the heuristic $h_f$ as an oracle for an approximate decision problem, then our results unconditionally rule out a large and natural class of approximate search-to-decision reductions (which we think of as "branch-and-bound" search-to-decision reductions). We therefore show an oracle model in which approximate search and decision are strongly separated. (In particular, our lower bound for TSP can be viewed as a negative answer to a question posed by Bellare and Goldwasser (SIAM J. Comput. 1994), though only in an oracle model.) By instead interpreting $h_f$ as a data structure, we see that our results unconditionally rule out black-box search-to-decision reductions for data structures.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/141"><span class="datestr">at September 28, 2021 08:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2021/09/28/summarization/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2021/09/28/summarization/">Statistics as algorithmic summarization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Though a multifaceted and complex discipline, Statistics’ greatest contribution is a rigorous framework for summarization. Statistics gives us reasonable procedures to estimate properties of a general population by examining only a few individuals from the population. In this regard, statistics is algorithmic: it provides randomized algorithms for extrapolation. In this blog, I’ll review some elementary stats (with as little mathematical formalism as possible), and try to crystalize why this algorithmic view is illuminating. In future blogs, I’ll build upon this algorithm perspective in applying it to more interesting examples in experiment design and prediction.</p>

<p>For a simple starter example, we know that every person on Earth has a height, defined as the distance from the bottom of their feet to the top of their head when standing upright. Suppose we would like to know the mean of the height of all living people. This would require us tracking down every living individual, getting out a tape measure, and measuring the distance from the bottom of their feet to the top of their head. To avoid such exhaustive counting we could instead devise an efficient algorithm to estimate this quantity. What if we selected a subset at random, and used this subset to estimate the mean? That is, we could collect a random sample of individuals from the population and measure the average height of all of the individuals in the sample.</p>

<p>The average height measured on this random sample is a random quantity. Thus it must have a mean and variance like we associate with other random quantities. If we were to sample each individual uniformly at random from all living humans, the expected mean height of the sample would be precisely the average height in the general population. Moreover, the variance of the average height of the sample will shrink proportionally to the number of sampled individuals. The more individuals you measure, the closer the average height on the sample will be to the average over the population.</p>

<p>Statistics provides powerful formulas that let us precisely quantify how close the sample average will be to the population average. For instance, we know a person’s height is a positive number and that there are no people who are taller than nine feet. With these two facts, a simple application of a formula called <a href="https://en.wikipedia.org/wiki/Hoeffding%27s_inequality"><em>Hoeffding’s inequality</em></a> tells us that if we sample the heights of thirty thousand individuals, our sample average will be within an inch of the true average height with probability at least 83%. This assertion is true no matter how large the population of individuals. The required sample size is dictated only by the variability of height, not by the number of total individuals.</p>

<p>You could replace “height” in this example with almost any attribute that you are able to measure well. For quantities with reasonable variability, a uniform sample from a general population will give a high quality estimate of the average value. Statistics provides a powerful framework to reason about population-level properties by examining properties of small subsets.</p>

<p>In this example, statistics provided an algorithm for estimation. We began with a quantity whose average value we would like to estimate. We specified how much this quantity can vary in the population under study. Using formulas from statistics, we computed the number of individuals we needed to examine in order to have an estimate of appropriate quality. We then can proceed to do our best to extract a random sample of individuals of this size from the population, measure these individuals, and report the mean of the sample. This is a full procedure for estimating the mean value of the general population.</p>

<p>This algorithmic description of statistical summarization probably seems uncontroversial, but it differs from how statistics is often taught or conceptualized. As I’ve discussed in <a href="https://www.argmin.net/2021/09/13/effect-size/">previous</a> <a href="https://www.argmin.net/2021/09/21/models-are-wrong/">blogs</a>, the statistical model is oftentimes given highest precedence. In this model-based framing of statistics, the world is governed by probabilistic rules. With enough effort, these rules can be specified by a generative statistical model, and we assume that measurement is equivalent to sampling from this generative model. The generative model will have properties like a mean, and the law-of-large numbers will tell us that if we sample enough times from the model, we can accurately estimate the mean and other properties.</p>

<p>This distinction between modeling the sampling and modeling the population may appear to be splitting hairs. In some sense, the two viewpoints only differ conceptually as the algorithms for estimating the mean height in a population will be identical. However, our interpretation of these two views is different: in the algorithmic view, one can use statistics to understand the physical world no matter how the general population arose. As our height example highlights, only the most minimal modeling assumptions are needed to make use of statistical methods. In the modeling view, we shoehorn ourselves into modeling all processes with probability distributions. Not only is this unnecessary, but validating probabilistic models is also quite difficult. As I described in my last two blog posts (<a href="https://www.argmin.net/2021/09/13/effect-size/">1</a>) (<a href="https://www.argmin.net/2021/09/21/models-are-wrong/">2</a>), proposed statistical models are never validated in the vast majority of scientific studies.</p>

<p>The algorithmic view of statistics moreover illuminates the aspects of randomness that we have under our control. For example, there are whole branches of computer science dedicated to deterministically generating numbers that look random for all intents and purposes. Random number generation is something we can control. We can focus on understanding how our measurements fail to be ideal, rather than focusing on how the natural world doesn’t obey our models. This empowers the statistical practitioner to tune their procedures to be more robust against the limitations of what that can measure.</p>

<p>I want to once more emphasize that the algorithmic perspective I’ve presented here is not novel at all. Thinking about the combinatorics of random permutations and how they could be used to design randomized experiments is nearly one hundred years old, and, for example, prevalent in the works of <a href="https://www.jstor.org/stable/2342192">Jerzy Neyman</a> and the eccentric eugenicist <a href="https://en.wikipedia.org/wiki/The_Design_of_Experiments">Ronald Fisher</a> by the 1930s. Fisher’s rambling discursion on the woman who can tell if milk was added to a cup before tea describes a randomization procedure that does not model the appearance of tea in cups, the composition of tea cups, nor the psychic abilities of the tea expert. It purely counts permutations and uses exact statistics to provide a way to evaluate validity of a claim. I’ll review in more detail how to use these effectively <em>model-free</em> ideas for experimentation in the next post.</p>

<p>There are obviously issues with the algorithmic view. Statistical sampling methods work best when the variability of the quantity of interest is low. In such a case, small experiments quickly reveal insights about the population. When variances are large or effectively unbounded, the number of samples required for high precision estimates might be impractical and our estimators and algorithms need to be rethought. There are many phenomena that obey “power law” scaling, and such quantities are harder to work with in this rudimentary experimental framework. The uniform sampling algorithm we have described will have unbounded variance, and hence the average on the sample will no longer be an accurate measure of the average of the population. More sophisticated means must be deployed to estimate means of quantities with such high variation.</p>

<p>Another drawback of statistical sampling is the requirement that samples be sampled uniformly. Uniform sampling is an idealization and is often hard to implement in practice. For example, what does it mean to collect an i.i.d. sampling of registered voters in a poll? Some voters may not respond to your phone calls. Even more problematic is when you cannot define the population well in advance, as would be the case of the vague notion of “likely” voters. More sophisticated statistical analyses can provide guarantees on non-uniform sampling strategies, but care must be taken to ensure that the statistical bounds we compute reflect the reality of the implementation of the data collection. Understanding our sampling capabilities is crucial to understanding the validity of our estimates.</p>

<p>With these caveats in mind, our algorithmic framing of statistics gives us a focused way to think about experiment design and prediction methods. In the next blogs, I’ll explore these both in depth.</p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2021/09/28/summarization/"><span class="datestr">at September 28, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2021/09/28/rct/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2021/09/28/rct/">Experiments as randomized algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>While every statistics course leads with how correlation does not imply causation, the methodological jump from observation to causal inference is small. Using the same algorithmic summarization and statistical analysis tools that we use to estimate averages, we can construct a reliable algorithm for evaluating the causal effect of interventions—actions that change the fate of individuals in a population. The crucial addition needed to evaluate cause and effect is the ability to intervene itself.</p>

<p>Let’s say that we have devised some intervention that can be applied to any individual in a population. We’d like to evaluate the impact of the intervention on the broader population by testing it on a small subset of individuals. As an example following on from the <a href="https://www.argmin.net/2021/09/28/summarization/">last post</a>, the reader can think of height as the property we’d like to affect, and milk consumption as the treatment. We cannot apply the treatment to every individual or else we’d never be able to disentangle whether the treatment caused the outcome or not. The solution is to restrict our attention to a subset of the population, and leverage randomized assignment to eliminate confounding effects.</p>

<p>The simplest mathematical formulation of experiment design often referred to in terms of <em>potential outcomes</em> and was originally conceived by <a href="https://www.jstor.org/stable/2245382">Jerzy Neyman</a> (a character who will likely appear in every blog post in this series). Suppose if we apply a treatment to an individual, the quantity of interest takes value $A$. If we don’t apply the treatment, the quantity of interest is equal to $B$. Then we can define a quantity $Y$ which is equal to $A$ if the treatment is applied and equal to $B$ if the treatment is not applied. $Y$ is a deterministic quantity like height. However, there is an odd conditional effect: the value of $Y$ changes depending on whether we applied the treatment or not.</p>

<p>As a simple example, let $A$ denote the height of a person at age 18 if they drank milk growing up and $B$ denote their height if they did not drink milk. Now, obviously, one person can only take one of these paths! But we can imagine the two alternate realities where the same child either drank a cup of milk a day or drank a cup of water instead. The goal of an experimenter is to determine what would happen to a general individual had they taken either of the two paths in the road. The two potential outcomes here are the outcome if the treatment is applied and the outcome if the treatment is not applied.</p>

<p>While the potential outcomes formulation is tautological, it lets us apply the same ideas and statistics we used for computing the mean to the problem of estimating more complex treatment effects. For any individual, the treatment effect is a relation between the quantities A and B, commonly just the difference $A-B$. If the difference is positive, we see that applying the treatment increases the outcome variable for this individual. If a child drank a lot of milk, perhaps they are taller as an adult than if they only drank water. But, as we’ve discussed, our main hitch is that we can never simultaneously observe $A$ and $B$: once we choose whether to apply the treatment or not, we can only measure the corresponding treated or untreated condition.</p>

<p>This is where statistics can enter. Statistical algorithms can be applied to estimate <em>average</em> treatment effects across the general population. We can examine trends in small groups of individuals and extrapolate the insights to the broader population.</p>

<p>For such extrapolation, there are a variety of conventions for defining population level treatment effects. For example, we can define the <em>average treatment effect</em> to be the difference between the mean of $A$ and the mean of $B$. For those more comfortable seeing this written out as a formula, we can write</p>

\[\small{
\text{Average Treatment Effect} = \text{mean}(A)-\text{mean}(B)}\]

<p>In our milk example, this would be the difference in the mean of the population height if everyone drank milk versus no one drank milk.</p>

<p>Other population level quantities of interest arise when $A$ and $B$ represent binary outcomes. This could be, say, whether a person is over six feet tall as an adult. Or, for a more salient contemporary example, this could be whether a patient catches a disease or not in a vaccine study. In this case, $A$ is whether the patient catches the disease after receiving a vaccine and $B$ is whether the patient catches the disease after receiving a placebo.</p>

<p>The odds that an individual catches the disease is the number of people who catch the disease divided by the number who do not. The odds ratio for a treatment is the odds when every person receives the vaccine divided by the odds when no one receives the vaccine. We can write this out as a formula in terms of our quantities $A$ and $B$: when $A$ and $B$ can only take values 0 or 1, $\text{mean}(A)$ is the number of individuals for which $A=1$ divided by the total number of individuals. Hence, we can write the odds ratio as</p>

\[\small{
\text{Odds Ratio} = \frac{\text{mean}(A)}{1-\text{mean}(A)} \cdot \frac{ 1-\text{mean}(B)}{\text{mean}(B)}}\]

<p>This measures the decrease (or increase!) of the odds of a bad event happening when the treatment is applied. When the odds ratio is less than 1, the odds of a bad event are lower if the treatment is applied. When the odds ratio is greater than 1, the odds of a bad event are higher if the treatment is applied.</p>

<p>Similarly, the risk that an individual catches the disease is the ratio of the number of people who catch the disease to the total population size. Risk and odds are similar quantities, but some disciplines prefer one to the other by convention. The risk ratio is the fraction of bad events when a treatment is applied divided by the fraction of bad events when not applied. Again, in a formula,</p>

\[\small{
  \text{Risk Ratio} = \frac{\text{mean}(A)}{\text{mean}(B)}}\]

<p>The risk ratio measures the increase or decrease of relative risk of a bad event when the treatment is applied. In the recent context of vaccines, this ratio is popularly reported differently. The effectiveness of a treatment is one minus the risk ratio.</p>

<p><a href="https://www.argmin.net/2021/09/13/effect-size/">This is precisely the number used when people say a vaccine is 95% effective.</a> It is equivalent to saying that the proportion of those treated who fell ill was 20 times less than the proportion of those not treated who fell ill. Importantly, it does not mean that one has a 5% chance of contracting the disease.</p>

<p>Randomized algorithms give us cut and dry techniques to construct high accuracy estimators of population-level effects. Specifically, we can frame the estimation of the various measures of treatment effects as a particular statistical sampling strategy.</p>

<p>Think of the potential outcomes framework as doubling the size of the population. Each individual has an outcome under treatment and not under treatment. Hence, if we randomly select a sample and then randomly assign a treatment to each individual of the sample, we can compute the mean values of all subjects assigned to the treatment and all patients assigned to control. As long as $A$ and $B$ are bounded, such means of our samples are reasonable estimates of all of the treatment effects provided the number of samples is large enough.</p>

<p>The two stage process of building a sample and then randomizing assignment is equivalent to computing a random sample of the potential outcomes population. Randomized assignment allows us to probe population level effects without observing both outcomes of each individual. It’s an algorithmic strategy to extract information: Experiments are algorithms.</p>

<p>Just like in the <a href="https://www.argmin.net/2021/09/28/summarization/">last post</a>, this sampling method does not assume anything about the randomness of A and B. This randomized experiment design assumes that we can select samples at random from the population and assign treatments at random. But the individual treatment effects can be either deterministic or random. We do not need a probabilistic view of the universe in order to take advantage of the power of randomized experiments and prediction. Statistics still serve as a way to reason about the proportion of beneficial and adverse effects of interventions.</p>

<p>Moreover, elementary statistics allows us to quantify how confident we should be in the point estimate generated by our experiment with very little knowledge about the processes behind A and B. If the outcomes are binary, we can compute <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval">exact confidence intervals</a> for our outcomes, regardless of how they are distributed. For example, returning to my favorite example of the <a href="https://www.nejm.org/doi/full/10.1056/nejmoa2034577">Pfizer vaccine trial</a>, the confidence intervals used were the <a href="https://en.wikipedia.org/wiki/Binomial_proportion_confidence_interval#Clopper%E2%80%93Pearson_interval">Clopper-Pearson intervals</a>, which are directly derived from the binomial distribution. The effect size was so large that simple statistics revealed an impressively large effect.</p>

<p>There are certainly limitations with the randomized experiment paradigm. Reliability estimating treatment effects needs the variability of the outcomes to be low, average effects may hide important variation across the population, and temporal dynamics and feedback effects can impact causal conclusions. In future posts, I’ll dive into these critiques in more detail.</p>

<p>Despite the potential limitations, it’s remarkable how causal effects can be measured with some rudimentary sampling and statistics. The same ideas used to estimate a mean can immediately be applied to estimate average effects of interventions. In both cases, we needed only modest knowledge of the effects under study to design algorithmic measures and to establish confidence intervals on their outcomes. In the next post, we’ll explore whether a similar program can be applied to the art of prediction and machine learning. (Spoiler alert: it’s complicated!)</p>

<p>Finally, I have to discuss an elephant I’ve left in the room. Determining cause and effect becomes impossibly challenging once we <em>can’t</em> intervene. For example, suppose we are trying to understand the effectiveness of a vaccine outside a well controlled clinical trial. In the wild, we have no control over who takes the vaccine, but instead can sample from a general population where a vaccine is available and count the number of people who got sick. Determining cause and effect from such <em>observational data</em> requires more modeling, knowledge, and statistical machinery. And no matter how sophisticated the analysis, arguments about hidden confounding variables and other counterfactuals are inevitable. Whenever naysayers are yelling how correlation doesn’t imply causation, it’s always targeting an observational study rather than a randomized controlled trial. For a comprehensive introduction to the deep complexity of this topic, let me shamelessly plug the causality chapter in <a href="http://mlstory.org"><em>Patterns, Predictions, and Actions</em></a>, which features both my favorite introduction to observational causal inference penned by Moritz and a version of this blog on experiments.</p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2021/09/28/rct/"><span class="datestr">at September 28, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/09/27/postdoc-at-university-of-washington-and-georgia-tech-apply-by-december-10-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/09/27/postdoc-at-university-of-washington-and-georgia-tech-apply-by-december-10-2021/">postdoc at University of Washington and Georgia Tech (apply by December 10, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Yin Tat Lee and Santosh Vempala are looking for a postdoc interested in the broad topics of high-dimensional optimization and sampling. The position is for up to 3 years, and the candidate can split their time between University of Washington and Georgia Tech. No teaching requirement. Start date is flexible.</p>
<p>Website: <a href="https://yintat.com/">https://yintat.com/</a><br />
Email: yintat@uw.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/09/27/postdoc-at-university-of-washington-and-georgia-tech-apply-by-december-10-2021/"><span class="datestr">at September 27, 2021 07:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/140">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/140">TR21-140 |  Tight Computational Indistinguishability Bound of Product Distributions | 

	Nathan Geier</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Assume that $X_0,X_1$ (respectively $Y_0,Y_1$) are $d_X$ (respectively $d_Y$) indistinguishable for circuits of a given size. It is well known that the product distributions $X_0Y_0,\,X_1Y_1$ are $d_X+d_Y$ indistinguishable for slightly smaller circuits. However, in probability theory where unbounded adversaries are considered through statistical distance, it is folklore knowledge that in fact $X_0Y_0$ and $X_1Y_1$ are $d_X+d_Y-d_X\cdot d_Y$ indistinguishable, and also that this bound is tight.

We formulate and prove the computational analog of this tight bound. Our proof is entirely different from the proof in the statistical case, which is non-constructive. As a corollary, we show that if $X$ and $Y$ are $d$ indistinguishable, then $k$ independent copies of $X$ and $k$ independent copies of $Y$ are almost $1-(1-d)^k$ indistinguishable for smaller circuits, as against $d\cdot k$ using the looser bound. Our bounds are useful in settings where only weak (i.e. non-negligible) indistinguishability is guaranteed. We demonstrate this in the context of cryptography, showing that our bounds yield simple analysis for amplification of weak oblivious transfer protocols.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/140"><span class="datestr">at September 27, 2021 06:01 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/09/27/tenure-track-faculty-at-portland-state-university-apply-by-november-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/09/27/tenure-track-faculty-at-portland-state-university-apply-by-november-1-2021/">Tenure-track faculty  at Portland State University (apply by November 1, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at Portland State University invites applications for two Assistant Professor positions. Theory, including algorithms and quantum computing, is a focus area. One position is part of a cluster hire in Computational Science for a Sustainable Future, and theory candidates working on related topics, such as big data algorithms &amp; theoretical ML are welcome to apply.</p>
<p>Website: <a href="https://jobs.hrc.pdx.edu/postings/35879">https://jobs.hrc.pdx.edu/postings/35879</a><br />
Email: cssearch@pdx.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/09/27/tenure-track-faculty-at-portland-state-university-apply-by-november-1-2021/"><span class="datestr">at September 27, 2021 03:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4828719808701026500">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2021/09/my-academic-lineage-and-more.html">My academic lineage and more interesting facts that come out of it</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> I got my PhD from Harvard in 1985 with advisor Harry Lewis</p><p>Harry Lewis got his PhD from Harvard in 1974 with advisor Burton Dreben (Dreben was in the Philosophy department and did logic). Burton Dreben never got a PhD (more on that later). So I thought my lineage stopped there. A while back I was in an email conversation with Harry and for some odd reason Galileo came up.</p><p>He then emailed me the following:</p><p>----------------</p><p>Did you know you were descended from Galileo, via Newton? See below. The data is from the Math Genealogy project (see <a href="https://www.genealogy.math.ndsu.nodak.edu/">here</a>). As you know  Dreben had no PhD, but it would certainly be fair to call Quine his advisor anyway. And, in fact, the Math Geneology project lists Quine as Dreben's advisor. By starting with Dreben and clicking backwards I found the following:</p><p>In the list below everyone was advised (in some form) by the person below them.</p><p>William Gasarch, Harvard 1985</p><p>Harry Lewis, Harvard 1974</p><p>Burton Dreben, Harvard 1955</p><p>WVO Quine, Harvard 1932</p><p>AN Whitehead, Cambridge 1884</p><p>Edward John Routh, Cambridge 1857</p><p>William Hopkins, Cambridge 1830</p><p>Adam Sedgwick, Cambridge 1811</p><p>Thomas Jones, Cambridge 1782</p><p>Thomas Postlethwaite, Cambridge 1756</p><p>Stephen Whisson, Cambridge 1742</p><p>Walter Taylor, Cambridge 1723</p><p>Robert Smith, Cambridge 1715</p><p>Roger Coles, Cambridge 1706</p><p>Isaac Newton, Cambridge 1668</p><p>Isaac Barrow, Cambridge 1652</p><p>Vincenzo Viviani, Pisa 1642</p><p>Galileo Galilei, Pisa 1585</p><p>--------------------------------------</p><p>A few observations</p><p>1) Dreben was a philosophy professor at Harvard without a PhD. How? He was a Junior Fellow, which is for brilliant people, some of which were made professors without  the burden of going  through the PhD-getting ritual.  Andrew Gleason was a professor of Math at Harvard without a PhD-- also a junior fellow (he solved Hilbert's 5th problem, which surely helped). Tom Cheatham was a CS professor at Harvard who did not have a PhD but  was <i>not</i> a junior fellow. I do not know how he did that. Things are more formal now, and more people have PhD's, so I suspect it is much rarer to be a professor without a PhD.  Harvard still has the Junior Fellows Program, but even they have PhDs now. If someone solved P vs NP as an ugrad, I suspect they would be hired as a professor even though they do not have a PhD. That's one way for a theorist to get out of taking graduate systems courses. </p><p>2) Note that Galileo and Vincenzo were in Pisa but then a long line of people from Cambridge. In those days schools hired their own. Is this good or bad? They know what they are getting, but you could have an old-boys-network blocking fresh new talent, and you may get stuck in your ways. Nowadays, at least in America, it is uncommon to stay at the same school as you got your PhD.</p><p>3) The shift from Pisa to Cambridge might be part of a more general phenomena--- the intellectual center for science shifting from Italy to England. What caused this? Amir Alexander, in his book <i>Infinitesimals: How a dangerous mathematical idea shaped the modern world </i>(see my review <a href="https://www.cs.umd.edu/~gasarch/bookrev/FRED/inf.pdf">here</a> ) speculates that the Catholic Church's rejection of Infinitesimals was the cause.  I suspect that letting non-scientists interfere with science was the cause (a lesson for us all).</p><p>4) Lance did a blog on his lineage <a href="https://blog.computationalcomplexity.org/2005/06/eulerian-tour.html">here</a>. He has Gauss and Euler as ancestors. </p><p>5) To honor the myths about  my two most famous academic ancestors, Galileo and Newton,  I am going to travel to Italy and have Darling drop two apples of different weights off the leaning tower of Pisa and see if they hit my head at the same time.</p><div><br /></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2021/09/my-academic-lineage-and-more.html"><span class="datestr">at September 27, 2021 03:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19144">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/">A Possible Ramsey Insight into P Versus NP?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>In mathematics the art of proposing a question must be held of higher value than solving it—Georg Cantor</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/dz/" rel="attachment wp-att-19146"><img width="171" alt="" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/dz.png?resize=171%2C161&amp;ssl=1" class="alignright size-full wp-image-19146" height="161" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from his <a href="https://www.cs.utexas.edu/people/faculty-researchers/david-zuckerman">page</a></font></td>
</tr>
</tbody>
</table>
<p>
David Zuckerman has a beautiful result on the approximate hardness of the clique problem. His <a href="https://www.theoryofcomputing.org/articles/v003a006/v003a006.pdf">paper</a>, “Linear Degree Extractors and the Inapproximability of Max Clique and Chromatic Number,” has has received almost 1,000 citations since it was first published in 2007. Wow.</p>
<p>
Today we discuss a possible relevance of this result for P versus NP.</p>
<p>
Recall a clique is a subset of nodes of an undirected graph, such that every two nodes in the subset are connected by an edge. Wikipedia’s <a href="https://en.wikipedia.org/wiki/Clique_%28graph_theory%29">illustration</a> below does not have large cliques—only two cliques of <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{4}" class="latex" /> nodes shaded blue to go with a bunch of triangles shaded lighter.</p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/clique/" rel="attachment wp-att-19147"><img width="200" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/clique.png?resize=200%2C160&amp;ssl=1" class="aligncenter wp-image-19147" height="160" /></a></p>
<p></p><p><br />
Is there a relatively small change we could make to the graph to give it a much larger clique? At top right, we could add two edges to extend the blur <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{4}" class="latex" />-clique to a <img src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{5}" class="latex" />-clique—a pentagram inside a pentagon. At bottom left we could add <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{4}" class="latex" /> edges to make the four triangles blossom into a <img src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{6}" class="latex" />-clique.</p>
<p>
Computing the size of the largest clique in a graph—or just telling whether it has a clique of a given size <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k}" class="latex" />—is a famous NP-complete problem. Counting the number of cliques of the largest size is evidently a harder problem still. Yet you might think it easier to tell a graph with only small cliques apart from a graph that has large ones. This is where David’s result comes in.</p>
<p>
In passing, we note David’s place among the <a href="https://www.maa.org/sites/default/files/pdf/Putnam/Competition_Archive/List%20of%20Previous%20Putnam%20Winners.pdf">winners</a> of the 1986 William Lowell Putnam Mathematical Competition. Also on the list was Bjorn Poonen, whom we have also <a href="https://rjlipton.wpcomstaging.com/2010/08/07/hilberts-tenth-over-the-rationals/">highlighted</a> <a href="https://rjlipton.wpcomstaging.com/2014/11/19/two-versus-three/">multiple</a> times <a href="https://rjlipton.wpcomstaging.com/2020/01/25/the-halting-no-go-theorem/">including</a> <a href="https://rjlipton.wpcomstaging.com/2021/03/13/hilberts-tenth-again/">recently</a>. Here is the 1986 <a href="https://kskedlaya.org/putnam-archive/1986.pdf">exam</a>; Ken and I confess we did much worse when we took the Putnam in earlier years.</p>
<p>
</p><p></p><h2> David’s Result </h2><p></p>
<p></p><p>
Polynomial growth refers to a function that is bounded by <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ec%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n^c}" class="latex" /> for some constant <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />. <b>Quasi-polynomial</b> growth means one bounded by <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B%5Clog%5Ec+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n^{\log^c n}}" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{\widetilde{P}}}" class="latex" /> those sets accepted by a deterministic algorithm that runs in quasi-polynomial time and let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{N\widetilde{P}}}" class="latex" /> be those sets accepted by a nondeterministic algorithm that runs in quasi-polynomial time</p>
<p>
Let <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> be an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />-vertex graph. We have two properties of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> for a fixed <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon&gt;0}" class="latex" />:</p>
<blockquote><p><b> </b> <em> </em></p><em>
<ul>
<li>
<b>Clumpy</b>: <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> has a clique of size at least <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+n%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon n}" class="latex" />. <p></p>
</li><li>
<b>Limpid</b>: <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> has no clique of size <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B%5Cepsilon%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n^{\epsilon}}" class="latex" />.
</li></ul>
</em><p><em></em>
</p></blockquote>
<p></p><p>
The following is a main result in David’s paper:</p>
<blockquote><p><b>Theorem 1</b> <em> The problem of distinguishing clumpy graphs from limpid graphs is not in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\widetilde{P}}" class="latex" /> provided <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D+%5Cneq+N%5Cwidetilde%7BP%7D%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{\widetilde{P} \neq N\widetilde{P}}}" class="latex" />. </em>
</p></blockquote>
<p></p><p>
It is fundamentally a de-randomization result. Our idea is to scale it down in a way that may bring <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D+%5Cneq+N%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{\widetilde{P} \neq N\widetilde{P}}}" class="latex" /> into contact with mathematical theorems that govern effects of the scaling. The theorems may be adjacent to conjectures that can suggest new approaches. The idea may require bringing back randomization, however.</p>
<p>
</p><p></p><h2> The Question </h2><p></p>
<p></p><p>
Our quest to build on David’s theorem leads us to interpose a classic idea. In work with Paul Erdős, Tibor Radó wrote <img src="https://s0.wp.com/latex.php?latex=%7BG%5Crightarrow%28H%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G\rightarrow(H)}" class="latex" /> to mean that every <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" />-coloring of the edges of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> has a monochromatic subgraph <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{H}" class="latex" />. The classic two-color Ramsey theorem states that for all <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> there is a <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BG%5Crightarrow%28K_r%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G\rightarrow(K_r)}" class="latex" />. Erdős and George Szekeres further showed <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> can have fewer than <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2r%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2^{2r}}" class="latex" /> nodes. </p>
<blockquote><p><b>Definition 2</b> <em> Say an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />-node graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is <b><img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó</b> if every edge 2-coloring of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> leaves a clique of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog+n+-+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{1}{2}\log n - c}" class="latex" /> vertices. </em>
</p></blockquote>
<p></p><p>
In Radó’s notation, this is if <img src="https://s0.wp.com/latex.php?latex=%7BG+%5Crightarrow+%28K_%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G \rightarrow (K_{\frac{1}{2}\log_2 n - c})}" class="latex" />. The first point is that all clumpy graphs are <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó for large enough <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />. Taking <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cgeq+2%5Clog_2%28%5Cfrac%7B1%7D%7B%5Cepsilon%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c \geq 2\log_2(\frac{1}{\epsilon})}" class="latex" /> puts the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon n}" class="latex" />-sized clique above the Erdős-Szekeres bound for the Ramsey property to hold. </p>
<p>
Thus the key question becomes:</p>
<blockquote><p><b> </b> <em><a name="limpid"></a> Suppose that <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is a limpid graph. Can <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> also be <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó? </em>
</p></blockquote>
<p></p><p>
Suppose the answer is <b>no</b>. Then every limpid graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> has an edge 2-coloring that does not leave a clique of size <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+%5Cfrac%7B1%7D%7B2%7D%5Clog+n+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k = \frac{1}{2}\log n - c}" class="latex" />. We can verify this in quasi-polynomial time by trying all <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k}" class="latex" />-subsets of the vertices. </p>
<p>
This sets up a situation where both “limpid” and “clumpy” have an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{N\widetilde{P}}}" class="latex" /> witness. More to the point, we obtain the modified problem of distinguishing “clumpy” from “not <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó” (for appropriately chosen <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />). This would then likewise be <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{N\widetilde{P}}}" class="latex" />-hard by David’s result. Then, we would have an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{N\widetilde{P}}}" class="latex" />-hard <b>promise problem</b> with promise set <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bclumpy+%5Ccup%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{clumpy \cup}}" class="latex" /> not-<i>c</i>-Radó belonging to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{N\widetilde{P}}}" class="latex" />. This would be a plausible unlikelihood along the lines of what the <a href="https://link.springer.com/article/10.1007/s00037-015-0107-6">ESY</a> <a href="https://www.sciencedirect.com/science/article/pii/S001999588480056X">conjecture</a>, which we covered <a href="https://rjlipton.wpcomstaging.com/2012/07/14/it-dont-come-easy/">here</a>, rules out. 	 We can obtain a clearer unlikelihood if we relax the new definition.</p>
<blockquote><p><b>Definition 3</b> <em><a name="almost"></a> An <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />-node graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is <b>almost <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó</b> if all but a negligible fraction of edge 2-colorings leave a monochrome clique on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{1}{2}\log_2 n - c}" class="latex" /> vertices. </em>
</p></blockquote>
<p></p><p>
Here “negligible” means a function asymptotically less than <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1/q(n)}" class="latex" /> for any quasi-polynomial function <img src="https://s0.wp.com/latex.php?latex=%7Bq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{q(n)}" class="latex" />. With some informality, we can prove:</p>
<blockquote><p><b>Proposition 4</b> <em> Suppose no limpid graphs are almost <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó. Then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{N\widetilde{P}}}" class="latex" /> is contained in randomized <img src="https://s0.wp.com/latex.php?latex=%7B%5Cwidetilde%7BP%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\widetilde{P}}" class="latex" />. </em>
</p></blockquote>
<p></p><p>
<em>Proof:</em>  Formally, the negation is worded so that there is a quasi-polynomial function <img src="https://s0.wp.com/latex.php?latex=%7Bq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{q(n)}" class="latex" /> such that for every limpid graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" />—with the concrete value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon}" class="latex" /> and corresponding <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />—there are a <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Bq%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{1}{q(n)}}" class="latex" /> fraction of 2-edge-colorings of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> that do not have a monochromatic clique of size <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{1}{2}\log_2 n - c}" class="latex" />. Now define an algorithm <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> that given any graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> guesses order-<img src="https://s0.wp.com/latex.php?latex=%7Bq%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{q(n)}" class="latex" /> such colorings at random.</p>
<ul>
<li>
If <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> finds a coloring that does not have a monochromatic clique of size <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%5Clog_2+n+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{1}{2}\log_2 n - c}" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> rejects. <p></p>
</li><li>
Else, <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> accepts.
</li></ul>
<p>
Whenever <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is clumpy, <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> will always accept. If <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is limpid, then with high probability, <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> will find a coloring witnessing that <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is not clumpy, and <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> will reject <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" />. Thus, <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> distinguishes limpid from clumpy in randomized quasi-polynomial time. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\Box" class="latex" /></p>
<p>
</p><p></p><h2> The Quest For Limpid Radó Graphs </h2><p></p>
<p></p><p>
If, like most, you believe <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BP%7D+%5Cneq+N%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{\widetilde{P} \neq N\widetilde{P}}}" class="latex" />, or further in the “ESY”-type strengthening of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5Cwidetilde%7BNP%7D+%5Cneq+%5Ctext%7Bco-%7DN%5Cwidetilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{\widetilde{NP} \neq \text{co-}N\widetilde{P}}}" class="latex" />, then the answer must be that limpid (almost-)<img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó graphs exist. The question of <em>finding</em> them, however, has a long trail that leads back into complexity theory.</p>
<p>
To begin, let’s decouple the clique size from the number <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> of nodes by considering graphs with a clique of size <img src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{6}" class="latex" /> to be “lumpy,” and use the original form of the Radó property: every 2-edge coloring has a monochrome triangle. It is surprisingly hard to find a <img src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K_6}" class="latex" />-free graph with the property. Brute-force attempts for <img src="https://s0.wp.com/latex.php?latex=%7B7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{7}" class="latex" />-node and <img src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{8}" class="latex" />-node graphs that are maximal for having no <img src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K_6}" class="latex" /> fail:</p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/?attachment_id=19149" rel="attachment wp-att-19149"><img width="550" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/NonRadoGraphs.png?resize=550%2C146&amp;ssl=1" class="aligncenter wp-image-19149" height="146" /></a></p>
<p></p><p><br />
The smallest <img src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K_6}" class="latex" />-free graph with the Radó triangle property that we know how to build has <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D14%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n=14}" class="latex" /> nodes and comes from a proof that the Radó triangle property is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" />-complete. The proof is in a 1985 <a href="https://bd.booksc.org/book/5907065/04eeae">paper</a> by Moon-Jung Chung, W. Michael Evangelist, and Ivan Hal Sudborough. The graph at left, which looks like a bat, is such that any 2-edge coloring without a monochrome triangle must give the two edges marked <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" /> the same color—whichever color is used for two edges of the middle triangle. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/ces1985graphs/" rel="attachment wp-att-19151"><img width="550" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/09/CES1985graphs.jpg?resize=550%2C236&amp;ssl=1" class="aligncenter wp-image-19151" height="236" /></a></p>
<p>
Joining a bat and an upside-down bat creates the graph at right, in which the edges marked <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\bar{x}}" class="latex" /> must have opposite colors. This creates a truth-assignment gadget for each pair of literals <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x_i}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\bar{x}_i}" class="latex" /> in a 3CNF formula <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\phi}" class="latex" /> given as instance of the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" />-complete Not-All-Equal 3SAT <a href="https://en.wikipedia.org/wiki/Not-all-equal_3-satisfiability">problem</a>. Using one triangle per clause of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\phi}" class="latex" />, connecting more bats between <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x_i}" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\bar{x}_j}" class="latex" /> appearing in the clause to the corresponding edges in the truth gadgets creates a <img src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K_6}" class="latex" />-free graph <img src="https://s0.wp.com/latex.php?latex=%7BG_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G_\phi}" class="latex" /> that has the Radó property if and only if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\phi}" class="latex" /> has an assignment making 1 or 2 literals true in each clause. </p>
<p>
Then every negative instance <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\phi}" class="latex" /> induces a <img src="https://s0.wp.com/latex.php?latex=%7BK_6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K_6}" class="latex" />-free Radó graph <img src="https://s0.wp.com/latex.php?latex=%7BG_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G_\phi}" class="latex" />. We can get one more simply, however, by adding a third “bat” to the graph at right above that connects <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbar%7Bx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\bar{x}}" class="latex" />. The resulting <img src="https://s0.wp.com/latex.php?latex=%7B14%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{14}" class="latex" />-node graph has no 2-edge coloring without making a monochrome triangle.</p>
<p>
To be truly “limpid,” however, the graph should exclude smaller cliques. The following problem of Erdős and Radó was open for some time:</p>
<blockquote><p><b> </b> <em> Does there exist a <img src="https://s0.wp.com/latex.php?latex=%7BK_4%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K_4}" class="latex" />-free graph with the Radó triangle property? </em>
</p></blockquote>
<p></p><p>
This was <a href="https://www.jstor.org/stable/2099355">solved</a> in 1970 by Jon Folkman and then improved in 1987 by a probabilistic argument of Joel Spencer, in a <a href="https://core.ac.uk/download/pdf/82159088.pdf">paper</a> titled, “Three Hundred Million Points Suffice.” That’s right: for the minimum Radó criterion he showed there is a limpid graph with <img src="https://s0.wp.com/latex.php?latex=%7BN+%3C+%5Cmathbf%7B300%2C000%2C000%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N &lt; \mathbf{300,000,000}}" class="latex" /> nodes. This 2007 <a href="https://www.cs.rit.edu/~spr/PUBL/paper53.pdf">paper</a> by the Ramsey-theory experts Stanisław Radziszowski and Xu Xiaodong proves that the minimum possible <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N}" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%7B19%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{19}" class="latex" /> and gives evidence that <img src="https://s0.wp.com/latex.php?latex=%7BN+%5Cleq+127%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N \leq 127}" class="latex" /> is plausible. let <img src="https://s0.wp.com/latex.php?latex=%7BN_%7B3%2C3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N_{3,3}}" class="latex" /> stand for the least possible such <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N}" class="latex" />.</p>
<p>
However one such graph exists, it must give rise to a “bat”-type construction and forthwith a reduction showing the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" />-completeness of the <img src="https://s0.wp.com/latex.php?latex=%7BK_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{K_4}" class="latex" />-free Radó property. Thus the Ramsey-type existence question is entangled with complexity theory. How this relationship <em>scales</em> up for <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó and clumpy versus limpid graphs is the point we are driving at.</p>
<p>
</p><p></p><h2> Ramsey Scaling And Complexity </h2><p></p>
<p></p><p>
There are two main levers by which we are scaling:</p>
<ul>
<li>
Up from the constant <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3}" class="latex" /> of the Radó triangle property to <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho+%3D+%5Cfrac%7B1%7D%7B2%7D%5Clog_2%28n%29+-+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\rho = \frac{1}{2}\log_2(n) - c}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó. <p></p>
</li><li>
Up to <img src="https://s0.wp.com/latex.php?latex=%7Bk%3Dn%5E%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k=n^\epsilon}" class="latex" /> as the allowed clique size in a <em>limpid</em> graph.
</li></ul>
<p>
The latter corresponds to the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon n}" class="latex" /> size for <em>clumpy</em> that we are distinguishing, but there is some freedom in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon}" class="latex" />. If we imagine <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\rho}" class="latex" /> as fixed—temporarily ignoring the dependence on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />—we can ask, what is the minimum size <img src="https://s0.wp.com/latex.php?latex=%7BN+%3D+N_%7B%5Crho%2Ck%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N = N_{\rho,k}}" class="latex" /> of a <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k}" class="latex" />-limpid graph that is <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />-Radó? </p>
<p>
To avoid a complexity collapse, we must bet on at worst a single-exponential dependence on <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\rho}" class="latex" />, polynomial in <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k}" class="latex" />. Can we possibly show this directly? Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\rho = 3}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k = 3}" class="latex" /> already raised the specter of <img src="https://s0.wp.com/latex.php?latex=%7BN_%7B3%2C3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N_{3,3}}" class="latex" /> in the hundred millions. Not only do we not see a way to scale up Spencer’s proof, he remarked in the intro that his proof is “extremely case specific” and does not scale even to 3-edge colorings. The “almost” feature of Definition <a href="https://rjlipton.wpcomstaging.com/feed/#almost">3</a> adds a further complication.</p>
<p>
It may be that the guiderails for ascending to higher <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{k}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\rho}" class="latex" /> (scaling with the number <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> of nodes) are already present among the details of the graph constructions in David’s proof and the proofs of the theorems his paper builds on. We have not had time to delve. There must be <em>some</em> connection; the question is whether complexity considerations take the lead or follow only in train of the sides that can be mathematically disproved.  Other connections of Ramsey theory are in this nice 2004 <a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/DS13/pdf">survey</a> by Vera Rosta.</p>
<p>
Here is one more indication of why we think the interaction between complexity and Ramsey theory can be nontrivial. Putting <img src="https://s0.wp.com/latex.php?latex=%7BR+%3D+2%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{R = 2^r}" class="latex" />, the upper bound noted above for the diagonal-<img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> Ramsey number has rough order <img src="https://s0.wp.com/latex.php?latex=%7BR%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{R^2}" class="latex" />. The best known lower bound has rough order <img src="https://s0.wp.com/latex.php?latex=%7BR%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{R^{1/2}}" class="latex" />. Can we show an impact of the growth of <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{R}" class="latex" /> on complexity theory, in advance of resolving this gap which has been open for over fifty years?</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
The key issue is, what about the above question? Assuming the usual belief that quasi-polynomial time and nondeterministic quasi-polynomial time are distinct we must be able to show a fact about <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" />-colorings of clumpy and limpid graphs. If this is hard to prove, then we have an interesting impasse. Even worse, if this is false, then our beliefs collapse. </p>
<p></p><p><br />
The feature that surprises us about the 1986 Putnam <a href="https://kskedlaya.org/putnam-archive/1986.pdf">exam</a> is that it does <em>not</em> have a question that involves the number <b>1,986</b>. Ken and I both remember such features. Here is a problem they could have used; we will give the answer later:</p>
<blockquote><p><b> </b> <em> Alan and Barbara play a game in which they take turns filling entries of an initially empty 1986 x 1986 array. Alan plays first. At each turn, a player chooses a real number and places it in a vacant entry. The game ends when all the entries are filled. Alan wins if the determinant of the resulting matrix is nonzero; Barbara wins if it is zero. Which player has a winning strategy? </em>
</p></blockquote>
<p>The answer is at the end of the next <a href="https://rjlipton.wpcomstaging.com/2021/09/30/baby-steps/">post</a>.</p>
<p></p><p><br />
[removed reference to Putnam ranking, “batch”-&gt;”bats” in the proof from 1985, added answer link for puzzle at end]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/09/26/a-possible-ramsey-insight-into-p-versus-np/"><span class="datestr">at September 26, 2021 08:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5854">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5854">“Is China Ahead in the Quantum Computing Race?”</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Please enjoy an <a href="https://www.youtube.com/watch?v=KzFEeQ49HHI">hourlong panel discussion of that question on YouTube</a>, featuring yours truly, my former MIT colleague Will Oliver, and political scientist and China scholar Elsa Kania.  If you’re worried that the title sounds too sensationalistic, I hope my fellow panelists and I will pleasantly surprise you with our relative sobriety!  Thanks so much to <a href="https://qcware.com/">QC Ware</a> for arranging the panel (full disclosure: I’m QC Ware’s scientific adviser).</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5854"><span class="datestr">at September 26, 2021 04:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/09/25/multilayer-tiles">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/09/25/multilayer-tiles.html">Multilayer tiles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>You’re probably familiar with the fact that you can draw a convex octagon with corners in an integer grid, fitting into a \(3\times 3\) square. It’s not regular, because its side lengths alternate between \(1\) and \(\sqrt 2\), but it has the same angles as a regular octagon and looks close enough to it for some purposes.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/7way-octagon.svg" alt="3x3 integer octagon and its 7-ply tiling of the plane" /></p>

<p>It also has another interesting property: if you place copies of it at every point of the integer grid, then each edge of each copy is also the edge of another copy. Therefore, if you let \(p\) be any point that avoids the edges of the octagons, count the number of octagons that cover any point of the plane, and then slide \(p\) around to another edge-avoiding point, the number of covering octagons always stays unchanged. Whenever \(p\) slides off from one octagon, it slides onto another one. Because the area of the integer octagon is seven units, and you’re placing one octagon for every unit square of the grid, the average covering depth is seven. And since the covering depth stays the same everywhere, it’s seven everywhere. You can think of this collection of octagons as forming a <span style="white-space: nowrap;">\(7\)-ply</span> tiling of the plane, despite the fact that convex octagons cannot tile the plane in the usual \(1\)-ply sense of tiling.</p>

<p>More generally, define a \(k\)-ply tiling to be a covering of the plane by congruent copies of some prototile (allowing rotations, even though these are not necessary for the octagon) such that, except at a subset of the plane of measure zero (the boundaries of the prototiles), every point is covered by exactly \(k\) copies, and define the “ply” of a prototile to be the minimum \(k\) such that it has a \(k\)-ply tiling. The integer octagon has <span style="white-space: nowrap;">ply \(7\):</span> once one octagon is placed anywhere in the plane, the rest of the tiling is forced to follow in the same way around it, in order to avoid creating seams where an octagon edge is not matched by another octagon and the ply changes. The same construction, using centrally symmetric octagons with integer vertices and longer sides, produces for any \(k\ge9\) a convex tile of <span style="white-space: nowrap;">ply \(k\).</span></p>

<p>This is the subject of my new short paper (or maybe extended abstract) “Multifold tiles of polyominoes and convex lattice polygons”, with many coauthors from the 2017 Bellairs Winter Workshop on Computational Geometry: Kota Chida, Erik Demaine, Martin Demaine, Adam Hesterberg, Takashi Horiyama, John Iacono, Hiro Ito, Stefan Langerman, Ryuhei Uehara, and Yushi Uno. You can find it in the <a href="http://www.math.science.cmu.ac.th/tjcdcggg/Book-abstract.pdf">book of abstracts of the 23rd Thailand–Japan Conference on Discrete and Computational Geometry, Graphs, and Games (TJCDCG<sup>3</sup> 2020+1)</a>, which was organized online by Chiang Mai University earlier this month.</p>

<p>As well as the family of octagon \(k\)-ply tilers described above, we found that cutting the bottom row of squares off a \(3\times 3\) octagon produces a \(5\)-ply hexagon tiler, this time requiring \(180^\circ\)-degree rotations for its tiling, and that stretching this hexagon can produce an <span style="white-space: nowrap;">\(8\)-ply</span> convex tiler. We also found polyomino <span style="white-space: nowrap;">\(k\)-ply</span> tilers for <span style="white-space: nowrap;">all \(k\ge 2\),</span> and three heptominoes (the smallest possible polyominoes) that can each form <span style="white-space: nowrap;">\(k\)-ply</span> tilings for all \(k\ge 2\) but not for <span style="white-space: nowrap;">\(k=1\).</span> I imagine the details will become available in a more complete paper at some point but for now the abstract just announces these results and gives pictures of these heptominoes. We still don’t know whether there can exist convex polygons whose ply is one of <span style="white-space: nowrap;">\(\{2,3,4,6\}\).</span></p>

<p>The TJCDCG<sup>3</sup> abstract book has many other intriguing results in discrete geometry, graph theory, and combinatorial game theory, so do check it out if you’re interested. Tiling-related highlights include a variation on Wang tiling adding connectivity constraints and inspired by a dungeon-making mini-game in <em>The Legend of Zelda: Link’s Awakening</em> (“Tiling the Plane Connectively with Wang Tiles”, Chao Yang), signal processing using high-dimensional substitution tilings (“Generating Frames via Discretized Substitution Tilings”, Luis S. Silvestre Jr. and Job A. Nable), a partial classification of edge-to-edge monohedral tilings of the sphere (“Tiling of the Sphere by Congruent Polygons”, Yohji Akama, Hoi Ping Luk, Erxiao Wang, and Min Yan), and tilings that can be used to make arrays of joined-up origami cranes (“Renzuru Tilings with Asymmetric Quadrilaterals”, Takashi Yoshino).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106995035140693185">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/09/25/multilayer-tiles.html"><span class="datestr">at September 25, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5850">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5850">Was Scientific American Sokal’d?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Here’s yesterday’s clickbait offering from <em>Scientific American</em>, the once-legendary home of Martin Gardner’s Mathematical Games column:</p>



<p><a href="https://www.scientificamerican.com/article/why-the-term-jedi-is-problematic-for-describing-programs-that-promote-justice-equity-diversity-and-inclusion/">Why the Term ‘JEDI’ Is Problematic for Describing Programs That Promote Justice, Equity, Diversity and Inclusion</a></p>



<p>The sad thing is, I see few signs that this essay was meant as a Sokal-style parody, although in many ways it’s written as one.  The essay actually develops a 100% cogent, reasoned argument: namely, that the ideology of the <em>Star Wars</em> films doesn’t easily fit with the new ideology of militant egalitarianism at the expense of all other human values, including irony, humor, joy, and the nurturing of unusual talents. The authors are merely oblivious to the conclusion that most people would draw from their argument: namely, so much the worse for the militant egalitarianism then!</p>



<p>I predict that this proposal—to send the acronym “JEDI” the way of “mankind,” “blacklist,” and, err, “quantum supremacy”—will meet with opposition even from the wokeists themselves, a huge fraction of whom (in my experience) have soft spots for the <em>Star Wars</em> franchise.  Recall for example that in 2014, Laurie Penny used <em>Star Wars</em> metaphors in her <a href="https://www.newstatesman.com/uncategorized/2014/12/on-nerd-entitlement-rebel-alliance-empire">interesting response</a> to my comment-171, telling male nerds like me that we need to learn to accept that “[we’re] not the Rebel Alliance, [we’re] actually part of the Empire and have been all along.”  Admittedly, I’ve never <em>felt like</em> part of an Empire, although I’ll confess to some labored breathing lately when ascending flights of stairs.</p>



<p>As for me, I spent much of my life opposed in principle to <em>Star Wars</em>—I hated how the most successful “science fiction” franchise of all time became that way <em>precisely</em> by ditching any pretense of science and fully embracing mystical woo—but sure, when the chips are down, I’m crazy and radical enough to take the side of Luke Skywalker, even if a team of woke theorists is earnestly, unironically explaining to me that lightsabers are phallocentric and that Vader ranks higher on the intersectional oppression axis because of his breathing problem.</p>



<p>Meantime, of course, the US continues to <a href="https://l.facebook.com/l.php?u=https%3A%2F%2Fwww.washingtonpost.com%2Fopinions%2F2021%2F09%2F23%2Frobert-kagan-constitutional-crisis">careen toward its worst Constitutional crisis since the Civil War</a>, as Trump prepares to run again in 2024, and as this time around, the Republicans are systematically purging state governments of their last Brad Raffenspergers, of anyone who might stand in the way of them simply setting aside the vote totals and declaring Trump the winner regardless of the actual outcome.  It’s good to know that my fellow progressives have their eyes on the ball—so that when that happens, at least universities will no longer be using offensive acronyms like “JEDI”!</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5850"><span class="datestr">at September 24, 2021 07:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/09/24/which-integer-sequences">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/09/24/which-integer-sequences.html">Which integer sequences form denominators of Egyptian fractions?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have a new paper out: “<a href="https://cs.uwaterloo.ca/journals/JIS/VOL24/Eppstein/eppstein2.html">Egyptian Fractions with Denominators from Sequences Closed Under Doubling</a>”, in the <em>Journal of Integer Sequences</em>. (There should also be an arXiv version soon but despite my long association with arXiv they made me get an endorser before I could upload to the number theory category, slowing down my submission there.)</p>

<p>Anyway, it’s basically a journal version of an old blog post here, “<a href="https://11011110.github.io/blog/2016/11/20/egyptian-fractions-with.html">Egyptian fractions with practical denominators</a>”. That post concerned the <a href="https://en.wikipedia.org/wiki/Practical_number">practical numbers</a>, positive integers \(n\) such that all other positive integers up to \(n\) can be represented as sums of distinct divisors of \(n\). This definition gives the practical numbers a natural connection to <a href="https://en.wikipedia.org/wiki/Egyptian_fraction">Egyptian fractions</a>, representations of rational numbers as sums of distinct unit fractions: if you represent a number \(k&lt;n\) by a sum of distinct divisors of \(n\), and then divide everything by \(n\), you get an Egyptian fraction for \(k/n\). Zhi-Wei Sun asked whether the practical numbers and Egyptian fractions were connected in a different way, with every positive integer having an Egyptian fraction representation in which all denominators are practical, and my blog post provides a positive answer to Sun’s question.</p>

<p>The new paper simplifies the presentation of the solution, compared to the blog post, by providing direct formulas for the representation rather than an iterative computational method for finding it. But beyond that, it also shows that the same method (based on dividing by a large power of two and dealing separately with the quotient and remainder) works for many other integer sequences beyond the practical numbers. All it needs from an integer sequence is two simple properties:</p>

<ul>
  <li>
    <p>The sequence should include a multiple of every integer. In order to represent \(k/p\) as an Egyptian fraction, when \(p\) is prime, the denominators must include at least one multiple of \(p\), so the requirement of including multiples is pretty natural in this context.</p>
  </li>
  <li>
    <p>For every number \(n\) that belongs to the sequence, \(2n\) should also belong to the sequence. This is the “closed under doubling” of the new article’s title, and is closely connected to the method used by the article involving division by powers of two.</p>
  </li>
</ul>

<p>Whenever a sequence \(S\) of positive integers has both properties, we can find Egyptian fractions for all positive rationals up to \(\sum_{x\in S}1/x\), the natural limiting value for such representations. When \(\sum_{x\in S}1/x\) diverges, we get all positive rationals. As well as the practical numbers, this works for some other nice sequences including the <a href="https://en.wikipedia.org/wiki/Odious_number">odious</a> and <a href="https://en.wikipedia.org/wiki/Evil_number">evil</a> numbers, the <a href="https://oeis.org/A001013">orders of isomorphism groups of trees</a>, and the <a href="https://oeis.org/A003714">fibbinary numbers</a>, numbers whose binary representation avoids consecutive ones. Because they’re based on binary representations, the doubling property of odious, evil, and fibbinary numbers follows from their definitions; the existence of multiples of other integers in these sequences is less obvious but was more or less already known. Isomorphism groups of trees have orders that are the products of factorials, from which (because 2 is a factorial and \(n!\) is a multiple of \(n\)) both properties follow immediately.</p>

<p>Although these two properties are sufficient for a sequence to form Egyptian fractions for rationals up to its natural limit, they are not necessary. Ron Graham’s PhD dissertation was on the same topic, and showed that the sequence of squares greater than one has the same property. (The sequence of all squares, including one, is a little more complicated: its sums of distinct reciprocals can represent all rationals in the intervals \([0,\pi^2/6-1)\) and \([1,\pi^2/6)\) but can’t cover the gap between these two intervals.) Characterizing which sequences do or do not form representations of this type more generally seems like an interesting question, but one that I don’t have much idea how to attack at this point.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106989108978976649">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/09/24/which-integer-sequences.html"><span class="datestr">at September 24, 2021 03:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/139">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/139">TR21-139 |  Punctured Large Distance Codes, and Many Reed-Solomon Codes, Achieve List-Decoding Capacity | 

	Venkatesan Guruswami, 

	Jonathan Mosheiff</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove the existence of Reed-Solomon codes of any desired rate $R \in (0,1)$ that are combinatorially list-decodable up to a radius approaching  $1-R$, which is the information-theoretic limit. This is established by starting with the full-length $[q,k]_q$ Reed-Solomon code over a field $\mathbb{F}_q$ that is polynomially larger than the desired dimension $k$, and "puncturing" it by including $k/R$ randomly chosen codeword positions. 
		
Our puncturing result is more general and applies to any code with large minimum distance: we show that a random rate $R$ puncturing of an $\mathbb{F}_q$-linear "mother" code whose relative distance is close enough to $1-1/q$ is list-decodable up to a radius approaching the $q$-ary list-decoding capacity bound $h_q^{-1}(1-R)$. In fact, for large $q$, or under a stronger assumption of low-bias of the mother-code, we prove that the threshold rate for list-decodability with a specific list-size (and more generally, any "local" property) of the random puncturing approaches that of fully random linear codes. Thus, all current (and future) list-decodability bounds shown for random linear codes extend automatically to random puncturings of any low-bias (or large alphabet) code. This can be viewed as a general derandomization result applicable to random linear codes. 
		
To obtain our conclusion about Reed-Solomon codes, we establish some hashing properties of field trace maps that allow us to reduce the list-decodability of RS codes to its associated trace (dual-BCH) code, and then apply our puncturing theorem to the latter. Our approach implies, essentially for free, optimal rate list-recoverability of punctured RS codes as well.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/139"><span class="datestr">at September 24, 2021 02:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=570">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2021/09/23/tcs-talk-wednesday-september-29-audra-mcmillan-apple/">TCS+ talk: Wednesday, September 29 — Audra McMillan, Apple</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk (and first of the semester!) will take place this coming Wednesday, September 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC: check your time zone!). We’re excited to have <a href="https://audramarymcmillan.wixsite.com/mysite"><strong>Audra McMillan</strong> </a>from Apple speak about “<em>Hiding among the clones: a simple and nearly optimal analysis of privacy amplification by shuffling</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk)</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Differential privacy (DP) is a model of privacy-preserving machine learning that has garnered significant interest in recent years due to its rigorous privacy guarantees. An algorithm differentially private if the output is stable under small changes in the input database. While DP has been adopted in a variety of applications, most applications of DP in industry actually satisfy a stronger notion called local differential privacy. In local differential privacy data subjects perturb their data before it reaches the data analyst. While this requires less trust, it comes a substantial cost to accuracy. Recent work of Erlingsson, Feldman, Mironov, Raghunathan, Talwar, and Thakurta [EFMRTT19] demonstrated that random shuffling amplifies differential privacy guarantees of locally randomized data. Such amplification implies substantially stronger privacy guarantees for systems in which data is contributed anonymously [BEMMRLRKTS17] and has led to significant interest in the shuffle model of privacy [CSUZZ19, EFMRTT19]. In this talk, we will discuss a new result on privacy amplification by shuffling, which achieves the asymptotically optimal dependence in the local privacy parameter. Our result is based on a new proof strategy which is simpler than previous approaches, and extends to a lightly weaker notion known as approximate differential privacy with nearly the same guarantees.</p>
<p>Based on joint work with Vitaly Feldman and Kunal Talwar (<a href="https://arxiv.org/abs/2012.12803">https://arxiv.org/abs/2012.12803</a>).</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2021/09/23/tcs-talk-wednesday-september-29-audra-mcmillan-apple/"><span class="datestr">at September 23, 2021 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
