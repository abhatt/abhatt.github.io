<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://www.blogger.com/feeds/25562705/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://benjamin-recht.github.io/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="https://cstheory.stackexchange.com/feeds/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/7233553492253101490/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://www.blogger.com/feeds/21224994/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="http://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/8890204/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A> &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at January 09, 2019 11:26 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-4590649641895956020">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2019/01/analco-sosa-soda-post.html">ANALCO, SOSA, SODA post</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I spent the last few days at SODA-ANALCO-ALENEX-SOSA in San Diego.  (Nice location choice, I'd say!)  Here's some news.<br /><br />This will be the last ANALCO (Analytic Algorithms and Combinatorics).  Apparently submissions have been decreasing, so they've decided it will halt and the work on these topics will go into SODA and other conferences.  I'm not sure how to think of it -- I think we as a community have far too many conferences/workshops generally, but I think the SODA model of having ANALCO and ALENEX (and now SOSA, I imagine) folded in cleanly into the main conference is an excellent model.  I also like the ANALCO topics.  But I can understand the time may have come to do something else.  Thanks to everyone who worked to organize ANALCO and keep it going these many years.<br /><br />It looks like SOSA (Symposium on Simplicity in Algorithms) will be taking its place in the SODA lineup.  I co-chaired the symposium with Jeremy Fineman this year, the second for the symposium.  I was surprised by the high quality of the submissions, and was then further surprised by the strong turnout at SODA.  The room was quite full for the Tuesday afternoon sessions, and there were easily 75+ people at several of the talks.  I do think there's a need for SOSA -- no other workshop/conference hits the theme of simplicity in our area, and it's a really nice fit with the rest of SODA.  I'm hoping it will last, and in particular that they'll continue to have a good number of high quality submissions, but that depends on all of you.  Ideally, there will be a positive feedback loop here -- now that there's a good home for this type of work (besides notes on the arxiv), people will be more inclined to write up and submit things to SOSA.  For Tuesday's talks, I'll call out Josh Alman's great presentation on "An Illuminating Algorithm for the Light Bulb Problem" as my favorite for the day.<br /><br />With ANALCO exiting, though, I think there's more room for additional satellite events at SODA, so hopefully some people will get creative.<br /><br />If I had thought about it I should have live-blogged the business meeting.  I'd say as highlights, first, Sandy Irani presented the report of the ad hoc committee to combat harassment and discrimination in the theory of computing community.   (See <a href="https://www.ics.uci.edu/~irani/safetoc.html">here</a> for the report.)  There was an overwhelming vote to adopt their recommendations going forward.  It's good to see progress in addressing these community concerns.  Second, Shuchi Chawla will be the next PC chair, and she brought forward a plan to have SODA PC members be allowed to submit papers (with a higher bar) that was voted on favorably as well.<br /><br />I suppose the last note is that Jon Kleinberg's invited talk was the conference highlight you expect a Jon Kleinberg talk to be, with interesting results and models related to fairness and implicit bias.<br /><br />Thanks to SIAM and all the organizers for their hard work.</div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2019/01/analco-sosa-soda-post.html"><span class="datestr">at January 09, 2019 10:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42183">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42183/new-subset-sum-approach-tc-results">new subset sum approach TC/results</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have been working on a new approach for a subset sum exact solver, and the current state provides an algorithm operating on <span class="math-container">$O{n/2 \choose n/4}$</span>, demonstrating as well the hardest target value is not <span class="math-container">$\approx \frac{sum(S)}{2}$</span> but <span class="math-container">$\approx\frac{sum(S)}{4}$</span> for dense instances (<span class="math-container">$d \approx 1$</span>) in all cases.</p>

<p>I asked several people about their opinion and I got mixed feedback, some people though it was worth it to keep pushing the approach before publishing (to try to obtain an improved result, given this is likely possible, then publish), while other people encouraged me to publish right away given the TC improvement over the <span class="math-container">$O(2^{\frac{n}{2}})$</span> approach and the new characterization for the hardest target values not demonstrated before in the available literature, then continue working looking to improve these results.</p>

<p>What are your suggestions/opinions? </p></div>







<p class="date">
by John Seppard <a href="https://cstheory.stackexchange.com/questions/42183/new-subset-sum-approach-tc-results"><span class="datestr">at January 09, 2019 09:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/">Mixed-Integer Nonlinear Optimization meets Data Science</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
June 25, 2018 – June 28, 2019 Ischia, Italy http://www.iasi.cnr.it/minoa/big-data-school/ CNR-IASI, as part of the MINOA project, announces the school for PhD students and post-docs on the theme Mixed Integer Non linear Optimization meets Data Science. The school will cover the following topics: Deep learning for AI Clustering for Big Data Machine Learning for Combinatorial … <a href="https://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/" class="more-link">Continue reading <span class="screen-reader-text">Mixed-Integer Nonlinear Optimization meets Data Science</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/01/09/mixed-integer-nonlinear-optimization-meets-data-science/"><span class="datestr">at January 09, 2019 08:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5374">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2019/01/09/the-baruch-distinguished-mathematics-lecture-series/">The Baruch Distinguished Mathematics Lecture Series</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I am happy to announce the beginning of the Baruch Distinguished Mathematics Lecture Series. In this series we will bring established mathematicians to give talks to a general mathematical audience. Our first Distinguished Lecture, by Bjorn Poonen, will be “Undecidability in Number Theory”. Click here for the full details. The talk is open to everyone, […]</div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2019/01/09/the-baruch-distinguished-mathematics-lecture-series/"><span class="datestr">at January 09, 2019 08:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blogs.princeton.edu/imabandit/?p=1350">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/bubeck.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blogs.princeton.edu/imabandit/2019/01/09/nemirovskis-acceleration/">Nemirovski’s acceleration</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I will describe here the very first (to my knowledge) acceleration algorithm for smooth convex optimization, which is due to <a href="https://en.wikipedia.org/wiki/Arkadi_Nemirovski" class="liinternal" rel="nofollow">Arkadi Nemirovski</a> (dating back to the end of the 70’s). The algorithm relies on a <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc2da46d9824359f6ac8d33c5fb882dd_l3.png?resize=8%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="8" alt="2" class="ql-img-inline-formula " />-dimensional plane-search subroutine (which, in theory, can be implemented in <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-38bfa3c1131fbae41cb358b8b685dc56_l3.png?resize=61%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="61" alt="\log(1/\epsilon)" class="ql-img-inline-formula " /> calls to a first-order oracle). He later improved it to only require a <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="13" width="7" alt="1" class="ql-img-inline-formula " />-dimensional line-search in 1981, but of course the breakthrough that everyone knows about came a year after with the famous 1982 paper by <a href="https://en.wikipedia.org/wiki/Yurii_Nesterov" class="liinternal" rel="nofollow">Nesterov</a> that gets rid of this extraneous logarithmic term altogether (and in addition is based on the <a href="https://blogs.princeton.edu/imabandit/2018/11/21/a-short-proof-for-nesterovs-momentum/" class="liinternal">deep insight</a> of modifying Polyak’s momentum).</p>
<p>Let <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="10" alt="f" class="ql-img-inline-formula " /> be a <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-21b5b4cbe9a10b6d847eeb4265b99898_l3.png?resize=7%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="13" width="7" alt="1" class="ql-img-inline-formula " />-smooth function. Denote <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d69559ebcb4e4ecdf7454cab91bf526b_l3.png?resize=125%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="125" alt="x^{+} = x - \nabla f(x)" class="ql-img-inline-formula " />. Fix a sequence <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ba9ca1ebe088d1befda0acb3c4644727_l3.png?resize=43%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="43" alt="(\lambda_t)_{t \in \N}" class="ql-img-inline-formula " />, to be optimized later. We consider the “conjugate” point <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d22daf1993fbb2397de0b21ab0ea87ee_l3.png?resize=119%2C23&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="23" width="119" alt="\sum_{s =1}^t \lambda_s \nabla f(x_s)" class="ql-img-inline-formula " />. The algorithm simply returns the optimal combination of the conjugate point and the gradient descent point, that is:</p>
<p style="line-height: 54px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-360399a70097a55997eaeacb3ec02615_l3.png?resize=424%2C54&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="54" width="424" alt="\[ x_{t+1} = \argmin_{x \in P_t} f(x) \, \text{where} \, P_t = \mathrm{span}\left(x_t^+, \sum_{s =1}^t \lambda_s \nabla f(x_s)\right) \,. \]" class="ql-img-displayed-equation " /></p>
<p>Let us denote <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e614d7a76c02a9a308f9898af91df8ff_l3.png?resize=95%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="95" alt="g_s = \nabla f(x_s)" class="ql-img-inline-formula " /> and <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-629dcf91ea83c14ea854c74de1069acd_l3.png?resize=143%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="143" alt="\delta_s = f(x_s) - f(x^*)" class="ql-img-inline-formula " /> for shorthand. The key point is that <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9d21b904e2ccc5df54959aa117a37b98_l3.png?resize=77%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="20" width="77" alt="g_{t+1} \in P_t^{\perp}" class="ql-img-inline-formula " />, and in particular <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e57279bc2d0342e42087a51af61fb76_l3.png?resize=231%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="22" width="231" alt="\|\sum_{s \leq t} \lambda_s g_s\|^2 = \sum_{s \leq t} \lambda_s^2 \|g_s\|^2" class="ql-img-inline-formula " />. Now recognize that <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b728147d95760e42ef7cdbb706a8cfd1_l3.png?resize=38%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="20" width="38" alt="\|g_s\|^2" class="ql-img-inline-formula " /> is a lower bound on the improvement <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0808cda8024eb11ab7ce37176832a9fe_l3.png?resize=68%2C17&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="17" width="68" alt="\delta_s - \delta_{s+1}" class="ql-img-inline-formula " /> (here we use that <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b0878f455a78407f8618e726e941aea6_l3.png?resize=33%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="13" width="33" alt="x_{s+1}" class="ql-img-inline-formula " /> is better than <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5acc4c663fcf2f647eb177ebb24bc154_l3.png?resize=20%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="20" alt="x_s^+" class="ql-img-inline-formula " />). Thus we get:</p>
<p style="line-height: 40px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a12bda17f9c1f0f0e13ef03c9a1c9d2c_l3.png?resize=404%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="40" width="404" alt="\[ \|\sum_{s \leq t} \lambda_s g_s\|^2 \leq \sum_{s \leq t} \lambda_s^2 (\delta_s - \delta_{s+1}) \leq \sum_{s \leq t} \delta_s (\lambda_s^2 - \lambda_{s-1}^2) \,. \]" class="ql-img-displayed-equation " /></p>
<p>In other words if the sequence <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab48baf331239642a00255b86324280a_l3.png?resize=10%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="10" alt="\lambda" class="ql-img-inline-formula " /> is chosen such that <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2f241a8315da6dd3f7735135d1d2b7ae_l3.png?resize=114%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="21" width="114" alt="\lambda_s = \lambda_s^2 - \lambda_{s-1}^2" class="ql-img-inline-formula " /> then we get</p>
<p style="line-height: 40px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-8e959561f27eec9096b81bd7148a4a75_l3.png?resize=180%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="40" width="180" alt="\[ \|\sum_{s \leq t} \lambda_s g_s\|^2 \leq \sum_{s \leq t} \lambda_s \delta_s \,. \]" class="ql-img-displayed-equation " /></p>
<p>This is good because roughly the reverse inequality also holds true by convexity (and the fact that <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-212cae06b1b9b8b6af498b589bb15865_l3.png?resize=56%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="56" alt="x_s \in P_s" class="ql-img-inline-formula " /> so <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cf91835fdc91be361d1c7e89f867c5db_l3.png?resize=78%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="78" alt="g_s \cdot x_s = 0" class="ql-img-inline-formula " />):</p>
<p style="line-height: 40px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9d1ee450c97dfc04bca3a123fb68daa8_l3.png?resize=391%2C40&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="40" width="391" alt="\[ \sum_{s \leq t} \lambda_s \delta_s \leq \sum_{s \leq t} \lambda_s g_s \cdot (x_s - x^*) \leq \|x^*\| \cdot \| \sum_{s \leq t} \lambda_s g_s\| \,. \]" class="ql-img-displayed-equation " /></p>
<p>So finally we get <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d58dea2404181d7f1751fcf8e68ad024_l3.png?resize=143%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="22" width="143" alt="\sum_{s \leq t} \lambda_s \delta_s \leq \|x^*\|^2" class="ql-img-inline-formula " />, and it just remains to realize that <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f100f89f751713a1814b3938a510009b_l3.png?resize=16%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="16" alt="\lambda_s" class="ql-img-inline-formula " /> is of order <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="8" alt="s" class="ql-img-inline-formula " /> so that <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ff4a3e78d1ced5a05f33eb077194504_l3.png?resize=103%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="20" width="103" alt="\delta_t \leq \|x^*\|^2 / t^2" class="ql-img-inline-formula " />.</p></div>







<p class="date">
by Sebastien Bubeck <a href="https://blogs.princeton.edu/imabandit/2019/01/09/nemirovskis-acceleration/"><span class="datestr">at January 09, 2019 06:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42180">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42180/coordinate-descent-in-integer-programing-when-does-it-work">Coordinate descent in integer programing: when does it work?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Denote <span class="math-container">$N_i=\{0,1,\dots,\bar{n}_i\}$</span> and define <span class="math-container">$N=N_1\times \dots \times N_I$</span>. I want to minimize a function <span class="math-container">$f:N\rightarrow \mathbb{R}$</span>. It is very easy to minimize <span class="math-container">$f$</span> coordinate by coordinate so one natural algorithm is to iterate on a mapping <span class="math-container">$T$</span> for which the <span class="math-container">$i$</span>th element is defined as
<span class="math-container">$$(Tn)_i=\arg\min_{\tilde{n}_i\in N_i} f\left( \left\{ n_1,\dots,\tilde{n}_i,\dots,n_I\right\}\right)$$</span>
until we have convergence. This is essentially a <a href="https://en.wikipedia.org/wiki/Coordinate_descent" rel="nofollow noreferrer">coordinate descent</a> algorithm but in a discrete space.</p>

<p>My question is: under what conditions does this approach yield the true global minimum of <span class="math-container">$f$</span>? For instance, is <span class="math-container">$f$</span> strictly convex a sufficient condition for this procedure to work? Also, if anybody has a reference on the topic that would be highly appreciated.</p></div>







<p class="date">
by user_lambda <a href="https://cstheory.stackexchange.com/questions/42180/coordinate-descent-in-integer-programing-when-does-it-work"><span class="datestr">at January 09, 2019 06:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=606">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/01/09/my-last-3-5-years/">My last 3.5 years</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p style="text-align: justify;">I haven’t breathed (freely) since 3.5 years ago.  Precisely since the day before I left my Cambridge flat, when the Pods guy told me he couldn’t park. I had to vacate within 24 hours, had no place to put all the stuff I had never used since moving there in 2008, and also happened to have a 3-hour CPR course planned long ago, starting in minutes.  I took that life-saving course on the edge of the seat, each 5-minute break dashing out to call movers who might have had an unlikely last minute cancellation in the busiest day of the year (August 31).</p>
<p style="text-align: justify;">Oh the times I wished that the fireproof storage where the things eventually went burned down to the ground.  Instead I was going to have to move my never used belongings a million times up and down stairs.</p>
<p style="text-align: justify;">Anyway, after Cambridge I went to the <a href="https://emanueleviola.wordpress.com/2015/11/16/from-the-simons-institute/">Simons institute</a>. Even with all the help from the staff, finding housing was atrocious, and I had to change it during the semester. I didn’t have a place to come back, and from Berkeley I eventually found a short-term rental in Needham, MA.  The idea was to buy a house in that short term.  This proved <a href="https://emanueleviola.wordpress.com/2015/12/15/how-to-buy-a-house/">impossible</a>.  So we had to find another rental.  In the process, I was discriminated against three times.  One time the landlord rejected in writing my application claiming that they did not want to rent to families. The other two times the landlord simply rejected my application, and then lowered the price. I thought these moves made them dumb, but maybe they are actually much smarter than me, because after toying with the idea I did not, in fact, sue.</p>
<p style="text-align: justify;">Eventually we found another longer-term rental.  From there, with more excruciating difficulties I <a href="https://emanueleviola.wordpress.com/2017/12/19/how-to-buy-a-house-ii/">wrote about earlier</a>, I bought a house, which however required 1 year of renovations (not exactly cosmetic — more about this later).  These were completed just in time to store my useless stuff there: I left for another semester at the Simons institute.</p>
<p style="text-align: justify;">My second visit to the institute was also great.  In fact I enjoyed it even more than the semester on fine-grained: I was there for the program on lower bounds, which are exactly the problems I went into computer science to study. I had the best time, and lots of research exchanges.</p>
<p style="text-align: justify;">But again, the housing situation in Berkeley was desperate.  Twice I lost a house for 1 hour. Meaning, the landlord called to make the deal, I couldn’t pick up the phone, and when I called back 1 hour later the place was gone.  I still think it would be better if the institute bought a block of houses, and also provided computers.  Even better if they make it easier to print, rather than having to stand in a corner or go through a complicated set up.</p>
<p style="text-align: justify;">Another interesting pattern is that during my first visit there was a heat wave and the AC broke, and it was hot.  This time there was a rather serious wildfire, causing very unhealthy conditions in the bay area, and at times they couldn’t run the heating systems to avoid sucking in the smoke, and it was cold.</p>
<p style="text-align: justify;">Berkeley isn’t Princeton, but it’s hard for me not to compare the logistics of my visits to Simons and the IAS in Princeton.  In the latter I was put in a house steps from the Institute, with minimal effort and at a fraction of the price.  In my office there was already a working computer, connected to a printer.</p>
<p>Here’s the meaning of cloud computing, remote desktop, telnet, etc in 2019, here’s the progress, the sustainability, the sharing economy: everybody brings their own laptop.</p>
<p style="text-align: justify;">Back from Simons, I can’t help but be surprised that I still have an office.  In fact this happens every time I go up the stairs, turn the corner and see my name on the tag, and it says “Professor”. Really? Under <em>my name</em>? I have a startle each time.  I know this feeling is irrational, but is there.  Coming back from California, the feeling is intense.</p>
<p style="text-align: justify;">Back to business, I am now teaching algorithms.  I am running an online section, for which I am making videos on my <a href="https://www.youtube.com/channel/UChbOQ1Q8Fv44LbrQMvTPoEQ">youtube channel</a>. It’s the future.</p></div>







<p class="date">
by Emanuele <a href="https://emanueleviola.wordpress.com/2019/01/09/my-last-3-5-years/"><span class="datestr">at January 09, 2019 04:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42178">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42178/approximate-multi-covering-with-randomized-rounding">Approximate Multi Covering with Randomized Rounding</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the set multicover problem we are given a set <span class="math-container">$N$</span> of <span class="math-container">$n$</span> elements and a set <span class="math-container">$S$</span> of <span class="math-container">$m$</span> subsets of <span class="math-container">$N$</span>. Additionally, each element has a coverage requirement (the number of times it has to be covered) and each set has a weight. The question is to cover <span class="math-container">$N$</span> with the minimum weight subsets from <span class="math-container">$S$</span>. I'm aware of the approximation algorithm for this problem using (Rajagopalan &amp; Vazirani) .</p>

<p>But I am interested in finding an algorithm for this problem that uses the randomized rounding and study its approximation factor.</p>

<p>Thanks in advance!</p></div>







<p class="date">
by user2404626 <a href="https://cstheory.stackexchange.com/questions/42178/approximate-multi-covering-with-randomized-rounding"><span class="datestr">at January 09, 2019 04:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42177">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42177/maximum-minimum-satisfiability">Maximum-minimum satisfiability</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In <a href="https://en.wikipedia.org/wiki/Maximum_satisfiability_problem" rel="nofollow noreferrer">MAX-SAT</a>, given a formula, we want to maximize the number of satisfied clauses: given a formula <span class="math-container">$\phi = c_1 \cap \cdots \cap c_n$</span>, where each <span class="math-container">$c_i$</span> is a disjunction, we want to find the largest <span class="math-container">$k\in\{1,\ldots,n\}$</span> such that, for some assignment, some <span class="math-container">$k$</span> clauses <span class="math-container">$c_{i1},\ldots,c_{ik}$</span> are true.</p>

<p>In <strong>MAX-MIN-SAT</strong>, given two different formulas, we want to maximize the minimum number of satisfied clauses in both.
I.e., given <span class="math-container">$\phi_a = a_1 \cap \cdots \cap a_n$</span> and <span class="math-container">$\phi_b = b_1 \cap \cdots \cap b_n$</span>,  where each <span class="math-container">$a_i$</span> and each <span class="math-container">$b_i$</span> is a disjunction, find the largest <span class="math-container">$k$</span> such that, for some assignment, some <span class="math-container">$k$</span> clauses <span class="math-container">$a_{i1},\ldots,a_{ik}$</span> and some <span class="math-container">$k$</span> clauses <span class="math-container">$b_{j1},\ldots,b_{jk}$</span> are true.</p>

<p>To illustrate the difference between the problems, suppose we have two assignments: one assignment satisfies 10 clauses in <span class="math-container">$\phi_a$</span> and 1 clause in <span class="math-container">$\phi_b$</span>, while another assignment satisfies 5 clauses in <span class="math-container">$\phi_a$</span> and 4 clauses in <span class="math-container">$\phi_b$</span>. Then, MAX-SAT (on <span class="math-container">$\phi_a \cap \phi_b$</span>) would prefer the first assignment since it satisfies <span class="math-container">$11&gt;9$</span> clauses overall, while MAX-MIN-SAT would prefer the second assignment since it satisfies at least <span class="math-container">$4&gt;1$</span> clauses in both formulas.</p>

<p>This problem is obviously NP-hard, so I am looking for reasonable approximations.</p>

<p>As a first approximation, suppose each formula is a conjunction of <span class="math-container">$n$</span> clauses, and each clause is a disjunction of <span class="math-container">$l$</span> variables. Suppose we set each variable randomly. Then, each clause is unsatisfied with probability <span class="math-container">$2^{-l}$</span>. So the expected number of unsatisfied clauses in each formula is <span class="math-container">$2^{-l}n$</span>. So the expected number of unsatisfied clauses in both formulas is <span class="math-container">$2^{1-l}n$</span>. So there exists an assignment in which the total number of unsatisfied clauses is at most <span class="math-container">$2^{1-l}n$</span>. In that assignment, in each formula, at least  <span class="math-container">$(1-2^{1-l})n$</span> clauses are satisfied. 
So we have a constant-factor <span class="math-container">$(1-2^{1-l})$</span> approximation to MAX MIN SAT. </p>

<p>Is there a better approximation? </p>

<p><sub><a href="https://cs.stackexchange.com/q/100375/1342">Posted some weeks ago in cs.SE,</a> with no replies</sub></p></div>







<p class="date">
by Erel Segal-Halevi <a href="https://cstheory.stackexchange.com/questions/42177/maximum-minimum-satisfiability"><span class="datestr">at January 09, 2019 03:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2727898493587029341">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html">Search versus Decision</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Shockingly I've never done a post on search versus decision, one of the more interesting dualities in complexity. In short: Decision: Is there a needle in the haystack? Search: Find the needle.<br />
<br />
In Satisfiability, or any other NP-complete problem, the two problems are essentially equivalent. If you can decided SAT you can find a solution (good homework problem) or even the best solution. Often people mix up the two, where people say finding the shortest Traveling Salesman Tour is NP-complete, <a href="https://blog.computationalcomplexity.org/2014/01/is-traveling-salesman-np-complete.html">usually</a> without getting into too much trouble.<br />
<br />
Decision is always at least as easy as search: If you have a solution you know there is one. What about the other direction? We can't actually prove search is hard without separating P and NP, but we have our conjectures.<br />
<br />
Sometimes both are easy. We can easily find the maximum weighted matching.<br />
<br />
Sometimes decision is easy and search is supposedly hard: Composite Numbers. The search version is factoring.<br />
<br />
Sometimes decision is trivial (i.e. they always exist) and search is still hard. Nash Equilibria. <a href="https://blog.computationalcomplexity.org/2006/05/dispersing-ramsey-graphs.html">Ramsey Graphs</a>.<br />
<br />
Often we ask whether search reduces to decision? If you have some oracle (magic black box) that answered decision questions, can you solve the search problem efficiently? SAT has this property, as does Matching (for trivial reasons). Nash Equilibrium and Composite Numbers likely don't.<br />
<br />
Graph Isomorphism does, i.e., given an oracle for graph isomorphism you can find the isomorphism (another good homework problem).<br />
<br />
There's also an interesting non-adaptive version. Given a SAT formula can you find an assignment with questions to a SAT oracle that all have to be asked at the same time?<br />
<br />
Here we get a probable yes. If the formula has one solution you can find it by asking for each bit of the solution. <a href="https://blog.computationalcomplexity.org/2006/09/favorite-theorems-unique-witnesses.html">Randomly you can reduce SAT to several formulas</a>, one of which is likely to have a single assignment that is also an assignment of the original formula. With standard hardness assumptions <a href="https://blog.computationalcomplexity.org/2006/07/full-derandomization.html">you can eliminate the randomness</a>.<br />
<br />
Is the same true for graph isomorphism? I think that's still open.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/01/search-versus-decision.html"><span class="datestr">at January 09, 2019 01:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.02441">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.02441">Lower bounds for maximal matchings and maximal independent sets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balliu:Alkida.html">Alkida Balliu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hirvonen:Juho.html">Juho Hirvonen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olivetti:Dennis.html">Dennis Olivetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rabie:Mika=euml=l.html">Mikaël Rabie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suomela:Jukka.html">Jukka Suomela</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02441">PDF</a><br /><b>Abstract: </b>There are distributed graph algorithms for finding maximal matchings and
maximal independent sets in $O(\Delta + \log^* n)$ communication rounds; here
$n$ is the number of nodes and $\Delta$ is the maximum degree. The lower bound
by Linial (1992) shows that the dependency on $n$ is optimal: these problems
cannot be solved in $o(\log^* n)$ rounds even if $\Delta = 2$.
</p>
<p>However, the dependency on $\Delta$ is a long-standing open question, and
there is currently an exponential gap between the upper and lower bounds.
</p>
<p>We prove that the upper bounds are tight. We show that maximal matchings and
maximal independent sets cannot be found in $o(\Delta + \log \log n / \log \log
\log n)$ rounds. Our lower bound holds for deterministic and randomized
distributed algorithms in the LOCAL model of distributed computing.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.02441"><span class="datestr">at January 09, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.02393">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.02393">Fair Algorithms for Clustering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bera:Suman_K=.html">Suman K. Bera</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarty:Deeparnab.html">Deeparnab Chakrabarty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Negahbani:Maryam.html">Maryam Negahbani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02393">PDF</a><br /><b>Abstract: </b>We study clustering problems under the lens of {\em algorithmic fairness}
inspired by the disparate impact doctrine. Given a collection of points
containing many {\em protected groups}, the goal is to find good clustering
solutions where each cluster {\em fairly represents} each group. We allow the
user to specify the parameters that define fair representation, and this
flexibility makes our model significantly more general than the recent models
of Chierichetti et al. (NIPS 2017) and R\"osner and Schmidt (ICALP 2018). Our
main result is a simple algorithm that, for any $\ell_p$-norm including the
$k$-center, $k$-median, and $k$-means objectives, transforms any clustering
solution to a fair one with only a slight loss in quality.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.02393"><span class="datestr">at January 09, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.02209">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.02209">Subset Feedback Vertex Set in Chordal and Split Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Philip:Geevarghese.html">Geevarghese Philip</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajan:Varun.html">Varun Rajan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tale:Prafullkumar.html">Prafullkumar Tale</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02209">PDF</a><br /><b>Abstract: </b>In the \textsc{Subset Feedback Vertex Set (Subset-FVS)} problem the input is
a graph $G$, a subset \(T\) of vertices of \(G\) called the `terminal'
vertices, and an integer $k$. The task is to determine whether there exists a
subset of vertices of cardinality at most $k$ which together intersect all
cycles which pass through the terminals. \textsc{Subset-FVS} generalizes
several well studied problems including \textsc{Feedback Vertex Set} and
\textsc{Multiway Cut}. This problem is known to be \NP-Complete even in split
graphs. Cygan et al. proved that \textsc{Subset-FVS} is fixed parameter
tractable (\FPT) in general graphs when parameterized by $k$ [SIAM J. Discrete
Math (2013)]. In split graphs a simple observation reduces the problem to an
equivalent instance of the $3$-\textsc{Hitting Set} problem with same solution
size. This directly implies, for \textsc{Subset-FVS} \emph{restricted to split
graphs}, (i) an \FPT algorithm which solves the problem in $\OhStar(2.076^k)$
time \footnote{The \(\OhStar()\) notation hides polynomial factors.}% for
\textsc{Subset-FVS} in Chordal % Graphs [Wahlstr\"om, Ph.D. Thesis], and (ii) a
kernel of size $\mathcal{O}(k^3)$. We improve both these results for
\textsc{Subset-FVS} on split graphs; we derive (i) a kernel of size
$\mathcal{O}(k^2)$ which is the best possible unless $\NP \subseteq \coNP/{\sf
poly}$, and (ii) an algorithm which solves the problem in time
$\mathcal{O}^*(2^k)$. Our algorithm, in fact, solves \textsc{Subset-FVS} on the
more general class of \emph{chordal graphs}, also in $\mathcal{O}^*(2^k)$ time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.02209"><span class="datestr">at January 09, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.02166">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.02166">K-Core Minimization: A Game Theoretic Approach</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Medya:Sourav.html">Sourav Medya</a>, Tiyani Ma, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Arlei.html">Arlei Silva</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Ambuj.html">Ambuj Singh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02166">PDF</a><br /><b>Abstract: </b>$K$-cores are maximal induced subgraphs where all vertices have degree at
least $k$. These dense patterns have applications in community detection,
network visualization and protein function prediction. However, $k$-cores can
be quite unstable to network modifications, which motivates the question: How
resilient is the k-core structure of a network, such as the Web or Facebook, to
edge deletions? We investigate this question from an algorithmic perspective.
More specifically, we study the problem of computing a small set of edges for
which the removal minimizes the $k$-core structure of a network.
</p>
<p>This paper provides a comprehensive characterization of the hardness of the
$k$-core minimization problem (KCM), including innaproximability and
fixed-parameter intractability. Motivated by such a challenge in terms of
algorithm design, we propose a novel algorithm inspired by Shapley value---a
cooperative game-theoretic concept--- that is able to leverage the strong
interdependencies in the effects of edge removals in the search space. As
computing Shapley values is also NP-hard, we efficiently approximate them using
a randomized algorithm with probabilistic guarantees. Our experiments, using
several real datasets, show that the proposed algorithm outperforms competing
solutions in terms of $k$-core minimization while being able to handle large
graphs. Moreover, we illustrate how KCM can be applied in the analysis of the
$k$-core resilience of networks.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.02166"><span class="datestr">at January 09, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.02070">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.02070">Convolutional Neural Networks on non-uniform geometrical signals using Euclidean spectral transformation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Chiyu "Max" Jiang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Dequan.html">Dequan Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Jingwei.html">Jingwei Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marcus:Philip.html">Philip Marcus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nie=szlig=ner:Matthias.html">Matthias Nießner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.02070">PDF</a><br /><b>Abstract: </b>Convolutional Neural Networks (CNN) have been successful in processing data
signals that are uniformly sampled in the spatial domain (e.g., images).
However, most data signals do not natively exist on a grid, and in the process
of being sampled onto a uniform physical grid suffer significant aliasing error
and information loss. Moreover, signals can exist in different topological
structures as, for example, points, lines, surfaces and volumes. It has been
challenging to analyze signals with mixed topologies (for example, point cloud
with surface mesh). To this end, we develop mathematical formulations for
Non-Uniform Fourier Transforms (NUFT) to directly, and optimally, sample
nonuniform data signals of different topologies defined on a simplex mesh into
the spectral domain with no spatial sampling error. The spectral transform is
performed in the Euclidean space, which removes the translation ambiguity from
works on the graph spectrum. Our representation has four distinct advantages:
(1) the process causes no spatial sampling error during the initial sampling,
(2) the generality of this approach provides a unified framework for using CNNs
to analyze signals of mixed topologies, (3) it allows us to leverage
state-of-the-art backbone CNN architectures for effective learning without
having to design a particular architecture for a particular data structure in
an ad-hoc fashion, and (4) the representation allows weighted meshes where each
element has a different weight (i.e., texture) indicating local properties. We
achieve results on par with the state-of-the-art for the 3D shape retrieval
task, and a new state-of-the-art for the point cloud to surface reconstruction
task.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.02070"><span class="datestr">at January 09, 2019 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/01/08/postdoc-at-saint-louis-university-apply-by-january-21-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/01/08/postdoc-at-saint-louis-university-apply-by-january-21-2019/">Postdoc at Saint Louis University (apply by January 21, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I have a openings for 2 postdocs, both starting in 2019: One is flexible in focus, fitting under the broad categories of computational topology/geometry and algorithms. The other is for a shape simplification project, jointly supervised by Dr. David Letscher, focusing on designing and implementing algorithms that use persistent homology as well as other tools from computational topology.</p>
<p>Website: <a href="http://cs.slu.edu/~chambers/">http://cs.slu.edu/~chambers/</a><br />
Email: erin.chambers@slu.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/01/08/postdoc-at-saint-louis-university-apply-by-january-21-2019/"><span class="datestr">at January 08, 2019 06:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42176">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42176/minimal-dfa-corresponding-to-complement-of-a-language">minimal DFA corresponding to complement of a language [on hold]</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>is it necessary that number of states in minimal DFA for a language corresponding to L' is equal to the number of states in minimal DFA of the language corresponding to L. </p>

<p>here L' is the complement of the language L.</p>

<p>for example,
number of states in the minimal DFA for the language</p>

<p>L={set of all string containing 01 and 011 as the substring over the alphabet {0,1}}</p>

<p>is 4. </p>

<p>if i'm making the DFA for the complement of this language, i'm getting 3. 
but is it true that it should be 4?</p>

<p>please help!! which one is correct-- 3 or 4?</p></div>







<p class="date">
by aambazinga <a href="https://cstheory.stackexchange.com/questions/42176/minimal-dfa-corresponding-to-complement-of-a-language"><span class="datestr">at January 08, 2019 02:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42171">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42171/minimum-relevant-variables-in-linear-system-additive-approximation">Minimum relevant variables in linear system - additive approximation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the problem <a href="https://en.wikipedia.org/wiki/Minimum_relevant_variables_in_linear_system" rel="nofollow noreferrer">Minimum Relevant Variables in Linear System</a> (Min-RVLS), the input is a linear system, e.g.:</p>

<p><span class="math-container">$$ A x = b $$</span></p>

<p>and the goal is to find a solution <span class="math-container">$x$</span> with as few nonzero variables as possible. </p>

<p>The problem is known to be NP-hard and hard to approximate to within a constant multiplicative factor (see the wikipedia page for details). </p>

<p>My question is: is anything known about <em>additive</em> approximations? In particular: what is the complexity of finding a solution that has at most <span class="math-container">$\text{OPT}+d$</span> nonzero variables, where <span class="math-container">$\text{OPT}$</span> is the smallest number of nonzero variables in a solution, and <span class="math-container">$d$</span> is some constant?</p></div>







<p class="date">
by Erel Segal-Halevi <a href="https://cstheory.stackexchange.com/questions/42171/minimum-relevant-variables-in-linear-system-additive-approximation"><span class="datestr">at January 07, 2019 04:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42169">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42169/optimal-algorithm-to-compare-lines-of-different-files-without-repetition">Optimal algorithm to compare lines of different files without repetition [on hold]</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have 1600 ASCII files with 1000 lines in each file. Each line has only one entry and is a floating point number e.g. 1.67923.
Let's denote the line1 of file1 with <code>L(1,1)</code>, line2 of file1 with <code>L(1,2)</code> and so forth to ...<code>L(1,1000)</code>. Similarly, line1 of file2 will be <code>L(2,1)</code> and the last line of file1600 will thus be <code>L(1600,1000)</code>.
My task is to come up with a memory efficient algorithm to compare all lines between each file and the lines within each file. Since, I have 1600 files and 1000 lines in each file, it will take approx. <code>10^12</code> calculations. These first comparisons will look like this:</p>

<pre><code>1. {L(1,1)-L(1,2)}, {L(1,1)-L(1,3)},....,{L(1,1)-L(1,1000)}
2. {L(1,1)-L(2,1)}, {L(1,1)-L(2,2)},....,{L(1,1)-L(2,1000)}
3. {L(1,1)-L(3,1)}, {L(1,1)-L(3,2)},....,{L(1,1)-L(3,1000)}
.
.
. 
</code></pre>

<p>Please note that I don't want repetitions i.e <code>{L(1,1)-L(2,1)} = {L(2,1)-L(1,1)}</code>.
I need to code this problem in Fortran but any help on a general scheme as to how the problem needs to be approached will be useful.
Thank you in advance!  </p></div>







<p class="date">
by Abedin Y. Abedin <a href="https://cstheory.stackexchange.com/questions/42169/optimal-algorithm-to-compare-lines-of-different-files-without-repetition"><span class="datestr">at January 07, 2019 03:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1259">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2019/01/07/catcs-mailing-list-and-sign-up-link/">CATCS mailing list and sign-up link</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>CATCS is starting up a new mailing list to send out annual newsletters. Messages will be sent out 1-2 times every year describing recent projects undertaken by the committee, funding opportunities, links to useful resources, etc. Anyone interested in hearing about our activities is welcome to sign up at <a href="https://groups.google.com/forum/#!forum/catcs-news">this link</a>. You do not have to be a member of SIGACT to sign up.<span style="color: #000000; font-family: Arial, sans-serif;"><br />
</span></p>
<div></div></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2019/01/07/catcs-mailing-list-and-sign-up-link/"><span class="datestr">at January 07, 2019 08:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42167">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42167/decomposition-for-a-certain-class-of-graphs">Decomposition for a certain class of graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Suppose a graph, <span class="math-container">$G = (V,E)$</span> is characterized as a lattice/network of cliques as in the picture below. Does there exist some decomposition principle (i.e. on the right) for <span class="math-container">$G$</span>, that yields some special structure that may be used to explain efficiencies experienced with what are supposed to be combinatorial hard problems?</p>

<p><a href="https://i.stack.imgur.com/FTbx8.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/FTbx8.png" alt="enter image description here" /></a></p></div>







<p class="date">
by Student <a href="https://cstheory.stackexchange.com/questions/42167/decomposition-for-a-certain-class-of-graphs"><span class="datestr">at January 07, 2019 06:19 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42166">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42166/algorithm-for-k-best-non-perfect-bipartite-matchings">Algorithm for K-best NON perfect bipartite matchings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I was reading this great article: <a href="https://core.ac.uk/download/pdf/82129717.pdf" rel="nofollow noreferrer">https://core.ac.uk/download/pdf/82129717.pdf</a></p>

<p>It solves a generalization of the maximum sum assignment problem by finding the k best assignments and not only the best.
However, it only looks at perfect matchings. I'm am especially interested in bipartite matchings.</p>

<p>In particular, for the bipartite graphs, the Theorem 1 p. 161 uses the fact that the matchings are considered perfect.</p>

<p>How can I solve the k-best assignment problem for general bipartite graphs?</p></div>







<p class="date">
by Labo <a href="https://cstheory.stackexchange.com/questions/42166/algorithm-for-k-best-non-perfect-bipartite-matchings"><span class="datestr">at January 06, 2019 11:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4355005625360509962">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/01/when-is-kilogram-not-kilogram.html">When is a kilogram not a kilogram?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A long long time ago the standards for meter's, kilograms, etc was an actual physical object.<br />
<br />
Those days are long gone of course. For example, the meter is defined is the length of the path traveled by light in 1/299,792,458 th of a second. Why such an odd number (can fractions be odd?)? Because they retrofitted it to what that the meter is.  Rather than go to France and compare my stick to the one under a glass case I can just measure the speed of light. Oh. That sounds hard!<br />
<br />
It matters a bit since the weight of what was the standard kilogram did increase over time, though of course not by much. When did the measurements for stuff STOP being based on physical objects and was all done based on constants of the universe?<br />
<br />
The answer surprised me:<br />
<br />
On Nov 16, 2018 (yes, you read that light) they decided that by May 20, 2019, the Kilogram will be defined in terms of Plank's constant. I have not been able to find out how they will use Plank, maybe they don't know yet (they do and its known -- see the first comment) .With that, there are no more standards based on physical objects. Read about it <a href="https://www.wired.com/story/new-kilogram-definition-based-on-planck-constant/">here</a>.<br />
<br />
Why did it take so long? I honestly don't know and I am tossing that question out to my readers. You can leave serious or funny answers, and best if I can't tell which is which!<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/01/when-is-kilogram-not-kilogram.html"><span class="datestr">at January 06, 2019 09:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15562">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/">Predictions For 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>The problem of predicting ‘when’ not just ‘what’</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg"><img width="180" alt="" src="https://rjlipton.files.wordpress.com/2019/01/asimovtorontostar.jpg?w=180&amp;h=167" class="alignright wp-image-15564" height="167" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Toronto Star <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Isaac Asimov was a prolific writer of science fiction and nonfiction. Thirty-five years ago, on the eve of the year 1984, he noted that 35 years had passed since the publication of George Orwell’s <em>1984</em>. He wrote an exclusive <a href="https://www.thestar.com/news/world/2018/12/27/35-years-ago-isaac-asimov-was-asked-by-the-star-to-predict-the-world-of-2019-here-is-what-he-wrote.html">feature</a> for the Toronto Star newspaper predicting what the world would be like 35 years hence, that is, in 2019.</p>
<p>
Today we give our take on his predictions and make our own for the rest of 2019.</p>
<p>
Asimov’s essay began by presupposing the absence of nuclear holocaust without predicting it. It then focused on two subjects: computerization and use of outer space. On the spectrum of evaluations subtended by this laudatory BBC <a href="https://www.bbc.com/news/technology-46736024">piece</a> and this critical <a href="https://www.thestar.com/news/world/2018/12/27/isaac-asimov-you-were-no-nostradamus.html">column</a> in the Toronto Star itself, we’re closer to the latter. On space he predicted we’d be mining the Moon by now; instead nothing more landed on the Moon until the Chinese <a href="https://en.wikipedia.org/wiki/Chang'e_3">Chang’e 3</a> mission in 2013 and <a href="https://en.wikipedia.org/wiki/Chang'e_4">Chang’e 4</a> happening now. His 35-year span should be lengthened to over a century.</p>
<p>
On computerization and robotics he was mostly right except again for the timespan: he said the transition would be “about over” by 2019 whereas it may be entering its period of greatest flux only now. However, for the end of 1983 we think the “whats” of his predictions were easy. Personal computers had already been around for almost a decade. Computer systems for business were plentiful. The Internet was already a proclaimed goal and the text-based <a href="https://en.wikipedia.org/wiki/Usenet">Usenet</a> was already operating. Asimov’s essay seems to miss how the combination of these three would soon move points of control outward to end-users. </p>
<p>
We still think what he wrote about space and robots will happen. This shows the problem of predictions is not just ‘what’ but ‘when.’ For another instance of being wrong on ‘when’ too soon, Ken told a Harvard Law graduate who visited him in Oxford in 1984 that what we now call <a href="https://en.wikipedia.org/wiki/Deepfake">deepfake</a> videos were imminent. We’ll make the rest of this post more about ‘when’ than ‘what.’</p>
<p>
</p><p></p><h2> Predictions in Past Years </h2><p></p>
<p></p><p>
Here are some predictions that we have made before. Seems we did not make any new predictions last year—oh well—but see <a href="https://rjlipton.wordpress.com/2018/01/02/predictions-we-didnt-make/">this</a>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>No circuit lower bound of <img src="https://s0.wp.com/latex.php?latex=%7B1000n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1000n}" class="latex" title="{1000n}" /> or better will be proved for SAT.</em> Well that’s a freebie.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>A computer scientist will win a Nobel Prize.</em> No—indeed, less close than other years.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>At least five claims that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%3D%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}=\mathsf{NP}}" class="latex" title="{\mathsf{P}=\mathsf{NP}}" /> and five that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" title="{\mathsf{P} \neq \mathsf{NP}}" /> will be made.</em> </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> A “provably” secure crypto-system will be broken. For this one we don’t have to check any claims. We just pocket the ‘yes’ answer. Really, could you ever prove the opposite? How about the <a href="https://cacm.acm.org/magazines/2019/1/233523-imperfect-forward-secrecy/abstract">attack</a> on Diffie-Hellman in the current CACM?</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <em>An Earth-sized planet will be detected orbiting within the habitable zone of its single star.</em> The “when” for this one came in 2017 already. We are retiring it.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <em>A Clay problem will be solved, or at least notable progress made.</em> Again we sense that the answer on progress is “no.” This includes saying that nothing substantial seems to have emerged from Sir Michael Atiyah’s <a href="https://aperiodical.com/2018/09/atiyah-riemann-hypothesis-proof-final-thoughts/">claim</a> of proving the Riemann Hypothesis. However, we note <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">via</a> Gil Kalai’s blog that a longstanding problem called the <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" />-conjecture for spheres has been <a href="https://arxiv.org/abs/1812.10454">solved</a> by Karim Adiprasito.</p>
<p>
</p><p></p><h2> Predictions This Year </h2><p></p>
<p></p><p>
We will add some new predictions—it seems unfair to keep repeating sure winners. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>Deep learning methods will be found able to solve integer factoring.</em> This will place current cryptography is trouble.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>Deep learning methods will be found to help prove that factoring is hard.</em></p>
<p>
These may not be as contradictory as they seem. There is a long-known <a href="http://www.cs.sfu.ca/~kabanets/papers/natural-learning-short.pdf">connection</a> between certain learning algorithms and the <a href="https://en.wikipedia.org/wiki/Natural_proof">natural</a> <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">proofs</a> of Alexander Razborov and Stephen Rudich. The hardness predicate at the core of a natural proof is a classifier to distinguish (succinct) hard Boolean functions from easy ones. There is a duality between upper and lower bounds that in particular leads to the unconditional result that the discrete log problem, which is related to factoring and equally amenable to Peter Shor’s famous polynomial-time quantum algorithm, does not have natural proofs of hardness—because their existence would make discrete log relatively easy. </p>
<p>
Talking about quantum, we predict:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>Quantum supremacy will be proved—finally.</em> But be careful: there is a problem with this whole direction. See the next section.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <em>An algorithm originating in a theoretical model will be enshrined in law.</em> </p>
<p>
There are several near-term opportunities for this. The Supreme Court yesterday agreed to <a href="https://www.cnn.com/2019/01/04/politics/supreme-court-gerrymandering-cases/index.html">hear</a> two cases on partisan gerrymandering, at least one of which promises to codify an algorithmic criterion for excessive vote dilution. Maine adopted a automatic-runoff voting system whose dependence on computer implementation gave grounds for an unsuccessful <a href="https://www.americanthinker.com/blog/2018/11/maine_gop_rep_sues_to_stop_counting_ranked_choice_ballots.html">lawsuit</a>. Algorithmic fairness is a burgeoning area which we <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">discussed</a> a year-plus ago. <a href="https://www.sciencemag.org/news/2019/01/can-set-equations-keep-us-census-data-private">Use</a> of differential privacy by the U.S. Census could involve legislation. We distinguish legal provisions from the myriad problematic uses of algorithmic models in public and private <em>policy</em> ranging from credit evaluations to parole decisions to college admissions and much else.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <em>The lines between heuristically solvable and really hard problems will become clearer.</em> We have <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">previously</a> <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">opined</a> that the great success of SAT solvers in particular renders the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P=NP}}" class="latex" title="{\mathsf{P=NP}}" /> question moot for many purposes. Well, now we say the opposite: SAT solvers will hit a wall.</p>
<p>
</p><p></p><h2> Quantum Supremacy and Advantage </h2><p></p>
<p></p><p>
Ken recently attended a workshop in central New York that aimed to bring together researchers in many fields working on quantum devices. Materials for the workshop led off with the question of building quantum computers and highlighted Gil Kalai’s skeptical position in particular. An <a href="https://rjlipton.wordpress.com/2012/01/30/perpetual-motion-of-the-21st-century/">eight</a>–<a href="https://rjlipton.wordpress.com/2012/02/15/nature-does-not-conspire/">part</a> <a href="https://rjlipton.wordpress.com/2012/06/20/can-you-hear-the-shape-of-a-quantum-computer/">debate</a> between him and Aram Harrow which we hosted in 2012 <a href="https://rjlipton.wordpress.com/2012/03/05/the-quantum-super-pac/">involved</a> also John Preskill and <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">ended</a> with a discussion of quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>, a term advanced that year by Preskill. The workshop preferred the term quantum <em>advantage</em>. We interpret these terms as having the following distinction:</p>
<ul>
<li>
(a) Quantum <em>supremacy</em> means that a quantum device can perform general-purpose computations that no classical program or device can emulate in comparably feasible time. <p></p>
</li><li>
(b) Quantum <em>advantage</em> means that some particular practical task can be achieved by available quantum devices at lower costs than near-term available classical devices.
</li></ul>
<p>
As theoreticians we tend to think about (a) but many businesses and public-sector organizations would be ecstatic to have (b) in important applications. </p>
<p>
A new angle on (a) was shown by the new construction by Ran Raz and Avishay Tal of an oracle <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{BQP}^A}" class="latex" title="{\mathsf{BQP}^A}" /> is not in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPH%7D%5EA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{PH}^A}" class="latex" title="{\mathsf{PH}^A}" />. This was <a href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html">hailed</a> as the “result of the year” by Lance Fortnow (his second and our first is this <a href="https://eccc.weizmann.ac.il/report/2018/006/">progress</a> on the Unique Games Conjecture), and Scott Aaronson furnished a great <a href="https://www.scottaaronson.com/blog/?p=3827">discussion</a> of its genesis and further ramifications in complexity theory. <a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">Several</a> <a href="https://cacm.acm.org/magazines/2019/1/233514-quantum-leap/fulltext">popular</a> <a href="https://www.thehindu.com/sci-tech/science/quantum-computers-have-an-edge-over-classical-ones-says-the-oracle/article24420375.ece">articles</a> tried to pump this as non-oracle evidence for (a). But there is the over-arching problem:</p>
<blockquote><p><b> </b> <em> We know <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Csubseteq+BPP+%5Csubseteq+BQP+%5Csubseteq+PP+%5Csubseteq+P%5E%7B%5C%23P%7D+%5Csubseteq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}" class="latex" title="{\mathsf{P \subseteq BPP \subseteq BQP \subseteq PP \subseteq P^{\#P} \subseteq PSPACE}}" /> but we don’t know <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%5Cneq+PSPACE%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{P \neq PSPACE}}" class="latex" title="{\mathsf{P \neq PSPACE}}" />. </em>
</p></blockquote>
<p></p><p>
So how are we ever going to be able to <em>prove</em> any form of supremacy? Even if we replace ‘polynomial time’ as our definition of ‘feasible’ by something more concrete, how can we prove that successful classical heuristics <em>do not exist</em>? On a certain practical problem of general import, Ewin Tang, a teenager in Texas advised by Scott, <a href="https://arxiv.org/abs/1807.04271">designed</a> an improved classical algorithm for low-rank matrix completion that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">eliminated</a> a previous quantum exponential advantage in the time dependence on the rank parameter. It is not just a case of <em>whether</em> we can prove supremacy, but judging <em>when</em> general quantum computers will be built to realize it.</p>
<p>
Whereas, the <em>when</em> involved in (b) is <em>now</em>. If a quantum device can do something useful now that classical methods are not delivering now, then it does not matter if the latter could be improved at greater hardware and development cost to work a year from now. This has been the gung-ho tenor of many responses to the recently-<a href="https://www.fedscoop.com/trump-signs-national-quantum-initiative-law/">signed</a> National Quantum Initiative Act. We do, however, still need to find and build said devices…</p>
<p>
As for the status of (a), we don’t know any better thought for January than the Janus-like title of this <a href="https://arxiv.org/abs/1807.10749">paper</a> by Igor Markov, Aneeqa Fatima, Sergei Isakov, and Sergio Boixo: </p>
<blockquote><p><b> </b> <em> “Quantum Supremacy Is Both Closer and Farther than It Appears.” </em>
</p></blockquote>
<p>
</p><p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What are your predictions for 2019? What are the most important matters we’ve left unsaid?</p>
<p>
[added some words to end of intro]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/01/06/predictions-for-2019/"><span class="datestr">at January 06, 2019 07:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42163">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42163/immutable-space-model">Immutable Space Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have heard it said that time is more precious than space because we can reuse space but not time.  What if we treat space with this much reverence?</p>

<h3>What is generally known about models of computation in which space is immutable?</h3>

<p>I would expect such models to initialize each memory cell to some "blank" state and then only allow the writing of some "non-blank" value to each cell at most once.</p>

<p>The study of <a href="https://en.wikipedia.org/wiki/Persistent_data_structure" rel="noreferrer">persistent data structures</a> seems to me like a possible way to answer this question.</p>

<p>I thought of this question while studying functional programming, which highly values immutability.</p></div>







<p class="date">
by Tyson Williams <a href="https://cstheory.stackexchange.com/questions/42163/immutable-space-model"><span class="datestr">at January 06, 2019 03:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42161">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete">Is this partition problem strongly NP-complete?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Some computational problems have variants that appear to be harder. For instance, Graph Automorphism (GA) problem has quasi-polynomial time algorithm ( by Babai's Graph Isomorphism result) while the fixed-point free GA problem is NP-complete. </p>

<p><a href="https://en.wikipedia.org/wiki/Partition_problem" rel="nofollow noreferrer">Partition problem</a> is weakly NP-complete problem since it has pseudo-polynomial time algorithm. I am interested in variants that are strongly NP-complete.</p>

<p>Here is a variant of partition problem:</p>

<p>Restricted partition problem</p>

<p><strong>Input</strong>: Set <span class="math-container">$S$</span> of <span class="math-container">$2N$</span> integers, and a collection <span class="math-container">$P$</span> of pairs from <span class="math-container">$S$</span>, <span class="math-container">$0 \lt |P| \lt N$</span> </p>

<p><strong>Query</strong>: Is there a partition of <span class="math-container">$S$</span> into two equal cardinality parts <span class="math-container">$A$</span> and <span class="math-container">$S-A$</span> such that both parts have the same sum and no pair in <span class="math-container">$P$</span> has both elements in one side of the partition?</p>

<blockquote>
  <p>Is this variant of partition problem NP-complete in the strong sense? </p>
</blockquote>

<p>This was posted first on <a href="https://mathoverflow.net/questions/306039/is-this-partition-problem-strongly-np-complete">Math overflow</a> (I believe the posted answer is incorrect since the proposed dynamic programming algorithm does not take into consideration the cardinality of <span class="math-container">$P$</span>).</p></div>







<p class="date">
by Mohammad Al-Turkistany <a href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete"><span class="datestr">at January 06, 2019 12:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42160">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph">maximize edges minus vertices in a weighted graph</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>for a given weighted vertices and edges graph, we want to find the maximum subgraph. the maximum subgraph is made of some vertices and some edges of the given graph which sum of the edges minus sum of the vertices is maximum. what is the algorithm for this problem? or any help with the code please.</p></div>







<p class="date">
by andrew <a href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph"><span class="datestr">at January 06, 2019 11:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/003">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/003">TR19-003 |  Near-Optimal Lower Bounds on the Threshold Degree and Sign-Rank of AC^0 | 

	Alexander A. Sherstov, 

	Pei Wu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The threshold degree of a Boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is the minimum degree of a real polynomial $p$ that represents $f$ in sign: $\mathrm{sgn}\; p(x)=(-1)^{f(x)}.$ A related notion is sign-rank, defined for a Boolean matrix $F=[F_{ij}]$ as the minimum rank of a real matrix $M$ with $\mathrm{sgn}\; M_{ij}=(-1)^{F_{ij}}$.  Determining the maximum threshold degree and sign-rank achievable by constant-depth circuits ($\text{AC}^{0}$) is a well-known and extensively studied open problem, with complexity-theoretic and algorithmic applications.

We give an essentially optimal solution to this problem. For any $\epsilon&gt;0,$ we construct an $\text{AC}^{0}$ circuit in $n$ variables that has threshold degree $\Omega(n^{1-\epsilon})$ and sign-rank $\exp(\Omega(n^{1-\epsilon})),$ improving on the previous best lower bounds of $\Omega(\sqrt{n})$ and $\exp(\tilde{\Omega}(\sqrt{n}))$, respectively. Our results subsume all previous lower bounds on the threshold degree and sign-rank of $\text{AC}^{0}$ circuits of any given depth, with a strict improvement starting at depth $4$. As a corollary, we also obtain near-optimal bounds on the discrepancy, threshold weight, and threshold density of $\text{AC}^{0}$, strictly subsuming previous work on these quantities.  Our work gives some of the strongest lower bounds to date on the communication complexity of $\text{AC}^{0}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/003"><span class="datestr">at January 06, 2019 08:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/002">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/002">TR19-002 |  Complexity of Linear Operators | 

	Alexander Kulikov, 

	Ivan Mikhailin, 

	Vladimir Podolskii, 

	Andrey Mokhov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Let $A \in \{0,1\}^{n \times n}$ be a matrix with $z$ zeroes and $u$ ones and $x$ be an $n$-dimensional vector of formal variables over a semigroup $(S, \circ)$. How many semigroup operations are required to compute the linear operator $Ax$?

As we observe in this paper, this problem contains as a special case the well-known range queries problem and has a rich variety of applications in such areas as graph algorithms, functional programming, circuit complexity, and others. It is easy to compute $Ax$ using $O(u)$ semigroup operations. The main question studied in this paper is: can $Ax$ be computed using $O(z)$ semigroup operations? We prove that in general this is not possible: there exists a matrix $A \in \{0,1\}^{n \times n}$ with exactly two zeroes in every row (hence $z=2n$) whose complexity is $\Theta(n\alpha(n))$ where $\alpha(n)$ is the inverse Ackermann function. However, for the case when the semigroup is commutative, we give a constructive proof of an $O(z)$ upper bound. This implies that in commutative settings, complements of sparse matrices can be processed as efficiently as sparse matrices (though the corresponding algorithms are more involved). Note that this covers the cases of Boolean and tropical semirings that have numerous applications, e.g., in graph theory. 

As a simple application of the presented linear-size construction, we show how to multiply two $n\times n$ matrices over an arbitrary semiring in $O(n^2)$ time if one of these matrices is a 0/1-matrix with $O(n)$ zeroes (i.e., a complement of a sparse matrix).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/002"><span class="datestr">at January 06, 2019 05:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42159">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often">NuSMV - How to indicate the execution should visit some states infinitely often?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have the following kripke structure:</p>

<p><a href="https://i.stack.imgur.com/3xDPG.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/3xDPG.png" alt="enter image description here" /></a></p>

<p>I need my model to follow the LTL constraint that state d will be visited infinitely often:</p>

<pre><code>LTLSPEC  G F (modelState=d)
</code></pre>

<p>This constraint fails due to existence of the loop .... b-&gt;c-&gt;b-&gt;c ......  </p>

<p>Question: What would be a solution to this problem? This may be related to fair traces, but I am not very familiar with that, or how to indicate d as a fair state in NuSMV. </p>

<p>I am learning model checking on my own and I appreciate your help very much.</p></div>







<p class="date">
by Fabiana <a href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often"><span class="datestr">at January 06, 2019 05:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42158">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems">Best polynomial-time approximation factor for NP-optimization problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Let us say that a function <span class="math-container">$f(n)$</span> is the <strong>best approximation factor</strong> for an NP-optimization problem, if both of the following hold:</p>

<ol>
<li><p>There exist a polynomial-time algorithm <span class="math-container">$A,$</span> and an integer <span class="math-container">$n_0$</span>, such that <span class="math-container">$A$</span> provides an <span class="math-container">$f(n)$</span>-approximation for the NP-optimization problem for every instance with size <span class="math-container">$n\geq n_0$</span>. (Note: the role of <span class="math-container">$n_0$</span> is merely to treat potentially deviant small instances, which might make the function "ugly.")</p></li>
<li><p>There is no polynomial-time <span class="math-container">$(1-o(1))f(n)$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p></li>
</ol>

<p>A classic example where such a best approximation is known is the SET COVER problem (for a summary and references see its Wikipedia page): the Greedy Algorithm provides an <span class="math-container">$\ln n$</span> approximation, but there is no  <span class="math-container">$(1-o(1))\ln n$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p>

<p><strong>Questions:</strong></p>

<ol>
<li><p>Which are some other interesting NP-optimization problems for which a best approximation factor, along with its realizing algorithm, are known?  </p></li>
<li><p>Are there any counterexamples, i.e., NP-optimization problems, for which such a best approximation cannot exist, unless <span class="math-container">$P=NP$</span>?</p></li>
</ol></div>







<p class="date">
by Andras Farago <a href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems"><span class="datestr">at January 05, 2019 04:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1075">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1075">News for December 2018</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Happy near year, and best wishes to those close and \(\varepsilon\)-far! December concluded the year with 4 new preprints, spanning quite a lot of the property testing landscape:</p>



<p><strong>Testing Stability Properties in Graphical Hedonic Games</strong>, by Hendrik Fichtenberger and Anja Rey (<a href="https://arxiv.org/abs/1812.09249">arXiv</a>). The authors of this paper consider the problem of deciding whether a given <em>hedonic game</em>  possesses some “coalition stability” in a property testing framework. Namely, recall that a hedonic game is a game where players (nodes) form coalitions (subsets of nodes) based on their individual preferences and local information about the considered coalition, thus resulting in a partition of the original graph. <br /> Several notions exist to evaluate how good such a partition is, based on how “stable” the given coalitions are. This work focuses on hedonic games corresponding to bounded-degree graphs, introducing and studying the property testing question of deciding <em>(for several such notions of stability)</em> whether a given game admits a stable coalition structure, or is far from admitting such a partition.</p>



<p><strong>Spectral methods for testing cluster structure of graphs</strong>, by Sandeep Silwal and Jonathan Tidor (<a href="https://arxiv.org/abs/1812.11564">arXiv</a>). Staying among bounded-degree graphs, we turn to testing clusterability of graphs, the focus of this paper. Given an \(n\)-node graph \(G\) of degree at most \(d\) and parameters \(k, \phi\), say that \(G\) is \((k, \phi)\)-clusterable if it can be partitioned in \(k\) parts of inner conductance at least \(\phi\).<br />Analyzing properties of a random walk on \(G\), this work gives a bicriterion guarantee (\((k, \phi)\)-clusterable vs. \(\varepsilon\)-far from \((k, \phi^\ast)\)-clusterable, where \(\phi^\ast \approx \varepsilon^2\phi^2\)) for the case \(k=2\), improving on previous work by Czumaj, Peng, and Sohler’15.</p>



<p>We then switch from graphs to probability distributions with our third paper:</p>



<p><strong>Inference under Information Constraints I: Lower Bounds from Chi-Square Contraction</strong>, by Jayadev Acharya, Clément Canonne, and Himanshu Tyagi (<a href="https://arxiv.org/abs/1812.11476">arXiv</a>). <em>(Disclaimer: I’m one of the authors.)</em> In this paper, the first of an announced series of three, the authors generalize the settings of two previous works we covered <a href="https://ptreview.sublinear.info/?m=201805">here</a> and <a href="https://ptreview.sublinear.info/?m=201809">there</a> to consider the general question of distribution testing and learning when the \(n\) i.i.d. samples are distributed among \(n\) players, which each can only communicate their sample to the central algorithm by respecting some pre-specified local information constraint <em>(e.g., privacy, or noise, or communication budget)</em>. This paper develops a general lower bound framework to study such questions, with a systematic focus on the power of public vs. private randomness between the \(n\) parties, and instantiate it to obtain tight bounds in the aforementioned locally private and communication-limited settings. (Spoiler: public randomness strictly helps, but not always.)</p>



<p>Finally, after games, graphs, and distributions, our fourth paper of the month concerns testing of functions:</p>



<p><strong>Partial Function Extension with Applications to Learning and Property Testing</strong>, by Umang Bhaskar and Gunjan Kumar (<a href="https://arxiv.org/abs/1812.05821">arXiv</a>). This work focuses on a problem quite related to property testing, that of partial function extension: given as input \(n\) pairs point/value from a purported function on a domain \(X\) of size \(|X| &gt; n\), one is tasked with deciding whether there does exist (resp., with finding) a function  \(f\) on \(X\) consistent with these \(n\) values which further satisfies a specific property, such as linearity or convexity. This is indeed very reminiscent of property testing, where one gets to query these \(n\) points and must decide (approximate) consistency with such a well-behaved function. Here, the authors study the computational hardness of this partial function extension problem, specifically for properties such as subadditivity and XOS (a sub-property of subadditivity); and as corollaries obtain new property testers for the classes of subadditive and XOS functions.</p>



<p>As usual, if you know of some work we missed from last December, let us know in the comments!</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1075"><span class="datestr">at January 05, 2019 02:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42155">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1">Why can't a left-recursive, non-deterministic, or ambiguous grammar be LL(1)?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I've learned from several sources that an LL(1) grammar is:</p>

<ol>
<li>unambiguous,</li>
<li>not left-recursive,</li>
<li>and, deterministic (left-factorized).</li>
</ol>

<p>What I can't fully understand is why the above is true for any LL(1) grammar. I know the LL(1) parsing table will have multiple entries at some cells, but what I really want to get is a formal and general (not with an example) proof to the following proposition(s):</p>

<p>A left-recursive (1), non-deterministic (2), or ambiguous (3) grammar is not LL(1).</p></div>







<p class="date">
by Mr Geek <a href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1"><span class="datestr">at January 05, 2019 01:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/001">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/001">TR19-001 |  On OBDD-based algorithms and proof systems that dynamically change order of   variables | 

	Alexander Knop, 

	Dmitry Itsykson, 

	Dmitry Sokolov, 

	Andrei Romashchenko</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In 2004 Atserias, Kolaitis and Vardi proposed OBDD-based propositional proof systems that prove unsatisfiability of a CNF formula by deduction of identically false OBDD from OBDDs representing clauses of the initial formula. All OBDDs in such proofs have the same order of variables. We initiate the study of OBDD based proof systems that additionally contain a rule that allows changing the order in OBDDs. At first, we consider a proof system OBDD($\land$, reordering) that uses the conjunction (join) rule and the rule that allows changing the order. We exponentially separate this proof system from OBDD($\land$) proof system that uses only the conjunction rule. We prove two exponential lower bounds on the size of OBDD($\land$, reordering) refutations of Tseitin formulas and the pigeonhole principle. The first lower bound was previously unknown even for OBDD($\land$) proofs and the second one extends the result of Tveretina et al. from OBDD($\land$) to OBDD($\land$, reordering).

In 2004 Pan and Vardi proposed an approach to the propositional satisfiability problem based on OBDDs and symbolic quantifier elimination (we denote algorithms based on this approach as OBDD($\land$, $\exists$) algorithms). An instance of the propositional satisfiability problem is considered as an existential quantified propositional formula. The algorithm chooses an order on variables and creates an ordered binary decision diagram (OBDD) $D$ that initially represents the constant $1$ function. Then the algorithm downloads to $D$ clauses of the CNF one by one, and applies to $D$ the elimination of the existential quantifier for variable $x$ if all clauses that contain $x$ are already downloaded. We augment these algorithms with the operation of reordering of variables and call the new scheme OBDD($\land$, $\exists$, reordering) algorithms. We notice that there exists an OBDD($\land$, $\exists$) algorithm that solves satisfiable and unsatisfiable Tseitin formulas in polynomial time. In contrast, we show that there exist formulas representing systems of linear equations over $\mathbb{F}_2$ that are hard for OBDD($\land$, $\exists$, reordering)  algorithms. Our hard instances are satisfiable formulas representing systems of linear equations over $\mathbb{F}_2$ that
correspond to some checksum matrices of error correcting codes.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/001"><span class="datestr">at January 05, 2019 07:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42150">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com">Prove that if A is NP-complete and B is coNP-complete, than AxB is NP-, coNP-complete</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>AxB means cartesian product of A and B.</p>

<p>May someone help me with this? I even have no idea how to prove that AxB belongs to NP or coNP</p></div>







<p class="date">
by guest <a href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com"><span class="datestr">at January 04, 2019 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42148">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission">Feel dissatisfied after each submission</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am a third year graduate student at a "top-20" university who works on fine-grained complexity (lots of playing with 3-SUM, OV and the usual popular hardness conjectures). I have been fairly productive over the last year or so and have 3 accepted papers and two submitted papers. All of this to say that I am a fairly experienced graduate student and what I am about to describe is not anecdotal.</p>

<p>Every submission brings me more dissatisfaction than satisfaction. Just before I start working on a problem, me and my advisor identify a list of concrete questions that need to be answered. After lots of thinking, we have some very nice non-trivial results which gives me a lot of happiness and satisfaction. As we start to write down all of the results, inevitably, there are some more interesting variants that pop up but are much harder to make progress on. After the initial euphoria point, I feel everything seems to go downhill. There are so many variants that also need to be answered, are clearly in the purview of the problem at hand but I am not able to. By the time we submit the paper, I am so dismayed that results in the paper seem almost trivial. Perhaps this is simply tunnel vision, but I can't overcome the sadness about not being able to answer peripheral questions (although these make for a terrific conclusion section).</p>

<p>This has happened every single time and I am wondering if this is a common feeling. Do other people in theory community feel the same way? I am not sure if this is an academia wide feeling. My fellow graduate students from other areas are over the moon after every submission (but this is just anecdotal).</p>

<p>Edit - I see that there is another soft-question on the front page. I apologize for adding another one. Its holiday season and (only?) after a few drinks, one starts to ponder over these things!</p></div>







<p class="date">
by karmanaut <a href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission"><span class="datestr">at January 04, 2019 05:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1474">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/">On PAC Analysis and Deep Neural Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>Guest post by <a href="http://amitdaniely.com/">Amit Daniely</a> and <a href="https://cs.stanford.edu/~rfrostig/">Roy Frostig</a>.</em></p>
<p>For years now—especially since the landmark work of <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">Krishevsky et. al.</a>—learning deep neural networks has been a method of choice in prediction and regression tasks, especially in perceptual domains found in computer vision and natural language processing. How effective might it be for solving <em>theoretical</em> tasks?</p>
<p>Specifically, focusing on supervised learning:</p>
<blockquote><p>Can a deep neural network, paired with a stochastic gradient method, be shown to <a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning">PAC learn</a> any interesting concept class in polynomial time?</p></blockquote>
<p>Depending on assumptions, and on one’s definition of “interesting,” present-day learning theory gives answers ranging from “no, that would solve hard problems,” to, more recently:</p>
<blockquote><p><strong>Theorem:</strong> Networks with depth between 2 and <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />,<a href="https://theorydish.blog/feed/#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> having standard activation functions,<a href="https://theorydish.blog/feed/#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> with weights initialized at random and trained with stochastic gradient descent, learn, in polynomial time, constant degree large margin polynomial thresholds.</p></blockquote>
<p>Learning constant-degree polynomials can also be done simply <em>with a linear predictor</em> over a polynomial embedding, or, in other words, by learning a halfspace. That said, what a linear predictor can do is also <em>essentially the state of the art</em> in PAC learning, so this result pushes neural net learning at least as far as one might hope at first. We will return to this point later, and discuss some limitations of PAC analysis once they are more apparent. In this sense, this post will turn out to be as much an overview of some PAC learning theory as it is about neural networks.</p>
<p>Naturally, there is a wide variety of theoretical perspectives on neural network analysis, especially in the past couple of years. Our goal in this post is not to survey or cover any extensive body of work, but simply to summarize our own recent line (from two papers: <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">DFS’16</a> and <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">D’17</a>), and to highlight the interaction with PAC learning.</p>
<h2 id="neural-network-learning">Neural network learning</h2>
<p>First, let’s define a learning task. To keep things simple, we’ll focus on binary classification over the boolean cube, without noise. Formally:</p>
<blockquote><p><strong>(Binary classification.)</strong> Given examples of the form <img src="https://s0.wp.com/latex.php?latex=%28x%2Ch%5E%2A%28x%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(x,h^*(x))" class="latex" title="(x,h^*(x))" />, where <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> is sampled from some unknown distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" /> on <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" />, and <img src="https://s0.wp.com/latex.php?latex=h%5E%2A%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*:\{\pm 1\}^n\to\{\pm 1\}" class="latex" title="h^*:\{\pm 1\}^n\to\{\pm 1\}" /> is some unknown function (the one that we wish to learn), find a function <img src="https://s0.wp.com/latex.php?latex=h%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h:\{\pm 1\}^n\to\{\pm 1\}" class="latex" title="h:\{\pm 1\}^n\to\{\pm 1\}" /> whose error, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h%29+%3D+%5Cmathrm%7BPr%7D_%7Bx%5Csim%5Cmathcal%7BD%7D%7D+%5Cleft%28h%28x%29+%5Cne+h%5E%2A%28x%29%5Cright%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" class="latex" title="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" />, is small.</p></blockquote>
<p>Second, define a neural network <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal N" class="latex" title="\mathcal N" /> formally as a directed acyclic graph <img src="https://s0.wp.com/latex.php?latex=%28V%2C+E%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(V, E)" class="latex" title="(V, E)" /> whose vertices <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="V" class="latex" title="V" /> are called neurons. Of them, <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> are input neurons, one is an output neuron, and the rest are called hidden neurons.<a href="https://theorydish.blog/feed/#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> A network together with a weight vector <img src="https://s0.wp.com/latex.php?latex=w+%3D+%5C%7Bw_%7Buv%7D+%3A+uv+%5Cin+E%5C%7D+%5Ccup+%5C%7Bb_v+%3A+v+%5Cin+V+%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" class="latex" title="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" /> defines a predictor <img src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" class="latex" title="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" /> whose prediction is computed by propagating <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> forward through the network. Concretely:</p>
<ul>
<li>For an input neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" />, <img src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{v,w}(x)" class="latex" title="h_{v,w}(x)" /> is the corresponding coordinate in <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" />.</li>
<li>For a hidden neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" />, define<img src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29+%3D+%5Csigma%5Cleft%28+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28v%29%7D+w_%7Buv%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_v+%5Cright%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." class="latex" title="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." />The scalar weight <img src="https://s0.wp.com/latex.php?latex=b_v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b_v" class="latex" title="b_v" /> is called a “bias.” In this post, the function <img src="https://s0.wp.com/latex.php?latex=%5Csigma+%3A+%5Cmathbb%7BR%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sigma : \mathbb{R} \to \mathbb{R}" class="latex" title="\sigma : \mathbb{R} \to \mathbb{R}" /> is the ReLU activation <img src="https://s0.wp.com/latex.php?latex=%5Csigma%28t%29+%3D+%5Cmax%5C%7Bt%2C+0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sigma(t) = \max\{t, 0\}" class="latex" title="\sigma(t) = \max\{t, 0\}" />, though others are possible as well.</li>
<li>For the output neuron <img src="https://s0.wp.com/latex.php?latex=o&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="o" class="latex" title="o" />, we drop the activation: <img src="https://s0.wp.com/latex.php?latex=h_%7Bo%2Cw%7D%28x%29+%3D+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28o%29%7D+w_%7Buo%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_o&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" class="latex" title="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" />.</li>
</ul>
<p>Finally, let <img src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D%28x%29+%3D+h_%7Bo%2C+w%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{\mathcal N, w}(x) = h_{o, w}(x)" class="latex" title="h_{\mathcal N, w}(x) = h_{o, w}(x)" />. This computes a real-valued function, so where we’d like to use it for classification, we do so by thresholding, and abuse the notation <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h_w)" class="latex" title="\mathrm{Err}(h_w)" /> to mean <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28%5Cmathrm%7Bsign%7D+%5Ccirc+h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(\mathrm{sign} \circ h_w)" class="latex" title="\mathrm{Err}(\mathrm{sign} \circ h_w)" />.</p>
<p>Some intuition for this definition would come from verifying that:</p>
<ul>
<li>Any function <img src="https://s0.wp.com/latex.php?latex=h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h : \{\pm 1\}^n \to \{\pm 1\}" class="latex" title="h : \{\pm 1\}^n \to \{\pm 1\}" /> can be computed by a network of depth two and <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="2^n" class="latex" title="2^n" /> hidden neurons.</li>
<li>The parity function <img src="https://s0.wp.com/latex.php?latex=h%28x%29+%3D+%5Cprod_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h(x) = \prod_{i=1}^n x_i" class="latex" title="h(x) = \prod_{i=1}^n x_i" /> can be computed by a network of depth two and <img src="https://s0.wp.com/latex.php?latex=4n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="4n" class="latex" title="4n" /> hidden neurons. (NB: this one is a bit more challenging.)</li>
</ul>
<p>In practice, the network architecture (this DAG) is designed based on some domain knowledge, and its design can impact the predictor that’s later selected by SGD. One default architecture, useful in the absence of domain knowledge, is the multi-layer perceptron, comprised of layers of complete bipartite graphs:</p>
<figure><img width="431" alt="full_con_net" src="https://theorydish.files.wordpress.com/2019/01/full_con_net.png?w=431&amp;h=426" class="  wp-image-1479 aligncenter" height="426" />A toy “fully-connected neural network”, a.k.a. a multi-layer perceptronAnother paradigmatic architecture is a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional network</a>:<p></p>
</figure>
<figure><img width="490" alt="conv_net" src="https://theorydish.files.wordpress.com/2019/01/conv_net.png?w=490&amp;h=463" class="  wp-image-1478 aligncenter" height="463" />A toy convolutional neural network</figure>
<p>Convolutional nets capture the notion of spatial input locality in signals such as images and audio.<a href="https://theorydish.blog/feed/#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> In the toy example drawn, each clustered triple of neurons is a so-called convolution filter applied to two components below it. In image domains, convolutions filters are two-dimensional and capture responses to spatial 2-D patches of the image or of an intermediate layer.</p>
<p>Training a neural net comprises (i) initialization, and (ii) iterative optimization run until <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsign%7D%28h_w%28x%29%29+%3D+h%5E%2A%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{sign}(h_w(x)) = h^*(x)" class="latex" title="\mathrm{sign}(h_w(x)) = h^*(x)" /> for sufficiently many examples <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" />. The initialization step sets the starting values of the weights <img src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^0" class="latex" title="w^0" /> at random:</p>
<blockquote><p><strong>(Glorot initialization.)</strong> Draw weights <img src="https://s0.wp.com/latex.php?latex=%5C%7Bw%5E0_%7Buv%7D%5C%7D_%7Buv%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{w^0_{uv}\}_{uv\in E}" class="latex" title="\{w^0_{uv}\}_{uv\in E}" /> from centered Gaussians with variance <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathrm%7BIN%7D%28v%29%7C%5E%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="|\mathrm{IN}(v)|^{-1}" class="latex" title="|\mathrm{IN}(v)|^{-1}" /> and biases <img src="https://s0.wp.com/latex.php?latex=%5C%7Bb%5E0_%7Bv%7D%5C%7D_%7Bv%5Cin+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{b^0_{v}\}_{v\in V}" class="latex" title="\{b^0_{v}\}_{v\in V}" /> from independent standard Gaussians.<a href="https://theorydish.blog/feed/#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p></blockquote>
<p>While other initialization schemes exists, this one is canonical, simple, and, as the reader can verify, satisfies <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bw%5E0%7D%5Cleft%5B%28h_%7Bv%2Cw%5E0%7D%28x%29%29%5E2%5Cright%5D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" class="latex" title="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" /> for every neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" /> and input <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \in \{\pm 1\}^n" class="latex" title="x \in \{\pm 1\}^n" />.</p>
<p>The optimization step is essentially a local search method from the initial point, using <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> (SGD) or a variant thereof.<a href="https://theorydish.blog/feed/#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> To apply SGD, we need a function suitable for descent, and we’ll use the commonplace logistic loss <img src="https://s0.wp.com/latex.php?latex=%5Cell%28z%29+%3D+%5Clog_2%281%2Be%5E%7B-z%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\ell(z) = \log_2(1+e^{-z})" class="latex" title="\ell(z) = \log_2(1+e^{-z})" />, which bounds the zero-one loss <img src="https://s0.wp.com/latex.php?latex=%5Cell%5E%7B0-1%7D%28z%29+%3D+%5Cmathbf%7B1%7D%5Bz+%5Cle+0%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" class="latex" title="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" /> from above:</p>
<figure><img width="329" alt="losses" src="https://theorydish.files.wordpress.com/2019/01/losses.png?w=329&amp;h=246" class="  wp-image-1480 aligncenter" height="246" />The logistic and zero-one losses</figure>
<p> </p>
<p>Define <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D%28w%29+%3D+%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathcal+D%7D%5Cleft%5B+%5Cell%28h_w%28x%29h%5E%2A%28x%29%29+%5Cright%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" class="latex" title="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" />. Note that <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29+%5Cle+L_%7B%5Cmathcal+D%7D%28w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" class="latex" title="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" />, so finding weights <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w" class="latex" title="w" /> for which the upper bound <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}" class="latex" title="L_{\mathcal D}" /> is small enough implies low error in turn. Meanwhile, <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}" class="latex" title="L_{\mathcal D}" /> is amenable to iterative gradient-based minimization.</p>
<p>Given samples from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />, stochastic gradient descent creates an unbiased estimate of the gradient at each step <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="t" class="latex" title="t" /> by drawing a batch of i.i.d. samples <img src="https://s0.wp.com/latex.php?latex=S_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_t" class="latex" title="S_t" /> from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />. The gradient <img src="https://s0.wp.com/latex.php?latex=%5Cnabla+L_%7BS_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\nabla L_{S_t}" class="latex" title="\nabla L_{S_t}" /> at a point <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w" class="latex" title="w" /> can be computed efficiently by the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> algorithm.</p>
<p>In more complete detail, our prototypical neural network training algorithm is as follows. On input a network <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal N" class="latex" title="\mathcal N" />, an iteration count <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" />, a batch size <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b" class="latex" title="b" />, and a step size <img src="https://s0.wp.com/latex.php?latex=%5Ceta+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\eta &gt; 0" class="latex" title="\eta &gt; 0" />:</p>
<p><strong>Algorithm: <em>SGDNN</em></strong></p>
<ol type="1">
<li>Let <img src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^0" class="latex" title="w^0" /> be random weights sampled per Glorot initialization</li>
<li>For <img src="https://s0.wp.com/latex.php?latex=t+%3D+1%2C+%5Cldots%2C+T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="t = 1, \ldots, T" class="latex" title="t = 1, \ldots, T" />:
<ol type="1">
<li>Sample a batch <img src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D+%3D+%5C%7B%28x%5Et_1%2C+h%5E%2A%28x%5Et_1%29%29%2C+%5Cldots%2C+%28x%5Et_b%2C+h%5E%2A%28x%5Et_b%29%29%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" class="latex" title="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" />, where <img src="https://s0.wp.com/latex.php?latex=x%5Et_1%2C+%5Cldots%2C+x%5Et_b&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x^t_1, \ldots, x^t_b" class="latex" title="x^t_1, \ldots, x^t_b" /> are i.i.d. samples from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />.</li>
<li>Update <img src="https://s0.wp.com/latex.php?latex=w%5Et+%5Cgets+w%5E%7Bt-1%7D+-+%5Ceta+%5Cnabla+L_%7BS_t%7D%28w%5E%7Bt-1%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" class="latex" title="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" />, where<img src="https://s0.wp.com/latex.php?latex=L_%7BS_t%7D%28w%5E%7Bt-1%7D%29+%3D+b%5E%7B-1%7D+%5Csum_%7Bi%3D1%7D%5Eb+%5Cell%28h_%7Bw%7D%28x%5Et_i%29+h%5E%2A%28x%5Et_i%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" class="latex" title="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" />.</li>
</ol>
</li>
<li>Output <img src="https://s0.wp.com/latex.php?latex=w%5ET&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^T" class="latex" title="w^T" /></li>
</ol>
<h2 id="pac-learning">PAC learning</h2>
<p>Learning a predictor from example data is a general task, and a hard one in the worst case. We cannot efficiently (i.e. in <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{poly}(n)" class="latex" title="\mathrm{poly}(n)" /> time) compute, let alone learn, general functions from <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}" class="latex" title="\{\pm 1\}" />. In fact, any learning algorithm that is guaranteed to succeed in general (i.e. with any target predictor <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> over any data distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />) runs, in the worst case, in time exponential in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" />. This is true even for rather weak definitions of “success,” such as finding a predictor with error less than <img src="https://s0.wp.com/latex.php?latex=1%2F2+-+2%5E%7B-n%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1/2 - 2^{-n/2}" class="latex" title="1/2 - 2^{-n/2}" />, i.e. one that slightly outperforms a random guess.</p>
<p>While it is impossible to efficiently learn general functions under general distributions, it might still be possible to learn efficiently under some assumptions on the target <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> or the distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />. Charting out such assumptions is the realm of learning theorists: by now, they’ve built up a broad catalog of function classes, and have studied the complexity of learning when the target function is in each such class. Although their primary aim has been to develop theory, the potential guidance for practice is easy to imagine: if one’s application domain happens to be modeled well by one of these easily-learnable function classes, there’s a corresponding learning algorithm to consider as well.</p>
<p>The vanilla PAC model makes no assumptions on the data distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />, but it does assume the target <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> belongs to some simple, predefined class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H" class="latex" title="\mathcal H" />. Formally, a <em>PAC learning problem</em> is defined by a function class<a href="https://theorydish.blog/feed/#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H+%5Csubset+%5C%7B%5Cpm+1%5C%7D%5E%7B%5C%7B%5Cpm+1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" class="latex" title="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" />. A learning algorithm <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal A" class="latex" title="\mathcal A" /> <em>learns</em> the class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H" class="latex" title="\mathcal H" /> if, whenever <img src="https://s0.wp.com/latex.php?latex=h%5E%2A+%5Cin+%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^* \in \mathcal H" class="latex" title="h^* \in \mathcal H" />, and provided <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\epsilon &gt; 0" class="latex" title="\epsilon &gt; 0" />, it runs in time <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%281%2F%5Cepsilon%2C+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{poly}(1/\epsilon, n)" class="latex" title="\mathrm{poly}(1/\epsilon, n)" />, and returns a function of error at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, with probability at least 0.9. Note that:</p>
<ol type="1">
<li>The learning algorithm need not return a function from the learnt class.</li>
<li>The polynomial-time requirement means in particular that the learning algorithm cannot output a complete truth table, as its size would be exponential. Instead, it must output a short description of a hypothesis that can be evaluated in polynomial time.</li>
</ol>
<p>For a taste of the computational learning theory literature, here are some of the function classes studied by theorists over the years:</p>
<ol type="1">
<li><em>Linear thresholds (halfspaces):</em> functions that map a halfspace to 1 and its complement to -1. Formally, functions of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Ctheta%28%5Clangle+w%2C+x+%5Crangle%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \theta(\langle w, x \rangle)" class="latex" title="x \mapsto \theta(\langle w, x \rangle)" /> for some <img src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w \in \mathbb{R}^n" class="latex" title="w \in \mathbb{R}^n" />, where <img src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\theta(z) = 1" class="latex" title="\theta(z) = 1" /> when <img src="https://s0.wp.com/latex.php?latex=z+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="z &gt; 0" class="latex" title="z &gt; 0" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\theta(z) = -1" class="latex" title="\theta(z) = -1" /> when <img src="https://s0.wp.com/latex.php?latex=z+%5Cle+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="z \le 0" class="latex" title="z \le 0" />.</li>
<li><em>Large-margin linear thresholds:</em> for<img src="https://s0.wp.com/latex.php?latex=%5Crho%28z%29+%3D+%5Cbegin%7Bcases%7D+1+%26+z+%5Cge+1+%5C%5C+%2A+%26+-1+%5Cle+z+%5Cle+1+%5C%5C+-1+%26+z+%5Cle+-1+%5Cend%7Bcases%7D%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," class="latex" title="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," />the class<img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%28%5Clangle+w%2Cx+%5Crangle%29+%5Ctext%7B+with+%7D+%5C%7Cw%5C%7C_2%5E2+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." class="latex" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." /></li>
<li><em>Intersections of halfspaces:</em> functions that map an intersection of polynomially many halfspaces to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1" class="latex" title="1" /> and its complement to <img src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="-1" class="latex" title="-1" />.</li>
<li><em>Polynomial threshold functions:</em> thresholds of constant-degree polynomials.</li>
<li><em>Large-margin polynomial threshold functions:</em> the class</li>
</ol>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%5Cleft%28+%5Csum_%7BA+%5Csubset+%5Bn%5D%2C+%7CA%7C+%5Cle+O%281%29%7D+%5Calpha_A+%5Cprod_%7Bi+%5Cin+A%7D+x_i+%5Cright%29+%5C%3B%5Ctext%7B+with+%7D%5C%3B+%5Csum_%7BA%7D+%5Calpha%5E2_A+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." class="latex" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." /></p>
<ol type="1">
<li><em>Decision trees</em>, <em>deterministic automata</em>, and <em><a href="https://en.wikipedia.org/wiki/Disjunctive_normal_form">DNF</a> formulas</em> of polynomial size.</li>
<li><em>Monotone conjunctions:</em> functions that, for some <img src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A \subset [n]" class="latex" title="A \subset [n]" /> map <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1" class="latex" title="1" /> if <img src="https://s0.wp.com/latex.php?latex=x_i+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_i = 1" class="latex" title="x_i = 1" /> for all <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i \in A" class="latex" title="i \in A" />, and to <img src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="-1" class="latex" title="-1" /> otherwise.</li>
<li><em>Parities:</em> functions of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cprod_%7Bi+%5Cin+A%7D+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \prod_{i \in A} x_i" class="latex" title="x \mapsto \prod_{i \in A} x_i" /> for some <img src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A \subset [n]" class="latex" title="A \subset [n]" />.</li>
<li><em>Juntas:</em> functions that depend on at most <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" /> variables.</li>
</ol>
<p>Learning theorists look at these function classes and work to distinguish those that are efficiently learnable from those that are <em>hard</em> to learn. They establish hardness results by reduction from other computational problems that are conjectured to be hard, such as random XOR-SAT (though none today are conditioned outright on NP hardness); see for example <a href="https://arxiv.org/abs/1404.3378">these</a> <a href="https://arxiv.org/abs/1505.05800">two</a> results. Meanwhile, halfspaces are learnable by linear programming. Parities, or more generally, <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />-linear functions for a field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />, are learnable by Gaussian elimination. In turn, via reductions, many other classes are efficiently learnable. This includes polynomial thresholds, decision lists, and more. To give an idea of what’s known in the literature, here is an artist’s depiction of some of what’s currently known:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/classes.png?w=620" alt="classes" class=" size-full wp-image-1477 aligncenter" />Learnable and conjectured hard-to-learn function classes</figure>
<p> </p>
<p>At a high-level, the upshot from all of this—and if you take away just one thing from this quick tour of PAC—is that:</p>
<blockquote><p>Barring a small handful of exceptions, all known efficiently learnable classes can be reduced to halfspaces or <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />-linear functions.</p></blockquote>
<p>Or, to put it more bluntly, <strong>the state of the art in PAC-learnability is essentially linear prediction</strong>.</p>
<h2 id="pac-analyzing-neural-nets">PAC analyzing neural nets</h2>
<p>Research in algorithms and complexity often follows these steps:</p>
<ol type="1">
<li>define a computational problem,</li>
<li>design an algorithm that solves it, and then</li>
<li>establish bounds on the resource requirements of that algorithm.</li>
</ol>
<p>A bound on the algorithm’s performance forms, in turn, a bound on the <em>computational problem’s</em> inherent complexity.</p>
<p>By contrast, we have already decided on our SGDNN algorithm, and we’d like to attain some grasp on its capabilities. So we’d like to do things in a different order:</p>
<ol type="1">
<li>define an <em>algorithm</em> (done),</li>
<li>design a computational problem to which the algorithm can be applied, and then</li>
<li>establish bounds on the resource requirements of the algorithm in solving the problem.</li>
</ol>
<p>Our computational problem will be a PAC learning problem, corresponding to a function class. For SGDNN, an ambitious function class we might consider is the class of all functions realizable by the network. But if we were to follow this approach, we would run up against the same hardness results mentioned before.</p>
<p>So instead, we’ve established the theorem stated at the top of this post. That is, that SGDNN, over a range of network configurations, learns a class that we <em>already know</em> to be learnable: large margin polynomial thresholds. Restated:</p>
<blockquote><p><strong>Theorem, again:</strong> There is a choice of SGDNN step size <img src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\eta" class="latex" title="\eta" /> and number of steps <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" />, as well as a with parameter <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="r" class="latex" title="r" />, where <img src="https://s0.wp.com/latex.php?latex=T%2C+r+%5Cle+%5Cmathrm%7Bpoly%7D%28n%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T, r \le \mathrm{poly}(n/\epsilon)" class="latex" title="T, r \le \mathrm{poly}(n/\epsilon)" />, such that SGDNN on a multi-layer perceptron of depth between 2 and <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />, and of width<a href="https://theorydish.blog/feed/#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="r" class="latex" title="r" />, learns large magin polynomials.</p></blockquote>
<p>How rich are large margin polynomials? They contain disjunctions, conjunctions, DNF and <a href="https://en.wikipedia.org/wiki/Conjunctive_normal_form">CNF</a> formulas with a constant many terms, DNF and CNF formulas with a constant many literals in each term. By corollary, SGDNN can PAC learn these classes as well. And at this point, we’ve covered a considerable fraction of the function classes known to be poly-time PAC learnable by <em>any</em> method.</p>
<p>Exceptions include constant-degree polynomial thresholds with no restriction on the coefficients, decision lists, and parities. It is well known that SGDNN cannot learn parities, and in ongoing work with Vitaly Feldman, we show that SGDNN cannot learn decision lists nor constant-degree polynomial thresholds with unrestricted coefficients. So the picture becomes more clear:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/classes_nn.png?w=620" alt="classes_nn" class=" size-full wp-image-1476 aligncenter" />Conjectured hard-to-learn classes, known learnable classes, and those known to be learnable by SGDNN.</figure>
<p> </p>
<p>The theorem above runs SGDNN with a multi-layer perceptron. What happens if we change the network architecture? It can be shown then that SGDNN learns a qualitatively different function class. For instance, with convolutional networks, the learnable functions include certain polynomials of <em>super-constant</em> degree.</p>
<h3 id="a-word-on-the-proof">A word on the proof</h3>
<p>The path to the theorem traverses two papers. There’s a corresponding outline for the proof.</p>
<p>The first step is to show that, with high probability, the Glorot random initialization renders the network in a state where the final hidden layer (just before the output node) is rich enough to approximate all large-margin polynomial threshold functions (LMPTs). Namely, every LMPT can be approximated by the network up to some setting of the weights that enter the output neuron (all remaining weights random). The tools for this part of the proof include (i) the connection between kernels and random features, (ii) a characterization of symmetric kernels of the sphere, and (iii) a variety of properties of Hermite polynomials. It’s described in our <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">2016 paper</a>.</p>
<p>An upshot of this correspondence is that if we run SGD <em>only on the top layer</em> of a network, leaving the remaining weights as they were randomly initialized, we learn LMPTs. (Remember when we said that we won’t beat what a linear predictor can do? There it is again.) The second step of the proof, then, is to show that the correspondence continues to hold even if we train all the weights. In the assumed setting (e.g. provided at most logarithmic depth, sufficient width, and so forth), what’s represented in the final hidden layer changes sufficiently slowly that, over the course of SGDNN’s iterations, it <em>remains</em> rich enough to approximate all LMPTs. The final layer does the remaining work of picking out the right LMPT. The argument is in Amit’s <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">2017 paper</a>.</p>
<h2 id="pacing-up">PACing up</h2>
<p>To what extent should we be satisfied, knowing that our algorithm of interest (SGDNN) can solve a (computationally) easy problem?</p>
<p>On the positive side, we’ve managed to say something at all about neural network training in the PAC framework. Roughly speaking, some class of non-trivially layered neural networks, trained as they typically are, learns any known learnable function class that isn’t “too sensitive.” It’s also appealing that the function classes vary across different architectures.</p>
<p>On the pessimistic side, we’re confronted to a major limitation on the “function class” perspective, prevalent in PAC analysis and elsewhere in learning theory. All of the classes that SGDNN learns, <em>under the assumptions</em> touched on in this post, are so-called large-margin classes. Large-margin classes are essentially linear predictors over a <em>fixed and data-independent</em> embedding of input examples, as alluded to before. These are inherently “shallow models.”</p>
<p>That seems rather problematic in pursuing any kind of theory for learning layered networks, where the entire working premise is that a deep network uses its hidden layers to learn a representation adapted to the example domain. Our analysis—both its goal and its proof—clash with this intuition: it works out that a “shallow model” can be learned when assumptions imply that “not too much” change takes place in hidden layers. It seems that the representation learning phenomenon is what’s interesting, yet the typical PAC approach, as well as the analysis touched on in this post, all avoid capturing it.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1">Here <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> is the dimension of the instance space.<a href="https://theorydish.blog/feed/#fnref1"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn2">For instance, ReLU activations, of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cmax%5C%7Bx%2C0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \max\{x,0\}" class="latex" title="x \mapsto \max\{x,0\}" />.<a href="https://theorydish.blog/feed/#fnref2"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn3">Recurrent networks allow for cycles, but in this post we stick to DAGs.<a href="https://theorydish.blog/feed/#fnref3"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn4">Convolutional networks often also constrain subsets of their weights to be equal; that turns out not to bear much on this post.<a href="https://theorydish.blog/feed/#fnref4"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn5">Although not essential to the results described, it also simplifies this post to zero the weights on edges incident to the output node as part of the initialization.<a href="https://theorydish.blog/feed/#fnref5"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn6"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants">Variants of SGD</a> are used in practice, including algorithms used elsewhere in optimization (e.g. <a href="https://distill.pub/2017/momentum/">SGD with momentum</a>, <a href="http://www.jmlr.org/papers/v12/duchi11a.html">AdaGrad</a>) or techniques developed more specifically for neural nets (e.g. RMSprop, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="https://arxiv.org/abs/1502.03167">batch norm</a>). We’ll stick to plain SGD.<a href="https://theorydish.blog/feed/#fnref6"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn7">More accurately, a sequence of function classes <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H_n" class="latex" title="\mathcal H_n" /> for <img src="https://s0.wp.com/latex.php?latex=n+%3D+1%2C+2%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n = 1, 2, \ldots" class="latex" title="n = 1, 2, \ldots" />.<a href="https://theorydish.blog/feed/#fnref7"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn8">The width of a multi-layer perceptron is the number of neurons in each hidden layer.<a href="https://theorydish.blog/feed/#fnref8"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
</ol>
</section></div>







<p class="date">
by amitdanielymailhujiacil <a href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/"><span class="datestr">at January 04, 2019 03:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42145">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications">Grid-Minor Theorem of Robertson and Seymour and its Algorithmic Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Graph-Minor Theorem of Robertson and Seymour [<a href="https://www.sciencedirect.com/science/article/pii/S0095895684710732" rel="nofollow noreferrer">1</a>] states that if graph G has large treewidth, then it contains a large grid as minor. Most approximation results on general classes of graphs with excluded minors make heavy use of Robertson and Seymour’s structure theory for graphs with excluded minors, especially when the treewidth is large (small treewidth usually makes problem to be easily solved by dynamic programming) [<a href="http://chekuri.cs.illinois.edu/talks/NIPS-Tutorial.pdf" rel="nofollow noreferrer">2</a>]. </p>

<p>However, there are some results are trying to avoid using the grid minor theorem. For example, Chekuri and Chuzhoy [<a href="https://arxiv.org/abs/1304.1577" rel="nofollow noreferrer">3</a>] show a framework for using theorems to bypass the well-known Grid-Minor Theorem of Robertson and Seymour in some applications. In particular, this leads to substantially improved parameters in some Erdos-Posa-type results, and faster running times for algorithms for some fi�xed parameter tractable problems.</p>

<p>Do you know any other examples of problems with large treewidth avoid using the grid minor theorem? </p></div>







<p class="date">
by Rupei Xu <a href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications"><span class="datestr">at January 04, 2019 09:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7217">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/01/03/quantum-games/">Quantum Games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Nilin Abrahamsen <font face="courier new">nilin@mit.edu</font>
</p><p>Daniel Alabi <font face="courier new">alabid@g.harvard.edu</font>
</p><p>Mitali Bafna <font face="courier new">mitalibafna@g.harvard.edu</font>
</p><p>Emil Khabiboulline <font face="courier new">ekhabiboulline@g.harvard.edu</font>
</p><p>Juspreet Sandhu <font face="courier new">jus065@g.harvard.edu</font>

<br />
<br />
Two-prover one-round (2P-1R) games have been the subject of intensive study in classical complexity theory and quantum information theory. In a 2P-1R game, a <em>verifier</em> sends questions privately to each of two collaborating <em>provers</em> , who then aim to respond with a compatible pair of answers without communicating with each other. Sharing quantum entanglement allows the provers to improve their strategy without any communication, illustrating an apparent paradox of the quantum postulates. These notes aim to give an introduction to the role of entanglement in nonlocal games, as they are called in the quantum literature. We see how nonlocal games have rich connections within computer science and quantum physics, giving rise to theorems ranging from hardness of approximation to the resource theory of entanglement.
</p><h2>Introduction</h2>
In these notes we discuss 2-prover 1-round games and the classical complexity of approximating the value of such games in the setting where the provers can share entanglement. That is, given the description of a game, we ask how hard it is to estimate the winning probability of the best winning strategy of the entangled provers. Let us first formally define games and its relation to the label cover problem. We write <img src="https://s0.wp.com/latex.php?latex=%7B+%5Bn%5D%3D%5C%7B1%2C%5Cldots%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ [n]=\{1,\ldots,n\}}" class="latex" title="{ [n]=\{1,\ldots,n\}}" />.
<h4>Definition (Label cover)</h4>
<em> A label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%3D%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I=(S,T,\Sigma,\Pi)}" class="latex" title="{ I=(S,T,\Sigma,\Pi)}" /> consists of variable sets <img src="https://s0.wp.com/latex.php?latex=%7B+S%3D%5C%7Bs_i%5C%7D_%7Bi%5Cin%5Bn%5D%7D%2CT%3D%5C%7Bt_j%5C%7D_%7Bj%5Cin%5Bn%5D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" class="latex" title="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" />, alphabet set <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma}" class="latex" title="{ \Sigma}" />, and a collection <img src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Pi}" class="latex" title="{ \Pi}" /> of constraints of the form <img src="https://s0.wp.com/latex.php?latex=%7B+t_j%3Df_%7Bi%2Cj%7D%28s_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_j=f_{i,j}(s_i)}" class="latex" title="{ t_j=f_{i,j}(s_i)}" />. Given an assignment (or coloring) <img src="https://s0.wp.com/latex.php?latex=%7B+c+%3A+S%5Ccup+T+%5Crightarrow+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c : S\cup T \rightarrow \Sigma}" class="latex" title="{ c : S\cup T \rightarrow \Sigma}" /> we define its value to be <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28c%29%3D%5Cmathbb+P_%7Bf_%7Bij%7D%5Csim%5CPi%7D%5Cbig%28c%28t_j%29%3Df_%7Bij%7D%28c%28s_i%29%29%5Cbig%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" class="latex" title="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" />. Define the value of <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" /> to be the maximum over all possible assignments, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29+%3D+%5Cmax_%7Bc%7D+%5Comega%28c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(I) = \max_{c} \omega(c)}" class="latex" title="{ \omega(I) = \max_{c} \omega(c)}" />. </em>



Many familiar computational problems can be formulated as a label cover, such as <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3SAT%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{3SAT}}" class="latex" title="{ \textsc{3SAT}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3Lin%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{3Lin}}" class="latex" title="{ \textsc{3Lin}}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7BMaxCut%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{MaxCut}}" class="latex" title="{ \textsc{MaxCut}}" />.
<figure style="width: 11em; margin: auto;">

<a href="https://windowsontheory.org/?attachment_id=7236"><img width="110" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/labelcover.png?w=110&amp;h=150" class="attachment-thumbnail size-thumbnail" height="150" /></a>
Label cover graph</figure>
<h4>Definition (2-prover 1-round game)</h4>
<em> Let <img src="https://s0.wp.com/latex.php?latex=%7B+I+%3D+%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I = (S,T,\Sigma,\Pi)}" class="latex" title="{ I = (S,T,\Sigma,\Pi)}" /> be a label cover instance. We can then associate the following two-prover one-round game <img src="https://s0.wp.com/latex.php?latex=%7B+G%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G(I)}" class="latex" title="{ G(I)}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B+P_1%2CP_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_1,P_2}" class="latex" title="{ P_1,P_2}" /> be two provers who cannot communicate, and let <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" /> be the verifier. Given the label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" />, the verifier uniformly samples a constraint <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bi%2Cj%7D+%5Cin+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{i,j} \in \Pi}" class="latex" title="{ f_{i,j} \in \Pi}" /> and sends <img src="https://s0.wp.com/latex.php?latex=%7B+s_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s_i}" class="latex" title="{ s_i}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+P_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_1}" class="latex" title="{ P_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_j}" class="latex" title="{ t_j}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+P_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_2}" class="latex" title="{ P_2}" />. The provers then reply with <img src="https://s0.wp.com/latex.php?latex=%7B+a+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a \in \Sigma}" class="latex" title="{ a \in \Sigma}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%5Cin%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b\in\Sigma}" class="latex" title="{ b\in\Sigma}" /> respectively to <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" />. Finally, <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" /> outputs <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%7B+b+%3D+f_%7Bi%2Cj%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b = f_{i,j}(a)}" class="latex" title="{ b = f_{i,j}(a)}" />. </em>


<figure style="width: 25em; margin: auto;">
 
<a href="https://windowsontheory.org/?attachment_id=7235"><img width="150" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/game.png?w=150&amp;h=104" class="attachment-thumbnail size-thumbnail" height="104" /></a>


The game view of label cover</figure>
Any coloring of the label cover instance corresponds to a deterministic strategy for the corresponding game. Therefore, with an optimal strategy the provers win the game associated to label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(I)}" class="latex" title="{ \omega(I)}" />. That is, the value of the game equals that of the label cover instance. However, this is with the assumption that provers can only use deterministic strategies or convex combinations of these (that is, using shared randomness). If the provers share an entangled quantum state, then the provers (who still cannot communicate) can enjoy correlations that allow them to win with a higher probability than classically. In the quantum literature, these 2P-1R games are known as nonlocal games referring to the fact that the correlations arise without signaling between the provers. We are concerned with the complexity of approximating the winning probability of this strategy.

We refer to the optimal winning probability within some class (classical or entangled) of strategies as the classical and quantum value of the game, respectively, and we use the terms quantum strategy and entangled strategy interchangeably.

Fixing different constraint families in the label cover game changes the complexity of finding the (classical and entangled) values of the game. We will show that approximating the entangled value of XOR games, or more generally <em>unique games</em> (to be defined later on), is possible in polynomial time. This is remarkable because a famous conjecture known as the <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture"> <em>unique games conjecture</em> </a> says that approximating the classical value of unique games is NP-hard. In contrast, we will see that for unrestricted edge constraints, it is NP-hard to approximate the entangled value of a nonlocal game. Thus, hardness of approximation of the game’s value, established by the celebrated <em>PCP theorem</em> , still applies in the presence of entanglement. In the quantum world, we have new complexity classes such as QMA (which can be regarded as “quantum NP”), so one may conjecture whether approximating the entangled value of a general game is QMA-hard (the games formulation of the <em>quantum PCP conjecture</em> ). We will indicate progress in this direction but will explicitly demonstrate the NP-hardness result.

Entanglement is often regarded as an expensive resource in quantum information because it is difficult to produce and maintain. Hence, even if sharing entanglement can improve the success probability of winning a game, the resource consumption may be costly. We will conclude by discussing lower bounds on the number of shared entangled bits required to achieve the optimal value of a game.
<h2>Notation and quantum postulates</h2>
Let us first establish notation and define what is meant by an entangled strategy. In keeping with physics notation we write a column vector as <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v}\rangle \in\mathbb C^d}" class="latex" title="{ |{v}\rangle \in\mathbb C^d}" /> and its conjugate-transpose (a row vector) as <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{v}| }" class="latex" title="{ \langle{v}| }" /> . More generally the conjugate-transpose (Hermitian conjugate) of a matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is written <img src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^\dag}" class="latex" title="{ A^\dag}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+w%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{v}| w\rangle}" class="latex" title="{ \langle{v}| w\rangle}" /> is the inner product of two vectors (a scalar) and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Clangle%7Bw%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v}\rangle \langle{w}| }" class="latex" title="{ |{v}\rangle \langle{w}| }" /> the outer product (a rank-1 matrix). A matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is said to be <em>Hermitian</em> if <img src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%3DA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^\dag=A}" class="latex" title="{ A^\dag=A}" />. A matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is <em>positive semidefinite</em> , written <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Csucceq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A\succeq 0}" class="latex" title="{ A\succeq 0}" />, if <img src="https://s0.wp.com/latex.php?latex=%7B+A%3DB%5E%5Cdag+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A=B^\dag B}" class="latex" title="{ A=B^\dag B}" /> for some matrix <img src="https://s0.wp.com/latex.php?latex=%7B+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B}" class="latex" title="{ B}" />. We write the identity matrix as <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathbb{I}}}" class="latex" title="{ {\mathbb{I}}}" />, denote by <img src="https://s0.wp.com/latex.php?latex=%7B+Herm%28%5Cmathbb%7BC%7D%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ Herm(\mathbb{C}^d)}" class="latex" title="{ Herm(\mathbb{C}^d)}" /> the set of <img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" /> Hermitian matrices.
<h3> Observables, states, and entanglement</h3>
In a quantum theory the <em>observables</em> are Hermitian operators <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Cin+Herm%28%5Cmathbb+C%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A\in Herm(\mathbb C^d)}" class="latex" title="{ A\in Herm(\mathbb C^d)}" /> on a vector space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" />. It then makes sense to say that a <em>state</em> is a functional <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varphi}" class="latex" title="{ \varphi}" /> on the set of observables. That is, to specify the state of a physical system means giving a (expected) value for each observable. It turns out states are <em>linear</em> functionals of the observables, and such functionals can be written <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%28A%29%3D%5Clangle+A%2C%5Crho%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varphi(A)=\langle A,\rho\rangle}" class="latex" title="{ \varphi(A)=\langle A,\rho\rangle}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" />. We call <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> the density matrix and require moreover that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> is positive semidefinite and has trace <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" />. Every density matrix is a convex combination of rank-one projections <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Clangle%5Cpsi%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\langle\psi|}" class="latex" title="{ |\psi\rangle\langle\psi|}" /> known as pure states. The unit vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" title="{ |\psi\rangle\in\mathbb C^d}" /> are also themselves known as pure states.

If the state of one particle is described by a vector in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> (referring here to pure states), then two particles are described by a vector in the tensor product <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ \mathbb C^d\otimes\mathbb C^d}" />. The two particles are entangled if their state is not in the form of a pure tensor <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cotimes%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle\otimes|\psi\rangle}" class="latex" title="{ |\phi\rangle\otimes|\psi\rangle}" />. We also write product states as <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle|\psi\rangle}" class="latex" title="{ |\phi\rangle|\psi\rangle}" />, omitting the tensor symbol.
<h3> Quantum measurements</h3>
A quantum measurement can be described in terms of a <em>projection-valued measure</em> (PVM).
<b>Definition 1 (PVM)</b> <em><a name="measurement"></a> A projection-valued measure on vector space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> (where the quantum states live) is a list of projection matrices <img src="https://s0.wp.com/latex.php?latex=%7B+A_1%2C%5Cldots%2CA_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_1,\ldots,A_k}" class="latex" title="{ A_1,\ldots,A_k}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B+A_iA_j%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_iA_j=0}" class="latex" title="{ A_iA_j=0}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\neq j}" class="latex" title="{ i\neq j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_i+A_i%3D%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_i A_i={\mathbb{I}}}" class="latex" title="{ \sum_i A_i={\mathbb{I}}}" />. The PVM describes a measurement which, on state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" title="{ |\psi\rangle\in\mathbb C^d}" /> outputs measurement outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cpsi%7C+A_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\psi| A_i|\psi\rangle}" class="latex" title="{ \langle\psi| A_i|\psi\rangle}" />. The quantum state after obtaining outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%5C%7CA_i%7C%5Cpsi%5Crangle%5C%7C%7DA_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" class="latex" title="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" />. </em>
When the projections are rank-one projections <img src="https://s0.wp.com/latex.php?latex=%7B+A_i%3D+%7C%7B%5Cbeta_i%7D%5Crangle+%5Clangle%7B%5Cbeta_i%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" class="latex" title="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" /> we say that we measure in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_i%7D%5Crangle+%5C%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_i}\rangle \}_i}" class="latex" title="{ \{ |{\beta_i}\rangle \}_i}" />. In this case the probability of outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> in state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle}" class="latex" title="{ |\psi\rangle}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_i+%7C%7B%5Cpsi%7D%5Crangle+%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\langle\beta_i |{\psi}\rangle |^2}" class="latex" title="{ |\langle\beta_i |{\psi}\rangle |^2}" />, and the post-measurement state is simply <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_i%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_i}\rangle}" class="latex" title="{ |{\beta_i}\rangle}" /> .

Applying the measurement <img src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%29_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A_i)_i}" class="latex" title="{ (A_i)_i}" /> on the left half of a two-particle state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5CPsi%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" /> means applying the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A_i\otimes {\mathbb{I}})_{i}}" class="latex" title="{ (A_i\otimes {\mathbb{I}})_{i}}" /> on the two-particle state.
<h3> Quantum strategies for nonlocal games</h3>
We now introduce the notion of a quantum strategy for a nonlocal game. Each prover holds a particle, say with state space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" />, and Alices particle may be entangled with Bob’s. The global state is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" />. Each player receives a question from the verifier and then chooses a measurement (a PVM) depending on the question. The player applies the measurement to their own particle and responds to the verifier with their measurement outcome. Hence for Alice we specify <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cin+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\in S}" class="latex" title="{ s\in S}" /> is a question, and each PVM is a list <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_%7Ba%3D1%7D%2C%5Cldots%2CA%5Es_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_{a=1},\ldots,A^s_k}" class="latex" title="{ A^s_{a=1},\ldots,A^s_k}" />. By definition <a href="https://windowsontheory.org/feed/#measurement">1</a>, given questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t}" class="latex" title="{ s,t}" /> the probability that Alice outputs <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and Bob outputs <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> is <a name="Qstrategy"></a>

<a name="Qstrategy">
</a><a name="Qstrategy"></a>
<p align="center"><a name="Qstrategy"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28a%2Cb%7Cs%2Ct%29%3D%5C%7C%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b%29%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5C%7C%5E2%3D+%5Clangle%7B%5Cphi%7D%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" class="latex" title="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" /></a></p>
<a name="Qstrategy">
</a><a name="Qstrategy"></a> where we have used that squaring a projection leaves it unchanged.
<h2>Quantum strategies beat classical ones</h2>
For any 2P-1R game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" />, let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" /> be the maximum probability — over the players’ classical strategies — that the verifier accepts and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> the maximum probability that the verifier accepts when the provers use qubits such that player 1’s qubits are entangled with those of player 2.

The game of Clauser, Horne, Shimony, and Holt (CHSH) has the property that the provers can increase their chance of winning by sharing an entangled pair of qubits, even when no messages are exchanged between the players. We show that there’s a characterization of the CHSH game’s value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29+%3D+%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" class="latex" title="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" /> which is better than the classical value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%5Cleq+%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)\leq \frac{3}{4}}" class="latex" title="{ \omega(G)\leq \frac{3}{4}}" />. Let us first define XOR games, of which the CHSH game is a special case.
<h4>Definition (XOR game)</h4>
<em> An XOR game is a 2-player classical game (the questions and answers are classical bits) where: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> Questions <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%5Cin%5C%7B0%2C+1%2C+%5Cldots%2C+n-1%5C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" class="latex" title="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" /> are asked according to some distribution <img src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Pi}" class="latex" title="{ \Pi}" /> (e.g. uniform).</li>
 	<li> Answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a, b\in\{0, 1\}}" class="latex" title="{ a, b\in\{0, 1\}}" /> are provided by players (call them Alice and Bob).</li>
 	<li> The verifier computes a predicate <img src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b%7Cs%2C+t%29+%3D+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" class="latex" title="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" /> used to decide acceptance/rejection.</li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>


<h4>Definition (CHSH Game)</h4>
<em> An XOR game with <img src="https://s0.wp.com/latex.php?latex=%7B+n%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n=2}" class="latex" title="{ n=2}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in\{0, 1\}}" class="latex" title="{ s, t\in\{0, 1\}}" /> are independent random bits and <img src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b+%7C+s%2C+t%29%3D1+%5CLongleftrightarrow+a%5Coplus+b+%3D+s%5Cwedge+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" class="latex" title="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" />. </em>



To win the CHSH game, Alice and Bob need to output bits <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> (from Alice) and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> (from Bob) that disagree if <img src="https://s0.wp.com/latex.php?latex=%7B+s%3Dt%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=t=1}" class="latex" title="{ s=t=1}" /> and agree otherwise.

If Alice and Bob are classical then they can do no better than by always outputting <img src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0}" class="latex" title="{ 0}" />, say, in which case they win in the three out of four cases when one of the questions is <img src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0}" class="latex" title="{ 0}" />. Equivalently, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%3D%5Cfrac34%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)=\frac34}" class="latex" title="{ \omega(G)=\frac34}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> is the CHSH game. This is the content of <em>Bell’s inequality</em> :
<h4>Lemma (Bell’s Inequality)</h4>
<em> For any two functions <img src="https://s0.wp.com/latex.php?latex=%7B+g%2C+h%3A+%5C%7B0%2C+1%5C%7D%5Crightarrow%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" class="latex" title="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" />, we have </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D+%5Cleq+%5Cfrac%7B3%7D%7B4%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" class="latex" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" /></em>

<em>
</em><em></em><em> where <img src="https://s0.wp.com/latex.php?latex=%7B+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x}" class="latex" title="{ x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ y}" class="latex" title="{ y}" /> are independent uniformly random bits. </em>



<em><br /><b>Proof.</b></em> The probability of any event is a multiple of <img src="https://s0.wp.com/latex.php?latex=%7B+1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1/4}" class="latex" title="{ 1/4}" /> so it suffices to show that <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D%5Cneq1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" class="latex" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" />. So assume for contradiction that <img src="https://s0.wp.com/latex.php?latex=%7B+g%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(x)\oplus h(y) = x\wedge y}" class="latex" title="{ g(x)\oplus h(y) = x\wedge y}" /> for all pairs <img src="https://s0.wp.com/latex.php?latex=%7B+x%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x,y}" class="latex" title="{ x,y}" />. Then we have that <img src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(0)\oplus h(0) = 0}" class="latex" title="{ g(0)\oplus h(0) = 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%281%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(0)\oplus h(1) = 0}" class="latex" title="{ g(0)\oplus h(1) = 0}" /> which implies that <img src="https://s0.wp.com/latex.php?latex=%7B+h%280%29%3Dh%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ h(0)=h(1)}" class="latex" title="{ h(0)=h(1)}" />. But then <img src="https://s0.wp.com/latex.php?latex=%7B+0%3Dg%281%29%5Coplus+h%280%29+%3Dg%281%29%5Coplus+h%281%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" class="latex" title="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" /> which is a contraction. 
<div align="right">□</div>
<h3> The strategy</h3>
The entangled strategy for the CHSH game requires that Alice and Bob each hold a qubit, so that their two qubits together are described by a vector in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E2%5Cotimes%5Cmathbb+C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^2\otimes\mathbb C^2}" class="latex" title="{ \mathbb C^2\otimes\mathbb C^2}" />. The two qubits together are in the state

<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B0%7D%5Crangle+_A+%7C%7B0%7D%5Crangle+_B+%2B+%7C%7B1%7D%5Crangle+_A+%7C%7B1%7D%5Crangle+_B%5Cright%29%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" class="latex" title="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" />

forming what is known as an EPR (Einstein-Podolsky-Rosen) pair. Now for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctheta%5Cin%5B-%5Cpi%2C+%5Cpi%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \theta\in[-\pi, \pi]}" class="latex" title="{ \theta\in[-\pi, \pi]}" /> define <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Ctheta%29%7D%5Crangle+%3D+%5Ccos%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Csin%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" class="latex" title="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Ctheta%29%7D%5Crangle+%3D+-%5Csin%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Ccos%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" class="latex" title="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" /> .

Now we describe a (quantum) strategy with winning probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\frac{\pi}{8})}" class="latex" title="{ \cos^2(\frac{\pi}{8})}" />. In each case Alice and Bob respond with their measurement outcome, where subscripts of the measurement basis vectors correspond to the answer to be sent back to the verifier.
<ul>
 	<li> If <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=0}" class="latex" title="{ s=0}" />, Alice measures in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%280%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%280%29%7D%5Crangle+%5C%7D+%3D+%5C%7B+%7C%7B0%7D%5Crangle+%2C+%7C%7B1%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" class="latex" title="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" />. If <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=1}" class="latex" title="{ s=1}" />, Alice measures in <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" class="latex" title="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" />. Alice answers bit <img src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a = 0}" class="latex" title="{ a = 0}" /> if outcome is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cbeta_0%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \beta_0(\cdot)}" class="latex" title="{ \beta_0(\cdot)}" /> and answers <img src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a = 1}" class="latex" title="{ a = 1}" /> otherwise.</li>
 	<li> If <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=0}" class="latex" title="{ t=0}" />, Bob measures in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" class="latex" title="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" />. If <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=1}" class="latex" title="{ t=1}" />, Bob measures in <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" class="latex" title="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" />.</li>
 	<li> Each player responds with their respective measurement outcome.</li>
</ul>
<b>Lemma 2</b> <em><a name="goodstrategy"></a> Alice and Bob win the CHSH game with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\frac{\pi}{8})}" class="latex" title="{ \cos^2(\frac{\pi}{8})}" />. </em>
<em><br /><b></b>Proof.</em> We will show that for each pair of questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t}" class="latex" title="{ s,t}" /> the pair of answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> is correct with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\pi/8)}" class="latex" title="{ \cos^2(\pi/8)}" />. We can split the pairs of questions into the two cases <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=0}" class="latex" title="{ s\wedge t=0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=1}" class="latex" title="{ s\wedge t=1}" />:
<ul>
 	<li> (<img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=0}" class="latex" title="{ s\wedge t=0}" />) The three cases <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%3D%280%2C0%29%2C%280%2C1%29%2C%281%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,t)=(0,0),(0,1),(1,0)}" class="latex" title="{ (s,t)=(0,0),(0,1),(1,0)}" /> are all analogous: in each case Alice an Bob must output the same answer, and in each case Bob’s measurement basis is almost the same as Alice’s except rotated by a small angle <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpm%5Cpi%2F8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \pm\pi/8}" class="latex" title="{ \pm\pi/8}" />.
Of the three above cases we consider the one where <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t=0}" class="latex" title="{ s,t=0}" /> and check that indeed the two measurement outcomes agree with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\pi/8)}" class="latex" title="{ \cos^2(\pi/8)}" />: When Alice measures her qubit and obtains some bit <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" />, the shared pair <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta}\rangle}" class="latex" title="{ |{\beta}\rangle}" /> collapses to <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{a}\rangle _A |{a}\rangle _B}" class="latex" title="{ |{a}\rangle _A |{a}\rangle _B}" />. Indeed, since the question was <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=0}" class="latex" title="{ s=0}" />, Alice measures her qubit in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{|0\rangle,|1\rangle\}}" class="latex" title="{ \{|0\rangle,|1\rangle\}}" />. This means that Alice applies the measurement <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%5Clangle+0%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%2C%7C1%5Crangle%5Clangle+1%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" class="latex" title="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" /> on the global state. The post-measurement state is the normalization of

<img src="https://s0.wp.com/latex.php?latex=%7B+%28+%7C%7Ba%7D%5Crangle+%5Clangle%7Ba%7D%7C+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%3D%5Cfrac%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B0%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C0%7D%7D%5Cotimes+%7C+0%5Crangle+%2B+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B1%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C1%7D%7D%5Cotimes+%7C%7B1%7D%5Crangle+%3D%5Cfrac+%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" class="latex" title="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" />

because <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle+a+%7C%7Ba%27%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle a |{a'}\rangle}" class="latex" title="{ \langle a |{a'}\rangle}" /> can be viewed as a Kronecker delta of <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+a%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a'}" class="latex" title="{ a'}" />. In particular, Bob is now in the pure state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{a}\rangle}" class="latex" title="{ |{a}\rangle}" /> .

Because Bob received question <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=0}" class="latex" title="{ t=0}" /> he measures in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_b%28%5Cpi%2F8%29%7D%5Crangle+%5C%7D_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" class="latex" title="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" /> Therefore his probability of correctly outputting <img src="https://s0.wp.com/latex.php?latex=%7B+b%3Da%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b=a}" class="latex" title="{ b=a}" /> is

<img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D%5B%5Ctext%7BBob+gets+outcome+%7Da%5D+%3D+%7C%5Clangle%5Cbeta_a%28%5Ctfrac%7B%5Cpi%7D%7B8%7D%29+%7C%7Ba%7D%5Crangle+%7C%5E2+%3D+%5Ccos%5E2%5Cleft%28%5Cfrac%7B%5Cpi%7D%7B8%7D%5Cright%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" class="latex" title="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" />

</li>
 	<li> (<img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=1}" class="latex" title="{ s\wedge t=1}" />)
Now consider the case <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%2Ct%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=1,t=1}" class="latex" title="{ s=1,t=1}" /> where Alice and Bob are supposed to give different answers. Alice measures in basis consisting of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" class="latex" title="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B-%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" class="latex" title="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" />. If Alice gets outcome <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> then the post-measurement global state is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" class="latex" title="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" /> . Therefore when Bob applies the measurement in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%5C%7D_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" class="latex" title="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" /> he mistakenly outputs <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> only with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_a%28%5Cfrac%5Cpi4%29+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%7C%5E2%3D%5Csin%5E2%28%5Cfrac%5Cpi8%29%3D1-%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" class="latex" title="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" />.</li>
</ul>

<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#goodstrategy">2</a> implies a lower bound on the value of the CHSH game.
<h4>Corollary</h4>
<em> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%5Cge%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" class="latex" title="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" /> </em>

 
<br />It turns out that this lower bound is sharp, that is, the strategy just described is optimal.

<h4>Lemma</h4><em> The value of the CHSH game using a quantum strategy is at most <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+%3D+%5Ccos%5E2%5Cfrac%7B%5Cpi%7D%7B8%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" class="latex" title="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" />. </em>



<em><b>Proof.</b></em>

We can describe the quantum strategy of Alice and Bob in an XOR game by (i) a shared quantum state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" title="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" /> (note that for the CHSH game, <img src="https://s0.wp.com/latex.php?latex=%7B+d%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d=2}" class="latex" title="{ d=2}" />); (ii) measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA%5E0_s%2C+A%5E1_s%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A^0_s, A^1_s\}}" class="latex" title="{ \{A^0_s, A^1_s\}}" /> for every question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> sent to Alice; (iii) measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB%5E0_t%2C+B%5E1_t%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B^0_t, B^1_t\}}" class="latex" title="{ \{B^0_t, B^1_t\}}" /> for every question <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> sent to Bob.

The probability of answering <img src="https://s0.wp.com/latex.php?latex=%7B+%28a%2C+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a, b)}" class="latex" title="{ (a, b)}" /> given questions <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s, t)}" class="latex" title="{ (s, t)}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" class="latex" title="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" /> . Now let us write <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%3DA%5E0_s+-+A%5E1_s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s=A^0_s - A^1_s}" class="latex" title="{ A_s=A^0_s - A^1_s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_t%3DB%5E0_t+-+B%5E1_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_t=B^0_t - B^1_t}" class="latex" title="{ B_t=B^0_t - B^1_t}" /> so that for any <img src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a, b\in\{0, 1\}}" class="latex" title="{ a, b\in\{0, 1\}}" />, we can write

<img src="https://s0.wp.com/latex.php?latex=%7B+A_s%5Ea+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%2C+B_t%5Eb+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" class="latex" title="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" />

Note that since the possible outcomes here are finite, <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s, B_t}" class="latex" title="{ A_s, B_t}" /> are Hermitian and we may assume have bounded norm of 1. Furthermore, we assume that <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s, B_t}" class="latex" title="{ A_s, B_t}" /> are <em>observables</em> so that <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%5E2+%3D+B_t%5E2+%3D+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s^2 = B_t^2 = {\mathbb{I}}}" class="latex" title="{ A_s^2 = B_t^2 = {\mathbb{I}}}" /> .

Now denoting <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{s, t}(a\oplus b)}" class="latex" title="{ f_{s, t}(a\oplus b)}" /> as the XOR predicate to be computed, we can write the quantum game value as

<img src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5Ea%5C%7D%2C+%5C%7BB_t%5Eb%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%28-1%29%5E%7Bab%7D%7D%7B4%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29%7D%7B2%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " class="latex" title="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " />

where the summation <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Ba%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%28%5Ccdot%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" class="latex" title="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" /> has been evaluated in the last line.

Now note that the first term is independent of the quantum strategy and as a result equals the value of the uniformly random strategy which is 1/2. So we proceed to focus on the second term. Note that for CHSH <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29+%3D+%28-1%29%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" class="latex" title="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" /> simplifying the second term to

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B8%7D%28+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+-+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+%29.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" class="latex" title="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" />

Next, we invoke Tsirelson’s Theorem (See Theorem <a href="https://windowsontheory.org/feed/#thmtsirelson">3</a>) to bound this second term as

<img src="https://s0.wp.com/latex.php?latex=%3D+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1+%2B+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%5C%7C%7B%5Ctextbf%7Bx%7D%7D_0%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7By%7D%7D_1%5C%7C+%2B+%5C%7C%7B%5Ctextbf%7Bx%7D%7D_1%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7By%7D%7D_1%5C%7C%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B8%7D%5Csqrt%7B2%5C%7C%7B%5Ctextbf%7By%7D%7D_0%5C%7C%5E2+%2B+2%5C%7C%7B%5Ctextbf%7By%7D%7D_1%5C%7C%5E2%7D+%5Cleq+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " class="latex" title="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " />

where we have used Cauchy-Schwartz and the concavity of the <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csqrt%7B%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sqrt{\cdot}}" class="latex" title="{ \sqrt{\cdot}}" /> function.

This completes our proof showing the exact characterization of the value (<img src="https://s0.wp.com/latex.php?latex=%7B+%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%3D%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" class="latex" title="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" />) of the CHSH game using a quantum strategy. This proof is an adaptation of the one in [12]. 
<div align="right">□</div>
<b>Theorem 3 (Tsirelson’s Theorem [1])</b> <em><a name="thmtsirelson"></a> For any <img src="https://s0.wp.com/latex.php?latex=%7B+n%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n\times n}" class="latex" title="{ n\times n}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+C+%3D+%28C_%7Bs%2C+t%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C = (C_{s, t})}" class="latex" title="{ C = (C_{s, t})}" />, the following are equivalent: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> There exist <img src="https://s0.wp.com/latex.php?latex=%7B+d%5Cin%5Cmathbb%7BN%7D%2C+%7C%7B%5Cphi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5E%7Bd%7D%5Cotimes%5Cmathbb%7BC%7D%5E%7Bd%7D%2C+A_s%2C+B_t%5Cin%5Ctext%7BHerm%7D%28%5Cmathbb%7BC%7D%5Ed%29%2C+A_s%5E2+%3D+B_t%5E2+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" class="latex" title="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" /> such that for any <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in[n]}" class="latex" title="{ s, t\in[n]}" /> <img src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" class="latex" title="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" /> . Further this would imply that <img src="https://s0.wp.com/latex.php?latex=%7B+d%5Cleq+2%5E%7B%5Clceil%5Cfrac%7Bn%2B2%7D%7B2%7D%5Crceil%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" class="latex" title="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" />;</li>
 	<li> There exist real unit vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%2C+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%5Cin%7B%5Cmathbb%7BR%7D%7D%5E%7Bn%2B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" class="latex" title="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in [n]}" class="latex" title="{ s, t\in [n]}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%5Ccdot+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" class="latex" title="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" />;</li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>
<h2>Entangled unique games are easy</h2>
The CHSH game provides the first example that the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> of a nonlocal game can exceed the classical value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" />. XOR-games like the CHSH game are the special case corresponding to alphabet size <img src="https://s0.wp.com/latex.php?latex=%7B+k%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k=2}" class="latex" title="{ k=2}" /> of the class of <em>unique games</em> :
<h4>Definition (Unique Games)</h4>
<em> A 2-prover 1-round game is called a <em>unique game</em> if its constraints are of the form <img src="https://s0.wp.com/latex.php?latex=%7B+b%3D%5Cpi_%7Bij%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b=\pi_{ij}(a)}" class="latex" title="{ b=\pi_{ij}(a)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpi_%7Bij%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \pi_{ij}}" class="latex" title="{ \pi_{ij}}" /> is a permutation of the alphabet <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma}" class="latex" title="{ \Sigma}" /> for each edge <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Csim+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\sim j}" class="latex" title="{ i\sim j}" />. </em>

 The famous <em>unique games conjecture</em> (UGC) by Khot says that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" /> is NP-hard to approximate for unique games. Surprisingly, Kempe et al. showed that a natural semidefinite relaxation for unique games yields an approximation to the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> which can be computed in polynomial time. In other words the UGC is false for entangled provers, in contrast to the classical case where the conjecture is open.
<br />Theorem 4 <em><a name="efficientUGC"></a> There is an efficient (classical) algorithm which takes a description of a nonlocal game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> as its input and outputs <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)}" class="latex" title="{ \hat\omega(G)}" /> such that </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+1-6%281-%5Chat%5Comega%28G%29%29%5Cle%5Comega%5E%2A%28G%29%5Cle%5Chat%5Comega%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" class="latex" title="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" /></em>

<em>Put differently, if <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D1-%5Cvarepsilon%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)=1-\varepsilon^*}" class="latex" title="{ \omega^*(G)=1-\varepsilon^*}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D1-%5Chat%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=1-\hat\varepsilon}" class="latex" title="{ \hat\omega(G)=1-\hat\varepsilon}" />, then</em>

<em><img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarepsilon%5E%2A%5Cin%5B%5Chat%5Cvarepsilon%2C6%5Chat%5Cvarepsilon%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" class="latex" title="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" /></em>

<em>
</em><em></em><em></em><em></em><em> </em>
<br />The algorithm of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> proceeds by relaxing the set of quantum strategies to a larger convex set <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> of <em>pseudo-strategies</em> and maximizing over <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> instead of actual strategies, a much easier task. In approximation theory one often encounters a collection of hypothetical moments not arising from a distribution, known as a pseudo-distribution. In contrast, our pseudo-strategies are actual conditional probability distributions on answers (conditional on the questions). What makes <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> a set of “pseudo”-strategies rather than actual strategies is that they may enjoy correlations which cannot be achieved without communication.
<h3> Convex relaxation of quantum strategies</h3>
We will define <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> to be a class of conditional probability distributions <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> on answers given questions. We will require that the pseudo-strategies satisfy a positive semidefinite constraint when arranged in matrix form. In particular this matrix has to be symmetric, so we symmetrize the conditional probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> by allowing each of <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> to be either a question for Alice or for Bob. That is, we extend the domain of definition for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> from <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma^2\times S\times T}" class="latex" title="{ \Sigma^2\times S\times T}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma^2\times (S\cup T)^2}" class="latex" title="{ \Sigma^2\times (S\cup T)^2}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S}" class="latex" title="{ S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ T}" class="latex" title="{ T}" /> are the question sets. So each question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> and answer <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> can be either for Alice or Bob — we indicate this by changing notation from <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%5Cin+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,t)\in S\times T}" class="latex" title="{ (s,t)\in S\times T}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'\in S\cup T}" class="latex" title="{ q,q'\in S\cup T}" /> and for the answers replacing <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> by <img src="https://s0.wp.com/latex.php?latex=%7B+c%2Cc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c,c'}" class="latex" title="{ c,c'}" />.

<br />Definition 5 (Block-matrix form) <em><a name="to_matrix"></a> Given a function <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" class="latex" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" /> defined on <img src="https://s0.wp.com/latex.php?latex=%7B+%28S%5Ccup+T%29%5E2%5Ctimes+%5CSigma%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (S\cup T)^2\times \Sigma^2}" class="latex" title="{ (S\cup T)^2\times \Sigma^2}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+%7CS%7C%3D%7CT%7C%3Dn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |S|=|T|=n}" class="latex" title="{ |S|=|T|=n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5CSigma%7C%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\Sigma|=k}" class="latex" title="{ |\Sigma|=k}" />, define a <img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> whose rows are indexed by pairs <img src="https://s0.wp.com/latex.php?latex=%7B+%28q%2Cc%29%5Cin%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (q,c)\in(S\cup T)\times\Sigma}" class="latex" title="{ (q,c)\in(S\cup T)\times\Sigma}" /> and columns by pairs <img src="https://s0.wp.com/latex.php?latex=%7B+%28q%27%2Cc%27%29%5Cin+%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (q',c')\in (S\cup T)\times\Sigma}" class="latex" title="{ (q',c')\in (S\cup T)\times\Sigma}" />, and whose entries are </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28q%2Cc%29%2C%28q%27%2Cc%27%29%7D%3D%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" class="latex" title="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" /></em>

<em>
</em><em></em><em> In other words <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> consists of <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> blocks where the block <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" title="{ M^{\tilde{P}}_{q,q'}}" /> at position <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'}" class="latex" title="{ q,q'}" /> contains the entries <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7Cq%2Cq%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(\cdot\cdot|q,q')}" class="latex" title="{ \tilde{P}(\cdot\cdot|q,q')}" />. </em><br />
Definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a> is simply a convenient change of notation and we identify <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" />, using either notation depending on the context.
<br />Definition 6 (Pseudo-strategies) <em><a name="Sdef"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S}" class="latex" title="{ S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ T}" class="latex" title="{ T}" /> be the question sets for Alice and Bob, respectively. We say that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" class="latex" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" /> (or its matrix form <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" />) is a pseudo-strategy if: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> is positive semidefinite.<a name="positive"></a></li>
 	<li> For any pair of questions <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'\in S\cup T}" class="latex" title="{ q,q'\in S\cup T}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Bc%2Cc%27%3D1%7D%5Ek+%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" class="latex" title="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" />.<a name="sum1"></a></li>
 	<li> The blocks <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" title="{ M^{\tilde{P}}_{q,q'}}" /> on the diagonal are themselves diagonal <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> matrices.<a name="diagonal"></a></li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>
Define the winning probability or value of a pseudo-strategy as:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29%3D%5Cmathbb+E_%7B%28s%2Ct%29%5Csim+%5CPi%7D+%5Csum_%7Ba%2Cb%7D+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29V%28a%2Cb%7Cs%2Ct%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" class="latex" title="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" />

The algorithm outputs the maximum winning probability:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" class="latex" title="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" />

over pseudo-strategies <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}\in \mathcal S}" class="latex" title="{ \tilde{P}\in \mathcal S}" />. This maximum is efficiently computable using standard semidefinite programming algorithms. As we will see, actual quantum strategies are in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> which immediately implies <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%5Cge%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)\ge\omega^*(G)}" class="latex" title="{ \hat\omega(G)\ge\omega^*(G)}" />. It then remains to show that the optimal pseudo-strategy can be approximated by an actual entangled strategy, thus bounding the gap from <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)}" class="latex" title="{ \hat\omega(G)}" />.
<h3> Quantum strategies are in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /></h3>
Let us establish that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> is indeed a relaxation of the class of quantum strategies, that is, it contains the quantum strategies. So suppose we are given a quantum strategy. By equation <a href="https://windowsontheory.org/feed/#Qstrategy">1</a> the probability of answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> given questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> is of the form

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%3D%5Clangle%5Cphi%7C%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b+%29%7C%5Cphi%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" class="latex" title="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" />

for some PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> and some <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" />. This conditional probability distibution is not immediately in the form of a pseudo-strategy because we cannot evaluate it on pairs of Alice-questions or pairs of Bob-questions. We therefore have to extend it, as follows: Place all the column vectors <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" class="latex" title="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ca%29%5Cin+S%5Ctimes+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,a)\in S\times \Sigma}" class="latex" title="{ (s,a)\in S\times \Sigma}" /> side by side, and then append the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+I%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I\otimes B^t_b|\phi\rangle}" class="latex" title="{ I\otimes B^t_b|\phi\rangle}" />, resulting in a <img src="https://s0.wp.com/latex.php?latex=%7B+d%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d^2}" class="latex" title="{ d^2}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R}" class="latex" title="{ R}" />. We then define <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" class="latex" title="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" /> through its matrix form (see the comment below definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a>): <a name="eqMp"></a>
<p align="center"><a name="eqMp"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7BP%7D%3A%3DR%5E%5Cdag+R%3D%5Cbegin%7Bpmatrix%7D+%28%5Clangle%5Cphi%7CA%5Es_a+A%5E%7Bs%27%7D_%7Ba%27%7D%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28s%27%2Ca%27%29%7D+%28%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D+%5C%5C%5C%5C+%28%5Clangle%5Cphi%7CB%5Et_b%5Cotimes+A%5Es_a+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28s%2Ca%29%7D+%28%5Clangle%5Cphi%7C%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_bB%5E%7Bt%27%7D_%7Bb%27%7D+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28t%27%2Cb%27%29%7D+%5Cend%7Bpmatrix%7D+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" class="latex" title="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" /></a></p>
<a name="eqMp">
</a><a name="eqMp"></a>
<b>Lemma 7</b> <em><a name="relaxation"></a> <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}}" class="latex" title="{ M^{P}}" /> defined in <a href="https://windowsontheory.org/feed/#eqMp">2</a> is a pseudo-strategy, that is, <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}\in\mathcal S}" class="latex" title="{ M^{P}\in\mathcal S}" />. </em>
<em><br />Proof.</em> We verify the conditions in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a>. Condition <a href="https://windowsontheory.org/feed/#positive">1</a> (<img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Csucceq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}\succeq0}" class="latex" title="{ M^{P}\succeq0}" />) holds because it is of the form <img src="https://s0.wp.com/latex.php?latex=%7B+R%5E%5Cdag+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R^\dag R}" class="latex" title="{ R^\dag R}" />. Condition <a href="https://windowsontheory.org/feed/#sum1">2</a> (Each block <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}_{q,q'}}" class="latex" title="{ M^{P}_{q,q'}}" /> sums to <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" />) holds because PVM’s sum to the identity. Condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> (Diagonal blocks <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DM%5E%7BP%7D_%7Bqq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde M=M^{P}_{qq}}" class="latex" title="{ \tilde M=M^{P}_{qq}}" /> are diagonal) holds because the projections in the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Eq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^q}" class="latex" title="{ A^q}" /> are mutually orthogonal, hence <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Eq_cA%5Eq_%7Bc%27%7D+%7C%7B%5Cphi%7D%5Crangle+%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" class="latex" title="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" /> if <img src="https://s0.wp.com/latex.php?latex=%7B+c%5Cneq+c%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c\neq c'}" class="latex" title="{ c\neq c'}" />. 
<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#relaxation">7</a> means <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%7BP%7D%5Cin+%5Cmathcal+S%7D%5Comega%5E%7BP%7D%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" class="latex" title="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" /> is an (efficiently computable) upper bound for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" />:
<h4>Corollary</h4><em> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%5Cge+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega\ge \omega^*(G)}" class="latex" title="{ \hat\omega\ge \omega^*(G)}" />. </em>



<br />To finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> we need to show that any pseudo-strategy <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" /> can be <em>rounded</em> to an actual quantum strategy with answer probabilities <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> such that <a name="roundingobjective"></a>
<p align="center"><a name="roundingobjective"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Comega%5E%7BP%7D%5Cle+6%281-%5Comega%5E%7B%5Ctilde+P%7D%29+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" class="latex" title="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" /></a></p>
<a name="roundingobjective">
</a><a name="roundingobjective"></a> Applying this rounding to the optimal pseudo-strategy implies that

<img src="https://s0.wp.com/latex.php?latex=%7B+1-%5Comega%5E%2A%5Cle+6%281-%5Chat%5Comega%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1-\omega^*\le 6(1-\hat\omega) }" class="latex" title="{ 1-\omega^*\le 6(1-\hat\omega) }" />

or <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%5Cge+1-6%281-%5Chat%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*\ge 1-6(1-\hat\omega)}" class="latex" title="{ \omega^*\ge 1-6(1-\hat\omega)}" />, which will finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.

<em><br /><b>Proof.</b></em>[Proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>] Let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}\in\mathcal S}" class="latex" title="{ \tilde{P}\in\mathcal S}" /> be a pseudo-strategy. We construct a quantum strategy <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> approximating <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" />. Since <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> is positive semidefinite we can write

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DR%5E%5Cdag+R+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde M=R^\dag R }" class="latex" title="{ \tilde M=R^\dag R }" />

for <em>some</em> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+R%5Cin+%5Cmathbb+C%5E%7Br%5Ctimes+2nk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R\in \mathbb C^{r\times 2nk}}" class="latex" title="{ R\in \mathbb C^{r\times 2nk}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+r%5Cleq+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ r\leq 2nk}" class="latex" title="{ r\leq 2nk}" />. Now let us define <img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+u%5Es_a%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\tilde u^s_a\rangle}" class="latex" title="{ |\tilde u^s_a\rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+v%5Et_b%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\tilde v^t_b\rangle}" class="latex" title="{ |\tilde v^t_b\rangle}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^{r}}" class="latex" title="{ \mathbb C^{r}}" />, and let <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_a%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{u^s_a}\rangle}" class="latex" title="{ |{u^s_a}\rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%5Et_b%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v^t_b}\rangle}" class="latex" title="{ |{v^t_b}\rangle}" /> be the same vectors normalized. The strategy is constructed as follows. Alice and Bob share the maximally entangled state

<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%3D%5Cfrac1%7B%5Csqrt+r%7D%5Csum_%7Bi%3D1%7D%5Er%7Ci%5Crangle%7Ci%5Crangle%5Cin%5Cmathbb+C%5Er%5Cotimes%5Cmathbb+C%5Er+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" class="latex" title="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" />

Before deciding on Alice and Bob’s PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> let us see what this choice of shared state means for the conditional distribution on answers (see equation <a href="https://windowsontheory.org/feed/#Qstrategy">(1)</a>).
<p align="center"> <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cphi%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle+%3D%5Cfrac1r%5Csum_%7Bi%2Cj%3D1%7D%5Er%5Clangle+i+%7C+A%5Es_a%7C+j%5Crangle%5Clangle+i+%7C+B%5Et_b%7C+j%5Crangle+%3D%5Cfrac1r+A%5Es_a%5Ccdot+B%5Et_b%3D%5Cfrac1r%5Clangle+A%5Es_a%2C%5Coverline%7BB%5Et_b%7D%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" class="latex" title="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" />, (*)</p>
where the bar represents entrywise complex conjugation, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cdot}" class="latex" title="{ \cdot}" /> is the entrywise dot product of matrices, and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5C%3A%2C%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\:,\rangle}" class="latex" title="{ \langle\:,\rangle}" /> the entrywise complex inner product (Hilbert-Schmidt inner product).

We now choose the measurements. Given question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" />, Alice measures in the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%3D%28A%5Es_a%29_%7Ba%3D0%7D%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s=(A^s_a)_{a=0}^k}" class="latex" title="{ A^s=(A^s_a)_{a=0}^k}" /> with

<img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%3D+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%5Ctext%7B+for+%7Da%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DA%5Es_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" class="latex" title="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" />

Similarly, Bob on question <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> applies the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> with

<img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et_b%3D+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%5Ctext%7B+for+%7Db%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DB%5Et_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" class="latex" title="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" />

The condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a> ensures that for any question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" />, the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_1%7D%5Crangle+%2C%5Cldots%2C+%7C%7Bu%5Es_1%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" class="latex" title="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" /> are orthogonal so that this is a valid PVM.

The measurement outcome “<img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />” is interpreted as “fail”, and upon getting this outcome the player attempts the measurement again on their share of a fresh copy of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle_{AB}}" class="latex" title="{ |\phi\rangle_{AB}}" />. This means that the strategy requires many copies of the entangled state to be shared before the game starts. It also leads to the complication of ensuring that with high probability the players measure the same number of times before outputting their measurement, so that the outputs come from measuring the same entangled state.

By (*), at a given round of measurements the conditional distribution of answers is given by

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%3D%5Cfrac1r%5CBig%5Clangle+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7B+u%5Es_a%7D%7C+%5C%3A%2C%5C%3A+%7C%7B%7Bv%5Et_b%7D%5Crangle+%7D+%5Clangle%7B+%7Bv%5Et_b%7D%7C+%7D%5CBig%5Crangle%3D%5Cfrac1r%7C%5Clangle+%7Bu%5Es_a%7D%7Cv%5Et_b%5Crangle%7C%5E2%3D%5Cfrac1%7Br%7C%5Ctilde+u%5Es_a%7C%5E2%7C%5Ctilde+v%5Et_b%7C%5E2%7D%5CBig%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29%5E2%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" class="latex" title="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" />

We wish to relate the LHS to <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(s,a),(t,b)}}" class="latex" title="{ M^{\tilde{P}}_{(s,a),(t,b)}}" />, so to handle the factor <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1r}" class="latex" title="{ \frac1r}" /> each prover performs repeated measurements, each time on a fresh copy of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle_{AB}}" class="latex" title="{ |\phi\rangle_{AB}}" />, until getting an outcome <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cneq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \neq0}" class="latex" title="{ \neq0}" />. Moreover, to handle the factor <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%7Cu%5Es_a%7C%5E2%7Cv%5Et_b%7C%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1{|u^s_a|^2|v^t_b|^2}}" class="latex" title="{ \frac1{|u^s_a|^2|v^t_b|^2}}" />, each prover consults public randomness and accepts the answer <img src="https://s0.wp.com/latex.php?latex=%7B+a%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a\in[k]}" class="latex" title="{ a\in[k]}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%7Cu%5Ea_s%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |u^a_s|^2}" class="latex" title="{ |u^a_s|^2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7Cv%5Eb_t%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |v^b_t|^2}" class="latex" title="{ |v^b_t|^2}" /> respectively, or rejects and start over depending on the public randomness. Under a few simplifying conditions (more precisely, assuming that the game is <em>uniform</em> meaning that an optimal strategy exists where the marginal distribution on each prover’s answers is uniform), we can let <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cle+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" class="latex" title="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ca%2Ct%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,a,t,b}" class="latex" title="{ s,a,t,b}" />, and one can ensure that the conditional probabilities <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> of the final answers satisfy
<p align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+1%2Fk-P%28a%2Cb%7Cs%2Ct%29%5Cle+3%5Cbig%281%2Fk-k%28M%5E%7B%5Ctilde+P%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2%5Cbig%29%2C%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" class="latex" title="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" />
<a name="PM"></a>

At this stage it is important that we are dealing with a <em>unique game</em> . Indeed, by <a href="https://windowsontheory.org/feed/#PM">(4)</a> we have for every <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" />,

<img src="https://s0.wp.com/latex.php?latex=1-%5Csum_%7Ba%3D1%7D%5Ek+P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29%3D%5Csum_a+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29+%5CBig%29+%5C%5C+%5Cleq+3%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-k%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2+%5CBig%29+%5C%5C+%5Cleq+6%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D%5Cbig%28%5Cfrac%7B1%7D%7Bk%7D-M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cbig%29%3D6%5CBig%281-%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " class="latex" title="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " />

where the last inequality follows from concavity. Taking the expectation over <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> implies the bound <a href="https://windowsontheory.org/feed/#roundingobjective">(3)</a>, thus concluding the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.
</p><div align="right">□</div>
<h2>General games are hard</h2>
We just saw that a specific class of games becomes easy in the presence of shared entanglement, in that semidefinite programming allows the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*}" class="latex" title="{ \omega^*}" /> to be approximated to within exponential precision in polynomial time. Does this phenomenon hold more generally, so that the value of entangled games can always be efficiently approximated? We answer in the negative, by constructing a game where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*}" class="latex" title="{ \omega^*}" /> is NP-hard to approximate to within inverse-polynomial factors. The complexity for 2P-1R entangled games can be strengthened to constant-factor NP-hardness, putting it on par with the classical PCP theorem. This result is used to prove (with some conditions) the games formulation of the quantum PCP theorem, which states that the entangled value of general games is QMA-hard to approximate within a constant factor.
<h3> Formulation of game</h3>
Given any instance <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" /> of a <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP (constraint satisfaction problem, where <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> is the number of literals), we can define a clause-vs-variable game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> (see clause-vs-variable figure):
<ol>
 	<li> The referee (verifier) randomly sends a clause to Alice (first prover) and a variable to Bob (second prover).</li>
 	<li> Alice and Bob reply with assignments.</li>
 	<li> The referee accepts if Alice’s assignment satisfies the clause and Bob’s answer is consistent with Alice’s.</li>
</ol>
To show hardness of approximation, we need to go beyond the usual 2-player construction. In particular, in our game [3] one of the players receives an extra dummy question (see subfigure (a)). Mathematically, the result is very similar to introducing another player and having the referee play the 2-player game with two players chosen randomly [4] (see subfigure (b)). In either variation, the quantum phenomenon of <em>monogamy of entanglement</em> , imposing that only two parties can be maximally entangled to one another, is key to establishing hardness. The players do not know where to use their entanglement, which prevents them from coordinating as well as they could in the standard game.
<figure style="width: 25em; margin: auto;">  
<a href="https://windowsontheory.org/?attachment_id=7233"><img width="107" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/2player.png?w=107&amp;h=150" class="attachment-thumbnail size-thumbnail" height="150" /></a>
<a href="https://windowsontheory.org/?attachment_id=7234"><img width="107" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/3player.png?w=107&amp;h=150" class="attachment-thumbnail size-thumbnail" height="150" /></a>


Two variations of a 2-player clause-vs-variable game; new features are in red and shared entanglement is denoted in blue. In the standard game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" />, given <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%3D%28C_1%2C%5Cldots%2CC_m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi=(C_1,\ldots,C_m)}" class="latex" title="{ \phi=(C_1,\ldots,C_m)}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> variables <img src="https://s0.wp.com/latex.php?latex=%7B+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x_i}" class="latex" title="{ x_i}" />, (1) the referee R randomly sends a clause <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> to Alice A and a literal index <img src="https://s0.wp.com/latex.php?latex=%7B+t%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t\in[k]}" class="latex" title="{ t\in[k]}" /> to Bob B, (2) A replies with an assignment <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)}" class="latex" title="{ (a_1,\ldots,a_k)}" /> and B replies with assignment <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" />, (3) R accepts iff <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)}" class="latex" title="{ (a_1,\ldots,a_k)}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+a_t%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_t=b}" class="latex" title="{ a_t=b}" />. In variation (a), R sends an additional dummy index <img src="https://s0.wp.com/latex.php?latex=%7B+l%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ l\in[k]}" class="latex" title="{ l\in[k]}" />, so that B replies with an additional assignment <img src="https://s0.wp.com/latex.php?latex=%7B+b%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b'}" class="latex" title="{ b'}" />, but he does not know which is the right variable. Equivalently, in (b) a third player Charlie C is introduced, but <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> is played with two randomly chosen players. Since only parties can be maximally entangled and the players do not know who is playing the game, they cannot coordinate perfectly. </figure>
<h3> NP-hardness of approximating the entangled value</h3>
To prove hardness, we rely on several results from classical complexity theory.
<br />Theorem 8 ([6]) <em> Given an instance of 1-in-3 3SAT (a CSP), it is NP-hard to distinguish whether it is satisfiable or no assignments satisfy more than a constant fraction of clauses. <a name="thmCSP"></a> </em>
<br />Theorem 9 ([2]) <em> For a PCP game <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> (emulating the CSP) and its oracularization <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> (transformation to a 2P-1R game), </em>

<p align="center"><em><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%28G%29%5Cleq+%5Comega%28G%27%29%5Cleq+1-%5Cfrac%7B1-%5Comega%28G%29%7D%7B3%7D%5C%2C.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" class="latex" title="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" /></em></p>
<em>
</em><em> <a name="thmMIP"></a> </em>
Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a> establishes the CSP variant of the classical PCP theorem: distinguishing between <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)=1}" class="latex" title="{ \omega(\phi)=1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq 1/2}" class="latex" title="{ \omega(\phi)\leq 1/2}" /> is NP-hard for some <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP. Here, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)}" class="latex" title="{ \omega(\phi)}" /> denotes the maximum fraction of clauses that are simultaneously satisfiable. Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> relates the general game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> obtained from the CSP to a two-player one-round game <img src="https://s0.wp.com/latex.php?latex=%7B+G%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G'}" class="latex" title="{ G'}" />, in terms of the value (probability of winning) the game. The first inequality, equivalently saying <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq \omega(G_\phi)}" class="latex" title="{ \omega(\phi)\leq \omega(G_\phi)}" />, is achieved since the players can answer the questions in the game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> to satisfy the clauses in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" />. These theorems together imply that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G_\phi)}" class="latex" title="{ \omega(G_\phi)}" /> is NP-hard to approximate to within constant factors.

Allowing the two players to share entanglement can increase the game value to <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%5Cgeq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" class="latex" title="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" />. Classical results do not necessarily carry over, but exploiting monogamy of entanglement allows us to limit the power of entangled strategies. One can show the following lemma, which is weaker than what we have classically.
<br /><b>Lemma 10 ([3])</b> <em> There exists a constant <img src="https://s0.wp.com/latex.php?latex=%7Bc%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c&gt;0}" class="latex" title="{c&gt;0}" /> such that for a CSP <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" />, </em>
<p align="center"><em><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" class="latex" title="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" /></em></p>
<em>
</em><em> where <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is the number of variables. <a name="lemmaIto"></a> </em>
Combining Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> and Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a>, we have

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" class="latex" title="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" />

Using Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a>, approximating <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G_\phi)}" class="latex" title="{ \omega^*(G_\phi)}" /> is NP-hard to within inverse polynomial factors. Proving Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a> takes some work in keeping track of approximations. For simplicity, we will show a less quantitative statement and indicate where the approximations come in.
<br />Proposition 11 (adapted from [13]) <em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> is satisfiable iff <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%5E%2A%28G_%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\omega^*(G_\phi)=1}" class="latex" title="{\omega^*(G_\phi)=1}" />. <a name="proposition"></a> </em>
<h3> Proof of Proposition <a href="https://windowsontheory.org/feed/#proposition">11</a></h3>
The forward direction is straightforward: If <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" /> is satisfiable, then there exists a perfect winning strategy where the questions are answered according to the satisfying assignment.

For the reverse direction, suppose there exists a strategy that succeeds with probability 1, specified by a shared entangled state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" title="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" /> and measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%28A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%29_%7Ba_1%2C%5Cldots%2Ca_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" class="latex" title="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" /> for Alice and <img src="https://s0.wp.com/latex.php?latex=%7B+%28B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%29_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (B^{t,l}_{b,b'})_{b,b'}}" class="latex" title="{ (B^{t,l}_{b,b'})_{b,b'}}" /> for Bob, where the questions <img src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ j\in[m]}" class="latex" title="{ j\in[m]}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+t%2Cl%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t,l\in[k]}" class="latex" title="{ t,l\in[k]}" /> and the answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> are from the CSP’s alphabet. Since one of the questions/answers for Bob corresponds to a dummy variable that is irrelevant to the game, trace over the dummy variable to define a new measurement operator <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5Et_b%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl%2Cb%27%7D+B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" class="latex" title="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" />. We can introduce a distribution on assignments to the <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> relevant variables,

<a name="eqpB"></a>
<p align="center"><a name="eqpB"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D%5Ccdots%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C.++%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" class="latex" title="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" /></a></p>
<a name="eqpB">
</a><a name="eqpB"></a> If we show that the distribution for assignments <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_{i_1},\ldots,a_{i_k}}" class="latex" title="{a_{i_1},\ldots,a_{i_k}}" /> on variables <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cldots%2Cx_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i_1},\ldots,x_{i_k}}" class="latex" title="{x_{i_1},\ldots,x_{i_k}}" /> in any clause <img src="https://s0.wp.com/latex.php?latex=%7BC_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_j}" class="latex" title="{C_j}" /> is <a name="eqpA"></a>
<p align="center"><a name="eqpA"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" class="latex" title="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" /></a></p>
<a name="eqpA">
</a><a name="eqpA"></a> then, since the players win with certainty, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> has a satisfying assignment. To transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a>, we need a relation between the <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{B}}" class="latex" title="{\tilde{B}}" /> measurement operators and a way to commute the <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{B}}" class="latex" title="{\tilde{B}}" /> operators.

The success probability of the players’ strategy is expressed as

<img src="https://s0.wp.com/latex.php?latex=%7B+P%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%5Cin%5Bm%5D%7D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%5Cin+C_j%7D+%5Csum_%7B%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D+%5Clangle%7B%5Cpsi%7D%7C+A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%2C%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" class="latex" title="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" />

where <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> is the index of one of the <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> variables on which <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> acts, and <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)\vdash C_j}" class="latex" title="{ (a_1,\ldots,a_k)\vdash C_j}" /> indicates that the assignment satisfies the clause. By positivity and summation to identity of the measurement operators <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}}" class="latex" title="{ \tilde{B}}" />, each term is at most 1; for our hypothesis <img src="https://s0.wp.com/latex.php?latex=%7B+P%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=1}" class="latex" title="{ P=1}" />, each has to be 1. Hence, using orthogonality of the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%5Cotimes%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" class="latex" title="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+a_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_i}" class="latex" title="{ a_i}" />, we have <a name="eqrelation"></a>
<p align="center"><a name="eqrelation"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7B%5Csubstack%7B%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5Cvdash+C_j+%5C%5C+a_i%3Db%7D%7D+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%3D+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D%7C%5Cpsi%5Crangle%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" class="latex" title="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" /></a></p>
<a name="eqrelation">
</a><a name="eqrelation"></a> for any <img src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ j\in[m]}" class="latex" title="{ j\in[m]}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Cin+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\in C_j}" class="latex" title="{ i\in C_j}" />.

We now demonstrate that two different <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^{t_1}_{b_1}}" class="latex" title="{ \tilde{B}^{t_1}_{b_1}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^{t_2}_{b_2}}" class="latex" title="{ \tilde{B}^{t_2}_{b_2}}" /> commute, so that Bob can match any satisfied clause/variable.

<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%3D++%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_1%2Cb_1%27%7D+B%5E%7Bt_1%2Cl_1%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_2%2Cb_2%27%7D+B%5E%7Bt_2%2Cl_2%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_2%2Cb_1%27%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_1%2Cb_2%27%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " class="latex" title="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " />

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate the measurements. The third line follows by the orthogonality of <img src="https://s0.wp.com/latex.php?latex=%7B+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^{t_1,t_2}_{b_1,b_2}}" class="latex" title="{ B^{t_1,t_2}_{b_1,b_2}}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+b_1%2Cb_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b_1,b_2}" class="latex" title="{ b_1,b_2}" />. For the fourth equation, we simply swap <img src="https://s0.wp.com/latex.php?latex=%7B+t_1%2Ct_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_1,t_2}" class="latex" title="{ t_1,t_2}" /> since the questions are indistinguishable to Bob. Thus, we can see how the dummy variable comes into play. If we had assumed <img src="https://s0.wp.com/latex.php?latex=%7B+P%3D1-%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=1-\epsilon}" class="latex" title="{ P=1-\epsilon}" /> and kept track of approximations, we would find <a name="eqcommutation"></a>
<p align="center"><a name="eqcommutation"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Cb_1%7D%5Csum_%7Bt_2%2Cb_2%7D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%28%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+-+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%29+%7C%5Cpsi%5Crangle+%5CrVert%5E2+%3D+O%28%5Cepsilon%29%5C%2C.++%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" class="latex" title="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" /></a></p>
<a name="eqcommutation">
</a><a name="eqcommutation"></a> This approximate commutativity results in the hardness of approximation holding only to within inverse poly<img src="https://s0.wp.com/latex.php?latex=%7B+%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (n)}" class="latex" title="{ (n)}" /> factors.

Now we are ready to transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a> to conclude the proof.

<img src="https://s0.wp.com/latex.php?latex=p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D+%5Cldots+%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bi_1%7D_%7Ba_%7Bi_1%7D%7D+%5Cldots+%5Ctilde%7BB%7D%5E%7Bi_k%7D_%7Ba_%7Bi_k%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3Dp%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5C%2C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " class="latex" title="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " />

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqcommutation">10</a>) to commute the measurement operators, along with their properties of orthogonality and summation to identity. For the third equality, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate Bob’s measurements to Alice’s, along with orthogonality of <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Ej_%7Ba_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^j_{a_{i_1,\ldots,i_k}}}" class="latex" title="{ A^j_{a_{i_1,\ldots,i_k}}}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+a_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_{i_1,\ldots,i_k}}" class="latex" title="{ a_{i_1,\ldots,i_k}}" />. 
<div align="right">□</div>
<h3> Constant-factor NP-hardness</h3>
The weakness in the above two-player game carries over from the original three-player variant. Thus, to achieve constant-factor NP-hardness of approximation, we could start with a different multiplayer game. Vidick [11] establishes the soundness of the “plane-vs-point” low-degree test (checking that the restriction of a low-degree polynomial to a plane matches its value at some point) in the presence of shared entanglement. <em> Soundness </em>, in the eponymous probabilistically checkable proof (PCP) formulation of the PCP theorem, refers to the verifier accepting a wrong proof with some bounded probability; bounding with a constant maps to constant-factor hardness of approximation. Here, soundness comes from a strong bound on error accumulation, similar to our approximate commutativity, but relies on the players’ Hilbert space being decomposable into three parts (i.e., there being three players). The particular game is constructed by combining the low-degree test with the 3-SAT test (encoding satisfying assignments in a low-degree polynomial), which can be reduced to the three-player QUADEQ test (testing satisfiability of a system of quadratic equations in binary variables, which is NP-complete). By the strong soundness result, the entangled value is NP-hard to approximate to within constant factors. Natarajan et al. [7] show that soundness holds even for two players, using a semidefinite program. They then construct a two-player game in a way similar to what we demonstrated.
<h3> Constant-factor QMA-hardness</h3>
The above can be thought of as the games formulation of the classical PCP theorem holding under shared entanglement. A true quantum PCP theorem states that the entangled value of general games is QMA-hard to approximate to within constant factors. Natarajan et al. [8] establish such a theorem, but under randomized reductions. This requirement stems from the lack of a sufficiently strong QMA-hardness result for local Hamiltonians (the quantum analog of CSPs). The soundness of the two-player low-degree test above is one instrumental component in the proof.
<h2>How much entanglement is needed?</h2>
We now focus on the question of quantifying exactly how much entanglement is needed to play XOR games optimally. As we shall see, the answer depends on the size of the question sets posed to Alice &amp; Bob in the game. The previous bound given by Tsirelson [10] (see table below) is tight for certain families of games, but is not tight for other families of games (such as a generalization of the CHSH game). The reason for this discrepancy is closely tied in with the the properties of the representation of the Observables that form the Optimal Strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />). Slofstra [9] shows that if the Observables constitute a Clifford Algebra (that is, the solutions are pair-wise anti-commutative), then the strategy is minimally entangled (uses the least number of entangled bits) iff the strategy is a unique solution to the SDP rounding problem. As a trivial corollary, if the SDP rounding problem does not have a unique solution (and a correspondingly unique strategy), then there exists a Non-Clifford optimal strategy that uses (atleast) <img src="https://s0.wp.com/latex.php?latex=%7B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |T|}" class="latex" title="{ |T|}" /> bits of entanglement less than the Clifford strategy. Slofstra further states that minimally entangled <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon}" class="latex" title="{ \epsilon}" />-optimal strategies may be constructed for XOR games where the optimal strategies have ‘stable’ representations. For the purposes of this post, we will analyze the exact result and merely state the approximate result.
<h3> Main Results</h3>
<h4><u>EXACT</u></h4>
For the exact realm, the table below summarizes Slofstra and Tsirelson’s main results.
<table border="1px">
<tbody>
<tr>
<th>Person</th>
<th> Strategy</th>
<th> Bound(entangled bits)</th>
</tr>
<tr>
<td> Slofstra</td>
<td> (Possibly) Non-Clifford</td>
<td> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \log_{2}(N)}" class="latex" title="{ \log_{2}(N)}" /></td>
</tr>
<tr>
<td> Tsirelson</td>
<td>Clifford</td>
<td><img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" /></td>
</tr>
</tbody>
</table>
Here, <img src="https://s0.wp.com/latex.php?latex=%7B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ r}" class="latex" title="{ r}" /> is the largest integer such that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cbinom%7Br+%2B+1%7D%7B2%7D+%3C+%7CS%7C+%2B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \binom{r + 1}{2} &lt; |S| + |T|}" class="latex" title="{ \binom{r + 1}{2} &lt; |S| + |T|}" /> and corresponds to the maximum-rank of an extremal point in the quantum correlation matrix corresponding to an optimal strategy.
<img src="https://s0.wp.com/latex.php?latex=%7B+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ N}" class="latex" title="{ N}" /> is the minimum dimension of the representations of the Operators (<img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" />).
<h4><u>APPROXIMATE</u></h4>
In the approximate realm, the minimum entanglement dimension of the representation of the Operators from an <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon}" class="latex" title="{ \epsilon}" />-Optimal Strategy is: min(<img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BO%7D%28%5Cepsilon%5E%7B%5Cfrac%7B-1%7D%7B12%7D%7D%29%2C+2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" title="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" />).

As we shall see, Slofstra’s theorem allows us to recover Tsirelson’s bound easily by using a fact from Representation Theory about the irreducible representations of Clifford Algebras, but stands as a more general lower bound for solutions that aren’t Clifford.
<h3> Marginals and Solution Algebras</h3>
We’ll begin by introducing 3 key ideas:
i) Degeneracy <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleftrightarrow%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \leftrightarrow}" class="latex" title="{ \leftrightarrow}" /> Non-Degeneracy
ii) Existence of Marginals
iii) Solution Algebra

Once these ideas are defined and their notions made clear, we will be in a position to state the main result and sketch a proof for it.
<h4>Definition (Marginal Strategy)</h4>
<em> Given an Optimal Quantum Strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />), a marginal constitutes <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}_{j \in T}}" class="latex" title="{ \{B_{j}\}_{j \in T}}" />, and the partial trace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \psi}" class="latex" title="{ \psi}" /> with respect to <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{A}}" class="latex" title="{ H_{A}}" /> (<img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho_{B}}" class="latex" title="{ \rho_{B}}" />). </em>

 It is also possible to dualize the definition for obtaining <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}_{i \in S}}" class="latex" title="{ \{A_{i}\}_{i \in S}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho_{A}}" class="latex" title="{ \rho_{A}}" />.
We now define the notion of degeneracy, which is critical when proving the main theorem. The main point to drive home is that a degenerate optimal quantum strategy can be reduced to a unique, non-degenerate optimal quantum strategy.
<h4>Definition (Degenerate Quantum Strategy)</h4>
<em> A quantum strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />) is said to be degenerate if <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cexists+%28P+%5Cin+H_A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \exists (P \in H_A)}" class="latex" title="{ \exists (P \in H_A)}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%28Q+%5Cin+H_B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (Q \in H_B)}" class="latex" title="{ (Q \in H_B)}" /> such that:
i) <img src="https://s0.wp.com/latex.php?latex=%7B+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P}" class="latex" title="{ P}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+A_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_i}" class="latex" title="{ A_i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%28P+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" class="latex" title="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" />
ii) <img src="https://s0.wp.com/latex.php?latex=%7B+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ Q}" class="latex" title="{ Q}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+B_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_j}" class="latex" title="{ B_j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%28%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+Q%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" class="latex" title="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" /> </em>

 Since we can efficiently construct for any degenerate Optimal Quantum Strategy a unique, non-degenerate Optimal Quantum Strategy, we will now assume WLOG that every Optimal Quantum Strategy is non-degenerate (and unique).

We now define the (unique) existence of marginal biases, which correspond to constants for the rows of the quantum correlation matrix (which is a generalization of the classical pay-off). An equivalent statement can be made for columns (<img src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d_{j}}" class="latex" title="{ d_{j}}" />) by dualizing the existence of row marginals. These constants can be thought of as representing the (expected) optimum-payoff possible for a set of operator choices by one player, given that the other player’s choice is fixed. Intuitively, this can be seen as “collapsing” the quantum correlation matrix into a column, by summing over the rows (or collapsing into a row, by summing over the columns).
<br /><b>Lemma 12 (Existence of Marginals)</b> <em> For all <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR games G, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cexists+%5C%7Bc_%7Bi%7D+%5Cgeq+0+%5Chspace%7B1mm%7D+%7C+%5Chspace%7B1mm%7D+i+%5Cin+%7CS%7C%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" class="latex" title="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" />, such that, if <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bu_%7Bi%7D%5C%7D_%7Bi+%5Cin+%7CS%7C%7D%2C+%5C%7Bv_%7Bj%7D%5C%7D_%7Bj+%5Cin+%7CT%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" class="latex" title="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" /> form an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-optimal vector strategy where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Cleq+%5Cfrac%7B1%7D%7B4%28m%2Bn%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon \leq \frac{1}{4(m+n)}}" class="latex" title="{\epsilon \leq \frac{1}{4(m+n)}}" />,
<a name="eqmarginale"></a></em>
<p align="center"><em><a name="eqmarginale"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+-+c_%7Bi%7Du_%7Bi%7D%5C%7C+%5Cleq+%5Csqrt%7B10%7D%28m+%2B+n%29%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%5Cepsilon%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" class="latex" title="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" /></a></em></p>
<em><a name="eqmarginale">
</a></em><em><a name="eqmarginale"></a> <a name="lemma"></a> </em>
If <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon = 0}" class="latex" title="{ \epsilon = 0}" /> and our strategy is perfectly optimal, we recover an exact estimation of the marginal biases: <a name="eqmarginal"></a>
<p align="center"><a name="eqmarginal"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+%3D+c_%7Bi%7Du_%7Bi%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2812%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" class="latex" title="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" /></a></p>
<a name="eqmarginal">
</a><a name="eqmarginal"></a> The proof for the above lemma provided by Slofstra relies on using techniques to analyze the structure of the SDP program that pertains to quantum marginals. In particular, conducting trace analysis on SDP matrices that correspond to using the game matrix as off-diagonal elements leads us to the construction of the desired marginal biases.
It is also critical to note that a dual statement allows us to recover the column biases <img src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d_{j} \geq 0}" class="latex" title="{ d_{j} \geq 0}" />: <a name="eqmarginalc"></a>
<p align="center"><a name="eqmarginalc"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%5Cin%5B%7CS%7C%5D%7DG_%7Bij%7Du_%7Bi%7D+%3D+d_%7Bj%7Dv_%7Bj%7D%2C+%5Cforall+j++%5C+%5C+%5C+%5C+%5C+%2813%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" class="latex" title="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" /></a></p>
<a name="eqmarginalc">
</a><a name="eqmarginalc"></a> We now move on to defining the notion of a solution algebra.
<br />Definition 13 (Solution Algebra) <em> A solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> consists of self-adjoint (Hermitian) operators <img src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{j}}" class="latex" title="{X_{j}}" /> that satisfy the following predicates:  <a name="eqhermit"></a></em>
<p align="center"><em><a name="eqhermit"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bj%7D%5E%7B2%7D+%3D+%5Cmathbb%7BI%7D%2C+%5Cforall+1+%5Cleq+j+%5Cleq+n++%5C+%5C+%5C+%5C+%5C+%2814%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" class="latex" title="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" /></a></em></p>
<em><a name="eqhermit">
</a><a name="eqhermit"></a> <a name="eqbiasespay"></a>
</em>
<p align="center"><em><a name="eqbiasespay"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Csum_%7Bj%5Cin%5B%7CT%7C%5D%7DG_%7Bij%7DX_%7Bj%7D%29%5E%7B2%7D+%3D+%28c_%7Bi%7D%29%5E%7B2%7D%5Ccdot%5Cmathbb%7BI%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2815%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" class="latex" title="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" /></a></em></p>
<em>
</em><em><a name="eqbiasespay">
</a></em><em><a name="eqbiasespay"></a> </em>
The definition above merely enforces the property that our unknown marginal operators be Hermitian <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a> and that they respect the optimal marginal biases (or payoffs) <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> we saw in <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a>, so that they correspond to being constructed from an optimal vector strategy. These unknown operators will be mapped to operators that are the marginal strategy corresponding to the optimal quantum strategy. This is at the heart of the main theorem we will now state:
<b>Theorem 14 (Slofstra, 2010)</b> <em> Given a <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR game G (with no zero rows or columns) and a solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" />, a collection of Linear Operators <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{B_{j}\}}" class="latex" title="{\{B_{j}\}}" /> and density matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> are the marginal of an optimal strategy iff the map <img src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{j} \rightarrow B_{j}}" class="latex" title="{X_{j} \rightarrow B_{j}}" /> induces a density-matrix representation of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> commutes with <img src="https://s0.wp.com/latex.php?latex=%7Bim%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{im(\mathcal{A})}" class="latex" title="{im(\mathcal{A})}" />. <a name="th20"></a> </em>
Put simply, the theorem states that our unknown self-adjoint operators map to an optimal marginal strategy iff the density matrix (traced from the joint Hilbert-Space) commutes with all the mapped operators (<img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" />). The result we desire on the lower bound for the number of entangled bits, given a mapping from these indeterminate operators to the marginal of an optimal strategy, comes from a corollary to <a href="https://windowsontheory.org/feed/#th20">(14)</a>.
<br />Corollary 15 <em> Given a <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR game G (with no zero rows or columns) and a solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> with minimum dimension <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> among non-zero representations, the strategy for minimum entanglement uses <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log_{2}(N)}" class="latex" title="{\log_{2}(N)}" /> entangled bits. <a name="co21"></a> </em>
The proof for this corollary follows from the eigenspace decomposition of the joint Hilbert Space <img src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H}" class="latex" title="{ H}" /> in terms of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" />, which is preserved by the action of <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\mathcal{A})}" class="latex" title="{ im(\mathcal{A})}" />. As a result, each eigenspace decomposes into a finite sum of irreducible representations of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" />. The minimum entanglement is realized when there is exactly one invariant subspace (with one irreducible representation). The entanglement used by such a representation is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28%5Ctext%7Bdim%7D%5C%2CH%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \log_{2}(\text{dim}\,H)}" class="latex" title="{ \log_{2}(\text{dim}\,H)}" />.
<h3> Proof of Theorem 20</h3>
The rest of the section is dedicated to sketching a brief (but formal) proof for Theorem <a href="https://windowsontheory.org/feed/#th20">(14)</a>, and then using a simple fact about the representations of a Clifford Algebra to show how Slofstra’s result subsumes Tsirelson’s bound.

For this section, <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle}" class="latex" title="{ |{\psi}\rangle}" /> refers to an arbitrary state in <img src="https://s0.wp.com/latex.php?latex=%7B+H+%3D+H_%7BA%7D+%5Cotimes+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H = H_{A} \otimes H_{B}}" class="latex" title="{ H = H_{A} \otimes H_{B}}" /> (the joint Hilbert space). We can write <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Csum_%7Bi%7D+%7C%7Bi%7D%5Crangle+%5Clambda+%7C%7Bi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" class="latex" title="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" /> over some basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{{i}\}}" class="latex" title="{ \{{i}\}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda}" class="latex" title="{ \lambda}" /> is a linear map. Then, the partial trace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \psi}" class="latex" title="{ \psi}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{A}}" class="latex" title="{ H_{A}}" /> is given by <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho+%3D+%5Clambda%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho = \lambda\lambda^{*}}" class="latex" title="{ \rho = \lambda\lambda^{*}}" />.
Let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BB%7D_%7BA%7D%2C+%5Cmathcal%7BB%7D_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" class="latex" title="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" /> denote the algebra generated by <img src="https://s0.wp.com/latex.php?latex=%7B+A_%7B1%7D%2C..%2CA_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_{1},..,A_{m}}" class="latex" title="{ A_{1},..,A_{m}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7B1%7D%2C..%2CB_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{1},..,B_{n}}" class="latex" title="{ B_{1},..,B_{n}}" />. Here, the generating elements are the observables of an optimal quantum strategy.

To arrive at a proof for the theorem, we will rely on 2 additional lemmas which we will not prove but state.
<br />Lemma 16 <em> Given Hermitian operators <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Cin+H_%7BA%7D%2C+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \in H_{A}, H_{B}}" class="latex" title="{B \in H_{A}, H_{B}}" />,
<a name="eqfrob"></a></em>
<p align="center"><em><a name="eqfrob"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5C%7C%5Clambda%5Coverline%7BA%7D+-+B%5Clambda%5C%7C_%7BF%7D++%5C+%5C+%5C+%5C+%5C+%2816%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" class="latex" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" /></a></em></p>
<em><a name="eqfrob">
</a><a name="eqfrob"></a> This allows us to conclude that,
<a name="eqcomm"></a>
</em>
<p align="center"><em><a name="eqcomm"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5Cepsilon+%5Cimplies+%5C%7C%5Crho%28B%29+-+B%5Crho%5C%7C_%7BF%7D+%5Cleq+2%5Cepsilon++%5C+%5C+%5C+%5C+%5C+%2817%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" class="latex" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" /></a></em></p>
<em>
</em><em><a name="eqcomm">
</a></em><em><a name="eqcomm"></a> <a name="lecomm"></a> </em>
<b>Lemma 17</b> <em> The optimal strategy in question is non-degenerate iff <a name="eqcl1"></a></em>
<p align="center"><em><a name="eqcl1"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+closure%28%5Cmathcal%7BB%7D_%7BA%7D%5Clambda%5E%7B%2A%7DH_%7BB%7D%29.+%5C%5C++%5C+%5C+%5C+%5C+%5C+%2818%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" class="latex" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" /></a></em></p>
<em><a name="eqcl1">
</a><a name="eqcl1"></a> As a special case:
<a name="eqcl2"></a>
</em>
<p align="center"><em><a name="eqcl2"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+H_%7BB%7D+%5Cleftrightarrow+closure%28%5Crho+H_%7BB%7D%29+%3D+H_%7BB%7D++%5C+%5C+%5C+%5C+%5C+%2819%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" class="latex" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" /></a></em></p>
<em>
</em><em><a name="eqcl2">
</a></em><em><a name="eqcl2"></a> <a name="lecl"></a> </em>
<b> Forward direction </b>:
We use the first lemma to prove commutativity of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho" class="latex" title="\rho" /> with all <img src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="B_{j}" class="latex" title="B_{j}" />, and we use the second lemma to show that the closure of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho" class="latex" title="\rho" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{B}}" class="latex" title="{ H_{B}}" />.
We first show the forward direction:
Suppose we are given an optimal quantum strategy (<img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" class="latex" title="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" />) for a game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" />. Then, we fix our optimal vector strategy as:
<a name="eqrs"></a>
<p align="center"><b><a name="eqrs"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u_%7Bi%7D+%3D+%28A_%7Bi%7D+%5Cotimes+%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2820%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" class="latex" title="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" /></a></b></p>
<b><a name="eqrs">
</a><a name="eqrs"></a> <a name="eqcs"></a>
</b>
<p align="center"><b><a name="eqcs"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v_%7Bj%7D+%3D+%28%5Cmathbb%7BI%7D+%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2821%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" class="latex" title="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" /></a></b></p>
<a name="eqcs">
</a><a name="eqcs"></a>

We can now use Equations <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a> and <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> to establish our optimal marginal biases to write a relationship between them and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle}" class="latex" title="{ |{\psi}\rangle}" /> , and apply Lemma <a href="https://windowsontheory.org/feed/#lecomm">(16)</a> to show commutativity and Lemma <a href="https://windowsontheory.org/feed/#lecl">(17)</a> to show that <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\mathcal{A})}" class="latex" title="{ im(\mathcal{A})}" /> = cyclic(<img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}, \rho}" class="latex" title="{ B_{j}, \rho}" />).
Using <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> with <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a>, we have:
<a name="eqqs1"></a>
<p align="center"><a name="eqqs1"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d_%7Bj%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bi%7DG_%7Bij%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2822%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" class="latex" title="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" /></a></p>
<a name="eqqs1">
</a><a name="eqqs1"></a> We can now use <a href="https://windowsontheory.org/feed/#eqcomm">(17)</a> with <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon = 0}" class="latex" title="{ \epsilon = 0}" /> on <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> to see that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> commutes with every <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />.
Additionally, as the terms in <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> constitute linear combinations of <img src="https://s0.wp.com/latex.php?latex=%7B+A_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_{i}}" class="latex" title="{ A_{i}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />, we can compute the closure of their actions on <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda H_{A}}" class="latex" title="{ \lambda H_{A}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%5E%7B%2A%7D+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda^{*} H_{B}}" class="latex" title="{ \lambda^{*} H_{B}}" />, which will be equivalent. Therefore, <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Crho%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\rho)}" class="latex" title="{ im(\rho)}" /> = <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{B}}" class="latex" title="{ H_{B}}" />, which follows from the special case of <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a>.
For the dual case, we substitute <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a> into <a href="https://windowsontheory.org/feed/#eqmarginal">(12)</a>:
<a name="eqdn"></a>
<p align="center"><a name="eqdn"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c_%7Bi%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj%7DG_%7Bij%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" class="latex" title="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" /> </a></p>
<a name="eqdn"></a>

<a name="eqdn">
</a><a name="eqdn"></a><a name="eqdn"></a> On taking the norm of the above on both sides and using a little algebra, we finally obtain the fact that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> satisfy predicate <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> making them the representations of <img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{j}}" class="latex" title="{ X_{j}}" />:

<img src="https://s0.wp.com/latex.php?latex=%7B+%28%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%29%5E%7B2%7D+%3D+c_%7Bi%7D%5E%7B2%7D%7B%5Cmathbb%7BI%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" class="latex" title="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" />

This shows that the map from <img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{j} \rightarrow B_{j}}" class="latex" title="{ X_{j} \rightarrow B_{j}}" /> computes a density matrix representation of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />.

<br /><b> Backward Direction </b>:
The proof for the backward direction is much less involved:
If we knew that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}, \rho}" class="latex" title="{ \{B_{j}\}, \rho}" /> constituted the cyclic representation of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" /> with commutativity (with <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />), then we can use Lemma <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a> to conclude that the image of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H}" class="latex" title="{ H}" /> would form a subspace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda H}" class="latex" title="{ \lambda H}" />. We define:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Coverline%7BA%7D_%7Bi%7D+%3D+%5Cfrac%7B%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%7D%7Bc_%7Bi%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" class="latex" title="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" />

allowing us to recover our original marginal biases <img src="https://s0.wp.com/latex.php?latex=%7B+c_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c_{i}}" class="latex" title="{ c_{i}}" /> that satisfy <a href="https://windowsontheory.org/feed/#eqdn">(23)</a> and therefore correspond to the optimal strategy. This shows us that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}}" class="latex" title="{ \{A_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> would constitute an optimal quantum strategy. 
<div align="right">□</div>
Having proved this theorem, we now obtain Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, which is the main desired result. To see how it subsumes Tsirelson’s result as a special case, we use a simple fact from Representation Theory:
<br /><b>Lemma 18</b> <em> For a Clifford Algebra generated by <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1%7D%2C..%2CX_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1},..,X_{r}}" class="latex" title="{X_{1},..,X_{r}}" />, there exist one or two irreducible representations of dimension <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" title="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" /> <a name="lecr"></a> </em>
Plugging Lemma <a href="https://windowsontheory.org/feed/#lecr">18</a> into Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, we simply recover the fact that the number of entangled bits of a solution algebra that is Clifford is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" />. However, note that being Clifford means an extra constraint:
<img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bi%7DX_%7Bj%7D+%3D+-X_%7Bj%7DX_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{i}X_{j} = -X_{j}X_{i}}" class="latex" title="{ X_{i}X_{j} = -X_{j}X_{i}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cforall+i%2C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \forall i, j}" class="latex" title="{ \forall i, j}" />

The constraints on the Solution Algebra <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a>, <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> given by Slofstra do \textit{not} necessarily mean that the solution is Clifford. In fact, when an optimal quantum strategy with minimal entanglement is Clifford, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}}" class="latex" title="{ \{A_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> are constructed from a unique set of <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bu_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{u_{i}\}}" class="latex" title="{ \{u_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bv_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{v_{j}\}}" class="latex" title="{ \{v_{j}\}}" />.
To end, we write down a lemma that shows there exist XOR games where the optimal strategy is not unique and for minimal entanglement, a solution generated by a Non-Clifford algebra must be used:
<h4>Lemma (Existence of XOR games with Non-Clifford optimal strategies)</h4>
<em> There exist a family of <img src="https://s0.wp.com/latex.php?latex=%7B+m+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ m \times n}" class="latex" title="{ m \times n}" /> XOR games <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BG%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{G\}}" class="latex" title="{ \{G\}}" /> that correspond to generalizations of the CHSH games (<img src="https://s0.wp.com/latex.php?latex=%7BCL_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{CL_{n}}" class="latex" title="{CL_{n}}" />), such that, the optimal strategy of minimal entanglement is Non-Clifford. </em>


<h2>References</h2>
<p>[1] David Avis, Sonoko Moriyama, and Masaki Owari. From bell inequalities to tsirelson’s theorem. IEICE Transactions, 92-A(5):1254–1267, 2009.

</p><p>[2] Lance Fortnow, John Rompel, and Michael Sipser. On the power of multi-prover interactive protocols. Theoretical Computer Science, 134(2):545 – 557, 1994.

</p><p>[3] T. Ito, H. Kobayashi, and K. Matsumoto. Oracularization and Two-Prover One-Round Interactive Proofs against Nonlocal Strategies. ArXiv e-prints, October 2008.

</p><p>[4] J. Kempe, H. Kobayashi, K. Matsumoto, B. Toner, and T. Vidick. Entangled games are hard to approximate. ArXiv e-prints, April 2007.

</p><p>[5] Julia Kempe, Oded Regev, and Ben Toner. Unique games with entangled provers are easy. SIAM Journal on Computing, 39(7):3207– 3229, 2010.

</p><p>[6] S. Khanna, M. Sudan, L. Trevisan, and D. Williamson. The approximability of constraint satisfaction problems. SIAM Journal on Computing, 30(6):1863–1920, 2001.

</p><p>[7] Anand Natarajan and Thomas Vidick. Two-player entangled games are NP-hard. arXiv e-prints, page arXiv:1710.03062, October 2017.

</p><p>[8] Anand Natarajan and Thomas Vidick. Low-degree testing for quantum states, and a quantum entangled games PCP for QMA. arXiv e-prints, page arXiv:1801.03821, January 2018.

</p><p>[9] William Slofstra. Lower bounds on the entanglement needed to play xor non-local games. CoRR, abs/1007.2248, 2010.

</p><p>[10] B.S. Tsirelson. Quantum analogues of the bell inequalities. the case of two spatially separated domains. Journal of Soviet Mathematics, 36(4):557–570, 1987.

</p><p>[11] Thomas Vidick. Three-player entangled XOR games are NP-hard to approximate. arXiv e-prints, page arXiv:1302.1242, February 2013.

</p><p>[12] Thomas Vidick. Cs286.2 lecture 15: Tsirelson’s characterization of xor games. Online, December 2014. Lecture Notes.

</p><p>[13] Thomas Vidick. Cs286.2 lecture 17: Np-hardness of computing <img src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\omega^*(G)" class="latex" title="\omega^*(G)" />. Online, December 2014. Lecture Notes.



</p><p></p></div>







<p class="date">
by mitalibafna <a href="https://windowsontheory.org/2019/01/03/quantum-games/"><span class="datestr">at January 04, 2019 04:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3027987398928428578">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/01/today-is-thirdsday-enjoy-it-while-you.html">Today is Thirdsday!  Enjoy it while you can!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Fellow Blogger James Propp has come up with a new Math holiday:<br />
<br />
<b>Thirsdsday!</b><br />
<br />
The day is Jan 3 (1-3 in America, though 3-1 in ... Everywhere else?) but only when Jan 3 is a Thursday.<br />
<br />
It is a day where we celebrate the magic of the number 1/3.<br />
<br />
0) For other math days to celebrate see <a href="https://stemjobs.com/math-holidays/">here</a><br />
<br />
1/3) James Propp's blog about Thirdsday on Monday Dec 31. Really ???   : <a href="https://mathenchant.wordpress.com/2018/12/31/introducing-thirdsday/#more-2632">here</a><br />
<br />
2/3) Evelyn Lamb blogged about Thirdsday on Tuesday Jan 1. Really ??? : <a href="https://blogs.scientificamerican.com/roots-of-unity/how-to-celebrate-thirdsday/">here</a><br />
<br />
3/3) Ben Orlin blogged about Thirsdsday on Wedensday Jan 2. Really??? <a href="https://mathwithbaddrawings.com/2019/01/02/thirdsday-the-holiday-thats-33-33-better-than-any-other/">here</a><br />
<br />
(Added ON Thirdsday: Matt Foreman has a video about Thirdsday: <a href="https://www.youtube.com/watch?v=NinrTW1Bx2Y&amp;feature=youtu.be">here</a> and a blog post <a href="https://www.think-maths.co.uk/celebrating-thirdsday">here</a>)<br />
<br />
 How come I'm the only one blogged  about Thirdsday on Thursday Jan 3 ??? (Added later- not quite true anymore, Matt Foreman also waited until Thirdsday to post on Thirdsday).<br />
I asked Jim Propp about this. He said that he want to help prepare teachers and other eduators for the excitment of Thirdsday! If they already know the wonders of 1/3 they can prepare and lecture on it! Kudos to him! I assume that Evelyn and Ben are similar! Kudos to them! And Ben blogged ON Thirdsday so Kudos to him!<br />
<br />
2) Darling asked me `<i>is it a real day like Pi-Day?'</i>  Is Pi-Day real? Is any Holiday real? All holidays are made up until they are accepted and become real. The distinction between <i>real holidays</i> and  <i>made up holidays</i>  is ... nonexistent.  One can talk of <i>accepted </i>and <i>not-accepted</i> holidays.  How long did Pi-day take to be accepted? This is prob not a well defined question.<br />
<br />
3) James Propp's and Evelyn Lamb's  blog has many math properties of 1/3.  One educational property: I think it is the first number that students see that is an infinite decimal. My favorite unbiased use of 1/3: The Cantor Set: Uncountable subset of [0,1] that has measure 0. Really!!! My favorite biased use: its important in Muffin Math. If m&gt;s and you want to divide and distribute m muffins to s students, there is always a way to do this with smallest piece at least 1/3. (Usually you can do better but this is sometimes the best you can do.)<br />
<br />
4) When will the next Thirdsday come?<br />
<br />
2019: Jan 3 is a Thursday, so YES<br />
<br />
2020: Jan 3 is a Friday, so NO<br />
<br />
2021: Jan 3 is a Sunday (why no Saturday? Leap year. Great- it will come sooner!)  so NO<br />
<br />
2022: Jan 3 is a Monday, so NO<br />
<br />
2023: Jan 3 is a Tuesday  so NO<br />
<br />
2024: Jan 3 is a Wednesday  so NO<br />
<br />
2025: Jan 3 is a Friday. WHAT! Why no Thirdsday?  Darn leap year! So NO.<br />
<br />
2026: Jan 3 is a Saturday, so NO<br />
<br />
2027: Jan 3 is a Sunday so NO<br />
<br />
2028: Jan 3 is a Monday so NO<br />
<br />
2029: Jan 3 is a Wedensday (Why no Tuesday? Leap year), so NO<br />
<br />
2030: Jan 3 is a Thursday (Leap Year helped!), so YES FINALLY!<br />
<br />
(Exercise: find a formula: if 2019 was the first Thirdsday, find the year for TD(i), the ith Thirdsday.)<br />
<br />
So enjoy Thirdsday in 2019 when spellcheck still flags it.<br />
<br />
In 2030 it will be an accepted holiday and spellcheck will think it's fine.<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/01/today-is-thirdsday-enjoy-it-while-you.html"><span class="datestr">at January 03, 2019 05:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
