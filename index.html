<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at September 30, 2019 01:21 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/130">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/130">TR19-130 |  A moment ratio bound for polynomials and some extremal properties of Krawchouk polynomials and Hamming spheres | 

	Alex Samorodnitsky, 

	Naomi Kirshner</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Let $p \ge 2$. We improve the bound $\frac{\|f\|_p}{\|f\|_2} \le (p-1)^{s/2}$ for a polynomial $f$ of degree $s$ on the boolean cube $\{0,1\}^n$, which comes from hypercontractivity, replacing the right hand side of this inequality by an explicit bivariate function of $p$ and $s$, which is smaller than $(p-1)^{s/2}$ for any $p &gt; 2$ and $s &gt; 0$. We show the new bound to be tight, within a smaller order factor, for the Krawchouk polynomial of degree $s$.

This implies several nearly-extremal properties of Krawchouk polynomials and Hamming spheres (equivalently, Hamming balls). In particular, Krawchouk polynomials have (almost) the heaviest tails among all polynomials of the same degree and $\ell_2$ norm (this has to be interpreted with some care). The Hamming spheres have the following approximate edge-isoperimetric property: For all $1 \le s \le \frac{n}{2}$, and for all even distances $0 \le i \le \frac{2s(n-s)}{n}$, the Hamming sphere of radius $s$ contains, up to a multiplicative factor of $O(i)$, as many pairs of points at distance $i$ as possible, among sets of the same size (there is a similar, but slightly weaker and somewhat more complicated claim for general distances). This also implies that Hamming spheres are (almost) stablest with respect to noise among sets of the same size. In coding theory terms this means that a Hamming sphere (equivalently a Hamming ball) has the maximal probability of undetected error, among all binary codes of the same rate.

We also describe a family of hypercontractive inequalities for functions on $\{0,1\}^n$, which improve on the `usual' ``$q \rightarrow 2$" inequality by taking into account the concentration of a function (expressed as the ratio between its $\ell_r$ norms), and which are nearly tight for characteristic functions of Hamming spheres.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/130"><span class="datestr">at September 30, 2019 07:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12760">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12760">Beating Greedy for Stochastic Bipartite Matching</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamlath:Buddhima.html">Buddhima Gamlath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kale:Sagar.html">Sagar Kale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12760">PDF</a><br /><b>Abstract: </b>We consider the maximum bipartite matching problem in stochastic settings,
namely the query-commit and price-of-information models. In the query-commit
model, an edge e independently exists with probability $p_e$. We can query
whether an edge exists or not, but if it does exist, then we have to take it
into our solution. In the unweighted case, one can query edges in the order
given by the classical online algorithm of Karp, Vazirani, and Vazirani to get
a $(1-1/e)$-approximation. In contrast, the previously best known algorithm in
the weighted case is the $(1/2)$-approximation achieved by the greedy algorithm
that sorts the edges according to their weights and queries in that order.
</p>
<p>Improving upon the basic greedy, we give a $(1-1/e)$-approximation algorithm
in the weighted query-commit model. We use a linear program (LP) to upper bound
the optimum achieved by any strategy. The proposed LP admits several structural
properties that play a crucial role in the design and analysis of our
algorithm. We also extend these techniques to get a $(1-1/e)$-approximation
algorithm for maximum bipartite matching in the price-of-information model
introduced by Singla, who also used the basic greedy algorithm to give a
$(1/2)$-approximation.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12760"><span class="datestr">at September 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12755">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12755">On the Approximation Ratio of the $k$-Opt and Lin-Kernighan Algorithm for Metric TSP</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Xianghui.html">Xianghui Zhong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12755">PDF</a><br /><b>Abstract: </b>The $k$-Opt and Lin-Kernighan algorithm are two of the most important local
search approaches for the metric TSP. Both start with an arbitrary tour and
make local improvements in each step to get a shorter tour. We show that, for
any fixed $k\geq 3$, the approximation ratio of the $k$-Opt algorithm is
$O(\sqrt[k]{n})$. Assuming the Erd\H{o}s girth conjecture, we prove a matching
lower bound of $\Omega(\sqrt[k]{n})$. Unconditionally, we obtain matching
bounds for $k=3,4,6$ and a lower bound of $\Omega(n^{\frac{2}{3k-3}})$. Our
most general bounds depend on the values of a function from extremal graph
theory and are sharp up to a logarithmic factor unconditionally. Moreover, all
the upper bounds also apply to a parameterized version of the Lin-Kernighan
algorithm with appropriate parameter.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12755"><span class="datestr">at September 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12658">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12658">Quantum Algorithm for Finding the Optimal Variable Ordering for Binary Decision Diagrams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tani:Seiichiro.html">Seiichiro Tani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12658">PDF</a><br /><b>Abstract: </b>An ordered binary decision diagram (OBDD) is a directed acyclic graph that
represents a Boolean function. OBDDs are also known as special cases of
oblivious read-once branching programs in the field of complexity theory. Since
OBDDs have many nice properties as data structures, they have been extensively
studied for decades in both theoretical and practical fields, such as VLSI
design, formal verification, machine learning, and combinatorial problems.
Arguably, the most crucial problem in using OBDDs is that they may vary
exponentially in size depending on their variable ordering (i.e., the order in
which the variable are to read) when they represent the same function. Indeed,
it is NP hard to find an optimal variable ordering that minimizes an OBDD for a
given function. Hence, numerous studies have sought heuristics to find an
optimal variable ordering. From practical as well as theoretical points of
view, it is also important to seek algorithms that output optimal solutions
with lower (exponential) time complexity than trivial brute-force algorithms
do. Friedman and Supowit provided a clever deterministic algorithm with
time/space complexity $O^\ast(3^n)$, where $n$ is the number of variables of
the function, which is much better than the trivial brute-force bound
$O^\ast(n!2^n)$. This paper shows that a further speedup is possible with
quantum computers by demonstrating the existence of a quantum algorithm that
produces a minimum OBDD together with the corresponding variable ordering in
$O^\ast(2.77286^n)$ time and space with an exponentially small error. Moreover,
this algorithm can be adapted to constructing other minimum decision diagrams
such as zero-suppressed BDDs, which provide compact representations of sparse
sets and are often used in the field of discrete optimization and enumeration.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12658"><span class="datestr">at September 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12518">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12518">Margin-Based Generalization Lower Bounds for Boosted Classifiers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Allan Grønland, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamma:Lior.html">Lior Kamma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Larsen:Kasper_Green.html">Kasper Green Larsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mathiasen:Alexander.html">Alexander Mathiasen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nelson:Jelani.html">Jelani Nelson</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12518">PDF</a><br /><b>Abstract: </b>Boosting is one of the most successful ideas in machine learning. The most
well-accepted explanations for the low generalization error of boosting
algorithms such as AdaBoost stem from margin theory. The study of margins in
the context of boosting algorithms was initiated by Schapire, Freund, Bartlett
and Lee (1998) and has inspired numerous boosting algorithms and generalization
bounds. To date, the strongest known generalization (upper bound) is the $k$th
margin bound of Gao and Zhou (2013). Despite the numerous generalization upper
bounds that have been proved over the last two decades, nothing is known about
the tightness of these bounds. In this paper, we give the first margin-based
lower bounds on the generalization error of boosted classifiers. Our lower
bounds nearly match the $k$th margin bound and thus almost settle the
generalization performance of boosted classifiers in terms of margins.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12518"><span class="datestr">at September 30, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12474">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12474">Stratified Space Learning: Reconstructing Embedded Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Yossi Bokor, Daniel Grixti-Cheng, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hegland:Markus.html">Markus Hegland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roberts:Stephen.html">Stephen Roberts</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Turner:Katharine.html">Katharine Turner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12474">PDF</a><br /><b>Abstract: </b>Many data-rich industries are interested in the efficient discovery and
modelling of structures underlying large data sets, as it allows for the fast
triage and dimension reduction of large volumes of data embedded in high
dimensional spaces. The modelling of these underlying structures is also
beneficial for the creation of simulated data that better represents real data.
In particular, for systems testing in cases where the use of real data streams
might prove impractical or otherwise undesirable. We seek to discover and model
the structure by combining methods from topological data analysis with
numerical modelling. As a first step in combining these two areas, we examine
the recovery of the abstract graph $G$ structure, and model a linear embedding
$|G|$ given only a noisy point cloud sample $X$ of $|G|$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12474"><span class="datestr">at September 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12441">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12441">Total Least Squares Regression in Input Sparsity Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diao:Huaian.html">Huaian Diao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Song:Zhao.html">Zhao Song</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Xin.html">Xin Yang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12441">PDF</a><br /><b>Abstract: </b>In the total least squares problem, one is given an $m \times n$ matrix $A$,
and an $m \times d$ matrix $B$, and one seeks to "correct" both $A$ and $B$,
obtaining matrices $\hat{A}$ and $\hat{B}$, so that there exists an $X$
satisfying the equation $\hat{A}X = \hat{B}$. Typically the problem is
overconstrained, meaning that $m \gg \max(n,d)$. The cost of the solution
$\hat{A}, \hat{B}$ is given by $\|A-\hat{A}\|_F^2 + \|B - \hat{B}\|_F^2$. We
give an algorithm for finding a solution $X$ to the linear system
$\hat{A}X=\hat{B}$ for which the cost $\|A-\hat{A}\|_F^2 + \|B-\hat{B}\|_F^2$
is at most a multiplicative $(1+\epsilon)$ factor times the optimal cost, up to
an additive error $\eta$ that may be an arbitrarily small function of $n$.
Importantly, our running time is $\tilde{O}( \mathrm{nnz}(A) + \mathrm{nnz}(B)
) + \mathrm{poly}(n/\epsilon) \cdot d$, where for a matrix $C$,
$\mathrm{nnz}(C)$ denotes its number of non-zero entries. Importantly, our
running time does not directly depend on the large parameter $m$. As total
least squares regression is known to be solvable via low rank approximation, a
natural approach is to invoke fast algorithms for approximate low rank
approximation, obtaining matrices $\hat{A}$ and $\hat{B}$ from this low rank
approximation, and then solving for $X$ so that $\hat{A}X = \hat{B}$. However,
existing algorithms do not apply since in total least squares the rank of the
low rank approximation needs to be $n$, and so the running time of known
methods would be at least $mn^2$. In contrast, we are able to achieve a much
faster running time for finding $X$ by never explicitly forming the equation
$\hat{A} X = \hat{B}$, but instead solving for an $X$ which is a solution to an
implicit such equation. Finally, we generalize our algorithm to the total least
squares problem with regularization.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12441"><span class="datestr">at September 30, 2019 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12386">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12386">Affine Extensions of Integer Vector Addition Systems with States</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Blondin:Michael.html">Michael Blondin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haase:Christoph.html">Christoph Haase</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mazowiecki:Filip.html">Filip Mazowiecki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raskin:Mikhail.html">Mikhail Raskin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12386">PDF</a><br /><b>Abstract: </b>We study the reachability problem for affine $\mathbb{Z}$-VASS, which are
integer vector addition systems with states in which transitions perform affine
transformations on the counters. This problem is easily seen to be undecidable
in general, and we therefore restrict ourselves to affine $\mathbb{Z}$-VASS
with the finite-monoid property (afmp-$\mathbb{Z}$-VASS). The latter have the
property that the monoid generated by the matrices appearing in their affine
transformations is finite. The class of afmp-$\mathbb{Z}$-VASS encompasses
classical operations of counter machines such as resets, permutations,
transfers and copies. We show that reachability in an afmp-$\mathbb{Z}$-VASS
reduces to reachability in a $\mathbb{Z}$-VASS whose control-states grow
linearly in the size of the matrix monoid. Our construction shows that
reachability relations of afmp-$\mathbb{Z}$-VASS are semilinear, and in
particular enables us to show that reachability in $\mathbb{Z}$-VASS with
transfers and $\mathbb{Z}$-VASS with copies is PSPACE-complete. We then focus
on the reachability problem for affine $\mathbb{Z}$-VASS with monogenic
monoids: (possibly infinite) matrix monoids generated by a single matrix. We
show that, in a particular case, the reachability problem is decidable for this
class, disproving a conjecture about affine $\mathbb{Z}$-VASS with infinite
matrix monoids we raised in a preliminary version of this paper. We complement
this result by presenting an affine $\mathbb{Z}$-VASS with monogenic matrix
monoid and undecidable reachability relation.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12386"><span class="datestr">at September 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12379">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12379">Packet-oblivious stable routing in multi-hop wireless networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cholvi:Vicent.html">Vicent Cholvi</a>, Paweł Garncarek, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jurdzinski:Tomasz.html">Tomasz Jurdzinski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kowalski:Dariusz_R=.html">Dariusz R. Kowalski</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12379">PDF</a><br /><b>Abstract: </b>In this work, we study the fundamental problem of scheduling communication in
multi-hop wireless networks.
</p>
<p>We focus on packet-oblivious routing protocols; that is, algorithms that do
not take into account any historical information about packets or carried out
by packets. Such protocols are well motivated in practice, as real forwarding
protocols and corresponding data-link layer architectures are typically
packet-oblivious. We provide a local-knowledge protocol, i.e., which is working
without using any topological information, except for some upper bounds on the
number of links and the network's degree, that is stable for a wide spectrum of
packet injection rates. It is based on novel transmission schedules, called
universally strong selectors, which, combined with some known queuing policies
(LIS, SIS, NFS, FTG), makes it the best known local-knowledge packet-oblivious
routing protocol regarding the injection rate for which stability is
guaranteed. We also propose a global-knowledge protocol, which is stable if the
packet injection rate per link is smaller than the inverse of the chromatic
number of the collision graph associated with the network. Although the
protocol does not take into account any historical information, it has to be
seeded by some information about the network topology.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12379"><span class="datestr">at September 30, 2019 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12353">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12353">Interactive Particle Systems on Hypergraphs, Drift Analysis and the WalkSAT algorithm</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Istrate:Gabriel.html">Gabriel Istrate</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonchis:Cosmin.html">Cosmin Bonchis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marin:Mircea.html">Mircea Marin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12353">PDF</a><br /><b>Abstract: </b>We analyze the expected running time of WalkSAT, a well-known local search
procedure for satisfiability solving, on satisfiable instances of the k-XOR SAT
problem. We obtain estimates of this expected running time by reducing the
problem to a setting amenable to classical techniques from drift analysis.
</p>
<p>A crucial ingredient of this reduction is the definition of (new, explosive)
hypergraph versions of interacting particle systems, notably of coalescing and
annihilating random walks as well as the voter model. The use of these tools
allows to show that the expected running time of WalkSAT depends on structural
parameter (we call odd Cheeger drift) of the dual of the formula hypergraph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12353"><span class="datestr">at September 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12328">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12328">Approximation Algorithms for Process Systems Engineering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Letsios:Dimitrios.html">Dimitrios Letsios</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baltean=Lugojan:Radu.html">Radu Baltean-Lugojan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Ceccon:Francesco.html">Francesco Ceccon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mistry:Miten.html">Miten Mistry</a>, Johannes Wiebe, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Misener:Ruth.html">Ruth Misener</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12328">PDF</a><br /><b>Abstract: </b>Designing and analyzing algorithms with provable performance guarantees
enables efficient optimization problem solving in different application
domains, e.g.\ communication networks, transportation, economics, and
manufacturing. Despite the significant contributions of approximation
algorithms in engineering, only limited and isolated works contribute from this
perspective in process systems engineering. The current paper discusses three
representative, NP-hard problems in process systems engineering: (i) pooling,
(ii) process scheduling, and (iii) heat exchanger network synthesis. We survey
relevant results and raise major open questions. Further, we present
approximation algorithms applications which are relevant to process systems
engineering: (i) better mathematical modeling, (ii) problem classification,
(iii) designing solution methods, and (iv) dealing with uncertainty. This paper
aims to motivate further research at the intersection of approximation
algorithms and process systems engineering.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12328"><span class="datestr">at September 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12256">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12256">Circuit equivalence in 2-nilpotent algebras</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Piotr Kawałek, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kompatscher:Michael.html">Michael Kompatscher</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krzaczkowski:Jacek.html">Jacek Krzaczkowski</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12256">PDF</a><br /><b>Abstract: </b>The circuit equivalence problem of a finite algebra $\mathbf A$ is the
computational problem of deciding whether two circuits over $\mathbf A$ define
the same function or not. This problem not just generalises the equivalence
problem for Boolean circuits, but is also of high interest in universal
algebra, as it models the problems of checking identities in $\mathbf A$. In
this paper we discuss the complexity for algebras from congruence modular
varieties. A partial classification was already given by Idziak and
Krzaczkowski, leaving essentially only a gap for nilpotent but not
supernilpotent algebras. We start a systematic study of this open case, proving
that the circuit equivalence problem is in P for $2$-nilpotent such algebras.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12256"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12252">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12252">Using E-Graphs for CAD Parameter Inference</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nandi:Chandrakana.html">Chandrakana Nandi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anderson:Adam.html">Adam Anderson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Willsey:Max.html">Max Willsey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wilcox:James_R=.html">James R. Wilcox</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Darulova:Eva.html">Eva Darulova</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grossman:Dan.html">Dan Grossman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatlock:Zachary.html">Zachary Tatlock</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12252">PDF</a><br /><b>Abstract: </b>Computational fabrication is increasingly popular among end-users and makers
in the form of 3D printing and laser cutting. Using Computer-Aided Design (CAD)
tools to construct models from scratch is a significant barrier to entry for
new users, so many online repositories provide ready-to-print though
difficult-to-edit triangle meshes of popular designs. Recent work has proposed
program synthesis techniques to automatically decompile triangle meshes to
easier-to-edit Constructive Solid Geometry (CSG) designs. While these
synthesized CSG designs simplify editing some models, they are flat, i.e., they
do not contain loops or other forms of parameterization, which makes editing
designs with repeated structure challenging.
</p>
<p>This paper presents an algorithm for lifting CSG designs to CAD programs,
preserving equivalence to the original CSGs but parameterizing over repetitive
structures. Our technique takes as input a flat CSG and infers parameters that
capture the latent structure of the CSG using an equality-graph based rewrite
mechanism combined with constraint solvers for inferring arithmetic operations.
Our algorithm synthesizes CAD programs with (possibly nested) loops and
arithmetic expressions including trigonometric functions. We implemented our
algorithm in a tool called tool and evaluated it by running it on 16 designs
collected from popular model-sharing websites and found that it reduces code
size by 64% on average, and exposes the underlying structure for 81% of the
models.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12252"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12211">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12211">On the complexity of the clone membership problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Emil Jeřábek <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12211">PDF</a><br /><b>Abstract: </b>We investigate the complexity of the Boolean clone membership problem (CMP):
given a set of Boolean functions $F$ and a Boolean function $f$, determine if
$f$ is in the clone generated by $F$, i.e., if it can be expressed by a circuit
with $F$-gates. Here, $f$ and elements of $F$ are given as circuits or formulas
over the usual De Morgan basis. B\"ohler and Schnoor (2007) proved that for any
fixed $F$, the problem is coNP-complete, with a few exceptions where it is in
P. Vollmer (2009) incorrectly claimed that the full problem CMP is also
coNP-complete. We prove that CMP is in fact $\Theta^P_2$-complete, and we
complement B\"ohler and Schnoor's results by showing that for fixed $f$, the
problem is NP-complete unless $f$ is a projection.
</p>
<p>More generally, we study the problem $B$-CMP where $F$ and $f$ are given by
circuits using gates from $B$. For most choices of $B$, we classify the
complexity of $B$-CMP as being $\Theta^P_2$-complete (possibly under randomized
reductions), coDP-complete, or in P.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12211"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12209">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12209">Heuristics for Symmetric Rectilinear Matrix Partitioning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Abdurrahman Yaşar, Ümit V. Çatalyürek <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12209">PDF</a><br /><b>Abstract: </b>Partitioning sparse matrices and graphs is a common and important problem in
many scientific and graph analytics applications. In this work, we are
concerned with a spatial partitioning called rectilinear partitioning (also
known as generalized block distribution) of sparse matrices, which is needed
for tiled (or {\em blocked}) execution of sparse matrix and graph analytics
kernels. More specifically, in this work, we address the problem of symmetric
rectilinear partitioning of square matrices. By symmetric, we mean having the
same partition on rows and columns of the matrix, yielding a special tiling
where the diagonal tiles (blocks) will be squares. We propose five heuristics
to solve two different variants of this problem, and present a thorough
experimental evaluation showing the effectiveness of the proposed algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12209"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12044">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12044">How does object fatness impact the complexity of packing in d dimensions?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kisfaludi=Bak:S=aacute=ndor.html">Sándor Kisfaludi-Bak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">Dániel Marx</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zanden:Tom_C=_van_der.html">Tom C. van der Zanden</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12044">PDF</a><br /><b>Abstract: </b>Packing is a classical problem where one is given a set of subsets of
Euclidean space called objects, and the goal is to find a maximum size subset
of objects that are pairwise non-intersecting. The problem is also known as the
Independent Set problem on the intersection graph defined by the objects.
Although the problem is NP-complete, there are several subexponential
algorithms in the literature. One of the key assumptions of such algorithms has
been that the objects are fat, with a few exceptions in two dimensions; for
example, the packing problem of a set of polygons in the plane surprisingly
admits a subexponential algorithm. In this paper we give tight running time
bounds for packing similarly-sized non-fat objects in higher dimensions.
</p>
<p>We propose an alternative and very weak measure of fatness called the
stabbing number, and show that the packing problem in Euclidean space of
constant dimension $d \geq 3$ for a family of similarly sized objects with
stabbing number $\alpha$ can be solved in $2^{O(n^{1-1/d}\alpha)}$ time. We
prove that even in the case of axis-parallel boxes of fixed shape, there is no
$2^{o(n^{1-1/d}\alpha)}$ algorithm under ETH. This result smoothly bridges the
whole range of having constant-fat objects on one extreme ($\alpha=1$) and a
subexponential algorithm of the usual running time, and having very "skinny"
objects on the other extreme ($\alpha=n^{1/d}$), where we cannot hope to
improve upon the brute force running time of $2^{O(n)}$, and thereby
characterizes the impact of fatness on the complexity of packing in case of
similarly sized objects. We also study the same problem when parameterized by
the solution size $k$, and give a $n^{O(k^{1-1/d}\alpha)}$ algorithm, with an
almost matching lower bound.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12044"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12025">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12025">The Approximation Ratio of the 2-Opt Heuristic for the Metric Traveling Salesman Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hougardy:Stefan.html">Stefan Hougardy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zaiser:Fabian.html">Fabian Zaiser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Xianghui.html">Xianghui Zhong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12025">PDF</a><br /><b>Abstract: </b>The 2-Opt heuristic is one of the simplest algorithms for finding good
solutions to the metric Traveling Salesman Problem. It is the key ingredient to
the well-known Lin-Kernighan algorithm and often used in practice. So far, only
upper and lower bounds on the approximation ratio of the 2-Opt heuristic for
the metric TSP were known. We prove that for the metric TSP with $n$ cities,
the approximation ratio of the 2-Opt heuristic is $\sqrt{n/2}$ and that this
bound is tight.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12025"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.12004">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.12004">Complexity of Liveness in Parameterized Systems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chini:Peter.html">Peter Chini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyer:Roland.html">Roland Meyer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saivasan:Prakash.html">Prakash Saivasan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.12004">PDF</a><br /><b>Abstract: </b>We investigate the fine-grained complexity of liveness verification for
leader contributor systems. These consist of a designated leader thread and an
arbitrary number of identical contributor threads communicating via a shared
memory. The liveness verification problem asks whether there is an infinite
computation of the system in which the leader reaches a final state infinitely
often. Like its reachability counterpart, the problem is known to be
NP-complete. Our results show that, even from a fine-grained point of view, the
complexities differ only by a polynomial factor.
</p>
<p>Liveness verification decomposes into reachability and cycle detection. We
present a fixed point iteration solving the latter in polynomial time. For
reachability, we reconsider the two standard parameterizations. When
parameterized by the number of states of the leader L and the size of the data
domain D, we show an (L + D)^O(L + D)-time algorithm. It improves on a previous
algorithm, thereby settling an open problem. When parameterized by the number
of states of the contributor C, we reuse an O*(2^C)-time algorithm. We show how
to connect both algorithms with the cycle detection to obtain algorithms for
liveness verification. The running times of the composed algorithms match those
of reachability, proving that the fine-grained lower bounds for liveness
verification are met.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.12004"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.11970">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.11970">Approximation Algorithms for Scheduling with Class Constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Klaus.html">Klaus Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lassota:Alexandra.html">Alexandra Lassota</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maack:Marten.html">Marten Maack</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.11970">PDF</a><br /><b>Abstract: </b>Assigning jobs onto identical machines with the objective to minimize the
maximal load is one of the most basic problems in combinatorial optimization.
Motivated by product planing and data placement, we study a natural extension
called Class Constrainted Scheduling (CCS). In this problem, each job
additionally belongs to a class and each machine can only schedule jobs from at
most $c$ different classes. Even though this problem is closely related to the
Class Constraint Bin Packing, the Class Constraint Knapsack and the Cardinality
Constraint variants, CCS lacks results regarding approximation algorithms, even
though it is also well-known to be NP-hard. We fill this gap by analyzing the
problem considering three different ways to feasibly allot the jobs: The
splittable case, where we can split and allot the jobs arbitrarily; the
preemptive case, where jobs pieces belonging to the same job are not allowed to
be scheduled in parallel; and finally the non-preemptive case, where no
splitting is allowed at all. For each case we introduce the first PTAS where
neither $c$ nor the number of all classes have to be a constant. In order to
achieve this goal, we give new insights about the structure of optimal
solutions. This allows us to preprocess the instance appropriately and by
additionally grouping variables to set up a configuration Integer Linear
Program (ILP) with N-fold structure. This N-fold structure allows us to solve
the ILP efficiently. Further we developed the first simple approximation
algorithms with a constant approximation ratio running in strongly polynomial
time. The splittable and the preemptive case admit algorithms with ratio $2$
and a running time of $O(n^2 \log(n))$. The algorithm for the non-preemptive
case has a ratio of $7/3$ and a running time of $O(n^2 \log^2(n))$. All results
even hold if the number of machines cannot be bounded by a polynomial in $n$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.11970"><span class="datestr">at September 29, 2019 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.11930">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.11930">String Indexing with Compressed Patterns</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Steiner:Teresa_Anna.html">Teresa Anna Steiner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.11930">PDF</a><br /><b>Abstract: </b>Given a string $S$ of length $n$, the classic string indexing problem is to
preprocess $S$ into a compact data structure that supports efficient subsequent
pattern queries. In this paper we consider the basic variant where the pattern
is given in compressed form and the goal is to achieve query time that is fast
in terms of the compressed size of the pattern. This captures the common
client-server scenario, where a client submits a query and communicates it in
compressed form to a server. Instead of the server decompressing the query
before processing it, we consider how to efficiently process the compressed
query directly. Our main result is a novel linear space data structure that
achieves near-optimal query time for patterns compressed with the classic
Lempel-Ziv compression scheme. Along the way we develop several data structural
techniques of independent interest, including a novel data structure that
compactly encodes all LZ77 compressed suffixes of a string in linear space and
a general decomposition of tries that reduces the search time from logarithmic
in the size of the trie to logarithmic in the length of the pattern.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.11930"><span class="datestr">at September 29, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.11929">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.11929">A moment ratio bound for polynomials and some extremal properties of Krawchouk polynomials and Hamming spheres</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kirshner:Naomi.html">Naomi Kirshner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Samorodnitsky:Alex.html">Alex Samorodnitsky</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.11929">PDF</a><br /><b>Abstract: </b>Let $p \ge 2$. We improve the bound $\frac{\|f\|_p}{\|f\|_2} \le (p-1)^{s/2}$
for a polynomial $f$ of degree $s$ on the boolean cube $\{0,1\}^n$, which comes
from hypercontractivity, replacing the right hand side of this inequality by an
explicit bivariate function of $p$ and $s$, which is smaller than $(p-1)^{s/2}$
for any $p &gt; 2$ and $s &gt; 0$. We show the new bound to be tight, within a
smaller order factor, for the Krawchouk polynomial of degree $s$.
</p>
<p>This implies several nearly-extremal properties of Krawchouk polynomials and
Hamming spheres (equivalently, Hamming balls). In particular, Krawchouk
polynomials have (almost) the heaviest tails among all polynomials of the same
degree and $\ell_2$ norm (this has to be interpreted with some care). The
Hamming spheres have the following approximate edge-isoperimetric property: For
all $1 \le s \le \frac{n}{2}$, and for all even distances $0 \le i \le
\frac{2s(n-s)}{n}$, the Hamming sphere of radius $s$ contains, up to a
multiplicative factor of $O(i)$, as many pairs of points at distance $i$ as
possible, among sets of the same size (there is a similar, but slightly weaker
and somewhat more complicated claim for general distances). This also implies
that Hamming spheres are (almost) stablest with respect to noise among sets of
the same size. In coding theory terms this means that a Hamming sphere
(equivalently a Hamming ball) has the maximal probability of undetected error,
among all binary codes of the same rate.
</p>
<p>We also describe a family of hypercontractive inequalities for functions on
$\{0,1\}^n$, which improve on the `usual' "$q \rightarrow 2$" inequality by
taking into account the concentration of a function (expressed as the ratio
between its $\ell_r$ norms), and which are nearly tight for characteristic
functions of Hamming spheres.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.11929"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.11778">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.11778">Design of Algorithms under Policy-Aware Local Differential Privacy: Utility-Privacy Trade-offs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiang:Zhuolun.html">Zhuolun Xiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ding:Bolin.html">Bolin Ding</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Xi.html">Xi He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Jingren.html">Jingren Zhou</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.11778">PDF</a><br /><b>Abstract: </b>Local differential privacy (LDP) enables private data sharing and analytics
without the need of a trusted data collector. Error-optimal primitives (for,
e.g., estimating means and item frequencies) under LDP have been well studied.
For analytical tasks such as range queries, however, the error is often
dependent on the domain size of private data, which is potentially prohibitive.
This deficiency is inherent as LDP protects the same level of
indistinguishability between any pair of private data values. In this paper, we
investigate a {policy-aware} extension of eps-LDP, where a {policy} is
customizable and defines heterogeneous privacy guarantees for different pairs
of private data values. The policy provides another knob besides eps to tune
utility-privacy trade-offs in analytical workloads. We show that, under
realistic relaxed LDP policies, for analytical workloads such as linear
counting queries, multi-dimensional range queries, and quantile queries, we can
achieve significant gains in utility. In particular, for range queries under
relaxed LDP, we design mechanisms with errors independent on the domain sizes;
instead, their errors depends on the policy, which specifies in what
granularity the private data is protected. We believe that the primitives we
design for policy-aware LDP will be useful in developing mechanisms for other
non-trivial analytical tasks with lower errors, and encourage the adoption of
LDP in practice.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.11778"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.11744">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.11744">Streaming PTAS for Binary $\ell_0$-Low Rank Approximation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharya:Anup.html">Anup Bhattacharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goyal:Dishant.html">Dishant Goyal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaiswal:Ragesh.html">Ragesh Jaiswal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Amit.html">Amit Kumar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.11744">PDF</a><br /><b>Abstract: </b>We give a 3-pass, polylog-space streaming PTAS for the constrained binary
$k$-means problem and a 4-pass, polylog-space streaming PTAS for the binary
$\ell_0$-low rank approximation problem. The connection between the above two
problems has recently been studied. We design a streaming PTAS for the former
and use this connection to obtain streaming PTAS for the latter. This is the
first constant pass, polylog-space streaming algorithm for either of the two
problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.11744"><span class="datestr">at September 29, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/129">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/129">TR19-129 |  Fourier and Circulant Matrices are Not Rigid | 

	Zeev Dvir, 

	Allen Liu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The concept of matrix rigidity was first introduced by Valiant in [Val77].  Roughly speaking, a matrix is rigid if its rank cannot be reduced significantly by changing a small number of entries.  There has been extensive interest in rigid matrices as Valiant showed  that rigidity can be used to prove arithmetic circuit lower bounds.  

In a surprising result, Alman and Williams showed that the (real valued) Hadamard matrix, which was conjectured  to be rigid, is actually not very rigid. This line of work was extended by [DE17] to a family of matrices related to the Hadamard matrix, but over finite fields.  In our work, we take another step in this direction and show that for any abelian group $G$ and function $f:G \rightarrow \mathbb C$, the matrix given by $M_{xy} = f(x - y)$ for $x,y \in G$ is not rigid.  In particular, we get that complex valued Fourier matrices, circulant matrices, and Toeplitz matrices are all not rigid and cannot be used to carry out Valiant's approach to proving circuit lower bounds. This complements a recent result of Goldreich and Tal  who showed that Toeplitz matrices are nontrivially rigid (but not enough for Valiant's method).  Our work differs  from previous non-rigidity results in that those works considered matrices whose underlying group of symmetries was of the form ${\mathbb F}_p^n$ with $p$ fixed and $n$ tending to infinity, while in the families  of matrices we study, the underlying group of symmetries can be any abelian group and, in particular,  the cyclic group ${\mathbb Z}_N$, which has very different structure. Our results also suggest natural new candidates for rigidity in the form of matrices whose symmetry groups are highly non-abelian. We are also able to extend these results to matrices with entries in a finite field, assuming sufficiently large dimension.

Our proof has four parts. The first extends the results of [AW16,DE17]  to generalized Hadamard matrices over the complex numbers via a new proof technique. The second part handles the $N \times N$ Fourier matrix when $N$ has a particularly nice factorization that allows us to embed smaller copies of (generalized) Hadamard matrices inside of it. The third part uses results from number theory to bootstrap the non-rigidity for these special values of $N$ and extend to all sufficiently large $N$.  The fourth and final part involves using the non-rigidity of the Fourier matrix to show that the group algebra matrix, given by $M_{xy} = f(x - y)$ for $x,y \in G$, is not rigid for any function $f$ and abelian group $G$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/129"><span class="datestr">at September 27, 2019 09:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1283">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2019/09/27/travel-funding-for-focs-2019/">Travel funding for FOCS 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="http://focs2019.cs.jhu.edu/">FOCS 2019</a> will be held in Baltimore, MA from Nov 9-12, 2019. The early registration deadline is October 9th.</p>
<p>For students interested in attending, Shang-Hua Teng has asked me to relay the message that there is some travel funding available, courtesy of the NSF. For details, see <a href="http://focs2019.cs.jhu.edu/travel_grants/">this website</a>. Ignore the deadline on that page, but apply ASAP for full consideration. Women and minorities are especially encouraged to apply. Having or presenting papers at FOCS’19 is *not* a prerequisite.</p></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2019/09/27/travel-funding-for-focs-2019/"><span class="datestr">at September 27, 2019 08:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=370">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/09/27/tcs-talk-wednesday-october-2-shachar-lovett-ucsd/">TCS+ talk: Wednesday, October 2 — Shachar Lovett, UCSD</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, October 2th <strong>(next week!)</strong> at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Shachar Lovett</strong> from UCSD will lead us “<em>Towards the sunflower conjecture</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: A sunflower with <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=fff&amp;fg=444444&amp;s=0" alt="r" class="latex" title="r" /> petals is a collection of <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=fff&amp;fg=444444&amp;s=0" alt="r" class="latex" title="r" /> sets so that the intersection of each pair is equal to the intersection of all. Erdos and Rado in 1960 proved the sunflower lemma: for any fixed <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=fff&amp;fg=444444&amp;s=0" alt="r" class="latex" title="r" />, any family of sets of size <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=fff&amp;fg=444444&amp;s=0" alt="w" class="latex" title="w" />, with at least about <img src="https://s0.wp.com/latex.php?latex=w%5Ew&amp;bg=fff&amp;fg=444444&amp;s=0" alt="w^w" class="latex" title="w^w" /> sets, must contain a sunflower. The famous sunflower conjecture is that the bound on the number of sets can be improved to <img src="https://s0.wp.com/latex.php?latex=c%5Ew&amp;bg=fff&amp;fg=444444&amp;s=0" alt="c^w" class="latex" title="c^w" /> for some constant <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=fff&amp;fg=444444&amp;s=0" alt="c" class="latex" title="c" />. Despite much research, the best bounds until recently were all of the order of <img src="https://s0.wp.com/latex.php?latex=w%5E%7Bcw%7D&amp;bg=fff&amp;fg=444444&amp;s=0" alt="w^{cw}" class="latex" title="w^{cw}" /> for some constant c. In this work, we improve the bounds to about <img src="https://s0.wp.com/latex.php?latex=%28%5Clog+w%29%5Ew&amp;bg=fff&amp;fg=444444&amp;s=0" alt="(\log w)^w" class="latex" title="(\log w)^w" />.</p>
<p>There are two main ideas that underlie our result. The first is a structure vs pseudo-randomness paradigm, a commonly used paradigm in combinatorics. This allows us to either exploit structure in the given family of sets, or otherwise to assume that it is pseudo-random in a certain way. The second is a duality between families of sets and DNFs (Disjunctive Normal Forms). DNFs are widely studied in theoretical computer science. One of the central results about them is the switching lemma, which shows that DNFs simplify under random restriction. We show that when restricted to pseudo-random DNFs, much milder random restrictions are sufficient to simplify their structure.</p>
<p>Joint work with Ryan Alweiss, Kewen Wu and Jiapeng Zhang.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/09/27/tcs-talk-wednesday-october-2-shachar-lovett-ucsd/"><span class="datestr">at September 27, 2019 08:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://bit-player.org/?p=2177">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/hayes.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://bit-player.org/2019/my-god-its-full-of-dots">My God, It’s Full of Dots!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://bit-player.org" title="bit-player">bit-player</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Please click or tap in the gray square below. It will fill with a jolly tableau of colored disks—first big blue ones, then somewhat smaller purple ones, and eventually lots of tiny red dots.</p>
<div class="canvas-container canvas-failure" id="demo">
<p>Sorry. My program and your browser are not getting along. None of the interactive elements of this page will work. Could you try a different browser? Current versions of Chrome, Firefox, and Safari seem to work.</p>
</div>
<p class="indent">The disks are scattered randomly, except that no disk is allowed to overlap another disk or extend beyond the boundary of the square. Once a disk has been placed, it never moves, so each later disk has to find a home somewhere in the nooks and crannies between the earlier arrivals. Can this go on forever?</p>
<p>The search for a vacant spot would seem to grow harder as the square gets more crowded, so you might expect the process to get stuck at some point, with no open site large enough to fit the next disk. On the other hand, because the disks get progressively smaller, later ones can squeeze into tighter quarters. In the specific filling protocol shown here, these two trends are in perfect balance. The process of adding disks, one after another, never seems to stall. Yet as the number of disks goes to infinity, they completely fill the box provided for them. There’s a place for every last dot, but there’s no blank space left over.</p>
<p>Or at least that’s the mathematical ideal. The computer program that fills the square above never attains this condition of perfect plenitude. It shuts down after placing just 5,000 disks, which cover about 94 percent of the square’s area. This early exit is a concession to the limits of computer precision and human patience, but we can still dream of how it would work in a world without such tiresome constraints.</p>
<p>This scheme for filling space with randomly placed objects is the invention of John Shier, a physicist who worked for many years in the semiconductor industry and who has also taught at Normandale Community College near Minneapolis. He explains the method and the mathematics behind it in a recent book, <em>Fractalize That! A Visual Essay on Statistical Geometry</em>. (For bibliographic details see the links and references at the end of this essay.) I learned of Shier’s work from my friend Barry Cipra.</p>
<p>Shier hints at the strangeness of these doings by imagining a set of 100 round tiles in graduated sizes, with a total area approaching one square meter. He would give the tiles to a craftsman with these instructions:</p>
<blockquote><p>“Mark off an area of one square meter, either a circle or a square. Start with the largest tile, and attach it permanently anywhere you wish in the marked-off area. Continue to attach the tiles anywhere you wish, proceeding always from larger to smaller. <em>There will always be a place for every tile regardless of how you choose to place them.</em>” How many experienced tile setters would believe this?</p></blockquote>
<p class="indent">Shier’s own creations go way beyond squares and circles filled with simple shapes such as disks. <img src="http://bit-player.org/wp-content/uploads/2019/07/Shier-book-cover-from-Wolrd-Scientific.jpg" height="" width="300" alt="Shier book cover from WS" border="0" class="alignright" />He has shown that the algorithm also works with an assortment of more elaborate designs, including nonconvex figures and even objects composed of multiple disconnected pieces. We get snow­flakes, nested rings, stars, butter­flies, fish eating lesser fish, faces, letters of the alphabet, and visual salads bringing together multiple ingredients. Shier’s interest in these patterns is aesthetic as well as mathematical, and several of his works have appeared in art exhibits; one of them won a best-of-show award at the 2017 Joint Mathematics Meeting.</p>
<p>Shier and his colleagues have also shown that the algorithm can be made to work in three-dimensional space. The book’s cover is adorned with a jumble of randomly placed toruses filling the volume of a transparent cube. If you look closely, you’ll notice that some of the rings are linked; they cannot be disentangled without breaking at least one ring. (The 3D illustration was created by Paul Bourke, who has <a href="http://paulbourke.net/fractals/linkedrings/">more examples online</a>, including 3D-printed models.)</p>
<p>After reading Shier’s account of his adventures, and admiring the pictures, I had to try it for myself. The experiments I’m presenting in this essay have no high artistic ambitions. I stick with plain-vanilla circular disks in a square frame, all rendered with the same banal blue-to-red color scheme. My motive is merely to satisfy my curiosity—or perhaps to overcome my skepticism. When I first read the details of how these graphics are created, I couldn’t quite believe it would work. Writing my own programs and seeing them in action has helped persuade me. So has a proof by Christopher Ennis, which I’ll return to below.</p>
<hr />
<p>Filling a region of the plane with disks is not in itself such a remarkable trick. <img src="http://bit-player.org/wp-content/uploads/2019/07/apollonian_gasket_detail.svg" height="" width="280" alt="Apollonian gasket detail" border="0" class="alignright" />One well-known way of doing it goes by the name Apollonian circles. Start with three disks that are all tangent to one another, leaving a spiky three-pointed vacancy between them. Draw a new disk in the empty patch, tangent to all three of the original disks; this is the largest disk that can possibly fit in the space. Adding the new disk creates three smaller triangular voids, where you can draw three more triply tangent disks. There’s nothing to stop you from going on in this way indefinitely, approaching a limiting configuration where the entire area is filled.</p>
<p>There are randomized versions of the Apollonian model. For example, you might place zero-diameter seed disks at random unoccupied positions and then allow them to grow until they touch one (or more) of their neighbors. This process, too, is space-filling in the limit. And it can never fail: Because the disks are custom-fitted to the space available, you can never get stuck with a disk that can’t find a home.</p>
<p>Shier’s algorithm is different. You are given disks one at a time in a predetermined order, starting with the largest, then the second-largest, and so on. To place a disk in the square, you choose a point at random and test to see if the disk will fit at that location without bumping into its neighbors or poking beyond the boundaries of the square. If the tests fail, you pick another random point and try again. It’s not obvious that this haphazard search will always succeed—and indeed it works only if the successive disks get smaller according to a specific mathematical rule. But if you follow that rule, you can keep adding disks forever. Furthermore, as the number of disks goes to infinity, the fraction of the area covered approaches \(1\). It’s convenient to have a name for series of disks that meet these two criteria; I have taken to calling them <em>fulfilling</em> series.</p>
<hr />
<p>In exploring these ideas computationally, it makes sense to start with the simplest case: disks that are all the same size. This version of the process clearly <em>cannot</em> be fulfilling. No matter how the disks are arranged, their aggregate area will eventually exceed that of any finite container. Click in the gray square below to start filling it with equal-size disks. The square box has area \(A_{\square} = 4\). The slider in the control panel determines the area of the individual disks \(A_k\), in a range from \(0.0001\) to \(1.0\).</p>
<h2 class="zf">Program 1: Fixed-Size Disks</h2>
<div class="canvas-container canvas-failure" id="fixed-size">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">If you play with this program for a while, you’ll find that the dots bloom quickly at first, but the process invariably slows down and eventually ends in a state labeled “Jammed,” indicating that the program has been unable The program gives up after trying 10 million random locations. to find a place where one more disk will fit. If you move the slider to the right, specifying larger disks, this impasse is reached very quickly, sometimes after placing just one or two disks. If you select very small disks, the program may churn away for five or ten minutes and fill the square with more than 20,000 disks before running out of options. Nevertheless, for any disk size greater than zero, a jammed outcome is inescapable.</p>
<p>The densest possible packing of equal-size disks places the centers on a triangular lattice with spacing equal to the disk diameter. The resulting density (for an infinite number of disks on an infinite plane) is \(\pi \sqrt{3}\, /\, 6 \approx 0.9069\), which means more than 90 percent of the area is covered. A random filling in a finite square is much looser. My first few trials all halted with a filling fraction fairly close to one-half, and so I wondered if that nice round number might be the expectation value of the probabilistic process. Further experiments suggested otherwise. Over a broad range of disk sizes, from \(0.0001\) up to about \(0.01\), the area covered varied from one run to the next, but the average was definitely above one-half—perhaps \(0.54\). After some rummaging through the voluminous literature on circle packing, I think I may have a clue to the exact expectation value: \(\pi / (3 + 2 \sqrt{2}) \approx 0.539012\). Where does that weird number come from? The answer has nothing to do with Shier’s algorithm, but I think  it’s worth a digression.</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/06/max-2-packing.svg" height="200" width="200" alt="The two largest equal-size disks that fit in a unit square." border="0" class="alignright" />Consider an adversarial process: Alice is filling a unit square with \(n\) equal-size disks and wants to cover as much of the area as possible. Bob, who wants to minimize the area covered, gets to choose \(n\). If Bob chooses \(n = 1\), Alice can produce a single disk that just fits inside the square and covers about \(79\) percent of the space. Can Bob do better? Yes, if Bob specifies \(n = 2\), Alice’s best option is to squeeze the two disks into diagonally opposite corners of the square as shown in the diagram at right. These disks are bounded by right isosceles triangles, which makes it easy to calculate their radii as \(r = 1 / (2 + \sqrt{2}) \approx 0.2929\). Their combined area works out to that peculiar number \(\pi / (3 + 2 \sqrt{2}) \approx 0.54\).</p>
<p>If two disks are better than one (from Bob’s point of view), could three be better still? Or four, or some larger number? Apparently not. In 2010, <a href="https://arxiv.org/abs/1008.1224">Erik Demaine, Sándor Fekete and Robert Lang</a> conjectured that the two-disk configuration shown above represents the worst case for any number of equal-size disks. In 2017 <a href="https://arxiv.org/abs/1705.00924">Fekete, Sebastian Morr, and Christian Scheffer</a> proved this result. </p>
<p>Is it just a coincidence that the worst-case density for packing disks into a square also appears to be the expected density when equal-size disks are placed randomly until no more will fit? Wish I knew.</p>
<hr />
<p>Let us return to the questions raised in Shier’s <em>Fractalize That!</em> If we want to fit infinitely many disks into a finite square, our only hope is to work with disks that get smaller and smaller as the process goes on. The disk areas must come from some sequence of ever-diminishing numbers. Among such sequences, the one that first comes to mind is \(\frac{1}{1}, \frac{1}{2}, \frac{1}{3}, \frac{1}{4}, \ldots\) These fractions have been known since antiquity as the harmonic numbers. (They are the wavelengths of the overtones of a plucked string.) </p>
<p>To see what happens when successive disks are sized according to the harmonic sequence, click in the square below.</p>
<h2 class="zf">Program 2: Disk Sizes from Harmonic Series</h2>
<div class="canvas-container canvas-failure" id="harmonic">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p>Again, the process halts when no open space is large enough to accommodate the next disk in the sequence. If you move the slider all the way to the right, you’ll see a sequence of disks with areas drawn from the start of the full harmonic sequence, \(\frac{1}{1} , \frac{1}{2}, \frac{1}{3}, \dots\); at this setting, you’ll seldom get beyond eight or nine disks. Moving the slider to the left omits the largest disks at the beginning of the sequence, leaving the infinite tail of smaller disks. For example, setting the slider to \(1/20\) skips all the disks from \(\frac{1}{1}\) through \(\frac{1}{19}\) and begins filling the square with disks of area \(\frac{1}{20}, \frac{1}{21}, \frac{1}{22}, \dots\) Such truncated series go on longer, but eventually they also end in a jammed configuration.</p>
<p>The slider goes no further than 1/50, but even if you omitted the first 500 disks, or the first 5 million, the result would be the same. This is a consequence of the most famous property of the harmonic numbers: Although the individual terms \(1/k\) dwindle away to zero as \(k\) goes to infinity, the sum of all the terms, </p>
<p>\[\sum_{k = 1}^{\infty}\frac{1}{k} = \frac{1}{1} + \frac{1}{2} + \frac{1}{3} + \cdots,\]</p>
<p class="undent">does not converge to a finite value. As long as you keep adding terms, the sum will keep growing, though ever more slowly. This curious fact was proved in the 14th century by the French bishop and scholar Nicole Oresme. The proof is simple but ingenious. Oresme pointed out that the harmonic sequence</p>
<p>\[\frac{1}{1} + \frac{1}{2} + \left(\frac{1}{3} + \frac{1}{4}\right) + \left(\frac{1}{5} + \frac{1}{6} + \frac{1}{7} + \frac{1}{8}\right) + \cdots\]</p>
<p class="undent">is greater than</p>
<p>\[\frac{1}{1} + \frac{1}{2} + \left(\frac{1}{4} + \frac{1}{4}\right) + \left(\frac{1}{8} + \frac{1}{8} + \frac{1}{8} + \frac{1}{8}\right) + \cdots\]</p>
<p class="undent">The latter series is equivalent to \(1 + \frac{1}{2} + \frac{1}{2} + \frac{1}{2} \cdots\), and so it is clearly divergent. Since the grouped terms of the harmonic series are even greater, they too must exceed any finite bound.</p>
<p>The divergence of the harmonic series implies that disks whose areas are generated by the series will eventually overflow any enclosing container. Dropping a finite prefix of the sequence, such as the first 50 disks, does not change this fact.</p>
<p>Let me note in passing that just as the filling fraction for fixed-size disks seems to converge to a specific constant, 0.5390, disks in harmonic series also seem to have a favored filling fraction, roughly 0.71. Can this be explained by some simple geometric argument? Again, I wish I knew.</p>
<hr />
<p>Evidently we need to make the disks shrink faster than the harmonic numbers do. Here’s an idea: Square each element of the harmonic series, yielding this:</p>
<p>\[\sum_{k = 1}^{\infty}\frac{1}{k^2} = \frac{1}{1^2} + \frac{1}{2^2} + \frac{1}{3^2} + \cdots.\]</p>
<p class="undent">Click below (or press the Start button) to see how this one turns out, again in a square of area 4.</p>
<h2 class="zf">Program 3: Disk Sizes from Zeta(2)</h2>
<div class="canvas-container canvas-failure" id="zeta2">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">At last we have a process that won’t get stuck in a situation where there’s no place to put another disk. It <em>could</em> run forever, but of course it doesn’t. It quits when the area of the next disk shrinks down to about a tenth of the size of a single pixel on a computer display. The stopped state is labeled “Exhausted” rather than “Jammed.”This is an algorithm that could truly run forever. And yet the result is still not quite what we were hoping for—it’s not <em>fulfilling</em>. The disks are scattered sparsely in the square, leaving vast open spaces unoccupied. The configuration reminds me of deep-sky images made by large telescopes.</p>
<p>Why does this outcome look so different from the others? Unlike the harmonic numbers, the infinite series \(1 +  \frac{1}{4} + \frac{1}{9} + \frac{1}{16} + \cdots\) converges to a finite sum. In the 18th century the task of establishing this fact (and determining the exact sum) was known as the Basel Problem, after the hometown of the Bernoulli family, who put much effort into the problem but never solved it. The answer came in 1735 from Leonhard Euler (another native of Basel, though he was working in St. Petersburg), who showed that the sum is equal to \(\pi^2 / 6\). This works out to about \(1.645\); since the area of the square we want to fill is \(4\), even an infinite series of disks would cover only about \(41\) percent of the territory.</p>
<p>Given that the numbers \(\frac{1}{1^1}, \frac{1}{2^1}, \frac{1}{3^1}, \dots\) diminish too slowly, whereas \(\frac{1}{1^2}, \frac{1}{2^2}, \frac{1}{3^2}, \dots\) shrink too fast, it makes sense to try an exponent somewhere between \(1\) and \(2\) in the hope of finding a Goldilocks solution. The computation performed below in Program 4 is meant to facilitate the search for such a happy medium. Here the disk sizes are elements of the sequence \(\frac{1}{1^s}, \frac{1}{2^s}, \frac{1}{3^s}, \dots\), where the value of the exponent \(s\) is determined by the setting of the slider, with a range of \(1 \lt s \le 2\). We already know what happens at the extremes of this range. What is the behavior in the middle?</p>
<h2 class="zf">Program 4: Disk Sizes from Zeta(s)</h2>
<div class="canvas-container canvas-failure" id="zeta-adjust">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">If you try the default setting of \(s = 1.5\), you’ll find you are still in the regime where the disks dwindle away so quickly that the box never fills up; if you’re willing to wait long enough, the program will end in an exhausted state rather than a jammed one. Reducing the exponent to \(s = 1.25\) puts you on the other side of the balance point, where the disks remain too large and at some point one of them will not fit into any available space. By continuing to shuttle the slider back and forth, you could carry out a binary search, closing in, step by step, on the “just right” value of \(s\). This strategy can succeed, but it’s not quick.  As you get closer to the critical value, the program will run longer and longer before halting. (After all, running forever is the behavior we’re seeking.) To save you some tedium, I offer a spoiler: the optimum setting is between 1.29 and 1.30.</p>
<p>At this point we have wandered into deeper mathematical waters. A rule of the form \(A_k = 1/k^s\) is called a power law, since each \(k\) is raised to the same power. And series of the form \(\sum 1/k^s\) are known as zeta functions, denoted \(\zeta(s)\). Zeta functions have quite a storied place in mathematics. The harmonic numbers correspond to \(\zeta(1) = \sum 1/k^1\), which does not converge. If \(\zeta(1)\) grows without limit whereas \(\zeta(2)\) converges, you might well wonder where the boundary lies between these two behaviors. As it happens, \(\zeta(1 + \epsilon)\) converges for any \(\epsilon \gt 0\).As mentioned above, Euler found that \(\zeta(2) = \pi^2 / 6\), and he went on to show that \(\zeta(s)\) also converges for all integer values of \(s\) greater than \(1\). Later, Pafnuty Chebyshev extended the domain of the function beyond the integers to all real numbers \(s\) greater than \(1\). And then Bernhard Riemann went further still: He devised a smoke-and-mirrors trick for defining the zeta function over the entire plane of complex numbers, with the single exception of \(s = 1\). </p>
<p>Today, Riemann’s version of the zeta function is the engine (or enigma!) driving a major mathematical industry. Shier’s use of this apparatus in making fractal art is far removed from that heavy-duty research enterprise—but no less fascinating. Think of it as the zeta function on vacation. </p>
<p>If a collection of disks are to fill a square exactly, their aggregate area must equal the area of the square. This is a necessary condition though not a sufficient one. In all the examples I’ve presented so far, the containing square has an area of 4, so what’s needed is to find a value of \(s\) that satisfies the equation:</p>
<p>\[\zeta(s) = \sum_{k = 1}^{\infty}\frac{1}{k^s} = 4\]</p>
<p class="undent">Except for isolated values of \(s\), Those isolated values are the negative integers and the even positive integers.there is no known method for solving this equation exactly. But numerical approximation works well enough for a computer program that draws pictures. The binary search described above is a crude and cumbersome version of this numerical method. <a href="http://www.sagemath.org/">SageMath</a> presumably does something more sophisticated. When I ask it to find a root of the equation \(zeta(s) = 4\), it returns the result \(1.2939615055572438\).</p>
<p>Having this result in hand solves one part of the square-filling problem. It tells us how to construct an infinite set of disks whose total area is just enough to cover a square of area \(4\), with adequate precision for graphical purposes. We assign each disk \(k\) (starting at \(k = 1\)) an area of \(1/k^{1.2939615}.\) This sequence begins 1.000, 0.408, 0.241, 0.166, 0.125, 0.098,…</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/07/zeta_curves_edit1.svg" height="" width="640" alt="Curves showing the convergence of zeta(s) for five different values of s, when the series is summed over a number of terms ranging up to 10^8. The curve for s = 1.29396 converges to a value of 4." border="0" class="centered" /></p>
<p class="undent">In the graph above, the maroon curve with \(s = 1.29396\) converges to a sum very close to 4. Admittedly, the rate of convergence is not quick. More than 3 million terms are needed to get within 1 percent of the target.</p>
<hr />
<p>Our off-label use of the zeta function defines an infinite sequence of disks whose aggregate area is equal to \(4\). The disks in this unique collection will exactly fill our square box (assuming they can be properly arranged). It’s satisfying to have a way of reliably achieving this result, after our various earlier failures. On the other hand, there’s something irksome about that number \(4\) appearing in the equation. It’s so arbitrary! I don’t dispute that \(4\) is a perfectly fine and foursquare number, but there are many other sizes of squares we might want to fill with dots. Why give all our attention to the \(2 \times 2\) variety?</p>
<p>This is all my fault. When I set out to write some square-filling programs, I knew I couldn’t use the unit square—which seems like the obvious default choice—because of the awkward fact that \(\zeta(s) = 1\) has no finite solution. The unit square is also troublesome in the case of the harmonic numbers; the first disk, with area \(A_1 = 1\),  is too large to fit. So I picked the next squared integer for the box size in those first programs. Having made my choice, I stuck with it, but now I feel hemmed in by that decision made with too little forethought.</p>
<p>We have all the tools we need to fill squares of other sizes (as long as the size is greater than \(1\)). Given a square of area \(A_{\square}\), we just solve for \(s\) in \(\zeta(s) = A_{\square}\). A square of area 8 can be covered by disks sized according to the rule \(A_k = 1/k^s\) with \(s = \zeta(8) \approx 1.1349\). For \(A_{\square} = 100\), the corresponding value of \(s\) is \(\zeta(100) \approx 1.0101\). For any \(A_{\square} \gt 1\) there is an \(s\) that yields a fulfilling set of disks, and vice versa for any \(s \gt 1\).</p>
<p>This relation between the exponent \(s\) and the box area \(A_{\square}\) suggests a neat way to evade the whole bother of choosing a specific container size. We can just scale the disks to fit the box, or else scale the box to accommodate the disks. Shier adopts the former method. Each disk in the infinite set is assigned an area of</p>
<p>\[A_k = \frac{A_{\square}}{\zeta(s)} \frac{1}{k^s},\]</p>
<p class="undent">where the first factor is a scaling constant that adjusts the disk sizes to fit the container. In my first experiments with these programs I followed the same approach. Later, however, when I began writing this essay, it seemed easier to think about the scaling—and explain it—if I transformed the size of the box rather than the sizes of the disks. In this scheme, the area of disk \(k\) is simply \(1 / k^s\), and the area of the container is \(A_{\square} = \zeta(s)\). (The two scaling procedures are mathematically equivalent; it’s only the ratio of disk size to container size that matters.)</p>
<p>Program 5 offers an opportunity to play with such scaled zeta functions. I’m not actually changing the physical size of the box—the number of pixels it occupies on-screen remains the same. I’m scaling the units of measure.No matter where you move the \(s\) slider, the area of the square container will adjust to match the total area of the infinite set of disks. As the ratio of disk size to container size shifts, so does the overall texture or appearance of the pattern. At a setting of \(s = 1.35\), the largest disk fills almost a third of the square; at \(s = 1.08\), the first disk occupies only about \(8\) percent of box area. At those lower settings it takes a very long time to reach a high filling percentage, but if you have true faith in mathematical certainties, your patience will be rewarded.</p>
<h2 class="zf">Program 5: Disk Sizes from Scaled Zeta(s)</h2>
<div class="canvas-container canvas-failure" id="zeta-scaled">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">At the other end of the scale, if you push the value of \(s\) up beyond about \(1.40\), you’ll discover something else: The program more often than not halts after placing just a few disks. At \(s = 1.50\) or higher, it seldom gets beyond the first disk. This failure is similar to what we saw with the harmonic numbers, but more interesting. In the case of the harmonic numbers, the total area of the disks is unbounded, making an overflow inevitable. With this new scaled version of the zeta function, the total area of the disks is always equal to that of the enclosing square. In principle, all the disks could all be made to fit, if you could find the right arrangement. I’ll return below to the question of why that doesn’t happen.</p>
<hr />
<p>In <em>Fractalize That!</em> Shier introduces another device for taming space-filling sets. He not only scales the object sizes so that their total area matches the space available; he also adopts a variant zeta function that has two adjustable parameters rather than just one: </p>
<p>A note on notation: Shier writes the Hurwitz zeta function as \(\zeta(c, N)\), whereas most of the mathematical literature seems to favor \(\zeta(s, a)\). I’m going with the majority.\[\zeta(s, a) = \sum_{k=0}^{\infty} \frac{1}{(a + k)^s}\]</p>
<p class="undent">This is the Hurwitz zeta function, named for the German mathematician Adolf Hurwitz (1859–1919). Before looking into the details of the function, let’s play with the program and see what happens. Try a few settings of the \(s\) and \(a\) controls:</p>
<h2 class="zf">Program 6: Disk Sizes from Scaled Hurwitz Zeta Function</h2>
<div class="canvas-container canvas-failure" id="hurwitz">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p>Different combinations of \(s\) and \(a\) produce populations of disks with different size distributions. The separate contributions of the two parameters are not always easy to disentangle, but in general decreasing \(s\) or increasing \(a\) leads to a pattern dominated by smaller disks. Here are snapshots of four outcomes:</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/07/four_hurwitz_snapshots.svg" height="" width="640" alt="Four hurwitz snapshots" border="0" class="centered" /></p>
<p class="undent">Within the parameter range shown in these four panels, the filling process always continues to exhaustion, but at higher values of \(s\) it can jam, just as it does with the scaled Riemann zeta function.</p>
<p>Adolf Hurwitz in the 1880s. Photo from <a href="https://en.wikipedia.org/wiki/Adolf_Hurwitz">Wikipedia</a>.<img src="http://bit-player.org/wp-content/uploads/2019/07/Adolf_Hurwitz-1880s-600px.jpg" height="300" width="200" alt="Adolf Hurwitz in the 1880s. Image from Wikimedia" border="0" class="alignleft" />Until I began this project, I knew nothing of Adolf Hurwitz or his work, although he is <a href="http://www-history.mcs.st-and.ac.uk/Biographies/Hurwitz.html">hardly an obscure figure</a> in the history of mathematics. He earned his Ph.D. under Felix Klein and also studied with Karl Weierstrass, Ernst Eduard Kummer, and Leopold Kronecker—key figures in the founding of modern analysis and number theory. Among his own pupils (and close friends) were David Hilbert and Hermann Minkowski. Albert Einstein was another of his students, although apparently he <a href="https://arxiv.org/abs/1205.4335">seldom went to class</a>.</p>
<p>Hurwitz wrote just one paper on the zeta function. It was published in 1882, when he was still quite young and just beginning his first academic appointment, at the University of Göttingen. (The paper is available from the <a href="https://gdz.sub.uni-goettingen.de/id/PPN599415665_0027">Göttinger Digitalisierungszentrum</a>; see pp. 86–101.) </p>
<p>Hurwitz modified the Riemann zeta function in two ways. First, the constant \(a\) is added to each term, turning \(1/k^s\) into \(1/(a + k)^s\). Second, the summation begins with \(k = 0\) rather than \(k = 1\). By letting \(a\) take on any value in the range \(0 \lt a \le 1\) we gain access to a continuum of zeta functions. The elements of the series are no longer just reciprocals of integers but reciprocals of real numbers. Suppose \(a = \frac{1}{3}\). Then \(\zeta(s, a)\) becomes:</p>
<p>\[\frac{1}{\left(\frac{1}{3} + 0\right)^s} + \frac{1}{\left(\frac{1}{3} + 1\right)^s} + \frac{1}{\left(\frac{1}{3} + 2\right)^s} + \cdots\ = \left(\frac{3}{1}\right)^s + \left(\frac{3}{4}\right)^s + \left(\frac{3}{7}\right)^s + \cdots\]</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/hurwitz-s1.3-plot.svg" height="" width="300" alt="Hurwitz s=1 3 plot" border="0" class="alignright" />The Riemann zeta function and the Hurwitz zeta function differ substantially only for small values of \(k\) or large values of \(a\). When \(k\) is large, adding a small \(a\) to it makes little difference in the value of the function. Thus as \(k\) grows toward infinity, the two functions are asymptotically equal, as suggested in the graph at right. When the Hurwitz function is put to work packing disks into a square, a rule with \(a &gt; 1\) causes the first several disks to be smaller than they would be with the Riemann rule. A value of \(a\) between \(0\) and \(1\) enlarges the early disks. In either case, the later disks in the sequence are hardly affected at all.</p>
<p class="indent">If \(a\) is a positive integer, the interpretation of \(\zeta(s, a)\) is even simpler. The case \(a = 1\) corresponds to the Riemann zeta sum. When \(a\) is a larger integer, the effect is to omit the first \(a - 1\) entries, leaving only the tail of the series. For example,</p>
<p>\[\zeta(s, 5) = \frac{1}{5^s} + \frac{1}{6^s} + \frac{1}{7^s} + \cdots.\] </p>
<p class="indent">In his fractal artworks, Shier chooses various values of \(a\) as a way of controlling the size distribution of the placed objects, and thereby fine-tuning the appearance of the patterns. Having this adjustment knob available is very convenient, but in the interests of simplicity, I am going to revert to the Riemann function in the rest of this essay.</p>
<p>Before going on, however, I also have to confess that I don’t really understand the place of the Hurwitz zeta function in modern mathematical research, or what Hurwitz himself had in mind when he formulated it. Zeta functions have been an indispensable tool in the long struggle to understand how the prime numbers are sprinkled among the integers. The connection between these two realms was made by Euler, with his remarkable equation linking a sum of powers of integers with a product of powers of primes:</p>
<p>Euler’s other famous equation, \(e^{i\pi} + 1 = 0\), has a bigger fan club, but this is the one that revs <em>my</em> motor.\[\sum_{k = 1}^{\infty} \frac{1}{k^s} = \prod_{p \text{ prime}} \frac{1}{1 - \frac{1}{p^s}}.\]</p>
<p>Riemann went further, showing that everything we might want to know about the distribution of primes is encoded in the undulations of the zeta function over the complex plane. Indeed, if we could simply pin down all the complex values of \(s\) for which \(\zeta(s) = 0\), we would have a master key to the primes. Hurwitz, in his 1882 paper, was clearly hoping to make some progress toward this goal, but I have not been able to figure out how his work fits into the larger story. The Hurwitz zeta function gets almost no attention in standard histories and reference works (in contrast to the Riemann version, which is everywhere). <a href="https://en.wikipedia.org/wiki/Hurwitz_zeta_function">Wikipedia</a> notes: “At rational arguments the Hurwitz zeta function may be expressed as a linear combination of Dirichlet <em>L</em>-functions and vice versa”—which sounds interesting, but I don’t know if it’s useful or important. A recent <a href="https://arxiv.org/abs/1506.00856">article by Nicola Oswald and Jörn Steuding</a> puts Hurwitz’s work in historical context, but it does not answer these questions—at least not in a way I’m able to understand.</p>
<p>But again I digress. Back to dots in boxes.</p>
<hr />
<p>If a set of circular disks and a square container have the same total area, can you always arrange the disks so that they completely fill the square without overflowing? Certainly not! Suppose the set consists of a single disk with area equal to that of the square; the disk’s diameter is greater than the side length of the square, so it will bulge through the sides while leaving the corners unfilled. A set of two disks won’t work either, no matter how you apportion the area between them. Indeed, when you are putting round pegs in a square hole, no finite set of disks can ever fill all the crevices.</p>
<p>Only an infinite set—a set with no smallest disk—can possibly fill the square completely. But even with an endless supply of ever-smaller disks, it seems like quite a delicate task to find just the right arrangement, so that every gap is filled and every disk has a place to call home. It’s all the more remarkable, then, that simply plunking down the disks at random locations seems to produce exactly the desired result. This behavior is what intrigued and troubled me when I first saw Shier’s pictures and read about his method for generating them. If a <em>random</em> arrangement works, it’s only a small step to the proposition that <em>any</em> arrangement works. Could that possibly be true?</p>
<p>Computational experiments offer strong hints on this point, but they can never be conclusive. What we need is a proof. Ennis’s proof was published in <em><a href="https://www.tandfonline.com/doi/abs/10.4169/mathhorizons.23.3.8">Math Horizons</a></em>, a publication of the Mathe­matical Association of America, which keeps it behind a paywall. If you have no library access and won’t pay the $50 ransom, I can recommend a <a href="https://wp.stolaf.edu/mscs/2014-2015-colloquium-series/">video</a> of Ennis explaining his proof in a talk at St. Olaf College.And so I turn to the work of Christopher Ennis, a mathematician at Normandale Community College, who met Shier when they were both teaching there. </p>
<p>As a warm-up exercise, Ennis proves a one-dimensional version of the area-filling conjecture, where the geometry is simpler and some of the constraints are easier to satisfy. In one dimension a disk is merely a line segment; its area is its length, and its radius is half that length. As in the two-dimensional model, disks are placed in descending order of size at random positions, with the usual proviso that no disk can overlap another disk or extend beyond the end points of the containing interval. In Program 7 you can play with this scheme.</p>
<h2 class="zf">Program 7: One-Dimensional Disks</h2>
<div class="canvas-container canvas-failure" id="one-dim">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="undent">I have given the line segment some vertical thickness to make it visible. The resulting pattern of stripes may look like a supermarket barcode or an atomic spectrum, but please imagine it as one-dimensional.</p>
<p>If you adjust the slider in this program, you’ll notice a difference from the two-dimensional system. In 2D, the algorithm is fulfilling only if the exponent \(s\) is less than a critical value, somewhere in the neighborhood of 1.4. In one dimension, the process continues without impediment for all values of \(s\) throughout the range \(1 \lt s \lt 2\). Try as you might, you won’t find a setting that produces a jammed state. (In practice, the program halts after placing no more than 10,000 disks, but the reason is exhaustion rather than jamming.)</p>
<p>Ennis titles his <em>Math Horizons</em> article “(Always) room for one more.” He proves this assertion by keeping track of the set of points where the center of a new disk can legally be placed, and showing the set is never empty. Suppose \(n - 1\) disks have already been randomly scattered in the container. The next disk to be placed, disk \(n\), will have an area (or length) of \(A_n = 1 / n^s\). Since the geometry is one-dimensional, the corresponding disk radius is simply \(r_n = A_n / 2\). The center of this new disk cannot lie any closer than \(r_n\) to the perimeter of another disk. It must also be at a distance of at least \(r_n\) from the boundary of the containing segment. We can visualize these constraints by adding bumpers, or buffers, of thickness \(r_n\) to the outside of each existing disk and to the inner edges of the containing segment. A few stages of the process are illustrated below.</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/08/1d-buffer-diagram.svg" height="" width="680" alt="1d buffer diagram" border="0" class="alignleft" /></p>
<p>Placed disks are blue, the excluded buffer areas are orange, and open areas—the set of all points where the center of the next disk could be placed—are black. In the top line, before any disks have been placed, the entire containing segment is open except for the two buffers at the ends. Each of these buffers has a length equal to \(r_1\),  the radius of the first disk to be placed; the center of that disk cannot lie in the orange regions because the disk would then overhang the end of the containing segment. After the first disk has been placed <em>(second line)</em>, the extent of the open area is reduced by the area of the disk itself and its appended buffers. On the other hand, all of the buffers have also shrunk; each buffer is now equal to the radius of disk \(2\), which is smaller than disk \(1\). The pattern continues as subsequent disks are added. Note that although the blue disks cannot overlap, the orange buffers can.</p>
<p>For another view of how this process evolves, click on the <em>Next</em> button in Program 8. Each click inserts one more disk into the array and adjusts the buffer and open areas accordingly.</p>
<h2 class="zf">Program 8: One-Dimensional with Buffers</h2>
<div class="canvas-container canvas-failure" id="one-dim-bumpers">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">Because the blue disks are never allowed to overlap, the total blue area must increase monotonically as disks are added. It follows that the orange and black areas, taken together, must steadily decrease. But there’s nothing steady about the process when you keep an eye on the separate area measures for the orange and black regions. Changes in the amount of buffer overlap cause erratic, seesawing tradeoffs between the two subtotals. If you keep clicking the <em>Next</em> button (especially with \(s\) set to a high value), you may see the black area falling below \(1\) percent. Can we be sure it will never vanish entirely, leaving no opening at all for the next disk?</p>
<p>Ennis answers this question through worst-case analysis. He considers only configurations in which no buffers overlap, thereby squeezing the black area to its smallest possible extent. If the black area is always positive under these conditions, it cannot be smaller when buffer overlaps are allowed.</p>
<p>The basic idea of the proofI have altered some of the notation and certain details of presentation to conform with choices I made elsewhere in this exposition. is to start with \(n - 1\) buffered disks already in place, arranged so that none of the orange buffer areas intersect. The total area of the blue disks is \(\sum_{k=1}^{k=n-1} 1/k^s\). Each buffer zone has a width equal to \(r_{n}\), the radius of the next disk to be added to the tableau; since each disk has two buffers, the total area of the orange buffers is \(2(n-1)r_{n}\). The black area is whatever’s left over. In other words,</p>
<p>\[A_{\square} = \zeta(s), \quad A_{\color{blue}{\mathrm{blue}}} = \sum_{k=1}^{k = n - 1} \frac{1}{k^s}, \quad A_{\color{orange}{\mathrm{orange}}} = 2(n-1)r_{n}.\]</p>
<p class="undent">Then we need to prove that</p>
<p> \[A_{\square} - (A_{\color{blue}{\mathrm{blue}}} + A_{\color{orange}{\mathrm{orange}}}) \gt 0.\]</p>
<p>A direct proof of this statement would require an exact, closed-form expression for \(\zeta(s)\), which we already know is problematic. Ennis evades this difficulty by turning to calculus. He needs to evaluate the remaining tail of the zeta series, \(\sum_{k = n}^\infty 1/k^s\), but this discrete sum is intractable. On the other hand, by shifting from a sum to an integral, the problem becomes an exercise in undergraduate calculus. Exchanging the discrete variable \(k\) for a continuous variable \(x\), we want to find the area under the curve \(1/x^s\) in the interval from \(n\) to infinity; this will provide a lower bound on the corresponding discrete sum. Evaluating the integral yields:</p>
<p>\[\int_{x = n}^{\infty} \frac{1}{x^{s}} d x = \frac{1}{(s-1) n^{s-1}}.\]</p>
<p class="undent">Some further manipulation reveals that the area of the black regions is never smaller than</p>
<p>\[\frac{2 - s}{(s - 1)n^{s - 1}}.\]</p>
<p class="undent">If \(s\) lies strictly between \(1\) and \(2\), this expression must be greater than zero, since both the numerator and the denominator will be positive. Thus for all \(n\) there is at least one black point where the center of a new disk can be placed.</p>
<p>Ennis’s proof is a stronger one than I expected. When I first learned there was a proof, I guessed that it would take a probabilistic approach, showing that although a jammed configuration may exist, it has probability zero of turning up in a random placement of the disks. Instead, Ennis shows that no such arrangement exists at all. Even if you replaced the randomized algorithm with an adversarial one that tries its best to block every disk, the process would still run to fulfillment.</p>
<hr />
<p>The proof for a two-dimensional system follows the same basic line of argument, but it gets more complicated for geometric reasons. In one dimension, as the successive disk areas get smaller, the disk radii diminish in simple proportion: \(r_k = A_k / 2\). In two dimensions, disk radius falls off only as the square root of the disk area: \(r_k = \sqrt{A_k / \pi}\). As a result, the buffer zone surrounding a disk excludes neighbors at a greater distance in two dimensions than it would in one dimension. There is still a range of \(s\) values where the process is provably unstoppable, but it does not extend across the full interval from \(s \gt 1\) to \(s \lt 2\).</p>
<p>Program 9, running in the panel below, is one I find very helpful in gaining intuition into the behavior of Shier’s algorithm. As in the one-dimensional model of Program 8, each press of the <em>Next</em> button adds a single disk to the containing square, and shows the forbidden buffer zones surrounding the disks.</p>
<h2 class="zf">Program 9: Two-Dimensional Disks with Buffers</h2>
<div class="canvas-container canvas-failure" id="bumpers2d">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p>Move the \(s\) slider to a position somewhere near 1.40. In the control panel for this program, the registers showing fill percentages for blue, orange, and black areas are not entirely trustworthy. In the one-dimensional case, it’s easy to calculate the areas to high precision. That’s much harder in two dimensions, where the overlapping regions of buffers can have complex shapes. I have resorted to counting pixels, a procedure that has limited resolution and is subject to errors caused by fuzzy boundaries.At this setting, there’s a fair chance (maybe 10 or 20 percent) that the very first disk and its orange buffer zone will entirely cover the open black region, creating a jammed state. On other runs you might get as far as two or three or 10 disks before you get stuck. If you make it beyond that point, however, you are likely to continue unimpeded for as long as you have the patience to keep pressing <em>Next</em>. Shier describes this phenomenon as “infant mortality”: If the placement process survives the high-risk early period, it is all but immortal.</p>
<p>There’s a certain whack-a-mole dynamic to the behavior of this system. Maybe the first disk covers all but one small corner of the black zone. It looks like the next disk will completely obliterate that open area. And so it does—but at the same time the shrinking of the orange buffer rings opens up another wedge of black elsewhere. The third disk blots out that spot, but again the narrowing of the buffers allows a black patch to peek out from still another corner. Later on, when there are dozens of disks, there are also dozens of tiny black spots where there’s room for another disk. You can often guess which of the openings will be filled next, because the random search process is likely to land in the largest of them. Again, however, as these biggest targets are buried, many smaller ones are born.</p>
<p>Ennis’s two-dimensional proof addresses the case of circular disks inside a circular boundary, rather than a square one. (The higher symmetry and the absence of corners streamlines certain calculations.) The proof strategy, again, is to show that after \(n - 1\) disks have been placed, there is still room for the \(n\)th disk, for any value of \(n \ge 1\). The argument follows the same logic as in one dimension, relying on an integral to provide a lower bound for the sum of a zeta series. But because of the \(\pi r^2\) area relation, the calculation now includes quadratic as well as linear terms. As a result, the proof covers only a part of the range of \(s\) values. The black area is provably nonempty if \(s\) is greater than \(1\) but less than roughly \(1.1\); outside that interval, the proof has nothing to say.</p>
<p>As mentioned above, Ennis’s proof applies only to circular disks in a circular enclosure. Nevertheless, in what follows I am going to assume the same ideas carry over to disks in a square frame, although the location of the boundary will doubtless be somewhat different. I have recently learned that Ennis has written a further paper on the subject, expected to be published in the <em>American Mathematical Monthly</em>. Perhaps he addresses this question there.</p>
<p>With Program 9, we can explore the entire spectrum of behavior for packing disks into a square. The possibilities are summarized in the candybar graph below.</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/spectrum-of-behaviors.svg" height="" width="650" alt="Spectrum of behaviors" border="0" class="centered" /></p>
<ul>
<li>The leftmost band, in darker green, is the interval for which Ennis’s proof might hold. The question mark at the upper boundary line signifies that we don’t really know where it lies.</li>
<li>In the lighter green region no proof is known, but in Shier’s extensive experiments the system never jams there.</li>
<li>The transition zone sees the probability of jamming rise from \(0\) to \(1\) as \(s\) goes from about \(1.3\) to about \(1.5\).</li>
<li>Beyond \(s \approx 1.5\), experiments suggest that the system <em>always</em> halts in a jammed configuration.</li>
<li>At \(s \approx 1.6\) we enter a regime where the buffer zone surrounding the first disk invariably blocks the entire black region, leaving nowhere to place a second disk. Thus we have a simple proof that the system always jams.</li>
<li>Still another barrier arises at \(s \approx 2.7\). Beyond this point, not even one disk will fit. The diameter of a disk with area \(1\) is greater than the side length of the enclosing square.</li>
</ul>
<hr />
<p>Can we pin down the exact locations of the various threshold points in the diagram above? This problem is tractable in those situations where the placement of the very first disk determines the outcome. <img src="http://bit-player.org/wp-content/uploads/2019/09/centered-disk-128-160pts.png" height="160" width="160" alt="Centered disk 128 160pts" border="0" class="alignright" />At high values of \(s\) (and thus low values of \(\zeta(s)\), the first disk can obliterate the black zone and thereby preclude placement of a second disk. What is the lowest value of \(s\) for which this can happen? As in the image at right, the disk must lie at the center of the square box, and the orange buffer zone surrounding it must extend just far enough out to cover the corners of the inner black square, which defines the locus of all points that could accommodate the center of the second disk. Finding the value of \(s\) that satisfies this condition is a messy but straightforward bit of geometry and algebra. With the help of SageMath I get the answer \(s = 1.282915\). This value—let’s call it \(\overline{s}\)—is an upper bound on the “never jammed” region. Above this limit there is always a nonzero probability that the filling process will end after placing a single disk.</p>
<p>The value of \(\overline{s}\) lies quite close to the experimentally observed boundary between the never-jammed range and the transition zone, where jamming first appears. Is it possible that \(\overline{s}\) actually marks the edge of the transition zone—that below this value of \(s\) the program can never fail? To prove that conjecture, you would have to show that when the first disk is successfully placed, the process never stalls on a subsequent disk. That’s certainly not true in higher ranges of \(s\). Yet the empirical evidence near the threshold is suggestive. In my experiments I have yet to see a jammed outcome at \(s \lt \overline{s}\), not even in a million trials just below the threshold, at \(s = 0.999 \overline{s}\). In contrast, at \(s = 1.001 \overline{s}\), a million trials produced 53 jammed results—all of them occuring immediately after the first disk was placed.</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/corner-disk-159-160pts.png" height="160" width="160" alt="Corner disk 159 160pts" border="0" class="alignright" />The same kind of analysis leads to a lower bound on the region where <em>every</em> run ends after the first disk <em>(medium pink in the diagram above)</em>. In this case the critical situation puts the first disk as close as possible to a corner of the square frame, rather than in the middle. If the disk and its orange penumbra are large enough to block the second disk in this extreme configuration, then they will also block it in any other position. Putting a number on this bound again requires some fiddly equation wrangling; the answer I get is \(\underline{s} = 1.593782\). No process with higher \(s\) can possibly live forever, since it will die with the second disk. In analogy with the lower-bound conjecture, one might propose that the probability of being jammed remains below \(1\) until \(s\) reaches \(\underline{s}\). If both conjectures were true, the transition region would extend from \(\overline{s}\) to \(\underline{s}\).</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/centered-disk-270-160pts.png" height="160" width="160" alt="Centered disk 270 160pts" border="0" class="alignright" />The final landmark, way out at \(s \approx 2.7\), marks the point where the first disk threatens to burst the bounds of the enclosing square. In this case the game is over before it begins. In program 9, if you push the slider far to the right, you’ll find that the black square in the middle of the orange field shrinks away and eventually winks out of existence. This extinction event comes when the diameter of the disk equals the side length of the square. Given a disk of area \(1\), and thus radius \(1/\sqrt{\pi}\), we want to find the value of \(s\) that satisfies the equation</p>
<p>\[\frac{2}{\sqrt{\pi}} = \sqrt{\zeta(s)}.\]</p>
<p class="undent">Experiments with Program 9 show that the value is just a tad more than 2.7. That’s an interesting numerical neighborhood, no? A famous number lives nearby. Do you suppose?</p>
<hr />
<p>Another intriguing set of questions concerns the phenomenon that Shier calls infant mortality. If you scroll back up to Program 5 and set the slider to \(s = 1.45\), you’ll find that roughly half the trials jam. The vast majority of these failures come early in the process, after no more than a dozen disks have been placed. At \(s = 1.50\) death at an early age is even more common; three-fourths of all the trials end with the very first disk. On the other hand, if a sequence of disks does manage to dodge all the hazards of early childhood, it may well live on for a very long time—perhaps forever.</p>
<p>Should we be surprised by this behavior? I am. As Shier points out, the patterns formed by our graduated disks are fractals, and one of their characteristic properties is self-similarity, or scale invariance. If you had a fully populated square—one filled with infinitely many disks—you could zoom in on any region to any magnification, and the arrangement of disks would look the same as it does in the full-size square. By “look the same” I don’t mean the disks would be in the same positions, but they would have the same size distribution and the same average number of neighbors at the same distances. This is a statistical concept of identity. And since the pattern looks the same and has the same statistics, you would think that the challenge of finding a place for a new disk would also be the same at any scale. Slipping in a tiny disk late in the filling operation would be no different from plopping down a large disk early on. The probability of jamming ought to be constant from start to finish.</p>
<p>But there’s a rejoinder to this argument: Scale invariance is broken by the presence of the enclosing square. The largest disks are strongly constrained by the boundaries, whereas most of the smaller disks are nowhere near the edges and are little influenced by them. The experimental data offer some support for this view. The graph below summarizes the outcomes of \(20{,}000\) trials at \(s = 1.50\). The red bars show the absolute numbers of trials ending after placing \(n\) disks, for each \(n\) from \(0\) through \(35\). The blue lollipops indicate the proportion of trials reaching disk \(n\) that halted after placing disk \(n\). This ratio can be interpreted (if you’re a frequentist!) as the probability of stopping at \(n\).</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/stymied-bars-and-pops-150-35-20000.svg" height="" width="" alt="Stymied bars and pops 150 35 20000" border="0" class="aligncenter" /></p>
<p class="indent">It certainly looks like there’s something odd happening on the left side of this graph. More than three fourths of the trials end after a single disk, but none at all jam at the second or third disks, and very few (a total of \(23\)) at disks \(4\) and \(5\). Then, suddenly, \(1{,}400\) more fall by the wayside at disk \(6\), and serious attrition continues through disk \(11\).</p>
<p>Geometry can explain some of this weirdness. It has to do with the squareness of the container; other shapes would produce different results.</p>
<p>At \(s = 1.50\) we are between \(\overline{s}\) and \(\underline{s}\), in a regime where the first disk is large enough to block off the entire black zone but not so large that it <em>must</em> do so. This is enough to explain the tall red bar at \(n = 1\): When you place the first disk randomly, roughly \(75\) percent of the time it will block the entire black region, ending the parade of disks. If the first disk <em>doesn’t</em> foreclose all further action, it must be tucked into one of the four corners of the square, leaving enough room for a second disk in the diagonally opposite corner. The sequence of images below (made with Program 9) tells the rest of the story.</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/s150-stymied-at-6-sequence-1280px.png" height="105" width="636" alt="S=150 stymied at 6 sequence 1280px" border="0" class="alignright" /></p>
<p>The placement of the second disk blocks off the open area in that corner, but the narrowing of the orange buffers also creates two tiny openings in the cross-diagonal corners. The third and fourth disks occupy these positions, and simultaneously allow the black background to peek through in two other spots. Finally the fifth and sixth disks close off the last black pixels, and the system jams.</p>
<p>This stereotyped sequence of disk placements accounts for the near absence of mortality at ages \(n = 2\) through \(n = 5\), and the sudden upsurge at age \(6\). The elevated levels at \(n = 7\) through \(11\) are part of the same pattern; depending on the exact positioning of the disks, it may take a few more to expunge the last remnants of black background. </p>
<p>At still higher values of \(n\)—for the small subset of trials that get there—the system seems to shift to a different mode of behavior. Although numerical noise makes it hard to draw firm conclusions, it doesn’t appear that any of the \(n\) values beyond \(n = 12\) are more likely jamming points than others. Indeed, the data are consistent with the idea that the probability of jamming remains constant as each additional disk is added to the array, just as scale invariance would suggest.</p>
<p>A much larger data set would be needed to test this conjecture, and collecting such data is painfully slow. Furthermore, when it comes to rare events, I don’t have much trust in the empirical data. During one series of experiments, I noticed a program run that stalled after \(290\) disks—unusually late. The 290-disk configuration, produced at \(s = 1.47\), is shown at left below.</p>
<p>This pattern, compared with those produced at lower values of \(s\), has a strongly Apollonian texture. Many of the disks are nestled tightly among their neighbors, and they form the recursive triangular motifs characteristic of Apollonian circles.<img src="http://bit-player.org/wp-content/uploads/2019/09/stymied-at-290-and-then-314-s148-maxAttmp1e10.png" height="320" width="645" alt="Stymied at 290 and then 314 s=148 maxAttmp=1e10" border="0" class="centered" /></p>
<p>I wondered if it was <em>truly</em> jammed. My program gives up on finding a place for a disk after \(10^7\) random attempts. Perhaps if I had simply persisted, it would have gone on. So I reset the limit on random attempts to \(10^9\), and sat back to wait. After some minutes the program discovered a place where disk \(291\) would fit, and then another for disk \(292\), and kept going as far as 300 disks. The program had an afterlife! Could I revive it again? Upping the limit to \(10^{10}\) allowed another \(14\) disks to squueze in. The final configuration is shown at right above (with the original \(290\) disks faded, in order to make the \(24\) posthumous additions more conspicuous).</p>
<p>Is it really finished now, or is there still room for one more? I have no reliable way to answer that question. Checking \(10\) billion random locations sounds like a lot, but it is still a very sparse sampling of the space inside the square box. Using 64-bit floating-point numbers to define the coordinate system allows for more than \(10^{30}\) distinguishable points. And to settle the question mathematically, we would need unbounded precision.</p>
<p>We know from Ennis’s proof that at values of \(s\) not too far above \(1.0\), the filling process can always go on forever. And we know that beyond \(s \approx 1.6\), every attempt to fill the square is doomed. There must be some kind of transition between these two conditions, but the details are murky. The experimental evidence gathered so far suggests a smooth transition along a sigmoid curve, with the probability of jamming gradually increasing from \(0\) to \(1\). As far as I can tell, however, nothing we know for certain rules out a single hard threshold, below which all disk sequences are immortal and above which all of them die. Thus the phase diagram would be reduced to this simple form:</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/two-state-spectrum-of-behaviors.svg" height="" width="640" alt="Two state spectrum of behaviors" border="0" class="centered" /></p>
<p class="undent">The softer transition observed in computational experiments would be an artifact of our inability to perform infinite random searches or place infinite sequences of disks.</p>
<hr />
<p>Here’s a different approach to understanding the random dots-in-a-box phenomenon. It calls for a mental reversal of figure and ground. Instead of placing disks on a square surface, we drill holes in a square metal plate. And the focus of attention is not the array of disks or holes but rather the spaces between them. Shier has a name for the perforated plate: the gasket. </p>
<p>Program 10 allows you to observe a gasket as it evolves from a solid black square to a delicate lace doily with less than 1 percent of its original substance.</p>
<h2 class="zf">Program 10: The Gasket</h2>
<div class="canvas-container canvas-failure" id="gasket">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">The gasket is quite a remarkable object. When the number of holes becomes infinite, the gasket must disappear entirely; its area falls to zero. Up until that very moment, however, it retains its structural integrity. This statement about the con­nectedness of the gasket requires a more careful consideration of what it means for two disks or holes to overlap. Are they allowed to touch, or in other words to be tangent, sharing a single point? The answer makes no difference to the calculation of areas, but it does matter for connectivity. Allowing tangency (as in Apollonian circles) would shatter the gasket, leaving tiny shards. To preserve connectivity, a computer program must test for overlaps with “\(\gt\)” rather than “\(\ge\)”.Although it may be reduced to a fine filigree, the perforated square never tears apart into multiple pieces; it remains a single, connected component, a network with multiple paths linking any two points you might choose.</p>
<p>As the gasket is etched away, can we measure the average thickness of the surviving wisps and tendrils? I can think of several methods that involve elaborate sampling schemes. Shier has a much simpler and more ingenious proposal: To find the average thickness of the gasket, divide its area by its perimeter. It was not immediately obvious to me why this number would serve as an appropriate measure of the width, but at least the units come out right: We are dividing a length squared by a length and so we get a length. And the operation does make basic sense: The area of the gasket represents the amount of substance in it, and the perimeter is the distance over which it is stretched. (The widths calculated in Program 10 differ slightly from those reported by Shier. The reason, I think, is that I include the outer boundary of the square in the perimeter, and he does not.)</p>
<p>Calculating the area and perimeter of a complicated shape such as a many-holed gasket looks like a formidable task, but it’s easy if we just keep track of these quantities as we go along. Initially (before any holes are drilled), the gasket area \(A_0^g\) is the area of the full square, \(A_\square\). The initial gasket perimeter \(P_0^g\) is four times the side length of the square, which is \(\sqrt{A_\square}\). Thereafter, as each hole is drilled, we subtract the new hole’s area from \(A^g\) and add its perimeter to \(P^g\). The quotient of these quantities is our measure of the average gasket width after drilling hole \(k\): \(\widehat{W}_k^g\). Since the gasket area is shrinking while the perimeter is growing, \(\widehat{W}_k^g\) must dwindle away as \(k\) increases.</p>
<p>The importance of \(\widehat{W}_k^g\) is that it provides a clue to how large a vacant space we’re likely to find for the next disk or hole. If we take the idea of “average” seriously, there must always be at least one spot in the gasket with a width equal to or greater than \(\widehat{W}_k^g\). From this observation Shier makes the leap to a whole new space-filling algorithm. Instead of choosing disk diameters according to a power law and then measuring the resulting average gasket width, he determines the radius of the next disk from the observed \(\widehat{W}_k^g\):</p>
<p>\[r_{k+1} = \gamma \widehat{W}_k^g = \gamma \frac{A_k^g}{P_k^g}.\]</p>
<p class="undent">Here \(\gamma\) is a fixed constant of proportionality that determines how tightly the new disks or holes fit into the available openings.</p>
<p>The area-perimeter algorithm has a recursive structure, in which each disk’s radius depends on the state produced by the previous disks. This raises the question of how to get started: What is the size of the first disk? Shier has found that it doesn’t matter very much. Initial disks in a fairly wide range of sizes yield jam-proof and aesthetically pleasing results.</p>
<p>Graphics produced by the original power-law algorithm and by the new recursive one look very similar. One way to understand why is to rearrange the equation of the recursion:</p>
<p>Perhaps this equation would be a little easier to interpret if the average width were defined in terms of hole diameters rather than hole perimeters. Then the denominator of the right hand side would be the sum of the first \(k\) diameters scaled by the \((k+1)\)st diameter.\[\frac{1}{2 \gamma} = \frac{A_k^g}{2 r_{k+1} P_k^g}.\]</p>
<p>On the right side of this equation we are dividing the average gasket width by the diameter of the next disk to be placed. The result is a dimensionless number—dividing a length by a length cancels the units. More important, the quotient is a constant, unchanging for all \(k\). If we calculate this same dimensionless gasket width when using the power-law algorithm, it also turns out to be nearly constant in the limit of karge \(k\), showing that the two methods yield sequences with similar statistics.</p>
<hr />
<p>Setting aside Shier’s recursive algorithm, all of the patterns we’ve been looking at are generated by a power law (or zeta function), with the crucial requirement that the series must converge to a finite sum. The world of mathematics offers many other convergent series in addition to power laws. Could some of them also create fulfilling patterns? The question is one that Ennis discusses briefly in his talk at St. Olaf and that Shier also mentions. </p>
<p>Among the obvious candidates are geometric series such as \(\frac{1}{1}, \frac{1}{2}, \frac{1}{4}, \frac{1}{8}, \dots\) A geometric series is a close cousin of a power law, defined in a similar way but exchanging the roles of \(s\) and \(k\). That is, a geometric series is the sum:</p>
<p>\[\sum_{k=0}^{\infty} \frac{1}{s^k} = \frac{1}{s^0} + \frac{1}{s^1} + \frac{1}{s^2} + \frac{1}{s^3} + \cdots\]</p>
<p class="undent">For any \(s &gt; 1\), the infinite geiometric series has a finite sum, namely \(\frac{s}{s - 1}\). Thus our task is to construct an infinite set of disks with individual areas \(1/s^k\) that we can pack into a square of area \(\frac{s}{s - 1}\). Can we find a range of \(s\) for which the series is fulfilling? As it happens, this is where Shier began his adventures; his first attempts were not with power laws but with geometric series. They didn’t turn out well. You are welcome to try your own hand in Program 11.</p>
<h2 class="zf">Program 11: Disk Sizes from Geometric Series</h2>
<div class="canvas-container canvas-failure" id="geometric">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p>There’s a curious pattern to the failures you’ll see in this program. No matter what value you assign to \(s\) (within the available range \(1 \lt s \le 2\)), the system jams when the number of disks reaches the neighborhood of \(A_\square = \frac{s}{s-1}\). <img src="http://bit-player.org/wp-content/uploads/2019/09/log-log-powerlaw-and-geom.svg" height="" width="" alt="Log log powerlaw and geom" border="0" class="alignright" />For example, at \(s = 1.01\), \(\frac{s}{s - 1}\) is 101 and the program typically gets stuck somewhere between \(k = 95\) and \(k = 100\). At \(s = 1.001\), \(\frac{s}{s - 1}\) is \(1{,}001\) and there’s seldom progress beyond about \(k = 1,000\). </p>
<p>For a clue to what’s going wrong here, consider the graph at right, plotting the values of \(1 / k^s\) <em>(red)</em> and \(1 / s^k\) <em>(blue)</em> for \(s = 1.01\). These two series converge on nearly the same sum (roughly \(100\)), but they take very different trajectories in getting there. On this log-log plot, the power-law series \(1 / s^k\) is a straight line. The geometric series \(1 / s^k\) falls off much more slowly at first, but there’s a knee in the curve at about \(k = 100\) <em>(dashed mauve line)</em>, where it steepens dramatically. If only we could get beyond this turning point, it looks like the rest of the filling process would be smooth sledding, but in fact we never get there. Whereas the first \(100\) disks of the power-law series fill up only about \(5\) percent of the available area, they occuy 63 percent in the geometric case. This is where the filling process stalls.</p>
<p>Even in one dimension, the geometric series quickly succumbs. (This is in sharp contrast to the one-dimensional power-law model, where any \(s\) between \(1\) and \(2\) yields a provably infinite progression of disks.)</p>
<h2 class="zf">Program 12: Disk Sizes from Geometric Series in One Dimension</h2>
<div class="canvas-container canvas-failure" id="geometric-1d">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">And just in case you think I’m pulling a fast one here, let me demonstrate that those same one-dimensional disks will indeed fit in the available space, if packed efficiently. In Program 13 they are placed in order of size from left to right.</p>
<h2 class="zf">Program 13: Deterministic One-Dimensional Geometric Series</h2>
<div class="canvas-container canvas-failure" id="deterministic-geom-1d">
<p>Sorry, the program will not run in this browser.</p>
</div>
<p class="indent">I have made casual attempts to find fulfillment with a few other convergent series, such as the reciprocals of the Fibonacci numbers (which converge to about \(3.36\)) and the reciprocals of the factorials (whose sum is \(e \approx 2.718\)). Both series jam after the first disk. There are plenty of other convergent series one might try, but I doubt this is a fruitful line of inquiry.</p>
<hr />
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/Shier-randomly-oriented-squares-600px.png" height="300" width="300" alt="Shier randomly oriented squares 600px" border="0" class="alignleft" />All the variations discussed above leave one important factor unchanged: The objects being fitted together are all circular. Exploring the wider universe of shapes has been a major theme of Shier’s work. He asks: What properties of a shape make it suitable for forming a statistical fractal pattern? And what shapes (if any) refuse to cooperate with this treatment? (The images in this section were created by John Shier and are reproduced here with his per­mission.)</p>
<p>Shier’s first experiments were with circular disks and axis-parallel squares; the filling algorithm worked splendidly in both cases. He also succeeded with axis-parallel rectangles of various aspect ratios, even when he mixed vertical and horizontal orientations in the same tableau. In collaboration with Paul Bourke he tried randomizing the orientation of squares as well as their positions. Again the outcome was positive, as the illustration above left shows.</p>
<p>Equilateral triangles were less cooperative, and at first Shier believed the algorithm would consistently fail with this shape. The triangles tended to form orderly arrays with the sharp point of one triangle pressed close against the broad side of another, leaving little “wiggle room.” <img src="http://bit-player.org/wp-content/uploads/2019/09/one_and_nines-transparent-300px.png" style="float: right;" height="600" width="300" alt="One and nines transparent 300px" border="0" class="alignright" />Further efforts showed that the algorithm was not truly getting stuck but merely slowing down. With an appropriate choice of parameters in the Hurwitz zeta function, and with enough patience, the triangles did come together in boundlessly extendable space-filling patterns.  </p>
<p>The casual exploration of diverse shapes eventually became a deliberate quest to stake out the limits of the space-filling process. Surely there must be <em>some</em> geometric forms that the algorithm would balk at, failing to pack an infinite number of objects into a finite area. Perhaps nonconvex shapes such as stars and snowflakes and flowers would expose a limitation—but no, the algorithm worked just fine with these figures, fitting smaller stars into the crevices between the points of larger stars. The next obvious test was “hollow” objects, such as annular rings, where an internal void is not part of the object and is therefore available to be filled with smaller copies. The image at right is my favorite example of this phenomenon. The bowls of the larger nines have smaller nines within them. It’s nines all the way down. When we let the process continue indefinitely, we have a whimsical visual proof of the proposition that \(.999\dots = 1\).</p>
<p>These successes with nonconvex forms and objects with holes led to an <em>Aha</em> moment, as Shier describes it. The search for a shape that would break the algorithm gave way to a suspicion that no such shape would be found, and then the suspicion gradually evolved into a conviction that any “reasonably compact” object is suitable for the <em>Fractalize That!</em> treatment. The phrase “reasonably compact” would presumably exclude shapes that are in fact dispersed sets of points, such as <a href="http://www.2dcurves.com/fractal/fractald.html">Cantor dust</a>. But Shier has shown that shapes formed of disconnected pieces, such as the words in the pair of images below, present no special difficulty.</p>
<p><img src="http://bit-player.org/wp-content/uploads/2019/09/MATH-and-ART-1280px.png" height="308" width="638" alt="MATH and ART 1280px" border="0" class="centered" /></p>
<p><em>Fractalize That!</em> is not all geometry and number theory. Shier is eager to explain the mathematics behind these curious patterns, but he also presents the algorithm as a tool for self-expression. MATH and ART both have their place.</p>
<hr />
<p>Finally, I offer some notes on what’s needed to turn these algorithms into computer programs. Shier’s book includes a chapter for do-it-yourselfers that explains his strategy and provides some crucial snippets of code (written in C). My own source code (in JavaScript) is available on <a href="https://github.com/bit-player/dotster">GitHub</a>. And if you’d like to play with the programs without all the surrounding verbiage, try the <a href="https://bit-player.github.io/dotster/">GitHub Pages version</a>.</p>
<p>The inner loop of a typical program looks something like this:</p>
<pre><code class="language-js">let attempt = 1;
while (attempt &lt;= maxAttempts) {
    disk.x = randomCoord();
    disk.y = randomCoord();
    if (isNotOverlapping(disk)) {
        return disk;
    }
    attempt++;
}
return false;</code></pre>
<p>We generate a pair of random \(x\) and \(y\) coordinates, which mark the center point of the new disk, and check for overlaps with other disks already in place. If no overlaps are discovered, the disk stays put and the program moves on. Otherwise the disk is discarded and we jump back to the top of the loop to try a new \(xy\) pair. </p>
<p>The main computational challenge lies in testing for overlaps. For any two specific disks, the test is easy enough: They overlap if the sum of their radii is greater than the distance between their centers. The problem is that the test might have to be repeated many millions of times. My program makes \(10\) million attempts to place a disk before giving up. If it has to test for overlap with \(100{,}000\) other disks on each attempt, that’s a trillion tests. A trillion is too many for an interactive program where someone is staring at the screen waiting for things to happen. To speed things up a little I divide the square into a \(32 \times 32\) grid of smaller squares. The largest disks—those whose diameter is greater than the width of a grid cell—are set aside in a special list, and all new candidate disks are checked for overlap with them. Below this size threshold, each disk is allocated to the grid cell in which its center lies. A new candidate is checked against the disks in its own cell and in that cell’s eight neighbors. The net result is an improvement by two orders of magnitude—lowering the worst-case total from \(10^{12}\) overlap tests to about \(10{10}\).</p>
<p>All of this works smoothly with circular disks. Devising overlap tests for the variety of shapes that Shier has been working with is much harder.</p>
<p>From a theoretical point of view, the whole rigmarole of overlap testing is hideously wasteful and unnecessary. If the box is already 90 percent full, then we know that 90 percent of the random probes will fail. A smarter strategy would be to generate random points only in the “black zone” where new disks can legally be placed. If you could do that, you would never need to generate more than one point per disk, and there’d be no need to check for overlaps. But keeping track of the points that comprise the black zone—scattered throughout multiple, oddly shaped, transient regions—would be a serious exercise in computational geometry.</p>
<p>For the actual drawing of the disks, Shier relies on the technology known as SVG, or scalable vector graphics. As the name suggests, these drawings retain full resolution at any size, and they are definitely the right choice if you want to create works of art. They are less suitable for the interactive programs embedded in this document, mainly because they consume too much memory. The images you see here rely on the HTML <em>canvas</em> element, which is simply a fixed-size pixel array.</p>
<p>Another point of possible interest is the evaluation of the zeta function. If we want to scale the disk sizes to match the box size (or vice versa), we need to compute a good approximation of the Riemann function \(\zeta(s)\) or the Hurwitz function \(\zeta(s, a)\). I didn’t know how to do that, and most of the methods I read about seemed overwhelming. Before I could get to zeta, I’d have to hack my way through thickets of polygamma functions and Stieltjes constants. For the Riemann zeta function I found a somewhat simpler algorithm published by Peter Borwein in 1995. It’s based on a polynomial approximation that yields ample precision and runs in less than a millisecond. For the Hurwitz zeta function I stayed with a straightforward translation of Shier’s code, which takes more of a brute-force approach. (There are alternatives for Hurwitz too, but I couldn’t understand them well enough to make them work.)</p>
<p>The JavaScript file in the <a href="https://github.com/bit-player/dotster">GitHub repository</a> has more discussion of implementation details.</p>
<hr />
<h2>Bibliography: Works by John Shier and colleagues</h2>
<p class="biblio">Shier, John. 2018. <em>Fractalize That! A Visual Essay on Statistical Geometry</em>. Singapore: World Scientific. <a href="https://www.worldscientific.com/worldscibooks/10.1142/11126">Publisher’s website</a>.</p>
<p class="biblio">Shier, John. Website: <a href="http://www.john-art.com/">http://www.john-art.com/</a></p>
<p class="biblio">Shier, John. 2011. The dimensionless gasket width \(b(c,n)\) in statistical geometry. <a href="http://www.john-art.com/gasket_width.pdf">http://www.john-art.com/gasket_width.pdf</a></p>
<p class="biblio">Shier, John. 2012. Random fractal filling of a line segment. <a href="http://www.john-art.com/gasket_width.pdf">http://www.john-art.com/gasket_width.pdf</a></p>
<p class="biblio">Dunham, Douglas, and John Shier. 2014. The art of random fractals. In <em>Proceedings of Bridges 2014: Mathematics, Music, Art, Architecture, Culture</em> pp. 79–86. <a href="http://archive.bridgesmathart.org/2014/bridges2014-79.pdf">PDF</a>.</p>
<p class="biblio">Shier, John. 2015. A new recursion for space-filling geometric fractals. <a href="http://www.john-art.com/gasket_width.pdf">http://www.john-art.com/gasket_width.pdf</a></p>
<p class="biblio">Dunham, Douglas, and John Shier. 2015. An algorithm for creating aesthetic random fractal patterns. Talk delivered at the Joint Mathematics Meetings January 2015, San Antonio, Texas. </p>
<p class="biblio">Dunham, Douglas, and John Shier. 2018. A property of area and perimeter. In <em>ICGG 2018: Proceedings of the 18th International Conference on Geometry and Graphics</em>, Milano, August 2018, pp. 228–237.</p>
<p class="biblio">Dunham, Douglas, and John Shier. 2017. New kinds of fractal patterns. In <em>Proceedings of Bridges 2017: Mathematics, Art, Music, Architecture, Education, Culture</em>,<br />
pp. 111–116. <a href="https://www.d.umn.edu/~ddunham/bridges17.pdf">Preprint</a>.</p>
<p class="biblio">Shier, John, and Paul Bourke. 2013. An algorithm for random fractal filling of space. <em>Computer Graphics Forum</em> 32(8):89–97. <a href="http://archive.bridgesmathart.org/2017/bridges2017-111.pdf">PDF</a>. <a href="http://www.john-art.com/Shier_Bourke_paper.pdf">Preprint</a>.</p>
<h2>Proof</h2>
<p class="biblio">Ennis, Christopher. 2016. (Always) room for one more. <em>Math Horizons</em> 23(3):8–12. <a href="https://www.tandfonline.com/doi/abs/10.4169/mathhorizons.23.3.8">PDF</a> (paywalled).</p>
<h2>Apollonian circles</h2>
<p class="biblio">Dodds, Peter Sheridan, and Joshua S. Weitz. 2002. Packing-limited growth. Physical Review E 65: 056108.</p>
<p class="biblio">Lagarias, Jeffrey C., Colin L. Mallows, and Allan R. Wilks. 2001. Beyond the Descartes circle theorem. <a href="https://arxiv.org/abs/math/0101066">https://arxiv.org/abs/math/0101066</a>. (Also published in <em>American Mathematical Monthly</em>, 2002, 109:338–361.)</p>
<p class="biblio">Mackenzie, Dana. 2010. A tisket, a tasket, an Apollonian gasket. <em>American Scientist</em> 98:10–14. <a href="https://www.americanscientist.org/article/a-tisket-a-tasket-an-apollonian-gasket">https://www.americanscientist.org/article/a-tisket-a-tasket-an-apollonian-gasket</a>.</p>
<p class="biblio">Manna, S. S. 1992. Space filling tiling by random packing of discs. <em>Physica A</em> 187:373–377.</p>
<h2>Zeta functions</h2>
<p class="biblio">Bailey, David H., and Jonathan M. Borwein. 2015. Crandall’s computation of the incomplete Gamma function and the Hurwitz zeta function, with applications to Dirichlet L-series. <em>Applied Mathematics and Computation</em>, 268, 462–477.</p>
<p class="biblio">Borwein, Peter. 1995. An efficient algorithm for the Riemann zeta function. http://www.cecm.sfu.ca/personal/pborwein/PAPERS/P155.pdf</p>
<p class="biblio">Coffey, Mark W. 2009. An efficient algorithm for the Hurwitz zeta and related functions. <em>Journal of Computational and Applied Mathematics</em> 225:338–346.</p>
<p class="biblio">Hurwitz, Adolf. 1882. Einige Eigenschaften der Dirichletschen Funktionen \(F(s) = \sum \left(\frac{D}{n} \frac{1}{n^s}\right)\), die bei der Bestimmung der Klassenzahlen binärer quadratischer Formen auftreten. <em>Zeitschrift für Mathematik und Physik</em> 27:86–101. <a href="https://gdz.sub.uni-goettingen.de/id/PPN599415665_0027">https://gdz.sub.uni-goettingen.de/id/PPN599415665_0027</a>.</p>
<p class="biblio">Oswald, Nicola, and Jörn Steuding. 2015. Aspects of zeta-function theory in the mathematical works of Adolf Hurwitz. <a href="https://arxiv.org/abs/1506.00856">https://arxiv.org/abs/1506.00856</a>.</p>
<p class="biblio">Xu, Andy. 2018. Approximating the Hurwitz zeta function. <a href="https://math.mit.edu/research/highschool/primes/materials/2018/Xu.pdf">PDF</a>.</p>
<p><br />
</p></div>







<p class="date">
by Brian Hayes <a href="http://bit-player.org/2019/my-god-its-full-of-dots"><span class="datestr">at September 27, 2019 03:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/09/26/congratulations-dr-mamano">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/09/26/congratulations-dr-mamano.html">Congratulations, Dr. Mamano!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Today <a href="https://www.ics.uci.edu/~nmamano/">Nil Mamano</a> successfully passed his dissertation defense. Nil has been a doctoral student at UCI, jointly supervised by Mike Goodrich and myself.</p>

<p>His dissertation, <em>New Applications of the Nearest-Neighbor Chain Algorithm</em>, includes material from several papers I’ve discussed here before:
<a href="https://11011110.github.io/blog/2017/04/11/stable-grid-matching.html">stable matching for points in grids</a>,
<a href="https://11011110.github.io/blog/2017/06/29/stable-redistricting-in.html">geographic clustering using stable matching with road network distances</a>,
<a href="https://11011110.github.io/blog/2018/03/14/finding-nearest-open.html">data structures for nearest neighbors in planar networks</a>,
<a href="https://11011110.github.io/blog/2018/04/26/stable-marriage-voronoi.html">stable-marriage Voronoi diagrams</a>, and
<a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html">the equivalence of local and global optimization for a wide range of combinatorial optimization problems</a>.</p>

<p>A common theme running through much of this work is the use of the <a href="https://en.wikipedia.org/wiki/Nearest-neighbor_chain_algorithm">nearest-neighbor chain algorithm</a> to find pairs of objects that are mutual nearest neighbors (a local definition of optimality) more quickly per pair than one could find the closest pair of objects (global optimality). A greedy algorithm based on this principle will find pairs in a different order than one that uses global closest pairs, but for many problems this ordering makes no difference in the eventual result. For these problems, once a pair become mutual nearest neighbors, they remain so until chosen, so the family of allowable sequences of choices made by the algorithm forms an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>.</p>

<p>As you might imagine, this makes for a long dissertation; unlike some other places, UCI has no upper limit on dissertation length. In fact, we briefly thought that Nil had unnecessarily included everything he’d done here in his dissertation, but it’s not even close to true. He also has publications on
<a href="https://11011110.github.io/blog/2016/06/01/robust-graph-isomorphism.html">graph watermarking</a> and <a href="https://11011110.github.io/blog/2019/01/31/linkage.html">knight’s tours</a> that didn’t fit with the main theme and were not included, as well as some even earlier publications on <a href="http://sana.ics.uci.edu/">simulated annealing for biological network alignment</a> with UCI professor Wayne Hayes, started while he was an exchange student here, before he joined the doctoral program and the theory group.</p>

<p>I think Nil already has a strong record of research and would do well continuing in that direction, but he has decided that he doesn’t want to, and I wouldn’t want to pressure him to change that decision even if I thought it would be successful. He tells me that he has a love-hate relation with research: he loves doing it, but he hates that (for him) to do it well, he has to make it the most important thing in his life. Instead, now that he has completed his doctorate, he will be looking for a job in industry.</p>

<p>Anyway, congratulations, Nil!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102862578075877620">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/09/26/congratulations-dr-mamano.html"><span class="datestr">at September 26, 2019 09:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16266">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/09/26/quantum-switch-em/">Quantum Switch-Em</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>A recipe for changing the objectives of problems</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/09/hhl.png"><img src="https://rjlipton.files.wordpress.com/2019/09/hhl.png?w=200&amp;h=100" alt="" width="200" class="aligncenter wp-image-16268" height="100" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://web.mit.edu/physics/people/faculty/harrow_aram.html">src1</a>, <a href="https://www.flickr.com/photos/barilan/45175102375">src2</a>, <a href="https://colloquium.phys.ethz.ch/programme/previous/autumn08/lloyd.html">src3</a></font></td>
</tr>
</tbody>
</table>
<p>
Aram Harrow, Avinatan Hassidim, and Seth Lloyd are quantum stars who have done many other things as well. They are jointly famous for their 2009 <a href="https://arxiv.org/pdf/0811.3171.pdf">paper</a>, “Quantum algorithm for linear systems of equations.”</p>
<p>
Today Ken and I discuss an aspect of their paper that speaks to a wider context.</p>
<p>
The paper by Harrow, Hassidim, and Lloyd addresses a fundamental problem: given an <img src="https://s0.wp.com/latex.php?latex=%7BN+%5Ctimes+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N \times N}" class="latex" title="{N \times N}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and an <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />-vector <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />, solve <img src="https://s0.wp.com/latex.php?latex=%7BAx+%3D+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Ax = b}" class="latex" title="{Ax = b}" />. This is called the Linear Systems Problem (LSP). They say in their abstract:</p>
<blockquote><p><b> </b> <em> Here, we exhibit a quantum algorithm for this task that runs in <img src="https://s0.wp.com/latex.php?latex=%7Bpoly%28log+N%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{poly(log N)}" class="latex" title="{poly(log N)}" /> time, an exponential improvement over the best classical algorithm. </em>
</p></blockquote>
<p></p><p>
What strikes us is what HHL meant by “this task” in their abstract. It is not LSP. Indeed, it can’t be LSP. They want to do it with a number <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> of qubits that is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cll+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ll N}" class="latex" title="{\ll N}" />. But the solution <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is a length-<img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> vector, which in general has at least <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> bits of information. No matter how much you entangle and wrangle, you <a href="https://en.wikipedia.org/wiki/Holevo's_theorem#Comments_and_remarks">cannot</a> extract more than <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> bits of information out of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> qubits. So even if <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n)}" class="latex" title="{O(n)}" />-sparse in some sense, and ignoring the issue of the time it would take to output the <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> entries of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, you can’t solve LSP with fewer qubits to get all of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> in the first place. </p>
<p>
The problem they solve has been given its own name in <a href="https://arxiv.org/pdf/1802.08227.pdf">subsequent</a> <a href="https://homepages.cwi.nl/~rdewolf/qcnotes.pdf">treatments</a>, including a 2015 <a href="https://arxiv.org/pdf/1511.02306.pdf">paper</a> by Andrew Childs, Robin Kothari, and Rolando Somma that greatly improved the time to achieve <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> precision:</p>
<blockquote><p><b> </b> <em> <b>Quantum Linear Systems Problem</b> (QLSP): Given a succinct representation of an invertible Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, code for a unitary operator <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> that maps <img src="https://s0.wp.com/latex.php?latex=%7B0%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{0^n}" class="latex" title="{0^n}" /> to a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7Cb%5Crangle%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{|b\rangle}" class="latex" title="{|b\rangle}" />, and an error tolerance <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />, output a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cxi%5Crangle%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{|\xi\rangle}" class="latex" title="{|\xi\rangle}" /> such that </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C%5C%3B%7C%5Cxi%5Crangle+-+%7C%5Cfrac%7Bx%7D%7B%7C%7Cx%7C%7C_2%7D%5Crangle%5C%3B%7C%7C_2+%3C+%5Cepsilon%2C+%5Cqquad%5Ctext%7Bwhere%7D%5Cqquad+x+%3D+A%5E%7B-1%7Db.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  ||\;|\xi\rangle - |\frac{x}{||x||_2}\rangle\;||_2 &lt; \epsilon, \qquad\text{where}\qquad x = A^{-1}b. " class="latex" title="\displaystyle  ||\;|\xi\rangle - |\frac{x}{||x||_2}\rangle\;||_2 &lt; \epsilon, \qquad\text{where}\qquad x = A^{-1}b. " /></p>
</em><p><em></em>
</p></blockquote>
<p></p><p>
The <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Ccdot%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\cdot\rangle}" class="latex" title="{|\cdot\rangle}" /> symbol is called a <b>ket</b> in Paul Dirac’s <a href="https://en.wikipedia.org/wiki/Bra-ket_notation">bra-ket</a> notation. “Ketting” a problem to our mind means accepting not only an approximate answer but also a loss of information that might apply to inputs as well as outputs.</p>
<p>
</p><p></p><h2> It’s a Changed Problem </h2><p></p>
<p></p><p>
What a solution to QLSP gives you is not <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> but a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cxi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\xi\rangle}" class="latex" title="{|\xi\rangle}" /> that approximates the unit-vector multiple of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. As HHL say earlier in their abstract, this changed problem is useful if what you really want is not <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> but some other value <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> derived from <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. They say for example that desired information could come from a quantum measurement of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />—that is, of <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cxi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\xi\rangle}" class="latex" title="{|\xi\rangle}" />. </p>
<p>
This blog did have a 2012 <a href="https://rjlipton.wordpress.com/2012/04/04/a-lazy-approach-to-problem-solving/">post</a> on “lazy problem solving” that included the quip: </p>
<blockquote><p><b> </b> <em> The idea is that when we solve a system <img src="https://s0.wp.com/latex.php?latex=%7BAx+%3D+b%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{Ax = b}" class="latex" title="{Ax = b}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, it is likely that we do not really want <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. We want some information about <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. For example, we might wish to know the norm of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. The question we plan to address is, are there algorithms that can do this faster than solving the entire linear system? </em>
</p></blockquote>
<p></p><p>
Ironically, the problem we suggested there, which is computing <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+x_i%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_i x_i^2}" class="latex" title="{\sum_i x_i^2}" /> up to multiplicative error <img src="https://s0.wp.com/latex.php?latex=%7B1+%5Cpm+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 \pm \epsilon}" class="latex" title="{1 \pm \epsilon}" />, is destroyed by normalizing <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> into a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cxi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\xi\rangle}" class="latex" title="{|\xi\rangle}" />. Oh well. But <a href="https://rjlipton.wordpress.com/2009/02/26/problems-not-algorithms/">other</a> <a href="https://rjlipton.wordpress.com/2014/07/21/shifts-in-algorithm-design/">posts</a> <a href="https://rjlipton.wordpress.com/2015/04/30/transcomputational-problems/">have</a> considered changing the objectives of algorithms. But the general idea involved in the formulation of QLSP strikes us anew—and in ways different from Scott Aaronson’s caveats in a wonderful <a href="https://scottaaronson.com/papers/qml.pdf">review</a> he wrote of HHL titled, “Quantum Machine Learning Algorithms: Read the Fine Print.” </p>
<p>
Going from LSP to QLSP switches the problem and enables showing that a quantum algorithm can solve the switched problem much faster than before. Very nice: HHL and its followups deserving of myriad citations. Scott’s review frames the question of whether the switch is fair from a practical perspective, including the restrictions on <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />. Perhaps the jury is still out on this: we’ve mentioned several times the nifty <a href="https://arxiv.org/abs/1807.04271">result</a> by Ewin Tang that found a quick classical solution to a <a href="https://cacm.acm.org/magazines/2019/8/238339-the-algorithm-that-changed-quantum-machine-learning/fulltext">problem</a> downstream of HHL that had been thought to require quantum. But switching a problem for research is fair—we do this all time in theory. We hope that the modified problem helps us understand the original problem. Let’s look at some examples.</p>
<p>
</p><p></p><h2> Ketted Problems </h2><p></p>
<p></p><p>
We think the general recipe will be clear from a couple more examples. The first one seems not to be the same as what is called “QSAT” <a href="https://arxiv.org/pdf/1203.6161.pdf">here</a> or <a href="https://dspace.mit.edu/handle/1721.1/108412">here</a>. </p>
<p></p><p><br />
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> “Ketted SAT”: Given a CNF formula <img src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Phi}" class="latex" title="{\Phi}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n}" class="latex" title="{2^n}" /> variables but <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^{O(1)}}" class="latex" title="{n^{O(1)}}" />-sized clauses, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0}" class="latex" title="{\epsilon &gt; 0}" />, output a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cxi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\xi\rangle}" class="latex" title="{|\xi\rangle}" /> such that for some satisfying assignment <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C%5C%3B%7C%5Cxi%5Crangle+-+%7C%5Cfrac%7Bx%7D%7B%7C%7Cx%7C%7C_2%7D%5Crangle+%7C%7C_2+%5Cleq+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{||\;|\xi\rangle - |\frac{x}{||x||_2}\rangle ||_2 \leq \epsilon}" class="latex" title="{||\;|\xi\rangle - |\frac{x}{||x||_2}\rangle ||_2 \leq \epsilon}" />. </p>
<p>
We still suspect this is known at least implicitly in the context of interactive proofs and PCPs and error-correcting codes. In that context, the idea of getting an assignment within distance <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> of a satisfying one might make sense. For other purposes it is not so useful—e.g., it might not help utiliize the self-reducibility structure of SAT. It may simply be equivalent to known succinct-SAT problems after applying the coding used to obtain <a href="http://www.cs.yale.edu/homes/spielman/PAPERS/holographic.pdf">holographic proofs</a>, but we don’t immediately see it.</p>
<p>
Note that the fact of <img src="https://s0.wp.com/latex.php?latex=%7B%5CPhi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Phi}" class="latex" title="{\Phi}" /> being in CNF with small clause size (which can even be constant) mirrors the sparseness condition on <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> that is usually assumed in cases of HHL. So the analogy to QLSP holds up there. At least “ketted SAT” is a different problem.</p>
<p></p><p><br />
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> “Ketted Factoring”: Given a really large integer <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, output a quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\pi\rangle}" class="latex" title="{|\pi\rangle}" /> such that for some nontrivial (prime) factor <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C%5C%3B%7C%5Cpi%5Crangle+-+k%28p%29%7C%7C+%3C+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{||\;|\pi\rangle - k(p)|| &lt; \epsilon}" class="latex" title="{||\;|\pi\rangle - k(p)|| &lt; \epsilon}" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bk%28p%29+%3D+%5Csum_%7Bi%3A+bin%28p%2Ci%29+%3D+1%7D+%7Ci%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k(p) = \sum_{i: bin(p,i) = 1} |i\rangle}" class="latex" title="{k(p) = \sum_{i: bin(p,i) = 1} |i\rangle}" />.</p>
<p>
We can suppose that we have oracle lookup to bits of <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, so that all the bits can be placed into quantum superposition. We could alternatively encode <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> as the quantum state <img src="https://s0.wp.com/latex.php?latex=%7Bk%28M%29+%3D+%5Csum_%7Bi%3A+bin%28N%2Ci%29+%3D+1%7D+%7Ci%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k(M) = \sum_{i: bin(N,i) = 1} |i\rangle}" class="latex" title="{k(M) = \sum_{i: bin(N,i) = 1} |i\rangle}" />, but then the problem might not be well-defined because <img src="https://s0.wp.com/latex.php?latex=%7Bk%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k(M)}" class="latex" title="{k(M)}" /> cannot retain all info about <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />. </p>
<p>
This is not in the shadow of Shor’s algorithm because that needs <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> to have <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n)}" class="latex" title="{O(n)}" /> digits in order eventually to get a factor exactly. The quantumized version applies when <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is really big. Again, it is not clear that the solutions <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\pi\rangle}" class="latex" title="{|\pi\rangle}" /> would be useful for things like breaking cryptosystems. They might represent points of cryptographic weakness in some detailed sense. In any event, it’s a different problem. </p>
<p>
</p><p></p><h2> More General Changed Problems </h2><p></p>
<p></p><p>
With all of these there are questions about how far the change reflects on the original problem, but at least the change generated substantial research and interesting new angles.</p>
<p>
</p><p></p><h3> The Goldbach problem </h3><p></p>
<p><i>Every even number is the sum of two primes</i> <img src="https://s0.wp.com/latex.php?latex=%7B%7E%5Crightarrow%7E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{~\rightarrow~}" class="latex" title="{~\rightarrow~}" /> <i>Every even number is the sum of two almost-primes</i>.</p>
<p>
A number is an almost prime if it is a prime or a product of at most two primes. This is a quite useful result, but not what we really believe is true.</p>
<p>
</p><p></p><h3> P=NP </h3><p></p>
<p><i><img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> not equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /></i> <img src="https://s0.wp.com/latex.php?latex=%7B%7E%5Crightarrow%7E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{~\rightarrow~}" class="latex" title="{~\rightarrow~}" /> <i><img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%5E%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}^{A}}" class="latex" title="{\mathsf{P}^{A}}" /> not equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%5E%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}^{A}}" class="latex" title="{\mathsf{NP}^{A}}" /></i>.</p>
<p>
This says that if we relativize to some oracle <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> are not equal. This is a famous <a href="https://en.wikipedia.org/wiki/Oracle_machine">result</a> of Theodore Baker, John Gill, and Robert Solovay. It sheds light on the structure of algorithms, but does not rule out that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> could still equal <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" />.</p>
<p>
</p><p></p><h3> The Collatz Problem </h3><p></p>
<p><i>The <img src="https://s0.wp.com/latex.php?latex=%7B3x%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3x+1}" class="latex" title="{3x+1}" /> problem.</i></p>
<p>
Let <img src="https://s0.wp.com/latex.php?latex=%7BCol%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Col(N)}" class="latex" title="{Col(N)}" /> be <img src="https://s0.wp.com/latex.php?latex=%7BN%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N/2}" class="latex" title="{N/2}" /> when <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> is even, and <img src="https://s0.wp.com/latex.php?latex=%7B%283N%2B1%29%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(3N+1)/2}" class="latex" title="{(3N+1)/2}" /> when <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> is odd. The problem is whether the orbit 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++N+%5Crightarrow+Col%28N%29+%5Crightarrow+Col%5E%7B2%7D%28N%29+%5Crightarrow+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  N \rightarrow Col(N) \rightarrow Col^{2}(N) \rightarrow \dots " class="latex" title="\displaystyle  N \rightarrow Col(N) \rightarrow Col^{2}(N) \rightarrow \dots " /></p>
<p>reaches <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> for all positive integers <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />. The change is:</p>
<p>
<i>All positive integers</i> <img src="https://s0.wp.com/latex.php?latex=%7B%7E%5Crightarrow%7E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{~\rightarrow~}" class="latex" title="{~\rightarrow~}" /> <i>Almost all</i>.</p>
<p>
Actually, Terence Tao got a cool result this year only by making a second change. In his <a href="https://arxiv.org/pdf/1909.03562.pdf">paper</a> “Almost All Orbits Of The Collatz Map Attain Almost Bounded Values” he proves that <img src="https://s0.wp.com/latex.php?latex=%7BColmin+%28N%29+%3C+f%28n%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Colmin (N) &lt; f(n) }" class="latex" title="{Colmin (N) &lt; f(n) }" /> for almost all <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> and any <img src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(n)}" class="latex" title="{f(n)}" /> that tends to infinity. Thus 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28n%29+%3D+%5Clog+%5Clog+%5Clog+%5Clog+N+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(n) = \log \log \log \log N " class="latex" title="\displaystyle  f(n) = \log \log \log \log N " /></p>
<p>is fine. Here <img src="https://s0.wp.com/latex.php?latex=%7BColmin%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Colmin(N)}" class="latex" title="{Colmin(N)}" /> is the smallest integer that is reached in the orbit of <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />. It is scary how hard this is to prove.</p>
<p>
</p><p></p><h3> Explicit Hard Boolean Functions </h3><p></p>
<p></p><p>
Find explicit boolean functions with non-linear boolean complexity.</p>
<p>
<i>Boolean complexity with negation</i> <img src="https://s0.wp.com/latex.php?latex=%7B%7E%5Crightarrow%7E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{~\rightarrow~}" class="latex" title="{~\rightarrow~}" /> <i>Boolean complexity without negation.</i> </p>
<p>
These are the seminal results on monotone boolean complexity. They came up two years ago in an abortive attempt to prove <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D+%5Cneq+%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P} \neq \mathsf{NP}}" class="latex" title="{\mathsf{P} \neq \mathsf{NP}}" />, which we covered <a href="https://rjlipton.wordpress.com/2017/08/17/on-the-edge-of-eclipses-and-pnp/">here</a>.</p>
<p>
</p><p></p><h3> Quantum Supremacy </h3><p></p>
<p></p><p>
We come full circle back to quantum computing. This week there has been much hubbub over a prematurely-released <a href="https://www.docdroid.net/h9oBikj/quantum-supremacy-using-a-programmable-superconducting-processor.pdf">announcement</a> that Google researchers have built a quantum device able to complete probabilistic searches that are not feasible by any classical computer. If one goes back to <a href="https://arxiv.org/pdf/1203.5813.pdf">origins</a> of the <a href="https://quantumfrontiers.com/2012/07/22/supremacy-now/">term</a> “quantum supremacy” in 2012, before Google’s approach was conceived in 2015, one can say the change is:</p>
<p>
<i>specific physical simulation or complexity-based problems</i> <img src="https://s0.wp.com/latex.php?latex=%7B%7E%5Crightarrow%7E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{~\rightarrow~}" class="latex" title="{~\rightarrow~}" /> <i>randomized problems</i>.</p>
<p>
Scott has a great <a href="https://www.scottaaronson.com/blog/?p=4317">post</a> with preliminary descriptions and evaluations, and we confess to adapting the following telegraphic evocation of how it works from Ryan O’Donnell and others in the comments section: Given a randomly-generated probability distribution <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0,1\}^n}" class="latex" title="{\{0,1\}^n}" />, call <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> “<img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />-heavy” if <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> gives it probability <img src="https://s0.wp.com/latex.php?latex=%7Bb%2F2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b/2^n}" class="latex" title="{b/2^n}" /> for some fixed <img src="https://s0.wp.com/latex.php?latex=%7Bb+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b &gt; 1}" class="latex" title="{b &gt; 1}" />. Even given <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> in white-box form via an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit quantum circuit <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> with randomly placed gates, it is evidently hard (compare <a href="https://arxiv.org/pdf/1803.04402.pdf">this</a>) for a classical computer to find heavy strings with frequency <img src="https://s0.wp.com/latex.php?latex=%7B%3E+%281+-+2%2Fe%29+%2B+%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{&gt; (1 - 2/e) + \delta}" class="latex" title="{&gt; (1 - 2/e) + \delta}" />, concretely for <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+53%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 53}" class="latex" title="{n = 53}" />. Google’s quantum machine, which is effectively programmed by the user presenting the random <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, can however find heavy strings with frequency <img src="https://s0.wp.com/latex.php?latex=%7B%281+-+2%2Fe%29+%2B+%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1 - 2/e) + \Delta}" class="latex" title="{(1 - 2/e) + \Delta}" /> with a highly significant separation between <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />. We surmise that exhaustive tests over classical circuits trying the search at smaller values of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> have witnessed the smaller <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> value at those <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />.</p>
<p>
Again, this approach is different from demonstrating a specific computable function to separate classical and quantum and from the instances considered in the concluding <a href="https://rjlipton.wordpress.com/2012/10/03/quantum-supremacy-or-classical-control/">post</a>, with “supremacy” in its title, of our eight-part series in 2012 between Gil Kalai and, yes, Aram Harrow.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Is our general notion of “ketted problems” useful? Ketted SAT and Factoring lack the natural continuity in (Q)LSP, but at least for SAT it can be grafted on by composing the formula with an error-correcting code. There is still the issue of being able to extract less classical information from the ketted approximations.</p>
<p>
We note a theory <a href="https://www.pims.math.ca/scientific-event/190928-ntd2paul">workshop</a> being held this Saturday at UW Seattle in honor of Paul Beame’s 60th birthday. We congratulate Paul on both.</p>
<p></p><p><br />
[added Aug. 2019 CACM link for Ewin Tang’s theorem; changed 1/e to (1 – 2/e) near end but not sure if that fix is intended by the source.]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/09/26/quantum-switch-em/"><span class="datestr">at September 26, 2019 06:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/09/26/33rd-conference-of-the-european-chapter-on-combinatorial-optimization/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/09/26/33rd-conference-of-the-european-chapter-on-combinatorial-optimization/">33rd Conference of the European Chapter on Combinatorial Optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
June 4-6, 2020 Saint Petersburg, Russia https://ecco2020.euro-online.org/ Submission deadline: February 1, 2020 The 33rd Conference of the European Chapter on Combinatorial Optimization (ECCO 2020) will be held in the beautiful city of St. Petersburg during the white nights season. It will be hosted by St. Petersburg Department of Steklov Mathematical Institute of the Russian Academy … <a href="https://cstheory-events.org/2019/09/26/33rd-conference-of-the-european-chapter-on-combinatorial-optimization/" class="more-link">Continue reading <span class="screen-reader-text">33rd Conference of the European Chapter on Combinatorial Optimization</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/09/26/33rd-conference-of-the-european-chapter-on-combinatorial-optimization/"><span class="datestr">at September 26, 2019 06:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5706639639416187826">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/09/quantum-supremacy.html">Quantum Supremacy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
By now you've probably heard the rumors of Google achieving quantum supremacy. I don't have inside information outside of <a href="https://www.scottaaronson.com/blog/?p=4317">Scott's blog post</a> but it looks like the news should be <a href="https://blog.computationalcomplexity.org/2006/10/embargoed-science.html">embargoed</a> until the release of a Science or Nature paper. These things usually happen on a Tuesday and you'd think they would avoid the news of the Nobel Prize announcements October 7-14.<br />
<br />
Since for now the Google paper doesn't officially exist, we live in an era of Classical Dominance. Any problem that can be solved on a quantum computer today, can be solved just as fast or faster on a traditional computer. Quantum Supremacy, despite its lofty name, is just the negation of Classical Dominance, that there is some problem that a current quantum machine can solve that all our regular machines would require a considerably longer time to solve. This isn't a formal mathematical or scientific definition, so one can debate when or if we cross this threshold and I'm sure <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/">people will</a>.<br />
<br />
Quantum Supremacy might not even be a monotone concept. Future classical algorithms might solve the problem quickly, leading us back to Classical Dominance but leaving open the possibility of returning to Quantum Supremacy with another problem.<br />
<br />
Quantum Supremacy is a long way from Quantum Usefulness, where quantum machines can solve problems we care about faster that traditional machines. Quantum computing will truly reach its potential when we can run general quantum algorithms like Shor's algorithm to factor products of large primes. We'll probably never see Quantum Dominance where classical transistors go the way of vacuum tubes.<br />
<br />
Nevertheless, quantum supremacy is an important step and whether or not you think Google has gotten there, I'm sure it's an incredible achievement of science and engineering.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/09/quantum-supremacy.html"><span class="datestr">at September 26, 2019 05:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://sarielhp.org/blog/?p=9392">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sariel.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://sarielhp.org/blog/?p=9392">CS UIUC is hiring in quantum computing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>In addition to the hiring in theory I <a href="https://sarielhp.org/blog/?p=9390">mentioned</a> earlier, we are also, independently, looking for people working in Quantum Computing. In particular, we might be able to hire several people doing QC this year. So, if you are in QC and interested, then you should <a href="https://cs.illinois.edu/about-us/faculty-positions">apply</a>!</p></div>







<p class="date">
by Sariel <a href="https://sarielhp.org/blog/?p=9392"><span class="datestr">at September 26, 2019 02:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://sarielhp.org/blog/?p=9390">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sariel.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://sarielhp.org/blog/?p=9390">UIUC CS is hiring in theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><span class="css-901oao css-16my406 r-1qd0xha r-ad9z0x r-bcqeeo r-qvutc0">UIUC CS is hiring faculty this academic year in all areas. All areas include theory.  So please apply if you are doing CS theory.</span></p>



<p>Job ad:<a href="https://cs.illinois.edu/about-us/faculty-positions">https://cs.illinois.edu/about-us/faculty-positions</a>.</p></div>







<p class="date">
by Sariel <a href="https://sarielhp.org/blog/?p=9390"><span class="datestr">at September 25, 2019 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/09/25/associate-professor-professor-in-algorithms-and-complexity-at-norwegian-university-of-science-and-technology-apply-by-october-16-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/09/25/associate-professor-professor-in-algorithms-and-complexity-at-norwegian-university-of-science-and-technology-apply-by-october-16-2019/">Associate professor/Professor in Algorithms and Complexity at Norwegian University of Science and Technology (apply by October 16, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science is looking for a researcher in Algorithms and Complexity. The focus of this position is on the more theoretical side of computer science, with an emphasis on complexity and algorithm design, possibly leaning more in one of the two directions than the other. While the connection to theory is central, applied research is certainly welcome.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/172226/associate-professor-professor-in-algorithms-and-complexity">https://www.jobbnorge.no/en/available-jobs/job/172226/associate-professor-professor-in-algorithms-and-complexity</a><br />
Email: magnus.sjalander@ntnu.no</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/09/25/associate-professor-professor-in-algorithms-and-complexity-at-norwegian-university-of-science-and-technology-apply-by-october-16-2019/"><span class="datestr">at September 25, 2019 11:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-2666895105637388793">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2019/09/two-phd-positions-at-department-of.html">Two PhD positions at the Department of Computer Science Reykjavik University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br /><br /><div class="x_MsoNormal"><i><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;">My Reykjavik colleagues </span><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;"><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;"><a href="https://dblp.org/pers/hd/i/Islind:Anna_Sigridur">Anna Sigríður Íslind </a>and </span></span></i><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;"><i><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;"><a href="https://dblp.org/pers/hd/o/Oskarsdottir:Maria">María Óskarsdóttir</a> have t</span>wo PhD positions available at Reykjavik University, Iceland. The position announcements are below. Please contact them for more information. In my biased opinion, they will be excellent PhD supervisors. </i></span></div><div class="x_MsoNormal"><br /></div><div class="x_MsoNormal"><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;">-----------------------------------------------------------------------------------------------------</span></div><div class="x_MsoNormal"><br /></div><h1><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;">Position 1: PhD position in learning analytics and informatics</span></h1><div><b><span style="color: black; font-size: 12pt;">Information about the research topic</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">We are looking for a full-time PhD student to conduct research on learning analytics in the context of learning management platforms. The aim of the PhD position is to study learning behavior in higher education through learning management platforms which are widely used for administration, documentation and reporting of educational courses and learning programs. The behavioral data that is generated while students use the platforms can be analyzed to understand how they interact with the learning content in relation to the learning outcomes and objectives. The PhD candidate will study learning behavior using advanced analytics and machine learning techniques with the goal of discovering patterns in learning as well as to understand and optimize the learning process and the environment in which it occurs, as well as investigate how the architecture of the learning environment enables learning.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Information about the department and the university</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">You will join us at the Department of Computer Science, Reykjavík University. The department covers a broad range of research topics in Computer Science and is engaged in several national and international research projects, often interdisciplinary in nature.</span></div><div><span style="color: black; font-size: 12pt;">Reykjavík University is a private university located in Reykjavík, Iceland. The university currently hosts approximately 3500 students, divided into the Departments of Computer Science, Sport Science, Psychology, Business, Law, Applied Engineering, and Engineering. All of Reykjavík University is located in a single building in one of the most beautiful areas of Reykjavík.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Qualification requirements</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">Candidates should have a strong interest in data science, information systems research as well as learning and teaching. To be eligible for this position, you should have/be about to obtain an MSc degree in Computer Science, Statistics, Information Systems, Informatics, Mathematics, Engineering or related fields. Strong candidates with a background in other relevant topics are very much encouraged to apply as well.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Position summary</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">Full-time temporary employment (currently paid 365,000 ISK per month before taxes, roughly 3000 USD at current exchange rate). You are expected to finish your PhD within four years' time. The position includes teaching duties of roughly 20%.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Application procedure</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">Interested applicants should submit their application through the recruitment website<span class="x_apple-converted-space"> </span>radningar.hr.is</span></div><div><span style="color: black; font-size: 12pt;">The application should include</span></div><ul type="disc"><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">CV<span style="font-family: Calibri, sans-serif, serif, EmojiFont;" class="x_apple-converted-space"> </span></li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Research proposal stating the possible development of what you would like to do based on the description above (ca. 2 pages)</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Two letters of reference (e.g., from academic supervisors, former superiors)</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">A 1 to 3-page personal letter where you introduce yourself and present your qualifications/experience/interests</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Attested copies of education certificates, including grade reports</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Bachelor and/or Master thesis</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Research publications, if existent</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Links to software repositories with relevant projects, if existent</li></ul><div><br /></div><div class="x_MsoNormal"><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;">-------------------------------------------------------------------------------------------</span></div><h1><span style="color: black; font-family: Calibri, sans-serif, serif, EmojiFont;">Position 2: PhD position in informatics focusing on health platforms</span></h1><div><b><span style="color: black; font-size: 12pt;">Information about the research topic</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">We are looking for a full-time PhD student to conduct research on design, development and use of platforms for continuous data gathering for health purposes. The aim of the PhD position is to study the design and development of a health data platform that takes in health data and how the health data can be used for decision-making purposes. The cases more specifically both includes data from extremely healthy individuals (on elite sport level) and on the other hand, from those that are chronically ill. The focus in the beginning will be on data from national teams collected both through measurements during practice, and on continuous data collection through wearable technologies. The PhD student will study the design and development of the multi-sided platform and how the use of the platform effects different stakeholders involved. For instance, the data collected by athletes, can be used by them as well as by trainers and researchers, which has implications both for the design process, as well as for those using the data. In addition, the PhD student will also study a case of chronically ill individuals, where the data is from the same types of technologies, but can be used for a different purpose, to support decision-making processes in healthcare. In these cases the where the stakeholders are patients , that gather data that which can be used by medical staff to support their decision-making process, and by researchers. Furthermore, we will apply machine learning and advanced analytics to discover patterns that can on the one hand help athletes enhance their performance and on the other hand detect warning signs for the chronically ill. In addition, on the topic of learning from data and designing, and developing platforms for health and wellbeing purposes, the PhD student will also work with a case on new ways of screening for breast cancer.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Information about the department and the university</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">You will join us at the Department of Computer Science, Reykjavík University. The department covers a broad range of research topics in Computer Science and information systems and is engaged in several national and international research projects, often interdisciplinary in nature.</span></div><div><span style="color: black; font-size: 12pt;">Reykjavík University is a private university located in Reykjavík, Iceland. The university currently hosts approximately 3500 students, divided into the Departments of Computer Science, Sport Science, Psychology, Business, Law, Applied Engineering, and Engineering. All of Reykjavík University is located in a single building in one of the most beautiful areas of Reykjavík. Reykjavík University is a private university located in Reykjavík, Iceland. The university currently hosts approximately 3500 students, divided into the Schools of Computer Science, Business, Law, and Science and Engineering. All of Reykjavík University is located in a single building in one of the most beautiful areas of Reykjavík.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Qualification requirements</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">Candidates should have a strong interest in data science, information systems research as well as in wellbeing and health related topics. To be eligible for this position, you should have/be about to obtain an MSc degree in Computer Science, Information Systems, Informatics, Engineering or related fields. Strong candidates with a background in other relevant topics are very much encouraged to apply as well.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Position summary</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">Full-time temporary employment (currently paid 365,000 ISK per month before taxes, roughly 3000 USD at current exchange rate). You are expected to finish your PhD within four years' time. The position includes teaching duties of roughly 20%.</span></div><div><span style="color: black; font-size: 12pt;"><br /><b>Application procedure</b></span></div><div><span style="color: black; font-size: 12pt;">Interested applicants should submit their application through the recruitment website; radningar.hr.is<br />The application should include:</span></div><ul type="disc"><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">CV<span style="font-family: Calibri, sans-serif, serif, EmojiFont;" class="x_apple-converted-space"> </span></li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Research proposal stating possible development that extends what you would like to do, based on the description above (ca. 2 pages)</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Two letters of reference (e.g., from academic supervisors, former bosses/superiors)</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">A 1 to 3-page personal letter where you introduce yourself and present your qualifications/experience/interests</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Attested copies of education certificates, including grade reports</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Bachelor and/or Master thesis.</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Research publications, if existent</li><li style="color: black; font-family: Calibri, sans-serif; font-size: 12pt;" class="x_MsoNormal">Links to software repositories with relevant projects, if existent</li></ul><div><br /></div><div><b><span style="color: black; font-size: 12pt;">The deadline for application in November 1st, 2019</span></b><span style="color: black; font-size: 12pt;">. We will start reviewing applications as soon as they arrive. We strongly encourage interested applicants to send their applications as soon as possible.</span></div><div><br /></div><div><b><span style="color: black; font-size: 12pt;">Questions?</span></b><span style="color: black; font-size: 12pt;"></span></div><div><span style="color: black; font-size: 12pt;">If you have any questions, want more details on the position, or just check before sending in your application, please contact us directly!</span></div><div><br /></div><div><br /></div><div><span style="color: black; font-size: 12pt;">Anna Sigríður Íslind</span></div><div><span style="color: black; font-size: 12pt;">Assistant Professor | School Department of Computer Science, Reykjavík University</span></div><div><span style="color: black; font-size: 12pt;"><a href="mailto:annasi@ru.is" target="_blank" rel="noopener noreferrer">annasi@ru.is</a></span></div><div><br /></div><div><span style="color: black; font-size: 12pt;">María Óskarsdóttir<span class="x_apple-converted-space"> </span></span></div><div><span style="color: black; font-size: 12pt;">Assistant Professor | School Department of Computer Science, Reykjavík University</span></div><div><span style="color: black; font-size: 12pt;"><a href="mailto:mariaoskars@ru.is" target="_blank" rel="noopener noreferrer">mariaoskars@ru.is</a></span></div></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2019/09/two-phd-positions-at-department-of.html"><span class="datestr">at September 24, 2019 12:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7557">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/09/23/is-quantum-supremacy-here/">Is quantum supremacy here?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>See <a href="https://www.scottaaronson.com/blog/?p=4317">Scott Aaronson’s blog</a>. It seems like researchers in John Martinis’s group at Google might have managed to demonstrate that a quantum computer can produce samples passing a certain statistical test for which we know no efficient classical algorithm to do so.</p>



<p>Of course I can’t help but posting again the <a href="https://windowsontheory.org/2017/06/11/two-years-ahead-of-schedule/">fake nytimes headline</a> I produced for my 2016 crypto course when I wanted to motivate the study of so called “quantum-resistant cryptography”:</p>



<figure class="wp-block-image size-large"><img src="https://windowsontheory.files.wordpress.com/2019/09/nytimes.jpg?w=1024" alt="" class="wp-image-7558" /></figure></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2019/09/23/is-quantum-supremacy-here/"><span class="datestr">at September 24, 2019 03:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/09/24/postdoc-at-national-institute-of-informatics-apply-by-december-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/09/24/postdoc-at-national-institute-of-informatics-apply-by-december-1-2019/">Postdoc at National Institute of Informatics (apply by December 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Postdoc positions are available to work on average sensitivity of algorithms in a theoretical or practical aspect or both, or related topics such as sublinear-time algorithms, approximate counting, statistical learning theory. Please contact Yuichi Yoshida directly with your CV. The start date is flexible.</p>
<p>Website: <a href="http://research.nii.ac.jp/~yyoshida/">http://research.nii.ac.jp/~yyoshida/</a><br />
Email: yyoshida@nii.ac.jp</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/09/24/postdoc-at-national-institute-of-informatics-apply-by-december-1-2019/"><span class="datestr">at September 24, 2019 03:10 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/128">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/128">TR19-128 |  Lower Bounds for (Non-monotone) Comparator Circuits | 

	Anna Gal, 

	Robert Robere</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Comparator circuits are a natural circuit model for studying the concept of bounded fan-out computations, which intuitively corresponds to whether or not a computational model can make "copies" of intermediate computational steps. Comparator circuits are believed to be weaker than general Boolean circuits, but they can simulate Branching Programs and Boolean formulas. In this paper we prove the first superlinear lower bounds in the general (non-monotone) version of this model for an explicitly defined function. More precisely, we prove that the $n$-bit Element Distinctness function requires $\Omega( (n/ \log n)^{3/2})$ size comparator circuits.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/128"><span class="datestr">at September 24, 2019 02:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7554">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/09/23/information-theoretic-cryptography-itc-conference-guest-post-by-benny-applebaum/">Information-Theoretic Cryptography (ITC) conference (guest post by Benny Applebaum)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>[The following is a guest post by Benny Applebaum announcing a new conference on information theoretic cryptography – an area with both beautiful math and important applications. –Boaz] </em></p>



<p>Deal friends,<br />We are happy to announce the birth of a new conference on Information-Theoretic Cryptography (ITC). Information-theoretic cryptography studies security in the presence of computationally unbounded adversaries and covers a wide array of topics at the intersection of cryptography, coding theory, information-theory and theory of computation. Notable examples include randomness extraction and privacy amplification, secret sharing, secure multiparty computation and proof systems, private-information retrieval and locally decodable codes, authentication codes and non-malleable codes, differential privacy, quantum information processing, and information-theoretic foundations of physical-layer security. See <a href="https://itcrypto.github.io/" target="_blank" rel="noreferrer noopener">https://itcrypto.github.io</a> for more information. </p>



<p>ITC replaces the International Conference on Information Theoretic Security (ICITS), which was dedicated to the same topic and ran 2005-2017. ITC can be seen as a reboot of ICITS with a new name, a new steering committee and a renewed excitement.  (beware: there is  a fake website for ICITS 2019 created by a known <a href="https://en.wikipedia.org/wiki/World_Academy_of_Science,_Engineering_and_Technology" target="_blank" rel="noreferrer noopener">fraudulent organization</a>)  </p>



<p>The conference will have two tracks: a conference track and  a “greatest hits” track. The conference track will operate like a traditional conference with the usual review process and published proceedings. The “greatest hits” track consists of invited talks (not included in the proceedings) that highlight the most exciting recent advances in the area. We solicit nominations for “greatest hits” talks from the community.</p>



<p>The first ITC conference will take place in Boston, MA on June 17-19, 2020 (just before STOC).  The submission deadline for ITC 2020 is Dec 16, 2019 and the call for papers (including a nomination procedure for the greatest hits track) is available here:  <a href="https://itcrypto.github.io/2020.html" target="_blank" rel="noreferrer noopener">https://itcrypto.github.io/2020.html</a></p>



<p>Please submit your best work to ITC 2020! We hope to see many of you there!</p>



<p>best regards,The Steering Committee:  Benny Applebaum (Chair), Ivan Damgård , Yevgeniy Dodis,  Yuval Ishai, Ueli Maurer,  Kobbi Nissim, Krzysztof Pietrzak, Manoj Prabhakaran, Adam Smith, Yael Tauman Kalai, Stefano Tessaro, Vinod Vaikuntanathan, Hoeteck Wee, Daniel Wichs, Mary Wootters,  Chaoping Xing, Moti Yung

</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2019/09/23/information-theoretic-cryptography-itc-conference-guest-post-by-benny-applebaum/"><span class="datestr">at September 23, 2019 09:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4317">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4317">Scott’s Supreme Quantum Supremacy FAQ!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>You’ve seen the stories—in the <em>Financial Times</em>, <em>Technology Review</em>, <em>CNET</em>, Facebook, Reddit, Twitter, or elsewhere—saying that a group at Google has now achieved quantum computational supremacy with a 53-qubit superconducting device.  While these stories are easy to find, I’m not going to link to them here, for the simple reason that <em>none of them were supposed to exist yet</em>.</p>



<p>As the world now knows, Google is indeed preparing a big announcement about quantum supremacy, to coincide with the publication of its research paper in a high-profile journal (which journal?  you can probably narrow it down to two).  This will hopefully happen within a month.</p>



<p>Meanwhile, though, NASA, which has some contributors to the work, inadvertently posted an outdated version of the Google paper on a public website.  It was there only briefly, but long enough to make it to the <em>Financial Times</em>, my inbox, and millions of other places.  Fact-free pontificating about what it means has predictably proliferated.</p>



<p>The world, it seems, is going to be denied its clean “moon landing” moment, wherein the Extended Church-Turing Thesis gets experimentally obliterated within the space of a press conference.  This is going to be more like the Wright Brothers’ flight—about which rumors and half-truths leaked out in dribs and drabs between 1903 and 1908, the year Will and Orville finally agreed to do public demonstration flights.  (This time around, though, it thankfully won’t take <em>that</em> long to clear everything up!)</p>



<p>I’ve known about what was in the works for a couple months now; it was excruciating not being able to blog about it.  Though sworn to secrecy, I couldn’t resist dropping some hints here and there (did you catch any?)—for example, in my recent <a href="https://www.scottaaronson.com/blog/?p=4301">Bernays Lectures</a> in Zürich, a lecture series whose entire structure built up to the brink of this moment.</p>



<p>This post is not an official announcement or confirmation of anything.  Though the lightning may already be visible, the thunder belongs to the group at Google, at a time and place of its choosing.</p>



<p>Rather, because so much misinformation is swirling around, what I thought I’d do here, in my role as blogger and “public intellectual,” is offer <strong>Scott’s Supreme Quantum Supremacy FAQ</strong>.  You know, just in case you were randomly curious about the topic of quantum supremacy, or wanted to know what the implications would be if some search engine company based in Mountain View or wherever were <em>hypothetically</em> to claim to have achieved quantum supremacy.</p>



<p>Without further ado, then:</p>



<p><strong>Q1. What is quantum computational supremacy?</strong></p>



<p>Often abbreviated to just “quantum supremacy,” the term refers to the use of a quantum computer to solve <em>some</em> well-defined set of problems that would take orders of magnitude longer to solve with any currently known algorithms running on existing classical computers—and not for incidental reasons, but for reasons of asymptotic quantum complexity.  The emphasis here is on being as sure as possible that the problem <em>really was</em> solved quantumly and <em>really is</em> classically intractable, and ideally achieving the speedup <em>soon</em> (with the noisy, non-universal QCs of the present or very near future).  If the problem is also <em>useful</em> for something, then so much the better, but that’s not at all necessary.  The Wright Flyer and the Fermi pile weren’t useful in themselves.</p>



<p><strong>Q2. If Google has indeed achieved quantum supremacy, does that mean that now <a href="https://mobile.twitter.com/AndrewYang/status/1175200727385464832">“no code is uncrackable”</a>, as Democratic presidential candidate Andrew Yang recently tweeted?</strong></p>



<p>No, it doesn’t.  (But I still like Yang’s candidacy.)</p>



<p>There are two issues here.  First, the devices currently being built by Google, IBM, and others have 50-100 qubits and no error-correction.  Running Shor’s algorithm to break the RSA cryptosystem would require several thousand logical qubits.  With known error-correction methods, that could easily translate into <em>millions</em> of physical qubits, and those probably of a higher quality than any that exist today.  I don’t think anyone is close to that, and we have no idea how long it will take.</p>



<p>But the second issue is that, even in a hypothetical future with scalable, error-corrected QCs, on our current understanding they’ll only be able to crack <em>some</em> codes, not all of them.  By an unfortunate coincidence, the public-key codes that they can crack include <em>most</em> of what we currently use to secure the Internet: RSA, Diffie-Hellman, elliptic curve crypto, etc.  But symmetric-key crypto should only be minimally affected.  And there are even candidates for public-key cryptosystems (for example, based on lattices) that no one knows how to break quantumly after 20+ years of trying, and some efforts underway now to start migrating to those systems.  For more, see for example my <a href="https://www.scottaaronson.com/blog/?p=3848">letter to Rebecca Goldstein</a>.</p>



<p><strong>Q3. What calculation is Google planning to do, or has it already done, that’s believed to be classically hard?</strong></p>



<p>So, I can tell you, but I’ll feel slightly sheepish doing so.  The calculation is: a “challenger” generates a random quantum circuit C (i.e., a random sequence of 1-qubit and nearest-neighbor 2-qubit gates, of depth perhaps 20, acting on a 2D grid of n = 50 to 60 qubits).  The challenger then sends C to the quantum computer, and asks it apply C to the all-0 initial state, measure the result in the {0,1} basis, send back whatever n-bit string was observed, and repeat some thousands or millions of times.  Finally, using its knowledge of C, the classical challenger applies a statistical test to check whether the outputs are consistent with the QC having done this.</p>



<p>So, this is not a problem like factoring with a single right answer.  The circuit C gives rise to some probability distribution, call it D<sub>C</sub>, over n-bit strings, and the problem is to output samples from that distribution.  In fact, there will typically be 2<sup>n</sup> strings in the support of D<sub>C</sub>—so many that, if the QC is working as expected, the same output will never be observed twice.  A crucial point, though, is that the distribution D<sub>C</sub> is <em>not</em> uniform.  Some strings enjoy constructive interference of amplitudes and therefore have larger probabilities, while others suffer destructive interference and have smaller probabilities.  And even though we’ll only see a number of samples that’s tiny compared to 2<sup>n</sup>, we can <em>check</em> whether the samples preferentially cluster among the strings that are predicted to be likelier, and thereby build up our confidence that something classically intractable is being done.</p>



<p>So, tl;dr, the quantum computer is simply asked to apply a random (but known) sequence of quantum operations—not because we intrinsically care about the result, but because we’re trying to prove that it can beat a classical computer at <em>some</em> well-defined task.</p>



<p><strong>Q4. But if the quantum computer is just executing some random garbage circuit, whose only purpose is to be hard to simulate classically, then who cares?  Isn’t this a big overhyped nothingburger?</strong></p>



<p>No.  As I put it the other day, it’s not an everythingburger, but it’s certainly at least a somethingburger!</p>



<p>It’s like, have a little respect for the immensity of what we’re talking about here, and for the terrifying engineering that’s needed to make it reality.  Before quantum supremacy, by definition, the QC skeptics can all laugh to each other that, for all the billions of dollars spent over 20+ years, <em>still</em> no quantum computer has even once been used to solve any problem faster than your laptop could solve it, or at least not in any way that depended on its being a quantum computer.  In a post-quantum-supremacy world, that’s no longer the case.  A superposition involving 2<sup>50</sup> or 2<sup>60</sup> complex numbers has been computationally harnessed, using time and space resources that are minuscule compared to 2<sup>50</sup> or 2<sup>60</sup>.</p>



<p>I keep bringing up the Wright Flyer only because the chasm between what we’re talking about, and the dismissiveness I’m seeing in some corners of the Internet, is kind of breathtaking to me.  It’s like, if you believed that useful air travel was fundamentally impossible, then seeing a dinky wooden propeller plane keep itself aloft wouldn’t refute your belief … <em>but it sure as hell shouldn’t reassure you either</em>.</p>



<p>Was I right to <a href="https://blogs.scientificamerican.com/cross-check/scott-aaronson-answers-every-ridiculously-big-question-i-throw-at-him/">worry</a>, years ago, that the constant drumbeat of hype about much less significant QC milestones would wear out people’s patience, so that they’d no longer care when something newsworthy finally did happen?</p>



<p><strong>Q5. Years ago, you scolded the masses for being super-excited about D-Wave, and its claims to get huge quantum speedups for optimization problems via quantum annealing.  Today you scold the masses for <em>not</em> being super-excited about quantum supremacy.  Why can’t you stay consistent?</strong></p>



<p>Because my goal is not to move the “excitement level” in some uniformly preferred direction, it’s to be right!  With hindsight, would you say that I was mostly right about D-Wave, even when raining on that particular parade made me unpopular in some circles?  Well, I’m trying to be right about quantum supremacy too.</p>



<p><strong>Q6. If quantum supremacy calculations just involve sampling from probability distributions, how do you check that they were done correctly?</strong></p>



<p>Glad you asked!  This is the subject of a fair amount of theory that I and others developed over the last decade.  I already gave you the short version in my answer to Q3: you check by doing statistics on the samples that the QC returned, to verify that they’re preferentially clustered in the “peaks” of the chaotic probability distribution D<sub>C</sub>.  One convenient way of doing this, which Google calls the “linear cross-entropy test,” is simply to sum up Pr[C outputs s<sub>i</sub>] over all the samples s<sub>1</sub>,…,s<sub>k</sub> that the QC returned, and then to declare the test a “success” if and only if the sum exceeds some threshold—say, bk/2<sup>n</sup>, for some constant b strictly between 1 and 2.</p>



<p>Admittedly, in order to apply this test, you need to <em>calculate</em> the probabilities Pr[C outputs s<sub>i</sub>] on your classical computer—and the only known ways to calculate them require brute force and take ~2<sup>n</sup> time.  Is that a showstopper?  No, not if n is 50, and you’re Google and are able to handle numbers like 2<sup>50</sup> (although not 2<sup>1000</sup>, which exceeds a <a href="https://en.wikipedia.org/wiki/Googol">googol</a>, har har).  By running a huge cluster of classical cores for (say) a month, you can eventually verify the outputs that your QC produced in a few seconds—while also seeing that the QC was many orders of magnitude faster.  However, this does mean that sampling-based quantum supremacy experiments are almost <em>specifically</em> designed for ~50-qubit devices like the ones being built right now.  Even with 100 qubits, we wouldn’t know how to verify the results using all the classical computing power available on earth.</p>



<p>(Let me stress that this issue is specific to <em>sampling</em> experiments like the ones that are currently being done.  If Shor’s algorithm factored a 2000-digit number, it would be easy to check the result by simply multiplying the claimed factors and running a primality test on them.  Likewise, if a QC were used to simulate some complicated biomolecule, you could check its results by comparing them to experiment.)</p>



<p><strong>Q7. Wait.  If classical computers can only check the results of a quantum supremacy experiment, in a regime where the classical computers can still simulate the experiment (albeit extremely slowly), then how do you get to claim “quantum supremacy”?</strong></p>



<p>Come on.  With a 53-qubit chip, it’s perfectly feasible to see a speedup by a factor of many millions, in a regime where you can still directly verify the outputs, and also to see that the speedup is growing exponentially with the number of qubits, exactly as asymptotic analysis would predict.  This isn’t marginal.</p>



<p><strong>Q8. Is there a mathematical proof that no fast classical algorithm could possibly spoof the results of a sampling-based quantum supremacy experiment?</strong></p>



<p>Not at present.  But that’s not quantum supremacy researchers’ fault!  As long as theoretical computer scientists can’t even prove basic conjectures like P≠NP or P≠PSPACE, there’s no hope of ruling out a fast classical simulation unconditionally.  The best we can hope for are conditional hardness results.  And we have indeed managed to prove some such results—see for example the <a href="https://arxiv.org/abs/1011.3245">BosonSampling paper</a>, or the <a href="https://arxiv.org/abs/1803.04402">Bouland et al. paper</a> on average-case #P-hardness of calculating amplitudes in random circuits, or <a href="https://arxiv.org/abs/1612.05903">my paper with Lijie Chen</a> (“Complexity-Theoretic Foundations of Quantum Supremacy Experiments”).  The biggest theoretical open problem in this area, in my opinion, is to prove <em>better</em> conditional hardness results.</p>



<p><strong>Q9. Does sampling-based quantum supremacy have any applications in itself?</strong></p>



<p>When people were first thinking about this subject, it seemed pretty obvious that the answer was “no”!  (I know because I was one of the people.)  Recently, however, the situation has changed—for example, because of my <a href="https://www.scottaaronson.com/talks/certrand2.ppt">certified randomness protocol</a>, which shows how a sampling-based quantum supremacy experiment could almost immediately be repurposed to generate bits that can be <em>proven to be random</em> to a skeptical third party (under computational assumptions).  This, in turn, has possible applications to proof-of-stake cryptocurrencies and other cryptographic protocols.  I’m hopeful that more such applications will be discovered in the near future.</p>



<p><strong>Q10. If the quantum supremacy experiments are just generating random bits, isn’t that uninteresting?  Isn’t it trivial to convert qubits into random bits, just by measuring them?</strong></p>



<p>The key is that a quantum supremacy experiment doesn’t generate <em>uniform</em> random bits.  Instead, it samples from some complicated, correlated probability distribution over 50- or 60-bit strings.  In my certified randomness protocol, the deviations from uniformity play a central role in how the QC convinces a classical skeptic that it really <em>was</em> sampling the bits randomly, rather than in some secretly deterministic way (e.g., using a pseudorandom generator).</p>



<p><strong>Q11. Haven’t decades of quantum-mechanical experiments–for example, the ones that violated the Bell inequality–already demonstrated quantum supremacy?</strong></p>



<p>This is purely a confusion over words.  Those other experiments demonstrated other forms of “quantum supremacy”: for example, in the case of Bell inequality violations, what you could call “quantum correlational supremacy.”  They did not demonstrate quantum <em>computational</em> supremacy, meaning doing something that’s infeasible to simulate using a classical computer (where the classical simulation has no restrictions of spatial locality or anything else of that kind).  Today, when people use the phrase “quantum supremacy,” it’s generally short for quantum computational supremacy.  </p>



<p><strong>Q12. Even so, there are countless examples of materials and chemical reactions that are hard to classically simulate, as well as special-purpose quantum simulators (like those of Lukin’s group at Harvard).  Why don’t these already count as quantum computational supremacy?</strong></p>



<p>Under some people’s definitions of “quantum computational supremacy,” they do!  The key difference with Google’s effort is that they have a <em>fully programmable </em>device—one that you can program with an arbitrary sequence of nearest-neighbor 2-qubit gates, just by sending the appropriate signals from your classical computer.</p>



<p>In other words, it’s no longer open to the QC skeptics to sneer that, sure, there are quantum systems that are hard to simulate classically, but that’s just because <em>nature</em> is hard to simulate, and you don’t get to arbitrarily redefine whatever random chemical you find in the wild to be a “computer for simulating itself.”  Under any sane definition, the superconducting devices that Google, IBM, and others are now building are indeed “computers.”</p>



<p><strong>Q13. Did you (Scott Aaronson) invent the concept of quantum supremacy?</strong></p>



<p>No.  I did play some role in developing it, which led to Sabine Hossenfelder among others <a href="http://backreaction.blogspot.com/2019/06/quantum-supremacy-what-is-it-and-what.html">generously overcrediting me</a> for the whole idea.  The term “quantum supremacy” was coined by John Preskill in 2012, though in some sense the core concept goes back to the beginnings of quantum computing itself in the early 1980s.  In 1993, <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.655.1186&amp;rep=rep1&amp;type=pdf">Bernstein and Vazirani</a> explicitly pointed out the severe apparent tension between quantum mechanics and the Extended Church-Turing Thesis of classical computer science.  Then, in 1994, the use of Shor’s algorithm to factor a huge number became the quantum supremacy experiment <em>par excellence</em>—albeit, one that’s still (in 2019) much too hard to perform.</p>



<p>The key idea of instead demonstrating quantum supremacy using a <em>sampling problem</em> was, as far as I know, first suggested by Barbara Terhal and David DiVincenzo, in a <a href="https://arxiv.org/abs/quant-ph/0205133">farsighted paper</a> from 2002.  The “modern” push for sampling-based supremacy experiments started around 2011, when Alex Arkhipov and I published our <a href="https://arxiv.org/abs/1011.3245">paper on BosonSampling</a>, and (independently of us) Bremner, Jozsa, and Shepherd published their <a href="https://arxiv.org/abs/1005.1407">paper on the commuting Hamiltonians model</a>.  These papers showed, not only that “simple,” non-universal quantum systems can solve apparently-hard sampling problems, but also that an efficient classical algorithm for the same sampling problems would imply a collapse of the <a href="https://en.wikipedia.org/wiki/Polynomial_hierarchy">polynomial hierarchy</a>.  Arkhipov and I also made a start toward arguing that even the <em>approximate</em> versions of quantum sampling problems can be classically hard.</p>



<p>As far as I know, the idea of “Random Circuit Sampling”—that is, generating your hard sampling problem by just picking a random sequence of 2-qubit gates in (say) a superconducting architecture—originated in an email thread that I started in December 2015, which also included John Martinis, Hartmut Neven, Sergio Boixo, Ashley Montanaro, Michael Bremner, Richard Jozsa, Aram Harrow, Greg Kuperberg, and others.  The thread was entitled “Hard sampling problems with 40 qubits,” and my email began “Sorry for the spam.”  I then discussed some advantages and disadvantages of three options for demonstrating sampling-based quantum supremacy: (1) random circuits, (2) commuting Hamiltonians, and (3) BosonSampling.  After Greg Kuperberg chimed in to support option (1), a consensus quickly formed among the participants that (1) was indeed the best option from an engineering standpoint—and that, if the theoretical analysis wasn’t yet satisfactory for (1), then that was something we could remedy.</p>



<p>[<strong>Update:</strong> Sergio Boixo tells me that, internally, the Google group had been considering the idea of random circuit sampling since February 2015, even before my email thread.  This doesn’t surprise me: while there are lots of details that had to be worked out, the idea itself is an extremely natural one.]</p>



<p>After that, the Google group did a huge amount of analysis of random circuit sampling, both theoretical and numerical, while <a href="https://arxiv.org/abs/1612.05903">Lijie Chen and I</a> and <a href="https://arxiv.org/abs/1803.04402">Bouland et al.</a> supplied different forms of complexity-theoretic evidence for the problem’s classical hardness.</p>



<p><strong>Q14. If quantum supremacy was achieved, what would it mean for the QC skeptics?</strong></p>



<p>I wouldn’t want to be them right now!  They could retreat to the position that <em>of course</em> quantum supremacy is possible (who ever claimed that it wasn’t? surely not them!), that the real issue has always been quantum error-correction.  And indeed, some of them have consistently maintained that position all along.  But others, including my good friend Gil Kalai, are <strong>on record, right here on this blog</strong> predicting that even quantum supremacy can never be achieved for fundamental reasons.  I won’t let them wiggle out of it now.</p>



<p>[<strong>Update:</strong> As many of you will have seen, Gil Kalai has <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/">taken the position</a> that the Google result won’t stand and will need to be retracted.  He asked for more data: specifically, a complete histogram of the output probabilities for a smaller number of qubits.  This turns out to be already available, in a <em><a href="https://arxiv.org/abs/1709.06678">Science</a></em><a href="https://arxiv.org/abs/1709.06678"> paper from 2018</a>.]</p>



<p><strong>Q15. What’s next?</strong></p>



<p><em>If</em> it’s achieved quantum supremacy, then I think the Google group already has the requisite hardware to demonstrate my <a href="https://www.scottaaronson.com/talks/certrand2.ppt">protocol for generating certified random bits</a>.  And that’s indeed one of the very next things they’re planning to do.</p>



<p>[<strong>Addendum:</strong> Also, of course, the evidence for quantum supremacy itself can be made stronger and various loopholes closed—for example, by improving the fidelity so that fewer samples need to be taken (something that Umesh Vazirani tells me he’d like to see), by having the circuit C be generated and the outputs verified by a skeptic external to Google. and simply by letting more time pass, so outsiders can have a crack at simulating the results classically.  My personal guess is that the basic picture is going to stand, but just like with the first experiments that claimed to violate the Bell inequality, there’s still plenty of room to force the skeptics into a tinier corner.]</p>



<p>Beyond that, one obvious next milestone would be to use a programmable QC, with (say) 50-100 qubits, to do some <em>useful quantum simulation</em> (say, of a condensed-matter system) much faster than any known classical method could do it.  A second obvious milestone would be to demonstrate the use of quantum error-correction, to keep an encoded qubit alive for longer than the underlying physical qubits remain alive.  There’s no doubt that Google, IBM, and the other players will now be racing toward both of these milestones.</p>



<p>[<strong>Update:</strong> Steve Girvin reminds me that the Yale group <a href="https://arxiv.org/abs/1602.04768">has already achieved</a> quantum error-correction “beyond the break-even point,” albeit in a bosonic system rather than superconducting qubits.  So perhaps a better way to phrase the next milestone would be: achieve quantum computational supremacy <em>and</em> useful quantum error-correction in the same system.]</p>



<p><strong>Another update:</strong> I thought <a href="https://spectrum.ieee.org/tech-talk/computing/hardware/how-googles-quantum-supremacy-plays-into-quantum-computings-long-game">this </a><em><a href="https://spectrum.ieee.org/tech-talk/computing/hardware/how-googles-quantum-supremacy-plays-into-quantum-computings-long-game">IEEE Spectrum</a></em><a href="https://spectrum.ieee.org/tech-talk/computing/hardware/how-googles-quantum-supremacy-plays-into-quantum-computings-long-game"> piece</a> gave a really nice overview of the issues.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4317"><span class="datestr">at September 23, 2019 08:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
