<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at May 25, 2019 08:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/075">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/075">TR19-075 |  Relations and Equivalences Between Circuit Lower Bounds and Karp-Lipton Theorems | 

	Lijie Chen, 

	Dylan McKay, 

	Cody Murray, 

	Ryan Williams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Relations and Equivalences Between Circuit Lower Bounds and Karp-Lipton Theorems

A frontier open problem in circuit complexity is to prove P^NP is not in SIZE[n^k] for all k; this is a necessary intermediate step towards NP is not in P/poly. Previously, for several classes containing P^NP, including NP^NP, ZPP^NP, and S_2 P, such lower bounds have been proved via Karp-Lipton-style Theorems: to prove C is not in SIZE[n^k] for all k, we show that C subset Ppoly implies a ``collapse'' D = C for some larger class D, where we already know D is not in SIZE[n^k] for all k. 

It seems obvious that one could take a different approach to prove circuit lower bounds for P^NP that does not require proving any Karp-Lipton-style theorems along the way. We show this intuition is wrong: (weak) Karp-Lipton-style theorems for P^NP are equivalent to fixed-polynomial size circuit lower bounds for P^NP. That is, P^NP not subset SIZE[n^k] for all k if and only if (NP is in P/poly implies PH is in i.o.-P^NP/n).
		
Next, we present new consequences of the assumption NP is in P/poly, towards proving similar results for NP circuit lower bounds. We show that under the assumption, fixed-polynomial circuit lower bounds for NP, nondeterministic polynomial-time derandomizations, and various fixed-polynomial time simulations of NP are all equivalent. Applying this equivalence, we show that circuit lower bounds for NP imply better Karp-Lipton collapses. That is, if NP is not in SIZE[n^k] for all k, then for all C in { ParP, PP, PSPACE, EXP }, C is in P/poly implies C is in i.o.-NP/n^eps for all eps &gt; 0. Note that unconditionally, the collapses are only to MA and not NP.
		
We also explore consequences of circuit lower bounds for a sparse language in NP. Among other results, we show if a polynomially-sparse NP language does not have n^(1+eps)-size circuits, then MA is in i.o.-NP/O(log n), MA is in i.o.-P^{NP[O(log n)]}, and NEXP is not in SIZE[2^o(m)]. Finally, we observe connections between these results and the ``hardness magnification'' phenomena described in recent works.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/075"><span class="datestr">at May 25, 2019 06:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15910">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/05/25/selected-papers-at-ccc-2019/">Selected Papers at CCC 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Some papers from the accepted list of this year’s Computational Complexity Conference</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/05/25/selected-papers-at-ccc-2019/unknown-122/" rel="attachment wp-att-15912"><img width="150" alt="" class="alignright  wp-image-15912" src="https://rjlipton.files.wordpress.com/2019/05/unknown-1.jpeg?w=150" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ UB CSE ]</font></td>
</tr>
</tbody>
</table>
<p>
Alan Selman is a long-time friend of Ken and I, and is a long-time researcher in complexity theory. Alan was the first president of the organizing <a href="https://www.computationalcomplexity.org/governance.php">body</a> for the Computational Complexity Conferences (CCC). </p>
<p>
Today we salute the <img src="https://s0.wp.com/latex.php?latex=%7B0b100010%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0b100010}" class="latex" title="{0b100010}" />th edition of the conference and discuss some of the accepted papers.</p>
<p>
The conference, and the governing body, have changed names over the years; by any name it remains an important conference. Alan <a href="https://www.computationalcomplexity.org/documents/first-cfp.pdf">chaired</a> the first program committee with Steve Mahaney and <a href="https://dl.acm.org/citation.cfm?id=648296&amp;picked=prox">edited</a> the first proceedings, in 1986. </p>
<p>
Ken recently saw Alan two weeks ago at the banquet for the <a href="http://www.fields.utoronto.ca/activities/18-19/NP50">symposium</a> honoring Steve Cook at the University of Toronto. We will cover event, once <a href="https://rjlipton.wordpress.com/2019/05/21/making-up-tests/">exams</a> are done. Ken saw another of the CCC past presidents there—if you wish to guess who, a hint is it was one of Cook’s past students.</p>
<ul>
<li>
Dieter van Melkebeek, 2012-2018 <p></p>
</li><li>
Peter Bro Miltersen, 2009-2012 <p></p>
</li><li>
Pierre McKenzie, 2006-2009 <p></p>
</li><li>
Lance Fortnow, 2000-2006 <p></p>
</li><li>
Eric Allender, 1997-2000 <p></p>
</li><li>
Steven Homer, 1994-1997 <p></p>
</li><li>
Timothy Long, 1992-1994 <p></p>
</li><li>
Stephen Mahaney, 1988-1992 <p></p>
</li><li>
Alan Selman, 1985-1988
</li></ul>
<p>
Although we do not usually do announcements, we note from the conference <a href="https://computationalcomplexity.org">website</a>:</p>
<blockquote><p><b> </b> <em> Details of the local arrangements for CCC 2019 and the preceding events, including the DIMACS Day of Tutorials, are available. Early registration runs till June 26. </em>
</p></blockquote>
<p>
</p><p></p><h2> Six Papers with Some Comments </h2><p></p>
<p></p><p>
Here are some papers that I, Dick, found interesting from the list of accepted papers. All accepted papers are interesting, of course. I selected six that were on topics that were directly connected with my interests.</p>
<p>
<b>Criticality of Regular Formulas</b>—<a href="http://www.math.toronto.edu/rossman/criticality.pdf">paper</a><br />
Benjamin Rossman<br />
<i>I thought this was about regular expressions. Shows something about me.</i> Here “regular” means the in-degree of gates being the same at each level of the circuit. This condition seems likely to be removable as Rossman conjectures, but I doubt it will be easy. The term “criticality” is a parameter that measures how much a random restriction reduces the size of a formula. Think switching lemma.</p>
<p>
<b>Typically-Correct Derandomization for Small Time and Space</b>—<a href="https://arxiv.org/abs/1711.00565">paper</a><br />
William Hoza<br />
<i>I like the notion of typically-correct.</i> Their algorithms work by treating the input as a source of randomness. This idea was pioneered by Oded Goldreich and Avi Wigderson. The title of their 2002 <a href="http://www.wisdom.weizmann.ac.il/~oded/p_rnd02.html">article</a> “Derandomization that is rarely wrong from short advice that is typically good”, gives away how one can prove such results. </p>
<p>
<b>Optimal Short-Circuit Resilient Formulas</b>—<a href="https://arxiv.org/abs/1807.05014">paper</a><br />
Mark Braverman, Klim Efremenko, Ran Gelles, and Michael Yitayew <br />
<i>This is on a kind of fault-tolerance.</i> They consider fault-tolerant boolean formulas in which the output of a faulty gate is stuck at one of the gate’s inputs. This is an interesting model of errors, and they show roughly: any formula can be converted into a formula that is not too much bigger and survives even if about <img src="https://s0.wp.com/latex.php?latex=%7B1%2F5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/5}" class="latex" title="{1/5}" /> of the gates are faulty. A surprise is that they use a method related to <i>blockchains</i>. Hmmmmm. Interesting.</p>
<p>
<b>Fourier and Circulant Matrices are Not Rigid</b>—<a href="https://arxiv.org/pdf/1902.07334.pdf">paper</a><br />
Allen Liu and Zeev Dvir <br />
<i>A matrix is rigid if its rank cannot be reduced significantly by changing a small number of entries.</i> As you probably know there are plenty of rigid matrices—take random ones—but no provable examples of explicit ones. Their beautiful results prove that specific families of matrices are not rigid. These families include ones that were long thought to be rigid. The highlight of this work could be that it suggests new families that may be rigid. </p>
<p>
<b>Average-Case Quantum Advantage with Shallow Circuits</b>—<a href="https://arxiv.org/pdf/1810.12792.pdf">paper</a><br />
François Le Gall <br />
<i>A quest, the quest that tops all others—is the search for evidence that quantum computers are better than classic ones.</i> Of course, this is nearly impossible, since P=PSPACE is an open problem. So one looks at special classes of computations. See <a href="https://arxiv.org/pdf/1612.05903.pdf">here</a> for how the quest for “quantum advantage” meets up with computational complexity.</p>
<p>
<b>Relations and Equivalences Between Circuit Lower Bounds and Karp-Lipton Theorems</b><br />
<a href="https://eccc.weizmann.ac.il/report/2019/075/">paper</a><br />
Lijie Chen, Dylan McKay, Cody Murray, and Ryan Williams <br />
<i>Of course I think this is an interesting paper.</i> There is the famous H-score. Perhaps there could be a T-score. This would be the number of times your name is in the title of a published paper. Thus Ron Rivest, for example, has a huge T-score.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What are your selected papers? </p>
<p>
[Added link to Relations and Equivalences… paper]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/05/25/selected-papers-at-ccc-2019/"><span class="datestr">at May 25, 2019 03:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4982821151012814632">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/05/logic-then-and-now.html">Logic Then and Now</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
This week I attended the <a href="https://asl2019.commons.gc.cuny.edu/">Association of Symbolic Logic North American Annual Meeting</a> in New York City, giving a talk on P v NP.<br />
<br />
First I must share the announcement that ASL member Tuna Antinel of Lyon 1 University has been arrested in Turkey for his political beliefs. <a href="http://math.univ-lyon1.fr/SoutienTunaAltinel/">This website</a> (<a href="https://webusers.imj-prg.fr/~adrien.deloro/">English version</a>) has details and how to show your support.<br />
<br />
I last attended the ASL annual meeting at Notre Dame in 1993 as a young assistant professor. Back then I talked about <a href="https://doi.org/10.1137/S0097539793248305">then recent work</a> using a special kind of generic oracle to make the Berman-Hartmanis isomorphism conjecture true. I remember someone coming up to me after the talk saying how excited they were to see such applications of logic. I'm not a theoretical computer scientist, I'm a applied logician.<br />
<br />
I asked at my talk this year and maybe 2-3 people were at that 1993 meeting. The attendance seemed smaller and younger, though that could be my memory playing tricks. I heard that the 2018 meeting in Macomb, Illinois drew a larger crowd. New York is expensive and logicians don't get large travel budgets.<br />
<br />
Logic like theoretical computer science has gotten more specialized so I was playing catch up trying to follow many of the talks. Mariya Soskova of Wisconsin talked about enumeration degrees that brought me back to the days I sat in logic classes and talks at the University of Chicago. A set A is enumeration reducible to B if from an enumeration of B you can compute an enumeration of A and Mariya gave a great overview of this area.<br />
<br />
I learned about the status of an open problem for Turing reducibility: Is there a non-trivial automorphism of the Turing Degrees? A degree is the equivalence class where each class are the languages all computably Turing-reducible to each other. So the question asks if there is a bijection f mapping degrees to degrees, other than identity, that preserves reducibility or lack thereof.<br />
<br />
Here's what's known: There are countably many such automorphisms. There is a definable degree C in the arithmetic hierarchy, such that if f(C) = C then f is the identity. Also if f is the identity on all the c.e.-degrees (those equivalence classes containing a computably enumerable set), then f is the identity on all the degrees. Still open if there is more than one automorphism.<br />
<br />
<br /></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/05/logic-then-and-now.html"><span class="datestr">at May 24, 2019 01:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09761">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09761">An Efficient Approach for Super and Nested Term Indexing and Retrieval</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Md Faisal Mahbub Chowdhury, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Farrell:Robert.html">Robert Farrell</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09761">PDF</a><br /><b>Abstract: </b>This paper describes a new approach, called Terminological Bucket Indexing
(TBI), for efficient indexing and retrieval of both nested and super terms
using a single method. We propose a hybrid data structure for facilitating
faster indexing building. An evaluation of our approach with respect to widely
used existing approaches on several publicly available dataset is provided.
Compared to Trie based approaches, TBI provides comparable performance on
nested term retrieval and far superior performance on super term retrieval.
Compared to traditional hash table, TBI needs 80\% less time for indexing.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09761"><span class="datestr">at May 24, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09750">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09750">Approximation schemes for the generalized extensible bin packing problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Asaf.html">Asaf Levin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09750">PDF</a><br /><b>Abstract: </b>We present a new generalization of the extensible bin packing with unequal
bin sizes problem. In our generalization the cost of exceeding the bin size
depends on the index of the bin and not only on the amount in which the size of
the bin is exceeded. This generalization does not satisfy the assumptions on
the cost function that were used to present the existing polynomial time
approximation scheme (PTAS) for the extensible bin packing with unequal bin
sizes problem. In this work, we show the existence of an efficient PTAS (EPTAS)
for this new generalization and thus in particular we improve the earlier PTAS
for the extensible bin packing with unequal bin sizes problem into an EPTAS.
Our new scheme is based on using the shifting technique followed by a solution
of polynomial number of $n$-fold programming instances. In addition, we present
an asymptotic fully polynomial time approximation scheme (AFPTAS) for the
related bin packing type variant of the problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09750"><span class="datestr">at May 24, 2019 11:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09719">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09719">Price of Dependence: Stochastic Submodular Maximization with Dependent Items</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tang:Shaojie.html">Shaojie Tang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09719">PDF</a><br /><b>Abstract: </b>In this paper, we study the stochastic submodular maximization problem with
dependent items subject to a variety of packing constraints such as matroid and
knapsack constraints. The input of our problem is a finite set of items, and
each item is in a particular state from a set of possible states. After picking
an item, we are able to observe its state. We assume a monotone and submodular
utility function over items and states, and our objective is to select a group
of items adaptively so as to maximize the expected utility. Previous studies on
stochastic submodular maximization often assume that items' states are
independent, however, this assumption may not hold in general. This motivates
us to study the stochastic submodular maximization problem with dependent
items. We first introduce the concept of \emph{degree of independence} to
capture the degree to which one item's state is dependent on others'. Then we
propose a non-adaptive policy based on a modified continuous greedy algorithm
and show that its approximation ratio is $\alpha(1 - e^{-\frac{\kappa}{2} +
\frac{\kappa}{18m^2}} - \frac{\kappa + 2}{3m\kappa})$ where the value of
$\alpha$ is depending on the type of constraints, e.g., $\alpha=1$ for matroid
constraint, $\kappa$ is the degree of independence, e.g., $\kappa=1$ for
independent items, and $m$ is the number of items.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09719"><span class="datestr">at May 24, 2019 11:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09656">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09656">On the Average Case of MergeInsertion</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Florian Stober, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei=szlig=:Armin.html">Armin Weiß</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09656">PDF</a><br /><b>Abstract: </b>MergeInsertion, also known as the Ford-Johnson algorithm, is a sorting
algorithm which, up to today, for many input sizes achieves the best known
upper bound on the number of comparisons. Indeed, it gets extremely close to
the information-theoretic lower bound. While the worst-case behavior is well
understood, only little is known about the average case.
</p>
<p>This work takes a closer look at the average case behavior. In particular, we
establish an upper bound of $n \log n - 1.4005n + o(n)$ comparisons. We also
give an exact description of the probability distribution of the length of the
chain a given element is inserted into and use it to approximate the average
number of comparisons numerically. Moreover, we compute the exact average
number of comparisons for $n$ up to 148.
</p>
<p>Furthermore, we experimentally explore the impact of different decision trees
for binary insertion. To conclude, we conduct experiments showing that a
slightly different insertion order leads to a better average case and we
compare the algorithm to the recent combination with (1,2)-Insertionsort by
Iwama and Teruyama.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09656"><span class="datestr">at May 24, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09624">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09624">COBS: a Compact Bit-Sliced Signature Index</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bingmann:Timo.html">Timo Bingmann</a>, Phelim Bradley, Florian Gauger, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iqbal:Zamin.html">Zamin Iqbal</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09624">PDF</a><br /><b>Abstract: </b>We present COBS, a compact bit-sliced signature index, which is a cross-over
between an inverted index and Bloom filters. Our target application is to index
$k$-mers of DNA samples or $q$-grams from text documents and process
approximate pattern matching queries on the corpus with a user-chosen coverage
threshold. Query results may contain a number of false positives which
decreases exponentially with the query length and the false positive rate of
the index determined at construction time. We compare COBS to seven other index
software packages on 100 000 microbial DNA samples. COBS' compact but simple
data structure outperforms the other indexes in construction time and query
performance with Mantis by Pandey et al. on second place. However, different
from Mantis and other previous work, COBS does not need the complete index in
RAM and is thus designed to scale to larger document sets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09624"><span class="datestr">at May 24, 2019 11:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09595">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09595">Non-monotone DR-submodular Maximization: Approximation and Regret Guarantees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=uuml=rr:Christoph.html">Christoph Dürr</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thang:Nguyen_Kim.html">Nguyen Kim Thang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srivastav:Abhinav.html">Abhinav Srivastav</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tible:L=eacute=o.html">Léo Tible</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09595">PDF</a><br /><b>Abstract: </b>Diminishing-returns (DR) submodular optimization is an important field with
many real-world applications in machine learning, economics and communication
systems. It captures a subclass of non-convex optimization that provides both
practical and theoretical guarantees. In this paper, we study the fundamental
problem of maximizing non-monotone DR-submodular functions over down-closed and
general convex sets in both offline and online settings. First, we show that
for offline maximizing non-monotone DR-submodular functions over a general
convex set, the Frank-Wolfe algorithm achieves an approximation guarantee which
depends on the convex set. Next, we show that the Stochastic Gradient Ascent
algorithm achieves a 1/4-approximation ratio with the regret of $O(1/\sqrt{T})$
for the problem of maximizing non-monotone DR-submodular functions over
down-closed convex sets. These are the first approximation guarantees in the
corresponding settings. Finally we benchmark these algorithms on problems
arising in machine learning domain with the real-world datasets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09595"><span class="datestr">at May 24, 2019 11:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09505">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09505">Graph Searches and Their End Vertices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cao:Yixin.html">Yixin Cao</a>, Guozhen Rong, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jianxin.html">Jianxin Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Zhifeng.html">Zhifeng Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09505">PDF</a><br /><b>Abstract: </b>Graph search, the process of visiting vertices in a graph in a specific
order, has demonstrated magical powers in many important algorithms. But a
systematic study was only initiated by Corneil et al.~a decade ago, and only by
then we started to realize how little we understand it. Even the apparently
na\"{i}ve question "which vertex can be the last visited by a graph search
algorithm," known as the end vertex problem, turns out to be quite elusive. We
give a full picture of all maximum cardinality searches on chordal graphs,
which implies a polynomial-time algorithm for the end vertex problem of maximum
cardinality search. It is complemented by a proof of NP-completeness of the
same problem on weakly chordal graphs.
</p>
<p>We also show linear-time algorithms for deciding end vertices of
breadth-first searches on interval graphs, and end vertices of lexicographic
depth-first searches on chordal graphs. Finally, we present $2^n\cdot
n^{O(1)}$-time algorithms for deciding the end vertices of breadth-first
searches, depth-first searches, maximum cardinality searches, and maximum
neighborhood searches on general graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09505"><span class="datestr">at May 24, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09434">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09434">Automated Process Planning for Turning: A Feature-Free Approach</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Behandish:Morad.html">Morad Behandish</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nelaturi:Saigopal.html">Saigopal Nelaturi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verma:Chaman_Singh.html">Chaman Singh Verma</a>, Mats Allard <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09434">PDF</a><br /><b>Abstract: </b>Turning is the most commonly available and least expensive machining
operation, in terms of both machine-hour rates and tool insert prices. A
practical CNC process planner has to maximize the utilization of turning, not
only to attain precision requirements for turnable surfaces, but also to
minimize the machining cost, while non-turnable features can be left for other
processes such as milling. Most existing methods rely on separation of surface
features and lack guarantees when analyzing complex parts with interacting
features. In a previous study, we demonstrated successful implementation of a
feature-free milling process planner based on configuration space methods used
for spatial reasoning and AI search for planning. This paper extends the
feature-free method to include turning process planning. It opens up the
opportunity for seamless integration of turning actions into a mill-turn
process planner that can handle arbitrarily complex shapes with or without a
priori knowledge of feature semantics.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09434"><span class="datestr">at May 24, 2019 11:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09401">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09401">Optimum Low-Complexity Decoder for Spatial Modulation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Al=Nahhal:Ibrahim.html">Ibrahim Al-Nahhal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basar:Ertugrul.html">Ertugrul Basar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dobre:Octavia_A=.html">Octavia A. Dobre</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ikki:Salama.html">Salama Ikki</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09401">PDF</a><br /><b>Abstract: </b>In this paper, a novel low-complexity detection algorithm for spatial
modulation (SM), referred to as the minimum-distance of maximum-length (m-M)
algorithm, is proposed and analyzed. The proposed m-M algorithm is a smart
searching method that is applied for the SM tree-search decoders. The behavior
of the m-M algorithm is studied for three different scenarios: i) perfect
channel state information at the receiver side (CSIR), ii) imperfect CSIR of a
fixed channel estimation error variance, and iii) imperfect CSIR of a variable
channel estimation error variance. Moreover, the complexity of the m-M
algorithm is considered as a random variable, which is carefully analyzed for
all scenarios, using probabilistic tools. Based on a combination of the sphere
decoder (SD) and ordering concepts, the m-M algorithm guarantees to find the
maximum-likelihood (ML) solution with a significant reduction in the decoding
complexity compared to SM-ML and existing SM-SD algorithms; it can reduce the
complexity up to 94% and 85% in the perfect CSIR and the worst scenario of
imperfect CSIR, respectively, compared to the SM-ML decoder. Monte Carlo
simulation results are provided to support our findings as well as the derived
analytical complexity reduction expressions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09401"><span class="datestr">at May 24, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09356">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09356">Convergence Analyses of Online ADAM Algorithm in Convex Setting and Two-Layer ReLU Neural Network</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fang:Biyi.html">Biyi Fang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klabjan:Diego.html">Diego Klabjan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09356">PDF</a><br /><b>Abstract: </b>Nowadays, online learning is an appealing learning paradigm, which is of
great interest in practice due to the recent emergence of large scale
applications such as online advertising placement and online web ranking.
Standard online learning assumes a finite number of samples while in practice
data is streamed infinitely. In such a setting gradient descent with a
diminishing learning rate does not work. We first introduce regret with rolling
window, a new performance metric for online streaming learning, which measures
the performance of an algorithm on every fixed number of contiguous samples. At
the same time, we propose a family of algorithms based on gradient descent with
a constant or adaptive learning rate and provide very technical analyses
establishing regret bound properties of the algorithms. We cover the convex
setting showing the regret of the order of the square root of the size of the
window in the constant and dynamic learning rate scenarios. Our proof is
applicable also to the standard online setting where we provide the first
analysis of the same regret order (the previous proofs have flaws). We also
study a two layer neural network setting with ReLU activation. In this case we
establish that if initial weights are close to a stationary point, the same
square root regret bound is attainable. We conduct computational experiments
demonstrating a superior performance of the proposed algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09356"><span class="datestr">at May 24, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1905.09320">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1905.09320">Solving Random Systems of Quadratic Equations with Tanh Wirtinger Flow</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Zhenwei Luo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Ye.html">Ye Zhang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1905.09320">PDF</a><br /><b>Abstract: </b>Solving quadratic systems of equations in n variables and m measurements of
the form $y_i = |a^T_i x|^2$ , $i = 1, ..., m$ and $x \in R^n$ , which is also
known as phase retrieval, is a hard nonconvex problem. In the case of standard
Gaussian measurement vectors, the wirtinger flow algorithm Chen and Candes
(2015) is an efficient solution. In this paper, we proposed a new form of
wirtinger flow and a new spectral initialization method based on this new
algorithm. We proved that the new wirtinger flow and initialization method
achieve linear sample and computational complexities. We further extended the
new phasing algorithm by combining it with other existing methods. Finally, we
demonstrated the effectiveness of our new method in the low data to parameter
ratio settings where the number of measurements which is less than
information-theoretic limit, namely, $m &lt; 2n$, via numerical tests. For
instance, our method can solve the quadratic systems of equations with gaussian
measurement vector with probability $\ge 97\%$ when $m/n = 1.7$ and $n = 1000$,
and with probability $\approx 60\%$ when $m/n = 1.5$ and $n = 1000$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1905.09320"><span class="datestr">at May 24, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=355">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/05/22/tcs-talk-wednesday-may-29th-lior-kamma-aarhus-university/">TCS+ talk: Wednesday, May 29th — Lior Kamma, Aarhus University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, May 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 19:00 Central European Summer Time, 17:00 UTC). <strong>Lior Kamma</strong> from Aarhus University will speak about “<em>Lower Bounds for Multiplication via Network Coding</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Multiplication is one of the most fundamental computational problems, yet its true complexity remains elusive. The best known upper bound, very recently proved by Harvey and Van Der Hoven shows that two <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" alt="n" class="latex" title="n" />-bit numbers can be multiplied via a boolean circuit of size <img src="https://s0.wp.com/latex.php?latex=O%28n+%5Clg+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(n \lg n)" class="latex" title="O(n \lg n)" />.</p>
<p>We prove that if a central conjecture in the area of network coding is true, then any constant degree Boolean circuit for multiplication must have size <img src="https://s0.wp.com/latex.php?latex=%5COmega%28n+%5Clg+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\Omega(n \lg n)" class="latex" title="\Omega(n \lg n)" />, thus (conditioned on the conjecture) completely settling the complexity of multiplication circuits. We additionally revisit classic conjectures in circuit complexity, due to Valiant, and show that the network coding conjecture also implies one of Valiant’s conjectures.</p>
<p>Joint work with Peyman Afshani, Casper Freksen and Kasper Green Larsen</p></blockquote>
<p><span id="more-355"></span></p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/05/22/tcs-talk-wednesday-may-29th-lior-kamma-aarhus-university/"><span class="datestr">at May 22, 2019 08:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=639">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/05/22/statement-of-concern-regarding-marijuana-in-massachusetts/">Statement of concern regarding Marijuana in Massachusetts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>You can read it <a href="https://gallery.mailchimp.com/d93a0b5fcff1daf7b38ecd20c/files/4a4118a7-45ed-4910-b3d1-c64a5e822417/MA_MJ_Policy_Statement_of_Concern_5_9_19_FINAL.pdf">here</a>. If you don’t want to click, some key takeaways are:</p>
<ul>
<li><span class="fontstyle0">We disagree with how marijuana policy is being shaped in the Commonwealth.</span></li>
<li><span class="fontstyle0">The science is clear; marijuana, specifically the psychoactive chemical THC (delta-9-tetrahydrocannabinol), has the potential to do significant harm to public health.</span></li>
<li><span class="fontstyle0">Diversion of high THC products (≥10%), vapes and edibles, to MA youth is a growing concern.</span></li>
<li><span class="fontstyle0">When public health is not prioritized in the regulation of addictive substances, the public and our young people are put at risk.</span></li>
</ul>
<p>You can also find in the statement a list of negative effects of THC.  This is all signed by a dozen+ doctors. The various marijuana players with zero medical knowledge will probably dismiss the experts’ opinion with, at best, a shrug. Instead, they are looking into opening <a href="https://www.boston.com/news/local-news/2019/05/16/massachusetts-marijuana-cafes-social-consumption">marijuana cafes</a>. And the first marijuana retail store will open in Newton <a href="https://patch.com/massachusetts/newton/newtons-first-recreational-marijuana-shop-has-grand-opening-date">this Saturday</a>.</p>
<p>If you want to get even more worked up about marijuana reading my <a href="https://emanueleviola.wordpress.com/2019/01/27/selling-your-town-to-the-marijuana-industry/">previous post</a> might help.</p>
<p>Finally, <a href="http://www.mapreventionalliance.org/">on June 5^th there will be a luncheon event at the JFK Library titled: Marijuana: Addiction, Mental Health and Policy – Advances in Research…What have we learned in the past 5 years?</a></p></div>







<p class="date">
by Emanuele <a href="https://emanueleviola.wordpress.com/2019/05/22/statement-of-concern-regarding-marijuana-in-massachusetts/"><span class="datestr">at May 22, 2019 07:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/074">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/074">TR19-074 |  Finding a Nash Equilibrium Is No Easier Than Breaking Fiat-Shamir | 

	Chethan Kamath, 

	Arka Rai Choudhuri, 

	Pavel Hubacek, 

	Krzysztof Pietrzak, 

	Alon Rosen, 

	Guy Rothblum</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The Fiat-Shamir heuristic transforms a public-coin interactive proof into a non-interactive argument, by replacing the verifier with a cryptographic hash function that is applied to the protocol’s transcript. Constructing hash functions for which this transformation is sound is a central and long-standing open question in cryptography.

We show that solving the End-of-Metered-Line problem is no easier than breaking the soundness of the Fiat-Shamir transformation when applied to the sumcheck protocol. In particular, if the transformed protocol is sound, then any hard problem in #P gives rise to a hard distribution in the class CLS, which is contained in PPAD.

Our main technical contribution is a stateful incrementally verifiable procedure that, given a SAT instance over n variables, counts the number of satisfying assignments. This is accomplished via an exponential sequence of small steps, each computable in time poly(n). Incremental verifiability means that each intermediate state includes a sumcheck-based proof of its correctness, and the proof can be updated and verified in time poly(n).

Combining our construction with a hash family proposed by Canetti et al. [STOC 2019] gives rise to a distribution in the class CLS, which is provably hard under the assumption that any one of a class of fully homomorphic encryption (FHE) schemes has almost-optimal security against quasi-polynomial time adversaries, and under the additional worst-case assumption that there is no polynomial time algorithm for counting the number of satisfying assignments for formulas over a polylogarithmic number of variables.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/074"><span class="datestr">at May 22, 2019 06:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/05/21/congratulations-dr-tillman">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/05/21/congratulations-dr-tillman.html">Congratulations, Dr. Tillman!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Today I participated in the successful dissertation defense of Bálint Tillman, a student of Athina Markopoulou in the <a href="http://www.networkedsystems.uci.edu/">UCI Graduate Program in Networked Systems</a>.</p>

<p>Bálint has been investigating problems connected with the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Gallai_theorem">Erdős–Gallai theorem</a>, which states that it is possible to test whether a sequence of numbers is the degree distribution of a graph (the sequence of numbers of vertices of each possible degree) and if so, find a graph with that degree distribution, in polynomial time. The degree distribution can be extended to a matrix called the <em>joint degree distribution</em>, which specifies the number of pairs of adjacent vertices with each combination of degrees, and to higher-order tensors specifying the degrees of subgraphs with more than two vertices.</p>

<p>In his INFOCOM 2015 paper “<a href="https://doi.org/10.1109/INFOCOM.2015.7218534">Construction of simple graphs with a target joint degree matrix and beyond</a>”, Bálint showed that one can recognize the joint degree distributions of simple graphs, and reconstruct a graph with that distribution, in polynomial time. The algorithm works equally well when the vertices are distinguished in other ways than by degree and the input matrix specifies the target number of edges with each pair of degrees between each class of vertices. Later, in KDD 2017, he extended these results to directed graphs and at NetSci 2018 he showed how to find a realization with as few connected components as possible.</p>

<p>On the other hand, if one adds only a little bit of extra information to the joint degree distribution, such as the total number of triangles in the graph, it becomes NP-complete to recognize whether the input describes a valid graph and NP-hard to reconstruct a graph that realizes a given description. This comes from a poster by Bálint with Will Devanny and me at NetSci 2016, where we found the reduction from graph 3-coloring depicted below.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/jdm-tri-hard.svg" alt="NP-completeness reduction from 3-coloring to realizability of joint degree matrices with numbers of triangles" /></p>

<p>To perform an NP-hardness reduction, one should start with a graph for which it’s hard to test 3-colorability, and translate it into an instance of whatever other problem you want to prove hard. But instead let’s pretend for now that we start with a little more information: a graph that’s known to be 3-colorable, and a specific 3-coloring of it.
To turn this into a hard problem for realizability of joint distribution plus number of triangles, we add a triangle to the graph, representing the three colors, and connect each original graph vertex to the new triangle vertex for its color. Then we add enough hair (in the form of degree-one vertices) to the augmented graph to make all vertices have distinct degrees, except within the triangle of new vertices where all three degrees should be the same. Now take as the result of the reduction the pair  of the joint degree distribution and number of triangles in the augmented graph.</p>

<p>But now the trick is that  can be computed directly from your starting graph, without knowing its coloring or even whether it is colorable.
Because the degrees are distinct, and  tells you the number of edges for each combination of degrees, any realization of  must contain a copy of your starting graph augmented by a triangle. The graph and the triangle might be connected to each other differently than they were before, but their connection pattern must still correspond to a different valid 3-coloring, because otherwise you would form some extra triangles in the graph (one for each invalidly-colored edge) and not correctly match the value of . So  is realizable if and only if your starting graph has a 3-coloring. This reduction proves that testing realizability of pairs  is NP-complete.</p>

<p>There’s even more material along these lines in Bálint’s dissertation, but some of it is not yet published. I think the plan is to get all of that submitted over the summer before
Bálint starts a new position at Google.
Congratulations, Bálint!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102137081740561085">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/05/21/congratulations-dr-tillman.html"><span class="datestr">at May 21, 2019 06:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15894">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/05/21/making-up-tests/">Making Up Tests</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>It’s harder to make up tests than to take them</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/05/21/making-up-tests/ken/" rel="attachment wp-att-15897"><img width="150" alt="" class="alignright  wp-image-15897" src="https://rjlipton.files.wordpress.com/2019/05/ken.png?w=150" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Recent photo ]</font></td>
</tr>
</tbody>
</table>
<p>
Ken Regan has been busy these last few days working on making a final exam, giving the exam, and now grading the exam. </p>
<p>
Today Ken and I want to talk about tests.</p>
<p>
I also have a test for you. You can jump right to our test of knowledge. Do not, please, use any search tools, especially Google.<span id="more-15894"></span></p>
<p>
</p><p></p><h2> Test Theory </h2><p></p>
<p></p><p>
Ken recently made up a final exam. We both have had to make countless tests over the years. I was never trained in how to make a good test. Nor how to make a test at all. I am still puzzled about how to do it.</p>
<p>
Avi Wigderson once told me that Michael Rabin only asked questions on his exams that he had stated already in lectures. Is there a theory of what makes a proper test? I do not know any.</p>
<p>
Suppose that before the exam we lectured and the students learned <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />: Here <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> are true statements and <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> are false statements. A rote type question might be: </p>
<blockquote><p><b> </b> <em> <i>Is the statement <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> true or false?</i> </em>
</p></blockquote>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> would be in either <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />. This type of question is purely a memory problem. </p>
<p>
A more difficult test would have questions like: </p>
<blockquote><p><b> </b> <em> <i>Is <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> true or false</i> </em>
</p></blockquote>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> would be equivalent to some <img src="https://s0.wp.com/latex.php?latex=%7BS%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S'}" class="latex" title="{S'}" /> that is in <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> or in <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />. The equivalence between <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BS%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S'}" class="latex" title="{S'}" /> would require only the application of a few simple logical rules. This is much harder for students. In the limit we could have <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BS%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S'}" class="latex" title="{S'}" /> far apart, even could have it an open problem if <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BS%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S'}" class="latex" title="{S'}" /> are equivalent. </p>
<p>
</p><p></p><h2> Our Test </h2><p></p>
<p></p><p>
<b>No looking at Google please.</b></p>
<p>
<i>Question 1</i>: We all know that Dick Karp created the P=NP question. What is Dick’s middle name? </p>
<ol>
<li>
Mark<p></p>
<p></p></li><li>
Manning <p></p>
</li><li>
Mathew <p></p>
</li><li>
Richard
</li></ol>
<p>
<i>Question 2</i>: This year is the fifty-first anniversary of STOC. Where was the first one held? </p>
<ol>
<li>
Marina del Rey, CA <p></p>
</li><li>
Massapequa, NY <p></p>
</li><li>
Boston, MA <p></p>
</li><li>
Chicago, IL
</li></ol>
<p>
<i>Question 3</i>: Which of these did <b>not</b> happen in 1969? </p>
<ol>
<li>
The first automatic teller machine in the United States is installed. <p></p>
</li><li>
The $500 bills are officially removed from circulation. <p></p>
</li><li>
The first The Limited store opens, in San Francisco. <p></p>
</li><li>
The New York Mets win the World Series.
</li></ol>
<p>
<i>Question 4</i>: The first STOC conference program committee included: </p>
<ol>
<li>
No women. <p></p>
</li><li>
A person named Mike. <p></p>
</li><li>
A person named Pat. <p></p>
</li><li>
All the above.
</li></ol>
<p>
<i>Question 5</i>: How do you tell if you are a “theoretical computer scientist”? </p>
<ol>
<li>
You wear flip-flops in the winter. <p></p>
</li><li>
You regularly attend STOC. <p></p>
</li><li>
You wear glasses. <p></p>
</li><li>
You cannot program a computer.
</li></ol>
<p>
<i>Question 6</i>: “Cooking” a chess problem means: </p>
<ol>
<li>
Showing it is in a family of NP-complete problems on <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \times n}" class="latex" title="{n \times n}" /> boards. <p></p>
</li><li>
Showing it has two or more solutions (or no solutions). <p></p>
</li><li>
Showing it cannot be solved by Steve Cook. <p></p>
</li><li>
Showing that it cannot be solved by the best-move strategy.
</li></ol>
<p>
<i>Question 7</i>: The other theory conference is called FOCS. Which of these is true about this conference: </p>
<ol>
<li>
The name was selected by a person named Edward. <p></p>
</li><li>
It has never had parallel sessions. <p></p>
</li><li>
It was originally called Symposium on Switching Circuit Theory and Logical Design. <p></p>
</li><li>
The artwork for the proceedings cover is by an artist named Smith, who never published in the conference.
</li></ol>
<p>
<i>Question 8</i>: What do the STOC conferences have in common with last night’s final episode of <i>Game of Thrones</i>? </p>
<ol>
<li>
Both had flying horses and whistling pigs. <p></p>
</li><li>
No dragons were harmed during either. <p></p>
</li><li>
Both have left many big questions unanswered. <p></p>
</li><li>
Both are explained by the “Prisoner’s Dilemma” game solution.
</li></ol>
<p>
<i>Question 9</i>: STOC has been held on each of these islands except: </p>
<ol>
<li>
Long Island, NY. <p></p>
</li><li>
Puerto Rico. <p></p>
</li><li>
Crete. <p></p>
</li><li>
Vancouver Island.
</li></ol>
<p>
<i>Question 10</i>: What term appears in the titles of three award-winning STOC/FOCS papers since 2016? </p>
<ol>
<li>
Quantum. <p></p>
</li><li>
Quadratic/subquadratic. <p></p>
</li><li>
Quadtree. <p></p>
</li><li>
Quasi/quasipolynomial.
</li></ol>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Answers: Note 1a means question 1 and answer 1 and so on. This is a wordpress issue.</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/05/21/making-up-tests/answers4/" rel="attachment wp-att-15899"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2019/05/answers4.png?w=300&amp;h=47" class="aligncenter size-medium wp-image-15899" height="47" /></a></p>
<p></p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/05/21/making-up-tests/"><span class="datestr">at May 21, 2019 12:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4249">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/05/20/online-optimization-post-5-bregman-projections-and-mirror-descent/">Online Optimization Post 5: Bregman Projections and Mirror Descent</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
 In this post we return to the generic form of the FTRL online optimization algorithm. If the cost functions are linear, as they will be in all the applications that I plan to talk about, the algorithm is:</p>
<p>
<a name="eq.ftrl.def"></a></p><a name="eq.ftrl.def">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++x_t+%3A%3D+%5Carg%5Cmin_%7Bx%5Cin+K%7D+%5C+R%28x%29+%2B+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Clangle+%5Cell_k%2C+x+%5Crangle+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   x_t := \arg\min_{x\in K} \ R(x) + \sum_{k=1}^{t-1} \langle \ell_k, x \rangle \ \ \ \ \ (1)" class="latex" title="\displaystyle   x_t := \arg\min_{x\in K} \ R(x) + \sum_{k=1}^{t-1} \langle \ell_k, x \rangle \ \ \ \ \ (1)" /></p>
</a><p><a name="eq.ftrl.def"></a> where <img src="https://s0.wp.com/latex.php?latex=%7BK%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K\subseteq {\mathbb R}^n}" class="latex" title="{K\subseteq {\mathbb R}^n}" /> is the convex set of feasible solutions that the algorithm is allowed to produce, <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+%5Clangle+%5Cell_k+%2C+x+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \rightarrow \langle \ell_k , x \rangle}" class="latex" title="{x \rightarrow \langle \ell_k , x \rangle}" /> is the linear loss function at time <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BR%3A+K+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R: K \rightarrow {\mathbb R}}" class="latex" title="{R: K \rightarrow {\mathbb R}}" /> is the strictly convex regularizer.</p>
<p>
If we have an unconstrained problem, that is, if <img src="https://s0.wp.com/latex.php?latex=%7BK%3D+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K= {\mathbb R}^n}" class="latex" title="{K= {\mathbb R}^n}" />, then the optimization problem <a href="https://lucatrevisan.wordpress.com/feed/#eq.ftrl.def">(1)</a> has a unique solution: the <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28x_t%29+%3D+-+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k " class="latex" title="\displaystyle  \nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k " /></p>
<p> and we can usually both compute <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> efficiently in an algorithm and reason about <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> effectively in an analysis.</p>
<p>
Unfortunately, we are almost always interested in constrained settings, and then it becomes difficult both to compute <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> and to reason about it.</p>
<p>
A very nice special case happens when the regularizer <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> acts as a <em>barrier function</em> for <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />, that is, the (norm of the) gradient of <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> goes to infinity when one approaches the boundary of <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />. In such a case, it is impossible for the minimum of <a href="https://lucatrevisan.wordpress.com/feed/#eq.ftrl.def">(1)</a> to occur at the boundary and the solution will be again the unique <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28x_t%29+%3D+-+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k " class="latex" title="\displaystyle  \nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k " /></p>
<p>
We swept this point under the rug when we studied FTRL with negative-entropy regularizer in the settings of experts, in which <img src="https://s0.wp.com/latex.php?latex=%7BK+%3D+%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K = \Delta}" class="latex" title="{K = \Delta}" /> is the set of probability distributions. When we proceeded to solve <a href="https://lucatrevisan.wordpress.com/feed/#eq.ftrl.def">(1)</a> using Lagrange multipliers, we ignored the non-negativity constraints. The reason why it was ok to do so was that the negative-entropy is a barrier function for the non-negative orthant <img src="https://s0.wp.com/latex.php?latex=%7B%28%7B%5Cmathbb+R%7D_%7B%5Cgeq+0%7D%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{({\mathbb R}_{\geq 0})^n}" class="latex" title="{({\mathbb R}_{\geq 0})^n}" />.</p>
<p>
Another important special case occurs when the regularizer <img src="https://s0.wp.com/latex.php?latex=%7BR%28x%29+%3D+c+%7C%7C+x%7C%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(x) = c || x||^2}" class="latex" title="{R(x) = c || x||^2}" /> is a multiple of length-squared. In this case, we saw that we could “decouple” the optimization problem by first solving the unconstrained optimization problem, and then projecting the solution of the unconstrained problem to <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+y_%7Bt%7D+%3D+%5Carg%5Cmin_%7By%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+c+%7C%7C+y%7C%7C%5E2+%2B+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Clangle+%5Cell_k%2C+y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle y_{t} = \arg\min_{y\in {\mathbb R}^n} \ c || y||^2 + \sum_{k=1}^{t-1} \langle \ell_k, y \rangle " class="latex" title="\displaystyle y_{t} = \arg\min_{y\in {\mathbb R}^n} \ c || y||^2 + \sum_{k=1}^{t-1} \langle \ell_k, y \rangle " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5CPi_K+%28y_t%29+%3D+%5Carg%5Cmin+_%7Bx%5Cin+K%7D+%7C%7C+x+-+y_t+%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \Pi_K (y_t) = \arg\min _{x\in K} || x - y_t || " class="latex" title="\displaystyle  x_t = \Pi_K (y_t) = \arg\min _{x\in K} || x - y_t || " /></p>
<p> Then we have the closed-form solution <img src="https://s0.wp.com/latex.php?latex=%7By_t+%3D+-+%5Cfrac+1%7B2c%7D+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell+_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_t = - \frac 1{2c} \sum_{k=1}^{t-1} \ell _k}" class="latex" title="{y_t = - \frac 1{2c} \sum_{k=1}^{t-1} \ell _k}" /> and, depending on the set <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />, the projection might also have a nice closed-form, as in the case <img src="https://s0.wp.com/latex.php?latex=%7BK%3D+%5B0%2C1%5D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K= [0,1]^n}" class="latex" title="{K= [0,1]^n}" /> that comes up in results related to regularity lemmas.</p>
<p>
As we will see today, this approach of solving the unconstrained problem and then projecting on <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> works for every regularizer, for an appropriate notion of projection called the <em>Bregman projection</em> (the projection will depend on the regularizer). </p>
<p>
To define the Bregman projection, we will first define the <em>Bregman divergence</em> with respect to the regularizer <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />, which is a non-negative “distance” <img src="https://s0.wp.com/latex.php?latex=%7BD%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D(x,y)}" class="latex" title="{D(x,y)}" /> defined on <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n}" class="latex" title="{{\mathbb R}^n}" /> (or possibly a subset of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n}" class="latex" title="{{\mathbb R}^n}" /> for which the regularizer <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> is a barrier function). Then, the Bregman projection of <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> on <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> is defined as <img src="https://s0.wp.com/latex.php?latex=%7B%5Carg%5Cmin_%7Bx%5Cin+K%7D+%5C+D%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\arg\min_{x\in K} \ D(x,y)}" class="latex" title="{\arg\min_{x\in K} \ D(x,y)}" />.</p>
<p>
Unfortunately, it is not so easy to reason about Bregman projections either, but the notion of Bregman divergence offers a way to reinterpret the FTRL algorithm from another point of view, called <em>mirror descent</em>. Via this reinterpretation, we will prove the regret bound </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T%28x%29+%5Cleq+D%28x%2Cx_1%29+%2B+%5Csum_%7Bt%3D1%7D%5ET+D%28x_t%2Cy_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  {\rm Regret}_T(x) \leq D(x,x_1) + \sum_{t=1}^T D(x_t,y_{t+1}) " class="latex" title="\displaystyle  {\rm Regret}_T(x) \leq D(x,x_1) + \sum_{t=1}^T D(x_t,y_{t+1}) " /></p>
<p> which carries the intuition that the regret comes from a combination of the “distance” of our initial solution from the offline optimum and of the “stability” of the algorithm, that is, the “distance” between consecutive soltuions. Nicely, the above bound measures both quantities using the same “distance” function.</p>
<p>
<span id="more-4249"></span> </p>
<p>
</p><p><b>1. Bregman Divergence and Bregman Projection </b></p>
<p></p><p>
For a strictly convex function <img src="https://s0.wp.com/latex.php?latex=%7BR%3A+%7B%5Cmathbb+R%7D%5En+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R: {\mathbb R}^n \rightarrow {\mathbb R}}" class="latex" title="{R: {\mathbb R}^n \rightarrow {\mathbb R}}" />, we define the <em>Bregman divergence</em> associated to <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> as </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D_R%28x%2Cy%29+%3A%3D+R%28x%29+-+R%28y%29+-+%5Clangle+%5Cnabla+R%28y%29%2C+x-y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D_R(x,y) := R(x) - R(y) - \langle \nabla R(y), x-y \rangle " class="latex" title="\displaystyle  D_R(x,y) := R(x) - R(y) - \langle \nabla R(y), x-y \rangle " /></p>
<p> that is, the difference between the value of <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> at <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and the value of the linear approximation of <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> at <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> (centered at <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />). By the strict convexity of <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> we have <img src="https://s0.wp.com/latex.php?latex=%7BD_R%28x%2Cy%29+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_R(x,y) \geq 0}" class="latex" title="{D_R(x,y) \geq 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD_R%28x%2Cy%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_R(x,y) = 0}" class="latex" title="{D_R(x,y) = 0}" /> iff <img src="https://s0.wp.com/latex.php?latex=%7Bx%3Dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x=y}" class="latex" title="{x=y}" />. These properties suggest that we may think of <img src="https://s0.wp.com/latex.php?latex=%7BD_R%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_R(x,y)}" class="latex" title="{D_R(x,y)}" /> as a kind of “distance” between <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, which is a useful intuition although it is important to keep in mind that the divergence need not be symmetric and need not satisfy the triangle inequality.</p>
<p>
Now we show that, assuming that <img src="https://s0.wp.com/latex.php?latex=%7BR%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(\cdot)}" class="latex" title="{R(\cdot)}" /> is well defined and strictly convex on all <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n}" class="latex" title="{{\mathbb R}^n}" />, and that the losses are linear, the constrained optimization problem <a href="https://lucatrevisan.wordpress.com/feed/#eq.ftrl.def">(1)</a> can be solved by first solving the unconstrained problem and then “projecting” the solution on <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> by finding the point in <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> of smallest Bregman divergence from the unconstrained optimum:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_t+%3D+%5Carg%5Cmin+_%7By%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+R%28y%29+%2B+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Clangle+%5Cell_k+%2C+y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y_t = \arg\min _{y\in {\mathbb R}^n} \ R(y) + \sum_{k=1}^{t-1} \langle \ell_k , y \rangle " class="latex" title="\displaystyle  y_t = \arg\min _{y\in {\mathbb R}^n} \ R(y) + \sum_{k=1}^{t-1} \langle \ell_k , y \rangle " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5Carg%5Cmin_%7Bx+%5Cin+K%7D+%5C+D_R%28x%2Cy_t%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \arg\min_{x \in K} \ D_R(x,y_t) " class="latex" title="\displaystyle  x_t = \arg\min_{x \in K} \ D_R(x,y_t) " /></p>
<p> The proof is very simple. The optimum of the unconstrained optimization problem is the unique <img src="https://s0.wp.com/latex.php?latex=%7By_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_t}" class="latex" title="{y_t}" /> such that</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+%5Cleft%28+R%28y_t%29+%2B+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k+%5Cright%29+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla \left( R(y_t) + \sum_{k=1}^{t-1} \ell_k \right) = 0 " class="latex" title="\displaystyle  \nabla \left( R(y_t) + \sum_{k=1}^{t-1} \ell_k \right) = 0 " /></p>
<p> that is, the unique <img src="https://s0.wp.com/latex.php?latex=%7By_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_t}" class="latex" title="{y_t}" /> such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28y_t%29+%3D+-+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(y_t) = - \sum_{k=1}^{t-1} \ell_k " class="latex" title="\displaystyle  \nabla R(y_t) = - \sum_{k=1}^{t-1} \ell_k " /></p>
<p> On the other hand, <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> is defined as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5Carg%5Cmin_%7Bx+%5Cin+K%7D+%5C+D_R%28x%2Cy_t%29+%3D+%5Carg%5Cmin_%7Bx+%5Cin+K%7D+R%28x%29+-+R%28y_t%29+-+%5Clangle+%5Cnabla+R%28y_t%29+%2C+x+-+y_t+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \arg\min_{x \in K} \ D_R(x,y_t) = \arg\min_{x \in K} R(x) - R(y_t) - \langle \nabla R(y_t) , x - y_t \rangle " class="latex" title="\displaystyle  x_t = \arg\min_{x \in K} \ D_R(x,y_t) = \arg\min_{x \in K} R(x) - R(y_t) - \langle \nabla R(y_t) , x - y_t \rangle " /></p>
<p> that is, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5Carg%5Cmin_%7Bx+%5Cin+K%7D+R%28x%29+-+R%28y_t%29+%2B+%5Clangle+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k+%2C+x+-+y_t+%5Crangle+%3D+%5Carg%5Cmin_%7Bx+%5Cin+K%7D+R%28x%29+%2B+%5Clangle+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k+%2C+x+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \arg\min_{x \in K} R(x) - R(y_t) + \langle \sum_{k=1}^{t-1} \ell_k , x - y_t \rangle = \arg\min_{x \in K} R(x) + \langle \sum_{k=1}^{t-1} \ell_k , x \rangle " class="latex" title="\displaystyle  x_t = \arg\min_{x \in K} R(x) - R(y_t) + \langle \sum_{k=1}^{t-1} \ell_k , x - y_t \rangle = \arg\min_{x \in K} R(x) + \langle \sum_{k=1}^{t-1} \ell_k , x \rangle " /></p>
<p> where the second equality above follows from the fact that two functions that differ by a constant have the same optimal solutions.</p>
<p>
Indeed we see that the above “decoupled” characterization of the FTRL algorithm would have worked for any definition of a function of the form</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28x%2Cy%29+%3D+R%28x%29+-+%5Clangle+%5Cnabla+R%28y%29%2C+x+%5Crangle+%2B+%5Clangle+%5Cmbox%7B+stuff+that+depends+only+on+%7D+y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D(x,y) = R(x) - \langle \nabla R(y), x \rangle + \langle \mbox{ stuff that depends only on } y \rangle " class="latex" title="\displaystyle  D(x,y) = R(x) - \langle \nabla R(y), x \rangle + \langle \mbox{ stuff that depends only on } y \rangle " /></p>
<p> and that our particular choice of what “stuff dependent only on <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />” to add makes <img src="https://s0.wp.com/latex.php?latex=%7BD%28x%2Cx%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D(x,x) = 0}" class="latex" title="{D(x,x) = 0}" /> which is reasonable for something that we want to think of as a “distance function.”</p>
<p>
Note that, in all of the above, we can replace <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n}" class="latex" title="{{\mathbb R}^n}" /> with a convex set <img src="https://s0.wp.com/latex.php?latex=%7BK+%5Csubseteq+S+%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K \subseteq S \subseteq {\mathbb R}^n}" class="latex" title="{K \subseteq S \subseteq {\mathbb R}^n}" /> provided that <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> is a barrier function for <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. In that case</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_t+%3D+%5Carg%5Cmin_%7By%5Cin+S%7D+R%28y%29+%2B+%5Csum_k+%5Cell_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y_t = \arg\min_{y\in S} R(y) + \sum_k \ell_k " class="latex" title="\displaystyle  y_t = \arg\min_{y\in S} R(y) + \sum_k \ell_k " /></p>
<p> is the unique <img src="https://s0.wp.com/latex.php?latex=%7By_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_t}" class="latex" title="{y_t}" /> such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28y_t%29+%3D+-+%5Csum+_k+%5Cell_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(y_t) = - \sum _k \ell_k " class="latex" title="\displaystyle  \nabla R(y_t) = - \sum _k \ell_k " /></p>
<p> and everything else follows analogously.</p>
<p>
</p><p><b>2. Examples </b></p>
<p>
</p><p><b>  2.1. Bregman Divergence of Length-Squared </b></p>
<p></p><p>
If <img src="https://s0.wp.com/latex.php?latex=%7BR%28x%29+%3D+%7C%7Cx+%7C%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(x) = ||x ||^2}" class="latex" title="{R(x) = ||x ||^2}" />, then </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28x%2Cy%29+%3D+%7C%7Cx%7C%7C%5E2+-+%7C%7Cy%7C%7C%5E2+-+%5Clangle+2+y+%2C+x-+y+%5Crangle+%3D+%7C%7Cx+-+y%7C%7C%5E2+%5C+%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D(x,y) = ||x||^2 - ||y||^2 - \langle 2 y , x- y \rangle = ||x - y||^2 \ , " class="latex" title="\displaystyle  D(x,y) = ||x||^2 - ||y||^2 - \langle 2 y , x- y \rangle = ||x - y||^2 \ , " /></p>
<p> so Bregman divergence is distance-squared, and Bregman projection is just (Euclidean) projection.</p>
<p>
</p><p><b>  2.2. Bregman Divergence of Negative Entropy </b></p>
<p></p><p>
If, for <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+%28%7B%5Cmathbb+R%7D_%7B%5Cgeq+0%7D%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in ({\mathbb R}_{\geq 0})^n}" class="latex" title="{x\in ({\mathbb R}_{\geq 0})^n}" />, we define</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28x%29+%3D+%5Csum_%7Bi%3D1%7D%5En+x_i+%5Cln+x_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  R(x) = \sum_{i=1}^n x_i \ln x_i " class="latex" title="\displaystyle  R(x) = \sum_{i=1}^n x_i \ln x_i " /></p>
<p> then the associated Bregman divergence is the generalized <em>KL divergence.</em></p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28x%2Cy%29+%3D+%5Csum_%7Bi%3D1%7D%5En+x_i+%5Cln+%7Bx_i%7D+%5C+-+%5Csum_i+y_i+%5Cln+y_i+%5C+-+%5Clangle+%5Cnabla+R%28y%29%2C+x-y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D(x,y) = \sum_{i=1}^n x_i \ln {x_i} \ - \sum_i y_i \ln y_i \ - \langle \nabla R(y), x-y \rangle " class="latex" title="\displaystyle  D(x,y) = \sum_{i=1}^n x_i \ln {x_i} \ - \sum_i y_i \ln y_i \ - \langle \nabla R(y), x-y \rangle " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cnabla+R%28y%29%29_i+%3D+1+%2B+%5Cln+y_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\nabla R(y))_i = 1 + \ln y_i}" class="latex" title="{(\nabla R(y))_i = 1 + \ln y_i}" /> so that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+D%28x%2Cy%29+%3D+%5Csum_%7Bi%3D1%7D%5En+x_i+%5Cln+x_i+%5C+-+%5Csum_i+y_i+%5Cln+y_i+%5C+-+%5Csum_i+x_i+%5Cln+y_i+%5C+%2B+%5Csum_i+y_i+%5Cln+y_i+%5C+-+%5Csum_i+x_i+%2B+%5Csum_i+y_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle D(x,y) = \sum_{i=1}^n x_i \ln x_i \ - \sum_i y_i \ln y_i \ - \sum_i x_i \ln y_i \ + \sum_i y_i \ln y_i \ - \sum_i x_i + \sum_i y_i " class="latex" title="\displaystyle D(x,y) = \sum_{i=1}^n x_i \ln x_i \ - \sum_i y_i \ln y_i \ - \sum_i x_i \ln y_i \ + \sum_i y_i \ln y_i \ - \sum_i x_i + \sum_i y_i " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+%5Csum_%7Bi%3D1%7D%5En+x_i+%5Cln+%5Cfrac%7Bx_i%7D+%7By_i%7D+%5C+-+%5Csum_i+x_i+%2B+%5Csum_i+y_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = \sum_{i=1}^n x_i \ln \frac{x_i} {y_i} \ - \sum_i x_i + \sum_i y_i " class="latex" title="\displaystyle  = \sum_{i=1}^n x_i \ln \frac{x_i} {y_i} \ - \sum_i x_i + \sum_i y_i " /></p>
<p>
Note that, if <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> are probability distributions, then the final two terms above cancel out, leaving just the KL divergence <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+x_i+%5Cln+%5Cfrac+%7Bx_i%7D%7By_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_i x_i \ln \frac {x_i}{y_i}}" class="latex" title="{\sum_i x_i \ln \frac {x_i}{y_i}}" />.</p>
<p>
</p><p><b>3. Mirror Descent </b></p>
<p></p><p>
We now introduce a new perspective on FTRL.</p>
<p>
In the unconstrained setting, if <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> is a strictly convex function and <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> is the associated Bregman divergence, the <em>mirror descent</em> algorithm for online optimization has the update rule</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5Carg%5Cmin_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+D%28x%2Cx_%7Bt-1%7D%29+%2B+%5Clangle+%5Cell_%7Bt-1%7D%2C+x+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \arg\min_{x\in {\mathbb R}^n} D(x,x_{t-1}) + \langle \ell_{t-1}, x \rangle " class="latex" title="\displaystyle  x_t = \arg\min_{x\in {\mathbb R}^n} D(x,x_{t-1}) + \langle \ell_{t-1}, x \rangle " /></p>
<p> The idea is that we want to find a solution that is good for the past loss functions, but that does not “overfit” too much. If, in past steps, <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bt-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{t-1}}" class="latex" title="{x_{t-1}}" /> had been chosen to be such a solution for the loss functions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_1%2C%5Cldots%2C%5Cell_%7Bt-2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_1,\ldots,\ell_{t-2}}" class="latex" title="{\ell_1,\ldots,\ell_{t-2}}" />, then, in choosing <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" />, we want to balance staying close to <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bt-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{t-1}}" class="latex" title="{x_{t-1}}" /> but also doing well with respect to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%7Bt-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_{t-1}}" class="latex" title="{\ell_{t-1}}" />, hence the above definition.</p>
<blockquote><p><b>Theorem 1</b> <em> Initialized with <img src="https://s0.wp.com/latex.php?latex=%7Bx_1+%3D+%5Carg%5Cmin_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+R%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1 = \arg\min_{x\in {\mathbb R}^n} R(x)}" class="latex" title="{x_1 = \arg\min_{x\in {\mathbb R}^n} R(x)}" />, the unconstrained mirror descent algorithm is identical to FTRL with regularizer <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. </em></p></blockquote>
<p></p><p>
<em>Proof:</em>  We will proceed by induction on <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />. At <img src="https://s0.wp.com/latex.php?latex=%7Bt%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t=1}" class="latex" title="{t=1}" />, the definition of <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> is the same. For larger <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />, we know that FTRL will choose the unique <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cnabla+R%28x_t%29+%3D+-+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k}" class="latex" title="{\nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k}" />, so we will assume that this is true for the mirror descent algorithm for <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bt-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{t-1}}" class="latex" title="{x_{t-1}}" /> and prove it for <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" />. </p>
<p>
First, we note that the function <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Crightarrow+D%28x%2Cx_%7Bt-1%7D%29+%2B+%5Clangle+%5Cell_%7Bt-1%7D+%2C+x+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \rightarrow D(x,x_{t-1}) + \langle \ell_{t-1} , x \rangle}" class="latex" title="{x \rightarrow D(x,x_{t-1}) + \langle \ell_{t-1} , x \rangle}" /> is strictly convex, because it equals </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28x%29+-+R%28x_%7Bt-1%7D%29+-+%5Clangle+%5Cnabla+R%28x_%7Bt-1%7D%29%2C+x+-+x_t+%5Crangle+%2B+%5Clangle+%5Cell_%7Bt-1%7D+%2C+x+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  R(x) - R(x_{t-1}) - \langle \nabla R(x_{t-1}), x - x_t \rangle + \langle \ell_{t-1} , x \rangle" class="latex" title="\displaystyle  R(x) - R(x_{t-1}) - \langle \nabla R(x_{t-1}), x - x_t \rangle + \langle \ell_{t-1} , x \rangle" /></p>
<p> and so it is a sum of a strictly convex function <img src="https://s0.wp.com/latex.php?latex=%7BR%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(x)}" class="latex" title="{R(x)}" />, linear functions in <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, and constants independent of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. This means that <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> is the unique point at which the gradient of the above function is zero, that is, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28x_t%29+-+%5Cnabla+R%28x_%7Bt-1%7D%29+%2B+%5Cell_%7Bt-1%7D+%3D+0+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(x_t) - \nabla R(x_{t-1}) + \ell_{t-1} = 0 " class="latex" title="\displaystyle  \nabla R(x_t) - \nabla R(x_{t-1}) + \ell_{t-1} = 0 " /></p>
<p> and so </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28x_t%29+%3D+%5Cnabla+R%28x_%7Bt-1%7D%29+-+%5Cell_%7Bt-1%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(x_t) = \nabla R(x_{t-1}) - \ell_{t-1} " class="latex" title="\displaystyle  \nabla R(x_t) = \nabla R(x_{t-1}) - \ell_{t-1} " /></p>
<p> and, using the inductive hypothesis, we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28x_t%29+%3D+-+%5Csum_%7Bk%3D1%7D%5E%7Bt-1%7D+%5Cell_k+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k " class="latex" title="\displaystyle  \nabla R(x_t) = - \sum_{k=1}^{t-1} \ell_k " /></p>
<p> as desired. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
In the constrained case, there are two variants of mirror descent. Using the terminology from Elad Hazan’s survey, <em>agile</em> mirror descent is the natural generalization of the unconstrained algorithm:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5Carg%5Cmin_%7Bx%5Cin+K%7D+%5C+D%28x%2Cx_%7Bt-1%7D%29+%2B+%5Clangle+%5Cell_%7Bt-1%7D%2C+x+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \arg\min_{x\in K} \ D(x,x_{t-1}) + \langle \ell_{t-1}, x \rangle " class="latex" title="\displaystyle  x_t = \arg\min_{x\in K} \ D(x,x_{t-1}) + \langle \ell_{t-1}, x \rangle " /></p>
<p> Following the same steps as the proof in the previous section, it is possible to show that agile mirror descent is equivalent to solving, at each iteration, the “decoupled” optimization problems</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_t+%3D+%5Carg%5Cmin_%7By%5Cin+%7B%5Cmathbb+R%7D%5En%7D+D%28y%2Cx_%7Bt-1%7D%29+%2B+%5Clangle+%5Cell_%7Bt-1%7D%2C+y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y_t = \arg\min_{y\in {\mathbb R}^n} D(y,x_{t-1}) + \langle \ell_{t-1}, y \rangle " class="latex" title="\displaystyle  y_t = \arg\min_{y\in {\mathbb R}^n} D(y,x_{t-1}) + \langle \ell_{t-1}, y \rangle " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5Carg%5Cmin_%7Bx%5Cin+K%7D+D%28x%2Cy_t%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \arg\min_{x\in K} D(x,y_t) " class="latex" title="\displaystyle  x_t = \arg\min_{x\in K} D(x,y_t) " /></p>
<p> That is, we can first solve the unconstrained problem and then project on <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />. (Again, we can always replace <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n}" class="latex" title="{{\mathbb R}^n}" /> by a set <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> for which <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> is a barrier function and such that <img src="https://s0.wp.com/latex.php?latex=%7BK+%5Csubseteq+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K \subseteq S}" class="latex" title="{K \subseteq S}" />.)</p>
<p>
The <em>lazy</em> mirror descent algorithm has the update rule </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_t+%3D+%5Carg%5Cmin_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+D%28y%2Cy_%7Bt-1%7D%29+%2B+%5Clangle+%5Cell_%7Bt-1%7D%2C+y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y_t = \arg\min_{x\in {\mathbb R}^n} D(y,y_{t-1}) + \langle \ell_{t-1}, y \rangle " class="latex" title="\displaystyle  y_t = \arg\min_{x\in {\mathbb R}^n} D(y,y_{t-1}) + \langle \ell_{t-1}, y \rangle " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_t+%3D+%5Carg%5Cmin_%7Bx%5Cin+K%7D+D%28x%2Cy_t%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_t = \arg\min_{x\in K} D(x,y_t) " class="latex" title="\displaystyle  x_t = \arg\min_{x\in K} D(x,y_t) " /></p>
<p> The initialization is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_1+%3D+%5Carg%5Cmin_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+R%28x%29+%5C+%5C+%5C+x_1+%3D+%5Carg%5Cmin_%7Bx%5Cin+K%7D+R%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y_1 = \arg\min_{x\in {\mathbb R}^n} \ R(x) \ \ \ x_1 = \arg\min_{x\in K} R(x)" class="latex" title="\displaystyle  y_1 = \arg\min_{x\in {\mathbb R}^n} \ R(x) \ \ \ x_1 = \arg\min_{x\in K} R(x)" /></p>
<blockquote><p><b>Fact 2</b> <em> Lazy mirror descent is equivalent to FTRL. </em></p></blockquote>
<p></p><p>
<em>Proof:</em>  The solutions <img src="https://s0.wp.com/latex.php?latex=%7By_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_t}" class="latex" title="{y_t}" /> are the unconstrained optimum of FTRL, and <img src="https://s0.wp.com/latex.php?latex=%7Bx_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_t}" class="latex" title="{x_t}" /> is the Bregman projection of <img src="https://s0.wp.com/latex.php?latex=%7By_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_t}" class="latex" title="{y_t}" /> on <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />. We proved in the previous section that this characterizes constrained FTRL. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
What about agile mirror descent? In certain special cases it is equivalent to lazy mirror descent, and hence to FTRL, but it usually leads to a different set of solutions. </p>
<p>
We will provide an analysis of lazy mirror descent, but first we will give an analysis of the regret of unconstrained FTRL in terms of Bregman divergence, which will be the model on which we will build the proof for the constrained case.</p>
<p>
</p><p><b>4. A Regret Bound for FTRL in Terms of Bregman Divergence </b></p>
<p></p><p>
In this section we prove the following regret bound.</p>
<blockquote><p><b>Theorem 3</b> <em> Unconstrained FTRL with regularizer <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> satisfies the regret bound </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T%28x%29+%5Cleq+D%28x%2Cx_1%29+%2B+%5Csum_%7Bt%3D1%7D%5ET+D%28x_t%2Cx_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  {\rm Regret}_T(x) \leq D(x,x_1) + \sum_{t=1}^T D(x_t,x_{t+1}) " class="latex" title="\displaystyle  {\rm Regret}_T(x) \leq D(x,x_1) + \sum_{t=1}^T D(x_t,x_{t+1}) " /></p>
</em><p><em> where <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> is the Bregman divergence associated with <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. </em></p></blockquote>
<p></p><p>
We will take the mirror descent view of unconstrained FTRL, so that</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_1+%3D+%5Carg%5Cmin_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+R%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_1 = \arg\min_{x\in {\mathbb R}^n} \ R(x) " class="latex" title="\displaystyle  x_1 = \arg\min_{x\in {\mathbb R}^n} \ R(x) " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x_%7Bt%2B1%7D+%3D+%5Carg%5Cmin_%7Bx%5Cin+%7B%5Cmathbb+R%7D%5En%7D+%5C+D%28x%2Cx_t%29+%2B+%5Clangle+%5Cell_t+%2C+x%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x_{t+1} = \arg\min_{x\in {\mathbb R}^n} \ D(x,x_t) + \langle \ell_t , x\rangle " class="latex" title="\displaystyle  x_{t+1} = \arg\min_{x\in {\mathbb R}^n} \ D(x,x_t) + \langle \ell_t , x\rangle " /></p>
<p> We proved that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28x_%7Bt%2B1%7D+%29+%3D+%5Cnabla+R%28x_t%29+-+%5Cell_t+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(x_{t+1} ) = \nabla R(x_t) - \ell_t " class="latex" title="\displaystyle  \nabla R(x_{t+1} ) = \nabla R(x_t) - \ell_t " /></p>
<p> This means that we can rewrite the regret suffered at step <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> with respect to <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cell_t+%2C+x_t+-+x+%5Crangle+%3D+%5Clangle+%5Cnabla+R%28x_t%29+-+%5Cnabla+R%28x_%7Bt%2B1%7D%29%2C+x_t+-+x+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \langle \ell_t , x_t - x \rangle = \langle \nabla R(x_t) - \nabla R(x_{t+1}), x_t - x \rangle " class="latex" title="\displaystyle  \langle \ell_t , x_t - x \rangle = \langle \nabla R(x_t) - \nabla R(x_{t+1}), x_t - x \rangle " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+D%28x%2Cx_t%29+-+D%28x%2Cx_%7Bt%2B1%7D+%29+%2BD%28x_t%2C+x_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = D(x,x_t) - D(x,x_{t+1} ) +D(x_t, x_{t+1}) " class="latex" title="\displaystyle  = D(x,x_t) - D(x,x_{t+1} ) +D(x_t, x_{t+1}) " /></p>
<p> and the theorem follows by adding up the above expression for <img src="https://s0.wp.com/latex.php?latex=%7Bt%3D1%2C%5Cldots%2CT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t=1,\ldots,T}" class="latex" title="{t=1,\ldots,T}" /> and recalling that <img src="https://s0.wp.com/latex.php?latex=%7BD%28x%2Cx_%7BT%2B1%7D%29+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D(x,x_{T+1}) \geq 0}" class="latex" title="{D(x,x_{T+1}) \geq 0}" />.</p>
<p>
Unfortunately I have no geometric intuition about the above identity, although, as you can check yourself, the algebra works neatly.</p>
<p>
</p><p><b>5. A Regret Bound for Agile Mirror Descent </b></p>
<p></p><p>
In this section we prove the following generalization of the regret bound from the previous section.</p>
<blockquote><p><b>Theorem 4</b> <em> Agile mirror descent satisfies the regret bound </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Crm+Regret%7D_T%28x%29+%5Cleq+D%28x%2Cx_1%29+%2B+%5Csum_%7Bt%3D1%7D%5ET+D%28x_t%2Cy_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  {\rm Regret}_T(x) \leq D(x,x_1) + \sum_{t=1}^T D(x_t,y_{t+1}) " class="latex" title="\displaystyle  {\rm Regret}_T(x) \leq D(x,x_1) + \sum_{t=1}^T D(x_t,y_{t+1}) " /></p>
</em><p><em> </em></p></blockquote>
<p></p><p>
The first part of the update rule of agile mirror descent is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y_%7Bt%2B1%7D+%3D+%5Carg%5Cmin_%7By%5Cin+%7B%5Cmathbb+R%7D%5En%7D+D%28y%2Cx_%7Bt%7D%29+%2B+%5Clangle+%5Cell_%7Bt%7D%2C+y+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y_{t+1} = \arg\min_{y\in {\mathbb R}^n} D(y,x_{t}) + \langle \ell_{t}, y \rangle " class="latex" title="\displaystyle  y_{t+1} = \arg\min_{y\in {\mathbb R}^n} D(y,x_{t}) + \langle \ell_{t}, y \rangle " /></p>
<p> and, following steps that we have already carried out before, <img src="https://s0.wp.com/latex.php?latex=%7By_%7Bt%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_{t+1}}" class="latex" title="{y_{t+1}}" /> satisfies </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cnabla+R%28y_%7Bt%2B1%7D+%29+%3D+%5Cnabla+R%28x_t%29+-+%5Cell_t+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \nabla R(y_{t+1} ) = \nabla R(x_t) - \ell_t " class="latex" title="\displaystyle  \nabla R(y_{t+1} ) = \nabla R(x_t) - \ell_t " /></p>
<p> This means that we can rewrite the regret suffered at step <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> with respect to <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cell_t+%2C+x_t+-+x+%5Crangle+%3D+%5Clangle+%5Cnabla+R%28x_t%29+-+%5Cnabla+R%28y_%7Bt%2B1%7D%29%2C+x_t+-+x+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \langle \ell_t , x_t - x \rangle = \langle \nabla R(x_t) - \nabla R(y_{t+1}), x_t - x \rangle " class="latex" title="\displaystyle  \langle \ell_t , x_t - x \rangle = \langle \nabla R(x_t) - \nabla R(y_{t+1}), x_t - x \rangle " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%3D+D%28x%2Cx_t%29+-+D%28x%2Cy_%7Bt%2B1%7D+%29+%2BD%28x_t%2C+y_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  = D(x,x_t) - D(x,y_{t+1} ) +D(x_t, y_{t+1}) " class="latex" title="\displaystyle  = D(x,x_t) - D(x,y_{t+1} ) +D(x_t, y_{t+1}) " /></p>
<p> where the same mystery cancellations as before make the above identity true.</p>
<p>
Now I will wield another piece of magic, and I will state without proof the following fact about Bregman projections</p>
<blockquote><p><b>Lemma 5</b> <em> If <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+K%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in K}" class="latex" title="{x\in K}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> is the Bregman projection on <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> of a point <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, then </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28x%2Cy%29+%5Cgeq+D%28x%2Cz%29+%2B+D%28z%2Cy%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D(x,y) \geq D(x,z) + D(z,y) " class="latex" title="\displaystyle  D(x,y) \geq D(x,z) + D(z,y) " /></p>
</em><p><em> </em></p></blockquote>
<p> That is, if we think of <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> as a “distance,” the distance from <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> to its closest point <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> plus the distance from <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is at most the distance from <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. Note that this goes in the opposite direction as the triangle inequality (which ok, because <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> typically does not satisfy the triangle inequality).</p>
<p>
In particular, the above lemma gives us </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28x%2Cy_%7Bt%2B1%7D%29+%5Cgeq+D%28x%2Cx_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D(x,y_{t+1}) \geq D(x,x_{t+1}) " class="latex" title="\displaystyle  D(x,y_{t+1}) \geq D(x,x_{t+1}) " /></p>
<p> and so </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cell_t+%2C+x_t+-+x+%5Crangle+%5Cleq+D%28x%2Cx_t%29+-+D%28x%2Cx_%7Bt%2B1%7D+%29+%2BD%28x_t%2C+y_%7Bt%2B1%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \langle \ell_t , x_t - x \rangle \leq D(x,x_t) - D(x,x_{t+1} ) +D(x_t, y_{t+1}) " class="latex" title="\displaystyle  \langle \ell_t , x_t - x \rangle \leq D(x,x_t) - D(x,x_{t+1} ) +D(x_t, y_{t+1}) " /></p>
<p> Now summing over <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> and recalling that <img src="https://s0.wp.com/latex.php?latex=%7BD%28x%2Cx_%7BT%2B1%7D%29+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D(x,x_{T+1}) \geq 0}" class="latex" title="{D(x,x_{T+1}) \geq 0}" /> we have our theorem.</p>
<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/05/20/online-optimization-post-5-bregman-projections-and-mirror-descent/"><span class="datestr">at May 21, 2019 01:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/05/20/lecturer-tenured-assistant-professor-at-royal-holloway-university-of-london-apply-by-june-7-2019-at-royal-holloway-university-of-london-apply-by-june-7-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/05/20/lecturer-tenured-assistant-professor-at-royal-holloway-university-of-london-apply-by-june-7-2019-at-royal-holloway-university-of-london-apply-by-june-7-2019/">Lecturer (Tenured Assistant Professor) at Royal Holloway, University of London (apply by June 7, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at Royal Holloway, University of London, invites applications for a Lecturer position (a full-time and permanent (tenured) post). We are recruiting for an academic member of staff who can strengthen our research, which falls broadly within Algorithms and Complexity, Artificial Intelligence, Distributed and Global Computing, and Software Language Engineering.</p>
<p>Website: <a href="https://jobs.royalholloway.ac.uk/vacancy.aspx?ref=0519-179">https://jobs.royalholloway.ac.uk/vacancy.aspx?ref=0519-179</a><br />
Email: Jose.Fiadeiro@rhul.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/05/20/lecturer-tenured-assistant-professor-at-royal-holloway-university-of-london-apply-by-june-7-2019-at-royal-holloway-university-of-london-apply-by-june-7-2019/"><span class="datestr">at May 20, 2019 06:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6282781001271163342">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/05/notorious-lah-or-notorious-lah-or-you.html">Notorious L.A.H or Notorious LAH? OR You always need one more proofread</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I noticed a while back that even on the nth proofread of a document there are still corrections. So I decided to keep track of how many corrections there are in a paper I was working on. I chose a non-technical paper so that errors-in-the-math would not be the issue.  I chose<br />
<br />
                                           Guest Column: The Third P =?NP Poll (see <a href="https://blog.computationalcomplexity.org/2019/03/third-poll-on-p-vs-np-and-related.html">here</a>)<br />
<br />
that appeared in Lane Hemaspaandra's SIGACT News Complexity Column.<br />
<br />
I kept track of the following:<br />
<br />
1) Number of corrections. Anything that I changed. Could be style, a new thought, need not be (though could be) an error.<br />
<br />
2) Errors. These are things that really need to be corrected, like having `think' instead of  `thing' .<br />
<br />
Corrections vs  Errors, an Example:<br />
<br />
If I refer to Lane Hemaspaandra as <i>Notorious L.A.N</i> that is a correction and an  error, as he is Notorous <i>L.A.H.</i><br />
<br />
If I refer to Lane Hemaspaandra as<i> Notorious L.A.H</i> and decide to change it to <i>LAH </i>that is a correction that is not an error.<br />
<br />
I didn't keep track of serious errors vs typos, but after the first 3 proofreads there were no more serious errors--- sort of- --you'll see. Most serious was a f<b>onts-gone-wild thing where half the paper was in boldface.</b><br />
<br />
Here is a history of the number of corrections<br />
<br />
1) Lane proofread the first draft. κ corrections where κ is some cardinal between the cardinality of N and the cardinality of  2<sup>N</sup> . Its value depends on which model of set theory you are in. (My spellchecker thinks that cardinality is not a word. I checked and I am spelling it correctly but perhaps it's one of those things where I stare at it too much and keep misreading it.)<br />
<br />
Henceforth I omit the word <i>proofread</i> as it is understood<br />
<br />
<br />
2) Bill G:  81 corrections, 29 of which were errors.<br />
<br />
3) Clyde: 64 corrections,  of which 17 were errors.<br />
<br />
4) Bill G: 40 corrections, of which 21 were errors (I had added a new section causing more errors)<br />
<br />
5) Clyde: 30 corrections of which 10 were errors.<br />
<br />
6) Bill G: 24 corrections of which 6 were errors.<br />
<br />
7) Clyde: 18 corrections of which 8 were errors.<br />
<br />
8) David Sekora (A CS grad student at Maryland who at one time wanted to be an English Major): f15 corrections of which 15 were errors. Really! Typos dagnabbit! (Spell check thinks that dagnabbit is spelled wrong. Um---in that case what is the correct spelling?)<br />
<br />
9) Nathan Grammel (A CS grad student at Maryland) :6 corrections of which  3 were errors.<br />
<br />
10) Bill G, proofreading backwards, a paragraph at a time: 29 corrections of which 5 were errors.<br />
<br />
11) Justin Hontz, an ugrad who TAs for me: 10 corrections of which 7 were errors.<br />
<br />
12) Karthik Abinav, a grad student in theory at Maryland: 2 corrections both of which were errors. Was this the end or are there still issues?<br />
<br />
13) Josh Twitty, an ugrad who TAs for me: 0 corrections. YEAH!<br />
<br />
14) Dan Smolyak, an ugrad CS and Eco major:4 corrections, all 4 errors. <i>Error  </i>sounds too strong. For example, one of them was to replace ?. with ?  Yes, its an error, but not that important. It DOES point to his carefulness as a proofreader.<br />
<br />
15) Clyde Kruskal :20 corrections, 10 of which were errors. To call them errors seems wrong when he corrects  <i>Group theory' </i>to  <i>Group Theory</i>. None of these corrections were caused by prior comments. I think all of the errors were in the paper early on, undetected until now!<br />
<br />
16)  Backwards Bill G again:  28 corrections,  14 of which were errors. Again, the errors were minor. Most of the errors were relatively recent. As an example, if I list out topics in math like:<br />
<br />
a) Group Theory, Set Theory, and  Ramsey Theory<br />
<br />
then I am supposed to use capital letters, but if I say in prose<br />
<br />
Lance Fortnow thinks that the techniques used will be group theory, set theory, and Ramsey theory<br />
<br />
then only the R in Ramsey Theory is in caps.  Makes me glad I'm in math.<br />
<br />
17) Lane got penultimate proofread. Lane found 75 (yes 75 WOW) of which 66 (yes 66 WOW) were errors. Many of these were spacing and latex things that I would never have noticed (indeed- I didn't notice) and most readers would not have noticed (hmmm- how do I know that?) but only an editor could catch (hmmm- when I've edited the book review column and now the open problems column and I never found more than 10 errors). So when all is said and done: KUDOS to Lane! And My point was that you can never get all the errors out. On that I am correct. I wonder if there are still errors? Yeah, but at most 10. However, I said that BEFORE giving it to Lane.<br />
<br />
18) Stephen Fenner, the editor of SIGACT news got FINAL proofread. He found that I spelled his name wrong . How many errors are left? I would bet at most 10. I would bet that I would lose that bet.<br />
------------------------------------------------------------------------------------------------------------<br />
<br />
Why after multiple proofreadings are there still errors? (My spell check thinks proofreadings is not a word. Maybe my spell check is worried that if people get documents proofread a lot then they won't be needed anymore. This blog post refutes that thought.)<br />
<br />
1)  An error can occur from a correction. This caused a massive problem with another paper. Lane's next column will be by me and co-authors on The Muffin Problem. We had all kinds of problems with the colors and sizes--- Massive Magenta Muffins or Miniature Magenta Muffins? Sizes gone wild! Again Kudos to my proofreaders and to Lane for catching this rather important error.<br />
<br />
2) If some passage is added late in the process it will surely have errors.<br />
<br />
3) An error correction may clear away the brush so you can see other errors.<br />
<br />
4) With LaTeX (or Word for some) we have the ability to get things perfect. So there is no cost to keeping on perfecting things. This lead so many corrections that are not errors.<br />
<br />
5) I know of an adviser who would first say change A to B, and later change B back to A. (None of that happened with the paper discussed above).<br />
<br />
Are errors inevitable? Clyde Kruskal tells me that his father Martin Kruskal, as a teenager, read Courant and Robbins book <i>What is Mathematics</i> and found some errors in it. Martin's mother didn't believe him and marched him over to Courant's house:<br />
<br />
MARTIN MOTHER: Martin claims to have found errors in your book.<br />
<br />
COURANT:  (laughs) There are errors in every book.<br />
<br />
Courant was so impressed that ten (or so) years later Courant became Martin's PhD adviser.<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/05/notorious-lah-or-notorious-lah-or-you.html"><span class="datestr">at May 20, 2019 02:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4246">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/05/18/%e5%8a%a0%e6%b2%b9%e5%8f%b0%e7%81%a3%ef%bc%81/">加油台灣！</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><img src="https://lucatrevisan.files.wordpress.com/2019/05/taiwan.jpg?w=584" alt="taiwan" class="alignnone size-full wp-image-4247" /></p>
<p>I would like to congratulate my Taiwanese readers for being in the first Asian country to introduce same-sex marriage.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/05/18/%e5%8a%a0%e6%b2%b9%e5%8f%b0%e7%81%a3%ef%bc%81/"><span class="datestr">at May 18, 2019 08:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15880">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/05/18/an-app-proof/">An App Proof</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>That is “app” as in an on-line application</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/05/18/an-app-proof/leo/" rel="attachment wp-att-15881"><img src="https://rjlipton.files.wordpress.com/2019/05/leo.png?w=600" alt="" class="alignright size-full wp-image-15881" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Leo Stein ]</font></td>
</tr>
</tbody>
</table>
<p>
Leo Stein is an assistant professor in the department of Physics and Astronomy at the University of Mississippi. His research interests include general relativity from an astrophysical <a href="https://arxiv.org/abs/1809.09125">standpoint</a>. </p>
<p>
Today I want to share an unusual proof of his.<span id="more-15880"></span></p>
<p>
Mathematics and complexity theory are all about proving theorems. Most of the time, so far, we prove the old way: we write out a humanly readable proof. At least we hope the proof is readable. Some of the time, we use a computer to check or even create the proof. Sometimes we do extensive numerical computations, but these are not proofs.</p>
<p>
</p><p></p><h2> Solving Quadratic Equations </h2><p></p>
<p></p><p>
I have known, as I am sure you do, forever that a quadratic equation can be solved in closed form. That is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7B2%7D+%2B+bx+%2B+c+%3D+0%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^{2} + bx + c = 0, " class="latex" title="\displaystyle  x^{2} + bx + c = 0, " /></p>
<p>has the two solutions 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++-b%2F2+%2B+1%2F2%5Csqrt%7Bb%5E%7B2%7D-4c%7D+%5Ctext%7B+and+%7D+-b%2F2+-+1%2F2%5Csqrt%7Bb%5E%7B2%7D-4c%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  -b/2 + 1/2\sqrt{b^{2}-4c} \text{ and } -b/2 - 1/2\sqrt{b^{2}-4c}. " class="latex" title="\displaystyle  -b/2 + 1/2\sqrt{b^{2}-4c} \text{ and } -b/2 - 1/2\sqrt{b^{2}-4c}. " /></p>
<p>I have discussed this before <a href="https://rjlipton.wordpress.com/2014/04/30/bells-fifty-year-old-mistake/">here</a> and its relationship to the World’s Fair in Flushing Meadows. </p>
<p>
A natural question is: Are square roots needed in any formula for quadratic equations? The answer is “Yes”.</p>
<blockquote><p><b>Theorem 1</b> <em> There does not exist any continuous function from the space of quadratic polynomials to complex numbers which associates to any quadratic polynomial a root of that polynomial. </em>
</p></blockquote>
<p>
</p><blockquote><p><b>Corollary 2</b> <em> There is no quadratic formula built out of a finite combination of field operations and the functions <img src="https://s0.wp.com/latex.php?latex=%7B%5Csin%2C+%5Ccos%2C+%5Cexp%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\sin, \cos, \exp}" class="latex" title="{\sin, \cos, \exp}" />, and the coefficients of the polynomial. </em>
</p></blockquote>
<p></p><p>
The corollary uses the basic fact that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csin%2C+%5Ccos%2C+%5Cexp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sin, \cos, \exp}" class="latex" title="{\sin, \cos, \exp}" /> are continuous functions. Note that each has a single branch on complex plane, whereas radicals and the logarithm function do not. So how do we prove the theorem?</p>
<p>
</p><p></p><h2> An App Based Proof </h2><p></p>
<p></p><p>
Here is a novel, I think, proof that uses an app. Stein has written the app and it is <a href="https://duetosymmetry.com/tool/polynomial-roots-toy/">here</a>. He explains how to use it. I strongly suggest that you try this yourself. </p>
<blockquote><p><b> </b> <em> To get a feel for all this, drag the <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B0%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{a_{0}}" class="latex" title="{a_{0}}" /> coefficient to <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> and the <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{a_{1}}" class="latex" title="{a_{1}}" /> coefficient to <img src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{1/2}" class="latex" title="{1/2}" />. You should have two real roots in root space (one at <img src="https://s0.wp.com/latex.php?latex=%7B%5Capprox+-1.28%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\approx -1.28}" class="latex" title="{\approx -1.28}" />, the other at <img src="https://s0.wp.com/latex.php?latex=%7B%5Capprox+0.78%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\approx 0.78}" class="latex" title="{\approx 0.78}" />). Let’s call <img src="https://s0.wp.com/latex.php?latex=%7Br_%7B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r_{1}}" class="latex" title="{r_{1}}" /> the negative root, and <img src="https://s0.wp.com/latex.php?latex=%7Br_%7B2%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r_{2}}" class="latex" title="{r_{2}}" /> the positive root. Now move the coefficient <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B0%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{a_{0}}" class="latex" title="{a_{0}}" /> around in a small loop (i.e. move it around a little bit, and then return it to <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> where it started). Note that the roots move continuously, and then return to their original positions. Next, move <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B0%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{a_{0}}" class="latex" title="{a_{0}}" /> in a big loop (big enough that it orbits around <img src="https://s0.wp.com/latex.php?latex=%7Br_%7B2%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r_{2}}" class="latex" title="{r_{2}}" />). Something funny happens: the roots <img src="https://s0.wp.com/latex.php?latex=%7Br_%7B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r_{1}}" class="latex" title="{r_{1}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Br_%7B2%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r_{2}}" class="latex" title="{r_{2}}" /> switch places. </em>
</p></blockquote>
<p></p><p>
Leo Goldmakher says <a href="https://web.williams.edu/Mathematics/lg5/394/ArnoldQuintic.pdf">here</a>: </p>
<blockquote><p>
Pause and think about this for a second. This is really, really weird.
</p></blockquote>
<p>Here is one immediate consequence of this observation: </p>
<blockquote><p><b>Theorem 3</b> <em> There does not exist any continuous function from the space of quadratic polynomials to complex numbers which associates to any quadratic polynomial a root of that polynomial. </em>
</p></blockquote>
<p></p><p>
And so the corollary follows.</p>
<p>
</p><p></p><h2> A Standard Proof </h2><p></p>
<p></p><p>
Goldmakher writes out a more conventional proof in his paper titled <em>Arnold’s Elementary Proof Of The Insolvability Of The Quintic</em>. He also shows the following theorem: </p>
<blockquote><p><b>Theorem 4</b> <em> Fix a positive integer <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />. Any quintic formula built out of the field operations, continuous functions, and radicals must have nesting of level more than <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />. </em>
</p></blockquote>
<p>This says that there can be no fixed formula for fifth degree, quintic, polynomials. Of course, this follows from <a href="https://en.wikipedia.org/wiki/Galois_theory">Galois theory</a>, but his proof uses just calculus. The Arnold is Vladimir Arnold.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p>Do you know other cases of an app with animation conveying the essence of a mathematical proof?  This means more than “proofs in pictures” or “proofs without words”—the animation and interactivity are crucial.  </p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/05/18/an-app-proof/"><span class="datestr">at May 18, 2019 08:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/073">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/073">TR19-073 |  Parity helps to compute Majority | 

	Igor Carboni Oliveira, 

	Rahul Santhanam, 

	Srikanth Srinivasan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the complexity of computing symmetric and threshold functions by constant-depth circuits with Parity gates, also known as AC$^0[\oplus]$ circuits. Razborov (1987) and Smolensky (1987, 1993) showed that Majority requires depth-$d$ AC$^0[\oplus]$ circuits of size $2^{\Omega(n^{1/2(d-1)})}$. By using a divide-and-conquer approach, it is easy to show that Majority can be computed with depth-$d$ AC$^0[\oplus]$ circuits of size $2^{\widetilde{O}(n^{1/(d-1)})}$. This gap between upper and lower bounds has stood for nearly three decades.

Somewhat surprisingly, we show that neither the upper bound nor the lower bound above is tight for large $d$. We show for $d \geq 5$ that any symmetric function can be computed with depth-$d$ AC$^0[\oplus]$ circuits of size $\exp({\widetilde{O} (n^{\frac{2}{3} \cdot \frac{1}{(d - 4)}} )})$. Our upper bound extends to threshold functions (with a constant additive loss in the denominator of the double exponent). We improve the Razborov-Smolensky lower bound to show that for $d \geq 3$ Majority requires depth-$d$ AC$^0[\oplus]$ circuits of size $2^{\Omega(n^{1/(2d-4)})}$. For depths $d \leq 4$, we are able to refine our techniques to get almost-optimal bounds: the depth-$3$ AC$^0[\oplus]$ circuit size of Majority is $2^{\widetilde{\Theta}(n^{1/2})}$, while its depth-$4$ AC$^0[\oplus]$ circuit size is $2^{\widetilde{\Theta}(n^{1/4})}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/073"><span class="datestr">at May 17, 2019 09:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/072">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/072">TR19-072 |  Broadcast Congested Clique: Planted Cliques and Pseudorandom Generators | 

	Lijie Chen, 

	Ofer Grossman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Consider the multiparty communication complexity model where there are n processors, each receiving as input a row of an n by n matrix M with entries in {0, 1}, and in each round each party can broadcast a single bit to all other parties (this is known as the BCAST(1) model). There are many lower bounds known for the number of rounds necessary for certain problems in this model, but they are all worst case lower bounds which apply only for very specifically constructed input distributions. We develop a framework for showing lower bounds in this setting for more natural input distributions, and apply the framework to show:
A lower bound for finding planted cliques in random inputs (i.e., each entry of the matrix is random, except there is a random subset a_1,..., a_k in [n] where M_{a_i,a_j} = 1 for all i and j). Specifically, we show that if k = n^(1/4 - eps), this problem requires a number of rounds polynomial in n.

A pseudo-random generator which fools the BCAST(1) model. That is, we show a distribution which is efficiently samplable using few random bits, and which is indistinguishable from uniform by a low-round BCAST(1) protocol. This allows us to show that every t = Omega(log n) round randomized algorithm in which each processor uses up to n random bits can be efficiently transformed into an O(t)-round randomized algorithm in which each processor uses only up to O(t) random bits, while maintaining a high success probability.

As a corollary of the pseudo-random generator, we also prove the first average case lower bound for the model (specifically, for the problem of determining whether the input matrix is full rank), as well as an average-case time hierarchy.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/072"><span class="datestr">at May 17, 2019 07:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4244">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/05/16/online-optimization-post-4-regularity-lemmas/">Online Optimization Post 4: Regularity Lemmas</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
 We now discuss how to view proofs of certain <em>regularity lemmas</em> as applications of the FTRL methodology.</p>
<p>
The Szemeredi Regularity Lemma states (in modern language) that every dense graph is well approximate by a graph with a very simple structure, made of the (edge-disjoint) union of a constant number of weighted complete bipartite subgraphs. The notion of approximation is a bit complicated to describe, but it enables the proof of <em>counting lemmas</em>, which show that, for example, the number of triangles in the original graph is well approximated by the (appropriately weighted) number of triangles in the approximating graph. </p>
<p>
Analogous regularity lemmas, in which an arbitrary object is approximated by a low-complexity object, have been proved for hypergraphs, for subsets of abelian groups (for applications to additive combinatorics), in an analytic setting (for applications to graph limits) and so on. </p>
<p>
The <em>weak regularity lemma</em> of Frieze and Kannan provides, as the name suggests, a weaker kind of approximation than the one promised by Szemeredi’s lemma, but one that is achievable with a graph that has a much smaller number of pieces. If <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> is the “approximation error” that one is willing to tolerate, Szemeredi’s lemma constructs a graph that is the union of a <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2%5E%7B%5Cvdots%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{2^{\vdots}}}" class="latex" title="{2^{2^{\vdots}}}" /> weighted complete bipartite subgraphs where the height of the tower of exponentials is polynomial in <img src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/\epsilon}" class="latex" title="{1/\epsilon}" />. In the Frieze-Kannan construction, that number is cut down to a single exponential <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%281%2F%5Cepsilon%5E2%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{O(1/\epsilon^2)}}" class="latex" title="{2^{O(1/\epsilon^2)}}" />. This result too can be generalized to graph limits, subsets of groups, and so on.</p>
<p>
With Tulsiani and Vadhan, we proved an abstract version of the Frieze-Kannan lemma (which can be applied to graphs, functions, distributions, etc.) in which the “complexity” of the approximation is <img src="https://s0.wp.com/latex.php?latex=%7BO%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1/\epsilon^2)}" class="latex" title="{O(1/\epsilon^2)}" />. In the graph case, the approximating graph is still the union of <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%281%2F%5Cepsilon%5E2%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{O(1/\epsilon^2)}}" class="latex" title="{2^{O(1/\epsilon^2)}}" /> complete bipartite subgraphs, but it has a more compact representation. One consequence of this result is that for every high-min-entropy distribution <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal D}" class="latex" title="{\cal D}" />, there is an efficiently samplable distribution with the same min-entropy as <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal D}" class="latex" title="{\cal D}" />, that is indistinguishable from <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal D}" class="latex" title="{\cal D}" />. Such a result could be taken to be a proof that what GANs attempt to achieve is possible in principle, except that our result requires an unrealistically high entropy (and we achieve “efficient samplability” and “indistinguishability” only in a weak sense).</p>
<p>
All these results are proved with a similar strategy: one starts from a trivial approximator, for example the empty graph, and then repeats the following iteration: if the current approximator achieves the required approximation, then we are done; otherwise take a counterexample, and modify the approximator using the counterexample. Then one shows that: </p>
<ul>
<li> The number of iterations is bounded, by keeping track of an appropriate potential function;
</li><li> The “complexity” of the approximator does not increase too much from iteration to iteration.
</li></ul>
<p>
Typically, the number of iterations is <img src="https://s0.wp.com/latex.php?latex=%7BO%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1/\epsilon^2)}" class="latex" title="{O(1/\epsilon^2)}" />, and the difference between the various results is given by whether at each iteration the “complexity” increases exponentially, or by a multiplicative factor, or by an additive term.</p>
<p>
Like in the post on pseudorandom constructions, one can view such constructions as an online game between a “builder” and an “inspector,” except that now the online optimization algorithm will play the role of the builder, and the inspector is the one acting as an adversary. The <img src="https://s0.wp.com/latex.php?latex=%7BO%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1/\epsilon^2)}" class="latex" title="{O(1/\epsilon^2)}" /> bound on the number of rounds comes from the fact that the online optimization algorithms that we have seen so far achieve amortized error per round <img src="https://s0.wp.com/latex.php?latex=%7BO%281%2F%5Csqrt+T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1/\sqrt T)}" class="latex" title="{O(1/\sqrt T)}" /> after <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> rounds, so it takes <img src="https://s0.wp.com/latex.php?latex=%7BO%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1/\epsilon^2)}" class="latex" title="{O(1/\epsilon^2)}" /> rounds for the error bound to go below <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />.</p>
<p>
We will see that the abstract weak regularity lemma of my paper with Tulsiani and Vadhan (and hence the graph weak regularity lemma of Frieze and Kannan) can be immediately deduced from the theory developed in the previous post. </p>
<p>
When I was preparing these notes, I was asked by several people if the same can be done for Szemeredi’s lemma. I don’t see a natural way of doing that. For such results, one should maybe use the online optimization techniques as a guide rather than as a black box. In general, iterative arguments (in which one constructs an object through a series of improvements) require the choice of a potential function, and an argument about how much the potential function changes at every step. The power of the FTRL method is that it creates the potential function and a big part of the analysis automatically and, even where it does not work directly, it can serve as an inspiration. </p>
<p>
One could imagine a counterfactual history in which people first proved the weak regularity lemma using online optimization out of the box, as we do in this post, and then decided to try and use an L2 potential function and an iterative method to get the Szemeredi lemma, subsequently trying to see what happens if the potential function is entropy, thus discovering Jacob Fox’s major improvement on the “triangle removal lemma,” which involves the construction of an approximator that just approximates the number of triangles.</p>
<p>
<span id="more-4244"></span></p>
<p>
</p><p><b>1. A “vanilla” weak regularity lemma </b></p>
<p></p><p>
Frieze and Kannan proved the following basic result about graph approximations, which has a number of algorithmic applications. If <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> is a set of vertices which is understood from the context, and <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B \subseteq V}" class="latex" title="{A,B \subseteq V}" /> are disjoint subsets of vertices, then let <img src="https://s0.wp.com/latex.php?latex=%7BK_%7BA%2CB%7D+%3D+%7B%5Cbf+1%7D_A+%5Ccdot+%7B%5Cbf+1%7D_B%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K_{A,B} = {\bf 1}_A \cdot {\bf 1}_B^T}" class="latex" title="{K_{A,B} = {\bf 1}_A \cdot {\bf 1}_B^T}" />, that is, the boolean matrix such that <img src="https://s0.wp.com/latex.php?latex=%7BK_%7BA%2CB%7D+%28i%2Cj%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K_{A,B} (i,j) = 1}" class="latex" title="{K_{A,B} (i,j) = 1}" /> iff <img src="https://s0.wp.com/latex.php?latex=%7Bi%5Cin+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i\in A}" class="latex" title="{i\in A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj%5Cin+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j\in B}" class="latex" title="{j\in B}" />.</p>
<p>
The <em>cut norm</em> of a matrix <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+M+%7C%7C_%7B%5Csquare%7D+%3A%3D+%5Cmax_%7BA%2CB%7D+%7C+%5Clangle+M%2C+K_%7BA%2CB%7D+%5Crangle+%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || M ||_{\square} := \max_{A,B} | \langle M, K_{A,B} \rangle | " class="latex" title="\displaystyle  || M ||_{\square} := \max_{A,B} | \langle M, K_{A,B} \rangle | " /></p>
<p>
In the following we will identify a graph with its adjacency matrix.</p>
<blockquote><p><b>Theorem 1</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G=(V,E)}" class="latex" title="{G=(V,E)}" /> be an graph on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> vertices and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt;0}" class="latex" title="{\epsilon &gt;0}" /> be an approximation parameter. </em></p><em>
<p>
Then there are sets <img src="https://s0.wp.com/latex.php?latex=%7BA_1%2CB_1%2C%5Cldots%2CA_T%2CB_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1,B_1,\ldots,A_T,B_T}" class="latex" title="{A_1,B_1,\ldots,A_T,B_T}" /> and scalars <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%2C%5Cldots%2C%5Calpha_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_1,\ldots,\alpha_T}" class="latex" title="{\alpha_1,\ldots,\alpha_T}" />, where <img src="https://s0.wp.com/latex.php?latex=%7BT+%5Cleq+O%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T \leq O(1/\epsilon^2)}" class="latex" title="{T \leq O(1/\epsilon^2)}" />, such that if we define</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++H%3A%3D+%5Csum_%7Bi%3D1%7D%5ET+%5Calpha_i+K_%7BA_i%2CB_i%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  H:= \sum_{i=1}^T \alpha_i K_{A_i,B_i} " class="latex" title="\displaystyle  H:= \sum_{i=1}^T \alpha_i K_{A_i,B_i} " /></p>
<p> we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+G+-+H+%7C%7C_%7B%5Csquare%7D+%5Cleq+%5Cepsilon+n%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || G - H ||_{\square} \leq \epsilon n^2 " class="latex" title="\displaystyle  || G - H ||_{\square} \leq \epsilon n^2 " /></p>
</em><p><em> </em></p></blockquote>
<p></p><p>
We will prove the following more general version.</p>
<blockquote><p><b>Theorem 2</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> be a set, <img src="https://s0.wp.com/latex.php?latex=%7Bg%3A+X+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g: X \rightarrow [0,1]}" class="latex" title="{g: X \rightarrow [0,1]}" /> be a bounded function, <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> be a family of functions mapping <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[0,1]}" class="latex" title="{[0,1]}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> be an approximation parameter. Then there are functions <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1,\ldots,f_T}" class="latex" title="{f_1,\ldots,f_T}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> and scalars <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%2C%5Cldots%2C%5Calpha_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_1,\ldots,\alpha_T}" class="latex" title="{\alpha_1,\ldots,\alpha_T}" />, with <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+O%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = O(1/\epsilon^2)}" class="latex" title="{T = O(1/\epsilon^2)}" />, such that if we define </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++h+%3A%3D+%5Csum_%7Bi%3D1%7D%5ET+%5Calpha_i+f_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  h := \sum_{i=1}^T \alpha_i f_i " class="latex" title="\displaystyle  h := \sum_{i=1}^T \alpha_i f_i " /></p>
<p> we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+f%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%7C+%5Clangle+f%2C+g-+h+%5Crangle+%7C+%5Cleq+%5Cepsilon+%7CX%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall f\in {\cal F}: \ \ | \langle f, g- h \rangle | \leq \epsilon |X| " class="latex" title="\displaystyle  \forall f\in {\cal F}: \ \ | \langle f, g- h \rangle | \leq \epsilon |X| " /></p>
</em><p><em> </em></p></blockquote>
<p></p><p>
We could also, with the same proof, argue about a possibly infinite set <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> with a measure <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu(X)}" class="latex" title="{\mu(X)}" /> is finite, and, after defining the inner product</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+f%2C+g+%5Crangle+%3A%3D+%5Cint_X+f%5Ccdot+g%5C+d+%5Cmu+%5C+%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \langle f, g \rangle := \int_X f\cdot g\ d \mu \ , " class="latex" title="\displaystyle  \langle f, g \rangle := \int_X f\cdot g\ d \mu \ , " /></p>
<p>
we could prove the same conclusion of the theorem, with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Ccdot+%5Cmu%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon \cdot \mu(X)}" class="latex" title="{\epsilon \cdot \mu(X)}" /> instead of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon |X|}" class="latex" title="{\epsilon |X|}" /> as an error bound.</p>
<p>
Here is the proof: run the FTRL algorithm with L2-squared regularizer in the setup in which the space of solutions <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> is the set of all functions <img src="https://s0.wp.com/latex.php?latex=%7B+X+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X \rightarrow {\mathbb R}}" class="latex" title="{ X \rightarrow {\mathbb R}}" /> and the loss functions are linear. Every time the algorithm proposes a solution <img src="https://s0.wp.com/latex.php?latex=%7Bh_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h_t}" class="latex" title="{h_t}" />, if there is a function <img src="https://s0.wp.com/latex.php?latex=%7Bf_t+%5Cin+%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_t \in {\cal F}}" class="latex" title="{f_t \in {\cal F}}" /> such that either <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle+h_t+-+g+%2C+f_t+%5Crangle+%3E+%5Cepsilon%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle h_t - g , f_t \rangle &gt; \epsilon|X|}" class="latex" title="{ \langle h_t - g , f_t \rangle &gt; \epsilon|X|}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle+h_t+-+g+%2C+f_t+%5Crangle+%3C+-+%5Cepsilon%7CX%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle h_t - g , f_t \rangle &lt; - \epsilon|X|}" class="latex" title="{ \langle h_t - g , f_t \rangle &lt; - \epsilon|X|}" />, the adversary will pick, respectively, <img src="https://s0.wp.com/latex.php?latex=%7Bf_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_t}" class="latex" title="{f_t}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B-f_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-f_t}" class="latex" title="{-f_t}" /> as a loss function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_t}" class="latex" title="{\ell_t}" />. When the adversary has no such choice, we stop and the function <img src="https://s0.wp.com/latex.php?latex=%7Bh_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h_t}" class="latex" title="{h_t}" /> is our desired approximation.</p>
<p>
First of all, let us analyze the number of rounds. Here the maximum norm of the functions in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+%7B%7CX%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt {|X|}}" class="latex" title="{\sqrt {|X|}}" />, so after <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> rounds we have the regret bound</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+h+%3A+%5C+%5C+%5Csum_%7Bt%3D1%7D%5ET+%5Clangle+%5Cell_t%2C+h_t+-+h+%5Crangle+%5Cleq+%5Csqrt%7B%7CX%7C%7D+%5Ccdot+%7C%7C+h+%7C%7C+%5Ccdot+%5Csqrt%7B2T%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall h : \ \ \sum_{t=1}^T \langle \ell_t, h_t - h \rangle \leq \sqrt{|X|} \cdot || h || \cdot \sqrt{2T} " class="latex" title="\displaystyle  \forall h : \ \ \sum_{t=1}^T \langle \ell_t, h_t - h \rangle \leq \sqrt{|X|} \cdot || h || \cdot \sqrt{2T} " /></p>
<p> Now let us consider <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> to be our offline solution: we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cepsilon+T+%7CX%7C+%3C+%5Csum_%7Bt%3D1%7D%5ET+%5Clangle+%5Cell_t%2C+h_t+-+g+%5Crangle+%5Cleq+%7CX%7C+%5Ccdot+%5Csqrt%7B2T%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \epsilon T |X| &lt; \sum_{t=1}^T \langle \ell_t, h_t - g \rangle \leq |X| \cdot \sqrt{2T} " class="latex" title="\displaystyle  \epsilon T |X| &lt; \sum_{t=1}^T \langle \ell_t, h_t - g \rangle \leq |X| \cdot \sqrt{2T} " /></p>
<p> which implies </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++T+%3C+%5Cfrac+2%7B%5Cepsilon%5E2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  T &lt; \frac 2{\epsilon^2} " class="latex" title="\displaystyle  T &lt; \frac 2{\epsilon^2} " /></p>
<p> Finally, recall that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++h_T+%3D+%5Csum_%7Bt%3D1%7D%5E%7BT-1%7D+-+%5Cfrac+1+%7B2c%7D+%5Cell_t+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  h_T = \sum_{t=1}^{T-1} - \frac 1 {2c} \ell_t " class="latex" title="\displaystyle  h_T = \sum_{t=1}^{T-1} - \frac 1 {2c} \ell_t " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> is the scaling constant in the definition of the regularizer (<img src="https://s0.wp.com/latex.php?latex=%7B1%2F2c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/2c}" class="latex" title="{1/2c}" /> is of order of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> when <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is order of <img src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Cepsilon%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/\epsilon^2}" class="latex" title="{1/\epsilon^2}" />), and so our final approximator <img src="https://s0.wp.com/latex.php?latex=%7Bh_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h_T}" class="latex" title="{h_T}" /> computed at the last round is a weighted sum of functions from <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" />.</p>
<p>
</p><p><b>2. The weak regularity lemma </b></p>
<p></p><p>
Frieze and Kannan’s weak regularity lemma has the following form.</p>
<blockquote><p><b>Theorem 3</b> <em><a name="th.fk"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G=(V,E)}" class="latex" title="{G=(V,E)}" /> be an graph on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> vertices and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt;0}" class="latex" title="{\epsilon &gt;0}" /> be an approximation parameter. </em></p><em>
<p>
Then there is a partition of <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> into <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+2%5E%7BO%281%2F%5Cepsilon%5E2%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k = 2^{O(1/\epsilon^2)}}" class="latex" title="{k = 2^{O(1/\epsilon^2)}}" /> sets <img src="https://s0.wp.com/latex.php?latex=%7BS_1%2C%5Cldots%2CS_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S_1,\ldots,S_k}" class="latex" title="{S_1,\ldots,S_k}" />, and there are bounded weights <img src="https://s0.wp.com/latex.php?latex=%7B0%5Cleq+p_%7Bi%2Cj%7D+%5Cleq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0\leq p_{i,j} \leq 1}" class="latex" title="{0\leq p_{i,j} \leq 1}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj+%5Cin+%5C%7B1%2C%5Cldots%2C+k%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i,j \in \{1,\ldots, k\}}" class="latex" title="{i,j \in \{1,\ldots, k\}}" /> such that if we defined the weighted graph <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> where the weight of the edge <img src="https://s0.wp.com/latex.php?latex=%7B%28u%2Cv%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(u,v)}" class="latex" title="{(u,v)}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> is <img src="https://s0.wp.com/latex.php?latex=%7Bp_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_{i,j}}" class="latex" title="{p_{i,j}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bu%5Cin+S_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u\in S_i}" class="latex" title="{u\in S_i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bv%5Cin+S_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v\in S_j}" class="latex" title="{v\in S_j}" />, then we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+G+-+H+%7C%7C_%7B%5Csquare%7D+%5Cleq+%5Cepsilon+n%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || G - H ||_{\square} \leq \epsilon n^2 " class="latex" title="\displaystyle  || G - H ||_{\square} \leq \epsilon n^2 " /></p>
</em><p><em> </em></p></blockquote>
<p></p><p>
Notice that if we did not require the weights to be between 0 and 1 then the result of the previous section can also be cast in the above language, because we can take the partition <img src="https://s0.wp.com/latex.php?latex=%7BS_1%2C%5Cldots%2CS_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S_1,\ldots,S_k}" class="latex" title="{S_1,\ldots,S_k}" /> to be the “Sigma-algebra generated by” the sets <img src="https://s0.wp.com/latex.php?latex=%7BA_1%2CB_1%2C%5Cldots%2CA_T%2CB_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1,B_1,\ldots,A_T,B_T}" class="latex" title="{A_1,B_1,\ldots,A_T,B_T}" />.</p>
<p>
For a scalar <img src="https://s0.wp.com/latex.php?latex=%7Bz%5Cin+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z\in {\mathbb R}}" class="latex" title="{z\in {\mathbb R}}" />, let <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tau(z)}" class="latex" title="{\tau(z)}" /> be defined as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctau%28z%29+%3D+%5Cleft%5C%7B+%5Cbegin%7Barray%7D%7Brl%7D+0+%26+%5Cmbox%7B+if+%7D+z+%3C0%5C%5C+z+%26+%5Cmbox%7B+if+%7D+0%5Cleq+z+%5Cleq+1%5C%5C+1+%26+%5Cmbox%7B+if+%7D+z+%3E+1+%5Cend%7Barray%7D+%5Cright.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \tau(z) = \left\{ \begin{array}{rl} 0 &amp; \mbox{ if } z &lt;0\\ z &amp; \mbox{ if } 0\leq z \leq 1\\ 1 &amp; \mbox{ if } z &gt; 1 \end{array} \right. " class="latex" title="\displaystyle  \tau(z) = \left\{ \begin{array}{rl} 0 &amp; \mbox{ if } z &lt;0\\ z &amp; \mbox{ if } 0\leq z \leq 1\\ 1 &amp; \mbox{ if } z &gt; 1 \end{array} \right. " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tau}" class="latex" title="{\tau}" /> stands for <em>t</em>runcation. Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tau(z)}" class="latex" title="{\tau(z)}" /> is the L2 projection of <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[0,1]}" class="latex" title="{[0,1]}" />.</p>
<p>
Theorem <a href="https://lucatrevisan.wordpress.com/feed/#th.fk">3</a> is a special case of the following result, proved in our paper with Tulsiani and Vadhan. </p>
<blockquote><p><b>Theorem 4</b> <em><a name="th.ttv"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> be a set, <img src="https://s0.wp.com/latex.php?latex=%7Bg%3A+X+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g: X \rightarrow [0,1]}" class="latex" title="{g: X \rightarrow [0,1]}" /> be a bounded function, <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> be a family of functions mapping <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[0,1]}" class="latex" title="{[0,1]}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> be an approximation parameter. Then there are functions <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1,\ldots,f_T}" class="latex" title="{f_1,\ldots,f_T}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> and scalars <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%2C%5Cldots%2C%5Calpha_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_1,\ldots,\alpha_T}" class="latex" title="{\alpha_1,\ldots,\alpha_T}" />, with <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+O%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = O(1/\epsilon^2)}" class="latex" title="{T = O(1/\epsilon^2)}" />, such that if we define </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++h+%3A%3D+%5Ctau%5Cleft+%28+%5Csum_%7Bi%3D1%7D%5ET+%5Calpha_i+f_i+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  h := \tau\left ( \sum_{i=1}^T \alpha_i f_i \right) " class="latex" title="\displaystyle  h := \tau\left ( \sum_{i=1}^T \alpha_i f_i \right) " /></p>
<p> we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+f%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%7C+%5Clangle+f%2C+g-+h+%5Crangle+%7C+%5Cleq+%5Cepsilon+%7CX%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall f\in {\cal F}: \ \ | \langle f, g- h \rangle | \leq \epsilon |X| " class="latex" title="\displaystyle  \forall f\in {\cal F}: \ \ | \langle f, g- h \rangle | \leq \epsilon |X| " /></p>
</em><p><em> </em></p></blockquote>
<p></p><p>
To prove Theorem <a href="https://lucatrevisan.wordpress.com/feed/#th.ttv">4</a> we play the same online game as in the previous section: the online algorithm proposes a solution <img src="https://s0.wp.com/latex.php?latex=%7Bh_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h_t}" class="latex" title="{h_t}" />; if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cforall+f%5Cin+%7B%5Ccal+F%7D%3A+%5C+%5C+%7C+%5Clangle+f%2C+g-+h+%5Crangle+%7C+%5Cleq+%5Cepsilon+%7CX%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\forall f\in {\cal F}: \ \ | \langle f, g- h \rangle | \leq \epsilon |X| }" class="latex" title="{\forall f\in {\cal F}: \ \ | \langle f, g- h \rangle | \leq \epsilon |X| }" /> then we stop and output <img src="https://s0.wp.com/latex.php?latex=%7Bh%3Dh_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h=h_t}" class="latex" title="{h=h_t}" />, otherwise we let the loss function be a function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_t}" class="latex" title="{\ell_t}" /> such that either <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_t}" class="latex" title="{\ell_t}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B-%5Cell_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-\ell_t}" class="latex" title="{-\ell_t}" /> is in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> and </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cell_t+%2C+g-+h_t+%5Crangle+%5Cgeq+%5Cepsilon+%7CX%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \langle \ell_t , g- h_t \rangle \geq \epsilon |X| " class="latex" title="\displaystyle  \langle \ell_t , g- h_t \rangle \geq \epsilon |X| " /></p>
<p>
The only difference is that we use the FTRL algorithm with L2 regularizer that has the set feasible solutions <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> defined to be the set of all functions <img src="https://s0.wp.com/latex.php?latex=%7Bh+%3A+X+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h : X \rightarrow [0,1]}" class="latex" title="{h : X \rightarrow [0,1]}" /> rather than the set of all functions <img src="https://s0.wp.com/latex.php?latex=%7Bh%3A+X+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h: X \rightarrow {\mathbb R}}" class="latex" title="{h: X \rightarrow {\mathbb R}}" />. Then each function <img src="https://s0.wp.com/latex.php?latex=%7Bh_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h_T}" class="latex" title="{h_T}" /> is the projection to <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bt%3D1%7D%5E%7BT-1%7D+-+%5Cfrac+1+%7B2c%7D%5Cell_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_{t=1}^{T-1} - \frac 1 {2c}\ell_t}" class="latex" title="{\sum_{t=1}^{T-1} - \frac 1 {2c}\ell_t}" />, and the projection to <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> is just composition with <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tau}" class="latex" title="{\tau}" />. The bound on the number of steps is the same as the one in the previous section.</p>
<p>
Looking at the case in which <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is the set of edges of a clique on <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> is the set of graphs of the form <img src="https://s0.wp.com/latex.php?latex=%7BK_%7BA%2CB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K_{A,B}}" class="latex" title="{K_{A,B}}" />, and considering the Sigma-algebra generated by <img src="https://s0.wp.com/latex.php?latex=%7BA_1%2CB_1%2C%5Cldots%2CA_T%2CB_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1,B_1,\ldots,A_T,B_T}" class="latex" title="{A_1,B_1,\ldots,A_T,B_T}" /> gives Theorem <a href="https://lucatrevisan.wordpress.com/feed/#th.fk">3</a> from Theorem <a href="https://lucatrevisan.wordpress.com/feed/#th.ttv">4</a>.</p>
<p>
</p><p><b>3. Sampling High-Entropy Distributions </b></p>
<p></p><p>
Finally we discuss the application to sampling high-entropy distributions. </p>
<p>
Suppose that <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> is a distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ 0,1 \}^n}" class="latex" title="{\{ 0,1 \}^n}" /> of min-entropy <img src="https://s0.wp.com/latex.php?latex=%7B%5Cgeq+n-d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\geq n-d}" class="latex" title="{\geq n-d}" />, meaning that for every <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in \{ 0,1 \}^n}" class="latex" title="{x\in \{ 0,1 \}^n}" /> we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%28x%29+%5Cleq+2%5E%7B-%28n-d%29%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D(x) \leq 2^{-(n-d)} " class="latex" title="\displaystyle  D(x) \leq 2^{-(n-d)} " /></p>
<p> where we think of the <em>entropy deficiency</em> <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> as being small, such as a constant or <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" /></p>
<p>
Let <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> be a class of functions <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+0%2C1+%5C%7D%5En+%5Crightarrow+%5C%7B+0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ 0,1 \}^n \rightarrow \{ 0,1\}}" class="latex" title="{\{ 0,1 \}^n \rightarrow \{ 0,1\}}" /> that we think of as being “efficient.” For example, <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" /> could be the set of all functions computable by circuits of size <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleq+S%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\leq S(n)}" class="latex" title="{\leq S(n)}" /> for some size bound <img src="https://s0.wp.com/latex.php?latex=%7BS%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(\cdot)}" class="latex" title="{S(\cdot)}" />, such as, for example <img src="https://s0.wp.com/latex.php?latex=%7BS%28n%29+%3D+10+n%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(n) = 10 n^2}" class="latex" title="{S(n) = 10 n^2}" />. We will assume that <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%5Cequiv+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x) \equiv 1}" class="latex" title="{f(x) \equiv 1}" /> is in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" />. Define </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%28x%29+%3D+2%5E%7Bn-d%7D+%5Ccdot+D%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  g(x) = 2^{n-d} \cdot D(x) " class="latex" title="\displaystyle  g(x) = 2^{n-d} \cdot D(x) " /></p>
<p> to be a bounded function <img src="https://s0.wp.com/latex.php?latex=%7Bg%3A+%5C%7B+0%2C1+%5C%7D%5En+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g: \{ 0,1 \}^n \rightarrow [0,1]}" class="latex" title="{g: \{ 0,1 \}^n \rightarrow [0,1]}" />. Fix an approximation parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt;0}" class="latex" title="{\epsilon &gt;0}" />.</p>
<p>
Then from Theorem <a href="https://lucatrevisan.wordpress.com/feed/#th.ttv">4</a> we have that there are <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+O%281%2F%5Cepsilon%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = O(1/\epsilon^2)}" class="latex" title="{T = O(1/\epsilon^2)}" /> functions <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%2C%5Cldots%2Cf_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1,\ldots,f_T}" class="latex" title="{f_1,\ldots,f_T}" />, and scalars <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%2C%5Cldots%2C%5Calpha_T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_1,\ldots,\alpha_T}" class="latex" title="{\alpha_1,\ldots,\alpha_T}" />, all equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+1%2F2c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pm 1/2c}" class="latex" title="{\pm 1/2c}" /> for a certain parameter <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" />, such that if we define </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++h%28x%29+%3D+%5Ctau+%5Cleft%28+%5Csum_%7Bt%3D1%7D%5ET+%5Calpha_t+f_t%28x%29+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  h(x) = \tau \left( \sum_{t=1}^T \alpha_t f_t(x) \right) " class="latex" title="\displaystyle  h(x) = \tau \left( \sum_{t=1}^T \alpha_t f_t(x) \right) " /></p>
<p> we have <a name="eq.ttv.main"></a></p><a name="eq.ttv.main">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cforall+f+%5Cin+%7B%5Ccal+F%7D+%3A+%5C+%5C+%5C+%5Cleft+%7C+%5Csum_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+%5Cleft%28+g%28x%29+f%28x%29+-+h%28x%29+f%28x%29+%5Cright+%29+%5Cright+%7C+%5Cleq+%5Cepsilon+2%5En+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( g(x) f(x) - h(x) f(x) \right ) \right | \leq \epsilon 2^n \ \ \ \ \ (1)" class="latex" title="\displaystyle   \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( g(x) f(x) - h(x) f(x) \right ) \right | \leq \epsilon 2^n \ \ \ \ \ (1)" /></p>
</a><p><a name="eq.ttv.main"></a> and so, multiplying by <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B-%28n-d%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{-(n-d)}}" class="latex" title="{2^{-(n-d)}}" /> <a name="eq.ttv.b"></a></p><a name="eq.ttv.b">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cforall+f+%5Cin+%7B%5Ccal+F%7D+%3A+%5C+%5C+%5C+%5Cleft+%7C+%5Csum_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+%5Cleft%28+D%28x%29+f%28x%29+-+h%28x%292%5E%7B-%28n-d%29%7D+f%28x%29+%5Cright+%29+%5Cright+%7C+%5Cleq+%5Cepsilon+2%5Ed+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( D(x) f(x) - h(x)2^{-(n-d)} f(x) \right ) \right | \leq \epsilon 2^d \ \ \ \ \ (2)" class="latex" title="\displaystyle   \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( D(x) f(x) - h(x)2^{-(n-d)} f(x) \right ) \right | \leq \epsilon 2^d \ \ \ \ \ (2)" /></p>
</a><p><a name="eq.ttv.b"></a> Now define the probability distribution </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++H%28x%29+%3D+%5Cfrac+%7Bh%28x%29%7D%7B%5Csum_%7By%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+h%28y%29+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  H(x) = \frac {h(x)}{\sum_{y\in \{ 0,1 \}^n} h(y) } " class="latex" title="\displaystyle  H(x) = \frac {h(x)}{\sum_{y\in \{ 0,1 \}^n} h(y) } " /></p>
<p> Applying <a href="https://lucatrevisan.wordpress.com/feed/#eq.ttv.main">(1)</a> to the case <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%5Cequiv+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x) \equiv 1}" class="latex" title="{f(x) \equiv 1}" />, we have </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft+%7C+%5Csum_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+%5Cleft%28+g%28x%29+-+h%28x%29+%5Cright+%29+%5Cright+%7C+%5Cleq+%5Cepsilon+2%5En+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left | \sum_{x\in \{ 0,1 \}^n} \left( g(x) - h(x) \right ) \right | \leq \epsilon 2^n " class="latex" title="\displaystyle  \left | \sum_{x\in \{ 0,1 \}^n} \left( g(x) - h(x) \right ) \right | \leq \epsilon 2^n " /></p>
<p> and we know that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_x+g%28x%29+%3D+2%5E%7Bn-d%7D+%5Csum_x+D%28x%29+%3D+2%5E%7Bn-d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_x g(x) = 2^{n-d} \sum_x D(x) = 2^{n-d}}" class="latex" title="{\sum_x g(x) = 2^{n-d} \sum_x D(x) = 2^{n-d}}" />, so </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft+%7C+2%5E%7Bn-d%7D+-+%5Csum_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+h%28x%29+%5Cright+%7C+%5Cleq+%5Cepsilon+2%5En+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left | 2^{n-d} - \sum_{x\in \{ 0,1 \}^n} h(x) \right | \leq \epsilon 2^n " class="latex" title="\displaystyle  \left | 2^{n-d} - \sum_{x\in \{ 0,1 \}^n} h(x) \right | \leq \epsilon 2^n " /></p>
<p> and we can rewrite <a href="https://lucatrevisan.wordpress.com/feed/#eq.ttv.b">(2)</a> as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+f+%5Cin+%7B%5Ccal+F%7D+%3A+%5C+%5C+%5C+%5Cleft+%7C+%5Csum_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+%5Cleft%28+D%28x%29+f%28x%29+-+H%28x%29+%5Ccdot+%28%5Csum_y+h%28y%29%29+2%5E%7B-%28n-d%29%7D+f%28x%29+%5Cright+%29+%5Cright+%7C+%5Cleq+%5Cepsilon+2%5Ed+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( D(x) f(x) - H(x) \cdot (\sum_y h(y)) 2^{-(n-d)} f(x) \right ) \right | \leq \epsilon 2^d " class="latex" title="\displaystyle  \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( D(x) f(x) - H(x) \cdot (\sum_y h(y)) 2^{-(n-d)} f(x) \right ) \right | \leq \epsilon 2^d " /></p>
<p> and, finally </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+f+%5Cin+%7B%5Ccal+F%7D+%3A+%5C+%5C+%5C+%5Cleft+%7C+%5Csum_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+%5Cleft%28+D%28x%29+f%28x%29+-+H%28x%29+f%28x%29+%5Cright+%29+%5Cright+%7C+%5Cleq+2+%5Cepsilon+2%5Ed+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( D(x) f(x) - H(x) f(x) \right ) \right | \leq 2 \epsilon 2^d " class="latex" title="\displaystyle  \forall f \in {\cal F} : \ \ \ \left | \sum_{x\in \{ 0,1 \}^n} \left( D(x) f(x) - H(x) f(x) \right ) \right | \leq 2 \epsilon 2^d " /></p>
<p> that is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cforall+f+%5Cin+%7B%5Ccal+F%7D+%3A+%5C+%5C+%5C+%5Cleft+%7C+%5CPr_%7Bx%5Csim+D%7D+%5Bf%28x%29+%3D+1%5D+-+%5CPr_%7Bx%5Csim+H%7D+%5Bf%28x%29+%3D1+%5D+%5Cright+%7C+%5Cleq+2+%5Cepsilon+2%5Ed+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \forall f \in {\cal F} : \ \ \ \left | \Pr_{x\sim D} [f(x) = 1] - \Pr_{x\sim H} [f(x) =1 ] \right | \leq 2 \epsilon 2^d " class="latex" title="\displaystyle  \forall f \in {\cal F} : \ \ \ \left | \Pr_{x\sim D} [f(x) = 1] - \Pr_{x\sim H} [f(x) =1 ] \right | \leq 2 \epsilon 2^d " /></p>
<p> which says that <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> are <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+2%5E%7Bd%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon 2^{d+1}}" class="latex" title="{\epsilon 2^{d+1}}" />-indistinguishable by functions in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" />. If we chose <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Ccal+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\cal F}}" class="latex" title="{{\cal F}}" />, for example, to be the class of functions computable by circuits of size <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleq+S%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\leq S(n)}" class="latex" title="{\leq S(n)}" />, then <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> are <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+2%5E%7Bd%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon 2^{d+1}}" class="latex" title="{\epsilon 2^{d+1}}" />-indistinguishable by circuits of size <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleq+S%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\leq S(n)}" class="latex" title="{\leq S(n)}" />.</p>
<p>
But <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> is also samplable in a relatively efficient way using rejection sampling: pick a random <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, then output <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(x)}" class="latex" title="{h(x)}" /> and fail with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-h%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-h(x)}" class="latex" title="{1-h(x)}" />. Repeat the above until the procedure does not fail. At each step, the probability of success is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%5Cin+%5C%7B+0%2C1+%5C%7D%5En%7D+h%28x%29+%5Cgeq+2%7B-d%7D+-+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}_{x\in \{ 0,1 \}^n} h(x) \geq 2{-d} - \epsilon}" class="latex" title="{\mathop{\mathbb E}_{x\in \{ 0,1 \}^n} h(x) \geq 2{-d} - \epsilon}" />, so, assuming (because otherwise all of the above makes no sense) that, say, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3C+2%5E%7B-d-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &lt; 2^{-d-1}}" class="latex" title="{\epsilon &lt; 2^{-d-1}}" />, the procedure succeeds on average in at most <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bd%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{d+1}}" class="latex" title="{2^{d+1}}" /> attempts. And if each <img src="https://s0.wp.com/latex.php?latex=%7Bf_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_t}" class="latex" title="{f_t}" /> is computable by a circuit of size <img src="https://s0.wp.com/latex.php?latex=%7BS%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(n)}" class="latex" title="{S(n)}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> is computable by a circuit of size <img src="https://s0.wp.com/latex.php?latex=%7BO%281%2F%5Cepsilon%5E2%29+%2B+S%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1/\epsilon^2) + S(n)}" class="latex" title="{O(1/\epsilon^2) + S(n)}" />.</p>
<p>
The undesirable features of this result are that the complexity of sampling and the quality of indistinguishability depend exponentially on the randomness deficiency, and the sampling circuit is a non-uniform circuit that it’s not clear how to construct without advice. Impagliazzo’s recent results address both these issues.</p>
<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/05/16/online-optimization-post-4-regularity-lemmas/"><span class="datestr">at May 16, 2019 07:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-9175787683601603334">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/05/getting-through-clutter.html">Getting Through the Clutter</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
My daughter showed up at her doctor's office the other day and found it closed. She complained that she had received all these alerts, texts, emails, voicemails, reminding her of the appointment and then they weren't there when she showed up. She had stopped reading the alerts, the last of which said the appointment need to be rescheduled.<br />
<br />
We all get too many alerts. I just assume many of the emails I send to faculty never get read or remembered. I get many requests to mention conferences, workshop and other theory happenings on this blog because nobody knows how to get the word out through the clutter. If we followed through on all these requests, this blog would become clutter itself.<br />
<br />
Back in 2009, Nikhil Devanur and I wrote a <a href="https://doi.org/10.1145/1562814.1562830">paper</a> trying to capture this phenomenon using complexity. Building on Levin's notion of universal search, the unawareness of a string x in an environment E is the amount of time needed to generate x from a context c given an oracle for E. Levin showed that one can have a universal algorithm, only a constant time slower to generate x than any other algorithm. One should think of E as the sum total of all our knowledge including search engines on the Internet. Technically we should have used the term "attention" instead of "awareness".<br />
<br />
One example is using a calendar as part of your environment, E, that reminds you of an event, x, on that date, c. We use calendars, contact lists, emails searches and many other ways to keep strings we need to remember. Advertisers try to alter your E to get the unawareness of x down.<br />
<br />
One of these papers that didn't go far because we didn't have great applications for the definition. But it follows a good philosophy, when life seems complex, model it.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/05/getting-through-clutter.html"><span class="datestr">at May 16, 2019 12:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/05/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/05/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://culturacientifica.com/2019/05/01/el-poema-de-los-numeros-primos/">El poema de los números primos</a> (<a href="https://mastodon.social/@victorhck/102020247143426975"></a>). Exhibit of the mathematically-inspired artworks of <a href="https://en.wikipedia.org/wiki/Esther_Ferrer">Esther Ferrer</a>, at <a href="https://en.wikipedia.org/wiki/Tabakalera">Tabakalera</a> in San Sebastián, Spain.</p>
  </li>
  <li>
    <p><a href="https://igorpak.wordpress.com/2019/04/26/how-combinatorics-became-legitimate-according-to-laszlo-lovasz-and-endre-szemeredi/">How combinatorics became legitimate</a> (<a href="https://mathstodon.xyz/@11011110/102036466457669447"></a>). Igor Pak recommends two interesting video interviews with László Lovász and Endre Szemerédi. The whole interviews are quite long but they’re broken into 10-minute clips and Igor has picked out the ones relevant to the title.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/how-twisted-graphene-became-the-big-thing-in-physics-20190430/">Magic angles and superconductivity in twisted graphene</a> (<a href="https://mathstodon.xyz/@11011110/102044547042991323"></a>). If you twist two sheets of hexagonally tiled carbon relative to each other you can get a superconductor, but only for certain very specific twist angles.</p>
  </li>
  <li>
    <p><a href="https://practicaltypography.com/ligatures-in-programming-fonts-hell-no.html">Matthew Butterick says no to ligatures in programming fonts</a> (<a href="https://mathstodon.xyz/@11011110/102047783718443248"></a>, <a href="https://news.ycombinator.com/item?id=19805053">via</a>). I tend to agree. They make some things cuter but more things inconsistent. The lack of a short double back arrow in the Fira example is telling. And anyone who expects to see individual characters has to know what font they’re displayed in and how it mangles them to understand what they’re reading. But if you like these for your own text editing, whatever. Just show me the ASCII when I have to view it in my browser.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1905.01325">Breaking the Bellman–Ford shortest-path bound</a> (<a href="https://mathstodon.xyz/@11011110/102051970319136719"></a>). Amr Elmasry claims a time bound of  for single-source shortest paths in graphs that may have cycles and negative edge weights, but no negative cycles. If correct, this would be a big improvement over the  time for Bellman–Ford. However, I got stuck somewhere around Lemma 3 when trying to understand it. Anyone else have better progress?</p>
  </li>
  <li>
    <p><a href="http://www.generalist.org.uk/blog/2019/gender-and-deletion-on-wikipedia/">Some actual data on how the subject’s gender influences biography creation and deletion on Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/102058999289661319"></a>). Still-existing older articles on women are more likely to have gone through a deletion discussion than men, but we don’t know whether more were nominated or equally many nominated but women survived better, and whether the inequality of nominations has lessened recently or the greater nomination rate for women takes longer to kick in and is still prevalent.</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1904.12761">The graphs behind Reuleaux polyhedra</a> (<a href="https://mathstodon.xyz/@11011110/102064338449854355"></a>), by
Luis Montejano, Eric Pauli, Miguel Raggi, and Edgardo Roldán-Pensado.
These shapes are the intersections of equal-radius balls centered at their vertices; smoothing some edges gives them constant width. Their vertices are the finite point sets with the most diameters. Their vertex-edge graphs are self-dual, unlike other polyhedral graphs. And their vertex-diameter graphs are 4-colorable. Examples include pyramids over odd polygons.</p>
  </li>
  <li>
    <p>It’s not like it’s difficult to make your own out of, you know, paper, but if you want a colorful kit to teach yourself about the Miura-ori and three other folds, <a href="https://www.thisiscolossal.com/2019/05/paper-folding-kit-by-kelli-anderson/">this one looks pretty if a little overpriced at $20 for eight sheets of paper</a> (<a href="https://mathstodon.xyz/@11011110/102070078247023735"></a>).</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1905.02167">Tensor products of graphs can require fewer colors than their factors</a> (<a href="https://mathstodon.xyz/@11011110/102072759747197000"></a>). This short new preprint by Yaroslav Shitov gives counterexamples to <a href="https://en.wikipedia.org/wiki/Hedetniemi%27s_conjecture">Hedetniemi’s conjecture</a> from 1966. In a new blog post <a href="https://gilkalai.wordpress.com/2019/05/10/sansation-in-the-morning-news-yaroslav-shitov-counterexamples-to-hedetniemis-conjecture/">Gil Kalai explains the construction</a>.</p>
  </li>
  <li>
    <p><a href="https://discrete-notes.github.io/natural-history">Algorithms and natural history</a> (<a href="https://mathstodon.xyz/@11011110/102080291126103628"></a>). In a new blog, Laurent Feuilloley writes about some algorithmic problems on polyhedra coming from the measurement of skulls, diamond cutting, and the use of symmetry to undo deformations of fossils.</p>
  </li>
  <li>
    <p>Did you know that Swiss mathematician <a href="https://en.wikipedia.org/wiki/Alice_Roth">Alice Roth</a> invented <a href="https://en.wikipedia.org/wiki/Swiss_cheese_(mathematics)">Swiss cheese</a>? (<a href="https://mathstodon.xyz/@11011110/102087095765063877"></a>). A Swiss cheese is a disk with smaller disks removed, leaving no interior. <a href="https://blogs.scientificamerican.com/roots-of-unity/the-serendipity-of-swiss-cheese/"><em>Scientific American</em> alerted me to this amusing terminology</a> but I got a clearer idea what they’re good for from <a href="http://www.math.tamu.edu/~boas/courses/618-2015a/roth.pdf">an exercise using them to show complex conjugation to be well-behaved on a compact domain but hard to approximate by rational functions</a>.</p>
  </li>
  <li>
    <p><a href="https://ooni.torproject.org/post/2019-china-wikipedia-blocking/">China is now blocking all language editions of Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/102089517303119369"></a>, <a href="https://boingboing.net/2019/05/13/report-china-now-blocks-wikip.html">via</a>), expanding its previous block which applied only to the Mandarin edition.</p>

    <p>Of course their internet blockage is hardly the biggest problem with China these days. I was surprised to find that some of my usually-well-informed friends hadn’t even heard of “<a href="https://www.france24.com/en/20190510-reporters-plus-surviving-china-uighur-camps-repression">the largest mass incarceration of the 21st century</a>” and “<a href="https://www.theguardian.com/world/2018/dec/07/uighur-leaders-warn-chinas-actions-could-be-precursors-to-genocide">precursors to genocide</a>”, <a href="https://www.washingtonpost.com/opinions/global-opinions/china-cant-prettify-the-human-rights-catastrophe-in-xinjiang/2019/03/24/4c844f62-45ca-11e9-90f0-0ccfeec87a61_story.html">China’s concentration camps</a> for <a href="https://www.amnesty.org/en/latest/news/2018/09/china-up-to-one-million-detained/">up to a million Uighur people</a>. So read and learn.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Hazel_Perfect">Hazel Perfect</a> (<a href="https://mathstodon.xyz/@11011110/102097362417443508"></a>). A new Wikipedia article on the inventor of <a href="https://en.wikipedia.org/wiki/Gammoid">gammoids</a> (how I came across her name this time) and <a href="https://aperiodical.com/2013/03/much-ado-about-noether/">Christian Lawson-Perfect’s mathematical hero</a> (despite or because of the unexplained similarity of names).</p>
  </li>
  <li>
    <p><a href="https://www.dailykos.com/stories/2019/5/13/1857360/-Poll-says-that-56-of-Americans-don-t-want-kids-taught-Arabic-numerals-We-have-some-bad-news">In a recent poll, “56% of Americans said Arabic numerals should not be taught in American schools”</a> (<a href="https://mathstodon.xyz/@11011110/102100871760570133"></a>).</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/05/15/linkage.html"><span class="datestr">at May 15, 2019 10:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/05/15/postdoc-at-boston-college-apply-by-june-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/05/15/postdoc-at-boston-college-apply-by-june-1-2019/">Postdoc at Boston College (apply by June 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>We invite applications for a postdoc position hosted by Hsin-Hao Su at Boston College. Areas of specific interests include but not limited to distributed graph algorithms, local algorithms, dynamic graph algorithms, gossip algorithms, and massive parallel computation algorithms. The starting date is flexible between Fall 2019 and Spring 2020. The position is for a period of up to two years.</p>
<p>Website: <a href="https://sites.google.com/site/distributedhsinhao/postdoc">https://sites.google.com/site/distributedhsinhao/postdoc</a><br />
Email: suhx@bc.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/05/15/postdoc-at-boston-college-apply-by-june-1-2019/"><span class="datestr">at May 15, 2019 07:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4191">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4191">The SSL Certificate of Damocles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Ever since I “upgraded” this website to use SSL, it’s become completely inaccessible once every three months, because the SSL certificate expires.  Several years in, I’ve been unable to find any way to prevent this from happening, and Bluehost technical support was unable to suggest any solution.  The fundamental problem is that, as long as the site remains up, the Bluehost control panel tells me that there’s nothing to do, since there <em>is</em> a current certificate.  Meanwhile, though, I start getting menacing emails saying that my SSL certificate is about to expire and “you must take action to secure the site”—<em>never</em>, of course, specifying what action to take.  The only thing to do seems to be to wait for the whole site to go down, then frantically take random certificate-related actions until somehow the site goes back up.  Those actions vary each time and are not repeatable.</p>



<p>Does anyone know a simple solution to this ridiculous problem?</p>



<p>(The deeper problem, of course, is that a PhD in theoretical computer science left me utterly unqualified for the job of webmaster.  And webmasters, as it turns out, need to do a lot just to prevent anything from changing.  And since childhood, I’ve been accustomed to countless tasks that are trivial for most people being difficult for me—-if that ever stopped being the case, I’d no longer feel like myself.)</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4191"><span class="datestr">at May 15, 2019 02:56 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/071">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/071">TR19-071 |  Time-Space Lower Bounds for Two-Pass Learning | 

	Sumegha Garg, 

	Ran Raz, 

	Avishay Tal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A line of recent works showed that for a large class of learning problems, any learning algorithm  requires either super-linear memory size or a super-polynomial number of samples [Raz16,KRT17,Raz17,MM18,BOGY18,GRT18]. For example, any algorithm for learning parities of size $n$ requires either a memory of size $\Omega(n^{2})$ or an exponential number of samples [Raz16].

All these works modeled the learner as a one-pass branching program, allowing only one pass over the stream of samples. In this work, we prove the first memory-samples lower bounds (with a super-linear lower bound on the memory size and super-polynomial lower bound on the number of samples) when the learner is allowed two passes over the stream of samples. For example, we prove that any two-pass algorithm for learning parities of size $n$ requires either a memory of size $\Omega(n^{1.5})$ or at least $2^{\Omega(\sqrt{n})}$ samples.

More generally, a matrix $M: A \times X \rightarrow \{-1,1\}$ corresponds to the following learning problem: An unknown element $x \in X$ is chosen uniformly at random. A learner tries to learn $x$ from a stream of samples, $(a_1, b_1), (a_2, b_2) \ldots$, where for every $i$, $a_i \in A$ is chosen uniformly at random and $b_i = M(a_i,x)$.

Assume that $k,l, r$ are such that any submatrix of $M$ of at least $2^{-k} \cdot |A|$ rows and at least $2^{-l} \cdot |X|$ columns, has a bias of at most $2^{-r}$. We show that any two-pass learning algorithm for the learning problem corresponding to $M$ requires either a memory of size at least $\Omega\left(k \cdot  \min\{k,\sqrt{l}\} \right)$, or at least $2^{\Omega(\min\{k,\sqrt{l},r\})}$ samples.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/071"><span class="datestr">at May 14, 2019 04:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15858">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/05/14/internet-dogs-and-the-abc-conjecture/">Internet, Dogs, and the ABC Conjecture</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>An inappropriate comment on the ABC conjecture</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<a href="https://rjlipton.wordpress.com/2019/05/14/internet-dogs-and-the-abc-conjecture/220px-david_masser/" rel="attachment wp-att-15867"><img width="150" alt="" class="alignright wp-image-15867" src="https://rjlipton.files.wordpress.com/2019/05/220px-david_masser.jpg?w=150" /></a><br /><a href="https://rjlipton.wordpress.com/2019/05/14/internet-dogs-and-the-abc-conjecture/220px-oesterle_joseph/" rel="attachment wp-att-15868"><img width="150" alt="" class="alignright  wp-image-15868" src="https://rjlipton.files.wordpress.com/2019/05/220px-oesterle_joseph.jpg?w=150" /></a><br /><table class="image alignright">
<tbody>
<tr>
<td>
</td>
</tr>
<tr>


</tr>
</tbody>
</table>
<p>
Joseph Oesterlé and David Masser are famous for their independent discovery of the ABC conjecture. </p>
<p>
Today I want to point out an unfair comment about their discovery.<span id="more-15858"></span></p>
<p>
Anonymity on the Internet was captured by a famous 1993 <a href="https://en.wikipedia.org/wiki/On_the_Internet,_nobody_knows_you%27re_a_dog">cartoon</a> in the <i>New Yorker</i> magazine titled, “On the Internet, nobody knows you’re a dog.”  Amazing to think that was more than a quarter-century ago and remains true.  But people <i>can</i> tell if what you’ve written is something inappropriate.</p>
<p></p><h2> The Comment </h2><p></p>
<p></p><p>
The comment is: </p>
<blockquote><p><b> </b> <em> <i>SAYS WHO??? I have some trouble with this item.</i> </em>
</p></blockquote>
<p></p><p>
Masser is a Fellow of the Royal Society, who was elected in 2005. He is </p>
<blockquote><p><b> </b> <em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /> also responsible, following an earlier insight of Joseph Oesterlé, for formulating the abc conjecture; this is a simple statement about integers which seems to hold the key to much of the future direction of number theory. </em>
</p></blockquote>
<p></p><p>
See this <a href="https://royalsociety.org/people/david-masser-11903/">link</a> for his full citation and the comment. Click on the <i>show more bibliography</i> button there. The comment is apparently anonymous, although the author is probably known to some. I thank Joël Ouaknine for pointing out this strange comment.</p>
<p>
<b>Update:</b> Ken speculates that it’s a misplaced comment by an editor of the Royal Society website itself.  Perhaps they compose HTML from MS Word or Acrobat or other software that provides comment bubbles—but this one escaped the bubble and wasn’t noticed.  Editors of Wikipedia have automatic tools for flagging assertions that are unsupported or at least need citation.  </p>
<p>
What the comment undoubtedly shows is vigorous debate behind the walls of Britain’s august institution.  So let’s say a little more on what the comment is about.</p>
<p></p><h2> The ABC Conjecture </h2><p></p>
<p></p><p>
The biggest mysteries about numbers often concern the interaction between addition and multiplication. For example: </p>
<ul>
<li>
The <a href="https://en.wikipedia.org/wiki/Twin_prime">twin</a> prime conjecture: There are an infinite number of primes <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bp%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p+2}" class="latex" title="{p+2}" /> is also prime. This is due to Alphonse de Polignac. <p></p>
</li><li>
The <a href="https://en.wikipedia.org/wiki/Goldbach%27s_conjecture">Goldbach</a> conjecture: Every even number greater than four is the sum of two odd primes. This is due to Christian Goldbach. <p></p>
</li><li>
The <a href="https://en.wikipedia.org/wiki/Brocard%27s_problem">Brocard</a> conjecture: There are only a finite number of solutions to <img src="https://s0.wp.com/latex.php?latex=%7Bn%21+%3D+m%5E%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n! = m^{2} + 1}" class="latex" title="{n! = m^{2} + 1}" /> in natural numbers. This is due to Henri Brocard.
</li></ul>
<p>
Suppose that <img src="https://s0.wp.com/latex.php?latex=%7BA+%2B+B+%3D+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A + B = C}" class="latex" title="{A + B = C}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" /> are positive and co-prime natural numbers. Let <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> be the product of all the distinct prime divisors of <img src="https://s0.wp.com/latex.php?latex=%7BABC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ABC}" class="latex" title="{ABC}" />. Then the ABC conjecture says that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+O%28D%5E%7B2%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le O(D^{2}). " class="latex" title="\displaystyle  C \le O(D^{2}). " /></p>
<p>Note, this inequality does indeed connect adding with multiplying. The usual conjecture is stronger, see <a href="https://en.wikipedia.org/wiki/Abc_conjecture">this</a> for details.	</p>
<p>
The ABC conjecture appears to be open, even though Shinichi Mochizuki has claimed a <a href="https://rjlipton.wordpress.com/2012/09/12/the-abc-conjecture-and-cryptography/">proof</a> for years. See <a href="https://www.quantamagazine.org/titans-of-mathematics-clash-over-epic-proof-of-abc-conjecture-20180920">this</a> for a discussion about the status of the conjecture. </p>
<blockquote><p><b> </b> <em> Despite multiple conferences dedicated to explicating Mochizuki’s proof, number theorists have struggled to come to grips with its underlying ideas. His series of papers, which total more than 500 pages, are written in an impenetrable style, and refer back to a further 500 pages or so of previous work by Mochizuki, creating what one mathematician, Brian Conrad of Stanford University, has called “a sense of infinite regress.” </em>
</p></blockquote>
<p>
</p><p></p><h2> The Comment II </h2><p></p>
<p></p><p>
The comment on Masser’s work is wrong, strange, inappropriate. Oesterlé and Masser deserve more credit, not less, for their brilliant discovery of the ABC conjecture. There are now many—perhaps hundreds—of applications of the ABC conjecture. For example consider generalizations of Fermat’s Last Theorem. Suppose that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Bp%7D+%2B+y%5E%7Bq%7D+%3D+z%5E%7Br%7D+%5Ctext%7B++%28%2A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^{p} + y^{q} = z^{r} \text{  (*)}" class="latex" title="\displaystyle  x^{p} + y^{q} = z^{r} \text{  (*)}" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7Bp%2Cq%2Cr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p,q,r}" class="latex" title="{p,q,r}" /> are odd primes. And <img src="https://s0.wp.com/latex.php?latex=r+%3E+6&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="r &gt; 6" class="latex" title="r &gt; 6" />. Provided <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y,z}" class="latex" title="{x,y,z}" /> are positive and co-prime, it follows by the ABC conjecture that <img src="https://s0.wp.com/latex.php?latex=%7Bz%5E%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z^{r}}" class="latex" title="{z^{r}}" /> is bounded by <img src="https://s0.wp.com/latex.php?latex=%7BO%28z%5E%7B2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(z^{2})}" class="latex" title="{O(z^{2})}" />. This is impossible for <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> large enough since <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cge+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \ge 3}" class="latex" title="{r \ge 3}" />. Therefore, (*) can only have a finite number of solutions. Pretty neat.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Do you know of any other inappropriate comments of this kind?</p>
<p></p><p><br />
[added remark by Ken, linked rather than embed dog cartoon]<br />
[Added prime r must be 7 or larger. Thanks to comment by MadHatter.]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/05/14/internet-dogs-and-the-abc-conjecture/"><span class="datestr">at May 14, 2019 02:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/070">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/070">TR19-070 |  On Local Testability in the Non-Signaling Setting | 

	Alessandro Chiesa, 

	Peter Manohar, 

	Igor Shinkar</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Non-signaling strategies are a generalization of quantum strategies that have been studied in physics for decades, and have recently found applications in theoretical computer science. These applications motivate the study of local-to-global phenomena for non-signaling functions.

We present general results about the local testability of linear codes in the non-signaling setting. Our contributions include formulating natural definitions that capture the condition that a non-signaling function "belongs" to a given code, and characterizing the sets of local constraints that imply membership in the code. We prove these results by relating the Fourier spectrum of non-signaling functions to Cayley hypergraphs induced by local constraints.

We apply the above results to show a separation between locally testable codes in the classical and non-signaling setting by proving that bivariate low-degree testing fails spectacularly in the non-signaling setting. Specifically, we show that there exist non-signaling functions that pass bivariate low-degree tests with probability 1, and yet are maximally far from low-degree.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/070"><span class="datestr">at May 14, 2019 05:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=633">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/05/13/and-this-is-me-with-my-buddies/">And this is me with my buddies</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div class="RY3tic">
<div class="eGiHwc"><img src="https://emanueleviola.files.wordpress.com/2019/05/warriors2.jpg?w=640" alt="warriors2" class="alignnone size-full wp-image-634" /></div>
<div class="KYCEmd"></div>
</div>
<div class="RY3tic">
<div class="eGiHwc"></div>
<div class="KYCEmd"></div>
</div>
<p> </p></div>







<p class="date">
by Emanuele <a href="https://emanueleviola.wordpress.com/2019/05/13/and-this-is-me-with-my-buddies/"><span class="datestr">at May 13, 2019 03:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3507110503322010708">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/05/ronald-grahams-other-large-number-well.html">Ronald Graham's other large number. Well---- it was large in 1964 anyway.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Graham's number (see <a href="https://en.wikipedia.org/wiki/Graham%27s_number">here</a>) was at one time the largest number to appear in a math proof.<br />
<br />
a) GN was an upper bound on a problem in Ramsey theory. There are now better upper bounds, see <a href="https://www.sciencedirect.com/science/article/pii/S0195669814000936?via%3Dihub">here</a>. These better upper bounds are still large- Hales-Jewitt-Large, but that's already much smaller than the original GN.<br />
<br />
b) Other proofs now have numbers even larger than GN. For example Harvey Friedman's work on the finite versions of Kruskal's Tree Theorem. (There may be other cases- if you know some then let me know in the comments.)<br />
<br />
Since my dept recently moved buildings I found old papers that I had not looked at in years. One of them was<br />
<br />
<i>Old and New Problems and Results in Combinatorial Number Theory</i><br />
<br />
by Erdos and Graham<br />
<br />
(see <a href="http://www.math.ucsd.edu/~ronspubs/79_09_combinatorial_number_theory.pdf">here</a>)<br />
<br />
So I began reading it and came across a result of Graham from 1964 that used large numbers. No where near as large as GN, but I found it interesting that Graham was involved with large numbers way back then.<br />
<br />
Here is the problem:<br />
<br />
A <i>Lucas Sequence</i> is a sequence that obeys<br />
<br />
a(n) = a(n-1) + a(n-2).<br />
<br />
Clearly such a sequence is determined by a(0) and a(1).<br />
<br />
QUESTION: Does there exists a(0) and a(1)  that are rel prime such that the sequence has only composite numbers?<br />
<br />
By ingenuity and some computing power Graham found YES. For how the got the numbers see <a href="http://www.math.ucsd.edu/~ronspubs/64_06_fibonacci.pdf">here</a>. The numbers are of course in the paper, and how they got them is interesting, but I present them anyway. Hope I don't make a typo:<br />
<br />
a(0) = 1786772701928802632268715130455793<br />
<br />
a(1) = 1059683225053915111058164141686995<br />
<br />
The paper Old and New... says its open if there is a smaller pair of numbers, I do not know if it is still open. If you know, let us all  know in the comments!<br />
<br />
These numbers seem small today since we have modern computers that can store and manipulate them easily. Were the considered large numbers in 1964? They were never called Graham Numbers which is probably just as well since that honor lay ahead.<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/05/ronald-grahams-other-large-number-well.html"><span class="datestr">at May 13, 2019 04:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-7244168862511547770">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2019/05/ice-tcs-theory-day-2019.html">ICE-TCS Theory Day 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<i>This post also appears on the <a href="https://ice-tcs.blogspot.com/2019/05/ice-tcs-theory-day-2019.html">ICE-TCS blog</a>. </i><br /><br />On Friday, 3 May, ICE-TCS hosted its <a href="http://icetcs.ru.is/theory-day2019.html">15th annual Theory Day</a>. The event consisted of two 45-minute presentations by <a href="https://dblp.uni-trier.de/pers/hd/b/Boppana:Ravi_B=">Ravi  Boppana</a> (Department of Mathematics, MIT) and <a href="https://dcc.fceia.unr.edu.ar/~erivas/">Exequiel Rivas</a>(Inria Paris - Rocquencourt, France),  and three ten-minute presentations by ICE-TCS researchers highlighting some of the recent research directions pursued by members of the centre.<br /><br /><a href="https://dblp.uni-trier.de/pers/hd/b/Boppana:Ravi_B=">Ravi  Boppana</a> kicked off the Theory Day with a wonderfully paced talk on his <a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/v24i3p40">work</a> with <a href="https://holzman.technion.ac.il/">Ron Holzman</a> on Tomaszewski’s problem on randomly signed sums. The problem is as follows. Let <span style="font-size: 129%;" tabindex="0" class="mjx-chtml MathJax_CHTML" id="MathJax-Element-1-Frame"><span class="mjx-math" id="MJXc-Node-1"><span class="mjx-mrow" id="MJXc-Node-2"><span class="mjx-msubsup" id="MJXc-Node-3"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-4"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">v</span></span></span><span class="mjx-sub"><span class="mjx-mn" id="MJXc-Node-5"><span style="padding-top: 0.39em;" class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span></span></span>, <span style="font-size: 129%;" tabindex="0" class="mjx-chtml MathJax_CHTML" id="MathJax-Element-2-Frame"><span class="mjx-math" id="MJXc-Node-6"><span class="mjx-mrow" id="MJXc-Node-7"><span class="mjx-msubsup" id="MJXc-Node-8"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-9"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">v</span></span></span><span class="mjx-sub"><span class="mjx-mn" id="MJXc-Node-10"><span style="padding-top: 0.39em;" class="mjx-char MJXc-TeX-main-R">2</span></span></span></span></span></span></span>, ..., <span style="font-size: 129%;" tabindex="0" class="mjx-chtml MathJax_CHTML" id="MathJax-Element-3-Frame"><span class="mjx-math" id="MJXc-Node-11"><span class="mjx-mrow" id="MJXc-Node-12"><span class="mjx-msubsup" id="MJXc-Node-13"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-14"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">v</span></span></span><span class="mjx-sub"><span class="mjx-mi" id="MJXc-Node-15"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span></span> be real numbers whose squares add up to 1.  Consider the <span style="font-size: 129%;" tabindex="0" class="mjx-chtml MathJax_CHTML" id="MathJax-Element-4-Frame"><span class="mjx-math" id="MJXc-Node-16"><span class="mjx-mrow" id="MJXc-Node-17"><span class="mjx-msubsup" id="MJXc-Node-18"><span class="mjx-base"><span class="mjx-mn" id="MJXc-Node-19"><span style="padding-top: 0.39em;" class="mjx-char MJXc-TeX-main-R">2</span></span></span><span style="font-size: 70.7%; padding-left: 0px; vertical-align: 0.591em;" class="mjx-sup"><span class="mjx-mi" id="MJXc-Node-20"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">n</span></span></span></span></span></span></span> signed sums of the form <span style="font-size: 129%;" tabindex="0" class="mjx-chtml MathJax_CHTML" id="MathJax-Element-5-Frame"><span class="mjx-math" id="MJXc-Node-21"><span class="mjx-mrow" id="MJXc-Node-22"><span class="mjx-mi" id="MJXc-Node-23"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">S</span></span><span class="mjx-mo MJXc-space3" id="MJXc-Node-24"><span class="mjx-char MJXc-TeX-main-R">=</span></span><span class="mjx-mo MJXc-space3" id="MJXc-Node-25"><span class="mjx-char MJXc-TeX-size1-R">∑</span></span><span class="mjx-mo MJXc-space1" id="MJXc-Node-26"><span style="padding-top: 0.39em;" class="mjx-char MJXc-TeX-main-R">±</span></span><span class="mjx-msubsup" id="MJXc-Node-27"><span class="mjx-base"><span class="mjx-mi" id="MJXc-Node-28"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">v</span></span></span><span class="mjx-sub"><span class="mjx-mi" id="MJXc-Node-29"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">i</span></span></span></span></span></span></span>.  Can there be more signed sums whose value is greater than 1 then those whose value  is at most 1? <a href="https://holzman.technion.ac.il/files/2012/09/combsigns.pdf">Holzman and Kleitman (1992) </a>proved that at least 3/8 of these sums satisfy <span style="font-size: 129%;" tabindex="0" class="mjx-chtml MathJax_CHTML" id="MathJax-Element-6-Frame"><span class="mjx-math" id="MJXc-Node-30"><span class="mjx-mrow" id="MJXc-Node-31"><span class="mjx-texatom" id="MJXc-Node-32"><span class="mjx-mrow" id="MJXc-Node-33"><span class="mjx-mo" id="MJXc-Node-34"><span class="mjx-char MJXc-TeX-main-R">|</span></span></span></span><span class="mjx-mi" id="MJXc-Node-35"><span style="padding-bottom: 0.28em;" class="mjx-char MJXc-TeX-math-I">S</span></span><span class="mjx-texatom" id="MJXc-Node-36"><span class="mjx-mrow" id="MJXc-Node-37"><span class="mjx-mo" id="MJXc-Node-38"><span class="mjx-char MJXc-TeX-main-R">|</span></span></span></span><span class="mjx-mo MJXc-space3" id="MJXc-Node-39"><span class="mjx-char MJXc-TeX-main-R">≤</span></span><span class="mjx-mn MJXc-space3" id="MJXc-Node-40"><span style="padding-top: 0.39em;" class="mjx-char MJXc-TeX-main-R">1</span></span></span></span></span>.  In his talk, Ravi showed us the main ideas Holzman and he used to improve the bound to  13/32.<br /><br />Computational effects model the interaction of computer programs with their environment. In his talk, <a href="https://dcc.fceia.unr.edu.ar/~erivas/"> Exequiel Rivas</a>taught us how <a href="https://en.wikipedia.org/wiki/Monad_(category_theory)">monads</a>can be used to capture computational effects (a research programme that started with <a href="https://core.ac.uk/download/pdf/21173011.pdf">Moggi's award-winning work</a>), and then, discussed some attempts to incorporate merging operations in the monadic picture.<br /><br />Two of the short talks were given by Henning A. Úlfarsson and Elli  Anastasiadi. Henning described the work of his group on  a tool, called  the CombSpecSearcher, that automates the methods used by  combinatorialists to prove some of their theorems, The tool is able to  prove results featured in dozens of research papers. Watch this space for updates on its  development and for its successes!<br /><br />Elli Anastasiadi, a PhD student who is already playing an important role  for the centre, gave a clear seven-minute introduction to <a href="https://people.csail.mit.edu/virgi/ipec-survey.pdf">fine-grained complexity</a> and to the notion of <a href="https://en.wikipedia.org/wiki/Fine-grained_reduction">fine-grained reduction</a>.<br /><br />The 2019 Theory Day was well attended, at least by the standards of a  TCS event in Iceland. If all goes well, we'll be back next year.</div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2019/05/ice-tcs-theory-day-2019.html"><span class="datestr">at May 12, 2019 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/069">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/069">TR19-069 |  Bounded-depth Frege complexity of Tseitin formulas for all graphs | 

	Artur Riazanov, 

	Dmitry Itsykson, 

	Nicola  Galesi, 

	Anastasia Sofronova</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove that there is a constant $K$ such that \emph{Tseitin} formulas for an undirected graph $G$ requires proofs of 
size $2^{\mathrm{tw}(G)^{\Omega(1/d)}}$ in depth-$d$ Frege systems for $d&lt;\frac{K \log n}{\log \log n}$, where $\tw(G)$ is the treewidth of $G$. This extends  H{\aa}stad recent lower bound for the grid graph to any graph. Furthermore, we prove tightness of our bound up to a multiplicative constant in the top exponent. 
Namely, we show that if a Tseitin formula for a graph $G$ has size $s$, then for all large enough $d$, it has a depth-$d$ Frege proof of size $2^{\mathrm{tw}(G)^{\O(1/d)}} \mathrm{poly}(s)$. 
Through this result we settle the question posed by M. Alekhnovich and A. Razborov  of showing that the class of Tseitin formulas is quasi-automatizable for resolution.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/069"><span class="datestr">at May 12, 2019 09:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15846">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/05/10/making-elections-safe/">Making Elections Safe</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>A new proof that MAJORITY is not in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAC%7D%5E%7B0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{AC}^{0}}" class="latex" title="{\mathsf{AC}^{0}}" />.</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/05/10/making-elections-safe/unknown-121/" rel="attachment wp-att-15848"><img src="https://rjlipton.files.wordpress.com/2019/05/unknown.jpeg?w=600" alt="" class="alignright size-full wp-image-15848" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Rich DeMillo ]</font></td>
</tr>
</tbody>
</table>
<p>
Rich DeMillo is a strong leader, a famous researcher, and a long-time best friend. <i>Proof</i>: He was the first CTO at HP and was the Dean of Computing at Georgia Tech; He helped created <a href="https://en.wikipedia.org/wiki/Mutation_testing">mutation</a> a powerful software testing method and did seminal work in complexity theory. The last is clear.</p>
<p>
Today I want to talk about his recent work on voting systems. </p>
<p>
The 2020 election is over a year away, yet it is on our collective minds. People voice concerns everyday on social media, on TV, on cable, in print, everywhere. Their concerns are that our next national election will be compromised. Rich has turned his concern into activism: he is working hard to make elections trusted in general and the 2020 election in particular. </p>
<p>
Rich is scheduled to give a talk this coming Monday, May 13, at Georgia Tech. I wish I could be there, but cannot. I do plan to watch the video of his presentation—see <a href="https://www.cc.gatech.edu/calendar/day/2019/05/13/15151">here</a>. The talk is based on his recent <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=3375755">paper</a> joint with Andrew Appel and Philip Stark titled, “Ballot-Marking devices (BMDs) cannot assure the will of the voters.” As an aside, their paper (ADS) has already generated measurable interest—it’s been downloaded over <img src="https://s0.wp.com/latex.php?latex=%7B300%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{300}" class="latex" title="{300}" /> times and viewed over <img src="https://s0.wp.com/latex.php?latex=%7B5%2C000%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5,000}" class="latex" title="{5,000}" /> times.</p>
<p>
</p><p></p><h2> What Makes A Good Election? </h2><p></p>
<p></p><p>
There are several criterion that a “good” election should have. </p>
<ul>
<li>
<i>During the voting</i>: Only eligible voters can vote. <p></p>
</li><li>
<i>During the tabulation</i>: Each voter gets exactly one vote. <p></p>
</li><li>
<i>After the election</i>: Each vote remains secret.
</li></ul>
<p>
Rich says in his talk abstract: </p>
<blockquote><p><b> </b> <em> Many people believe that, in an Internet-enabled world, secure, safe voting should be easy to achieve. For example, using known cryptographically secure protocols (maybe even blockchains), a secure website might be developed to relieve voters of the burden of driving to a polling place on election day. </em>
</p></blockquote>
<p></p><p>
This belief is wrong. Elections are hard—impossible?—to safeguard. A U.S. national election is the union of about ten thousand local elections. Each has different rules and protocols, which makes safeguarding the national election difficult. </p>
<ul>
<li>
<i>During the voting</i>: Who votes is subject to human decisions? People must prove they are eligible voters. Even computer identification is subject to bias. <p></p>
</li><li>
<i>During the tabulation</i>: Counting is usually a combination of human and computer systems. The former make errors and as do the latter. Computers can have bugs or can be hacked by adversaries. <p></p>
</li><li>
<i>After the election</i>: Since records are usually kept of the voting, they must be safeguarded to avoid disclosing how someone voted.
</li></ul>
<p>
The last point is central. There must be a record of the votes to allow audits after the election is over. We must be able to audit and check that the tabulation was correct. This is the central question that Rich and his co-authors discuss. We will turn to this issue in a moment. </p>
<p>
Before that I note that keeping a vote secret is impossible in an absolute sense. Suppose that you vote “yes” in some district. After the election suppose that the count in that district is made public, as it usually is. Say <img src="https://s0.wp.com/latex.php?latex=%7B61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{61\%}" class="latex" title="{61\%}" /> of the votes were yes. Then clearly information is leaked about how you voted.</p>
<p>
</p><p></p><h2> How Are Votes Recorded? </h2><p></p>
<p></p><p>
There are two main ways to record votes. One method is to have voters hand-mark their ballots, in the old-fashioned way. It is simple, cheap, and not 21st century. Hand-marked ballots can be read by automatic scanners, at least in principle. A difficulty is voters are human and may mark their ballots incorrectly. They may miss a box, or mark two boxes, or make some other mistake. What if the voter is instructed to:</p>
<blockquote><p><b> </b> <em> Select two of the following six choices. </em>
</p></blockquote>
<p></p><p>
There can be other difficulties: Some voters may have special needs and may require instructions to be in a large type font, for example.</p>
<p>
Another recoding method is to have voters use a device to print their paper ballots. These are cleverly called <a href="https://en.wikipedia.org/wiki/Ballot_marking_device">Ballot Marking Devices</a> (BMDs). The name sounds slightly strange to me; there is an alternative name, electronic ballot markers (EBMs).</p>
<p>
The authors, ADS, argue that BMDs are dangerous. Such devices can fail, they argue, and not protect the election. The BMDs rely on software, complex special purpose software, and thus are subject to bugs, errors, mistakes, and to active attacks by adversaries. </p>
<p>
A BMD device takes input from a voter and then prints out a paper ballot. Often the ballot will contain a machine-readable bar code. This is so scanners can more easily read the paper ballots, later. The problem, the danger, is that most voters cannot tell if a bar code is correct or not. An attacker need only have the BMD confirm that you voted say “yes” and print a ballot that says “yes”. Then the attacker has the BMD cheat you by printing a bar code that says “no”. This is a nasty attack, which is hard to stop. The ADS team discusses this and related problems with BDMs. </p>
<p>
<a href="https://rjlipton.wordpress.com/2019/05/10/making-elections-safe/bar/" rel="attachment wp-att-15852"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2019/05/bar.png?w=300&amp;h=147" class="aligncenter size-medium wp-image-15852" height="147" /></a></p>
<p>
</p><p></p><h2> Mathematics and Voting </h2><p></p>
<p></p><p>
Can complexity theory help us design better elections? Unclear. Can election theory help us understand complexity theory? Perhaps.</p>
<p>
</p><p></p><h3> Elections Inform Complexity Theory </h3><p></p>
<p>
</p><blockquote><p><b>Theorem 1</b> <em> The <i>Election Hardness Axiom</i> implies that the MAJORITY function cannot be computed by a polynomial size constant depth Boolean circuit of NOT, AND, and OR gates. </em>
</p></blockquote>
<p></p><p>
That is, the MAJORITY function is not in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAC%7D%5E%7B0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{AC}^{0}}" class="latex" title="{\mathsf{AC}^{0}}" />. What is the Election Hardness Axiom? It is the empirical fact that there is no practical way to compute who won an election. The MAJORITY function is the tabulation of votes: The outcome of an election is the same as computing the MAJORITY function of the votes—“yes” is a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> and “no” is a <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />.</p>
<p>
Okay we are kidding. But not completely. Suppose that MAJORITY function were in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAC%7D%5E%7B0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{AC}^{0}}" class="latex" title="{\mathsf{AC}^{0}}" />. Then a series of decisions of the form:</p>
<blockquote><p><b> </b> <em> The tabulators have looked at the following ballots <img src="https://s0.wp.com/latex.php?latex=%7BB_%7B1%7D%2C%5Cdots%2CB_%7Bm%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{B_{1},\dots,B_{m}}" class="latex" title="{B_{1},\dots,B_{m}}" /> and we agree that there is a “yes” vote in ballot <img src="https://s0.wp.com/latex.php?latex=%7BB_%7Bi%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{B_{i}}" class="latex" title="{B_{i}}" />. </em>
</p></blockquote>
<p>
</p><p></p><h3> Complexity Informs Elections </h3><p></p>
<p></p><p>
Rich, in his talk abstract, states that it is unlikely that crypto theory could be used to create trusted elections. His reason is voters will not trust elections that rely on crypto results. I agree. But I wonder if ideas from theory could be useful. Here are two high-level thoughts.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> There is a vast literature on computing in the presence of faults. Usually “faults” are thought to occur at the nano level: the faults are due to hiccups in electronics. What if the faults came from errors in the counting of votes? What if the faults were at the macro level? That is at the level of human decisions? Perhaps we will revisit this in the future.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> There is a vast literature on computing as a “game”. An election is usually viewed as being run by some trusted party. This could be replaced by assuming that the election is a game. Imagine two parties D and R. As the tabulation is performed D and R can challenge each other. They interact as in game. Could this help make the election trusted? Perhaps we will revisit this too in the future.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Can we elections be trusted? Can we formalize the connection between election and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAC%7D%5E%7B0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{AC}^{0}}" class="latex" title="{\mathsf{AC}^{0}}" />? Could this connect be useful? Can theory help with future elections?</p>
<p></p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/05/10/making-elections-safe/"><span class="datestr">at May 10, 2019 12:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17447">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/05/10/sansation-in-the-morning-news-yaroslav-shitov-counterexamples-to-hedetniemis-conjecture/">A sensation in the morning news –  Yaroslav Shitov: Counterexamples to Hedetniemi’s conjecture.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Two days ago Nati Linial sent me an email entitled “A sensation in the morning news”. The link was to a new arXived paper by Yaroslav Shitov:<a href="https://arxiv.org/abs/1905.02167"> Counterexamples to Hedetniemi’s conjecture</a>.</p>
<p><a href="https://en.wikipedia.org/wiki/Hedetniemi%27s_conjecture">Hedetniemi’s 1966 conjecture</a> asserts that if <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> and <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> are two graphs, then the chromatic number of their tensor product <img src="https://s0.wp.com/latex.php?latex=G+%5Ctimes+H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G \times H" class="latex" title="G \times H" /> equals the minimum of their individual chromatic numbers.  Here, the vertex set of <img src="https://s0.wp.com/latex.php?latex=G+%5Ctimes+H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G \times H" class="latex" title="G \times H" /> is the Cartesian product of <img src="https://s0.wp.com/latex.php?latex=V%28G%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V(G)" class="latex" title="V(G)" /> and <img src="https://s0.wp.com/latex.php?latex=V%28H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V(H)" class="latex" title="V(H)" /> and two vertices <img src="https://s0.wp.com/latex.php?latex=%28g_1%2Ch_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(g_1,h_1)" class="latex" title="(g_1,h_1)" /> and <img src="https://s0.wp.com/latex.php?latex=%28g_2%2Ch_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(g_2,h_2)" class="latex" title="(g_2,h_2)" /> are adjacent if <img src="https://s0.wp.com/latex.php?latex=g_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_1" class="latex" title="g_1" /> is adjacent to <img src="https://s0.wp.com/latex.php?latex=g_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_2" class="latex" title="g_2" /> and  <img src="https://s0.wp.com/latex.php?latex=h_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_1" class="latex" title="h_1" /> is adjacent to <img src="https://s0.wp.com/latex.php?latex=h_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_2" class="latex" title="h_2" />. (mistake corrected.) Every coloring of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> induces a coloring  of <img src="https://s0.wp.com/latex.php?latex=G+%5Ctimes+H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G \times H" class="latex" title="G \times H" />, and so is every coloring of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />.  Therefore, <img src="https://s0.wp.com/latex.php?latex=%5Cchi+%28G+%5Ctimes+H%29+%5Cle+%5Cmin+%28%5Cchi+%28G%29%2C+%5Cchi+%28H%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\chi (G \times H) \le \min (\chi (G), \chi (H))" class="latex" title="\chi (G \times H) \le \min (\chi (G), \chi (H))" />. Hedetniemi conjectured that equality always hold and this is now refuted by  by Yaroslav Shitov.</p>
<p>The example and the entire proof are quite short (the entire paper is less than 3 pages; It is a bit densely-written).</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/05/js.png"><img src="https://gilkalai.files.wordpress.com/2019/05/js.png?w=640" alt="" class="alignnone size-full wp-image-17450" /></a></p>
<p><span style="color: #ff0000;"><strong> Yaroslav Shitov </strong></span></p>
<p>To tell you what the construction is, I need two important definitions.  The first  is the notion of the exponential graph <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D_c%28H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\cal E}_c(H)" class="latex" title="{\cal E}_c(H)" />.</p>
<p>The exponential graph  <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D_c%28H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\cal E}_c(H)" class="latex" title="{\cal E}_c(H)" /> arose in the study of Hedetniemi’s conjecture in a 1985 paper by El-Zahar and Sauer. The vertices of <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D_c%28H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\cal E}_c(H)" class="latex" title="{\cal E}_c(H)" /> are all maps from <img src="https://s0.wp.com/latex.php?latex=V%28H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V(H)" class="latex" title="V(H)" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C2%2C%5Cdots%2Cc%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{1,2,\dots,c\}" class="latex" title="\{1,2,\dots,c\}" />. Two maps <img src="https://s0.wp.com/latex.php?latex=%5Cphi%2C+%5Cpsi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi, \psi" class="latex" title="\phi, \psi" /> are adjacent if whenever <img src="https://s0.wp.com/latex.php?latex=v%2Cu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v,u" class="latex" title="v,u" /> are adjacent vertices of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> then <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28u%29+%5Cne+%5Cpsi+%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi(u) \ne \psi (v)" class="latex" title="\phi(u) \ne \psi (v)" />.  <a href="https://link.springer.com/article/10.1007/BF02579374">El-Zahar and Sauer showed</a> that importance of the case  that <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is a graph and <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is an exponential graph of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> for Hedetniemi’s conjecture. (The entire conjecture reduces to this case.) It is thus crucial to study  coloring of exponential graphs which is the subject of the three claims of Section 1 of Shitov’s paper.</p>
<p>The second definition is another important notion of product of graphs: <a href="https://en.wikipedia.org/wiki/Strong_product_of_graphs">The strong product <i>G</i> ⊠ <i>H </i>of two graphs <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> and <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />.</a> The set of vertices is again the Cartesian product of the two sets of vertices. This time,  <img src="https://s0.wp.com/latex.php?latex=%28g_1%2Ch_1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(g_1,h_1)" class="latex" title="(g_1,h_1)" /> and <img src="https://s0.wp.com/latex.php?latex=%28g_2%2Ch_2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(g_2,h_2)" class="latex" title="(g_2,h_2)" /> are adjacent in <i>G</i> ⊠ <i>H</i> if either</p>
<p>(a) <img src="https://s0.wp.com/latex.php?latex=g_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_1" class="latex" title="g_1" /> is adjacent to <img src="https://s0.wp.com/latex.php?latex=g_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_2" class="latex" title="g_2" /> and  <img src="https://s0.wp.com/latex.php?latex=h_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_1" class="latex" title="h_1" /> is adjacent to <img src="https://s0.wp.com/latex.php?latex=h_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_2" class="latex" title="h_2" /></p>
<p>OR</p>
<p>(b) <img src="https://s0.wp.com/latex.php?latex=g_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_1" class="latex" title="g_1" /> is adjacent to <img src="https://s0.wp.com/latex.php?latex=g_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_2" class="latex" title="g_2" /> and  <img src="https://s0.wp.com/latex.php?latex=h_1+%3D+h_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_1 = h_2" class="latex" title="h_1 = h_2" /> or <img src="https://s0.wp.com/latex.php?latex=g_1+%3Dg_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_1 =g_2" class="latex" title="g_1 =g_2" /> and  <img src="https://s0.wp.com/latex.php?latex=h_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_1" class="latex" title="h_1" /> is adjacent to <img src="https://s0.wp.com/latex.php?latex=h_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_2" class="latex" title="h_2" /></p>
<p>(The edges of condition (a) are the edges of the <em>tensor product</em> of the two graphs and the edges of condition (b) are the edges of the <em>Cartesian product</em> of the two graphs.)</p>
<p>For Shitov’s counterexample given in Section 2 of his paper, <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is the strong product of a graph <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> with girth at least 10 and fractional chromatic number at least 4.1 with a large clique of size <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" />. The second graph <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is the exponential graph <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D_c%28H%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\cal E}_c(H)" class="latex" title="{\cal E}_c(H)" />. Put <img src="https://s0.wp.com/latex.php?latex=c+%3D%5Clceil+4.1q+%5Crceil&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c =\lceil 4.1q \rceil" class="latex" title="c =\lceil 4.1q \rceil" />.  Shitov shows that when <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" /> is sufficiently large then  the chromatic number of both <img src="https://s0.wp.com/latex.php?latex=H%2CG&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H,G" class="latex" title="H,G" /> is <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />,  but the chromatic number of their tensor product is smaller than <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />.</p>
<p><span style="color: #ff0000;"> (Have a look also at Yaroslav’s other <a href="https://arxiv.org/search/advanced?advanced=&amp;terms-0-operator=AND&amp;terms-0-term=Shitov&amp;terms-0-field=author&amp;classification-physics_archives=all&amp;classification-include_cross_list=include&amp;date-filter_by=all_dates&amp;date-year=&amp;date-from_date=&amp;date-to_date=&amp;date-date_type=submitted_date&amp;abstracts=show&amp;size=50&amp;order=-announced_date_first">arXived papers</a>! )</span></p>
<h3>Finite and infinite combinatorics</h3>
<p>Let me make one more remark. (See the <a href="https://en.wikipedia.org/wiki/Hedetniemi%27s_conjecture">Wikipedea article</a>.) The infinite version of Hedetniemi’s conjecture was known to be false.  Hajnal (1985) gave an example of two infinite graphs, each requiring an uncountable number of colors, such that their product can be colored with only countably many colors. Rinot (2013) proved that in the <a href="https://en.wikipedia.org/wiki/Constructible_universe" title="Constructible universe">constructible universe</a>, for every infinite cardinal <span class="mwe-math-element"><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/54ddec2e922c5caea4e47d04feef86e782dc8e6d" alt="\kappa " class="mwe-math-fallback-image-inline" /></span>, there exist a pair of graphs of chromatic number greater than <span class="mwe-math-element"><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/54ddec2e922c5caea4e47d04feef86e782dc8e6d" alt="\kappa " class="mwe-math-fallback-image-inline" /></span>, such that their product can still be colored with only countably many colors. (<a href="https://arxiv.org/pdf/1307.6841.pdf">Here is the paper</a>.) Is there a relation between the finite case and the infinite case? (Both theories are quite exciting but direct connections are rare. A rare statement where the same proof applies for the finite and infinite case is the inequality <img src="https://s0.wp.com/latex.php?latex=2%5En%3En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n&gt;n" class="latex" title="2^n&gt;n" />.</p>
<h3>More information</h3>
<p>Here is a link to a survey article by Claude Tardif, (2008), <a href="http://www.mast.queensu.ca/~ctardif/articles/gtn5406rp.pdf" class="external text" rel="nofollow">“Hedetniemi’s conjecture, 40 years later”</a> .</p>
<p>A few more thing worth knowing:</p>
<p>1) The weak version of the conjecture that asserts that If <img src="https://s0.wp.com/latex.php?latex=%5Cchi+%28G%29%3D+%5Cchi+%28H%29%29%3Dn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\chi (G)= \chi (H))=n" class="latex" title="\chi (G)= \chi (H))=n" />, then <img src="https://s0.wp.com/latex.php?latex=%5Cchi+%28G+%5Ctimes+H%29+%5Cge+f%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\chi (G \times H) \ge f(n)" class="latex" title="\chi (G \times H) \ge f(n)" /> where <img src="https://s0.wp.com/latex.php?latex=f%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(n)" class="latex" title="f(n)" /> tends to infinity with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> is still open.</p>
<p>2)  Xuding Zhu proved in 2011 that <a href="https://www.sciencedirect.com/science/article/pii/S0195669811000552">the fractional version of the conjecture is correct</a>,</p>
<p>3) The directed version of the conjecture was known to be false (Poljak and Rodl, 1981).</p>
<p>4) The conjecture is part of a rich and beautiful theory of graph homomorphisms (and the category of graphs) that I hope to come back to in another post.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/05/10/sansation-in-the-morning-news-yaroslav-shitov-counterexamples-to-hedetniemis-conjecture/"><span class="datestr">at May 10, 2019 12:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
