<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="https://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="http://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://scottaaronson.blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at November 05, 2021 03:39 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/11/04/faculty-at-university-of-haifa-at-oranim-college-apply-by-december-31-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/11/04/faculty-at-university-of-haifa-at-oranim-college-apply-by-december-31-2021/">Faculty at University of Haifa at Oranim College (apply by December 31, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Mathematics-Physics-Computer Science of the University of Haifa at Oranim College invites applications for a tenure-track faculty position in all areas of Computer Science, to begin October 1st 2022.</p>
<p>Website: <a href="https://mathphys.haifa.ac.il/en/announcements/">https://mathphys.haifa.ac.il/en/announcements/</a><br />
Email: ackerman@sci.haifa.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/11/04/faculty-at-university-of-haifa-at-oranim-college-apply-by-december-31-2021/"><span class="datestr">at November 04, 2021 01:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-3367673395710171015">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2021/11/hotnets-presentation-zero-cpu.html">HotNets Presentation : Zero-CPU Collection with Direct Telemetry Access</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>HotNets has asked that we let people know that the 2021 presentations <a href="https://www.youtube.com/channel/UCZZ5nf4RNDIIe4nifI8grwQ/videos">are available here</a>.  I'm using that an excuse to highlight our paper on Zero-CPU Collection with Direct Telemetry Access (<a href="https://arxiv.org/abs/2110.05438">arxiv version here</a>), but really I want to highlight the talk by graduate student Jonatan Langlet (Queen Mary University of London) who, as is the nature of graduate students, did all of the real work, and who really did a great job on <a href="https://www.youtube.com/watch?v=_M8AbF_f8Kk&amp;t=2s">the talk (direct link)</a>.  If you guessed from my involvement this involves hashing in some way, your maximum likelihood estimate turns out to be correct.</p><p>I think our work fits the HotNets call, which asks for new approaches and preliminary work.  Specifically, the call for the HotNets workshop says this:</p><p></p><blockquote><p>We invite researchers and practitioners to submit short position papers. We encourage papers that identify fundamental open questions, advocate a new approach, offer a constructive critique of the state of networking research, re-frame or debunk existing work, report unexpected early results from a deployment, report on promising but unproven ideas, or propose new evaluation methods. Novel ideas need not be supported by full evaluations; well-reasoned arguments or preliminary evaluations can support the possibility of the paper’s claims.</p><p>We seek early-stage work, where the authors can benefit from community feedback. An ideal submission has the potential to open a line of inquiry for the community that results in multiple conference papers in related venues (SIGCOMM, NSDI, CoNEXT, SOSP, OSDI, MobiCom, MobiSys, etc.), rather than a single follow-on conference paper. The program committee will explicitly favor early work and papers likely to stimulate reflection and discussion over “conference papers in miniature”.</p></blockquote><p>There are similar other "Hot" workshops in other areas, and it was about <a href="http://mybiasedcoin.blogspot.com/2007/08/hottheory-workshop.html">14 years ago that I asked whether CS theory should have a HotTheory workshop</a>.  There's been a proliferation of new conferences and workshops in theory since then, but none of them really seem to have this flavor.  So maybe it's worth asking again whether a HotTheory workshop would make sense?  Or do existing theory events meet the theory community needs?</p><p></p><p><br /></p></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2021/11/hotnets-presentation-zero-cpu.html"><span class="datestr">at November 04, 2021 01:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/11/04/lecturer-in-theoretical-computer-science-sheffield-uk-at-university-of-sheffield-apply-by-november-16-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/11/04/lecturer-in-theoretical-computer-science-sheffield-uk-at-university-of-sheffield-apply-by-november-16-2021/">Lecturer in Theoretical Computer Science, Sheffield (UK) at University of Sheffield (apply by November 16, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The University of Sheffield has an opening for a Lecturer in Theoretical Computer Science. Researchers in the area of computational complexity, where the interests of the Algorithms and Verification groups in the Department overlap, are particularly encouraged to apply.</p>
<p>Website: <a href="https://www.jobs.ac.uk/job/CKB031/lecturer-in-theoretical-computer-science">https://www.jobs.ac.uk/job/CKB031/lecturer-in-theoretical-computer-science</a><br />
Email: g.j.brown@sheffield.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/11/04/lecturer-in-theoretical-computer-science-sheffield-uk-at-university-of-sheffield-apply-by-november-16-2021/"><span class="datestr">at November 04, 2021 12:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/11/04/professor-associate-professor-assistant-professor-at-george-washington-university-apply-by-december-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/11/04/professor-associate-professor-assistant-professor-at-george-washington-university-apply-by-december-1-2021/">Professor, Associate Professor, Assistant Professor at George Washington University (apply by December 1, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>We invite applications to multiple faculty positions at all ranks. Our search is focused on machine learning; artificial intelligence; computer and distributed systems; security and privacy; and candidates that can support our multidisciplinary initiatives in Smart and Trustworthy Systems and Meaningful Computing, broadly defined.</p>
<p>Website: <a href="https://www.gwu.jobs/postings/87400">https://www.gwu.jobs/postings/87400</a><br />
Email: cssearch@gwu.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/11/04/professor-associate-professor-assistant-professor-at-george-washington-university-apply-by-december-1-2021/"><span class="datestr">at November 04, 2021 02:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2021/11/04/perceptron/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2021/11/04/perceptron/">The Perceptron as a prototype for machine learning theory.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Just as many of the algorithms and community practices of machine learning were invented <a href="http://www.argmin.net/2021/10/20/highleyman/">in the late 1950s and early 1960s</a>, the foundations of machine learning theory were also established during this time. Many of the analyses of this period were strikingly simple, had surprisingly precise constants, and provided prescient guidelines for contemporary machine learning practice. Here, I’ll summarize the study of the Perceptron, highlighting both its algorithmic and statistical analyses, and using it as a prototype to illustrate further how prediction deviates from the umbrella of classical statistics.</p>

<p>Let’s begin with a classification problem where each individual from some population has a feature vector $x$ and an associated binary label $y$ that we take as valued $\pm 1$ for notational convenience. The goal of the Perceptron is to find a linear separator such that $\langle w, x \rangle&gt;0$ for when $y=1$ and $\langle w, x \rangle&lt;0$ when $y=-1$. We can write this compactly as saying that we want to find a $w$ for which $y \langle w, x \rangle &gt;0$ for as many individuals in the population as possible.</p>

<p>Rosenblatt’s Perceptron provides a simple algorithm for finding such a $w$. The Perceptron inputs an example, checks if it makes the correct classification. If yes, it does nothing and proceeds to the next example. If no, the decision boundary is nudged in the direction of classifying the example correctly next time.</p>

<p><strong>Perceptron</strong></p>

<ul>
  <li>Start from the initial solution $w_0=0$</li>
  <li>At each step $t=0,1,2,…$:
    <ul>
      <li>Select an individual from the population and look up their attributes: (x_t,y_t).</li>
      <li>Case 1: If $y_t\langle w_t, x_t\rangle \leq 0$, put
\(w_{t+1} = w_t + y_t x_t\)</li>
      <li>Case 2: Otherwise put $w_{t+1} = w_t$.</li>
    </ul>
  </li>
</ul>

<p>If the examples were selected at random, machine learners would recognize this algorithm as an instance of stochastic gradient descent, still the most ubiquitous way to train classifiers whether they be deep or shallow. Stochastic gradient descent minimizes sums of functions</p>

\[f(w) = \frac{1}{N} \sum_{i=1}^N \mathit{loss}( f(x_i; w) , y_i)\]

<p>with the update</p>

\[w_{t+1} = w_t - \alpha_t \nabla_w \mathit{loss}( f(x_t; w_t) , y_t)\,.\]

<p>When the examples are sampled randomly, the Perceptron is stochastic gradient descent with $\alpha_t=1$, $f(x;w) = \langle w,x \rangle$, and loss function $\mathit{loss}(\hat{y},y) = \max(-\hat{y} y, 0)$.</p>

<p>Stochastic gradient methods were invented a few years before the Perceptron. And the relations between these methods were noted by the mid-60s. Vapnik discusses some of this history in Chapter 1.11 of <a href="https://link.springer.com/book/10.1007/978-1-4757-3264-1"><em>The Nature of Statistical Learning Theory</em></a>.</p>

<p>While we might be tempted to use a standard stochastic gradient analysis to understand the optimization properties of the Perceptron, it turns out that a more rarified proof technique applies that uses no randomization whatsoever. Moreover, the argument will not only bound errors in optimization but also in generalization. Optimization is concerned with errors on a training data set. Generalization is concerned with errors on data we haven’t seen. The analysis from the 1960s links these two by first understanding the dynamics of the algorithm.</p>

<p><a href="https://cs.uwaterloo.ca/~y328yu/classics/novikoff.pdf">A celebrated result by Al Novikoff in 1962</a> showed that under reasonable conditions the algorithm makes a bounded number of updates no matter how large the sample size. Novikoff’s result is typically referred to as a <em>mistake bound</em> as it bounds the number of total misclassifications made when running the Perceptron on some data set. The key assumption in Novikoff’s argument is that the positive and negative examples are cleanly separated by a linear function. People often dismiss the Perceptron because of this <em>separability</em> assumption. But for any finite data set, can always add features and end up with a linearly separable problem. And if we add enough features, we’ll usually be separable no matter how many points we have.</p>

<p>This has been the trend in modern machine learning: don’t fear big models and don’t fear getting zero errors on your training set. This is no different than what was being proposed in the Perceptron. In fact, <a href="https://cs.uwaterloo.ca/~y328yu/classics/kernel.pdf">Aizerman, Braverman, and Roeznoer</a> recognized the power of such overparameterization, and extended Novikoff’s argument to “potential functions” that we now recognize as functions belonging to an infinite dimensional Reproducing Kernel Hilbert Space.</p>

<p>To state Novikoff’s result, we make the following assumptions: First, we assume as input a set of examples $S$. We assume every data point has norm at most $R(S)$ and that there exists a hyperplane that correctly classifies all of the data points and is of distance at least $\gamma(S)$ from every data point. This second assumption is called a <em>margin condition</em> that quantifies how separated the given data is. With these assumptions, Novikoff proved the Perceptron algorithm makes at most</p>

\[{\small
\frac{R(S)^2}{\gamma(S)^{2}}
}\]

<p>mistakes when run on $S$. No matter what the ordering of the data points in $S$, the algorithm makes a bounded number of errors.</p>

<p>The algorithmic analysis of Novikoff has many implications. First, if the data is separable, we can conclude that the Perceptron will terminate if it is run over the data set several times. This is because we can think of $k$ epochs of the Perceptron as running on the union of $k$ distinct copies of $S$, and the Perceptron eventually stops updating when run on this enlarged data set. Hence, the mistake bound tells us something particular about optimization: the Perceptron converges to a solution with zero training errors and hence a global minimizer of the empirical risk.</p>

<p>Second, we can think of the Perceptron algorithm as an <em>online learning algorithm</em>. We need not assume anything distributional about the sequence $S$. We can instead think about how long it takes for the Perceptron to converge to a solution that would have been as good as the optimal classifier. We can quantify this convergence by measuring the <em>regret</em>, equal to</p>

\[\mathcal{R}_T = \sum_{t=1}^T \mathrm{error}(w_t, (x_t,y_t)) - \sum_{t=1}^T \mathrm{error}(w_\star, (x_t,y_t))\,,\]

<p>where $w_\star$ denotes the optimal hyperplane. That is, the regret counts how frequently the classifier at step $t$ misclassifies the next example in the sequence. Novikoff’s argument shows that, if a sequence is perfectly classifiable, then the accrued regret is a constant that does not scale with T.</p>

<p>A third, less well known application of Novikoff’s bound is as a building block for a  <em>generalization bound</em>. A generalization bound estimates the probability of making an error on a new example given that the new example is sampled from the same population as the data thus far sceen. To state the generalization bound for the Perceptron, I <em>now</em> need to return to statistics. Generalization theory concerns statistical validity, and hence we need to define some notion of sampling from the population. I will use the same sampling model I have been using in this blog series. Rather than assuming a statistical model of the population, I will assume we have some population of data from which we can uniformly sample. Our training data will consist of $n$ points sampled uniformly from this population: $S={(x_1,y_1)\ldots, (x_n,y_n) }$.</p>

<p>We know that the Perceptron will find a good linear predictor for the training data if it exists. What we now show is that this predictor also works on new data sampled uniformly from the same population.</p>

<p>To analyze what happens on new data, I will employ an elegant argument I learned from Sasha Rakhlin. This argument appears in a book on Learning Theory by Vapnik and Chervonenkis from 1974, which, to my knowledge, is only available in Russian. Sasha also believes this argument is considerably older as <a href="http://www.mit.edu/~rakhlin/papers/chervonenkis_chapter.pdf">Aizermann and company were making similar “online to batch” constructions in the 1960s</a>. The proof here leverages the assumption that the data are sampled in such a way that they are identically distributed, so we can swap the roles of training and test examples in the analysis. It foreshadows later studies of stability and generalization that would be revisited decades later.</p>

<p><strong>Theorem</strong> <em>Let $w(S)$ be the output of the Perceptron on a dataset $S$ after running until the hyperplane makes no more mistakes on $S$. Let $S_n$ denote a training set of $n$ samples uniformly at random from some population. And let $(x,y)$ be an additional independent uniform sample from the same population. Then, the probability of making a mistake on $(x,y)$ is bounded as</em></p>

\[\Pr[y \langle w(S_n), x \rangle \leq 0] \leq \frac{1}{n+1} {\mathbb{E}}_{S_{n+1}}\left[ \frac{R(S_{n+1})^2}{\gamma(S_{n+1})^2} \right]\,.\]

<p>To prove the theorem, define the “leave-one-out set” to be the set where we drop $(x_k,y_k)$:</p>

\[{\scriptsize
S^{-k}=\{(x_1,y_1),\dots,(x_{k-1},y_{k-1}),(x_{k+1},y_{k+1}),...,(x_{n+1},y_{n+1})\}\,.
}\]

<p>With this notation, since all of the data are sampled identically and independently, we can rewrite the probability of a mistake on the final data point as the expectation of the leave-one-out error</p>

\[{\small
\Pr[y \langle w(S_n), x \rangle   \leq 0]
= \frac1{n+1}\sum_{k=1}^{n+1} \mathbb{E}[\mathbb{1}\{y_k \langle w(S^{-k}), x_k \rangle \leq 0\}]\,.
}\]

<p>Novikoff’s mistake bound asserts the Perceptron makes at most</p>

\[{\small
m=\frac{R(S_{n+1})^2}{\gamma(S_{n+1})^2}
}\]

<p>mistakes when run on the entire sequence $S_{n+1}$. Let $I={i_1,\dots,i_m}$ denote the indices on which the algorithm makes a mistake in any of its cycles over the data. If $k$ is not in $I$, the output of the algorithm remains the same after we remove the $k$-th sample from the sequence. It follows that such $k \in S_{n+1}\setminus I$ satisfy  $y_k w(S^{-k})x_k \geq 0$ and therefore do not contribute to the right hand side of the summation. The other terms can at most contribute $1$ to the summation.
Hence,</p>

\[\Pr[y \langle w(S_n), x \rangle \leq 0] \le \frac{\mathbb{E}[m]}{n+1}\,,\]

<p>which is what we wanted to prove.</p>

<p>What’s most stunning to me about this argument is that there are no numerical constants or logarithms. The generalization error is perfectly quantified by a simple formula of $R$, $\gamma$, and $n$. There are a variety of other arguments that get the $\tilde{O}(R/(n\gamma))$ scaling with far more complex arguments and large constants and logarithmic terms. For example, one can show that the set of hyperplanes in Euclidean space with norm bounded by $\gamma^{-1}$ has <a href="https://www.wiley.com/en-us/Statistical+Learning+Theory-p-9780471030034">VC dimension $R/\gamma$</a>. Similarly, a <a href="https://www.jmlr.org/papers/volume3/bartlett02a/bartlett02a.pdf">Rademacher complexity argument will achieve a similar scaling</a>. These arguments apply to far more algorithms than the Perceptron, but it’s frustrating how this simple algorithm from 1956 gets such a tight bound with such a short argument whereas analyzing more “powerful” algorithms often takes pages of derivations.</p>

<p>It’s remarkable that these bounds on optimization, regret, and generalization worked out in the 1960s all turned out to be optimal for classification theory. This strikes me as particularly odd because when I was in graduate school I was taught that the Perceptron was a failed enterprise. But as fads in AI have come and gone, the role of the Perceptron has remained central for 65 years. We’ve made more progress in machine learning theory since then, but it’s not always at the front of our minds just how long ago we had established our modern learning theory framework.</p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2021/11/04/perceptron/"><span class="datestr">at November 04, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02361">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02361">Augmenting Edge Connectivity via Isolating Cuts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cen:Ruoxu.html">Ruoxu Cen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jason.html">Jason Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panigrahi:Debmalya.html">Debmalya Panigrahi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02361">PDF</a><br /><b>Abstract: </b>We give an algorithm for augmenting the edge connectivity of an undirected
graph by using the isolating cuts framework (Li and Panigrahi, FOCS '20). Our
algorithm uses poly-logarithmic calls to any max-flow algorithm, which yields a
running time of $\tilde O(m + n^{3/2})$ and improves on the previous best time
of $\tilde O(n^2)$ (Bencz\'ur and Karger, SODA '98) for this problem. We also
obtain an identical improvement in the running time of the closely related edge
splitting off problem in undirected graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02361"><span class="datestr">at November 04, 2021 10:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02336">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02336">An Improved Algorithm for The $k$-Dyck Edit Distance Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Dvir Fried, Shay Golan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kociumaka:Tomasz.html">Tomasz Kociumaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopelowitz:Tsvi.html">Tsvi Kopelowitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porat:Ely.html">Ely Porat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Starikovskaya:Tatiana.html">Tatiana Starikovskaya</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02336">PDF</a><br /><b>Abstract: </b>A Dyck sequence is a sequence of opening and closing parentheses (of various
types) that is balanced. The Dyck edit distance of a given sequence of
parentheses $S$ is the smallest number of edit operations (insertions,
deletions, and substitutions) needed to transform $S$ into a Dyck sequence. We
consider the threshold Dyck edit distance problem, where the input is a
sequence of parentheses $S$ and a positive integer $k$, and the goal is to
compute the Dyck edit distance of $S$ only if the distance is at most $k$, and
otherwise report that the distance is larger than $k$. Backurs and Onak
[PODS'16] showed that the threshold Dyck edit distance problem can be solved in
$O(n+k^{16})$ time.
</p>
<p>In this work, we design new algorithms for the threshold Dyck edit distance
problem which costs $O(n+k^{4.782036})$ time with high probability or
$O(n+k^{4.853059})$ deterministically. Our algorithms combine several new
structural properties of the Dyck edit distance problem, a refined algorithm
for fast $(\min,+)$ matrix product, and a careful modification of ideas used in
Valiant's parsing algorithm.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02336"><span class="datestr">at November 04, 2021 10:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02318">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02318">Nearly Tight Lower Bounds for Succinct Range Minimum Query</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Mingmou.html">Mingmou Liu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02318">PDF</a><br /><b>Abstract: </b>Given an array of distinct integers $A[1\ldots n]$, the Range Minimum Query
(RMQ) problem requires us to construct a data structure from $A$, supporting
the RMQ query: given an interval $[a,b]\subseteq[1,n]$, return the index of the
minimum element in subarray $A[a\ldots b]$, i.e. return
$\text{argmin}_{i\in[a,b]}A[i]$. The fundamental problem has a long history.
The textbook solution which uses $O(n)$ words of space and $O(1)$ time by
Gabow, Bentley, Tarjan (STOC 1984) and Harel, Tarjan (SICOMP 1984) dates back
to 1980s. The state-of-the-art solution is presented by Fischer, Heun (SICOMP
2011) and Navarro, Sadakane (TALG 2014). The solution uses
$2n+n/\left(\frac{\log n}{t}\right)^t+\tilde{O}(n^{3/4})$ bits of space and
$O(t)$ query time, assuming the word-size is $\Theta(\log n)$ bits. On the
other hand, the only known lower bound is proven by Liu and Yu (STOC 2020).
They show that any data structure which solves RMQ in $t$ query time must use
$2n+n/(\log n)^{O(t^2\log^2t)}$ bits of space, assuming the word-size is
$\Theta(\log n)$ bits.
</p>
<p>In this paper, we prove nearly tight lower bound for this problem. We show
that, for any data structure which solves RMQ in $t$ query time, $2n+n/(\log
n)^{O(t\log^2t)}$ bits of space is necessary in the cell-probe model with
word-size $\Theta(\log n)$. We emphasize that, for any $r$, we present a lower
bound of $t=\Omega(t_{opt}/\log^3 t_{opt})$, where $t_{opt}$ is the optimal
time cost when the data structure is allowed to consume $2n+r$ bits of space.
Hence our lower bound is nearly tight.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02318"><span class="datestr">at November 04, 2021 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02296">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02296">On polynomially many queries to NP or QMA oracles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gharibian:Sevag.html">Sevag Gharibian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rudolph:Dorian.html">Dorian Rudolph</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02296">PDF</a><br /><b>Abstract: </b>We study the complexity of problems solvable in deterministic polynomial time
with access to an NP or Quantum Merlin-Arthur (QMA)-oracle, such as $P^{NP}$
and $P^{QMA}$, respectively. The former allows one to classify problems more
finely than the Polynomial-Time Hierarchy (PH), whereas the latter
characterizes physically motivated problems such as Approximate Simulation
(APX-SIM) [Ambainis, CCC 2014]. In this area, a central role has been played by
the classes $P^{NP[\log]}$ and $P^{QMA[\log]}$, defined identically to $P^{NP}$
and $P^{QMA}$, except that only logarithmically many oracle queries are
allowed. Here, [Gottlob, FOCS 1993] showed that if the adaptive queries made by
a $P^{NP}$ machine have a "query graph" which is a tree, then this computation
can be simulated in $P^{NP[\log]}$.
</p>
<p>In this work, we first show that for any verification class
$C\in\{NP,MA,QCMA,QMA,QMA(2),NEXP,QMA_{\exp}\}$, any $P^C$ machine with a query
graph of "separator number" $s$ can be simulated using deterministic time
$\exp(s\log n)$ and $s\log n$ queries to a $C$-oracle. When $s\in O(1)$ (which
includes the case of $O(1)$-treewidth, and thus also of trees), this gives an
upper bound of $P^{C[\log]}$, and when $s\in O(\log^k(n))$, this yields bound
$QP^{C[\log^{k+1}]}$ (QP meaning quasi-polynomial time). We next show how to
combine Gottlob's "admissible-weighting function" framework with the
"flag-qubit" framework of [Watson, Bausch, Gharibian, 2020], obtaining a
unified approach for embedding $P^C$ computations directly into APX-SIM
instances in a black-box fashion. Finally, we formalize a simple no-go
statement about polynomials (c.f. [Krentel, STOC 1986]): Given a multi-linear
polynomial $p$ specified via an arithmetic circuit, if one can "weakly
compress" $p$ so that its optimal value requires $m$ bits to represent, then
$P^{NP}$ can be decided with only $m$ queries to an NP-oracle.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02296"><span class="datestr">at November 04, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02295">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02295">The Parameterized Complexity of the Survivable Network Design Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukherjee:Anish.html">Anish Mukherjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leeuwen:Erik_Jan_van.html">Erik Jan van Leeuwen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02295">PDF</a><br /><b>Abstract: </b>For the well-known Survivable Network Design Problem (SNDP) we are given an
undirected graph $G$ with edge costs, a set $R$ of terminal vertices, and an
integer demand $d_{s,t}$ for every terminal pair $s,t\in R$. The task is to
compute a subgraph $H$ of $G$ of minimum cost, such that there are at least
$d_{s,t}$ disjoint paths between $s$ and $t$ in $H$. If the paths are required
to be edge-disjoint we obtain the edge-connectivity variant (EC-SNDP), while
internally vertex-disjoint paths result in the vertex-connectivity variant
(VC-SNDP). Another important case is the element-connectivity variant
(LC-SNDP), where the paths are disjoint on edges and non-terminals.
</p>
<p>In this work we shed light on the parameterized complexity of the above
problems. We consider several natural parameters, which include the solution
size $\ell$, the sum of demands $D$, the number of terminals $k$, and the
maximum demand $d_\max$. Using simple, elegant arguments, we prove the
following results.
</p>
<p>- We give a complete picture of the parameterized tractability of the three
variants w.r.t. parameter $\ell$: both EC-SNDP and LC-SNDP are FPT, while
VC-SNDP is W[1]-hard.
</p>
<p>- We identify some special cases of VC-SNDP that are FPT:
</p>
<p>* when $d_\max\leq 3$ for parameter $\ell$,
</p>
<p>* on locally bounded treewidth graphs (e.g., planar graphs) for parameter
$\ell$, and
</p>
<p>* on graphs of treewidth $tw$ for parameter $tw+D$.
</p>
<p>- The well-known Directed Steiner Tree (DST) problem can be seen as
single-source EC-SNDP with $d_\max=1$ on directed graphs, and is FPT
parameterized by $k$ [Dreyfus &amp; Wagner 1971]. We show that in contrast, the
2-DST problem, where $d_\max=2$, is W[1]-hard, even when parameterized by
$\ell$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02295"><span class="datestr">at November 04, 2021 10:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02291">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02291">Physarum Inspired Dynamics to Solve Semi-Definite Programs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Hamidreza Kamkari, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karrenbauer:Andreas.html">Andreas Karrenbauer</a>, Mohammadamin Sharifi <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02291">PDF</a><br /><b>Abstract: </b>Physarum Polycephalum is a Slime mold that can solve the shortest path
problem. A mathematical model based on the Physarum's behavior, known as the
Physarum Directed Dynamics, can solve positive linear programs. In this paper,
we will propose a Physarum based dynamic based on the previous work and
introduce a new way to solve positive Semi-Definite Programming (SDP) problems,
which are more general than positive linear programs. Empirical results suggest
that this extension of the dynamic can solve the positive SDP showing that the
nature-inspired algorithm can solve one of the hardest problems in the
polynomial domain. In this work, we will formulate an accurate algorithm to
solve positive and some non-negative SDPs and formally prove some key
characteristics of this solver thus inspiring future work to try and refine
this method.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02291"><span class="datestr">at November 04, 2021 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02277">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02277">Counting Small Induced Subgraphs with Hereditary Properties</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Focke:Jacob.html">Jacob Focke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roth:Marc.html">Marc Roth</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02277">PDF</a><br /><b>Abstract: </b>We study the computational complexity of the problem $\#\text{IndSub}(\Phi)$
of counting $k$-vertex induced subgraphs of a graph $G$ that satisfy a graph
property $\Phi$. Our main result establishes an exhaustive and explicit
classification for all hereditary properties, including tight conditional lower
bounds under the Exponential Time Hypothesis (ETH):
</p>
<p>- If a hereditary property $\Phi$ is true for all graphs, or if it is true
only for finitely many graphs, then $\#\text{IndSub}(\Phi)$ is solvable in
polynomial time.
</p>
<p>- Otherwise, $\#\text{IndSub}(\Phi)$ is $\#\mathsf{W[1]}$-complete when
parameterised by $k$, and, assuming ETH, it cannot be solved in time $f(k)\cdot
|G|^{o(k)}$ for any function $f$.
</p>
<p>This classification features a wide range of properties for which the
corresponding detection problem (as classified by Khot and Raman [TCS 02]) is
tractable but counting is hard. Moreover, even for properties which are already
intractable in their decision version, our results yield significantly stronger
lower bounds for the counting problem. As additional result, we also present an
exhaustive and explicit parameterised complexity classification for all
properties that are invariant under homomorphic equivalence. By covering one of
the most natural and general notions of closure, namely, closure under
vertex-deletion (hereditary), we generalise some of the earlier results on this
problem. For instance, our results fully subsume and strengthen the existing
classification of $\#\text{IndSub}(\Phi)$ for monotone (subgraph-closed)
properties due to Roth, Schmitt, and Wellnitz [FOCS 20].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02277"><span class="datestr">at November 04, 2021 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02234">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02234">Approximation Algorithms for Vertex-Connectivity Augmentation on the Cycle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=aacute=lvez:Waldo.html">Waldo Gálvez</a>, Francisco Sanhueza-Matamala, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soto:Jos=eacute=_A=.html">José A. Soto</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02234">PDF</a><br /><b>Abstract: </b>Given a $k$-vertex-connected graph $G$ and a set $S$ of extra edges (links),
the goal of the $k$-vertex-connectivity augmentation problem is to find a set
$S' \subseteq S$ of minimum size such that adding $S'$ to $G$ makes it
$(k+1)$-vertex-connected. Unlike the edge-connectivity augmentation problem,
research for the vertex-connectivity version has been sparse.
</p>
<p>In this work we present the first polynomial time approximation algorithm
that improves the known ratio of 2 for $2$-vertex-connectivity augmentation,
for the case in which $G$ is a cycle. This is the first step for attacking the
more general problem of augmenting a $2$-connected graph.
</p>
<p>Our algorithm is based on local search and attains an approximation ratio of
$1.8704$. To derive it, we prove novel results on the structure of minimal
solutions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02234"><span class="datestr">at November 04, 2021 10:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02200">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02200">The Algorithmic Complexity of Tree-Clique Width</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Chris Aronis <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02200">PDF</a><br /><b>Abstract: </b>Tree-width has been proven to be a useful parameter to design fast and
efficient algorithms for intractable problems. However, while tree-width is low
on relatively sparse graphs can be arbitrary high on dense graphs. Therefore,
we introduce tree-clique width, denoted by $tcl(G)$ for a graph $G$, a new
width measure for tree decompositions. The main aim of such a parameter is to
extend the algorithmic gains of tree-width on more structured and dense graphs.
In this paper, we show that tree-clique width is NP-complete and that there is
no constant-factor approximation algorithm for any constant value $c$. We also
provide algorithms to compute tree-clique width for general graphs and for
special graphs such as cographs and permutation graphs. We seek to understand
further tree-clique width and its properties and to research whether it can be
used as an alternative where tree-width fails.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02200"><span class="datestr">at November 04, 2021 10:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02138">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02138">Effective guessing has unlikely consequences</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salamon:Andr=aacute=s_Z=.html">András Z. Salamon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wehar:Michael.html">Michael Wehar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02138">PDF</a><br /><b>Abstract: </b>A classic result of Paul, Pippenger, Szemer\'edi and Trotter states that
DTIME(n) is strictly contained in NTIME(n). The natural question then arises:
could DTIME(t(n)) be contained in NTIME(n) for some superlinear
time-constructible function t(n)? If such a function t(n) does exist, then
there also exist effective nondeterministic guessing strategies to speed up
deterministic computations. In this work, we prove limitations on the
effectiveness of nondeterministic guessing to speed up deterministic
computations by showing that the existence of effective nondeterministic
guessing strategies would have unlikely consequences. In particular, we show
that if a subpolynomial amount of nondeterministic guessing could be used to
speed up deterministic computation by a polynomial factor, then P is strictly
contained in NTIME(n). Furthermore, even achieving a logarithmic speedup at the
cost of making every step nondeterministic would show that SAT is in NTIME(n)
under appropriate encodings. Of possibly independent interest, under such
encodings we also show that SAT can be decided in O(n lg n) steps on a
nondeterministic multitape Turing machine, improving on the well-known O(n(lg
n)^c) bound for some constant but undetermined exponent c which is at least 1.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02138"><span class="datestr">at November 04, 2021 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02125">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02125">Average complexity of matrix reduction for clique filtrations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giunti:Barbara.html">Barbara Giunti</a>, Guillaume Houry, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kerber:Michael.html">Michael Kerber</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02125">PDF</a><br /><b>Abstract: </b>We study the algorithmic complexity of computing persistent homology of a
randomly chosen filtration. Specifically, we prove upper bounds for the average
fill-up (number of non-zero entries) of the boundary matrix on Erd\"os-Renyi
filtrations and Vietoris-Rips filtration after matrix reduction. Our bounds
show that, in both cases, the reduced matrix is expected to be significantly
sparser than what the general worst-case predicts. Our bounds are based on
previous results on the expected first Betti numbers of corresponding
complexes. We establish a link between these results to the fill-up of the
boundary matrix. Our bound forVietoris-Rips complexes is asymptotically tight
up to logarithmic factors
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02125"><span class="datestr">at November 04, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02052">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02052">Efficient algorithms for optimization problems involving distances in a point set</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Katz:Matthew_J=.html">Matthew J. Katz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharir:Micha.html">Micha Sharir</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02052">PDF</a><br /><b>Abstract: </b>We present a general technique, based on parametric search with some twist,
for solving a variety of optimization problems on a set of points in the plane
or in higher dimensions. These problems include (i) the reverse shortest path
problem in unit-disk graphs, recently studied by Wang and Zhao, (ii) the same
problem for weighted unit-disk graphs, with a decision procedure recently
provided by Wang and Xue, (iii) extensions of these problems to three and
higher dimensions, (iv) the discrete Fr\'echet distance with one-sided
shortcuts in higher dimensions, extending the study by Ben Avraham et al., and
(v) the maximum-height independent towers problem, in which we want to erect
vertical towers of maximum height over a 1.5-dimensional terrain so that no
pair of tower tips are mutually visible. We obtain significantly improved
solutions for problems (i) and (ii), and new efficient solutions to problems
(iii), (iv) and (v), which do not appear to have been studied earlier.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02052"><span class="datestr">at November 04, 2021 10:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02025">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02025">W[1]-hardness of Outer Connected Dominating set in d-degenerate Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meybodi:Mohsen_Alambardar.html">Mohsen Alambardar Meybodi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hooshmandasl:Mohammad_Reza.html">Mohammad Reza Hooshmandasl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shakiba:Ali.html">Ali Shakiba</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02025">PDF</a><br /><b>Abstract: </b>A set $D \subseteq V$ of a graph $G = (V,E)$ is called an outer-connected
dominating set of $G$ if every vertex $v$ not in $D$ is adjacent to at least
one vertex in $D$, and the induced subgraph of $G$ on $V \setminus D$ is
connected. The Minimum Outer-connected Domination problem is to find an
outer-connected dominating set of minimum cardinality for the input graph $G$.
Given a positive integer $k$ and a graph $G = (V, E)$, the Outer-connected
Domination Decision problem is to decide whether $G$ has an outer-connected
dominating set of cardinality at most $k$. The Outer-connected Domination
Decision problem is known to be NP-complete, even for bipartite graphs. We
study the problem of outer-connected domination on sparse graphs from the
perspective of parameterized complexity and show that it is W[1]-hard on
d-degenerate graphs, while the original connected dominating set has FTP
algorithm on d-degenerate graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02025"><span class="datestr">at November 04, 2021 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02022">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02022">Approximate Gomory-Hu Tree Is Faster Than $n-1$ Max-Flows</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jason.html">Jason Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panigrahi:Debmalya.html">Debmalya Panigrahi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02022">PDF</a><br /><b>Abstract: </b>The Gomory-Hu tree or cut tree (Gomory and Hu, 1961) is a classic data
structure for reporting $(s,t)$ mincuts (and by duality, the values of $(s,t)$
maxflows) for all pairs of vertices $s$ and $t$ in an undirected graph. Gomory
and Hu showed that it can be computed using $n-1$ exact maxflow computations.
Surprisingly, this remains the best algorithm for Gomory-Hu trees more than 50
years later, *even for approximate mincuts*. In this paper, we break this
longstanding barrier and give an algorithm for computing a
$(1+\epsilon)$-approximate Gomory-Hu tree using $\text{polylog}(n)$ maxflow
computations. Specifically, we obtain the runtime bounds we describe below.
</p>
<p>We obtain a randomized (Monte Carlo) algorithm for undirected, weighted
graphs that runs in $\tilde O(m + n^{3/2})$ time and returns a
$(1+\epsilon)$-approximate Gomory-Hu tree algorithm w.h.p. Previously, the best
running time known was $\tilde O(n^{5/2})$, which is obtained by running Gomory
and Hu's original algorithm on a cut sparsifier of the graph.
</p>
<p>Next, we obtain a randomized (Monte Carlo) algorithm for undirected,
unweighted graphs that runs in $m^{4/3+o(1)}$ time and returns a
$(1+\epsilon)$-approximate Gomory-Hu tree algorithm w.h.p. This improves on our
first result for sparse graphs, namely $m = o(n^{9/8})$. Previously, the best
running time known for unweighted graphs was $\tilde O(mn)$ for an exact
Gomory-Hu tree (Bhalgat et al., STOC 2007); no better result was known if
approximations are allowed.
</p>
<p>As a consequence of our Gomory-Hu tree algorithms, we also solve the
$(1+\epsilon)$-approximate all pairs mincut and single source mincut problems
in the same time bounds. (These problems are simpler in that the goal is to
only return the $(s,t)$ mincut values, and not the mincuts.) This improves on
the recent algorithm for these problems in $\tilde O(n^2)$ time due to Abboud
et al. (FOCS 2020).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02022"><span class="datestr">at November 04, 2021 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.02008">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.02008">Deterministic Min-cut in Poly-logarithmic Max-flows</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jason.html">Jason Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panigrahi:Debmalya.html">Debmalya Panigrahi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.02008">PDF</a><br /><b>Abstract: </b>We give a deterministic algorithm for finding the minimum (weight) cut of an
undirected graph on $n$ vertices and $m$ edges using $\text{polylog}(n)$ calls
to any maximum flow subroutine. Using the current best deterministic maximum
flow algorithms, this yields an overall running time of $\tilde O(m \cdot
\min(\sqrt{m}, n^{2/3}))$ for weighted graphs, and $m^{4/3+o(1)}$ for
unweighted (multi)-graphs. This marks the first improvement for this problem
since a running time bound of $\tilde O(mn)$ was established by several papers
in the early 1990s.
</p>
<p>To obtain this result, we introduce a new tool for finding minimum cuts of an
undirected graph: *isolating cuts*. Given a set of vertices $R$, this entails
finding cuts of minimum weight that separate (or isolate) each individual
vertex $v\in R$ from the rest of the vertices $R\setminus \{v\}$. Na\"ively,
this can be done using $|R|$ maxflow calls, but we show that just $O(\log |R|)$
suffice for finding isolating cuts for any set of vertices $R$. We call this
the *isolating cut lemma*.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.02008"><span class="datestr">at November 04, 2021 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.01997">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.01997">Deterministic Approximation of Random Walks via Queries in Graphs of Unbounded Size</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pyne:Edward.html">Edward Pyne</a>, Salil Vadhan <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.01997">PDF</a><br /><b>Abstract: </b>Consider the following computational problem: given a regular digraph
$G=(V,E)$, two vertices $u,v \in V$, and a walk length $t\in \mathbb{N}$,
estimate the probability that a random walk of length $t$ from $u$ ends at $v$
to within $\pm \varepsilon.$ A randomized algorithm can solve this problem by
carrying out $O(1/\varepsilon^2)$ random walks of length $t$ from $u$ and
outputting the fraction that end at $v$.
</p>
<p>In this paper, we study deterministic algorithms for this problem that are
also restricted to carrying out walks of length $t$ from $u$ and seeing which
ones end at $v$. Specifically, if $G$ is $d$-regular, the algorithm is given
oracle access to a function $f : [d]^t\to \{0,1\}$ where $f(x)$ is $1$ if the
walk from $u$ specified by the edge labels in $x$ ends at $v$. We assume that G
is consistently labelled, meaning that the edges of label $i$ for each $i\in
[d]$ form a permutation on $V$.
</p>
<p>We show that there exists a deterministic algorithm that makes
$\text{poly}(dt/\varepsilon)$ nonadaptive queries to $f$, regardless of the
number of vertices in the graph $G$. Crucially, and in contrast to the
randomized algorithm, our algorithm does not simply output the average value of
its queries. Indeed, Hoza, Pyne, and Vadhan (ITCS 2021) showed that any
deterministic algorithm of the latter form that works for graphs of unbounded
size must have query complexity at least
$\exp(\tilde{\Omega}(\log(t)\log(1/\varepsilon)))$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.01997"><span class="datestr">at November 04, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.01970">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.01970">Rectangular Partitions of a Rectilinear Polygon</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Hwi.html">Hwi Kim</a>, Jaegun Lee, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahn:Hee=Kap.html">Hee-Kap Ahn</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.01970">PDF</a><br /><b>Abstract: </b>We investigate the problem of partitioning a rectilinear polygon $P$ with $n$
vertices and no holes % with no holes into rectangles using disjoint line
segments drawn inside $P$ under two optimality criteria. In the minimum ink
partition, the total length of the line segments drawn inside $P$ is minimized.
We present an $O(n^3)$-time algorithm using $O(n^2)$ space that returns a
minimum ink partition of $P$. In the thick partition, the minimum side length
over all resulting rectangles is maximized. We present an $O(n^3
\log^2{n})$-time algorithm using $O(n^3)$ space that returns a thick partition
using line segments incident to vertices of $P$, and an $O(n^6 \log^2{n})$-time
algorithm using $O(n^6)$ space that returns a thick partition using line
segments incident to the boundary of $P$. We also show that if the input
rectilinear polygon has holes, the corresponding decision problem for the thick
partition problem using line segments incident to vertices of the polygon is
NP-complete. We also present an $O(m^3)$-time $3$-approximation algorithm for
the minimum ink partition for a rectangle containing $m$ point holes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.01970"><span class="datestr">at November 04, 2021 10:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.01955">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.01955">Probing to Minimize</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Weina.html">Weina Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Anupam.html">Anupam Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williams:Jalani.html">Jalani Williams</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.01955">PDF</a><br /><b>Abstract: </b>We develop approximation algorithms for set-selection problems with
deterministic constraints, but random objective values, i.e., stochastic
probing problems. When the goal is to maximize the objective, approximation
algorithms for probing problems are well-studied. On the other hand, few
techniques are known for minimizing the objective, especially in the adaptive
setting, where information about the random objective is revealed during the
set-selection process and allowed to influence it. For minimization problems in
particular, incorporating adaptivity can have a considerable effect on
performance. In this work, we seek approximation algorithms that compare well
to the optimal adaptive policy.
</p>
<p>We develop new techniques for adaptive minimization, applying them to a few
problems of interest. The core technique we develop here is an approximate
reduction from an adaptive expectation minimization problem to a set of
adaptive probability minimization problems which we call threshold problems. By
providing near-optimal solutions to these threshold problems, we obtain
bicriteria adaptive policies.
</p>
<p>We apply this method to obtain an adaptive approximation algorithm for the
MIN-ELEMENT problem, where the goal is to adaptively pick random variables to
minimize the expected minimum value seen among them, subject to a knapsack
constraint. This partially resolves an open problem raised in Goel et. al's
"How to probe for an extreme value". We further consider three extensions on
the MIN-ELEMENT problem, where our objective is the sum of the smallest k
element-weights, or the weight of the min-weight basis of a given matroid, or
where the constraint is not given by a knapsack but by a matroid constraint.
For all three variations we explore, we develop adaptive approximation
algorithms for their corresponding threshold problems, and prove their
near-optimality via coupling arguments.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.01955"><span class="datestr">at November 04, 2021 10:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.01904">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.01904">Adaptive Massively Parallel Constant-round Tree Contraction</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hajiaghayi:MohammadTaghi.html">MohammadTaghi Hajiaghayi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Knittel:Marina.html">Marina Knittel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saleh:Hamed.html">Hamed Saleh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Su:Hsin=Hao.html">Hsin-Hao Su</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.01904">PDF</a><br /><b>Abstract: </b>Miller and Reif's FOCS'85 classic and fundamental tree contraction algorithm
is a broadly applicable technique for the parallel solution of a large number
of tree problems. Additionally it is also used as an algorithmic design
technique for a large number of parallel graph algorithms. In all previously
explored models of computation, however, tree contractions have only been
achieved in $\Omega(\log n)$ rounds of parallel run time. In this work, we not
only introduce a generalized tree contraction method but also show it can be
computed highly efficiently in $O(1/\epsilon^3)$ rounds in the Adaptive
Massively Parallel Computing (AMPC) setting, where each machine has
$O(n^\epsilon)$ local memory for some $0 &lt; \epsilon &lt; 1$. AMPC is a practical
extension of Massively Parallel Computing (MPC) which utilizes distributed hash
tables. In general, MPC is an abstract model for MapReduce, Hadoop, Spark, and
Flume which are currently widely used across industry and has been studied
extensively in the theory community in recent years. Last but not least, we
show that our results extend to multiple problems on trees, including but not
limited to maximum and maximal matching, maximum and maximal independent set,
tree isomorphism testing, and more.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.01904"><span class="datestr">at November 04, 2021 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.01874">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.01874">Numerical Smoothing with Hierarchical Adaptive Sparse Grids and Quasi-Monte Carlo Methods for Efficient Option Pricing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Christian Bayer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hammouda:Chiheb_Ben.html">Chiheb Ben Hammouda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tempone:Ra=uacute=l.html">Raúl Tempone</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.01874">PDF</a><br /><b>Abstract: </b>When approximating the expectation of a functional of a stochastic process,
the efficiency and performance of deterministic quadrature methods, such as
sparse grid quadrature and quasi-Monte Carlo (QMC) methods, may critically
depend on the regularity of the integrand. To overcome this issue and reveal
the available regularity, we consider cases in which analytic smoothing cannot
be performed, and introduce a novel numerical smoothing approach by combining a
root finding algorithm with one-dimensional integration with respect to a
single well-selected variable. We prove that under appropriate conditions, the
resulting function of the remaining variables is a highly smooth function,
potentially affording the improved efficiency of adaptive sparse grid
quadrature (ASGQ) and QMC methods, particularly when combined with hierarchical
transformations (i.e., Brownian bridge and Richardson extrapolation on the weak
error). This approach facilitates the effective treatment of high
dimensionality. Our study is motivated by option pricing problems, and our
focus is on dynamics where the discretization of the asset price is necessary.
Based on our analysis and numerical experiments, we show the advantages of
combining numerical smoothing with the ASGQ and QMC methods over ASGQ and QMC
methods without smoothing and the Monte Carlo approach.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.01874"><span class="datestr">at November 04, 2021 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.01851">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.01851">Private Interdependent Valuations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eden:Alon.html">Alon Eden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldner:Kira.html">Kira Goldner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zheng:Shuran.html">Shuran Zheng</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.01851">PDF</a><br /><b>Abstract: </b>We consider the single-item interdependent value setting, where there is a
monopolist, $n$ buyers, and each buyer has a private signal $s_i$ describing a
piece of information about the item. Each bidder $i$ also has a valuation
function $v_i(s_1,\ldots,s_n)$ mapping the (private) signals of all buyers to a
positive real number representing their value for the item. This setting
captures scenarios where the item's information is asymmetric or dispersed
among agents, such as in competitions for oil drilling rights, or in auctions
for art pieces. Due to the increased complexity of this model compared to
standard private values, it is generally assumed that each bidder's valuation
function $v_i$ is public knowledge. But in many situations, the seller may not
know how a bidder aggregates signals into a valuation. In this paper, we design
mechanisms that guarantee approximately-optimal social welfare while satisfying
ex-post incentive compatibility and individual rationality for the case where
the valuation functions are private to the bidders.
</p>
<p>When the valuations are public, it is possible for optimal social welfare to
be attained by a deterministic mechanism under a single-crossing condition. In
contrast, when the valuations are the bidders' private information, we show
that no finite bound can be achieved by any deterministic mechanism even under
single-crossing.
</p>
<p>Moreover, no randomized mechanism can guarantee better than an
$n$-approximation. We thus consider valuation functions that are submodular
over signals (SOS), introduced in the context of combinatorial auctions in a
recent breakthrough paper by Eden et al. [EC'19]. Our main result is an
$O(\log^2 n)$-approximation for buyers with private signals and valuations
under the SOS condition. We also give a tight $\Theta(k)$-approximation for the
case each agent's valuation depends on at most $k$ other signals even for
unknown $k$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.01851"><span class="datestr">at November 04, 2021 10:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2111.01848">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2111.01848">Improved Iteration Complexities for Overconstrained $p$-Norm Regression</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jambulapati:Arun.html">Arun Jambulapati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yang_P=.html">Yang P. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidford:Aaron.html">Aaron Sidford</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2111.01848">PDF</a><br /><b>Abstract: </b>In this paper we obtain improved iteration complexities for solving $\ell_p$
regression. We provide methods which given any full-rank $\mathbf{A} \in
\mathbb{R}^{n \times d}$ with $n \geq d$, $b \in \mathbb{R}^n$, and $p \geq 2$
solve $\min_{x \in \mathbb{R}^d} \left\|\mathbf{A} x - b\right\|_p$ to high
precision in time dominated by that of solving
$\widetilde{O}_p(d^{\frac{p-2}{3p-2}})$ linear systems in $\mathbf{A}^\top
\mathbf{D} \mathbf{A}$ for positive diagonal matrices $\mathbf{D}$. This
improves upon the previous best iteration complexity of
$\widetilde{O}_p(n^{\frac{p-2}{3p-2}})$ (Adil, Kyng, Peng, Sachdeva 2019). As a
corollary, we obtain an $\widetilde{O}(d^{1/3}\epsilon^{-2/3})$ iteration
complexity for approximate $\ell_\infty$ regression. Further, for $q \in (1,
2]$ and dual norm $q = p/(p-1)$ we provide an algorithm that solves $\ell_q$
regression in $\widetilde{O}(d^{\frac{p-2}{2p-2}})$ iterations.
</p>
<p>To obtain this result we analyze row reweightings (closely inspired by
$\ell_p$-norm Lewis weights) which allow a closer connection between $\ell_2$
and $\ell_p$ regression. We provide adaptations of two different iterative
optimization frameworks which leverage this connection and yield our results.
The first framework is based on iterative refinement and multiplicative weights
based width reduction and the second framework is based on highly smooth
acceleration. Both approaches yield $\widetilde{O}_p(d^{\frac{p-2}{3p-2}})$
iteration methods but the second has a polynomial dependence on $p$ (as opposed
to the exponential dependence of the first algorithm) and provides a new
alternative to the previous state-of-the-art methods for $\ell_p$ regression
for large $p$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2111.01848"><span class="datestr">at November 04, 2021 10:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8862914568867887724">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2021/11/a-complexity-view-of-machine-learning.html">A Complexity View of Machine Learning?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Complexity is at its best when it models new technologies so we can study it in a principled way. Quantum computing comes to mind as a good relatively recent example. With machine learning playing an every growing role in computing, how can complexity play a role?</p><p>The theory community questions about machine learning typically look at finding mathematical reasons to explain why the models well with little overfitting or trying to get good definitions of privacy, fairness, explainability to mitigate the social challenges of ML. But what about from a computational complexity point of view? I don't have a great answer yet but here are some thoughts.</p><p>In much of structural complexity, we use relativization to understand the relative power of complexity classes. We define an oracle as a set A where a machine can ask questions about membership to A and magically get an answer. Relativization can be used to help us define classes like Σ<sub>2</sub><sup>P</sup> = NP<sup>NP</sup> or allow us to succinctly state <a href="https://doi.org/10.1137/0220053">Toda's theorem</a> as PH in P<sup>#P</sup>.</p><p>As I <a href="https://twitter.com/fortnow/status/1453827400383488002">tweeted</a> last week, machine learning feels like an oracle, after all machine learning models and algorithms are typically accessed through APIs and Python modules. What kind of oracle? Definitely not an NP-complete problem like SAT since machine learning fails miserably if you try to use it to break cryptography. </p><p>The real information in machine learning comes from the data. For a length parameter n, consider a string x which might be exponential in n. Think of x as a list of labeled or unlabeled examples of some larger set S. Machine learning creates a model M from x that tries to predict whether x is in S. Think of M as the oracle, as some compressed version of S.</p><p>Is there a computational view of M? We can appeal to Ockham's razor and consider the simplest model consistent with the data for which x as a set are random in the S that M generates. One can formalize this Minimum Description Length approach using <a href="https://doi.org/10.1109/18.825807">Kolmogorov Complexity</a>. This model is too ideal, for one it can also break cryptography, and typical deep learning models are not simple at all with sometimes millions of parameters.</p><p>This is just a start. One could try time bounds on the Kolmogorov definitions or try something different completely. Adversarial and foundational learning models might yield different kinds of oracles. </p><p>If we can figure out even a rough complexity way to understand learning, we can start to get a hold of learning's computational power and limitations, which is the purpose of studying complexity complexity in the first place. </p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2021/11/a-complexity-view-of-machine-learning.html"><span class="datestr">at November 03, 2021 02:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/148">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/148">TR21-148 |  Explicit Exponential Lower Bounds for Exact Hyperplane Covers | 

	Benjamin Diamond, 

	Amir Yehudayoff</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We describe an explicit and simple subset of the discrete hypercube which cannot be exactly covered by fewer than exponentially many hyperplanes. The proof exploits a connection to communication complexity, and relies heavily on Razborov's lower bound for disjointness.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/148"><span class="datestr">at November 03, 2021 11:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=581">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2021/11/03/tcs-talk-wednesday-november-10-kuikui-liu-university-of-washington/">TCS+ talk: Wednesday, November 10 — Kuikui Liu, University of Washington</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, November 10th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <a href="https://homes.cs.washington.edu/~liukui17/"><strong>Kuikui Liu</strong></a> from the University of Washington will speak about “<em>Spectral Independence: A New Tool to Analyze Markov Chains</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Registration is <em>not</em> required to attend the interactive talk, and the link will be posted on the website the day prior to the talk; however, by registering in the form, you will receive a reminder, along with the link. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: Markov chain Monte Carlo is a widely used class of algorithms for sampling from high-dimensional probability distributions, both in theory and in practice. While simple to implement, analyzing the rate of convergence to stationarity, i.e. the “mixing time”, remains a challenging problem in many settings. We introduce a new technique to bound mixing times called “spectral independence”, which says that certain pairwise correlation matrices all have bounded spectral norm. This surprisingly powerful technique originates in the emerging study of high-dimensional expanders, and has allowed us to “unify” nearly all existing approaches to approximate counting and sampling by building new connections with other areas, including statistical physics, geometry of polynomials, functional analysis, and more. Through these connections, several long-standing open problems have recently been answered, including counting bases of matroids and optimal mixing of the Glauber dynamics/Gibbs sampler up to the algorithmic phase transition threshold.</p>
<p>Based on several joint works with Dorna Abdolazimi, Nima Anari, Zongchen Chen, Shayan Oveis Gharan, Eric Vigoda, Cynthia Vinzant, and June Vuong.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2021/11/03/tcs-talk-wednesday-november-10-kuikui-liu-university-of-washington/"><span class="datestr">at November 03, 2021 09:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5760">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2021/11/03/cs-tenure-track-positions-at-cuny/">CS Tenure Track Positions at CUNY</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Interested in a computer science position in Manhattan? Apply to our positions here! We are starting to form a computer science program at CUNY’s Baruch College. Joining us at the beginning of this process will give you a chance to influence how computer science will look like at our college: the research and teaching directions that […]</div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2021/11/03/cs-tenure-track-positions-at-cuny/"><span class="datestr">at November 03, 2021 01:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/11/02/postdoc-at-uc-santa-barbara-apply-by-january-10-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/11/02/postdoc-at-uc-santa-barbara-apply-by-january-10-2022/">Postdoc at UC Santa Barbara (apply by January 10, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A postdoc position is available to work with Eric Vigoda (and other theory faculty) at UC Santa Barbara. The position is for 2 years (no teaching required). Start date is flexible.<br />
Interested candidates should send their CV to Eric Vigoda.</p>
<p>Website: <a href="https://sites.cs.ucsb.edu/~vigoda/">https://sites.cs.ucsb.edu/~vigoda/</a><br />
Email: ericvigoda@gmail.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/11/02/postdoc-at-uc-santa-barbara-apply-by-january-10-2022/"><span class="datestr">at November 02, 2021 10:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/11/02/gilbert-tessellations-cellular">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/11/02/gilbert-tessellations-cellular.html">Gilbert tessellations from a cellular automaton</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>A <a href="https://en.wikipedia.org/wiki/Gilbert_tessellation">Gilbert tessellation</a> is what you get from choosing a random set of points-with-slopes in the plane, growing line segments in both directions with the chosen slope from each chosen point, at constant speed, and stopping the growth when each line segment runs into something else. The slopes can be in uniformly random directions but one standard variant of the Gilbert tessellation uses only horizontal and vertical slopes.</p>

<p style="text-align: center;"><a href="https://commons.wikimedia.org/wiki/File:Gilbert_tessellation_axis.svg"><img src="https://11011110.github.io/blog/assets/2018/Gilbert-rectangles.svg" alt="Axis-aligned Gilbert tessellation subdivides the plane into rectangles, by Claudio Rocchini" /></a></p>

<p>My paper “<a href="https://arxiv.org/abs/0911.2890">Growth and decay in life-like cellular automata</a>” observed that the Life-like cellular automaton rule B017/S1, when started with a sufficiently sparse random set of live cells, forms lines of replicators that look sort of like one of these axis-parallel Gilbert tessellations, as I discussed in <a href="https://11011110.github.io/blog/2018/12/27/motorcycle-graphs-eventual.html">a previous post on sparse Life</a>.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/b017s1.png" alt="Replicator chaos in B017/S1" /></p>

<p>But it’s a bit messy: you also get stable or oscillating blobs of live cells, and replicators can sometimes make large gaps big enough for something else to get across them, rather than forming the impenetrable barriers that the segments of a true Gilbert tessellation would do. So I wondered: how easy is it to get Gilbert tessellations with less mess, in a cellular automaton?</p>

<p>Very easy, if you’re willing to make an automaton that hardcodes into its rules the construction process of a Gilbert tessellation. For instance, make an automaton on an infinite square grid with three states, empty, horizontal, and vertical. Horizontal cells always stay horizontal, and vertical cells always stay vertical. Empty cells with exactly one non-empty neighbor that is either a horizontally-adjacent horizontal cell or a vertically-adjacent vertical cell take on the same state as that neighbor, and otherwise stay empty. Then any horizontal cells will grow into horizontal walls, and vertical cells will grow into vertical walls, at constant speed, until running into other non-empty cells, just as the Gilbert tessellation definition demands. If you start with a sparse random set of non-empty cells of both types, you should get a Gilbert tessellation, more or less by definition. But controlling horizontal versus vertical growth by different cell states rather than by the pattern of live cells seems kind of a cheat. It makes creating Gilbert tessellations the only thing this three-state automaton can do, rather than an emergent behavior of the automaton. And it isn’t even symmetric under 90-degree rotations (although it does have a symmetry that combines rotation with state-swapping). Is there an automaton with only two states, and natural symmetric rules that can do other things but that when seeded randomly generates non-messy Gilbert tessellations?</p>

<p>Yes! I don’t know of a Life-like rule that does this (<a href="https://en.wikipedia.org/wiki/Life_without_Death">Life without death</a> does make nice impenetrable walls but with too much other stuff). But I think the rule below fits the bill. It’s the first thing I tried, at least, so I didn’t have to do any fine adjustments of the rules to make it work.</p>

<p>Here’s the rule:</p>

<ul>
  <li>
    <p>The cells form a square grid with the <a href="https://en.wikipedia.org/wiki/Moore_neighborhood">Moore 8-cell neighborhood</a>.</p>
  </li>
  <li>
    <p>There are two states of cells, live and dead.</p>
  </li>
  <li>
    <p>A dead cell becomes live only under two conditions:</p>

    <ol>
      <li>
        <p>It has exactly two live neighbors (among its eight possible neighbors) that are orthogonally adjacent to each other.</p>
      </li>
      <li>
        <p>It has exactly four live neighbors at the corners of a rectangle (necessarily in two orthogonally adjacent pairs, because we don’t count squares as being rectangles).</p>
      </li>
    </ol>
  </li>
  <li>
    <p>All live cells immediately die.</p>
  </li>
</ul>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/gilbert/rule.svg" alt="Rules for the Gilbert cellular automaton" /></p>

<p>Or, in <a href="http://golly.sourceforge.net/">Golly</a> rule format:</p>

<pre>@RULE Gilbert
@TABLE
n_states:2
neighborhood:Moore
symmetries:rotate8reflect
var a={0,1}
var b={0,1}
var c={0,1}
var d={0,1}
var e={0,1}
var f={0,1}
var g={0,1}
var h={0,1}
0,1,1,0,0,0,0,0,0,1
0,1,1,0,1,1,0,0,0,1
1,a,b,c,d,e,f,g,h,0</pre>

<p>Then an initial pattern of two orthogonally adjacent live cells (a “domino”) will in the next step form two side-by-side dominos, in the step after that three dominos (with the center one in the initial location), and so on, building a wall two cells wide that alternates between dominos and dead cells, and oscillates with period two.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/gilbert/wall.svg" alt="Wall of alternating dominos in the Gilbert cellular automaton" /></p>

<p>Here’s what it looks like when I selected a large rectangle, randomly filled it with 2% live cells, and ran it in Golly. The red lines in this image are walls like the one above.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/gilbert/wide.png" alt="Gilbert cellular automaton on a sparse random field" /></p>

<p>Of course, at the edges of the randomly filled rectangle, the walls shoot off to infinity with no more obstructions. Here’s a closeup, showing the detailed pattern of the walls and how they meet:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/gilbert/crop.png" alt="Close-up of Gilbert cellular automaton on a sparse random field" /></p>

<p>It looks a lot like a Gilbert tessellation to me! Even starting with a 50% random fill produces the same sort of pattern at a finer scale:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/gilbert/5050.png" alt="Gilbert cellular automaton on a 50/50 random field" /></p>

<p>But rather than just going by intuitive visual appearance here’s some analysis showing that, if the plane is filled with live cells with some small probability \(p\), and then this rule is run on the result, then as \(p\to0\) the probability of seeing something that looks like a Gilbert tessellation in the neighborhood of any cell will tend to one. By “neighborhood” I mean everything within distance \(r\), where \(r\) should be chosen as a function of \(p\) that grows faster than linearly in \(1/p\) (so that we have nontrivial probability of seeing something other than just empty space) but slower than \((1/p)^{4/3}\).</p>

<p>The reason we need to limit the radius of the neighborhoods is that, in a large enough neighborhood, you will likely see something that deviates from a Gilbert tessellation. In the runs above, for instance, there are some right-angle corners where two line segments both meet and stop, or points where it appears that walls met head-to-head, but this shouldn’t happen in a Gilbert tessellation (or more precisely it happens with probability zero). There are two natural ways of getting a corner: you could start with an L-tromino of live cells, or two growing walls could coincidentally run into each other. But the expected number of triples of nearby live cells within the neighborhood is \(O(p^3r^2)\), and the expected number of pairs of dominos whose walls would meet at the same point is \(O(p^4r^3)\). It might also be the case that three or more initial live cells produce more exotic behavior; if so, the expected number of things like this that happen within the neighborhood is still \(O(p^3r^2)\). With our assumption on the growth rate of \(r\) relative to \(p\), these expected numbers, and therefore the probability of seeing any of these situations within the neighborhood, is negligible. For the same reason they have low probability of occurring close enough to the neighborhood to impinge on it before the Gilbert tessellation within the neighborhood forms.</p>

<p>So with high probability, in neighborhoods of radius \(r\), you’ll only see single live cells and double live cells in the initial state, and the pairs of double cells won’t be horizontally, vertically, or diagonally aligned with each other. Some of the double live cells will be dominos, with density \(\Theta(p^2)\). The only thing that can happen with such a state is that dominos start building walls which grow until they hit each other, exactly as described by a Gilbert tessellation. Once the Gilbert tessellation has been set up, it appears indestructible: the alternating live cells along the wall prevent any births into the layers of dead cells on either side, and if a wall is perturbed at its end it quickly grows back. However, proving this indestructability rigorously would require a more careful case analysis.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107211819080878015">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/11/02/gilbert-tessellations-cellular.html"><span class="datestr">at November 02, 2021 09:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19270">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/">Quantum Trick or Treat</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><font color="#0044cc"><br />
<em>Are crazy quantum walks fact or fiction?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/photo-by-patrick-campbell-university-of-colorado/" rel="attachment wp-att-19272"><img width="150" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/LesleySmith.jpg?resize=150%2C155&amp;ssl=1" class="wp-image-19272" height="155" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">NOAA <a href="https://psl.noaa.gov/people/lesley.l.smith/">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Lesley Smith is a climate researcher at the University of Colorado’s Cooperative Institute for Research in Environmental Sciences. She is also <a href="https://psl.noaa.gov/people/lesley.l.smith/">associated</a> to the National Oceanic and Atmospheric Administration’s Physical Science Laboratory and has worked on behalf of several other national organizations. Her PhD was in particle physics at the University of Kansas, and she incorporates quantum physics into some of her non-nonfiction writings.</p>
<p>
Today we discuss a quantum walk on a simple graph with behavior wild enough to inspire at least the latter kind of writing.</p>
<p>
Smith was most recently second author on a <a href="https://repository.library.noaa.gov/view/noaa/31032">paper</a> in the April, 2021 <em>Journal of Climate</em> whose title immediately speaks a vital subject: “Explaining the Spatial Pattern of U.S. Extreme Daily Precipitation Change.” The years-long <a href="https://www.courthousenews.com/drought-grips-american-west-with-no-relief-in-sight/">drought</a> in the US West has critically depleted lakes and reservoirs and rivers. But just one week ago, much of California had its <a href="https://www.washingtonpost.com/weather/2021/10/25/atmospheric-river-record-rain-california/">wettest</a> day ever. Both the drought and the pattern of extremes have spread across the country, as many easily-found stories this year attest. The question is how to distinguish standard fluctuations from deep-seated causal factors.</p>
<p>
As for her <a href="http://www.lesleylsmith.com/index.html">other</a> <a href="http://www.lesleylsmith.com/blog.html">writings</a>, this is representative:</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/quantumtricksandtreatscover/" rel="attachment wp-att-19274"><img width="167" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/QuantumTricksAndTreatsCover.jpg?resize=167%2C250&amp;ssl=1" class="aligncenter wp-image-19274" height="250" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Amazon <a href="https://www.amazon.com/Quantum-Tricks-Treats-Madison-Martin-ebook/dp/B0763DZZ8Q">page</a></font>
</td>
</tr>
</tbody></table>
<p>
The first lines are likewise topical: “Despite it being October, the sun felt warm on my skin. Forest-fire smoke from states west of Colorado gave the air a three-dimensional quality…” She has also written novels titled <em>Quantum Murder</em>, <em>The Quantum Cop</em>, and <em>Quantum Juneteenth</em>, plus just now a <a href="http://www.lesleylsmith.com/shortfiction.html">short story</a>, “Lucky Halloween,” about a quantum computer scientist. She is writing a series called <em>Kat Cubed</em>—well we will raise Schrödinger cat-walks to powers well beyond cubed below.</p>
<p>
</p><p></p><h2> Climate and Dynamism </h2><p></p>
<p></p><p>
The climate paper’s opening paragraphs review the the general prediction of greater precipitation from the thermal component of climate change and the effects of changes in atmospheric currents. Then it observes:</p>
<blockquote><p><b> </b> <em> Yet, the regional pattern of observed heavy precipitation trends across the United States departs from this theoretical expectation, being remarkable for its heterogeneity rather than the more uniform structure that thermodynamic effects alone would predict. … The regionally diverse trends in extreme precipitation are likely related to dynamical factors. </em>
</p></blockquote>
<p></p><p>
The paper speaks to care needed to distinguish causes and draws two conclusions:</p>
<blockquote><p><b> </b> <em> First, the absence of appreciable increases [in annual maximum single day of rain] over the West is attributed to a dynamical effect of the observed centennial-scale trends in [sea-surface temperature], sea ice, and atmospheric composition. … A second factor is sampling variability […from…] a combination of moderate forced increases comingled with a strong articulation of internal atmospheric variability. </em>
</p></blockquote>
<p></p><p>
The nub of the latter from my perspective is distinguishing what we can infer on the basis of increased dynamism alone. In our <a href="https://rjlipton.wpcomstaging.com/2014/01/30/global-warming/">post</a> seven years ago on global warming, I opined that greater energy and dynamism should be treated as more-primary effects than temperature. The challenge of inferring further effects from dynamism is recognized by another excerpt from the conclusions:</p>
<blockquote><p><b> </b> <em> Recognizing the potency of unforced atmospheric dynamics, [one cannot discount] a scenario in which internal variability could mute if not reverse the observed upward trend in eastern U.S. [extreme rains]. </em>
</p></blockquote>
<p></p><p>
In the rest of this post, we’ll offer an example of wild dynamics from a small quantum system that may speak to both her <em>métiers</em>.</p>
<p>
</p><p></p><h2> Classical Random and Quantum Walks </h2><p></p>
<p></p><p>
Consider the following graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" />. It looks like a Q-tip. The two self-loops depart from usual examples of undirected graphs. </p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/propellergraph/" rel="attachment wp-att-19275"><img width="550" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/PropellerGraph.png?resize=550%2C72&amp;ssl=1" class="aligncenter size-large wp-image-19275" height="72" /></a></p>
<p></p><p><br />
A classical random walk on <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> starts at some node—say node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" />—and at each step flips a coin to determine the next node. The “walker” stays on node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> if the result is heads (<img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{H}" class="latex" />) but goes to node <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" /> if tails (<img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{T}" class="latex" />). The walker cannot go from <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3}" class="latex" /> in one step because there is no edge. The <b>probabilistic transition matrix</b> <img src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_G}" class="latex" /> is given at right. The vector </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bbmatrix%7D+0.5+%5C%5C+0.25+%5C%5C+0.25+%5Cend%7Bbmatrix%7D+%3D+A_G%5Ccdot+%5Cbegin%7Bbmatrix%7D+0.5+%5C%5C+0.5+%5C%5C+0+%5Cend%7Bbmatrix%7D+%3D+A_G%5E2+%5Ccdot+x%5E%7B%280%29%7D+%5Cqquad%5Ctext%7Bwhere%7D%5Cqquad+x%5E%7B%280%29%7D+%3D+%5Cbegin%7Bbmatrix%7D+1+%5C%5C+0+%5C%5C+0+%5Cend%7Bbmatrix%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \begin{bmatrix} 0.5 \\ 0.25 \\ 0.25 \end{bmatrix} = A_G\cdot \begin{bmatrix} 0.5 \\ 0.5 \\ 0 \end{bmatrix} = A_G^2 \cdot x^{(0)} \qquad\text{where}\qquad x^{(0)} = \begin{bmatrix} 1 \\ 0 \\ 0 \end{bmatrix} " class="latex" /></p>
<p>gives the probabilities for each node after two steps. (Although multiplying row vectors on the left is commonly used for classical walks, we will use column vectors for consistency with quantum usage; that <img src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_G}" class="latex" /> is symmetric moots the difference anyway.) For any <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7B%28t%29%7D+%3D+A_G%5Et+x_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x^{(t)} = A_G^t x_0}" class="latex" /> can be called the “classical state” of the walk after <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t}" class="latex" /> steps. </p>
<p>
The state <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" /> whose entries <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Bi%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x[i]}" class="latex" /> are given by the degree of node <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{i}" class="latex" /> divided by the sum of the degrees makes <img src="https://s0.wp.com/latex.php?latex=%7BA_G+x+%3D+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_G x = x}" class="latex" />, and thus gives a <b>stable distribution</b> for the walk. A central theorem states that for every <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> that is not bipartite, the powers of <img src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_G}" class="latex" /> converge entrywise in every column to a unique stable distribution. When <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is regular, as here, this is simply the uniform distribution. The convergence in our case is quite quick, as signified by the exact values </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_G%5E%7B10%7D+%3D+%5Cbegin%7Bbmatrix%7D+0.333984375+%26+0.3330078125+%26+0.3330078125+%5C%5C+0.3330078125+%26+0.333984375+%26+0.3330078125+%5C%5C+0.3330078125+%26+0.3330078125+%26+0.333984375+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  A_G^{10} = \begin{bmatrix} 0.333984375 &amp; 0.3330078125 &amp; 0.3330078125 \\ 0.3330078125 &amp; 0.333984375 &amp; 0.3330078125 \\ 0.3330078125 &amp; 0.3330078125 &amp; 0.333984375 \end{bmatrix}. " class="latex" /></p>
<p>
The quantum case needs to bind the graph and the “coin” into one system, so its domain has six members, which we list in order </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathcal%7BS%7D+%3D+%5C%7B%281%2CH%29%2C%281%2CT%29%2C%282%2CH%29%2C%282%2CT%29%2C%283%2CH%29%2C%283%2CT%29%5C%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \mathcal{S} = \{(1,H),(1,T),(2,H),(2,T),(3,H),(3,T)\}. " class="latex" /></p>
<p>In quantum notation, this is the tensor product of the “node space” <img src="https://s0.wp.com/latex.php?latex=%7BV+%3D+%5C%7B1%2C2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{V = \{1,2,3\}}" class="latex" /> and the “coin space” <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BC%7D+%3D+%5C%7BH%2CT%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathcal{C} = \{H,T\}}" class="latex" />. The meaning of <img src="https://s0.wp.com/latex.php?latex=%7B%28v%2C%5Cmathfrak%7Bc%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(v,\mathfrak{c})}" class="latex" /> is that the walker just arrived at node <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{v}" class="latex" /> via the coin outcome <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bc%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{c}}" class="latex" />. It is incumbent that every node <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{v}" class="latex" /> can be reached on either outcome. Our <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{H}" class="latex" />–<img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{T}" class="latex" /> labeling above complies. Then we get a permutation <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{P}" class="latex" /> on <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" /> from the action </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28v%2C%5Cmathfrak%7Bc%7D%29+%3D+%28v%27%2C%5Cmathfrak%7Bc%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  P(v,\mathfrak{c}) = (v',\mathfrak{c}), " class="latex" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7Bv%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{v'}" class="latex" /> is the vertex reached from <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{v}" class="latex" /> by the outcome <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bc%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{c}}" class="latex" /> from the classical walk, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bc%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{c}}" class="latex" /> is kept the same. The penultimate trick is to expand this to a mapping <img src="https://s0.wp.com/latex.php?latex=%7BP%27%3A+%5Cmathcal%7BS%7D+%5Ctimes+%5Cmathcal%7BC%7D+%5Crightarrow+%5Cmathcal%7BS%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{P': \mathcal{S} \times \mathcal{C} \rightarrow \mathcal{S}}" class="latex" /> by </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%27%28%28v%2C%5Cmathfrak%7Bb%7D%29%2C%5Cmathfrak%7Bc%7D%29+%3D+%28v%27%2C%5Cmathfrak%7Bc%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  P'((v,\mathfrak{b}),\mathfrak{c}) = (v',\mathfrak{c}), " class="latex" /></p>
<p>whereby the previous coin outcome <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{b}}" class="latex" /> is “forgotten” while the current flip is preserved in the state. We can represent this by the <em>directed</em> graph <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G'}" class="latex" /> shown next. </p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/quantumgraph/" rel="attachment wp-att-19281"><img width="360" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/QuantumGraph.png?resize=360%2C210&amp;ssl=1" class="aligncenter wp-image-19281" height="210" /></a></p>
<p></p><p><br />
Incidentally, <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G'}" class="latex" /> is planar (switch nodes <img src="https://s0.wp.com/latex.php?latex=%7B2H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2H}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B2T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2T}" class="latex" /> to see). The last trick is to label its edges by quantum amplitudes for the coin outcomes.</p>
<p>
</p><p></p><h2> Realm of the Coin </h2><p></p>
<p></p><p>
Our quantum coin can be “flipped” by applying any chosen <img src="https://s0.wp.com/latex.php?latex=%7B2+%5Ctimes+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2 \times 2}" class="latex" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BU%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{U}}" class="latex" /> to the current state of the coin, provided <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BU%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{U}}" class="latex" /> is a unitary matrix. In general, if <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" /> is a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" />-regular graph and we have a suitable labeling for results of a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" />-sided die, then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BU%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{U}}" class="latex" /> can be a <img src="https://s0.wp.com/latex.php?latex=%7Bd+%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d \times d}" class="latex" /> matrix acting on a single <b>qudit</b>, or we can use <img src="https://s0.wp.com/latex.php?latex=%7B%5Clceil+%5Clog_2+d+%5Crceil%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\lceil \log_2 d \rceil}" class="latex" /> qubits to encode the coin. But here we just need one qubit. Before fixing the choice of coin matrix, we can represent it abstractly as </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbf%7BU%7D+%3D+%5Cbegin%7Bbmatrix%7D+a+%26+b+%5C%5C+c+%26+d+%5Cend%7Bbmatrix%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \mathbf{U} = \begin{bmatrix} a &amp; b \\ c &amp; d \end{bmatrix} " class="latex" /></p>
<p>To apply the coin on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BS%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathcal{S}}" class="latex" />, we form the <img src="https://s0.wp.com/latex.php?latex=%7B6+%5Ctimes+6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{6 \times 6}" class="latex" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BU%27%7D+%3D+%5Cmathbf%7BI%7D+%5Cotimes+%5Cmathbf%7BU%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{U'} = \mathbf{I} \otimes \mathbf{U}}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BI%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{I}}" class="latex" /> is the <img src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3 \times 3}" class="latex" /> identity matrix. To move the walker after the coin result, we apply the <img src="https://s0.wp.com/latex.php?latex=%7B6+%5Ctimes+6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{6 \times 6}" class="latex" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{P}}" class="latex" /> of the permutation <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{P}" class="latex" />. Since we use column vectors for states, the walk matrix is given by </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbf%7BW%7D+%3D+%5Cmathbf%7BP%7D%5Ccdot%5Cmathbf%7BU%27%7D+%3D+%5Cbegin%7Bbmatrix%7D+1+%26+0+%26+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+1+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%26+1+%26+0+%5C%5C+0+%26+1+%26+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+1+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%26+0+%26+1+%5C%5C+%5Cend%7Bbmatrix%7D+%5Ccdot+%5Cbegin%7Bbmatrix%7D+a+%26+b+%26+0+%26+0+%26+0+%26+0+%5C%5C+c+%26+d+%26+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+a+%26+b+%26+0+%26+0+%5C%5C+0+%26+0+%26+c+%26+d+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%26+a+%26+b+%5C%5C+0+%26+0+%26+0+%26+0+%26+c+%26+d+%5Cend%7Bbmatrix%7D+%3D+%5Cleft%5B%5Cbegin%7Barray%7D%7Bcc%7Ccc%7Ccc%7D+a+%26+b+%26+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+c+%26+d+%26+0+%26+0+%5C%5C+%5Chline+0+%26+0+%26+0+%26+0+%26+a+%26+b+%5C%5C+c+%26+d+%26+0+%26+0+%26+0+%26+0+%5C%5C+%5Chline+0+%26+0+%26+a+%26+b+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%26+c+%26+d+%5Cend%7Barray%7D%5Cright%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \mathbf{W} = \mathbf{P}\cdot\mathbf{U'} = \begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\ \end{bmatrix} \cdot \begin{bmatrix} a &amp; b &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ c &amp; d &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; a &amp; b &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; c &amp; d &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; a &amp; b \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; c &amp; d \end{bmatrix} = \left[\begin{array}{cc|cc|cc} a &amp; b &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; c &amp; d &amp; 0 &amp; 0 \\ \hline 0 &amp; 0 &amp; 0 &amp; 0 &amp; a &amp; b \\ c &amp; d &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ \hline 0 &amp; 0 &amp; a &amp; b &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; c &amp; d \end{array}\right] " class="latex" /></p>
<p>We have drawn lines to show how the coin acts between each pair of nodes. Notice that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{W}}" class="latex" /> is no longer symmetric, so specifying column-vector inputs matters. For instance, the <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{b}" class="latex" /> in the top row comes in from the column at <img src="https://s0.wp.com/latex.php?latex=%7B1T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1T}" class="latex" /> and exits at <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" />. This means the previous coin result was tails and took the walker (from node 2) to node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" />; now the coin gives heads so the walker stays at node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" />. We can diagram this action also on the expanded graph <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G'}" class="latex" />, so that the <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{b}" class="latex" /> goes on the arrow from <img src="https://s0.wp.com/latex.php?latex=%7B1T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1T}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" />, and so on:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/quantumgprime/" rel="attachment wp-att-19278"><img width="300" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/QuantumGprime.png?resize=300%2C193&amp;ssl=1" class="aligncenter wp-image-19278" height="193" /></a></p>
<p>
The first step has no “previous coin result” but we still have to specify one to initialize the coin state as well as the walker’s state. For starting on node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> there is still an infinitude of combinations of the basis states <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B1T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1T}" class="latex" />. If we fix the start as <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" />, this is like saying the coin was heads-up before the initial act of flipping it.</p>
<p>
</p><p></p><h2> Walking Into Chaos </h2><p></p>
<p></p><p>
A natural and popular choice of coin is the Hadamard matrix </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbf%7BH%7D+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cbegin%7Bbmatrix%7D+1+%26+1+%5C%5C+1+%26+-1+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \mathbf{H} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 &amp; 1 \\ 1 &amp; -1 \end{bmatrix}. " class="latex" /></p>
<p>We need only mark the edges with <img src="https://s0.wp.com/latex.php?latex=%7Bd+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d = -1}" class="latex" />, keeping the normalizing <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{1}{\sqrt{2}}}" class="latex" /> in mind. Here are <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G'}" class="latex" /> and the three steps of the quantum walk after the first:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/fouriterations/" rel="attachment wp-att-19279"><img width="550" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/11/FourIterations.png?resize=550%2C282&amp;ssl=1" class="aligncenter size-large wp-image-19279" height="282" /></a></p>
<p>
To visualize the <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t}" class="latex" />-step walk, say starting from <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bs%7D_0+%3D+1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{s}_0 = 1H}" class="latex" />, we take each possible path of length <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t}" class="latex" /> and multiply the numbers on its edges. Over all paths that end at the same <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bs%7D%3D%28v%2C%5Cmathfrak%7Bc%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{s}=(v,\mathfrak{c})}" class="latex" /> we add those products to give the <b>amplitude</b> <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7Bu%2Cv%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a_{u,v}}" class="latex" />, which in our column-first notation equals the entry <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D%5Et%5B%5Cmathfrak%7Bs%7D%2C%5Cmathfrak%7Bs%7D_0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{W}^t[\mathfrak{s},\mathfrak{s}_0]}" class="latex" />. </p>
<p>
For example, there are two paths of <img src="https://s0.wp.com/latex.php?latex=%7Bt%3D3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t=3}" class="latex" /> steps from <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" /> back to itself. One takes the loop at <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" /> three times and contributes the phase value <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" />, but the other does <img src="https://s0.wp.com/latex.php?latex=%7B1H%5Crightarrow+2T+%5Crightarrow+1T+%5Crightarrow+1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H\rightarrow 2T \rightarrow 1T \rightarrow 1H}" class="latex" /> and picks up the value <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{-1}" class="latex" />. Adding those values cancels them, leaving the red <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0}" class="latex" /> shown at upper left in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{W}^3}" class="latex" />. If our walker is a Schrödinger cat, that part of it is not just “dead” but completely annihilated.</p>
<p>
It is still possible for the cat to end on node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> after being cubed, because the path <img src="https://s0.wp.com/latex.php?latex=%7B1H+%5Crightarrow+1H+%5Crightarrow+2T+%5Crightarrow+1T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H \rightarrow 1H \rightarrow 2T \rightarrow 1T}" class="latex" /> is not canceled. That the cat ends with phase <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{-1}" class="latex" /> does not matter, because to get the probabilities—given we started at <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" />—we take the squared magnitude of each entry in column <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> and add the adjacent pairs denoting the same vertex of the original graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" />. Thus the cat has probability only </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p_1%5E%7B%283%29%7D+%3D+%5Cfrac%7B0%5E2+%2B+%28-1%29%5E2%7D%7B%282%5Csqrt%7B2%7D%29%5E2%7D+%3D+%5Cfrac%7B1%7D%7B8%7D+%3D+0.125+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  p_1^{(3)} = \frac{0^2 + (-1)^2}{(2\sqrt{2})^2} = \frac{1}{8} = 0.125 " class="latex" /></p>
<p>of being still on node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> after three time steps. Given the ease of looping at node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" />, this is counterintuitive. After nine and ten steps, we have: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbf%7BW%7D%5E9+%3D+%5Cfrac%7B1%7D%7B2%5E%7B4.5%7D%7D%5Cbegin%7Bbmatrix%7D+18+%26+4+%26+-1+%26+13+%26+-1+%26+-1%5C%5C+13+%26+1+%26+4+%26+-18+%26+-1+%26+1%5C%5C+-1+%26+13+%26+-1+%26+-1+%26+18+%26+4%5C%5C+4+%26+-18+%26+-1+%26+1+%26+13+%26+1%5C%5C+-1+%26+-1+%26+18+%26+4+%26+-1+%26+13%5C%5C+-1+%26+1+%26+13+%26+1+%26+4+%26+-18+%5Cend%7Bbmatrix%7D+.%5Cqquad+%5Cmathbf%7BW%7D%5E%7B10%7D+%3D+%5Cfrac%7B1%7D%7B32%7D%5Cbegin%7Bbmatrix%7D+31+%26+5+%26+3+%26+-5+%26+-2+%26+0%5C%5C+-5+%26+31+%26+0+%26+-2+%26+5+%26+3%5C%5C+-2+%26+0+%26+31+%26+5+%26+3+%26+-5%5C%5C+5+%26+3+%26+-5+%26+31+%26+0+%26+-2%5C%5C+3+%26+-5+%26+-2+%26+0+%26+31+%26+5%5C%5C+0+%26+-2+%26+5+%26+3+%26+-5+%26+31+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \mathbf{W}^9 = \frac{1}{2^{4.5}}\begin{bmatrix} 18 &amp; 4 &amp; -1 &amp; 13 &amp; -1 &amp; -1\\ 13 &amp; 1 &amp; 4 &amp; -18 &amp; -1 &amp; 1\\ -1 &amp; 13 &amp; -1 &amp; -1 &amp; 18 &amp; 4\\ 4 &amp; -18 &amp; -1 &amp; 1 &amp; 13 &amp; 1\\ -1 &amp; -1 &amp; 18 &amp; 4 &amp; -1 &amp; 13\\ -1 &amp; 1 &amp; 13 &amp; 1 &amp; 4 &amp; -18 \end{bmatrix} .\qquad \mathbf{W}^{10} = \frac{1}{32}\begin{bmatrix} 31 &amp; 5 &amp; 3 &amp; -5 &amp; -2 &amp; 0\\ -5 &amp; 31 &amp; 0 &amp; -2 &amp; 5 &amp; 3\\ -2 &amp; 0 &amp; 31 &amp; 5 &amp; 3 &amp; -5\\ 5 &amp; 3 &amp; -5 &amp; 31 &amp; 0 &amp; -2\\ 3 &amp; -5 &amp; -2 &amp; 0 &amp; 31 &amp; 5\\ 0 &amp; -2 &amp; 5 &amp; 3 &amp; -5 &amp; 31 \end{bmatrix}. " class="latex" /></p>
<p>The corresponding node probabilities are <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7B%289%29%7D+%3D+%5B+0.96289%2C+0.0332%2C+0.00391%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p^{(9)} = [ 0.96289, 0.0332, 0.00391]}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7B%2810%29%7D+%3D+%5B+0.96289%2C+0.02832%2C+0.00879%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p^{(10)} = [ 0.96289, 0.02832, 0.00879]}" class="latex" />. The probability of the first node is the same between every odd and even step, echoing how starting at <img src="https://s0.wp.com/latex.php?latex=%7B1H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1H}" class="latex" /> presumes a previous coin flip of heads, which kept the cat on node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" /> at time <img src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t = -1}" class="latex" />. At <img src="https://s0.wp.com/latex.php?latex=%7Bt%3D10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t=10}" class="latex" /> the cat has almost come back fully to node <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{1}" class="latex" />, indeed to the initial quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C1H%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{|1H\rangle}" class="latex" />, but not quite. The swing is even closer at <img src="https://s0.wp.com/latex.php?latex=%7Bt%3D38%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{t=38}" class="latex" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbf%7BW%7D%5E%7B38%7D+%3D+%5Cfrac%7B1%7D%7B524288%7D%5Cbegin%7Bbmatrix%7D+522919+%26+-23939+%26+-11285+%26+23939+%26+12654+%26+0%5C%5C+23939+%26+522919+%26+0+%26+12654+%26+-23939+%26+-11285%5C%5C+12654+%26+0+%26+522919+%26+-23939+%26+-11285+%26+23939%5C%5C+-23939+%26+-11285+%26+23939+%26+522919+%26+0+%26+12654%5C%5C+-11285+%26+23939+%26+12654+%26+0+%26+522919+%26+-23939%5C%5C+0+%26+12654+%26+-23939+%26+-11285+%26+23939+%26+522919+%5Cend%7Bbmatrix%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \mathbf{W}^{38} = \frac{1}{524288}\begin{bmatrix} 522919 &amp; -23939 &amp; -11285 &amp; 23939 &amp; 12654 &amp; 0\\ 23939 &amp; 522919 &amp; 0 &amp; 12654 &amp; -23939 &amp; -11285\\ 12654 &amp; 0 &amp; 522919 &amp; -23939 &amp; -11285 &amp; 23939\\ -23939 &amp; -11285 &amp; 23939 &amp; 522919 &amp; 0 &amp; 12654\\ -11285 &amp; 23939 &amp; 12654 &amp; 0 &amp; 522919 &amp; -23939\\ 0 &amp; 12654 &amp; -23939 &amp; -11285 &amp; 23939 &amp; 522919 \end{bmatrix} " class="latex" /></p>
<p>with state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bs%7D_%7B38%7D+%3D+%5B0.99739%2C+0.04566%2C+0.02414%2C+-0.04566%2C+-0.02152%2C+0%5D%5ET%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{s}_{38} = [0.99739, 0.04566, 0.02414, -0.04566, -0.02152, 0]^T}" class="latex" /> and node probabilities <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7B%2838%29%7D+%3D+%5B+0.99687%2C+0.00267%2C+0.00046%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p^{(38)} = [ 0.99687, 0.00267, 0.00046]}" class="latex" />. The next probabilities, however, are <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7B%2839%29%7D+%3D+%5B+0.54641%2C+0.45313%2C+0.00046%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p^{(39)} = [ 0.54641, 0.45313, 0.00046]}" class="latex" />, which is not close to the first-step distribution <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7B%281%29%7D+%3D+%5B0.5%2C0.5%2C0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p^{(1)} = [0.5,0.5,0]}" class="latex" />. </p>
<p>
Most treatments of quantum walks, including a seminal <a href="https://arxiv.org/abs/quant-ph/0012090">paper</a> by Dorit Aharonov, Andris Ambainis, Julia Kempe, and Umesh Vazirani, and an influential 2003 <a href="https://arxiv.org/abs/quant-ph/0303081">survey</a> by Kempe, emphasize the dispersion time being linear rather than quadratic as in classical random walks on undirected graphs. Here, the quadratic nature effects quick divergence between close states like <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bs%7D_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{s}_0}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7Bs%7D_%7B38%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathfrak{s}_{38}}" class="latex" />, which is the signature of dynamical chaos. </p>
<p>
The coin <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BJ%7D+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cbegin%7Bbmatrix%7D+1+%26+i+%5C%5C+i+%26+1%5Cend%7Bbmatrix%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{J} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 &amp; i \\ i &amp; 1\end{bmatrix}}" class="latex" /> is reputed to make quantum walks smoother. That works to some extent for our three-node graph, but there appears to be no periodic stability, let alone convergence as in the classical case. Simple Python code for trying other coins is available <a href="https://cse.buffalo.edu/~regan/cse610/qtipwalk.py">here</a>.</p>
<p>
</p><p></p><h2> Real or Fiction? </h2><p></p>
<p></p><p>
Our main question is simple: </p>
<blockquote><p><b> </b> <em> Are these crazy walks real? </em>
</p></blockquote>
<p></p><p>
The answer is <em>yes</em> if we can engineer a qutrit+qubit system that evolves by repeating <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{W}}" class="latex" />. <em>Simulating</em> such a system throws up a second issue: No one would say that the classical computer executing my Python code is behaving chaotically. We can program <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{W}}" class="latex" /> via basic gates available to run on real hardware at <a href="https://quantum-computing.ibm.com/">IBM Quantum</a> or some other services. </p>
<blockquote><p><b> </b> <em> Is quantum hardware that applies powers of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbf{W}}" class="latex" /> behaving chaotically? Does that pose a concretely physical impediment to maintaining its coherence? </em>
</p></blockquote>
<p></p><p>
On expecting a <em>yes</em> answer to the walks’ physical existence in the microworld, our questions next try to connect to Smith’s paper:</p>
<blockquote><p><b> </b> <em> Does the mathematical existence of chaotic quantum systems on such small scales have macroscopic effects in our world? Such as on the chaotic dynamics of our atmosphere? </em>
</p></blockquote>
<p></p><p>
Again, the answer should be <em>yes</em> at the level of <a href="https://link.springer.com/chapter/10.1007/3-540-09718-X_73">connecting</a> Brownian motion to quantum processes, or of quantum-walk <a href="https://repository.tudelft.nl/islandora/object/uuid:08ad4a94-483d-46db-8840-6f73c3e48a70/datastream/OBJ/download">interpretations</a> of physical systems such as the quantum harmonic oscillator (<a href="https://en.wikipedia.org/wiki/Quantum_harmonic_oscillator">QHO</a>). So the most specific form of our question is:</p>
<blockquote><p><b> </b> <em> Does our (not-so-)simple three-node quantum walk appear as a non-negligible term in a Feynman-style summation needed to understand a macroscopic physical system? </em>
</p></blockquote>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Can the quantum chaos of the Q-tip graph be tamed? See <a href="https://arxiv.org/pdf/2008.00316.pdf">this</a> for success on other graphs including the 3-cycle. There are are affinities between the 3-cycle and Q-tip walks, especially at even timesteps, and the 3-cycle is an option in the Python code.</p>
<p>
Smith also has many activities promoting STEM, including her <a href="http://www.physicsisfun.net/">Phyiscs Is Fun</a> website and a <a href="https://books2read.com/u/bMavLX">book</a> on particle physics.  She maintains a <a href="http://www.lesleylsmith.com/blog.html">blog</a> of her writing and reading, plus much else on her <a href="http://www.lesleylsmith.com/">author site</a>.  Dick and I were already wondering about women in the community of math/theory bloggers, such as <a href="https://blog.tanyakhovanova.com/">Tanya Khovanova</a>, <a href="https://fractalkitty.com/">Sophia Wood</a>, <a href="http://vihart.com/">Vi Hart</a>, and <a href="https://mathmunch.org/author/aweltman/">Anna Weltman</a>.  </p>
<p></p><p><br />
[fixed link for Python code, some word changes, fixed entry of J matrix]</p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/11/01/quantum-trick-or-treat/"><span class="datestr">at November 02, 2021 03:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://scottaaronson.blog/?p=6098">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://scottaaronson.blog/?p=6098">Q2B 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>This is a quick post to let people know that the 2021 <a href="https://q2b.qcware.com/">Q2B (Quantum 2 Business) conference</a> will be this December 7-9 at the Santa Clara Convention Center.  (Full disclosure: Q2B is hosted by <a href="https://qcware.com/">QC Ware, Inc.</a>, to which I’m the scientific adviser.)  Barring a dramatic rise in cases or the like, I’m planning to attend to do my Ask-Me-Anything session, in what’s become an annual tradition.  Notably, this will be my first in-person conference, and in fact my first professional travel of any kind, since before covid shut down the US in late March 2020.  I hope to see many of you there!  And if you <em>won’t</em> be at Q2B, but you’ll be in the Bay Area and would like to meet otherwise, let me know and we’ll try to work something out.</p></div>







<p class="date">
by Scott <a href="https://scottaaronson.blog/?p=6098"><span class="datestr">at November 01, 2021 10:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2754344269552524293">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2019/07/when-did-math-get-so-hard.html">When did Math Get So Hard?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
I have been on many Math PhD thesis defense's  as the Dean's Representative. This means I don't have to understand the work, just make sure the rules are followed. I've done this for a while and I used to understand some of it but now there are times I understand literally none of it. As a result, when the student leaves the room and we talk among ourselves I ask<br />
<br />
<br />
When did Math get so hard?<br />
<br />
I mean it as a statement and maybe a joke, but I decided to email various people and ask for a serious answer. Here are some thoughts of mine and others<div><br /></div><div>1) When you get older math got harder. Lance blogged on this <a href="https://blog.computationalcomplexity.org/2021/10/a-young-persons-game.html">here</a></div><div><br /></div><div>2) When math got more abstract it got harder. Blame Grothendieck.</div><div><br /></div><div>3) When math stopped being tied to the real work it got harder. Blame Hardy. </div><div><br /></div><div>4) Math has always been hard. We NOW understand some of the older math better so it seems easy to us, but it wasn't at the time. </div><div><br /></div><div>5) With the web and more people working in math, new results come out faster so its harder to keep up.</div><div><br /></div><div>6) All fields of math have a period of time when they are easy, at the beginning, and then as the low-hanging fruit gets picked it gets harder and harder.  So if a NEW branch was started it might initially be easy. Counterthought- even a new branch might be hard now since it can draw on so much prior math. Also, the low hanging fruit may be picked rather quickly. </div><div><br />
<br /><br />
</div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2019/07/when-did-math-get-so-hard.html"><span class="datestr">at October 31, 2021 07:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/10/31/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/10/31/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Square-difference-free_set">Square-difference-free set</a> (<a href="https://mathstodon.xyz/@11011110/107112823640205029">\(\mathbb{M}\)</a>), now a Good Article on Wikipedia. As the name suggests, these are sets of integers no two of which differ by a square. My favorite such set consists of the losing positions in <a href="https://en.wikipedia.org/wiki/Subtract_a_square">subtract-a-square</a>, where each move removes a square number of coins from a pile of coins, winning by taking the last coin. This general class of sets and the subtract-a-square set have \(o(n)\) elements up to \(n\), but their maximum density remains unknown.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/q/406120/440">Can a convex polyhedron have an odd number of faces, all congruent</a> (<a href="https://mathstodon.xyz/@11011110/107121133147692528">\(\mathbb{M}\)</a>). If so the faces would have to all be kites, per comments at the link. Which raises the question: can a convex polyhedron with congruent kite faces avoid being either a <a href="https://en.wikipedia.org/wiki/Trapezohedron">trapezohedron</a> or formed from deltahedron (a polyhedron with equilateral triangle faces) by subdividing each triangle into three kites? Both automatically have evenly many faces.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Regular_number">You might know about regular numbers</a> (<a href="https://mathstodon.xyz/@11011110/107127099279073309">\(\mathbb{M}\)</a>), of the form \(2^i\cdot 3^j\cdot 5^k\), from Babylonian mathematics, music theory, Plato, or as a test case for functional programming. But did you know that they come up in biology, as numbers of years between mass flowering in certain types of bamboo? See Veller, Nowak and Davis, “<a href="https://doi.org/10.1111/ele.12442">Extended flowering intervals of bamboos evolved by discrete multiplication</a>”, <em>Ecol. Lett.</em> 2015, via Andrey Zabolotskiy at <a href="https://oeis.org/A051037">OEIS A051037</a>.</p>
  </li>
  <li>
    <p>My new paper “<a href="https://arxiv.org/abs/2110.06163">Finding relevant points for nearest-neighbor classification</a>”, has won the best paper award of the SIAM Symposium on Simplicity in Algorithms, SOSA22 <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107132784717543034">\(\mathbb{M}\)</a>).</span> Woo! In other news, the lists of accepted papers at <a href="https://www.siam.org/conferences/cm/program/accepted-papers/sosa22-accepted-papers">SOSA</a>, <a href="https://www.siam.org/conferences/cm/program/accepted-papers/soda22-accepted-papers">SODA</a>, and <a href="https://www.siam.org/conferences/cm/program/accepted-papers/alenex22-accepted-papers">ALENEX</a> are online.</p>
  </li>
  <li>
    <p><a href="https://twitter.com/thienan496/status/1446021847292669953">Animation of the minimum-weight matchings of increasingly many points of two colors in a unit square</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107140270923344318">\(\mathbb{M}\)</a>).</span> Because the color densities fluctuate, the matching develops regions of many parallel long edges transporting excess density from one place to another. This is reflected mathematically in the fact that the expected length is \(\Theta(\sqrt{n\log n})\) compared to \(\Theta(\sqrt{n})\) for non-bipartite matching; see Ajtai, Komlós, and Tusnády, “<a href="https://doi.org/10.1007/BF02579135">On optimal matchings</a>”, <em>Combinatorica</em> 1984.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Jacob_E._Goodman">Jacob E. Goodman</a>, famed as a discrete and computational geometer and cofounder of the top journal in the field, <em>Discrete &amp; Computational Geometry</em>, <a href="https://web.archive.org/web/20211025204323/https://newyorkcomposerscircle.org/index.html">died on October 10</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107143828784210981">\(\mathbb{M}\)</a>,</span> <a href="https://newyorkcomposerscircle.org/composers/jacob-e-goodman.html">see also</a>).</p>
  </li>
  <li>
    <p>The classical CS interview question of destructively reversing a singly-linked list goes back at least to <a href="http://i.stanford.edu/pub/cstr/reports/cs/tr/76/544/CS-TR-76-544.pdf">Ed McCreight in 1973</a> (<a href="https://mathstodon.xyz/@11011110/107147889403810499">\(\mathbb{M}\)</a>). But if you generalize a singly-linked list to a zipper (directed out in both directions from a finger <span style="white-space: nowrap;">into it)</span> then reversal is trivial and you get the classical algorithm by moving your finger from start to end. I don’t know of references; maybe the zipper people are too focused on functional/non-destructive/reentrant methods to mention this?</p>
  </li>
  <li>
    <p>I recently learned that the name “Thomsen graph” for  comes from the work of Danish chemist <a href="https://en.wikipedia.org/wiki/Hans_Peter_J%C3%B8rgen_Julius_Thomsen">Julius Thomsen</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107154978136052455">\(\mathbb{M}\)</a>)</span> who <a href="https://archive.org/download/crossref-pre-1909-scholarly-works/10.1002%252Fcber.18860190141.zip/10.1002%252Fcber.188601902285.pdf">proposed in 1886 that it describes the structure of benzene</a>. Thomsen was late to the party: Kekulé had already proposed the benzene ring in 1865. But the name for the graph stuck.</p>
  </li>
  <li>
    <p>My UCI colleague <a href="https://recruit.ap.uci.edu/JPF07189">Vijay Vazirani is looking for a postdoc in algorithmic design / algorithmic game theory</a> (<a href="https://mathstodon.xyz/@11011110/107157944689667569">\(\mathbb{M}\)</a>). One-year, renewable.</p>
  </li>
  <li>
    <p><a href="https://sinews.siam.org/Details-Page/fairmandering-generating-fairness-optimized-political-districts">Fairmandering: generating fairness-optimized political districts</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107169485099658532">\(\mathbb{M}\)</a>),</span> Wes Gurnee and David Shmoys. If you generate a hierarchically-organized and large family of partitions of a state into contiguous equal-population regions, you can then optimize over the hierarchy for fairness. Gurnee and Shmoys choose to optimize the <a href="https://en.wikipedia.org/wiki/Efficiency_gap">efficiency gap</a> but their method is a two-edged sword: it would work equally well to optimize for partisan advantage.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/107173511804051329">What high-order regular polygons do you have lying around your house?</a></p>
  </li>
  <li>
    <p><a href="http://skepticsplay.blogspot.com/2013/06/in-praise-of-non-deductive-puzzles.html">In praise of non-deductive puzzles</a> (<a href="https://mathstodon.xyz/@11011110/107183397931741236">\(\mathbb{M}\)</a>). I’m not sure I agree that logic puzzles solved by intuition and guessing are better than ones where you have to make sufficiently deep deductions, but they both beat blind backtracking. I do agree that numberlinks should fill the grid as a natural consequence of connecting the numbers, not an extra constraint. And that <a href="http://mathgrant.blogspot.com/2010/10/grants-review-corner-volume-2.html">non-unique generators for puzzles whose solutions should be unique are an abomination</a>.</p>
  </li>
  <li>
    <p><a href="https://sinews.siam.org/Details-Page/preserving-the-history-of-applied-mathematics">Preserving the history of applied mathematics</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107191450699219701">\(\mathbb{M}\)</a>),</span> John Boyd in <em>SIAM News</em>.</p>
  </li>
  <li>
    <p><a href="https://www.npr.org/2021/10/30/1050817670/university-florida-professors-free-speech-voting-rights">University of Florida blocks faculty from being expert witnesses on voting rights, claiming that lawsuits against the state create a conflict of interest</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107198292249996684">\(\mathbb{M}\)</a>,</span> <a href="https://www.chronicle.com/article/u-of-florida-stops-professors-from-participating-in-voting-rights-suit-raising-cries-of-censorship">also</a>, <a href="https://www.nytimes.com/2021/10/29/us/florida-professors-voting-rights-lawsuit.html">also</a>). Beyond being an assault on academic freedom, this appears to violate the 1st amendment. US states can limit on-the-job speech, but here they would have testified on their own time, a routine activity that was blocked only because of its content.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/10/31/linkage.html"><span class="datestr">at October 31, 2021 06:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/10/31/assistant-professor-with-tenure-at-university-of-amsterdam-apply-by-november-22-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/10/31/assistant-professor-with-tenure-at-university-of-amsterdam-apply-by-november-22-2021/">Assistant Professor (with tenure) at University of Amsterdam (apply by November 22, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>We currently have a vacancy for an Assistant Professor in Model-Based AI at the Institute for Logic, Language and Computation (ILLC) at the University of Amsterdam. Relevant topics of expertise include SAT solving, constraint programming, planning and scheduling, answer set programming, description logics, ontology engineering, and computer-aided verification (non-exhaustive list).</p>
<p>Website: <a href="https://www.illc.uva.nl/NewsandEvents/News/Positions/newsitem/13023/Assistant-Professor-in-Model-Based-AI">https://www.illc.uva.nl/NewsandEvents/News/Positions/newsitem/13023/Assistant-Professor-in-Model-Based-AI</a><br />
Email: Ulle Endriss</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/10/31/assistant-professor-with-tenure-at-university-of-amsterdam-apply-by-november-22-2021/"><span class="datestr">at October 31, 2021 11:46 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/10/31/postdoc-at-university-of-california-irvine-apply-by-january-31-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/10/31/postdoc-at-university-of-california-irvine-apply-by-january-31-2022/">Postdoc  at University of California, Irvine (apply by January 31, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>UC Irvine has one postdoc position open to work in Vijay Vazirani’s group on algorithm design and algorithmic game theory. Can start anytime, one year, renewable one more year.</p>
<p>Website: <a href="https://recruit.ap.uci.edu/JPF07189">https://recruit.ap.uci.edu/JPF07189</a><br />
Email: <a href="https://recruit.ap.uci.edu/JPF07189">https://recruit.ap.uci.edu/JPF07189</a></p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/10/31/postdoc-at-university-of-california-irvine-apply-by-january-31-2022/"><span class="datestr">at October 31, 2021 11:36 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/10/30/two-counterexamples-covering">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/10/30/two-counterexamples-covering.html">Two counterexamples for covering points by two polygons</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>One of our students made a seminar presentation this week on the problem of covering
a given set of \(n\) points by two scaled and translated copies of a given convex <span style="white-space: nowrap;">\(k\)-gon,</span> minimizing the scale factor, based on a 2016 conference paper on the problem published by someone else. The presentation was good but the paper turns out to be wrong in several ways. I think it should not be difficult to find the paper if you look, but I’m avoiding naming it here: it’s uncited, so it hasn’t done much damage to the literature, its author’s other papers are not as far as I know problematic, the author appears to want to forget the paper (there was no journal version and it is not included in their online publication list), and I want to focus on the geometric nature of the mistakes rather than on pointing fingers.</p>

<p>The algorithm of the paper starts by (correctly) computing the optimal cover of the given points by a single copy of the polygon. This is a low-dimensional linear program, but one with \(O(nk)\) constraints, one for each pair of a side of the polygon and an input point to be covered. The paper makes the observation that the only pairs that matter are the ones that match each side to the extreme point in a perpendicular direction, and it uses a nice divide-and-conquer method to find these extreme points in time \(O(n\log k)\), which turns out to be the bottleneck of the algorithm.</p>

<p>It then tries to use this one-copy cover to speed up the two-copy cover, and this is where things go wrong. It claims that if the one-copy cover has five or more of its sides touched by input points, then the optimal two-copy cover has the same scale factor: there are so many touching points that three or more of them would all have to be in the same copy of the two-copy cover, and would force it to have the same size as the one-copy cover. This is false.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/6fixture-can-shrink.svg" alt="Even when a regular hexagon is touched on six sides by the points that it covers, it may be possible to cover the same points by two smaller regular hexagons" /></p>

<p>It claims that, when four or fewer sides of the one-copy cover are touched by input points, then for the optimal two-copy cover, one of the two copies will be touched on two sides with the same slopes. If true this would greatly simplify the search for the optimal partition into two subsets and the optimal scale factor for that partition. But it is false: there exist instances where the slopes of sides touched on the two-copy cover are completely disjoint from the slopes touched on the one-copy cover.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/4fixture-can-shrink.svg" alt="Even when an octagon is touched on four sides by the points that it covers, the smallest two scaled and translated octagons that cover the same points may not be touched on any of the same sides" /></p>

<p>I think what is going on here is a more general phenomenon relating to linear programming, rather than to this specific geometric optimization problem. Suppose you have a linear program with \(k\) variables (here, three variables for the scale factor and translation vector of the single-copy cover), and to keep things simple let’s say that it has a unique optimal solution. That solution will be determined by a basis, a minimal subset of inequalities with the same solution. The basis inequalities become tight equalities rather than inequalities, and if you know which ones they are then you can just solve these \(k\) linear equations in the \(k\) unknowns. However, more than \(k\) inequalities may be  tight, and there may be more than one basis. With some additional assumptions that are automatically satisfied here you can choose any <span style="white-space: nowrap;">\(k\)-tuple</span> of tight inequalities, solve linear equations, and get the same solution. But that does <em>not</em> mean that every <span style="white-space: nowrap;">\(k\)-tuple</span> of tight inequalities is a basis, and it does not mean that these tight inequalities stay tight for all subsets of the constraints.</p>

<p>Turning this idea back into geometry, in each of these figures, the inequalities come from pairs of a point and a polygon side. Each inequality states that its point must be contained in the halfspace bounded by its side, and it is tight when the point lies on the side. Any translated and scaled copy of a polygon is determined by points that touch any three of its sides. But forming a basis, for the problem of covering points with the smallest possible copy, is a stronger property. A set of three sides and (maybe fewer than three) touching points forms a basis only when the normal vectors to those sides do not span an angle less <span style="white-space: nowrap;">than \(\pi\).</span></p>

<p>For instance, for the hexagons of the first illustration, triples of consecutive sides have normal vectors that span only an angle <span style="white-space: nowrap;">of \(2\pi/3\),</span> too small to form a basis. Other triples of sides have normal vectors that are more spread out and do form a basis. The blue one-copy hexagon containing all of the points is optimal, because all six of its sides are touched, and many triples of those touched sides are non-consecutive. But when we split the points into the two yellow hexagons, each yellow hexagon contains the points that touch only a consecutive triple of blue sides, not a basis. Because they are not a basis, those three points (and the other points that are grouped along with them) can be contained in a smaller hexagon than the blue one. (Exercise: find a basis for one of the yellow hexagons, showing that at least for this partition into two subsets the scale factor is optimal.)</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107192319455242081">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/10/30/two-counterexamples-covering.html"><span class="datestr">at October 30, 2021 12:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
