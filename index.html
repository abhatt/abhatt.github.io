<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at June 12, 2021 12:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8133">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2021/06/11/causality-and-fairness/">Causality and Fairness</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>Scribe notes by Junu Lee, Yash Nair, and <a href="https://github.com/rxu18">Richard Xu</a>.</em></p>



<p><strong>Previous post:</strong> <a href="https://windowsontheory.org/2021/04/24/towards-a-theory-of-generalization-in-reinforcement-learning-guest-lecture-by-sham-kakade/">Toward a theory of generalization learning</a> <strong>Next post:</strong> TBD. </p>



<p>See also <a href="https://windowsontheory.org/category/ml-theory-seminar/">all seminar posts</a> and <a href="https://boazbk.github.io/mltheoryseminar/cs229br.html#plan">course webpage</a>.</p>



<p><a href="http://files.boazbarak.org/misc/mltheory/ML_seminar_lecture_6.pdf">lecture slides (pdf)</a> – <a href="http://files.boazbarak.org/misc/mltheory/ML_seminar_lecture_6.pptx">lecture slides (Powerpoint with animation and annotation)</a> – <a href="https://harvard.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=87a43259-6b47-49f1-931f-acfa0177fe20">video</a></p>



<p>Much of the material on causality is taken from the wonderful <a href="https://mlstory.org/">book by Hardt and Recht</a>.</p>



<p>For fairness, a central source was the <a href="https://fairmlbook.org/">book in preparation by Barocas, Hardt, and Narayanan</a> as well as the related <a href="https://fairmlbook.org/tutorial1.html">NeurIPS 2017 tutorial</a>, and other papers mentioned below.</p>



<h1>Causality</h1>



<p>We may have heard that <strong>“correlation does not imply causation”</strong>. How can we mathematically represent this statement, and furthermore differentiate the two rigorously?</p>



<p>Roughly speaking, <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="A" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="B" class="latex" /> are correlated if <img src="https://s0.wp.com/latex.php?latex=P%28B%3Db%7CA%3Da%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(B=b|A=a)" class="latex" /> is different for different values of <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="a" class="latex" />. To represent causation, we change the second part of the formula: <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="A" class="latex" /> causes <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="B" class="latex" /> if <em>intervening</em> to change <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="A" class="latex" /> to some value <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="a" class="latex" /> changes the probability of <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="B" class="latex" />. That is,</p>



<p><img src="https://s0.wp.com/latex.php?latex=Pr%28B%3Db%7C%5Ctext%7B+do+%7DA%5Cleftarrow+a%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Pr(B=b|\text{ do }A\leftarrow a)" class="latex" /></p>



<p>depends on <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="a" class="latex" />.</p>



<h2>Example of Causality</h2>



<p>Suppose we have the random variables <img src="https://s0.wp.com/latex.php?latex=X%2CW%2CH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X,W,H" class="latex" /> (taken over choice of a random person), which represent e<strong>X</strong>ercising, being over<strong>W</strong>eight and having <strong>H</strong>eart disease, respectively. We put forth the following (hypothetical! this is not medical advice!) scenarios for their relationships:</p>



<p><strong>Scenario 1.</strong> <img src="https://s0.wp.com/latex.php?latex=X%5Csim+Bern%281%2F2%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X\sim Bern(1/2)" class="latex" />. Now <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="W" class="latex" />, the overweight indicator, follows the causal relation:</p>



<p><img src="https://s0.wp.com/latex.php?latex=W+%5Csim+%5Cbegin%7Bcases%7D+0+%26+%5Ctext%7Bif+%7D+X+%3D+1%5C%5C+Bern%281%2F2%29+%26+%5Ctext%7Bif+%7D+X%3D0%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="W \sim \begin{cases} 0 &amp; \text{if } X = 1\\ Bern(1/2) &amp; \text{if } X=0\end{cases}" class="latex" /></p>



<p>and the heart disease indicator <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="H" class="latex" /> follows the same rule</p>



<p><img src="https://s0.wp.com/latex.php?latex=H+%5Csim+%5Cbegin%7Bcases%7D+0+%26+%5Ctext%7Bif+%7D+X+%3D+1%5C%5C+Bern%281%2F2%29+%26+%5Ctext%7Bif+%7D+X%3D0%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="H \sim \begin{cases} 0 &amp; \text{if } X = 1\\ Bern(1/2) &amp; \text{if } X=0\end{cases}" class="latex" /></p>



<p>So, in this scenario, exercise prevents heart disease and being overweight, while if we don’t exercise, we may be overweight or suffer from heart disease with probability 1/2 independently..</p>



<p><strong>Scenario 2.</strong> <img src="https://s0.wp.com/latex.php?latex=W%5Csim+Bern%281%2F4%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="W\sim Bern(1/4)" class="latex" /></p>



<p><img src="https://s0.wp.com/latex.php?latex=X%5Csim+%5Cbegin%7Bcases%7D+0+%26+%5Ctext%7Bif+%7D+W%3D+1%5C%5C+Bern%282%2F3%29+%26+%5Ctext%7Bif+%7D+W%3D0+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X\sim \begin{cases} 0 &amp; \text{if } W= 1\\ Bern(2/3) &amp; \text{if } W=0 \end{cases}" class="latex" /></p>



<p>and <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="H" class="latex" /> still depends on <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> in the same rule in the previous scenario. So, in this scenario, people are naturally prone to being overweight with probability 1/4, and being overweight makes you less likely to exercise, rather than the causal relation being in the other way around. As before, exercise prevents heart disease, and someone who did not exercise will get heart disease with probability 1/2.</p>



<p>We find that in scenario 1, <img src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7CX%3D0%29%3D1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(W=1|X=0)=1/2" class="latex" />. In scenario 2,</p>



<p><img src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7CX%3D0%29%3D%5Cfrac%7BP%28W%3D1%29P%28X%3D0%7CW%3D1%29%7D%7BP%28X%3D0%29%7D%3D%5Cfrac%7B%5Cfrac14%5Ccdot+1%7D%7B%5Cfrac14%2B%5Cfrac34%5Cfrac13%7D%3D%5Cfrac12.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(W=1|X=0)=\frac{P(W=1)P(X=0|W=1)}{P(X=0)}=\frac{\frac14\cdot 1}{\frac14+\frac34\frac13}=\frac12." class="latex" /></p>



<p>In fact, as this table shows, the probabilities for all combinations of <img src="https://s0.wp.com/latex.php?latex=X%2CW%2CH&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X,W,H" class="latex" /> are identical in the two scenarios!</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/HGYQ4eh.png" alt="" /></figure>



<p>Now, consider the intervention of setting <img src="https://s0.wp.com/latex.php?latex=X%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X=0" class="latex" />, i.e. stop exercising. That is, we change the generating model for <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> to be <img src="https://s0.wp.com/latex.php?latex=X%3A%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X:=0" class="latex" />. In scenario 1, <img src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7C%5Ctext%7B+do+%7DX%3D0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(W=1|\text{ do }X=0)" class="latex" /> is still <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="1/2" class="latex" />. In scenario 2, <img src="https://s0.wp.com/latex.php?latex=X%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X=0" class="latex" /> tells us nothing about <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="W" class="latex" /> now so we get <img src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7C%5Ctext%7B+do+%7DX%3D0%29%3D1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(W=1|\text{ do }X=0)=1/4" class="latex" />. Now that we added in an intervention, the two scenarios are different!</p>



<p>This is an example of why <strong>correlations are not causations</strong>: while the conditional probabilities <img src="https://s0.wp.com/latex.php?latex=%5CPr%28+W%3D1+%7CX%3D0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\Pr( W=1 |X=0)" class="latex" /> identical in the two scenarios, the causal probabilities are diffent <img src="https://s0.wp.com/latex.php?latex=P%28W%3D1%7C%5Ctext%7B+do+%7DX%3D0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(W=1|\text{ do }X=0)" class="latex" />.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/LGEGtvR.png" alt="" /></figure>



<p><strong><span style="color: #a30000;" class="has-inline-color">NOTE:</span></strong> Working out this example,  and understanding <strong>(a)</strong> why the two scenarios induce identical probabilities, and in particular all conditional probabilities are identical and <strong>(b)</strong> why the causal probabilities differ from the conditional probabilities in Scenario 2, is a great way to get intuition for causality and its pitfalls.</p>



<h2>Causal Probabilities and confounders</h2>



<p>Consider Scenario 1, where the causal structure is as follows:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/FJlQyaO.png" alt="" /></figure>



<p>Looking at the table above, we see that the unconditional probability <img src="https://s0.wp.com/latex.php?latex=P%28H%3D1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(H=1)" class="latex" /> equals <img src="https://s0.wp.com/latex.php?latex=1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="1/4" class="latex" />. Since in this scenario, there is no causal relation between being overweight and suffering from heat disease, the causal probability  <img src="https://s0.wp.com/latex.php?latex=P%28H%3D1+%7C+%5Ctext%7B+do+%7D+W+%5Cleftarrow+0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(H=1 | \text{ do } W \leftarrow 0)" class="latex" />  is also equal to  <img src="https://s0.wp.com/latex.php?latex=1%2F4&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="1/4" class="latex" />.</p>



<p>However, we can calculate the conditional probability from the table and see that <img src="https://s0.wp.com/latex.php?latex=P%28H%3D1%7CW%3D0%29%3D1%2F6&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(H=1|W=0)=1/6" class="latex" />.<br />That means that even though in this scenario, there is no causal relation between being overweight and getting heart disease, conditioning on not being overweight reduces the probability of getting heart disease.<br />Once again we see here a <strong>gap</strong> between the <strong>conditional </strong>and <strong>causal</strong> probabilities.</p>



<p>The reason is for this gap is that there is a <strong>counfounding variable</strong>, namely <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> that is a common cause of both <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="H" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="W" class="latex" />.</p>



<p><strong>Definition:</strong> <img src="https://s0.wp.com/latex.php?latex=H%2CW&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="H,W" class="latex" /> are <em>confounded</em> if there are values <img src="https://s0.wp.com/latex.php?latex=h%2Cw&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="h,w" class="latex" /> such that</p>



<p><img src="https://s0.wp.com/latex.php?latex=P%28H%3Dh%7C%5Ctext%7B+do+%7DW%3Dw%29%5Cneq+P%28H%3Dh%7CW%3De%29%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(H=h|\text{ do }W=w)\neq P(H=h|W=e)," class="latex" /></p>



<p>To fix the effect of a confounder, we condition on <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" />. It also allows us to find the probability of an intervention. The general <strong>deconfounding formula</strong> is</p>



<p><img src="https://s0.wp.com/latex.php?latex=P%28H%3Dh%7C%5Ctext%7B+do+%7DW%3Dw%29%3D%5Csum_x+P%28H%3Dh%7CW%3Dw%2C+X%3Dx%29+P%28X%3Dx%29%5C%3B%5C%3B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(H=h|\text{ do }W=w)=\sum_x P(H=h|W=w, X=x) P(X=x)\;\;" class="latex" />   (★),</p>



<p>where <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> ranges over all the immediate causes of <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="W" class="latex" />.</p>



<p>Contrast this with the formula for computing the conditional probability which is</p>



<p><img src="https://s0.wp.com/latex.php?latex=P%28H%3Dh+%7C+W%3Dw%29+%3D+%5Csum_x+P%28H%3Dh+%7C+W%3Dw%2C+X%3Dx%29+P%28X%3Dx+%7C+W%3Dw%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(H=h | W=w) = \sum_x P(H=h | W=w, X=x) P(X=x | W=w)" class="latex" /></p>



<p>Using the deconfounding formula (★) requires <strong>(a)</strong> knowing the causal graph, and <strong>(b)</strong> observing the confounders. If we get this wrong and control for the wrong confounders we can get the causal probabilities wrong, as demonstrated by the following example.</p>



<p><br />One way to describe causality theory is that it aims to clarify the situations under which <strong>correlation does in fact equal causation</strong> (i.e., the <strong>conditional probabilities are equal to the causal probabilities</strong>), and how (by appropriately controlling for confounders) we can get to such a situation.</p>



<p><strong>Example (two diseases)</strong> Consider the diagram below where there are two diseases <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y" class="latex" /> such that each occurs independently with probability <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="p" class="latex" />. We assume each will send you to the hospital (variable <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" />) and those are the only reason to arrive at the hospital.</p>



<p>If you control for <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> (i.e look at only people who went to the hospital), we find that the probabilities are now correlated: A priori the probability is <img src="https://s0.wp.com/latex.php?latex=p%2F%282p-p%5E2%29%5Capprox+1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="p/(2p-p^2)\approx 1/2" class="latex" />, and conditioned on <img src="https://s0.wp.com/latex.php?latex=X%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X=1" class="latex" />, the probability is <img src="https://s0.wp.com/latex.php?latex=p%5E2%2Fp%3Dp+%3C1%2F2&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="p^2/p=p &lt;1/2" class="latex" />.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/9mETSEo.png" alt="" /></figure>



<p>This relates to the joke “the probability of having 2 bombs on a plane is very low, so if I bring a bomb then it is very unlikely that there will be another bomb.”</p>



<p>In general, the causal graph can look as one of the following shapes:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/ARygORn.png" alt="" /></figure>



<p>If <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> is a fork then controlling for <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> can tease out the causal relation. If <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> is a mediator or collider then controlling for <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> can actually make things worse. –&gt;</p>



<p><strong>Backdoor paths:</strong> If <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y" class="latex" /> are two random variables, we say that there is a “backdoor path” from <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y" class="latex" /> if there is direct ancestor <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> that is connected in the undirected version of the causal graph in a path not going through <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" />.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/n45KXt9.png" alt="" /></figure>



<p>We can show the following theorem:</p>



<p><strong>Theorem:</strong> If there is no backdoor path then <img src="https://s0.wp.com/latex.php?latex=P%28Y%3Dy+%7C+%5Ctext%7B+do+%7D+X+%5Cleftarrow+X%29+%3D+P%28Y%3Dy%7CX%3Dx%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(Y=y | \text{ do } X \leftarrow X) = P(Y=y|X=x)" class="latex" /></p>



<p>Here is a “proof by picture”:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/UAC2lWE.png" alt="" /></figure>



<p>If there isn’t a backdoor path, we sort the graph in topological order, so that all the events that happen before <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> are not connected to <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y" class="latex" /> except through <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" />. So we can first generate all the variables <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="A" class="latex" /> that result in <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" />. Then the probability distribution of the events <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="B" class="latex" /> between <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y" class="latex" /> only depends on the value <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" /> of <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="X" class="latex" />, and so similarly <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y" class="latex" /> is generated from some probability distribution that only depends on <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="x" class="latex" />.</p>



<h2>Experimental Design</h2>



<p>When we design experiments, we often want to estimate <em>causal effects</em>, and to do so we try to make sure we eliminate backdoor paths.<br />Consider the example of a COVID vaccine trial.<br />We let <img src="https://s0.wp.com/latex.php?latex=V%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="V=1" class="latex" /> be the event that a trial participant obtained a vaccine, and <img src="https://s0.wp.com/latex.php?latex=C%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="C=1" class="latex" /> be the event that the participant was infected with COVID.<br />We want to figure out <img src="https://s0.wp.com/latex.php?latex=P%28C%3D1%7C%5Ctext%7B+do+%7DV%3D1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P(C=1|\text{ do }V=1)" class="latex" />.<br />However, there is a “backdoor path”.<br />You will not get the vaccine if you don’t participate in the trial (which we denote by <img src="https://s0.wp.com/latex.php?latex=V%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="V=1" class="latex" />), but particpating in the trial could change your behavior and hence have a causal effect on <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="C" class="latex" />.</p>



<p>To fix this we can cut the backdoor path using a placebo: it cuts the backward path by removing the confounding variable of participation, since it ensure that (conditioning on <img src="https://s0.wp.com/latex.php?latex=P%3D1&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="P=1" class="latex" />), <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="V" class="latex" /> is now an independent variable from any behavioral changes that might impact <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="C" class="latex" />.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/TfH4Bzn.png" alt="" /></figure>



<h2>Conditioning</h2>



<p>In general, how does conditioning on some variable <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> affect correlations? It may introduce correlations in events that occur before <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" />, but cuts any path that depends on <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" />.<br /><img src="https://i.imgur.com/Qk5p0s7.png" alt="" /></p>



<h2>Average Treatment Effect and Propensity Score</h2>



<p>Suppose we have some treatment variable <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="T" class="latex" /> that we don’t get to control (e.g. in a natural experiment). Let <img src="https://s0.wp.com/latex.php?latex=Y_t+%3D+Y%7C+%5Ctext%7B+do+%7D+T%3Dt&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y_t = Y| \text{ do } T=t" class="latex" /> , and we hope to estimate <img src="https://s0.wp.com/latex.php?latex=E%28Y_1%29-E%28Y_0%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="E(Y_1)-E(Y_0)" class="latex" /> which is known as the the <strong>treatment effect</strong>.<br />However, we worry that some underlying variable <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> (e.g. healthy lifestyle) can affect both <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="T" class="latex" />.</p>



<p>The <em>propensity score</em>, defined as <img src="https://s0.wp.com/latex.php?latex=e%28z%29%3DE%28T%7CZ%3Dz%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="e(z)=E(T|Z=z)" class="latex" />, allows us to calculate <img src="https://s0.wp.com/latex.php?latex=E%28Y%7C%5Ctext%7B+do+T%7D%3D1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="E(Y|\text{ do T}=1)" class="latex" />. We claim that as long as <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> is a valid confounder (for which the formula (★) holds)</p>



<p><img src="https://s0.wp.com/latex.php?latex=E%28Y%7C%5Ctext%7B+do+T%7D%3D1%29%3DE%28YT%2Fe%28Z%29%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="E(Y|\text{ do T}=1)=E(YT/e(Z))." class="latex" /></p>



<p>The proof is obtained by expanding out the claim, see below</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/gyKYlZn.png" alt="" /></figure>



<p>Intuitively, knowing the probability that different groups of people get treatment allows us to make <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="T" class="latex" /> independent from <img src="https://s0.wp.com/latex.php?latex=%28Y_0%2CY_1%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="(Y_0,Y_1)" class="latex" /> and calculate the treatment effect.</p>



<p><strong>Calculating treatment effect using ML.</strong> Suppose that the treatment effect is <img src="https://s0.wp.com/latex.php?latex=%5Ctau&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\tau" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=Y%3D%5Cpsi%28Z%29%2B%5Ctau+T%2B%5Ctext%7B+noise%7D&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y=\psi(Z)+\tau T+\text{ noise}" class="latex" />. Now, if we learn a model <img src="https://s0.wp.com/latex.php?latex=f%28z%29%5Capprox+E%28Y%7CZ%3Dz%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="f(z)\approx E(Y|Z=z)" class="latex" />, then</p>



<p><img src="https://s0.wp.com/latex.php?latex=Y-f%28z%29%5Capprox+%5Ctau%28T-e%28z%29%29.&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y-f(z)\approx \tau(T-e(z))." class="latex" /></p>



<p>Since both <img src="https://s0.wp.com/latex.php?latex=Y-f%28z%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y-f(z)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=T-e%28z%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="T-e(z)" class="latex" /> are calculable, we only need to do a linear regression.</p>



<h2>Instrumental Variables</h2>



<p>When we cannot observe the counfounding variable, we can still sometimes use <em>instrumental variables</em> to estimate a causal effect.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/XHo3Q5e.png" alt="" /></figure>



<p>Assume a linear model <img src="https://s0.wp.com/latex.php?latex=Y%3D%5Ctau+T%2Bf%28W%29&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Y=\tau T+f(W)" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="W" class="latex" /> is the stuff we don’t observe. If <img src="https://s0.wp.com/latex.php?latex=Z&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Z" class="latex" /> is some variable that satisfies <img src="https://s0.wp.com/latex.php?latex=Cov%28Z%2Cf%28W%29%29%3D0&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="Cov(Z,f(W))=0" class="latex" /> then</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Ctau%3D%5Cfrac%7BCov%28Z%2CY%29%7D%7BCov%28Z%2CT%29%7D%2C&amp;bg=ffffff&amp;fg=666666&amp;s=0&amp;c=20201002" alt="\tau=\frac{Cov(Z,Y)}{Cov(Z,T)}," class="latex" /></p>



<p>which is the ratio between two observable quantities.</p>



<h1>Fairness</h1>



<p>We focus on fairness in classification problems, rather than fairness in learning generative models or representation (which also have their own issues, see in particular <a href="https://dl.acm.org/doi/10.1145/3442188.3445922">this paper</a> by Bender, Gebru, McMillan-Major, and “Shmitchell”).</p>



<p>In the public image, AI has been perceived to be very successful for some tasks, and some people might hope that it is more “objective” or “impartial” than human decisions which are known to be <a href="https://www.nber.org/papers/w9873">fraught with bias</a>). However, there are some works suggesting this might not be the case:</p>



<ul><li>Usage in prediciting recidivism for bail decisions. For example in ProPublica <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Angwin, Larson, Mattu, and Kirchner</a> showed that 44.9% of African Americans who didn’t reoffend were labeled higher risk, whereas only 23.5% of white defendants who didn’t reoffend were labeled as such.</li><li>Machine vision can sometimes work better on some segments of population than others. For example, <a href="http://gendershades.org/">Buolamwini and Gebrue</a> showed that some “gender classifiers” achieve 99.7% accuracy on white men but only 65.3% accuracy (not much better than coin toss) on black women.</li><li><a href="https://rss.onlinelibrary.wiley.com/doi/full/10.1111/j.1740-9713.2016.00960.x">Lum and Isaac</a> gave an example of a “positive feedback loop” in predictive policing in Oakland, CA. While drug use is fairly uniform across the city, the arrests are centered on particular neighborhood (that have more minority residents). In predictive policing, more police would be sent out to the places where arrests occured, hence only exercabating this disparate treatment.</li></ul>



<p>Drug use in Oakland:<br /><img src="https://i.imgur.com/nrH0dEy.png" alt="" /></p>



<p>Drug arrests in Oakland:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/hIvgmEK.png" alt="" /></figure>



<p>While algorithms can sometimes also help, the populations they help might not be distributed equally. For example, see this table from <a href="https://www.tandfonline.com/doi/abs/10.1080/10511482.2002.9521447">Gates, Perry and Zorn</a>. A more accurate underwriting model (that can better predict the default probability) enables a lender to use a more agressive risk cut off and so end up lending to more people.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/xxms8Jk.png" alt="" /></figure>



<p>However, this is true within each subpopulation too, so it may be that if the model is less accurate in a certain subpopulation, then a profit-maximizing lender will unfairly offer fewer loans to this subpopulation.</p>



<h2>Formalizing Unfairness</h2>



<p>In the case of employment discrimination in the U.S., we have the following components:</p>



<ul><li>Protected class<ul><li>categories such as race, sex, nationality, citizenship, veteran status, etc.</li></ul></li><li>An unfairness metric, measuring either:<ul><li>disparate treatment</li><li>disparate impact.</li></ul></li></ul>



<p>Employers are not allowed to discriminate across protected classes when hiring. The unfairness metric gives us a way to measure if there is discrimination with respected to a protected class. In particular, disparate impacts across different protected classes is often <em>necessary</em> but <em>not sufficient</em> evidence of discrimination.</p>



<h2>Algorithms for Fairness: an Example</h2>



<p>To see why algorithms, which at first glance seem agnostic to group membership, may exhibit disparate treatment or impact, we consider the following <a href="https://research.google.com/bigpicture/attacking-discrimination-in-ml/">Google visualization by Wattenberg, Viégas, and Hardt</a>.</p>



<p>Consider a blue population and an orange population for which there is no difference in the probability of a member of either population paying back the loan, but for which our model has different accuracies—in particular, the model is more accurate on the orange population. This is described by the plot below, in which the scores correspond to the model’s prediction of the probability of paying back the loan and opaque circles correspond to those who actually do not pay back the loan, whereas filled in circles correspond to those who do.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/BEy6yqi.png" alt="" /></figure>



<p>Suppose we are in charge of making a lending decision given the model prediction.<br />A scenario in which we give everyone a loan would be fair, but would be bad us —we would go bankrupt!</p>



<p>Profit when giving everyone a loan:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/1uCdp2Q.png" alt="" /></figure>



<p>If we wanted to <strong>maximize profit</strong>, we would, however, give more loans to the orange population (since we’re more sure about which members of the orange population would actually pay back their loans) by setting a lower threshold (in terms of the score given by our algorithm) above which we give out loans.</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/Njtg1FU.png" alt="" /></figure>



<p>This maximizes profit but is blatantly unfair. We are treating the identical blue and orange groups differently, just because our model is more accurate on one than the other, and we also have disparate impact on the two groups. A non-defaulting applicant would be 78% likely to get a loan if they are a member of the orange group, but only 60% likely to get a loan if they are a member of the orange group.</p>



<p>This “profit maximization” is likely the end result of any sufficiently complex lending algorithm in the absence of a fairness intervention. Even if the algorithm does not explicitly rely on the group membership attribute, by simply optimizing it to maximize profit, it may well pick up on attributes that are correlated with group membership.</p>



<p>Suppose on the other hand that we wanted to mandate “equal treatment” in the sense of keeping the same thresholds for the blue and orange group. The result would be the following:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/c13O4Ly.png" alt="" /></figure>



<p>In this case, since the threshold are identical, the algorithm will be <strong>calibrated</strong>. 79% of the decisions we make will be the correct ones, for both the blue and orange population. So, from our point of view, the algorithm is fair and treats the blue and orange populations identically. However, from the point of view of the applicants, this is not the case. If you are a blue applicant that will pay your loan, you have 81% chance of getting a loan, but if you are an orange customer you only have 60% of getting it. This demonstrates that defining fairness is quite delicate. In particular the above “color blind” algorithm is still arguable unfair.</p>



<p>This difference between the point of view of the lender and lendee also arose in the recidivism case mentioned above. From the point of view of the defendant that would not recidivate, the algorithm was more likely to label them as “high risk” if they were Black than if they were white. From the point of view of the decision maker, the algorithm was calibrated, and if anything it was a bit more likely that a white defendant labeled high risk would not recidivate than a Black defendant. See (slightly rounded and simplified) data below</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/M73xLoe.png" alt="" /></figure>



<p></p>



<p>If we wanted to achieve demographic parity (both populations get same total number of loans) or equal opportunity (true positive rate same for both) then we can do so, but again using different thresholds for each group:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/uMHsFPz.png" alt="" /></figure>



<figure class="wp-block-image"><img src="https://i.imgur.com/pAnbY6m.png" alt="" /></figure>



<h2>Fico Scores and Different Types of Fairness</h2>



<p>While the above was a hypothetical scenario, a real life example was shown by <a href="https://arxiv.org/abs/1610.02413">Hardt, Price and Srebro</a> using credit (also known as FICO) scores, as described by the plot below:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/S8H0gjj.png" alt="" /></figure>



<p>For a single threshold, around 75% of Asian candidates will get loans, whereas only around 20% of Black candidates will get loans. To ensure that all groups get loans at the same rate, we would need to set the thresholds differently. In order to equalize opportunity, we’d also need to initialize the thresholds differently as well.</p>



<p>We see that we have different notions of what it means to be <em>fair</em> and that each of these different notions result in different algorithms.</p>



<h2>Fairness and Causality</h2>



<p>Berkeley graduate admissions in 1973 had the following statistics:</p>



<ul><li>44% male applicants admitted, 35% female applicants admitted;</li><li>However, female acceptance rate was higher at the <em>department level</em>, for most departments.</li></ul>



<figure class="wp-block-image"><img src="https://i.imgur.com/MizH3NY.png" alt="" /></figure>



<p>This paradox is commonly referred to as <a href="https://en.wikipedia.org/wiki/Simpson%27s_paradox">Simpson’s Paradox</a>.</p>



<p>A “fair” causal model for this scenario might be as follows:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/sVG4l7l.png" alt="" /></figure>



<p>In the above, perhaps gender has a causal impact on the choice of department to which the applicant applies. However, a fair application process would, conditional on the department, be independent of gender of the applicant.</p>



<p>However, not all models that follow this causal structure are necessarily <em>fair</em>. In the case Griggs v. Duke Power Co., 1971, the court ruled that decision-making under the following causal model was <em>unfair</em>:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/9f6iEKH.png" alt="" /></figure>



<p>While the model appears to be fair, since the job offer is conditionall independent of race, given the diploma, the court ruled that the job did not actually require a high school diploma. Hence, using the diploma as a factor in hiring decisions was really just a proxy for race, resulting in essentially purposeful unfair discrimination based on race. This creation of proxies is referred to as <a href="https://en.wikipedia.org/wiki/Redlining">redlining</a>.</p>



<h1>Bottom Line</h1>



<p>We cannot come up with universal fairness criteria. The notion of fairness itself is based on assumptions about:</p>



<ul><li>representation of data</li><li>relationships to unmeasured inputs and outcomes</li><li>causal relation of inputs, predictions, outcomes.</li></ul>



<p>Fairness depends on what we choose to measure to observe, in both inputs and outputs, and how we choose to act upon them. In particular, we have the following causal structure, wherein measure inputs, decision-making, and measured outcomes all play a role in affecting the real-world and function together in a feedback cycle:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/LcW07id.png" alt="" /></figure>



<p>A more comprehensive illustration is given in this paper of <a href="https://cacm.acm.org/magazines/2021/4/251365-the-impossibility-of-fairness/fulltext">Friedler, Scheidegger, and Venkatasubramanian</a>:</p>



<figure class="wp-block-image"><img src="https://i.imgur.com/4BaQTSH.png" alt="" /></figure></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2021/06/11/causality-and-fairness/"><span class="datestr">at June 11, 2021 08:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4522">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2021/06/10/benny-chor/">Benny Chor</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I just heard that Benny Chor died this morning. Chor did very important work on computational biology and distributed algorithms, but I (and probably many of my readers) know him primarily for his work on cryptography, for his work on randomness extraction and for introducing the notion of private information retrieval.</p>



<p>I only met him once, at the event for <a href="https://lucatrevisan.wordpress.com/2017/04/20/fests/">Oded Goldreich’s 60th birthday</a>. On the occasion, he gave a talk on the Chor-Goldreich paper, which introduced the problem of randomness extraction from independent sources, and which introduced min-entropy as the right parameter by which to quantify the randomness content of random sources. He did so using the original slides used for the FOCS 1985 talk.</p>



<figure class="wp-block-image size-large"><a href="https://lucatrevisan.files.wordpress.com/2017/04/img_6726.jpg"><img src="https://lucatrevisan.files.wordpress.com/2017/04/img_6726.jpg?w=768" alt="" class="wp-image-3735" /></a></figure>



<p>I took a picture during the talk, which I posted online, and later he sent me an email asking for the original. Sadly, this was the totality of our correspondence. I heard that besides being a brilliant and generous researchers, he was a very playful, likeable and nice person. My thoughts are with his family and his friends.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2021/06/10/benny-chor/"><span class="datestr">at June 10, 2021 08:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4515">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2021/06/10/the-simons-institute-reopens/">The Simons Institute Reopens</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This coming Fall semester the Simons Institute for the Theory of Computing in Berkeley will have in-person activities, including the really interesting program on the complexity of statistical inference, within which I will co-organize a <a href="https://simons.berkeley.edu/programs/si2021">workshop</a> on cryptography, average-case complexity, and the complexity of statistical problems.</p>
<p>As it had been the case before the pandemic, all Simons Institute events will be streamed and available remotely. This includes a new series of <a href="https://simons.berkeley.edu/events">Public Lectures</a> called <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">“Breakthroughs”</a> that starts next week with a talk by Virginia Williams on matrix multiplication.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2021/06/10/the-simons-institute-reopens/"><span class="datestr">at June 10, 2021 08:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5542">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5542">On Guilt</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>The other night Dana and I watched <a href="https://www.youtube.com/watch?v=9vz06QO3UkQ">“The Internet’s Own Boy,”</a> the 2014 documentary about the life and work of <a href="https://en.wikipedia.org/wiki/Aaron_Swartz">Aaron Swartz</a>, which I’d somehow missed when it came out.  Swartz, for anyone who doesn’t remember, was the child prodigy who helped create RSS and Reddit, who then became a campaigner for an open Internet, who was arrested for using a laptop in an MIT supply closet to download millions of journal articles and threatened with decades in prison, and who then committed suicide at age 26.  I regret that I never knew Swartz, though he did once send me a fan email about <em>Quantum Computing Since Democritus</em>.</p>



<p>Say whatever you want about the tactical wisdom or the legality of Swartz’s actions; it seems inarguable to me that he was <em>morally</em> correct, that certain categories of information (e.g. legal opinions and taxpayer-funded scientific papers) need to be made freely available, and that sooner or later our civilization will catch up to Swartz and regard his position as completely obvious.  The beautifully-made documentary filled me with rage and guilt not only that the world had failed Swartz, but that I personally had failed him.</p>



<p>At the time of Swartz’s arrest, prosecution, and suicide, I was an MIT CS professor who’d previously <a href="https://www.scottaaronson.com/writings/journal.html">written</a> in strong support of open access to scientific literature, and who had the platform of this blog.  Had I understood what was going on with Swartz—had I <em>taken the time to find out</em> what was going on—I could have been in a good position to help organize a grassroots campaign to pressure the MIT administration to urge prosecutors to drop the case (like JSTOR had already done), which could plausibly have made a difference.  As it was, I was preoccupied in those years with BosonSampling, getting married, etc., I didn’t bother to learn whether anything was being done or <em>could</em> be done about the Aaron Swartz matter, and then before I knew it, Swartz had joined Alan Turing in computer science’s pantheon of lost geniuses.</p>



<p>But maybe there was something deeper to my inaction.  If I’d strongly defended the substance of what Swartz had done, it would’ve raised the question: <em>why wasn’t I doing the same?</em>  Why was I merely complaining about paywalled journals from the comfort of my professor’s office, rather than putting my own freedom on the line like Swartz was?  It was as though I <em>had</em> to put some psychological distance between myself and the situation, in order to justify my life choices to myself.</p>



<p>Even though I see the error in that way of “thinking,” it keeps recurring, keeps causing me to make choices that I feel guilt or at least regret about later.  In February 2020, there were a few smart people saying that a new viral pneumonia from Wuhan was about to upend life on earth, but the people around me certainly weren’t <em>acting</em> that way, and <em>I</em> wasn’t acting that way either … and so, “for the sake of internal consistency,” I didn’t spend much time thinking about it or investigating it.  After all, if the fears of a global pandemic had a good chance of being true, I should be dropping everything else and panicking, shouldn’t I?  But I <em>wasn’t</em> dropping everything else and panicking … so how could the fears be true?</p>



<p>Then I <a href="https://www.scottaaronson.com/blog/?p=4695">publicly repented</a>, and resolved not to make such an error again.  And now, 15 months later, I realize that I <em>have</em> made such an error again.</p>



<p>All throughout the pandemic, I’d ask my friends, privately, why the hypothesis that the virus had accidentally leaked from the Wuhan Institute of Virology wasn’t being taken far more seriously, given what seemed like a shockingly strong <em>prima facie</em> case.  But I didn’t discuss the lab leak scenario on this blog, except once in passing.  I could <em>say</em> I didn’t discuss it because I’m not a virologist and I had nothing new to contribute.  But I worry that I also didn’t discuss it because it seemed incompatible with my self-conception as a cautious scientist who’s skeptical of lurid coverups and conspiracies—and because I’d already spent my “weirdness capital” on other issues, and didn’t relish the prospect of being sneered at on social media yet again.  Instead I simply waited for discussion of the lab leak hypothesis to become “safe” and “respectable,” as today it finally has, thanks to writers who were more courageous than I was.  I became, basically, another sheep in one of the conformist herds that we rightly despise when we read about them in history.</p>



<p>(For all that, it’s still plausible to me that the virus had a natural origin after all.  What’s become clear is simply that, <em>even if so</em>, the failure to take the possibility of a lab escape more seriously back when the trail of evidence was fresher will stand as a major intellectual scandal of our time.)</p>



<p>Sometimes people are wracked with guilt, but over completely different things than the world <em>wants</em> them to be wracked with guilt over.  This was one of the great lessons that I learned from reading Richard Rhodes’s <em><a href="https://www.amazon.com/Making-Atomic-Bomb-Richard-Rhodes/dp/1451677618">The Making of the Atomic Bomb</a></em>.  Many of the Manhattan Project physicists felt lifelong guilt, <em>not</em> that they’d participated in building the bomb, but only that they hadn’t <em>finished</em> the bomb by 1943, when it could have ended the war in Europe and the Holocaust.</p>



<p>On a much smaller scale, I suppose some readers would still like me to feel guilt about comment 171, or some of the other stuff I wrote about nerds, dating, and feminism … or if not that, then maybe about my defense of a two-state solution for Israel and Palestine, or of standardized tests and accelerated math programs, or maybe my vehement condemnation of Trump and his failed insurrection.  Or any of the dozens of other times when I stood up and said something I actually believed, or when I recounted my experiences as accurately as I could.  The truth is, though, I don’t.</p>



<p>Looking back—which, now that I’m 40, I confess is an increasingly large fraction of my time—the pattern seems consistent.  I feel guilty, not for having stood up for what I strongly believed in, but for having <em>failed</em> to do so.  This suggests that, if I want fewer regrets, then I should click “Publish” on more potentially controversial posts!  I don’t know how to force myself to do that, but maybe this post itself is a step.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5542"><span class="datestr">at June 10, 2021 05:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2554136414226144895">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/06/the-future-of-faculty-hiring.html">The Future of Faculty Hiring</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Faculty hiring in computer science is a <a href="https://blog.computationalcomplexity.org/2016/12/fixing-academic-job-market.html">process long due for an overhaul</a>. The pandemic certainly changed some of the dynamics moving most of the interviews online and saving a ton of money and time. Will this be the start of a fresh approach to recruiting?</p><p>A typical search in the past few years had some schools flying in 30-40 candidates, typically costing over a $1000 each and a full-time job for a staff member during the search. We'd justify the expense as small compared to the millions we'd invest in a faculty member throughout their career, but it is generally the largest discretionary expense for a CS department. It also gives advantages to rich departments over others.</p><p>During the pandemic all those interviews moved online and worked reasonably well at virtually no additional cost. Also no need to scrounge around to find faculty willing to skip family meals to have dinner with the candidates. And if a faculty had a conflict with a candidate on the interview day, they could schedule on a different day. There really is no reason to have all the meetings on the same day.</p><p>With the pandemic mostly behind us, will we go back to in-person interviews moving forward. I suspect the <a href="https://www.chronicle.com/article/whiffing-the-airport-interview/">airport interview</a>, where you fly out 20 or so candidates to have hour long interviews in a hotel near an airport with a search committee for an administrative position, will be the first to go completely virtual. </p><p>Even for regular faculty interviews, there will be great pressure to reduce the number of in-person visits, perhaps to just the top candidates, or just the ones who have offers--make the "second visit" the only visit. Richer departments may find the expense worthwhile to make a bigger impression on the candidates and that will only expand the advantage of wealthier universities.</p><p>Times like this are the perfect opportunity for CS leadership to come in and give some sanity to the hiring process but I'm not holding my breath.</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/06/the-future-of-faculty-hiring.html"><span class="datestr">at June 10, 2021 01:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/080">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/080">TR21-080 |  Hardness vs Randomness, Revised: Uniform, Non-Black-Box, and Instance-Wise | 

	Lijie Chen, 

	Roei Tell</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We propose a new approach to the hardness-to-randomness framework and to the promise-BPP=promise-P conjecture. Classical results rely on non-uniform hardness assumptions to construct derandomization algorithms that work in the worst-case, or rely on uniform hardness assumptions to construct derandomization algorithms that work only in the average-case. In both types of results, the derandomization algorithm is ``black-box'' and uses the standard PRG approach. In this work we present results that closely relate **new and natural uniform hardness assumptions** to **worst-case derandomization** of promise-BPP, where the algorithms underlying the latter derandomization are **non-black-box**.

In our main result, we show that promise-BPP=promise-P if the following holds: There exists a multi-output function computable by logspace-uniform circuits of polynomial size and depth $n^2$ that cannot be computed by uniform probabilistic algorithms in time $n^c$, for some universal constant $c&gt;1$, on **almost all inputs**. The required failure on ``almost all inputs'' is stronger than the standard requirement of failing on one input of each length; however, the same assumption without the depth restriction on $f$ is **necessary** for the conclusion. This suggests a potential equivalence between worst-case derandomization of promise-BPP of any form (i.e., not necessarily by a black-box algorithm) and the existence of efficiently computable functions that are hard for probabilistic algorithms on almost all inputs.

In our second result, we introduce a new and uniform hardness-to-randomness tradeoff for the setting of **superfast average-case derandomization**; prior to this work, superfast average-case derandomization was known only under non-uniform hardness assumptions. In an extreme instantiation of our new tradeoff, under appealing uniform hardness assumptions, we show that for every polynomial $T(n)$ and constant $\epsilon&gt;0$ it holds that $BPTIME[T]\subseteq heur-DTIME[T\cdot n^{\epsilon}]$, where the ``heur'' prefix means that no polynomial-time algorithm can find, with non-negligible probability, an input on which the deterministic simulation errs.

Technically, our approach is to design **targeted PRGs and HSGs**, as introduced by Goldreich (LNCS, 2011). The targeted PRGs/HSGs ``produce randomness from the input'', as suggested by Goldreich and Wigderson (RANDOM 2002); and their analysis relies on non-black-box versions of the reconstruction procedure of Impagliazzo and Wigderson (FOCS 1998). Our main reconstruction procedure crucially relies on the ideas underlying the proof system of Goldwasser, Kalai, and Rothblum (J. ACM 2015).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/080"><span class="datestr">at June 10, 2021 07:46 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/079">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/079">TR21-079 |  The zero-rate threshold for adversarial bit-deletions is less than 1/2 | 

	Venkatesan Guruswami, 

	Xiaoyu He, 

	Ray Li</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove that there exists an absolute constant $\delta&gt;0$ such any binary code $C\subset\{0,1\}^N$ tolerating $(1/2-\delta)N$ adversarial deletions must satisfy $|C|\le 2^{\poly\log N}$ and thus have rate asymptotically approaching $0$. This is the first constant fraction improvement over the trivial bound that codes tolerating $N/2$ adversarial deletions must have rate going to $0$ asymptotically.  Equivalently, we show that there exists absolute constants $A$ and $\delta&gt;0$ such that any set $C\subset\{0,1\}^N$ of $2^{\log^A N}$ binary strings must contain two strings $c$ and $c'$ whose longest common subsequence has length at least $(1/2+\delta)N$. As an immediate corollary, we show that $q$-ary codes tolerating a fraction $1-(1+2\delta)/q$ of adversarial deletions must also have rate approaching $0$.
 
Our techniques include string regularity arguments and a structural lemma that classifies binary strings by their oscillation patterns.  Leveraging these tools, we find in any large code two strings with similar oscillation patterns, which is exploited to find a long common subsequence.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/079"><span class="datestr">at June 09, 2021 04:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=21799">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/">To cheer you up in difficult times 26: Two real-life lectures yesterday at the Technion</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>After 16 months without lecturing to an audience in my same location, I gave yesterday two lectures at the Technion in front of a live audience (and some additional audience in remote locations). The main lecture was in <a href="https://comsoc2021.net.technion.ac.il/">COMSOC 2021,</a> an international conference on computational social choice,  and earlier I gave a guest lecture in Roy Meshulam’s class about simple polytopes. I also met many friends. </p>
<p><a href="https://reshef.net.technion.ac.il/">Reshef Meir</a> who organized (with Bill Zwicker) COMSOC 2021 wrote:</p>
<blockquote>
<div><span style="color: #993366;"><em>Hi all, </em></span></div>
<div><span style="color: #993366;"><em>today was beyond expectations – the first feeling of a real actual conference after almost a year and a half!  We had about 40 people attending, viewing posters, and listening to talks. I truly hope this will return to be a common scene and that we can all meet face to face soon.</em></span></div>
</blockquote>
<div> </div>
<p>In my COMSOC lecture I talked about some earlier ideas and results in my work on social choice, starting with my paper with Ariel Rubinstein and Rani Spiegler on rationalizing individual choice by multiple rationals, and my subsequent attempt to use learnability as a tool for understanding choices of economic agents. This led to interesting questions on social choice <a href="https://gilkalai.wordpress.com/2009/06/02/social-choice-preview/">that are discussed in this 2009 post.</a></p>
<p>In Roy’s course I explained <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="h" class="latex" />-vectors of polytopes and the Dehn-Sommerville relations based on counting outdegrees of the graph of the polytope when we direct its edges based on a generic abstract objective function. I moved on to present a proof of Blind-Mani’s theorem that the graph of the polytope determines the full combinatorics. This proof is probably the one proof I presented the most and it is given in <a href="https://gilkalai.wordpress.com/2009/01/16/telling-a-simple-polytope-from-its-graph/">this 2009 post</a>.</p>
<p><img width="420" alt="sc1" src="https://gilkalai.files.wordpress.com/2021/06/sc1.png" class="alignnone size-full wp-image-21802" height="391" /></p>
<p><span style="color: #ff0000;">In my  COMSOC lecture I described how to fill the two question marks in the table above.</span></p>
<p><img width="420" alt="sc2" src="https://gilkalai.files.wordpress.com/2021/06/sc2.png" class="alignnone size-full wp-image-21803" height="391" /></p>


<p></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/"><span class="datestr">at June 09, 2021 06:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1526">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1526">News for May 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>We hope you are all staying safe. With massive vaccination programs across the globe we hope you and your loved ones are getting back to what used to be normal. With that out of the way, let us circle back to Property Testing. This month was less sleepy as compared to the two preceding months and we saw six papers in total (two of them explore problems in quantum property testing). Without further ado, let us take a deeper dive.</p>



<p></p>



<p><strong>GSF-locality is not sufficient for proximity-oblivious testing</strong>, by Isolde Adler, Noleen Kohler, Pan Peng (<a href="https://arxiv.org/abs/2105.08490">arXiv</a>) The notion of proximity oblivious testers was made explicit in the seminal work of Goldreich and Ron in 2009 [GR09]. A proximity oblivious tester for a graph property is a constant query tester that rejects a graph with probability that monotonically increases with distance to the property. (<strong>Edit</strong>: <em>Correction</em>) A property is called proximity oblivious testable (or PO testable) if it has a one sided proximity oblivious tester. [GR09] gave a characterization of which properties \(\Pi\) are PO testable in the bounded degree model <em>if and only if</em> it is a “local” property of some kind which satisfies a certain non propagation condition. [GR09] conjectured that all such “local” properties satisfy this non propagation condition. This paper refutes the above conjecture from [GR09].</p>



<p></p>



<p>Coming up next. More action on triangle freeness.</p>



<p><strong>Testing Triangle Freeness in the General Model in Graphs with Arboricity \(O(\sqrt n)\)</strong>, by Reut Levi (<a href="https://arxiv.org/abs/2105.04809">arXiv</a>) PTReview readers are likely to be aware that triangle freeness has been a rich source of problems for developing new sublinear time algorithms. This paper considers the classic problem of testing triangle freeness in general graphs. In the dense case, algorithms with running time depending only on \(\varepsilon\) are known thanks to the work of Alon, Fischer, Krivelevich and Szegedy. In the bounded degree case, Goldreich and Ron gave testers with query complexity \(O(1/\varepsilon)\). This paper explores the problem in general graph case and proves an upper bound of \(O(\Gamma/d_{avg} + \Gamma)\) where \(\Gamma\) is the arboricity of the graph. The author also shows that this upperbound is tight for graphs with arboricity at most \(O(\sqrt n)\). Curiously enough, the algorithm does not take arboricity of the graph as an input and yet \(\Gamma\) (the arboricity) shows up in the upper and lower bounds.</p>



<p></p>



<p><strong>Testing Dynamic Environments: Back to Basics</strong>, by Yonatan Nakar and Dana Ron (<a href="https://arxiv.org/abs/2105.00759">arXiv</a>) Goldreich and Ron introduced the problem of testing “dynamic environments” in 2014. Here is the setup for this problem. You are given an environment that evolves according to a local rule.  Your goal is to query some of the states in the system at some point of time and determine if the system is evolving according to some fixed rule or is far from it. In this paper, the authors consider environments defined by elementary cellular automata which evolve according to threshold rules as one of the first steps towards understanding what makes a dynamic environment tested efficiently.  The main result proves the following: if your local rules satisfy some <em>conditions</em>, you can use a meta algorithm with query complexity \(poly(1/\varepsilon)\) which is non adaptive and has one sided error. And all the threshold rules indeed satisfy these <em>conditions</em> which means they can be tested efficiently. </p>



<p></p>



<p><strong>Identity testing under label mismatch</strong>, by Clement Canonne and Karl Wimmer (<a href="https://arxiv.org/abs/2105.01856">arXiv</a>) This paper considers a classic problem distribution testing with the following twist. Let \(q\) denote a distribution supported on \([n]\). You are given access to samples from another distribution \(p\) where \(p  = q \circ \pi\) where \(\pi\) is some unknown permutation. Thus, I relabel the data and I give you access to samples from the relabeled dataset. Under this promise, note that identity testing becomes a trivial problem if \(q\) is known to be uniform over \([n]\). The authors develop algorithms for testing and tolerant testing of distributions under this additional promise of \(p\) being a permutation of some known distribution \(q\). The main result shows as exponential gap between the sample complexity of testing and tolerant testing under this promise. In particular, identity testing under the promise of permutation has sample complexity \(\Theta(\log^2 n)\) whereas tolerant identity testing under this promise has sample complexity \(\Theta(n^{1-o(1)})\).</p>



<p></p>



<p><strong>Testing symmetry on quantum computers</strong>, by Margarite L. LaBorde and Mark M. Wilde (<a href="https://arxiv.org/abs/2105.12758">arXiv</a>) This paper develops algorithms which test symmetries of a quantum states and changes generated by quantum circuits. These tests additionally also quantify how symmetric these states (or channels) are. For testing what are called “Bose states” the paper presents efficient algorithms. The tests for other kinds of symmetry presented in the paper rely on some aid from a quantum prover.</p>



<p></p>



<p><strong>Quantum proofs of proximity</strong>, by Marcel Dall’Agnol, Tom Gur, Subhayan Roy Moulik, Justin Thaler (<a href="https://eccc.weizmann.ac.il/report/2021/068/">ECCC</a>) The sublinear time (quantum) computation model has been gathering momentum steadily over the past several years. This paper seeks to understand the power of \({\sf QMA}\) proofs of proximity for property testing (recall \({\sf QMA}\) is the quantum analogue of \({\sf NP}\)). On the algorithmic front, the paper develops sufficient conditions for properties to admit efficient \({\sf QMA}\) proofs of proximity. On the complexity front, the paper demonstrates a property which admits  an efficient \({\sf QMA}\) proof but does not admit a \({\sf MA}\) or an interactive proof of proximity.</p></div>







<p class="date">
by Akash <a href="https://ptreview.sublinear.info/?p=1526"><span class="datestr">at June 09, 2021 05:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5539">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5539">More quantum computing popularization!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I now have a feature article up at <em>Quanta</em> magazine, entitled <a href="https://www.quantamagazine.org/why-is-quantum-computing-so-hard-to-explain-20210608/">“What Makes Quantum Computing So Hard To Explain?”</a>  I.e., why do journalists, investors, etc. so consistently get central points wrong, even after the subject has been in public consciousness for more than 25 years?  Perhaps unsurprisingly, I found it hard to discuss that meta-level question, as <em>Quanta</em>‘s editors asked me to do, without also engaging in the object-level task of actually explaining QC.  For regular <em>Shtetl-Optimized</em> readers, there will be nothing new here, but I’m happy with how the piece turned out.</p>



<p>Accompanying the <em>Quanta</em> piece is a <a href="https://www.youtube.com/watch?v=jHoEjvuPoB8&amp;t=6s">10-minute YouTube explainer on quantum computing</a>, which (besides snazzy graphics) features interviews with me, John Preskill, and Dorit Aharonov.</p>



<p>On a different note, my colleague <a href="https://www.markwilde.com/">Mark Wilde</a> has recorded a <a href="https://soundcloud.com/mark-m-wilde/quantum-computer">punk-rock song about BosonSampling</a>.  I can honestly report that it’s some of the finest boson-themed music I’ve heard in years.  It includes the following lyrics:</p>



<blockquote class="wp-block-quote"><p>Quantum computer, Ain’t no loser<br />Quantum computer, Quantum computer</p><p>People out on the streets<br />They don’t know what it is<br />They think it finds the cliques<br />Or finds graph colorings<br />But it don’t solve anything<br />Said it don’t solve anything<br />Bosonic slot machine<br />My lil’ photonic dream</p></blockquote>



<p>Speaking of BosonSampling, A. S. Popova and A. N. Rubtsov, of the Skolkovo Institute in Moscow, have a new preprint entitled <a href="https://arxiv.org/abs/2106.01445">Cracking the Quantum Advantage threshold for Gaussian Boson Sampling</a>.  In it, they claim to give an efficient classical algorithm to simulate noisy GBS experiments, like the <a href="https://www.scottaaronson.com/blog/?p=5159">one six months ago</a> from USTC in China.  I’m still unsure how well this scales from 30-40 photons up to 50-70 photons; which imperfections of the USTC experiment are primarily being taken advantage of (photon losses?); and how this relates to the earlier proposed classical algorithms for simulating noisy BosonSampling, like the one by <a href="https://arxiv.org/abs/1409.3093">Kalai and Kindler</a>.  Anyone with any insight is welcome to share!</p>



<p>OK, one last announcement: the Simons Institute for the Theory of Computing, in Berkeley, has a new online lecture series called <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">“Breakthroughs,”</a> which many readers of this blog might want to check out.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5539"><span class="datestr">at June 08, 2021 08:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/078">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/078">TR21-078 |  A direct product theorem for quantum communication complexity with applications to device-independent QKD | 

	Rahul  Jain, 

	Srijita Kundu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give a direct product theorem for the entanglement-assisted interactive quantum communication complexity of an $l$-player predicate $V$. In particular we show that for a distribution $p$ that is product across the input sets of the $l$ players, the success probability of any entanglement-assisted quantum communication protocol for computing $n$ copies of $V$, whose communication is $o(\log(\mathrm{eff}^*(V,p))\cdot n)$, goes down exponentially in $n$. Here $\mathrm{eff}^*(V, p)$ is a distributional version of the quantum efficiency or partition bound introduced by Laplante, Lerays and Roland (2014), which is a lower bound on the distributional quantum communication complexity of computing a single copy of $V$ with respect to $p$.
  As an application of our result, we show that it is possible to do device-independent quantum key distribution (DIQKD) without the assumption that devices do not leak any information after inputs are provided to them. We analyze the DIQKD protocol given by Jain, Miller and Shi (2017), and show that when the protocol is carried out with devices that are compatible with $n$ copies of the Magic Square game, it is possible to extract $\Omega(n)$ bits of key from it, even in the presence of $O(n)$ bits of leakage. Our security proof is parallel, i.e., the honest parties can enter all their inputs into their devices at once, and works for a leakage model that is arbitrarily interactive, i.e., the devices of the honest parties Alice and Bob can exchange information with each other and with the eavesdropper Eve in any number of rounds, as long as the total number of bits or qubits communicated is bounded.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/078"><span class="datestr">at June 08, 2021 12:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8127">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2021/06/07/new-seminar-series-in-simons-institute/">New seminar series in Simons Institute</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Simons institute started a <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">new virtual seminar</a> series highlighting recent advances in theoretical computer science. The first two talks in the series will be:</p>



<ul><li>June 16th 10am-11am PDT (1pm-2pm EDT). Virginia Vassilevska Williams on a  <a href="https://simons.berkeley.edu/events/breakthroughs-refined-laser-method-and-faster-matrix-multiplication">Refined Laser Method and Faster Matrix Multiplication</a></li><li>August 5 10am-11am PDT (1pm-2pm EDT) Yuansi Chen on <a href="https://simons.berkeley.edu/events/breakthroughs-almost-constant-lower-bound-isoperimetric-coefficient-kls-conjecture-0">An Almost Constant Lower Bound of the Isoperimetric Coefficient in the KLS Conjecture</a></li></ul>



<p></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2021/06/07/new-seminar-series-in-simons-institute/"><span class="datestr">at June 07, 2021 06:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/icml2021/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/icml2021/">Conference Digest - ICML 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a href="https://icml.cc/Conferences/2021">ICML 2021</a>, one of the biggest conferences in machine learning, naturally has a ton of interesting sounding papers on the topic of differential privacy.
We went through this year’s <a href="https://icml.cc/Conferences/2021/AcceptedPapersInitial">accepted papers</a> and aggregated all the relevant papers we could find.
In addition, this year features three workshops on the topic of privacy, as well as a tutorial.
As always, please inform us if we overlooked any papers on differential privacy.</p>

<h2 id="workshops">Workshops</h2>

<ul>
  <li>
    <p><a href="http://federated-learning.org/fl-icml-2021/">Federated Learning for User Privacy and Data Confidentiality</a></p>
  </li>
  <li>
    <p><a href="https://sites.google.com/view/ml4data">Machine Learning for Data: Automated Creation, Privacy, Bias</a></p>
  </li>
  <li>
    <p><a href="https://tpdp.journalprivacyconfidentiality.org/2021/">Theory and Practice of Differential Privacy</a></p>
  </li>
</ul>

<h2 id="tutorial">Tutorial</h2>

<ul>
  <li><a href="https://icml.cc/Conferences/2021/Schedule?showEvent=10839">Privacy in Learning: Basics and the Interplay</a><br />
<a href="https://www.microsoft.com/en-us/research/people/huzhang/">Huishuai Zhang</a>, <a href="https://www.microsoft.com/en-us/research/people/weic/">Wei Chen</a></li>
</ul>

<h2 id="papers">Papers</h2>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/2009.02668">A Framework for Private Matrix Analysis in Sliding Window Model</a><br />
<a href="https://sites.google.com/view/jalajupadhyay/home">Jalaj Upadhyay</a>, <a href="https://www.fujitsu.com/us/about/businesspolicy/tech/rd/research-staff/sarvagya.html">Sarvagya Upadhyay</a></p>
  </li>
  <li>
    <p>Accuracy, Interpretability, and Differential Privacy via Explainable Boosting<br />
<a href="https://scholar.google.com/citations?user=HmxjgMAAAAAJ">Harsha Nori</a>, <a href="https://www.microsoft.com/en-us/research/people/rcaruana/">Rich Caruana</a>, <a href="https://sites.google.com/view/zhiqi-bu">Zhiqi Bu</a>, <a href="https://heyyjudes.github.io/">Judy Hanwen Shen</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan Kulkarni</a></p>
  </li>
  <li>
    <p>Differentially Private Aggregation in the Shuffle Model: Almost Central Accuracy in Almost a Single Message<br />
<a href="https://sites.google.com/view/badihghazi/home">Badih Ghazi</a>, <a href="https://sites.google.com/site/ravik53/">Ravi Kumar</a>, <a href="https://pasin30055.github.io/">Pasin Manurangsi</a>, <a href="https://rasmuspagh.net/">Rasmus Pagh</a>, <a href="https://www.linkedin.com/in/amersinha/">Amer Sinha</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2011.00467">Differentially Private Bayesian Inference for Generalized Linear Models</a><br />
<a href="https://warwick.ac.uk/fac/sci/dcs/people/u1554597">Tejas Kulkarni</a>, <a href="https://users.aalto.fi/~jalkoj1/">Joonas Jälkö</a>, <a href="https://scholar.google.com/citations?user=Y_EvCPAAAAAJ">Antti Koskela</a>, <a href="https://people.aalto.fi/samuel.kaski">Samuel Kaski</a>, <a href="https://www.cs.helsinki.fi/u/ahonkela/">Antti Honkela</a></p>
  </li>
  <li>
    <p>Differentially-Private Clustering of Easy Instances<br />
<a href="http://www.cohenwang.com/edith/">Edith Cohen</a>, <a href="http://www.cs.tau.ac.il/~haimk/">Haim Kaplan</a>, <a href="https://www.tau.ac.il/~mansour/">Yishay Mansour</a>, <a href="https://www.uri.co.il/">Uri Stemmer</a>, <a href="https://www.linkedin.com/in/eliad-tsfadia-21482b96/">Eliad Tsfadia</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.08885">Differentially Private Correlation Clustering</a><br />
<a href="https://cs-people.bu.edu/mbun/">Mark Bun</a>, <a href="https://elias.ba30.eu/">Marek Elias</a>, <a href="https://www.microsoft.com/en-us/research/people/jakul/">Janardhan Kulkarni</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2105.13287">Differentially Private Densest Subgraph Detection</a><br />
<a href="https://biocomplexity.virginia.edu/person/dung-nguyen">Dung Nguyen</a>, <a href="https://engineering.virginia.edu/faculty/anil-vullikanti">Anil Vullikanti</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.08244">Differentially Private Quantiles</a><br />
<a href="http://jgillenw.com/">Jennifer Gillenwater</a>, <a href="https://www.majos.net/">Matthew Joseph</a>, <a href="https://www.alexkulesza.com/">Alex Kulesza</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.06641">Differentially Private Query Release Through Adaptive Projection</a><br />
<a href="https://sergulaydore.github.io/">Sergul Aydore</a>, <a href="https://wibrown.github.io/">William Brown</a>, <a href="https://www.cis.upenn.edu/~mkearns/">Michael Kearns</a>, <a href="http://www-cs-students.stanford.edu/~kngk/">Krishnaram Kenthapadi</a>, <a href="https://www.lucamel.is/">Luca Melis</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, <a href="https://ankitsiva.xyz/">Ankit Siva</a></p>
  </li>
  <li>
    <p>Differentially Private Sliced Wasserstein Distance<br />
<a href="http://asi.insa-rouen.fr/enseignants/~arakoto/">Alain Rakotomamonjy</a>, <a href="https://pageperso.lif.univ-mrs.fr/~liva.ralaivola/doku.php">Liva Ralaivola</a></p>
  </li>
  <li>
    <p>Large Scale Private Learning via Low-rank Reparametrization<br />
<a href="https://scholar.google.com/citations?user=FcRGdiwAAAAJ">Da Yu</a>, <a href="https://www.microsoft.com/en-us/research/people/huzhang/">Huishuai Zhang</a>, <a href="https://www.microsoft.com/en-us/research/people/weic/">Wei Chen</a>, Jian Yin, <a href="https://www.microsoft.com/en-us/research/people/tyliu/">Tie-Yan Liu</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.08598">Leveraging Public Data for Practical Private Query Release</a><br />
<a href="https://www.linkedin.com/in/terrance-liu-26796974/">Terrance Liu</a>, <a href="https://sites.google.com/umn.edu/giuseppe-vietri/home">Giuseppe Vietri</a>, <a href="http://www.thomas-steinke.net/">Thomas Steinke</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a>, <a href="https://zstevenwu.com/">Steven Wu</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2104.09734">Locally Private k-Means in One Round</a><br />
Alisa Chang, <a href="https://sites.google.com/view/badihghazi/home">Badih Ghazi</a>, <a href="https://sites.google.com/site/ravik53/">Ravi Kumar</a>, <a href="https://pasin30055.github.io/">Pasin Manurangsi</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.12099">Lossless Compression of Efficient Private Local Randomizers</a><br />
<a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2105.08233">Oneshot Differentially Private Top-k Selection</a><br />
<a href="https://lsa.umich.edu/stats/people/phd-students/qiaogang.html">Gang Qiao</a>, <a href="http://www-stat.wharton.upenn.edu/~suw/">Weijie Su</a>, <a href="https://research.google/people/LiZhang/">Li Zhang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2002.12321">PAPRIKA: Private Online False Discovery Rate Control</a><br />
<a href="https://wanrongz.github.io/">Wanrong Zhang</a>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, <a href="https://sites.gatech.edu/rachel-cummings/">Rachel Cummings</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.00039">Practical and Private (Deep) Learning without Sampling or Shuffling</a><br />
<a href="https://kairouzp.github.io/">Peter Kairouz</a>, <a href="https://research.google/people/author35837/">Brendan McMahan</a>, <a href="https://shs037.github.io/">Shuang Song</a>, <a href="http://www.omthakkar.com/">Om Thakkar</a>, <a href="https://athakurta.squarespace.com/">Abhradeep Thakurta</a>, <a href="https://research.google/people/106689/">Zheng Xu</a></p>
  </li>
  <li>
    <p>Private Adaptive Gradient Methods for Convex Optimization<br />
<a href="http://web.stanford.edu/~asi/">Hilal Asi</a>, <a href="https://web.stanford.edu/~jduchi/">John Duchi</a>, <a href="https://afallah.lids.mit.edu/">Alireza Fallah</a>, <a href="https://scholar.google.com/citations?user=_JXjrEp9FhYC">Omid Javidbakht</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p>Private Alternating Least Squares: (Nearly) Optimal Privacy/Utility Trade-off for Matrix Completion<br />
Steve Chien, <a href="https://www.prateekjain.org/">Prateek Jain</a>, <a href="http://walid.krichene.net/">Walid Krichene</a>, <a href="https://scholar.google.com/citations?user=yR-ugIoAAAAJ">Steffen Rendle</a>, <a href="https://shs037.github.io/">Shuang Song</a>, <a href="https://athakurta.squarespace.com/">Abhradeep Thakurta</a>, <a href="https://research.google/people/LiZhang/">Li Zhang</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2103.01516">Private Stochastic Convex Optimization: Optimal Rates in L1 Geometry</a><br />
<a href="http://web.stanford.edu/~asi/">Hilal Asi</a>, <a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="https://tomerkoren.github.io/">Tomer Koren</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2102.06387">The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation</a><br />
<a href="https://kairouzp.github.io/">Peter Kairouz</a>, <a href="https://kenziyuliu.github.io/">Ziyu Liu</a>, <a href="http://www.thomas-steinke.net/">Thomas Steinke</a></p>
  </li>
</ul></div>







<p class="date">
by Gautam Kamath <a href="https://differentialprivacy.org/icml2021/"><span class="datestr">at June 07, 2021 04:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=857">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2021/06/07/data-structure-lower-bounds-without-encoding-arguments/">Data-structure lower bounds without encoding arguments</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>                        </p>
<p style="text-align: justify;">I have recently posted the paper <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-rank-samp">Vio21</a>]</span> (<a href="https://eccc.weizmann.ac.il/report/2021/073/">download</a>) which does something that I have been trying to do for a long time, more than ten years, on and off. Consider the basic data-structure problem of storing <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="m" class="latex" /> bits of data <img src="https://s0.wp.com/latex.php?latex=x%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bm%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="x\in \{0,1\}^{m}" class="latex" /> into <img src="https://s0.wp.com/latex.php?latex=m%2Br&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="m+r" class="latex" /> bits so that the <em>prefix-sum queries</em></p>
<div style="text-align: center;"> <img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7B%5Ctext+%7B%5Ctextsc+%7BRank%7D%7D%7D%28i%29%3A%3D%5Csum+_%7Bj%5Cle+i%7Dx_%7Bj%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\begin{aligned} \mathbb {\text {\textsc {Rank}}}(i):=\sum _{j\le i}x_{j} \end{aligned}" class="latex" /></div>
<p style="text-align: justify;">   can be computed by probing <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="q" class="latex" /> <em>cells</em> (or <em>words</em>) of <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w" class="latex" /> bits each. (You can think <img src="https://s0.wp.com/latex.php?latex=w%3D%5Clog+m&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w=\log m" class="latex" /> throughout this post.) The paper <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascuV10">PV10</a>]</span> with Pǎtraşcu shows that <img src="https://s0.wp.com/latex.php?latex=r%5Cge+m%2Fw%5E%7BO%28q%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="r\ge m/w^{O(q)}" class="latex" />, and this was recently shown to be tight by Yu <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/conf/stoc/Yu19">Yu19</a>]</span> (building on the breakthrough data structure <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascu08Succincter">Pǎt08</a>]</span> which motivated the lower bound and is not far from it).</p>
<p style="text-align: justify;">   As is common in data-structure lower bounds, the proof in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascuV10">PV10</a>]</span> is an <em>encoding argument</em>. In the recently posted paper, an alternative proof is presented which avoids the encoding argument and is perhaps more in line with other proofs in complexity lower bounds. Of course, <em>everything</em> is an encoding argument, and <em>nothing </em>is an encoding argument, and this post won’t draw a line.</p>
<p style="text-align: justify;">   The new proof establishes an <em>intrinsic property</em> of efficient data structures, whereas typical proofs including <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XPatrascuV10">PV10</a>]</span> are somewhat tailored to the problem at hand. The property is called the <em>separator</em> and is a main technical contribution of the work. At the high level the separator shows that in any efficient data structure you can restrict the input space a little so that many queries are nearly <em>pairwise independent</em>.</p>
<p style="text-align: justify;">   Also, the new proof rules out a stronger object: a <em>sampler</em> (<a href="https://emanueleviola.wordpress.com/2014/11/09/is-nature-a-low-complexity-sampler/">see previous post here</a> on sampling lower bounds). Specifically, the distribution Rank<img src="https://s0.wp.com/latex.php?latex=%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="(U)" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="U" class="latex" /> is the uniform distribution cannot be sampled, not even slightly close, by an efficient cell-probe algorithm. This implies the data-structure result, and it can be informally interpreted as saying that the “reason” why the lower bound holds is not that the data is compressed, but rather that one can’t generate the type of dependencies occurring in Rank via an efficient cell-probe algorithm, regardless of what the input is.</p>
<p style="text-align: justify;">   Building on this machinery, one can prove several results about sampling, like showing that cell-probe samplers are strictly weaker than AC0 samplers. While doing this, it occurred to me that one gets a corollary for data structures which I had not seen in the literature. The corollary is a <em>probe hierarchy</em>, showing that some problem can be solved with zero redundancy (<img src="https://s0.wp.com/latex.php?latex=r%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="r=0" class="latex" />) with <img src="https://s0.wp.com/latex.php?latex=O%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="O(q)" class="latex" /> probes, while it requires almost linear <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="r" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="q" class="latex" /> probes. For example I don’t know of a result yielding this for small <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="q" class="latex" /> such as <img src="https://s0.wp.com/latex.php?latex=q%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="q=O(1)" class="latex" />; I would appreciate a reference. (As mentioned in the                                                                                                                                                        paper, the sampling viewpoint is not essential and just like for Rank one can prove the data-structure corollaries directly. Personally, and obviously, I find the sampling viewpoint useful.)</p>
<p style="text-align: justify;">   One of my favorite open problems in the area still is: can a uniform distribution over <img src="https://s0.wp.com/latex.php?latex=%5Bm%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="[m]" class="latex" /> be approximately sampled by an efficient cell-probe algorithm? I can’t even rule out samplers making <em>two </em>probes!</p>
<h3 class="likesectionHead"><a id="x1-1000"></a>References</h3>
<p style="text-align: justify;">
</p><div class="thebibliography">
<p class="bibitem"><span class="biblabel">  [Pǎt08]<span class="bibsp">   </span></span><a id="XPatrascu08Succincter"></a>Mihai  Pǎtraşcu.      Succincter.      In  49th  IEEE  Symp. on         Foundations of Computer Science (FOCS). IEEE, 2008.</p>
<p class="bibitem"><span class="biblabel">  [PV10]<span class="bibsp">   </span></span><a id="XPatrascuV10"></a>Mihai Pǎtraşcu and Emanuele Viola.  Cell-probe lower bounds         for succinct partial sums.  In 21th ACM-SIAM Symp. on Discrete         Algorithms (SODA), pages 117–122, 2010.</p>
<p class="bibitem"><span class="biblabel">  [Vio21]<span class="bibsp">   </span></span><a id="Xviola-rank-samp"></a>Emanuele       Viola.                    Lower       bounds       for         samplers and data structures via the cell-probe separator. Available         at <a href="http://www.ccs.neu.edu/home/viola/" rel="nofollow">http://www.ccs.neu.edu/home/viola/</a>, 2021.</p>
<p class="bibitem"><span class="biblabel">  [Yu19] <span class="bibsp">   </span></span><a id="XDBLP:conf/stoc/Yu19"></a>Huacheng  Yu.     Optimal  succinct  rank  data  structure  via         approximate nonnegative tensor decomposition.  In Moses Charikar         and Edith Cohen, editors, ACM Symp. on the Theory of Computing         (STOC), pages 955–966. ACM, 2019.</p>
</div></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2021/06/07/data-structure-lower-bounds-without-encoding-arguments/"><span class="datestr">at June 07, 2021 03:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=18838">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/06/07/happy-moms-day/">Happy Mom’s Day</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>You know, I loved math. My mom was a math teacher—Joan Cusack</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/06/07/happy-moms-day/kfrlmothers/" rel="attachment wp-att-18865"><img width="212" alt="" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/KFRLmothers.jpg?resize=212%2C139&amp;ssl=1" class="alignright size-full wp-image-18865" height="139" /></a></p>
<p>
Mary Kay Farley, my dear wife’s mom, and Dorothy Lipton, my mom, have unfortunately both passed away. Kathryn and I miss them greatly. Both women shared keen mathematical skills, a fascination with the game of baseball and a commitment to living a well-ordered life.  </p>
<p>
Today is <b>not</b> Mother’s Day. We still hope all mothers everywhere are enjoying their day.</p>
<p>
We will take this time to thank all of you out there. We missed doing so last month, but the pandemic has distended time anyway. What we are hearing now are stories of mothers and children and grandchildren finally being able to think of seeing each other in person rather than via video.</p>
<p>
</p><p></p><h2> Another Kind of Parentage </h2><p></p>
<p></p><p>
This has blended with musings on our recent <a href="https://rjlipton.wpcomstaging.com/2021/03/26/congrats-avi-and-laci-on-the-abel-prize/">post</a> in which I (Dick) noted that Dorit Aharonov is an academic grandchild of mine, in that Avi Wigderson co-supervised her doctoral thesis and I supervised Avi’s. </p>
<p>
Years ago we featured on Father’s Day a <a href="https://rjlipton.wpcomstaging.com/2011/06/19/who's-your-doktorvater/">post</a> with the title “Who’s Your <em>Doktorvater</em>?”—which was a play on the <a href="https://bosoxinjection.com/2014/09/24/ten-years-gone-pedro-martinez-calls-yankees-daddy/">expression</a> “who’s your daddy?” Now it is high time to note that there are many “doctor mothers”—as Dorit has herself <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=102209">become</a>. </p>
<p>
One difference from human genealogy is that most often there is only one “doctor parent.” My <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=86340&amp;fChrono=1">advisor</a>, David Parnas, has two: Alan Perlis and Everard Williams. From Perlis it is a straight shot back to Siméon Poisson, whose 1800 dissertation was co-advised by Joseph Lagrange and Pierre Laplace. For Lagrange there is a strange <a href="https://www.mathgenealogy.org/id.php?id=17864">note</a> of Leonhard Euler as a virtual advisor, but the real one is Giovanni Beccaria—who has no listed parent. Going through Laplace also dead-ends. But selecting Euler includes a chain that ends in the 1100s with Sharaf al-Dīn al-Ṭūsī, who <a href="https://en.wikipedia.org/wiki/Sharaf_al-Din_al-Tusi#Mathematics">improved</a> the complexity of approximately solving cubic equations.</p>
<p>
I appear not to have any female ancestors in my doctoral genealogy. I have two female PhD graduates, one of whom is a <em>Doktormutter</em>. Ken’s first female doctoral student, co-advised, had a successful thesis defense last week; he has another nearing the ABD stage. But I have known quite a few other “doctor mothers” personally. Today, Ken and I thought to recognize them.</p>
<p>
</p><p></p><h2> Some Doctor Moms I Know </h2><p></p>
<p></p><p>
Here are some that I have had the honor to know. They are in a certain order—do you see what it is? I give only the surname on purpose—click the second name and note its URL for a singular reflection of this.</p>
<ul>
<li>
<a href="https://en.wikipedia.org/wiki/Monica_S._Lam">Lam</a>: <a href="https://mathgenealogy.org/id.php?id=50307">advisees</a> <p></p>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Blum/">Blum</a>: <a href="http://www.cs.cmu.edu/~lblum/PAPERS/lblumShortVita.pdf">co-advisees</a> <p></p>
</li><li>
<a href="https://en.wikipedia.org/wiki/Mary_Shaw_(computer_scientist)">Shaw</a>: <a href="https://www.mathgenealogy.org/id.php?id=50083">advisees</a> <p></p>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Chung/">Chung</a>: <a href="https://www.mathgenealogy.org/id.php?id=23154">advisees</a> <p></p>
</li><li>
<a href="https://en.wikipedia.org/wiki/Maria_Klawe">Klawe</a>: <a href="https://www.mathgenealogy.org/id.php?id=43243">advisee</a> <p></p>
</li><li>
<a href="https://people.csail.mit.edu/lynch/">Lynch</a>: <a href="https://www.mathgenealogy.org/id.php?id=81227">advisees</a> <p></p>
</li><li>
<a href="https://en.wikipedia.org/wiki/Ruzena_Bajcsy">Bajcsy</a>: <a href="https://www.mathgenealogy.org/id.php?id=39957">advisees</a> <p></p>
</li><li>
<a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/graham-s.html">Graham</a>: <a href="https://www.mathgenealogy.org/id.php?id=22787">advisees</a> <p></p>
</li><li>
<a href="https://en.wikipedia.org/wiki/Barbara_Liskov">Liskov</a>: <a href="https://www.mathgenealogy.org/id.php?id=61932">advisees</a> <p></p>
</li><li>
<a href="https://en.wikipedia.org/wiki/Eva_Tardos">Tardos</a>: <a href="https://www.mathgenealogy.org/id.php?id=39422">advisees</a> <p></p>
</li><li>
<a href="https://annacgilbert.github.io/">Gilbert</a>: <a href="https://www.mathgenealogy.org/id.php?id=24150">advisees</a> <p></p>
</li><li>
<a href="https://people.math.gatech.edu/~randall/">Randall</a>: <a href="https://www.mathgenealogy.org/id.php?id=81757">advisees</a> <p></p>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Rasiowa/">Rasiowa</a>: <a href="https://www.mathgenealogy.org/id.php?id=22601">advisees</a> <p></p>
</li><li>
<a href="https://en.wikipedia.org/wiki/Sheila_Greibach">Greibach</a>: <a href="https://www.mathgenealogy.org/id.php?id=25274">advisees</a> <p></p>
</li><li>
<a href="https://en.wikipedia.org/wiki/Shafi_Goldwasser">Goldwasser</a>: <a href="https://www.mathgenealogy.org/id.php?id=35879">advisees</a> <p></p>
</li><li>
<a href="https://mathshistory.st-andrews.ac.uk/Biographies/Daubechies/">Daubechies</a>: <a href="https://www.mathgenealogy.org/id.php?id=44561">advisees</a>
</li></ul>
<p>
The last gives us an all-female tree, not just one branch, of people we know. Besides Anna Gilbert, another of Ingrid Daubechies’s students, who herself has <a href="https://www.mathgenealogy.org/id.php?id=92059">advisees</a>, is Cynthia Rudin of Duke, whom Ken knew and taught while she was an undergraduate at Buffalo.</p>
<p>
There are others I could mention who went into research labs where there are different relationships besides PhD advising. They include Irene Greif, Tal Rabin, Lynn Conway, and Jean Sammet. I could include Jamie Morgenstern, whom we recently <a href="https://rjlipton.wpcomstaging.com/2021/03/10/making-algorithms-fair/">featured</a> and who his <a href="https://jamiemorgenstern.com/">advising</a> her first students at the University of Washington—do they have to be “born” yet to count you as a <em>Doktormutter</em>? I’ve left others out—apologies for that—but the ones I’ve listed make a nice <img src="https://s0.wp.com/latex.php?latex=%7B4+%5Ctimes+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{4 \times 4}" class="latex" /> collage:</p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/2021/06/07/happy-moms-day/comoms2/" rel="attachment wp-att-18841"><img width="450" alt="" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/comoms2.png?resize=450%2C486&amp;ssl=1" class="aligncenter size-full wp-image-18841" height="486" /></a></p>
<p>
</p><p></p><h2> My Upbringing </h2><p></p>
<p></p><p>
Of these, the one with the most formative impact on me was Helena Rasiowa. I learned advanced logic from her when I was an undergraduate. </p>
<p>
Here is a tribute to <a href="http://comet.lehman.cuny.edu/fitting/bookspapers/pdf/papers/Rasiowa.pdf">her</a> by Melvin Fitting: </p>
<blockquote><p><b> </b> <em> I once heard Dana Scott criticize her <a href="https://www.amazon.com/Mathematics-Metamathematics-Helena-SIKORSKI-RASIOWA/dp/B005JGKZXW">book</a>, <em>The Mathematics of Metamathematics</em> with Roman Sikorski, because, while it took an algebraic approach to logic, it did not carry the work further and consider set theory. If it had, then <a href="https://en.wikipedia.org/wiki/Forcing_(mathematics)">forcing</a> would have been discovered years earlier than it was. This is not, at heart, a criticism, but a tribute. The building of mathematics always goes on. Foundations, firmly laid, enable later construction, and the foundations laid by that book were powerfully firm. </em>
</p></blockquote>
<p>
Ken also points to logic as a formative influence—though from men at Oxford.  Both of us were attracted to Gödel-type undecidability issues in complexity theory in the early 1980s.  The nexus of logic and algebra has been important to us in different ways, Ken more with finite automata and descriptive complexity.  Courses in logic gave both of us a habit of framing problems along formal lines.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Which “doctor mothers” have you known or been influenced by?</p>
<p></p><p><br />
[Added and re-formatted photos at top]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/06/07/happy-moms-day/"><span class="datestr">at June 07, 2021 04:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2021/06/07/workshop-on-machine-learning-for-algorithms/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2021/06/07/workshop-on-machine-learning-for-algorithms/">Workshop on Machine Learning for Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
July 13-14, 2021 Foundations of Data Science Institute (FODSI) https://fodsi.us/ml4a.html In recent years there has been increasing interest in using machine learning to improve the performance of classical algorithms in computer science, by fine-tuning their behavior to adapt to the properties of the input distribution. This “data-driven” or “learning-based” approach to algorithm design has the … <a href="https://cstheory-events.org/2021/06/07/workshop-on-machine-learning-for-algorithms/" class="more-link">Continue reading <span class="screen-reader-text">Workshop on Machine Learning for Algorithms</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2021/06/07/workshop-on-machine-learning-for-algorithms/"><span class="datestr">at June 07, 2021 04:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-562506050674619397">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/06/when-do-you-use-et-al-as-opposed-to.html">When do you use et al. as opposed to listing out the authors? First names? Middle initials? Jr?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> If I was refering to the paper with bibtex entry: </p><p><br /></p><p>@misc{BCDDL-2018,</p><p>  author    = {Jeffrey Bosboom and</p><p>               Spencer Congero and</p><p>               Erik D. Demaine and</p><p>               Martin L. Demaine and</p><p>               Jayson Lynch},</p><p>  title     = {Losing at Checkers is Hard},</p><p>  year      = {2018},</p><p>  note      = {\newline\url{http://arxiv.org/abs/1806.05657}},</p><p>}</p><p>(The paper is <a href="http://arxiv.org/abs/1806.05657">here</a>.)</p><p>I would write </p><p><i>Bosboom et al.~\cite{BCDDL-2018} proved that trying to lose at checkers (perhaps you are playing a child and want to keep up their self-esteem, or a Wookie and don't want your arms to be torn off your shoulders   (see <a href="https://www.starwars.com/video/let-the-wookiee-win">here</a>),  or a Wookie child) is hard. </i></p><p><br /></p><p>Why did I use<i> et al. </i>?<i> </i>Because it would be a pain to write out all of those names. </p><p>How many names does it take to make you write <i>et al. </i>? Are there exceptions? </p><p>I have not seen any discussion of this point on the web. So here are my rules of thumb and some questions.(CORRECTION- a commenter points out that this IS discussed on the web. Even so, you can comment on my thoughts or give your thoughts or whatever you like.) </p><p>1) If  there are 3 or more people than use et al. Exception: If the three are VERY WELL KNOWN as a triple. E.g., <i>the double play was Tinker to Evers to Chance. </i>Well, that would not really come up since in baseball nobody ever says <i>the double play was Tinker et al.</i>  More relevant examples:</p><p>Aho, Hopcroft, and Ullman</p><p>Cormen, Leiserson, and Rivest, also known as CLR</p><p>The more recent edition is</p><p>Cormen, Leiserson, Rivest, and Stein. I have heard CLRS but I don't know if people WRITE all four names. </p><p>Lenstra-Lenstra-Lovasz also usually mentions all three. </p><p>2) If there is one name do not use <i>et al</i>.  unless that one person has a multiple personality disorder.</p><p>3) If there are 2 people it can be tricky and perhaps unfair. If the second one has a long name then I am tempted to use<i> et al.</i> For example</p><p>Lewis and Papadimitriou (If I mispelled Christos's name-- well- that's  the point!- to avoid spelling errors I want to use <i>et al.</i> )</p><p>Lampropoulos and Paraskevopoulou (the first one is UMCP new faculty!). After typing in the first name I would not be in the mood to type in the second. </p><p>Similar if there are lots of accents in the name making it hard to type in LaTeX (though I have macros for some people like Erdos who come up a lot) then I might use<i> et al. </i></p><p>(ADDED LATER- some of the commenters object to my `rule' of leaving out the last name if its complicated. That is not really my rule- the point of this post was to get a discussion going about the issue, which I am happy to say has happened.) </p><p>----------</p><p>There are other issues along these lines: when to include the first name (when there is more than one person with that last name, e.g. Ryan Williams and Virginia  Vassilevska Williams), when to use middle initials (in the rare case where there is someone with the same first and last name- Michael  J. Fox added the J and uses it since there was an actor named Michael Fox.)</p><p>I will soon give a quote from a math paper that amused me, but first some context.  The problem of determining if a poly in n variables over Z has an integer solution is called E(n). By the solution to Hilbert's 10th problem we know that there exists n such that E(n) is undecidable. E(9) is undecidable, but the status of E(8) is unknown (as of May 2021) and has been since the early 1980's. </p><p>Here is the quote (from <a href="http://maths.nju.edu.cn/~zwsun/14z.pdf">here</a>).</p><p><i>Can we replace 9 by a smaller number? It is believed so. In fact, A. Baker, Matiyasevich and J.Robinson  even conjectured that E(3) is undecidable over N.</i></p><p>Note that Baker and Robinson get their first initial but Matiyasevich does not.</p><p>I suspect that they use J. Robinson since there is another mathematician with last name Robinson: Rafael Robinson who was Julia's Robinson's husband (to my younger readers--- there was a time when a women who got married took her husband's last name). There is at least one other Math-Robinson: Robert W Robinson. I do not think he is closely related. </p><p>Baker: I do not know of another mathematician named Baker. I tried Google, but the Bakers  I found were   not in the right time frame. I also kept finding hits to an anecdote about Poincare and a man whose profession was a baker (see <a href="https://gilkalai.wordpress.com/2019/10/13/the-story-of-poincare-and-his-friend-the-baker/">here</a> though its later in that blog post). However, I suspect there was another mathematician named Baker which is why the author uses the first initial.  Its possible the author did not want to confuse Alan  Baker with Theodore Baker, one of the authors of Baker-Gill-Solovay that showed there were oracles that made P = NP and others that made P NE NP.  But somehow, that just doesn't seem right to me. I suspect there is only one mathematician with last name Matijsavic. </p><p>Thomas Alva Edison named his son Thomas Alva Edison Jr.  This was a bad idea but not for reasons of authorship, see <a href="http://edisontinfoil.com/taejr/edisonjr.htm">here</a>.</p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/06/when-do-you-use-et-al-as-opposed-to.html"><span class="datestr">at June 07, 2021 03:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/077">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/077">TR21-077 |  Lower Bounds on Stabilizer Rank | 

	Shir Peleg, 

	Amir Shpilka, 

	Ben Lee Volk</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The stabilizer rank of a quantum state $\psi$ is the minimal $r$ such that $\left| \psi \right \rangle = \sum_{j=1}^r c_j \left|\varphi_j \right\rangle$ for $c_j \in \mathbb{C}$ and stabilizer states $\varphi_j$. The running time of several classical simulation methods for quantum circuits is determined by the stabilizer rank of the $n$-th tensor power of single-qubit magic states.

We prove a lower bound of $\Omega(n)$ on the stabilizer rank of such states, improving a previous lower bound of $\Omega(\sqrt{n})$ of Bravyi, Smith and Smolin [BSS16]. Further, we prove that for a sufficiently small constant $\delta$, the stabilizer rank of any state which is $\delta$-close to those states is $\Omega(\sqrt{n}/\log n)$. This is the first non-trivial lower bound for approximate stabilizer rank.

Our techniques rely on the representation of stabilizer states as quadratic functions over affine subspaces of $\mathbb{F}_2^n$, and we use tools from analysis of boolean functions and complexity theory. The proof of the first result involves a careful analysis of directional derivatives of quadratic polynomials, whereas the proof of the second result uses Razborov-Smolensky low degree polynomial approximations and correlation bounds against the majority function.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/077"><span class="datestr">at June 06, 2021 07:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/076">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/076">TR21-076 |  Pseudorandom Generators, Resolution and Heavy Width | 

	Dmitry Sokolov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Following the paper of Alekhnovich, Ben-Sasson, Razborov, Wigderson \cite{ABRW04} we call a pseudorandom generator $\mathrm{PRG}\colon \{0, 1\}^n \to \{0, 1\}^m$ hard for for a propositional proof system $\mathrm{P}$ if $\mathrm{P}$ cannot efficiently prove the (properly encoded) statement $b \notin \mathrm{Im}(\mathrm{PRG})$ for any string $b \in \{0, 1\}^m$.

In \cite{ABRW04} authors suggested the ``functional encoding'' of considered statement for Nisan--Wigderson generator that allows the introduction of ``local'' extension variables. These extension variables may potentially significantly increase the power of the proof system. In \cite{ABRW04} authors gave a lower bound $\exp\left[\frac{n^2}{m \Omega\left(2^{2^{\Delta}}\right)}\right]$ on the length of Resolution proofs where $\Delta$ is the degree of the dependency graph of the generator. This lower bound meets the barrier for the restriction technique.

In this paper, we introduce a ``heavy width'' measure for Resolution that allows showing a lower bound $\exp\left[\frac{n^2}{m 2^{O(\varepsilon \Delta)}}\right]$ on the length of Resolution proofs of the considered statement for the Nisan--Wigderson generator. This gives an exponential lower bound up to $\Delta := \log^{2 - \delta} n$ (the bigger degree the more extension variables we can use). It is a solution to an open problem from \cite{ABRW04}.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/076"><span class="datestr">at June 04, 2021 02:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/inference-is-not-a-privacy-violation/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/inference-is-not-a-privacy-violation/">Statistical Inference is Not a Privacy Violation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>On April 28, 2021, the US Census Bureau <a href="https://www.census.gov/programs-surveys/decennial-census/decade/2020/planning-management/process/disclosure-avoidance/2020-das-updates.html">released</a> a new demonstration of its differentially private Disclosure Avoidance System (DAS) for the 2020 US Census. The public were given a month to submit feedback before the system is finalized.
This demonstration data and the feedback has generated a lot of discussion, including media coverage on <a href="https://www.npr.org/2021/05/19/993247101/for-the-u-s-census-keeping-your-data-anonymous-and-useful-is-a-tricky-balance">National Public Radio</a>, in <a href="https://www.washingtonpost.com/local/social-issues/2020-census-differential-privacy-ipums/2021/06/01/6c94b46e-c30d-11eb-93f5-ee9558eecf4b_story.html">the Washington Post</a>, and via <a href="https://apnews.com/article/business-census-2020-technology-e701e313e841674be6396321343b7e49">the Associated Press</a>. The DAS is also the subject of an <a href="https://www.courtlistener.com/docket/59728874/state-v-united-states-department-of-commerce/">ongoing lawsuit</a>.</p>

<p>The following is a response from experts on differential privacy and cryptography to the <a href="https://alarm-redist.github.io/posts/2021-05-28-census-das/Harvard-DAS-Evaluation.pdf">working paper of Kenny et al.</a> on the impact of the 2020 U.S. Census Disclosure Avoidance System (DAS) on redistricting.</p>

<p>This paper makes a <a href="https://github.com/frankmcsherry/blog/blob/master/posts/2016-06-14.md">common but serious mistake</a>, from which the authors wrongfully conclude the Census Bureau should not modernize its privacy-protection technology.  Not only do the results not support this conclusion, but they instead show the power of the methodology, known as differential privacy, adopted by the Bureau, precisely the opposite of the authors’ erroneous conclusions.</p>

<p>Trust is essential; once destroyed it can be nearly impossible to rebuild, and getting privacy wrong in this Census will have an impact on all future government surveys.  The Census Bureau has shown that their <a href="https://desfontain.es/privacy/index.html">2010 (DAS) does not survive modern privacy threats</a>, and in fact was roughly equivalent to publishing nearly three quarters of the responses.  The Census Bureau’s decision to modernize its Disclosure Avoidance System (DAS) for the 2020 Decennial Census to be differentially private is the correct response to decades of theoretical and empirical work on the privacy risks inherent in releasing large numbers of statistics derived from a dataset.</p>

<p>The importance of the Census, and the reality that no technology competing with differential privacy exists for meeting their confidentiality obligations, makes it very important that the public and policy makers have accurate information. We imagine you will be reporting on this topic in the future.  Others have <a href="https://gerrymander.princeton.edu/DAS-evaluation-Kenny-response">addressed flaws</a> in the paper regarding implications for redistricting; we want to provide you with an understanding of the privacy mistake in the study.</p>

<p>To understand the flaw in the paper’s argument, consider the role of smoking in determining cancer risk.  Statistical study of medical data has taught us that smoking causes cancer.   Armed with this knowledge, if we are told that 40 year old Mr. S is a smoker, we can conclude that he has an elevated cancer risk.  The statistical inference of elevated cancer risk—made before Mr. S was born—did not violate Mr. S’s privacy. To conclude otherwise is to define science to be a privacy attack.  This is the mistake made in the paper.</p>

<p>This is basically what Kenny et al. found.</p>

<p>The authors looked at three different predictors: one built directly from (swapped) 2010 Census data and the other two built using differential privacy applied to (swapped) 2010 Census data, and evaluated all three “on approximately 5.8 million registered voters included in the North Carolina February 2021 voter file.”  What did they find?</p>

<blockquote>
  <p>“Our analysis shows that across three main racial and ethnic groups, the predictions based on the [differential privacy based] DAS data appear to be as accurate as those based on the 2010 Census data.”</p>
</blockquote>

<p>This makes perfect sense. Bayesian Improved Surname Geocoding, or BISG, is a statistical method of building a predictor inferring ethnicity (or race) from name and geography.  Here, name and geography play the role of the information as to whether or not one smokes, and the prediction of ethnicity corresponds to the cancer risk prediction.  The predictor is constructed from census data on the ethnic makeup of individual census blocks and statistical information about the popularity of individual surnames within different ethnic groups.  With such a predictor, moving across the country can change the outcome, as can changing one’s name.  But a BISG prediction is not about the individual, it is about the statistical—population-level—relationship between name, geography, and ethnicity.</p>

<p>The differentially private DAS enabled learning to make statistical inferences about ethnicity from name and geography, without compromising the privacy of any Census respondent, exactly as it was intended to do.  In other words, the paper establishes fitness-for-use of the DAS data for the BISG statistical method!  Because differential privacy permits learning statistical patterns without compromising the privacy of individual members of the dataset, it should not interfere with learning the predictor, which is exactly what the authors found. Returning to our “smoking causes cancer” example, the researchers found that it was just as easy to detect this statistical pattern with a modern disclosure avoidance system in place as it was with the older, less protective system.</p>

<p>The authors’ conclusions –“ the DAS data may not provide universal privacy protection” – are simply not supported by their findings.</p>

<p>They have confused learning that smoking causes cancer—and applying this predictor to an individual smoker—with learning medical details of individual patients in the dataset. Change the input to the predictor—replace “smoker” with “non-smoker” or move across the country, for example—and the prediction changes.</p>

<p>The BISG prediction is not about the individual, it does not accompany her as she relocates from one neighborhood to another, it is a statistical relationship between name, geography, and ethnicity.  It is not a privacy compromise, it is science.</p>

<p>Signed:</p>
<ul>
  <li>Mark Bun, Assistant Professor of Computer Science, Boston University</li>
  <li>Damien Desfontaines, Privacy Engineer, Google</li>
  <li>Cynthia Dwork, Professor of Computer Science, Harvard University</li>
  <li>Moni Naor, Professor of Computer Science, The Weizmann Institute of Science</li>
  <li>Kobbi Nissim, Professor of Computer Science, Georgetown University</li>
  <li>Aaron Roth, Professor of Computer and Information Science, University of Pennsylvania</li>
  <li>Adam Smith, Professor of Computer Science, Boston University</li>
  <li>Thomas Steinke, Research Scientist, Google</li>
  <li>Jonathan Ullman, Assistant Professor of Computer Science, Northeastern University</li>
  <li>Salil Vadhan, Professor of Computer Science and Applied Mathematics, Harvard University</li>
</ul>

<p>Please contact Cynthia Dwork for contact information for authors happy to speak about this on the record.</p></div>







<p class="date">
by Jonathan Ullman <a href="https://differentialprivacy.org/inference-is-not-a-privacy-violation/"><span class="datestr">at June 03, 2021 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/075">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/075">TR21-075 |  Affine Extractors for Almost Logarithmic Entropy | 

	Eshan Chattopadhyay, 

	Jesse Goodman, 

	Jyun-Jie Liao</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give an explicit construction of an affine extractor (over $\mathbb{F}_2$) that works for affine sources on $n$ bits with min-entropy $k \ge~  \log n \cdot (\log \log n)^{1 + o(1)}$. This improves prior work of Li (FOCS'16) that requires  min-entropy at least $\mathrm{poly}(\log n)$.
    
Our construction is based on the framework of using correlation breakers and resilient functions, a paradigm that was also used by Li. On a high level, the key sources of our improvement are based on the following new ingredients: (i) A new construction of  an affine somewhere random extractor, that we use in a crucial step instead of a linear seeded extractor (for which optimal constructions are not known) that was used by Li. (ii) A near optimal construction of a correlation breaker for linearly correlated sources. The construction of our correlation breaker takes inspiration from an exciting line of recent work that constructs two-source extractors for near logarithmic min-entropy.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/075"><span class="datestr">at June 03, 2021 11:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-583257573096655269">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/06/what-happened-to-self-driving-cars.html">What happened to self-driving cars?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In 2014, I wrote a blog post about a fake company <a href="https://blog.computationalcomplexity.org/2014/07/elfdrive.html">Elfdrive</a>.</p><blockquote style="border: none; margin: 0px 0px 0px 40px; padding: 0px; text-align: left;"><p>With a near record-setting investment announced last week, the self-driving car service Elfdrive is the hottest, most valuable technology start-up on the planet. It is also one of the most controversial.</p><p>The company, which has been the target of protests across Europe this week, has been accused of a reckless attitude toward safety, of price-gouging its customers, of putting existing cabbies out of work and of evading regulation. And it has been called trivial. In The New Yorker last year, George Packer huffed that Elfdrive typified Silicon Valley’s newfound focus on “solving all the problems of being 20 years old, with cash on hand.”</p><p>It is impossible to say whether Elfdrive is worth the $117 billion its investors believe it to be; like any start-up, it could fail. But for all its flaws, Elfdrive is anything but trivial. It could well transform transportation the way Amazon has altered shopping — by using slick, user-friendly software and mountains of data to completely reshape an existing market, ultimately making many modes of urban transportation cheaper, more flexible and more widely accessible to people across the income spectrum.</p></blockquote><p>It was a spoof on Uber but now it looks more like Tesla, expect that Tesla's market value is over half a trillion, about six times larger than General Motors.</p><p>The post was really about self-driving cars which I thought at the time would be commonplace by 2020. We are mostly there but there are issues of silent communication between drivers or between a driver and a pedestrian on who goes first that's hard to duplicate for a self-driving car. There is the paradox that if we make a car that will always stop if someone runs in front of it, then some people will run in front of it.</p><p>There is also the man-bites-dog problem. Any person killed by a self-driving car will be a major news item while the person killed by a human-driven car while you've been reading this post will never be reported.</p><p>We'll get to self-driving cars eventually, it just won't be all at once. We're already have basically self-driving cars on highways and in many other roads as well. As the technology improves and people see that it's safe at some point people will say, "So why do we even need the steering wheel anymore?"</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/06/what-happened-to-self-driving-cars.html"><span class="datestr">at June 03, 2021 08:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/074">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/074">TR21-074 |  Space characterizations of complexity measures and size-space trade-offs in propositional proof systems | 

	Theodoros Papamakarios, 

	Alexander Razborov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We identify two new big clusters of proof complexity measures equivalent up to
polynomial and $\log n$ factors. The first cluster contains, among others,
the logarithm of tree-like resolution size, regularized (that is, multiplied
by the logarithm of proof length) clause and monomial space, and clause
space, both ordinary and regularized, in regular and tree-like resolution. As
a consequence, separating clause or monomial space from the (logarithm of)
tree-like resolution size is the same as showing a strong trade-off between
clause or monomial space and proof length, and is the same as showing a
super-critical trade-off between clause space and depth. The second cluster
contains width, $\Sigma_2$ space (a generalization of clause
space to depth 2 Frege systems), both ordinary and regularized, as well as
the logarithm of tree-like size in the system $R(\log)$. As an application of some of
these simulations, we improve a known size-space trade-off for polynomial calculus with resolution. In
terms of lower bounds, we show a quadratic lower bound on tree-like
resolution size for formulas refutable in clause space $4$. We introduce on
our way yet another proof complexity measure intermediate between depth and
the logarithm of tree-like size that might be of independent interest.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/074"><span class="datestr">at June 03, 2021 04:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/073">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/073">TR21-073 |  Lower bounds for samplers and data structures via the cell-probe separator | 

	Emanuele Viola</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Suppose that a distribution $S$ can be approximately sampled by an
efficient cell-probe algorithm. It is shown to be possible to restrict
the input to the algorithm so that its output distribution is still
not too far from $S$, and at the same time many output coordinates
are almost pairwise independent.

Building on this several results are obtained, including:

- A lower bound for sampling prefix sums.

- A lower bound for sampling a variant of the predecessor problem.

- A separation between AC0 and cell-probe sampling.

- A separation between sampling with $O(q)$ and $q$ probes.

- A new proof of the Patrascu-Viola data-structure lower bound for
prefix sums, demonstrating the feasibility of obtaining data-structure
lower bounds via sampling.

- A separation between data structures making $O(q)$ and $q$ probes.

The only previous cell-probe lower bounds for sampling followed from
the AC0 lower bounds and applied to pseudorandom objects like error-correcting
and extractors, making them inadequate for the above applications.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/073"><span class="datestr">at June 03, 2021 02:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=565">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2021/06/03/tcs-talk-wednesday-june-9-ankur-moitra-mit-and-pravesh-kothari-cmu/">TCS+ talk: Wednesday, June 9 — Pravesh Kothari (CMU) and Ankur Moitra (MIT)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, June 9th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC).<strong> <a href="https://www.cs.cmu.edu/~praveshk/">Pravesh Kothari</a>  and <a href="https://people.csail.mit.edu/moitra/">Ankur Moitra</a> </strong>from CMU and MIT will (jointly) speak about “<em>Robustly Learning Mixtures of Gaussians</em>” (abstract below).</p>
<p>Note that the seminar will be a bit longer than the usual: it’s a double feature!</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/view/tcsplus/welcome/next-tcs-talk">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The recorded talk will also be posted <a href="https://sites.google.com/view/tcsplus/welcome/past-talks">on our website</a> afterwards, so people who did not sign up will still be able to watch the talk) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/view/tcsplus/welcome/suggest-a-talk">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/view/tcsplus/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: For a while now the problem of robustly learning a high-dimensional mixture of Gaussians has had a target on its back. The first works in algorithmic robust statistics gave provably robust algorithms for learning a single Gaussian. Since then there has been steady progress, including algorithms for robustly learning mixtures of spherical Gaussians, mixtures of Gaussians under separation conditions, and arbitrary mixtures of two Gaussians. In this talk we will discuss two recent works that essentially resolve the general problem. There are important differences in their techniques, setup, and overall quantitative guarantees, which we will discuss.</p>
<p>The talk will cover the following independent works:</p>
<ul>
<li>Liu, Moitra, “Settling the Robust Learnability of Mixtures of Gaussians”</li>
<li>Bakshi, Diakonikolas, Jia, Kane, Kothari, Vempala, “Robustly Learning Mixtures of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="k" class="latex" /> Arbitrary Gaussians”</li>
</ul>
</blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2021/06/03/tcs-talk-wednesday-june-9-ankur-moitra-mit-and-pravesh-kothari-cmu/"><span class="datestr">at June 03, 2021 04:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5536">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5536">Three updates</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<ol><li>Hooray, I’m <a href="https://www.acm.org/articles/people-of-acm/2021/scott-aaronson">today’s “Featured ACM Member”</a>!  Which basically means, yet another interview with me about quantum computing, with questions including what’s most surprised me about the development of QC, and what students should do to get into the field.</li><li>I’m proud to announce that <a href="https://arxiv.org/abs/2105.14697">An Automated Approach to the Collatz Conjecture</a>, a paper by Emre Yolcu, myself, and Marijn Heule that we started working on over four years ago, is finally available on the arXiv, and will be presented at the 2021 <a href="https://www.cs.cmu.edu/~mheule/CADE28/">Conference on Automated Deduction</a>.  Long story short: no, we didn’t prove <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz</a>, but we have an approach that can for the first time prove certain Collatz-like statements in a fully automated way, so hopefully that’s interesting!  There was also a <a href="https://www.quantamagazine.org/can-computers-solve-the-collatz-conjecture-20200826/"><em>Quanta</em> article</a> even before our paper had come out (I wasn’t thrilled about the timing).</li><li>The legendary <a href="https://en.wikipedia.org/wiki/Baba_Brinkman">Baba Brinkman</a> has a <a href="https://www.youtube.com/watch?v=kVcOx9Bg3a4">new rap about quantum computing</a> (hat tip to blog commenter YD).  Having just watched the music video, I see it as one of the better popularization efforts our field has seen in the past 25 years—more coherent than the average journalistic account and with a <em>much</em> better backbeat.  (I do, however, take a more guarded view than Brinkman of the potential applications, especially to e.g. autonomous driving and supply-chain optimization.)</li></ol>



<p></p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5536"><span class="datestr">at June 01, 2021 08:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3526">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2021/06/01/wine21-call-for-papers/">WINE’21 Call for Papers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>WINE 2021: The 17th Conference on Web and Internet Economics </strong></p>



<p><strong>December 14-17, 2021</strong><br /><strong>Hasso Plattner Institute, Potsdam, Germany</strong></p>



<p></p><blockquote class="wp-embedded-content"><a href="https://hpi.de/wine2021/">Overview</a></blockquote><p></p>



<p>Over the past two decades, researchers in theoretical computer science, artificial intelligence, operations research, and economics have joined forces to understand the interplay of incentives and computation. These issues are of particular importance in the Web and the Internet that enable the interaction of large and diverse populations. The Conference on Web and Internet Economics (WINE) is an interdisciplinary forum for the exchange of ideas and results on incentives and computation arising from these various fields. WINE 2021 continues the successful tradition of the Conference on Web and Internet Economics (named Workshop on Internet &amp; Network Economics until 2013), which was held annually from 2005 to present.</p>



<p>The program will feature invited talks, tutorials, paper presentations, and a poster session. All paper submissions will be peer-reviewed and evaluated on the basis of the quality of their contribution, originality, soundness, and significance. Submissions are invited in, but not limited to, the following topics:</p>



<ul><li>Algorithmic Game Theory</li><li>Algorithmic Mechanism Design</li><li>Auction Algorithms and Analysis</li><li>Computational Advertising</li><li>Computational Aspects of Equilibria</li><li>Computational Social Choice</li><li>Learning in Markets and Mechanism Design</li><li>Learning under Strategic Behavior</li><li>Coalitions, Coordination, and Collective Action</li><li>Economic Aspects of Security and Privacy</li><li>Economic Aspects of Distributed Computing and Cryptocurrencies</li><li>Econometrics, ML, and Data Science</li><li>Behavioral Economics and Behavioral Modeling</li><li>Fairness and Trust in Games and Markets</li><li>Price Differentiation and Price Dynamics</li><li>Revenue Management</li><li>Social Networks and Network Games</li></ul>



<p><strong>Authors of the accepted papers will have a choice to attend the conference virtually.</strong></p>



<p><strong>Important Dates</strong></p>



<p>Paper submission deadline: July 12, 2021, 11:59pm Pacific Time</p>



<p>Author notification: September (exact date TBA)</p>



<p><strong>Submission Format</strong></p>



<p>Authors are invited to submit extended abstracts presenting original research on any of the research fields related to WINE 2021.</p>



<p>An extended abstract submitted to WINE 2021 should start with the title of the paper, each author’s name, affiliation and e-mail address, followed by a one-paragraph summary of the results to be presented. This should then be followed by a technical exposition of the main ideas and techniques used to achieve these results, including motivation and a clear comparison with related work.</p>



<p>The extended abstract should not exceed 18 single-spaced pages (excluding references) using reasonable margins (at least one-inch margins all around) and at least 11-point font. If the authors believe that more details are essential to substantiate the claims of the paper, they may include a clearly marked appendix (with no space limit) that will be read at the discretion of the Program Committee. It is strongly recommended that submissions adhere to the specified format and length. Submissions that are clearly too long may be rejected immediately. The above specifications are meant to provide more freedom to the authors at the time of submission. Note that accepted papers will be allocated 14 pages (including references) in the LNCS format in the proceedings (see below).</p>



<p>The proceedings of the conference will be published by Springer-Verlag in the ARCoSS/LNCS series, and will be available for distribution at the conference. Accepted papers will be allocated 14 pages total in the LNCS format in the proceedings. Submissions are encouraged, though not required, to follow the LNCS format (Latex, Word). More information about the LNCS format can be found on the <a href="https://www.springer.com/cn/computer-science/lncs/conference-proceedings-guidelines" target="_blank" rel="noreferrer noopener">author instructions page of Springer-Verlag</a>. </p>



<p><strong>Best Paper Award</strong></p>



<p>The program committee will decide upon a best paper award and a best student paper award.</p>



<p><strong>Important Notice</strong></p>



<p>To accommodate the publishing traditions of different fields, authors of accepted papers can ask that only a one-page abstract of the paper appear in the proceedings, along with a URL pointing to the full paper. The authors should guarantee the link to be reliable for at least two years. This option is available to accommodate subsequent publication in journals that would not consider results that have been published in preliminary form in conference proceedings. Such papers must be submitted and formatted just like papers submitted for full-text publication.</p>



<p>Simultaneous submission of results to another conference with published proceedings is not allowed. Results previously published or presented at another archival conference prior to WINE 2021, or published (or accepted for publication) at a journal prior to the submission deadline of WINE 2021, will not be considered. Simultaneous submission of results to a journal is allowed only if the authors intend to publish the paper as a one-page abstract in WINE 2021. Papers that are accepted and appear as a one-page abstract can be subsequently submitted for publication in a journal but may not be submitted to any other conference that has a published proceeding.</p>



<p>Program PC co-chairs: Michal Feldman (chair), Hu Fu and Inbal Talgam-Cohen</p></div>







<p class="date">
by michalfeldman <a href="https://agtb.wordpress.com/2021/06/01/wine21-call-for-papers/"><span class="datestr">at June 01, 2021 09:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://toc4fairness.org/?p=1768">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/fair.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://toc4fairness.org/forc-2021-is-coming-up/">FORC 2021 is coming up!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>The Second annual Symposium on the Foundations of Responsible Computing (FORC) will be held virtually (on Gather.town) June 9-11, 2021.<a href="https://docs.google.com/forms/d/e/1FAIpQLSfELj0MvgcI83dmYThUPiynqWj8-G9Xve2dVf84EqKzgXXsHQ/viewform" target="_blank" rel="noreferrer noopener"> Registration is free, but required, by June 7</a>. Instructions for joining the event will be emailed to registered participants and posted online on June 8.</p>



<p>The program will feature 24 papers, six exciting panel discussions, three social hours featuring interactive board games, keynotes by Julie Owono (of the Facebook Oversight Board) and Kate Crawford (on her new book, the Atlas of AI), and a mentoring meetup.</p>



<p>The full program is here: <a href="https://responsiblecomputing.org/forc-2021-program/" target="_blank" rel="noreferrer noopener">https://responsiblecomputing.org/forc-2021-program/</a></p>



<p>The Symposium on Foundations of Responsible Computing (FORC) is a forum for mathematical research in computation and society writ large. The Symposium aims to catalyze the formation of a community supportive of the application of theoretical computer science, statistics, economics and other relevant analytical fields to problems of pressing and anticipated societal concern.</p>



<figure class="wp-block-image size-large"><img width="800" alt="" src="https://i2.wp.com/toc4fairness.org/wp-content/uploads/2021/05/white-logo-no-background.png?resize=800%2C858&amp;ssl=1" class="wp-image-1770" height="858" /></figure></div>







<p class="date">
by galoosh33 <a href="https://toc4fairness.org/forc-2021-is-coming-up/"><span class="datestr">at June 01, 2021 06:49 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6576209065051505306">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/05/what-is-natural-question-who-should.html">What is a natural question? Who should decide?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><br /></p><p>(Thanks to Timothy Chow for inspiring this post.)</p><p>My survey on Hilbert's Tenth Problem(see  <a href="https://arxiv.org/abs/2104.07220">here</a>) is about variants of the problem. One of them is as follows: </p><p>For which degrees d and number-of-vars n, is Hilbert's tenth problem decidable? undecidable? unknown? </p><p> I wondered why there was not a website with this information. More generally, the problem didn't seem to be getting much attention. (My survey does report on the attention it has gotten.) </p><p>I got several emails telling me it was the wrong question. I didn't quite know what they meant until Timothy Chow emailed me the following eloquent explanation:</p><p>-----------------------------------</p><p><i>One reason there isn't already a website of the type you envision is that from a number-theoretic (or decidability) point of view, parameterization by  degree and number of variables is not as natural as it might seem at first glance. The most fruitful lines of research have been geometric, and so geometric concepts such as smoothness, dimension, and genus are more natural than, say, degree. A nice survey by a number theorist is the book Rational Points on Varieties by Bjorn Poonen. Much of it is highly technical; however, reading the preface is very enlightening. Roughly speaking, the current state of the art is that there is really only one known way to prove that a system of Diophantine equations has no rational solution.</i></p><p>----------------------------------</p><p>AGAINST THE NUMBER THEORISTS VIEWPOINT:</p><p>1) ALICE: Why are you looking for your keys under the lamppost instead of where you dropped them?</p><p>   BOB: The light is better here.</p><p>2) I can imagine the following conversation:</p><p>BILL: I want to know about what happens with degree 3, and number of variables 3.</p><p>MATHPERSON: That's the wrong question you moron. The real question is what happens for fixed length of cohomology subchains.</p><p>BILL: Why is that more natural?</p><p>MATHPERSON: Because that is what we can solve. And besides, I've had 10 papers on it.</p><p><br /></p><p>FOR THE NUMBER THEORISTS VIEWPOINT</p><p>1) They are working on really hard problems so it is natural to gravitate towards those that can be solved.</p><p>2) I suspect that the math that comes out of studying classes of equations based on smoothness, dimension, genus is more interesting than what comes out of degree and number of vars. Or at least it has been so far. </p><p>META QUESTION</p><p>Who gets to decide what problems are natural?</p><p>People outside the field (me in this case) are asking the kind of questions that a layperson would ask and there is some merit to that.</p><p>People inside the field KNOW STUFF and hence their opinion of what's interesting to study has some merit. But they can also mistake `I cannot solve X' for `X is not interesting'</p><div><br /></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/05/what-is-natural-question-who-should.html"><span class="datestr">at May 30, 2021 11:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=21758">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2021/05/30/to-cheer-you-up-in-difficult-times-24-borodins-colouring-conjecture/">To Cheer You Up in Difficult times 24: Borodin’s colouring conjecture!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>An <a href="https://en.wikipedia.org/wiki/Acyclic_coloring">acyclic colouring</a> of a graph is a colouring of its vertices so that the subgraph spanned on union of every two colour classes is acyclic (a forest). Grunbaum conjectured in 1973 that </p>



<p class="has-text-align-center"><strong><span style="color: #a30042;" class="has-inline-color">Every planar graph has acyclic colouring with five colours.</span> </strong></p>



<p>This was proved by Borodin in 1976.</p>



<p>Borodin made the following stronger conjecture. Recall that a graph is <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="r" class="latex" />-degenerate if every  subgraph has a vertex of degree at most <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="r" class="latex" />. </p>



<p class="has-text-align-center"><strong><span style="color: #a3001e;" class="has-inline-color">Every planar graph <em>G</em> can be coloured with five colours so that the union of every <em>k</em> colour classes, <img src="https://s0.wp.com/latex.php?latex=1+%5Cle+k+%5Cle+4&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="1 \le k \le 4" class="latex" /> induces a <em>(k-1)</em>-degenerate graph. </span></strong></p>



<p>Let me mention an intermediate conjecture in-between Grunbaum’s conjecture and Borodin’s </p>



<p class="has-text-align-center"><strong><span style="color: #a30011;" class="has-inline-color">Every planar graph <em>G</em> can be coloured with five colours so that the union of every <em>k</em> colour classes, <img src="https://s0.wp.com/latex.php?latex=1+%5Cle+k+%5Cle+4&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="1 \le k \le 4" class="latex" /> induces a stress free graph for generic embedding into <img src="https://s0.wp.com/latex.php?latex=R%5E%7Bk-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="R^{k-1}" class="latex" />.</span></strong> <br /><br /></p>



<p>Grunbaum’s 1973 paper <a href="https://idp.springer.com/authorize/casa?redirect_uri=https://link.springer.com/article/10.1007/BF02764716&amp;casa_token=vnWD-T_S73sAAAAA:mUenckyg9cyx5mrJI0hGdRqZ5WznXX-keyu4jYW61z-CkI1pslMA4w7SheVILEa1g1yHmjmFrP63EoqPODY">Acyclic<strong> </strong>colorings of planar graphs‏</a> is a very imaginative and highly cited paper. It was the first paper I ever refereed and I remember spending a lot of time reading it.  Here is the link to Borodin’s paper <a href="https://www.sciencedirect.com/science/article/pii/0012365X79900773">On acyclic colorings of planar graphs‏</a>. I am not sure what is the current world-record for the number of colours.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2021/05/30/to-cheer-you-up-in-difficult-times-24-borodins-colouring-conjecture/"><span class="datestr">at May 30, 2021 08:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=2235">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2021/05/26/few-lessons-from-the-history-of-multiparty-computation/">A few lessons from the history of multiparty computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>As part of my Ph.D. qualifying exam, I gave a survey talk on some of the recent progress in practical multi-party computation (MPC). After the talk, Omer Reingold asked me why so much progress on MPC happened in the last decade or so, given that the main theoretical groundwork for multiparty computation was laid out in the 1980s.  Omer’s question got me interested, so I looked at some MPC papers from over the years and talked to a few people who have been working on MPC for some time now. In this post, I want to share some of what I’ve learned about the history of the progress of MPC, a few answers to Omer’s question, and potentially a few takeaways on progress in science more broadly.</p>



<p>To give a bit of background, MPC is one of the most fundamental problems in cryptography. In particular, MPC protocols allow a set of parties, each of which holds its private input, to compute a joint function over their inputs, in a way that protects the confidentiality and integrity of the computation from an adversary that controls a subset of the parties and the communication channels. Defining this precisely requires a lot of care, yet for now, you can think of an MPC protocol as being secure, if the adversary can only cause as much damage as it can in an “ideal world” in which the computation is performed with the aid of a trusted incorruptible party. Intuitively, in such an ideal world, the adversary cannot do much more than choose its inputs, modify its output, or choose not to participate in the computation at all. </p>



<p>In the 1980s, a <a href="https://ieeexplore.ieee.org/abstract/document/4568207">sequence</a> <a href="https://dl.acm.org/doi/10.1145/28395.28420">of</a> <a href="https://dl.acm.org/doi/10.1145/62212.62213">works</a> <a href="https://dl.acm.org/doi/10.1145/62212.62214">initiated</a> the study of multiparty computation and established very powerful and general results, showing the feasibility of constructing protocols for securely computing any multi-party functionality in a variety of settings. Those results were mostly theoretical. In contrast, the last 15 years saw a growing interest in MPC from a more practical perspective. To put this rising interest in context, consider the following two graphs (data for the graphs is <a href="https://docs.google.com/spreadsheets/d/1IzfKDRqv6C9hSeD9TyosvCl9fknN2V3Ja4tQjy54y0A/edit?usp=sharing">here</a>).</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="620" alt="" src="https://theorydish.files.wordpress.com/2021/05/comptime.png?w=620" class="wp-image-2245" height="372" /></figure></div>



<p>This graph shows the time of a two-party secure computation of the AES block cipher over the years. That is the time it takes to evaluate AES(k,x), where one party holds a 128-bit key k to the block cipher, the other party holds a 256-bit data block x, and the output is 256-bit long. The measurements are from the original papers. There are different variants of this “benchmark”, in terms of the number of parties (2PC/MPC), the number of corrupted parties (honest/dishonest majority), precise security model (semi-honest/fully malicious), hardware, network (LAN/WAN), and cost model (single/batch execution), but, for concreteness, the graph only includes results in the batch-evaluation setting in the fully malicious two-party setting. </p>



<p class="has-text-align-center"><img width="624" src="https://lh4.googleusercontent.com/lfa7-L5D3d5U8ZCHbAmUoqRH-RVaUmpFfSiFhBl7yF38ieoUmdo-LL0xH-gzXEaPauRXkCUmOYWDovfJvE792a0ikVxojM6g4P7EFD-mg4A2XbvzJWAslBug8UE6W4CnRhtIt4el" height="375" /></p>



<p>The second graph shows the number of papers on two-party computation, over the years. This is not a very well-defined characterization, but for simplicity, I looked at all the papers referenced from the relevant chapters in the <a href="https://securecomputation.org/">book on MPC</a> by Evans, Kolesnikov, and Rosulek. Admittedly, these are not all the papers in the area, there might be valuable indirect contributions that are missing, and, more importantly, the number of papers is a bit of a superficial metric. Yet, even with these caveats, I think this is helpful to get a general picture. On top of the flurry of academic research, MPC has also been thriving in the industry, with companies like <a href="https://www.curv.co/">Curv</a>, <a href="https://partisia.com/">Partisia</a>, <a href="https://sharemind.cyber.ee/">Sharemind</a>, <a href="https://www.unboundsecurity.com/">Unbound</a>, and others building MPC-based products and services.</p>



<p>The first graph shows quite impressive progress. In less than a decade, the time to securely compute AES in the two-party setting decreased by more than 60,000x, from more than 10 minutes to less than 10 milliseconds. (For reference, in the same period, CPU speeds increased <a href="https://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i7-975+%40+3.33GHz&amp;id=841">roughly</a> <a href="https://www.cpubenchmark.net/cpu.php?cpu=Intel+Core+i7-7740X+%40+4.30GHz&amp;id=3041">twofold</a>, and typical local-area network speeds increased from 1GB/S to 10GB/S.) The second graph illustrates the increase in the volume of research, which has enabled this progress. This includes advances such as <a href="https://dl.acm.org/doi/10.1145/100216.100287">various</a> <a href="https://dl.acm.org/doi/10.1145/336992.337028">increasingly</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-70583-3_40">efficient</a> <a href="https://link.springer.com/chapter/10.1007/978-3-662-46803-6_8">garbling</a> <a href="https://dl.acm.org/doi/10.1145/3133956.3134053">techniques</a>, <a href="https://link.springer.com/chapter/10.1007%2F11745853_30">more</a> <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.140.2627&amp;rep=rep1&amp;type=pdf">efficient</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-72540-4_4">cut</a>–<a href="https://link.springer.com/chapter/10.1007/978-3-642-20465-4_22">and</a>–<a href="https://link.springer.com/chapter/10.1007/978-3-642-19571-6_20">choose</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-40084-1_3">techniques</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-00457-5_22">for</a> <a href="https://dl.acm.org/doi/10.1145/2508859.2516698">malicious security</a>, <a href="https://link.springer.com/chapter/10.1007/978-3-642-20465-4_11">protocols</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-32009-5_38">based on</a> <a href="https://link.springer.com/chapter/10.1007/978-3-642-32009-5_40">information-theoretic</a> <a href="https://dl.acm.org/doi/10.1145/2976749.2978357">message-authentication</a> <a href="https://link.springer.com/chapter/10.1007/978-3-319-78372-7_6">codes</a>, <a href="https://crypto.stanford.edu/craig/craig-thesis.pdf">homomorphic</a> <a href="https://dl.acm.org/doi/10.1145/2090236.2090262">encryption</a>, and many others. (See the EKR book for an overview of these techniques and more references.) The second graph also clearly shows the inflection point that happened about 15 years ago. This inflection point illustrates the premise of the question that has triggered this blog post.</p>



<p>I use the term inflection point, since progress in MPC never really stopped between the late 80s and the mid-2000s, and there was a lot of research in the interim period. For example, <a href="https://eprint.iacr.org/2005/187.pdf">oblivious</a> <a href="https://dl.acm.org/doi/10.1145/1008908.1008920">transfer</a>–one of the fundamental primitives used <a href="https://dl.acm.org/doi/10.1145/3812.3818">to</a> <a href="https://link.springer.com/content/pdf/10.1007%2F3-540-47721-7_17.pdf">build</a> <a href="https://dl.acm.org/doi/10.1145/62212.62215">MPC</a>–<a href="https://link.springer.com/chapter/10.1007/3-540-44750-4_9">received</a> <a href="https://dl.acm.org/doi/abs/10.1145/237814.237996">a</a> <a href="https://link.springer.com/article/10.1007/BF00208002">lot</a> <a href="https://link.springer.com/chapter/10.1007/BFb0054139">of</a> <a href="https://dl.acm.org/doi/10.1145/301250.301312">attention</a> <a href="https://link.springer.com/chapter/10.1007/3-540-44987-6_8">and</a> <a href="https://dl.acm.org/doi/abs/10.5555/365411.365502">saw</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-45146-4_9">significant</a> <a href="https://link.springer.com/chapter/10.1007/978-3-540-40061-5_27">progress</a>. There <a href="https://link.springer.com/article/10.1007/BF02252866">have</a> <a href="https://link.springer.com/chapter/10.1007/3-540-38424-3_6">been</a> <a href="https://link.springer.com/article/10.1007/BF00196771">many</a> <a href="https://link.springer.com/chapter/10.1007/3-540-46766-1_32">works</a> <a href="https://dl.acm.org/doi/10.1145/167088.167109">developing</a> <a href="https://dl.acm.org/doi/abs/10.1145/195058.195408">the</a> <a href="https://dl.acm.org/doi/10.1145/259380.259412">theoretical</a> <a href="https://link.springer.com/chapter/10.1007/3-540-44598-6_5">framework</a> <a href="https://dl.acm.org/doi/10.1145/352600.352639">of</a> <a href="https://link.springer.com/chapter/10.1007/3-540-44448-3_13">secure</a> <a href="https://dl.acm.org/doi/abs/10.1145/380752.380855">computation</a>, studying <a href="https://eprint.iacr.org/2000/067">secure composition</a>, and <a href="https://dl.acm.org/doi/10.1145/72981.72995">reducing</a> <a href="https://dl.acm.org/doi/10.1145/100216.100287">the</a> <a href="https://link.springer.com/chapter/10.1007/3-540-38424-3_5">round</a> <a href="https://ieeexplore.ieee.org/document/595170">complexity</a> <a href="https://ieeexplore.ieee.org/document/814630">of</a> <a href="https://link.springer.com/chapter/10.1007/3-540-45022-X_43">secure</a> <a href="https://link.springer.com/chapter/10.1007/3-540-45539-6_23">multiparty</a> <a href="https://ieeexplore.ieee.org/abstract/document/892118">computation</a> <a href="https://dl.acm.org/doi/10.5555/646766.704286">protocols</a>. Other works developed special-purpose secure computation protocols for concrete applications such as <a href="https://ieeexplore.ieee.org/document/502223">secure auctions</a> and  <a href="https://dl.acm.org/doi/10.1145/293347.293350">private information retrieval</a>. Many of the techniques and ideas in these works were instrumental for the more recent progress.</p>



<p>Having said that, there still seems to have been a dip in the attention devoted to MPC for a certain period. One explanation that I’ve found interesting is that the powerful feasibility results from the early days made the problem seem “solved” from a theoretical point of view. As a result, interest in MPC within the theory community decreased. It took time before the interest ramped up again, this time more within the more-practically oriented crypto community. (Interestingly, since then, MPC found renewed interest in the theoretical cryptography community as well.)</p>



<p>One work that, to me, is a key point in the transition of MPC from theory to practice is the 2004 <a href="https://www.usenix.org/conference/13th-usenix-security-symposium/fairplay%E2%80%94-secure-two-party-computation-system">Fairplay paper</a>. This was the first full-fledged system that implemented generic secure function evaluation. I believe that, together with other early implementations of MPC-based systems (such as <a href="https://link.springer.com/chapter/10.1007/978-3-642-03549-4_20">the system</a> developed for the Danish sugar-beet auction and the <a href="https://link.springer.com/chapter/10.1007/978-3-540-88313-5_13">Sharemind system</a>), it played a pivotal role in accelerating practical research. I view it as a lesson on the value of “first systems”: they help to identify bottlenecks and discover new concerns, which are hard to predict without building an actual system. Moreover, such systems put “theory problems” on the radar of practitioners and demonstrate which ideas are closer to being practical.  In some sense, a system is an evidence that “the constants in the big-O have been worked out…and they are not astronomical.” Furthermore, when code is made public, follow-up works can build upon an initial system and improve on it more rapidly. A first system can mark the transition of an idea from pure theory to practice. It’s still fair to ask what determines the timing of the appearance of such a first system. One answer is that it often takes the right type of collaboration of researchers from different research communities, as seems to have been the case with “Fairplay”. </p>



<p>I think that external factors also played a role in the timing of events. Specifically, the growth of the Internet and the demand for security on the Internet stimulated a lot of interest and progress in applied cryptography. The late 1990s saw large-scale adoption of public-key cryptography with the successful development and deployment of SSL. More complex Internet applications began to appear later, including those that are inherently security-sensitive, like e-commerce. These applications stimulated interest in more advanced cryptographic tools, MPC being one of them. Indeed, MPC papers from that period discuss new Internet-driven applications as part of their motivation. </p>



<p>A final factor that I want to mention ties back to the first graph above. The fact that many works demonstrate their performance by measuring AES evaluation is, to me, an example of the value of standardized benchmarks. Such benchmarks help to evaluate new techniques and ideas within a certain area and can help progress on a particular dimension, partly because of the competitive element they add. As with any measurement, there is a risk of overfitting to the benchmark, rather than focusing on the true goal, but I think they are very helpful overall.</p>



<p>I am sure there are other valuable lessons to be learned from this case study. Moreover, I am quite certain that folks with more experience in the area have a much better perspective on the history of these developments than I do. I will be very happy to hear other perspectives!</p>



<p><strong>Acknowledgements:</strong> I would like to thank my quals committee, Dan Boneh, Omer Reingold, and Mary Wootters, for an interesting discussion that has led to this blog post. I am grateful to Yuval Ishai and Benny Pinkas for interesting conversations on the progress of MPC and to Henry Corrigan-Gibbs and Saba Eskandarian for providing me with helpful comments.</p></div>







<p class="date">
by Dima Kogan <a href="https://theorydish.blog/2021/05/26/few-lessons-from-the-history-of-multiparty-computation/"><span class="datestr">at May 27, 2021 01:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=18791">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/05/26/the-voting-paradox/">The Voting Paradox</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>Trust, but verify—Ronald Reagan</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/26/the-voting-paradox/group-3/" rel="attachment wp-att-18806"><img src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/group.png?w=200&amp;ssl=1" alt="" class="aligncenter size-medium wp-image-18806" /></a></p>
<p>
are researchers in the area of voting security. Some have worked in this area for decades, others for years, and some are new to the area. But they all signed a letter about election security—right after the last presidential election. The body of <a href="https://electionlawblog.org/?p=118718">the letter</a> is also below.</p>
<p>
Today I thought we might look into the main paradox surrounding voting security.<br />
<span id="more-18791"></span></p>
<p>
Peter G. Neumann and Rebecca Mercuri just published a <a href="https://cacm.acm.org/magazines/2021/6/252836-the-risks-of-election-believability-or-lack-thereof/fulltext">paper</a> in the CACM on voting security. It is titled <i>The Risks of Election Believability (or Lack Thereof)</i>. </p>
<p>They say: </p>
<blockquote><p><b> </b> <em> Trustworthiness in elections is inherently a total-system problem <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\dots}" class="latex" /> </em>
</p></blockquote>
<p>
</p><p>
So let’s look at election security.</p>
<p>
</p><p></p><h2> The Paradox </h2><p></p>
<p></p><p>
<i>The people who cast the votes don’t decide an election, the people who count the votes do—Joseph Stalin</i></p>
<p>
I am reluctant in citing Stalin. But I believe that he hit the mark. The key in any election, in the US or elsewhere, is how and by whom the votes are counted.  </p>
<p>
The issue with the letter, with the recent paper, and more is that the researchers seem to be caught in the middle between two points of view:</p>
<ul>
<li>
There is no evidence of voter fraud in the last presidential election. None. Zero. <p></p>
</li><li>
There is no proof of voting security in the last presidential election. None. Zero.
</li></ul>
<p>
This is the problem. We would like to believe that voting is fair and secure. We would like to believe that our election—especially for president—is fair and correct. But we really have no proof that this is true. We are left with desire to make elections safer, but take the position that there is no issue with them. </p>
<p>
Good luck.</p>
<p>
</p><p></p><h2> The Letter </h2><p></p>
<p></p><p>
Here is the letter. I think they miss saying things as bluntly as Stalin does. But they do say essentially the same.</p>
<blockquote><p><b> </b> <em> We are specialists in election security, having studied the security of voting machines, voting systems, and technology used for government elections for decades.</em></p><em>
<p>
We and other scientists have warned for many years that there are security weaknesses in voting systems and have advocated that election systems be better secured against malicious attack. As the National Academies recently concluded, “There is no realistic mechanism to fully secure vote casting and tabulation computer systems from cyber threats.” However, notwithstanding these serious concerns, we have never claimed that technical vulnerabilities have actually been exploited to alter the outcome of any US election.</p>
<p>
Anyone asserting that a US election was “rigged” is making an extraordinary claim, one that must be supported by persuasive and verifiable evidence. Merely citing the existence of technical flaws does not establish that an attack occurred, much less that it altered an election outcome. It is simply speculation.</p>
<p>
The presence of security weaknesses in election infrastructure does not by itself tell us that any election has actually been compromised. Technical, physical, and procedural safeguards complicate the task of maliciously exploiting election systems, as does monitoring of likely adversaries by law enforcement and the intelligence community. Altering an election outcome involves more than simply the existence of a technical vulnerability.</p>
<p>
We are aware of alarming assertions being made that the 2020 election was “rigged” by exploiting technical vulnerabilities. However, in every case of which we are aware, these claims either have been unsubstantiated or are technically incoherent. To our collective knowledge, no credible evidence has been put forth that supports a conclusion that the 2020 election outcome in any state has been altered through technical compromise.</p>
</em><p><em>
That said, it is imperative that the US continue working to bolster the security of elections against sophisticated adversaries. At a minimum, all states should employ election security practices and mechanisms recommended by experts to increase assurance in election outcomes, such as post-election risk-limiting audits. </em>
</p></blockquote>
<p></p><p>
The letter is well written, but <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\dots}" class="latex" /> They say in the letter: </p>
<blockquote><p><b> </b> <em> However, notwithstanding these serious concerns, we have never claimed that technical vulnerabilities have actually been exploited to alter the outcome of any US election. </em>
</p></blockquote>
<p>This seems to be a problem. How do you get people to <i>look both ways when crossing the street</i>, when you have also basically asserted: “No one has ever been hit by a car when crossing the street.”</p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/26/the-voting-paradox/cs/" rel="attachment wp-att-18795"><img width="276" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/cs.png?resize=276%2C183&amp;ssl=1" class="aligncenter size-full wp-image-18795" height="183" /></a></p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We believe that election security is a real issue. Perhaps our single point is: Even if we do not believe that any fraud happen in the past, we must agree to make the voting process secure. We must use all our insights to make elections not only fair, but believed to be fair.</p>
<p>
Look both ways. </p>
<p>
Ken notes that “Trust but verify” was first the Russian proverb <i>Doveryay no proveryay</i>, but that its origins are <a href="https://www.rbth.com/lifestyle/330521-reagan-trust-but-verify-chernobyl">unclear</a> even to Russians.  He adds that besides <i>how</i> and <i>by whom</i> there is also the issue of <i>when</i> votes are counted.  The warnings he gave in our election-eve <a href="https://rjlipton.wpcomstaging.com/2020/11/03/the-election-night-time-warp/">post</a> were reflected in <a href="https://www.factcheck.org/2020/12/false-claim-about-bidens-win-probability/">claims</a> made in the early December Texas attorney general filing.</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wpcomstaging.com/2021/05/26/the-voting-paradox/"><span class="datestr">at May 27, 2021 12:01 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/05/26/postdoc-opportunity-in-algebraic-complexity-at-boston-college-apply-by-july-30-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/05/26/postdoc-opportunity-in-algebraic-complexity-at-boston-college-apply-by-july-30-2021/">Postdoc Opportunity in Algebraic Complexity at Boston College (apply by July 30, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Computer Science department at Boston College invites applications for a postdoctoral position in the area of algebraic complexity under the supervision of Ilya Volkovich.</p>
<p>See attached pamphlet for more information.</p>
<p>Please direct any inquiries to Ilya Volkovich (Email: ilya.volkovich@bc.edu)</p>
<p>Website: <a href="https://sites.google.com/site/ilyavv/Postdoc%20add.pdf">https://sites.google.com/site/ilyavv/Postdoc%20add.pdf</a><br />
Email: ilya.volkovich@bc.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/05/26/postdoc-opportunity-in-algebraic-complexity-at-boston-college-apply-by-july-30-2021/"><span class="datestr">at May 26, 2021 09:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8240675027790472002">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/05/does-university-matter.html">Does the university matter?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>As we come out of a pandemic with online teaching and research collaborations, how much do we actually need the university?</p><p>Theoretical research in computer science, math and elsewhere it hardly slowed down with everyone hunkered down at home, and when it did it was more because of supervising kids with their on-line learning than being away from the university. Collaborating with those around the world was basically the same as collaborating with your colleagues on campus.</p><p>Many courses, especially the larger ones, worked about as well on-line as they do in person.</p><p>The pandemic is accelerating changes already in place. Before say 1960, the fastest travel for the masses was on train and boats and fast communication limited to expensive phone calls. You needed strong colleagues, a strong library and a strong support staff to be a successful academic. Traveling to meet colleagues and attend conferences was a luxury that few could do often.</p><p>The 60's gave us air travel though it wasn't until the 90's that we could readily send academic papers electronically. It's really only recently that we have the infrastructure to allow high-quality teaching and research collaboration online.</p><p>Suppose universities now just disappeared. Professors would be free agents, supported by grants and tuition from students taking their on-line courses and consulting. Students would pick and choose courses from the best instructors, their "transcript" being recorded on a blockchain-like database. PhD students would be more of an apprenticeship, a low salary in exchange for personalized mentoring from a professor. </p><p>For the experimental sciences, there would be a set of national labs that professors could join.</p><p>Startups would create apps to enable all these things, professors would just become yet another piece of the gig economy. Superstar academics can pull in large salaries, the rest would struggle to make a decent wage--not that different from actors and musicians. </p><p>Don't worry, universities aren't going anywhere soon. Or are they?</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/05/does-university-matter.html"><span class="datestr">at May 25, 2021 05:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5517">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5517">In which I answer more quantum computing questions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Yesterday, I had fun doing an open-ended Q&amp;A at the <a href="https://astralcodexten.substack.com/">Astral Codex Ten</a> weekly online meetup.  <a href="https://www.youtube.com/watch?v=DEYUt1tJlck">See here</a> for the YouTube video.  The questions were mainly about quantum computing, but ranged over various other topics as well, including education policy, the Great Stagnation, and what my biggest disagreements with Scott Alexander are.</p>



<p>In other news, last week I gave my talk about quantum supremacy at the (virtual, of course) <a href="https://quantumscienceseminar.com/videos/">Quantum Science Seminar</a>, organized by Sebastian Blatt and others.  <a href="https://www.youtube.com/watch?v=EeF7T9Bc1B0">See here</a> for the YouTube video.  Since I (alas) needed to leave after an hour sharp, the organizers asked if they could send me additional questions in writing and have me answer them.  I said sure, as long as I could also post the Q&amp;A on this blog!  So without further ado…</p>



<p><strong>Q:</strong> As you said, in computer science it’s difficult to prove that things are hard. From a computer science perspective, to what extent is “quantum supremacy” something absolute, and to what extent is it a shifting bar that depends on how good our classical hardware and algorithms are?</p>



<p><strong>SCOTT:</strong> It’s kind of like the question “can computers beat the best humans at chess?” The latter question also involves a non-absolute shifting bar – maybe humans are getting better! Or maybe they simply haven’t figured out how to beat the computers yet! So how can we say “computer supremacy” has been decisively achieved? Nevertheless, one can clearly see a phase transition, with Deep Blue in 1996-1997, where the burden of proof shifted massively from one side to the other, and has stayed there ever since. Even if humans are getting better, the computers have also gotten better, and at such an insane rate that humans seem to have no chance of ever again catching up.</p>



<p>From a theoretical standpoint, that’s exactly what we might expect to happen with quantum supremacy experiments – simply because they involve tasks that have polynomial scaling for quantum computers, but (as far as we know) exponential scaling for classical computers, where each additional qubit roughly doubles the classical resources required. In analyzing concrete quantum supremacy experiments, I’d say that the goal is not to pin down the exact factor by which they’re beating this or that classical simulation (the answers will change rapidly anyway, and depend on all sorts of low-level details), but simply to figure out whether or not we’ve entered that phase transition.</p>



<p><strong>Q:</strong> What do you generally think about improvements in tensor network methods as a challenge to quantum supremacy and the recent simulation of the supremacy result in Beijing?</p>



<p><strong>SCOTT:</strong> I <a href="https://www.scottaaronson.com/blog/?p=5371">blogged about this here</a>. It was a clever paper, which showed that if you focus narrowly on spoofing the linear cross-entropy benchmark used by Google, then there’s a classical algorithm to do that much faster than had been previously pointed out, by generating many samples that all share most of their bits in common (e.g., that all agree on the first 30 of the 53 bits). But many people remain unaware that, if you just changed the benchmark – for example, if you insisted that the returned samples not only pass the linear cross-entropy benchmark, but also be sufficiently different – then this classical spoofing strategy wouldn’t work and we’d be back to the previous status quo.</p>



<p><strong>Q:</strong> Why do you need a random circuit to test the device, and also why is this more interesting/useful than doing something very specific many times to test the device?</p>



<p><strong>SCOTT:</strong> The reasons to use random quantum circuits are simply that<br />(1) they generate complicated entangled states on all the qubits nearly as rapidly as it’s possible to do so – indeed, we now have theoretical results that give a detailed understanding of this process, and<br />(2) random circuits seem to have about as little “usable structure” (which a classical simulation might exploit) as it’s possible to have.<br />Eventually, of course, we’d like to run actually useful circuits (say, those that arise in Shor’s factoring algorithm), which will typically have regular patterns and be extremely far from random! But then more qubits will be needed to get an advantage over classical computers. It’s not terribly surprising for the <em>first</em> advantage over classical to be via random quantum circuits, which in some sense “maximally exploit” the hardware resources available.</p>



<p><strong>Q:</strong> Have you heard of/what do you think about the <a href="https://www.nature.com/articles/s41467-021-21119-1">recent NP-verification experiment</a> using a quantum optical setup from Paris?</p>



<p><strong>SCOTT:</strong> That experiment was actually based on a protocol that Beigi, Fefferman, Drucker, Shor, and I <a href="https://arxiv.org/abs/0804.0802">proposed back in 2008</a>. It’s crucial for people to understand that there’s no claimed speedup here for <em>solving</em> any NP-complete problem. We’re talking about a more arcane task: namely, proving to someone that an NP-complete problem has a solution by sending them a small number of qubits. Even there, the protocol depends on the ability to send two quantum states that are guaranteed <em>not</em> to be entangled with each other; also, the communication savings is “only” polynomial rather than exponential (in our original protocol, roughly √n qubits where n classical bits would have been needed). Nevertheless, it’s always fun to see a real experiment implementing some version of something that you worked out on paper, even if you already knew it would work!</p>



<p><strong>Q:</strong> If the difficulty for classical simulation is related to the Hilbert space dimension, has it been formally proven that an ideal analog classical computer cannot outperform a quantum computer?</p>



<p><strong>SCOTT:</strong> This is not a question of “formal proof” but of physics. In my view, we already know deep reasons why, in our universe, analog classical computers are unlikely to be able to do anything that can’t be efficiently simulated using a standard digital computer. (In other words, why analog classical computers don’t violate the “Extended Church-Turing Thesis.”) Those reasons have to do with nonlinear dynamics chaotically amplifying even the tiniest errors in an analog device. Or, if you really want to push this discussion to the bitter end, they have to do with the breakdown in our picture of a smooth spacetime that’s expected to occur at the Planck scale, of ~10<sup>-33</sup> centimeters and ~10<sup>-43</sup> seconds, for reasons of black hole thermodynamics and quantum gravity. Crucially, neither of these issues apply to quantum computation. The former doesn’t apply because of quantum error correction  and fault-tolerance, which have the effect of “discretizing” continuous errors; while the latter doesn’t apply because as far as anyone knows today, quantum mechanics (unlike theories that assume a smooth spacetime) is exactly true.</p>



<p><strong>Q:</strong> [In the comparison between quantum and classical computation], what do we mean by “classical resources” here? Do we mean something parochial like “resources obeying non-quantum laws that are available to us humans on Earth?” Or is any classical resource fair game, no matter its size and classical equations of motion? In that case, doesn’t demonstrating quantum supremacy require demonstrating that the quantum computer exceeds the capabilities of, say, a classical computer the size of the solar system that exploits some CTC (closed timelike curve)?</p>



<p><strong>SCOTT:</strong> If CTCs were possible, that would be a revolution in physics even greater than quantum mechanics! Leaving CTCs aside, though, cosmology and quantum gravity seem to impose a limit of roughly 10<sup>122</sup> on the number of bits (and the number of operations on the bits) that any computer that fit inside the observable universe could possibly have. And if you envision that cosmological computer as a classical one, then it shouldn’t take impossibly long for us to build quantum computers that can outperform it on some tasks: indeed, a device with ~400 qubits should already be enough! But of course we’re not there yet: with 50-60 qubits, QCs right now are “merely” challenging the largest classical computers currently available on earth (again, on contrived sampling tasks), rather than the largest that could fit in the observable universe.</p>



<p><strong>Q:</strong> Why is a quantum state (superposition or entangled state) inherently more fragile than a classical state?</p>



<p><strong>SCOTT:</strong> Because when information from the state (say, whether a qubit is 0 or 1, or which path a photon takes through a beamsplitter network) “leaks out” into the environment, the information effectively becomes entangled with the environment, which damages the state in a measurable way.  Indeed, it now appears to an observer as a mixed state rather than a pure state, so that interference between the different components can no longer happen. This is a fundamental, justly-famous feature of quantum information that’s not shared by classical information.</p>



<p><strong>Q:</strong> Given that we have noisy-intermediate scale quantum devices, what do you see as the fundamental role of noise in the discussion on quantum advantage or quantum supremacy. Is it simply a question of less noise is better, or are there things that cannot be done if there is noise?</p>



<p><strong>SCOTT:</strong> There will always be <em>some</em> noise. The big question, about any given platform, is whether the noise is low enough that you can start usefully error-correcting it away, or whether the noise is so high that there’s no point (i.e., whether you’re above or below the “fault-tolerance threshold”).  Until you start doing error-correction, most experts believe there’s a severe limit to how far you can scale: probably to quantum computations involving a few hundred qubits at most. Whereas once you have error-correction, at least in principle the sky’s the limit.</p>



<p><strong>Q:</strong> You used the Wright brothers as an example where an airplane that was not practically useful itself pioneered the path to useful flight. In what sense to the sampling experiments of Google and USTC also pioneer that path for what we need for the future of quantum computing, or to what extent do you see them as niche examples of quantum supremacy?</p>



<p><strong>SCOTT:</strong> I think the majority of what Google did, in integrating 53 superconducting qubits, making them programmable, etc. – and especially in characterizing the noise in a system at that scale – will be directly useful going forward. Indeed, that’s a large part of why they did it!  Likewise, a lot of what USTC did, in integrating hundreds of beamsplitters, photon sources, and photodetectors, could be directly relevant to building a universal optical quantum computer. On the other hand, it’s true that both groups took shortcuts with the immediate goal of quantum supremacy in mind. As an example, Google’s chip uses a particular 2-qubit gate that was chosen, not because it shows up naturally in any application, but simply because it’s extra-hard to simulate using tensor network contraction algorithms, so it let them get to quantum supremacy faster than if they’d used a more conventional 2-qubit gate like the CNOT.</p>



<p><strong>Q:</strong> To what extent does the measured circuit fidelity of 0.2% in the Google experiment limit the usability of this system for other computations?</p>



<p><strong>SCOTT:</strong> Oh, we don’t know of anything particularly useful to do with Google’s Sycamore chip – that is, anything that you couldn’t do much more easily without it – other than<br />(1) quantum supremacy demonstrations,<br />(2) <em>possibly</em> the generation of cryptographically certified random bits, and<br />(3) of course, calibration experiments that tell you about the behavior of integrated superconducting qubits and thereby help you iterate to the next device.<br />But things are developing rapidly – the best circuit fidelity that was achievable in 2019 is not necessarily the best now, or the best that will be achieved in another year or two.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (May 25):</span></strong> <strong>Please, no new questions</strong>; just discussion of the existing questions and answers! I had hoped to get some work done today; I hadn’t planned on another ask-me-anything session. Thanks!</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5517"><span class="datestr">at May 24, 2021 09:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=18770">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/">ACM Athena Lecturer Award</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><font color="#0044cc"><br />
<em>It was never about winning medals or being famous—Nancy Kerrigan</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/ah-2/" rel="attachment wp-att-18783"><img width="154" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/ah-1.png?resize=154%2C138&amp;ssl=1" class="alignright wp-image-18783" height="138" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Award <a href="https://awards.acm.org/about/2021-athena">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Ayanna Howard is this year’s winner of the ACM Athena Lecturer <a href="https://awards.acm.org/athena">Award</a>. She works in robotics and is <a href="https://engineering.osu.edu/about/office-dean/about-dean-ayanna-howard">Dean</a> of Engineering at Ohio State. She was previously Chair of the School of Interactive Computing at Georgia Tech.</p>
<p>
Today Ken and I congratulate her and also recognize past winners of the award.<br />
<span id="more-18770"></span></p>
<p>
The award is not for lecturing. Here is the description:</p>
<blockquote><p><b> </b> <em> Initiated in 2006, the ACM Athena Lecturer Award celebrates women researchers who have made fundamental contributions to computer science. The award carries a cash prize of $25,000, with financial support provided by Two Sigma. The Athena Lecturer gives an invited talk at a major ACM conference of her choice. </em>
</p></blockquote>
<p>
</p><h2> Howard’s Research </h2><p></p>
<p>
Ayanna Howard’s research spans three interconnected areas of robotics:</p>
<ul>
<li>
<b>Outer Space Robotics:</b> She did early work for NASA’s Jet Propulsion Laboratory. Here is a 2002 <a href="https://www.nasa.gov/vision/universe/roboticexplorers/ayanna_howard.html">article</a> that leads with her work on the “Safe Navigation Rover.” <p></p>
</li><li>
<b>Inner Space Robotics:</b> This work involves interaction and assistive technologies. It includes her co-founding the company <a href="http://zyrobotics.com/about/">Zyrobotics</a>, which creates mobile therapy and educational technology tools for children. <p></p>
</li><li>
<b>Inner Mindspace Robotics:</b> On what grounds can we <em>trust</em> robots? How can they be programmed to avoid biases in their interactions with human beings? Can the algorithms they use be certified for <em>fairness?</em> (We had some recent <a href="https://rjlipton.wpcomstaging.com/2021/03/10/making-algorithms-fair/">thoughts</a> of our own on the last subject.)
</li></ul>
<p>
There are technical connections that flow from a whole-situation/whole-person approach. Her NASA landing and navigation systems were not designed simply to solve a computer-vision and calculus problem of finding the flattest terrain. Instead, the design expressly maps visual and sensor readings into a knowledge and logic-based system of human reasoning. Then the system either judges or makes recommendations to human controllers. This kind of approach naturally flows into assessing the robotic judgments for blind spots and bias. Most in particular, she tries to combat a human tendency of uncritical acceptance of personal assistants. She wants to facilitate humans to challenge the robots and have the robots modulate their reasoning and behavior accordingly.</p>
<p>
She was inspired as a child by the TV show <a href="https://en.wikipedia.org/wiki/The_Bionic_Woman">The Bionic Woman</a>. Adding “-nic” after “bio” took what could have been influence to go into medicine into an avenue that channeled her childhood love of mathematics.</p>
<p>
</p><h2> A Puzzle </h2><p></p>
<p>
I designed a word-search puzzle by feeding terms from the award to a web app for creating them. We wondered if it was silly to include it. But maybe the puzzle is not so silly—besides that it was created by a ‘bot—if you think in these terms:</p>
<blockquote><p><b> </b> <em> How might a robot get the most out of solving it? </em>
</p></blockquote>
<p>
Here is the grid—see if you can find the words in it. The key is at the end.</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/pu/" rel="attachment wp-att-18774"><img width="400" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/pu.png?resize=400%2C400&amp;ssl=1" class="aligncenter wp-image-18774" height="400" /></a></p>
<p>
From a human standpoint, three minutes is award level. But for a robot:</p>
<ul>
<li>
Of course, a robot could solve the puzzle in three microseconds by brute-force string matching along every row, column, and diagonal. But there is no challenge in that—it is not what we think of as human <em>reading</em>. <p></p>
</li><li>
To be human fun, the puzzle should be fairly dense and have a “wordscape” where parallel rows, columns, and diagonals are used. Once we find one word, we can often find neighbors more quickly, and that feels rewarding.
</li></ul>
<p>
That’s what we’re asking: is there a way to teach robots to solve these puzzles in more human ways? OK, it’s too simple. But we like to put a peg down on a simple example, then run a line into the heart of the work, and ask: at what point does it cross the threshold of being nontrivial?</p>
<p>
</p><h2> All Athena Winners </h2><p></p>
<p>
Here are links to all the winners of this award:</p>
<p>
2021 <a href="https://awards.acm.org/award_winners/howard_5736184">Ayanna Howard</a></p>
<p>
2020 <a href="https://awards.acm.org/award_winners/kraus_4452744">Sarit Kraus</a></p>
<p>
2019 <a href="https://awards.acm.org/award_winners/bertino_2269926">Elisa Bertino</a></p>
<p>
2018 <a href="https://awards.acm.org/award_winners/goldsmith_5482565">Andrea Goldsmith</a></p>
<p>
2017 <a href="https://awards.acm.org/award_winners/kavraki_3691391">Lydia Kavraki</a></p>
<p>
2016 <a href="https://awards.acm.org/award_winners/rexford_4157665">Jennifer Rexford</a></p>
<p>
2015 <a href="https://awards.acm.org/award_winners/widom_2272011">Jennifer Widom</a></p>
<p>
2014 <a href="https://awards.acm.org/award_winners/dumais_2360550">Susan Dumais</a></p>
<p>
2013 <a href="https://awards.acm.org/award_winners/yelick_3873601">Katherine Yelick</a></p>
<p>
2012 <a href="https://awards.acm.org/award_winners/lynch_2276129">Nancy Lynch</a></p>
<p>
2011 <a href="https://awards.acm.org/award_winners/olson_2607695">Judith Olson</a></p>
<p>
2010 <a href="https://awards.acm.org/award_winners/irwin_1411388">Mary Jane Irwin</a></p>
<p>
2009 <a href="https://awards.acm.org/award_winners/eggers_1922665">Susan Eggers</a></p>
<p>
2008 <a href="https://awards.acm.org/award_winners/goldwasser_8627889">Shafi Goldwasser</a></p>
<p>
2007 <a href="https://awards.acm.org/award_winners/sparck-jones_7172364">Karen Sparck-Jones</a></p>
<p>
2006 <a href="https://awards.acm.org/award_winners/estrin_1782044">Deborah Estrin</a></p>
<p>
</p><h2> Open Problems </h2><p></p>
<p>
Lynch and Goldwasser are the only theory researchers. This is less than <img src="https://s0.wp.com/latex.php?latex=%7B10+%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{10 \%}" class="latex" />. </p>
<p>
The puzzle key:</p>
<p><a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/key/" rel="attachment wp-att-18773"><img width="400" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/05/key.png?resize=400%2C425&amp;ssl=1" class="aligncenter wp-image-18773" height="425" /></a></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/"><span class="datestr">at May 24, 2021 04:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/072">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/072">TR21-072 |  Arithmetic Circuit Complexity of Division and Truncation | 

	Gorav Jindal, 

	Pranjal Dutta, 

	Anurag Pandey, 

	Amit Sinhababu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Given polynomials $f,g,h\,\in \mathbb{F}[x_1,\ldots,x_n]$ such that $f=g/h$, where both $g$ and $h$ are computable by arithmetic circuits of size $s$, we show that $f$ can be computed by a circuit of size  $\poly(s,\deg(h))$.  This solves a special case of division elimination for high-degree circuits (Kaltofen'87 \&amp; WACT'16). The result is an exponential improvement over Strassen's classic result (Strassen'73) when $\deg(h)$ is $\poly(s)$ and $\deg(f)$ is $\exp(s)$, since the latter gives an upper bound of $\poly(s, \deg(f))$.

Further, we show that any univariate polynomial family $(f_d)_d$, defined by the initial segment of the power series expansion of rational function $g_d(x)/h_d(x)$ up to degree $d$ (i.e.~$f_d = g_d/h_d \bmod x^{d+1}$), where circuit size of $g$ is $s_d$ and degree of $g_d$ is at most $d$, can be computed by a circuit of size $\poly(s_d,\deg(h_d),\log d)$.
We also show a hardness result when the degrees of the rational functions are high (i.e.~$\Omega (d)$), assuming hardness of the integer factorization problem.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/072"><span class="datestr">at May 24, 2021 01:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/071">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/071">TR21-071 |  On the Algorithmic Content of Quantum Measurements | 

	Samuel Epstein</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that given a quantum measurement, for an overwhelming majority of pure states, no meaningful information is produced. This is independent of the number of outcomes of the quantum measurement. Due to conservation inequalities, such random noise cannot be processed into coherent data.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/071"><span class="datestr">at May 23, 2021 02:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5510">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5510">On turning 40 today</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Holy crap.</p>



<p>In case you’re wondering how I spent such a milestone of a day: well, I spent hours of it at an important virtual grant review meeting with the Department of Defense.  Alas, when it came time for my own big presentation at that meeting—about what my students and I had done over the past five years to lay the theoretical foundations for the recent achievement of quantum computational supremacy—I’d uploaded the completely wrong PowerPoint file (it was something.pptx rather than something.ppt, where they <em>weren’t</em> two versions of the same presentation).  Sorting this out took about 10 minutes, destroyed my momentum, and wasted everyone’s time.  I partly blame the Microsoft Teams platform, whose limitations as conferencing software compared to Zoom necessitated emailing my presentation in the first place.  But of course, part of the blame rests with me.</p>



<p>I had to explain apologetically to the US Department of Defense that I’m no good with tech stuff—being a mere computer science PhD.  And unlike many of my colleagues (who I envy), back in my youth—for at age 40 I’m no longer young—I never had enough time to become <em>both</em> the kind of person who might earn a big grant to do quantum computing theory, <em>and</em> the kind of person who’d be minimally competent at the logistics of a review meeting for such a grant.</p>



<p></p><hr /><p></p>



<p>Forty years.  Seven-eighths of those years, aware of the finiteness of the speed of light and of its value.  Four-fifths of them, aware of the grislier details of the Holocaust.  Three-quarters of them, aware of what it means to write code.  Two-thirds of them, aware of polynomial versus exponential time.  More than half of them trying to understand the capabilities and limitations of quantum computers as my day job.  And then, rounding the corner, more than a third of the years writing this blog, a third of them being a professor, a quarter of them married, a fifth of them raising kids, a thirtieth of them in the midst of a global pandemic.</p>



<p>I didn’t even come <em>close </em>to achieving everything I hoped I would in my thirties.  At least a half-dozen major papers, ones I expected would’ve been finished years ago (on the mixing of coffee and cream, on complexity and firewalls and AdS/CFT, on certified random numbers from sampling-based quantum supremacy experiments, on the implications of the Raz-Tal oracle separation, …), still need to be revised or even written.  Other projects (e.g., the graphic novel about teaching math to Lily) were excitedly announced and then barely even started.  I never wrote most of my promised blog post about the continuum hypothesis, <em>or</em> the one about Stephen Wolfram’s recrudescent claims of a unified theory of physics.  And covid, which determined the world’s working conditions while we were running out the clock, turned out <em>not</em> to be a hyper-productive time for me.  That’s how you know I’m not Newton (well, it’s the not the only way you know).</p>



<p>Anyway, during the runup to it, one’s 40th birthday feels like a temporal singularity, where you have to compress more and more of what you’d hoped to achieve before age 40 as you get closer and closer to it, because what the hell is there on the other side? <em> The</em>y<em>‘re</em> over-40 and hence “old”; <em>you’re</em> under-40 and hence still “young.”</p>



<p>OK, but here I am on the other side right now, <em>the “old” side</em>, and I’m still here, still thinking and writing and feeling fairly continuous with my pre-singularity embodiment!  And so far, in 16 hours on this side, the most senile thing I’ve done has been to email the wrong file attachment and thereby ruin an important funding presenta… you know what, let’s not even go there.</p>



<p>If you feel compelled to give me a 40<sup>th</sup> birthday present, then just make it a comment on this post, as short or long as you like, about what anything I said or did meant for you.  I’m a total softie for that stuff.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5510"><span class="datestr">at May 21, 2021 08:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2021/05/21/international-school-conference-in-algorithms-combinatorics-and-complexity/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2021/05/21/international-school-conference-in-algorithms-combinatorics-and-complexity/">International School-conference in Algorithms, Combinatorics, and Complexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
May 24-28, 2021 Online https://indico.eimi.ru/event/199/ An advanced school for young researchers featuring three minicourses in vibrant areas of mathematics and computer science. The target audience includes graduate, master, and senior bachelor students of any mathematical speciality.</div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2021/05/21/international-school-conference-in-algorithms-combinatorics-and-complexity/"><span class="datestr">at May 21, 2021 09:14 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
