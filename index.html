<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at April 02, 2019 03:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/04/01/ph-d-postdoc-positions-at-technical-university-of-munich-germany-apply-by-april-23-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/04/01/ph-d-postdoc-positions-at-technical-university-of-munich-germany-apply-by-april-23-2019/">Ph.D. &amp; Postdoc Positions at Technical University of Munich (Germany) (apply by April 23, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The group of Alexander-von-Humboldt Professor Andreas S. Schulz at Technische Universität München (TUM) is seeking exceptional, highly motivated talents with expertise or interest in algorithms, algorithmic game theory, combinatorial optimization, graph theory, integer programming, machine learning, network flows, operations research, stochastic optimization, or a related subject.</p>
<p>Website: <a href="https://www.or.tum.de/fileadmin/w00bwl/www/PDFs/TUM_Job_Offer.pdf">https://www.or.tum.de/fileadmin/w00bwl/www/PDFs/TUM_Job_Offer.pdf</a><br />
Email: or@tum.de</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/04/01/ph-d-postdoc-positions-at-technical-university-of-munich-germany-apply-by-april-23-2019/"><span class="datestr">at April 01, 2019 07:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5766992926243003607">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/04/an-interdisciplinary-approach-to-p-vs-np.html">An Interdisciplinary approach to P vs NP</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I have a grant with some brain scientists on the following exciting approach to P vs NP.<br />
<br />
We want to prove:<br />
<br />
                               There is no algorithm for SAT in P<br />
<br />
This seems hard.  So lets scale down our goals to:<br />
<br />
                              Lance cannot find an algorithm for SAT in P<br />
<br />
You can replace Lance with someone else, but Lance has volunteered to have brain scans done. The idea is to scan the P vs NP part of his brain and see what we can discern.<br />
<br />
I know what you are thinking. Lance truly believes that SAT is NOT in P so perhaps even if SAT is in P, he would have a mental block. Hence I am hoping to also get some serious theorists that think SAT is in P to participate.  This might also shed light on the following conjecture:  is it easier to prove a theorem if you believe it is true.<br />
<br />
Lance has proposed another line of research. Barriers. Try to establish<br />
<br />
                             Lance cannot prove that SAT is NOT in P<br />
<br />
using brain scans and he volunteered.<br />
<br />
<table cellpadding="0" align="center" style="margin-left: auto; margin-right: auto; text-align: center;" cellspacing="0" class="tr-caption-container"><tbody>
<tr><td style="text-align: center;"><a style="margin-left: auto; margin-right: auto;" href="https://1.bp.blogspot.com/-w0aJgcjWXp0/XI-8jhzGnlI/AAAAAAABmv4/xmXbmb5HDy4zahASbPwc-RjOqeRjLD0DgCLcBGAs/s1600/mribrain.jpg"><img width="259" src="https://1.bp.blogspot.com/-w0aJgcjWXp0/XI-8jhzGnlI/AAAAAAABmv4/xmXbmb5HDy4zahASbPwc-RjOqeRjLD0DgCLcBGAs/s320/mribrain.jpg" border="0" height="320" /></a></td></tr>
<tr><td style="text-align: center;" class="tr-caption">Brain Scan of Lance's Proving Ability</td></tr>
</tbody></table>
<br />
For this one the mental block problem is gone; however,   as you can clearly see from his brain scan, Lance will never prove that SAT is not in P. Seven years as department chair has caused irreversible damage to his ability to reason logically.<br />
<br />
We hope to recruit other theorists to the project. The sticking point might be privacy: if we prove that professor X cannot solve P vs NP will the affect their being hired? For this reason we will restrict the study to professors with Tenure. But this is a weakness of the study since we had wanted to study if younger people have a better chance to resolve P vs NP.  So we need to find very young tenured professors.<br />
<br />
After we get the technology working on Theorists and P vs NP we will try to expand it for home use. For example, if a spouse claims <i>I could never learn to cook </i>or <i>I could never learn to drive (that's me) </i>their partner  will be able to verify the statement. It is not clear if this will make the divorce rate go up or down. Or if a child says <i>I just can't do algebra</i> the parents can test the child and say <i>Oh yes you can</i>!</div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/04/an-interdisciplinary-approach-to-p-vs-np.html"><span class="datestr">at April 01, 2019 04:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/046">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/046">TR19-046 |  andom walks and forbidden minors II: A $\poly(d\eps^{-1})$-query tester for minor-closed properties of bounded degree graphs | 

	Akash Kumar, 

	C. Seshadhri, 

	Andrew Stolman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Let $G$ be a graph with $n$ vertices and maximum degree $d$. Fix some minor-closed property $\mathcal{P}$ (such as planarity).
We say that $G$ is $\varepsilon$-far from $\mathcal{P}$ if one has to remove $\varepsilon dn$ edges to make it have $\mathcal{P}$.
The problem of property testing $\mathcal{P}$ was introduced in the seminal work of Benjamini-Schramm-Shapira (STOC 2008)
that gave a tester with query complexity triply exponential in $\varepsilon^{-1}$.
Levi-Ron (TALG 2015) have given the best tester to date, with a quasipolynomial (in $\varepsilon^{-1}$) query complexity.
It is an open problem to get property testers whose query complexity is $\poly(d\varepsilon^{-1})$,
even for planarity.

In this paper, we resolve this open question. For any minor-closed property,
we give a tester with query complexity $d\cdot \poly(\varepsilon^{-1})$.
The previous line of work on (independent of $n$, two-sided) testers is primarily combinatorial.
Our work, on the other hand, employs techniques from spectral graph theory. This paper
is a continuation of recent work of the authors (FOCS 2018) analyzing random walk algorithms
that find forbidden minors.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/046"><span class="datestr">at April 01, 2019 08:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/04/01/the-sat-smt-ar-summer-school/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/04/01/the-sat-smt-ar-summer-school/">The SAT/SMT/AR Summer School</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
July 3-6, 2019 Lisbon, Portugal https://reason.di.fc.ul.pt/ssa-school-2019/ Registration deadline: May 31, 2019 Satisfiability (SAT), Satisfiability Modulo Theories (SMT), and Automated Reasoning (AR) continue to make rapid advances and find novel uses in a wide variety of applications, both in computer science and beyond. The SAT/SMT/AR Summer School aims to bring a select group of students up … <a href="https://cstheory-events.org/2019/04/01/the-sat-smt-ar-summer-school/" class="more-link">Continue reading <span class="screen-reader-text">The SAT/SMT/AR Summer School</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/04/01/the-sat-smt-ar-summer-school/"><span class="datestr">at April 01, 2019 08:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15715">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/04/01/the-breakthrough-result-of-2019/">The Breakthrough Result Of 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Our nomination for best result of the year</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/04/carnivalfool.png"><img src="https://rjlipton.files.wordpress.com/2019/04/carnivalfool.png?w=123&amp;h=135" alt="" width="123" class="alignright wp-image-15716" height="135" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://pxhere.com/en/photo/1036632">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Faadosly Polir has had an incredible year of research success. A year ago we <a href="https://rjlipton.wordpress.com/2018/04/01/the-entropy-of-baseball/">covered</a> his research on universal information entropy in baseball. This led to uncredited co-authorship on a <a href="https://arxiv.org/abs/1812.05561">paper</a>, which <em>Quanta</em> <a href="https://www.quantamagazine.org/quantum-scarring-appears-to-defy-universes-push-for-disorder-20190320/">covered</a> last week, about reversal of entropy in a previously-built 51-qubit quantum <a href="https://www.nature.com/articles/nature24622">computer</a>. The paper focuses on quantum many-body scarring in a Bunimovich <a href="https://blogs.ams.org/visualinsight/2016/11/15/bunimovich-stadium/">stadium</a>, but Polir’s work on athletic body scarring in baseball stadiums was integral. </p>
<p>
Today we report on his exciting and topical new findings.</p>
<p>
Polir’s next project implemented a <a href="https://www.quora.com/How-do-random-events-of-quantum-physics-influence-the-information-content-of-the-universe">suggestion</a> by the complexity theorist Vaughan Pratt on how to research the influence of random events on the information content of the universe:</p>
<blockquote><p><b> </b> <em> Picture inserting a giant eggbeater into the deep state cloud servers and relocating all its bits at random. How would you recover important information like the net worth of Meghan Markle or President Trump’s tax returns? </em>
</p></blockquote>
<p></p><p>
Polir began the Cloud Beater Project using spare Amazon Web Services credits from Ken. The results so far are classified, but in addition to the above objectives there is a current push to infer from web traffic the full text of the impending <a href="https://en.wikipedia.org/wiki/Special_Counsel_investigation_(2017-2019)">report</a> by Robert Mueller. The string length has been <a href="https://www.nytimes.com/2019/03/28/us/politics/mueller-report-length.html">inferred</a>. Polir’s model algebraically represents the entire cloud as a finite automaton analogous to Alan Turing’s model of the Enigma machine during World War II. The inferencing process is similar and <a href="https://www.nhregister.com/technology/businessinsider/article/With-just-60-and-internet-access-researchers-13628061.php">cheap</a>. </p>
<p>
The newest work, however, will have the greatest social impact for the research community.</p>
<p>
</p><p></p><h2> The Problem </h2><p></p>
<p></p><p>
The problem is one we all are familiar with: the impact of the Internet and computing technology resources on critical thinking and academic research <a href="https://www.weforum.org/agenda/2018/03/is-technology-hurting-productivity">productivity</a>. After extensive analysis-of-variance runs on Google Scholar data, Polir’s team isolated one key adverse factor:</p>
<blockquote><p><b> </b> <em> <i>LaTeX forces one to compile and recompile multiple times</i>. </em>
</p></blockquote>
<p></p><p>
In retrospect the effect of this should have been suspected—after all, LaTeX is the one factor common to a major part of research across all scientific disciplines. Here are examples of relevant user <a href="https://tex.stackexchange.com/questions/107967/need-to-typeset-twice-for-correct-compile">comments</a>, some paraphrased:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> You cannot avoid it. LaTeX has to build the .aux file to store the table of contents (ToC) and such, because when typesetting the ToC it cannot know beforehand what sections will occur. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> Often not only two but three or more runs are necessary. Imagine a document with lots of figures and a list of figures somewhere at the first pages of the document. All pages are numbered using ascending Arabic numbers. First compilation run will typeset the document without any entry at the list of figures but collects the information at the .lof file (via .aux file). Second compilation run will typeset the list of figures with several pages and as a consequence of this the page numbers of all figures will change. So you need a third run to get the correct numbers at the list of figures.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> To correctly line up the various parts of a longtable, “In the typical case the algorithm will converge after three or four passes” (manual, section 4).</p>
<p>
</p><p></p><h2> The Magnitude </h2><p></p>
<p></p><p>
The result is the observation that there now are so many uses of LaTeX that any inefficiency in using it has great consequences. The bottom line of the first findings chapter in the report led by Polir is:</p>
<blockquote><p><b> </b> <em> We found that over 100 million hours of productive time per year are lost to the multiple-pass issue in LaTeX. </em>
</p></blockquote>
<p></p><p>
There are now billions of LaTeX pages being worked on each year. See <a href="https://www.overleaf.com/blog/219-youve-created-three-million-projects-and-counting-dot-dot-dot">this</a> for some data. Thus at a conservative estimate of $100 dollars per hour this means that we are losing <i>over ten billion dollars per year</i>. </p>
<p>
</p><p></p><h2> Ken’s Solution </h2><p></p>
<p></p><p>
Ken has a way of coping. He spends the time waiting for LaTeX documents to open and compile on his office PC in a productive way. He used to check fantasy baseball or football player news during these waits. But last year he acquired a Facebook friend (FBF) from the chess world who became the first—out of his several hundred FBFs—to post cat videos. Several times daily cat videos, all new. </p>
<p>
Ken had never seen a Facebook cat video before. So now he goes to the FBF’s page and clicks the next one while waiting for LaTeX to finish. This does, however, have less relevance to his statistical chess research than <a href="https://rjlipton.wordpress.com/2012/07/29/benfords-law-and-baseball/">fantasy</a> <a href="https://rjlipton.wordpress.com/2015/10/12/is-the-hot-hand-fallacy-a-fallacy/">sports</a> <a href="https://rjlipton.wordpress.com/2018/03/28/is-there-momentum-in-chess/">had</a>.</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/04/videocat.png"><img src="https://rjlipton.files.wordpress.com/2019/04/videocat.png?w=600" alt="" class="aligncenter size-full wp-image-15717" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">The mother <a href="https://en.wikipedia.org/wiki/Recurring_Saturday_Night_Live_characters_and_sketches_introduced_1988%E2%80%931989#Toonces_The_Driving_Cat">lode</a>?</font>
</td>
</tr>
</tbody></table>
<p></p><h2> Polir’s Solution </h2><p></p>
<p>
Polir found a different solution that does not use cat videos—too bad for the cats. Polir first approached the most recently responsible party, who won the 2013 ACM Turing Award for solving the <em>broken deli number dispenser</em> problem. The prize-winning solution, as described in the <a href="https://amturing.acm.org/award_winners/lamport_1205376.cfm">citation</a>, is to have each customer choose a number higher than all the other customers’ numbers. But how to leverage this brilliant solution to solve the multi-pass problem?</p>
<p>
Polir’s insight came while consulting the original responsible party and author of the following computer <a href="https://www-cs-faculty.stanford.edu/~knuth/programs/sat13.w">code</a> for a SAT solver. While hearing the author explain how this code emerged from his Pascal-based <a href="https://en.wikipedia.org/wiki/WEB">WEB</a> and C-based <a href="https://en.wikipedia.org/wiki/CWEB">CWEB</a> programming environments, Polir realized this in a flash:</p>
<blockquote><p><b> </b> <em> A LaTeX document is a <b>network</b>. </em>
</p></blockquote>
<p></p><p>
This led to the realization that the quick-compilation problems could be formulated as instances of <a href="https://en.wikipedia.org/wiki/Linear_network_coding">network coding</a> problems upon dividing the document into <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" />-sized chunks. A helpful reader of this blog supplied the final needed piece last week in a <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/#comment-100107">comment</a>: via this new <a href="https://arxiv.org/abs/1902.10935">paper</a>, there is an efficient reduction from network coding to integer multiplication. The reduction is not a string mapping but rather “corporate” via direct analysis of solving circuits.</p>
<p>
Thus the solution came down to ideas in the brilliant new <a href="https://web.maths.unsw.edu.au/~davidharvey/papers/nlogn/">paper</a> on integer multiplication which we just <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">posted</a> about. It means that we can solve the multi-pass problem essentially by multiplying pieces of the document together—or more exactly, <a href="https://en.wikipedia.org/wiki/Convolution#Discrete_convolution">convolving</a> them. We needn’t be concerned about our remarks on the algorithm in that paper being galactic—there is a clear proof of concept in that the paper’s second author is also the chief developer of the <a href="http://texmacs.org/tmweb/home/welcome.en.html">TeXmacs</a> composition environment. We thus nominate the paper plus Polir’s breakthrough consequence for result of the year.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Incidentally, that comment has tag number 100,107—which means we just passed the 100,000 milepost in whatever those tags signify. We actually have 18,694 comments over the history of the blog and have been intending to mark its passing 20K. This again gives us a “no-fooling” opportunity to thank our readers.</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/04/01/the-breakthrough-result-of-2019/"><span class="datestr">at April 01, 2019 06:01 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12641">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12641">Connected max cut is polynomial for graphs without $K_5\backslash e$ as a minor</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaourar:Brahim.html">Brahim Chaourar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12641">PDF</a><br /><b>Abstract: </b>Given a graph $G=(V, E)$, a connected cut $\delta (U)$ is the set of edges of
E linking all vertices of U to all vertices of $V\backslash U$ such that the
induced subgraphs $G[U]$ and $G[V\backslash U]$ are connected. Given a positive
weight function $w$ defined on $E$, the connected maximum cut problem (CMAX
CUT) is to find a connected cut $\Omega$ such that $w(\Omega)$ is maximum among
all connected cuts. CMAX CUT is NP-hard even for planar graphs. In this paper,
we prove that CMAX CUT is polynomial for graphs without $K_5\backslash e$ as a
minor. We deduce a quadratic time algorithm for the minimum cut problem in the
same class of graphs without computing the maximum flow.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12641"><span class="datestr">at April 01, 2019 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12525">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12525">Shed More Light on Bloom Filter's Variants</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patgiri:Ripon.html">Ripon Patgiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayak:Sabuzima.html">Sabuzima Nayak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Borgohain:Samir_Kumar.html">Samir Kumar Borgohain</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12525">PDF</a><br /><b>Abstract: </b>Bloom Filter is a probabilistic membership data structure and it is
excessively used data structure for membership query. Bloom Filter becomes the
predominant data structure in approximate membership filtering. Bloom Filter
extremely enhances the query response time, and the response time is very fast.
Bloom filter (BF) is used to detect whether an element belongs to a given set
or not. The Bloom Filter returns True Positive (TP), False Positive (FP), or
True Negative (TN). The Bloom Filter is widely adapted in numerous areas to
enhance the performance of a system. In this paper, we present a) in-depth
insight on the Bloom Filter,and b) the prominent variants of the Bloom Filters.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12525"><span class="datestr">at April 01, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12516">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12516">Ham-Sandwich cuts and center transversals in subspaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schnider:Patrick.html">Patrick Schnider</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12516">PDF</a><br /><b>Abstract: </b>The Ham-Sandwich theorem is a well-known result in geometry. It states that
any $d$ mass distributions in $\mathbb{R}^d$ can be simultaneously bisected by
a hyperplane. The result is tight, that is, there are examples of $d+1$ mass
distributions that cannot be simultaneously bisected by a single hyperplane. In
this abstract we will study the following question: given a continuous
assignment of mass distributions to certain subsets of $\mathbb{R}^d$, is there
a subset on which we can bisect more masses than what is guaranteed by the
Ham-Sandwich theorem?
</p>
<p>We investigate two types of subsets. The first type are linear subspaces of
$\mathbb{R}^d$, i.e., $k$-dimensional flats containing the origin. We show that
for any continuous assignment of $d$ mass distributions to the $k$-dimensional
linear subspaces of $\mathbb{R}^d$, there is always a subspace on which we can
simultaneously bisect the images of all $d$ assignments. We extend this result
to center transversals, a generalization of Ham-Sandwich cuts. As for
Ham-Sandwich cuts, we further show that for $d-k+2$ masses, we can choose $k-1$
of the vectors defining the $k$-dimensional subspace in which the solution
lies.
</p>
<p>The second type of subsets we consider are subsets that are determined by
families of $n$ hyperplanes in $\mathbb{R}^d$. Also in this case, we find a
Ham-Sandwich-type result. In an attempt to solve a conjecture by Langerman
about bisections with several cuts, we show that our underlying topological
result can be used to prove this conjecture in a relaxed setting.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12516"><span class="datestr">at April 01, 2019 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12449">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12449">Multiplication method for factoring natural numbers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nesiolovskiy:Igor.html">Igor Nesiolovskiy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nesiolovskiy:Artem.html">Artem Nesiolovskiy</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12449">PDF</a><br /><b>Abstract: </b>We offer multiplication method for factoring big natural numbers which
extends the group of the Fermat's and Lehman's factorization algorithms and has
run-time complexity $O(n^{1/3})$. This paper is argued the finiteness of
proposed algorithm depending on the value of the factorizable number n. We
provide here comparative tests results of related algorithms on a large amount
of computational checks. We describe identified advantages of the proposed
algorithm over others. The possibilities of algorithm optimization for reducing
the complexity of factorization are also shown here.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12449"><span class="datestr">at April 01, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12400">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12400">A Force-Directed Approach for Offline GPS Trajectory Map Matching</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rappos:Efstratios.html">Efstratios Rappos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Robert:Stephan.html">Stephan Robert</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cudr=eacute==Mauroux:Philippe.html">Philippe Cudré-Mauroux</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12400">PDF</a><br /><b>Abstract: </b>We present a novel algorithm to match GPS trajectories onto maps offline (in
batch mode) using techniques borrowed from the field of force-directed graph
drawing. We consider a simulated physical system where each GPS trajectory is
attracted or repelled by the underlying road network via electrical-like
forces. We let the system evolve under the action of these physical forces such
that individual trajectories are attracted towards candidate roads to obtain a
map matching path. Our approach has several advantages compared to traditional,
routing-based, algorithms for map matching, including the ability to account
for noise and to avoid large detours due to outliers in the data whilst taking
into account the underlying topological restrictions (such as one-way roads).
Our empirical evaluation using real GPS traces shows that our method produces
better map matching results compared to alternative offline map matching
algorithms on average, especially for routes in dense, urban areas.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12400"><span class="datestr">at April 01, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12359">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12359">Parallelizable global conformal parameterization of simply-connected surfaces via partial welding</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Choi:Gary_P=_T=.html">Gary P. T. Choi</a>, Yusan Leung-Liu, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Xianfeng.html">Xianfeng Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lui:Lok_Ming.html">Lok Ming Lui</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12359">PDF</a><br /><b>Abstract: </b>Conformal surface parameterization is useful in graphics, imaging and
visualization, with applications to texture mapping, atlas construction,
registration, remeshing and so on. With the increasing capability in scanning
and storing data, dense 3D surface meshes are common nowadays. While meshes
with higher resolution better resemble smooth surfaces, they pose computational
difficulties for the existing parameterization algorithms. In this work, we
propose a novel parallelizable algorithm for computing the global conformal
parameterization of simply-connected surfaces via partial welding maps. A given
simply-connected surface is first partitioned into smaller subdomains. The
local conformal parameterizations of all subdomains are then computed in
parallel. The boundaries of the parameterized subdomains are subsequently
integrated consistently using a novel technique called partial welding, which
is developed based on conformal welding theory. Finally, by solving the Laplace
equation for each subdomain using the updated boundary conditions, we obtain a
global conformal parameterization of the given surface, with bijectivity
guaranteed by quasi-conformal theory. By including additional shape
constraints, our method can be easily extended to achieve disk conformal
parameterization for simply-connected open surfaces and spherical conformal
parameterization for genus-0 closed surfaces. Experimental results are
presented to demonstrate the effectiveness of our proposed algorithm. When
compared to the state-of-the-art conformal parameterization methods, our method
achieves a significant improvement in both computational time and accuracy.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12359"><span class="datestr">at April 01, 2019 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12312">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12312">Data structures to represent sets of k-long DNA sequences</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chikhi:Rayan.html">Rayan Chikhi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Holub:Jan.html">Jan Holub</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Medvedev:Paul.html">Paul Medvedev</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12312">PDF</a><br /><b>Abstract: </b>The analysis of biological sequencing data has been one of the biggest
applications of string algorithms. The approaches used in many such
applications are based on the analysis of k-mers, which are short fixed-length
strings present in a dataset. While these approaches are rather diverse,
storing and querying k-mer sets has emerged as a shared underlying component.
Sets of k-mers have unique features and applications that, over the last ten
years, have resulted in many specialized approaches for their representation.
In this survey, we give a unified presentation and comparison of the data
structures that have been proposed to store and query k-mer sets. We hope this
survey will not only serve as a resource for researchers in the field but also
make the area more accessible to outsiders
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12312"><span class="datestr">at April 01, 2019 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.12243">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.12243">DEEP-FRI: Sampling outside the box improves soundness</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Sasson:Eli.html">Eli Ben-Sasson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Lior.html">Lior Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopparty:Swastik.html">Swastik Kopparty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saraf:Shubhangi.html">Shubhangi Saraf</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.12243">PDF</a><br /><b>Abstract: </b>Motivated by the quest for scalable and succinct zero knowledge arguments, we
revisit worst-case-to-average-case reductions for linear spaces, raised by
[Rothblum, Vadhan, Wigderson, STOC 2013]. We first show a sharp quantitative
form of a theorem which says that if an affine space $U$ is $\delta$-far in
relative Hamming distance from a linear code $V$ - this is the worst-case
assumption - then most elements of $U$ are almost $\delta$-far from $V$ - this
is the average case. This leads to an optimal analysis of the soundness of the
FRI protocol of [Ben-Sasson, et.al., eprint 2018] for proving proximity to
Reed-Solomon codes.
</p>
<p>To further improve soundness, we sample outside the box. We suggest a new
protocol which asks a prover for values of a polynomial at points outside the
domain of evaluation of the Reed-Solomon code. We call this technique Domain
Extending for Eliminating Pretenders (DEEP).
</p>
<p>We use the DEEP technique to devise two new protocols: (1) An Interactive
Oracle Proof of Proximity (IOPP) for RS codes, called DEEP-FRI. This soundness
of the protocol improves upon that of the FRI protocol while retaining linear
arithmetic proving complexity and logarithmic verifier arithmetic complexity.
(2) An Interactive Oracle Proof (IOP) for the Algebraic Linking IOP (ALI)
protocol used to construct zero knowledge scalable transparent arguments of
knowledge (ZK-STARKs) in [Ben-Sasson et al., eprint 2018]. The new protocol,
called DEEP-ALI, improves soundness of this crucial step from a small constant
$&lt; 1/8$ to a constant arbitrarily close to $1$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.12243"><span class="datestr">at April 01, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/03/31/summer-school-on-randomness-and-learning-in-non-linear-algebra/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/03/31/summer-school-on-randomness-and-learning-in-non-linear-algebra/">Summer School on Randomness and Learning in Non-Linear Algebra</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
July 1-4, 2019 Leipzig, Germany https://www.mis.mpg.de/calendar/conferences/2019/ranlearn2019.html This summer school aims at bringing together researchers working on probabilistic and statistical methods and questions in nonlinear algebra. Keynote speakers will be: Peter Bürgisser (Technische Universität Berlin) Daniel Erman (University of Wisconsin-Madison) Antonio Lerario (Scuola Internazionale Superiore di Studi Avanzati)</div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/03/31/summer-school-on-randomness-and-learning-in-non-linear-algebra/"><span class="datestr">at March 31, 2019 08:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17274">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/03/31/is-it-legitimate-ethical-for-google-to-close-google/">Is it Legitimate/Ethical for Google to close Google+?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2019/03/google.png"><img src="https://gilkalai.files.wordpress.com/2019/03/google.png?w=640" alt="" class="alignnone size-full wp-image-17276" /></a></p>
<p> </p>
<p>Google Plus is a nice social platform with tens of millions participants. I found it especially nice for scientific posts, e.g. by <a href="https://plus.google.com/u/0/117663015413546257905">John Baez</a>, <a href="https://plus.google.com/u/0/104488217075635760621">Moshe Vardi</a>, or about <a href="https://plus.google.com/u/0/s/symplectic%20geometry/top">symplectic geometry, </a> about <a href="https://plus.google.com/u/0/s/majorana%20fermions/top">Majorana Fermions</a>, and with a discussion about <a href="https://plus.google.com/u/0/106808239073321070854/posts/cwzYpKXSACM">What is combinatorics</a>. A few months ago Google announced  that Google+ will be closed. This is going to happen today (March 31, 2019) in a few hours. For example, I am not even sure if the above valuable links will continue to operate. (Every individual user can get his own stuff.)</p>
<p>For possible answers on why Google shut down Google Plus see this <a href="https://www.quora.com/Why-is-Google+-closed">Quora question</a>.</p>
<p>My question is different. <span style="color: #0000ff;"><strong>Is it legitimate for Google to close Google+? Is it legitimate and is it ethical for Google to eliminate existing content from the public domain?</strong> </span></p>
<p> </p>
<p>(Related post: <a href="https://gilkalai.wordpress.com/2008/06/06/what-do-firms-want/">What do firms want</a> .)</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/03/31/is-it-legitimate-ethical-for-google-to-close-google/"><span class="datestr">at March 31, 2019 05:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/03/31/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/03/31/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://arxiv.org/abs/1903.04304">A 3-regular matchstick graph of girth 5 consisting of 54 vertices</a>, Mike Winkler, Peter Dinkelacker, and Stefan Vogel (<a href="https://mathstodon.xyz/@11011110/101761530841835018"></a>). The previous smallest-known graph with these properties had 180 vertices, but this one might still not be optimal, as the known lower bound is only 30. I found it difficult to understand the connectivity of the graph from <a href="https://commons.wikimedia.org/wiki/File:Winkler_3-reg_girth5_54.svg">its matchstick representation</a> so I made another drawing of the same graph in a different style:</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/girth-5-matchstick.svg" alt="The 54-vertex 3-regular girth-5 matchstick graph of Winkler, Dinkelacker, and Vogel in Lombardi drawing style" /></p>
  </li>
  <li>
    <p><a href="https://www.reddit.com/r/plexodus/comments/az285j/saving_of_public_google_content_at_the_internet/">Saving public Google+ content at the Internet Archive</a> (<a href="https://mathstodon.xyz/@11011110/101767934776473984"></a>, <a href="https://news.ycombinator.com/item?id=19407865">via</a>). Archive.org and the <a href="https://www.archiveteam.org/">Archive Team</a> (a separate “loose collective of rogue archivists, programmers, writers and loudmouths dedicated to saving our digital heritage”) are undertaking an organized effort to capture it all before Google takes it down at the end of the month.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@shonk/101807604452877379">Symmetric minimality</a>, Clayton Shonkwiler. An animation of a symmetric minimal-length grid realization of a trefoil knot, posted after I complained that <a href="https://mathstodon.xyz/@shonk/101768569662399661">his earlier animation</a> was too asymmetric, and suggested using the realization below (drawn using  <a href="http://vzome.com/home/">vZome</a>). Clayton also posted a <a href="https://mathstodon.xyz/@shonk/101819922406308000">bcc figure-8</a> and <a href="https://mathstodon.xyz/@shonk/101825678378019686">bcc </a>. Not every symmetric knot has a symmetric lattice realization (e.g. the  lattice knot doesn’t) but it may be an interesting question whether every lattice-realizable symmetry of a knot can be realized by a minimal lattice knot.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/zomeknot.png" alt="Symmetric lattice trefoil knot drawn using vZome" /></p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Karen_Uhlenbeck">Karen Uhlenbeck</a> becomes <a href="http://www.abelprize.no/c73996/seksjon/vis.html?tid=74011&amp;strukt_tid=73996">the first woman to win the Abel Prize</a> (<a href="https://mathstodon.xyz/@JordiGH/101778053801507834"></a>).</p>
  </li>
  <li>
    <p><a href="http://corner.mimuw.edu.pl/?p=1073">The curse of the Euclidean metric</a> (<a href="https://mathstodon.xyz/@11011110/101785024820380513"></a>). Krzysztof Fleszar posts about a big difficulty with algorithms for problems like Euclidean shortest paths where the answer is a sum of distances: we don’t know how to compare two solutions efficiently. Fortunately in the case of <a href="https://epubs.siam.org/doi/10.1137/1.9781611975482.67">Krzysztof’s SODA 2019 paper on approximate TSP of hyperplanes</a> (find a short tour that touches each given hyperplane) it’s possible to use approximate numerical comparisons.</p>
  </li>
  <li>
    <p><a href="https://hal.archives-ouvertes.fr/hal-02070778/document">Integer multiplication in time </a> (<a href="https://mathstodon.xyz/@erou/101787744661719386"></a>, <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">see also</a>).</p>
  </li>
  <li>
    <p><a href="https://www.latimes.com/entertainment/arts/la-ca-cm-inksap-linda-lack-20190314-story.html">An odd couple of Los Angeles street art</a> (<a href="https://mathstodon.xyz/@11011110/101794533654899105"></a>): 20-something Inksap, a son of Vietnamese refugees, and 70-something dance teacher Linda Lack.</p>
  </li>
  <li>
    <p><a href="https://archive.org/stream/BrainfillingCurves-AFractalBestiary/BrainFilling">Brain-filling curves: A fractal bestiary</a> (<a href="https://mathstodon.xyz/@11011110/101801960587162487"></a>). A 200-page compendium by Jeffrey Ventrella of space-filling curves, generated by subdivision rules that expand line segments to lattice paths whose sum of squared edge lengths equals the square of the segment.</p>
  </li>
  <li>
    <p><a href="http://www.graphics.rwth-aachen.de/software/zometool">Automatically translate any 3d model into a zometool approximation of it</a> (<a href="https://mathstodon.xyz/@11011110/101807397098535057"></a>, <a href="http://www.zometool.com/news/amazing-app-zometool-shape-approximation/">via</a>). With obligatory Stanford bunny. See also their <a href="https://www.youtube.com/watch?v=piDPsHTLV1A">1-minute video introduction</a>.</p>
  </li>
  <li>
    <p><a href="https://arstechnica.com/science/2019/03/physicists-are-decoding-math-y-secrets-of-knitting-to-make-bespoke-materials/">Physicists are decoding math-y secrets of knitting to make bespoke materials</a> (<a href="https://mathstodon.xyz/@11011110/101813393444829450"></a>). Jennifer Ouelette writes on <em>Ars Technica</em> that by varying the stitching one can control both the stretchiness and shape of the resulting knit.</p>
  </li>
  <li>
    <p><a href="https://mathml.igalia.com/news/2019/02/12/launch-of-the-project/">The MathML people are trying again</a> (<a href="https://mathstodon.xyz/@11011110/101820557668090856"></a>, <a href="https://news.ycombinator.com/item?id=19344843">via</a>). Much as I think MathML has failed and that promotion by its proponents after its failure was already obvious directly caused the continued bad mathematics rendering on Wikipedia, I wish them well. A working web mathematics markup language (if it can be achieved) would be a step up from Javascripted LaTeX. Of course I’m not about to give up LaTeX in my source but that’s what markup processors are for.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@ccppurcell/101822142519831628">Chris Purcell asks “who is the mathematician/scientist who has the most Wikipedia citations without having a Wikipedia page?”</a>. <a href="https://mathstodon.xyz/@11011110/101822690106826262">My guess</a> is Heidi Burgiel, co-author of frequently-cited book <em>The Symmetries of Things</em>.</p>
  </li>
  <li>
    <p><a href="https://jmfork.github.io/2048/">Deterministic 2048</a> (<a href="https://mathstodon.xyz/@11011110/101830138376282978"></a>). The next tile is always a 2 at the first available square. It should be possible to describe a strategy that applies to any  board and that provably achieves a score of  but apparently this is not known.</p>
  </li>
  <li>
    <p><a href="https://adamsheffer.wordpress.com/2019/03/11/incidences-open-problem-part-1/">Adam Sheffer points out that, despite recent advances in incidence geometry, many problems remain open, and sets out on a project to catalog them</a> (<a href="https://mathstodon.xyz/@11011110/101837928344081808"></a>). His starting points are the unit distances problem and incidences with nonlinear algebraic plane curves.</p>
  </li>
  <li>
    <p><a href="https://gizmodo.com/rss-is-better-than-twitter-1833624929">Why you should be keeping up with news and long-form websites using RSS rather than twitter</a> (<a href="https://mathstodon.xyz/@11011110/101840580734668234"></a>, <a href="https://news.ycombinator.com/item?id=19529442">via</a>). If you want to incorporate RSS feeds into your Mastodon stream, <a href="https://friend.camp/@darius/100897757870017125">Darius Kazemi’s RSS-to-Mastodon tool</a> looks useful, but I haven’t tried it, because so far I’m happy reading those feeds through NetNewsWire.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/news/2019/03/28/scholars-complain-visa-problems-ahead-international-conference-canada">International Studies Association participants unable to get visas to go to their conference in Toronto</a> (<a href="https://mathstodon.xyz/@11011110/101847752696450725"></a>), a repeat of an issue I posted about for <a href="https://11011110.github.io/blog/2019/01/31/linkage.html">NeurIPS in January</a>. According to the story, the proportion of participants with visa issues is similar to recent years when the conference has been in the US. Which is not a great target for Canada to aspire to…</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/03/31/linkage.html"><span class="datestr">at March 31, 2019 04:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7489">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/03/30/physics-computation-blog-post-round-up/">Physics &amp; Computation Blog Post Round-up</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In the Fall, Boaz and I co-taught a <a href="https://www.boazbarak.org/fall18seminar/">grad seminar</a> on physics and computation (see <a href="https://windowsontheory.org/2018/08/06/physics-envy/">here</a> for some of the original press coverage). We were lucky to attract an intrepid group of students from multiple fields, with representatives from computer science, physics, math and biology. As part of the course, we asked our students to give presentations and write expository blog posts on a number of topics at the intersection of computation and physics, including algorithms from statistical physics, quantum area laws, and the firewall paradox. The students worked hard to produce posts that make the physics concepts accessible to a computer science audience, and the result is a nice collection of posts that create a “bridge” from CS to physics.</p>
<p>Here, the aim is to give a (long overdue) table of contents for their posts. Followers of the blog may have noticed a landslide of physics &amp; computation posts around December and January; if you weren’t able to keep up with them all at the time, then here they are, rounded up and organized by topic.</p>
<h2>Statistical Physics</h2>
<h4>Background and intro to phase transitions:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/09/15/statistical-physics-an-introduction-in-two-parts/">Statistical Physics: an introduction in two parts</a> (by Tselil Schramm)</li>
</ul>
<h4>Algorithms from statistical physics: belief propagation and approximate message passing:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/10/20/belief-propagation-and-the-stochastic-block-model/">Belief Propagation and the Stochastic Block Model</a> (by Thomas Orton)</li>
<li><a href="https://windowsontheory.org/2019/01/26/introduction-to-amp-and-the-replica-trick/">Introduction to AMP and the Replica Trick</a> (by Preetum Nakkiran and <span class="qu"><span class="gD">Yueqi </span></span><span class="qu"><span class="gD">Sheng)</span></span></li>
</ul>
<h4>Informational and computational phase transitions:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/12/16/algorithmic-and-information-theoretic-decoding-thresholds-for-low-density-parity-check-code/">Algorithmic and Information Theoretic Decoding Thresholds for Low density Parity-Check Code</a> (by Jeremy Dohmann, Vanessa Wong, and Venkat Arun)</li>
</ul>
<h4>Proving the existence of phase transitions:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/12/13/ising-perceptron-under-gaussian-disorder-and-k-nae-sat/">Ising Perceptron under Gaussian Disorder, and k-NAE-SAT</a> (based on a guest lecture by <a href="https://www.stat.berkeley.edu/~nikesun/">Nike Sun</a>, as scribed by Patrick Guo, Vinh-Kha Le, Shyam Narayanan, and David Stoner)</li>
</ul>
<h4> Using convex relaxations to approximate partition functions:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/11/11/approximating-partition-functions/">Approximating Partition Functions</a> (based on a guest lecture by <a href="https://math.mit.edu/~risteski/">Andrej Risteski</a> as scribed by Alex Kelser, Alex Lin, Amil Merchant, and Suproteem Sarkar)</li>
</ul>
<h2>Quantum Computation</h2>
<h4>Background on Quantum Hamiltonians and tensor network representations:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/12/20/quantum-hamiltonian-complexity/">What is Quantum Hamiltonian Complexity?</a> (by Ben Edelman)</li>
<li><a href="https://windowsontheory.org/2018/12/20/tensor-networks-matrix-product-states-dmrg/">Tensor Networks, Matrix Product States and Density Matrix Renormalization Group</a> (by Fred Zhang)</li>
</ul>
<h4>Area laws:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/12/18/a-1d-area-law-for-gapped-local-hamiltonians/">A 1D Area Law for Gapped Local Hamiltonians</a> (by Boriana Gjura and Prayaag Venkat)</li>
</ul>
<h4>Quantum algorithms:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/12/23/introduction-to-quantum-walks/">Introduction to Quantum Walks</a> (by Beatrice Nash)</li>
<li><a href="https://windowsontheory.org/2018/12/20/efficient-preparation-of-thermal-states-of-quantum-systems-natural-or-artificial/">Efficient preparation of thermal states of quantum systems: natural or artificial</a> (based on a guest lecture by <a href="http://web.mit.edu/aram/www/">Aram Harrow</a> as scribed by Sinho Chewi, William S. Moses, Tasha Schoenstein, Ary Swaminathan)</li>
<li><a href="https://windowsontheory.org/2018/12/22/quantum-approximate-optimization-algorithm-and-applications/">Quantum Approximate Optimization Algorithm and Applications</a> (by
<div class="b4">
<div class="dl">
<div class="aIj">
<div class="c5 J-J5-Ji">Amir Karamlou)</div>
</div>
</div>
</div>
<div class="dp"></div>
</li>
</ul>
<h4>Quantum games and quantum PCPs:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/12/22/towards-quantum-pcp-a-proof-of-the-nlets-theorem/">Towards Quantum PCP: A Proof of the NLETS Theorem</a> (by Abhijit Mudigonda, Richard Wang, and Lisa Yang)</li>
<li><a href="https://windowsontheory.org/2019/01/03/quantum-games/">Quantum Games</a> (by Nilin Abrahamsen, Daniel Alabi, Mitali Bafna, Emil Khabiboulline, and Juspreet Sandhu)</li>
</ul>
<h4>Quantum supremacy:</h4>
<ul>
<li><a href="https://windowsontheory.org/2019/01/25/quantum-circuits-and-their-role-in-demonstrating-quantum-supremacy/">Quantum circuits and their role in demonstrating quantum supremacy</a> (by Hikari Sorensen)</li>
</ul>
<h4>Quantum error correction:</h4>
<ul>
<li><a href="https://windowsontheory.org/2018/12/07/quantum-error-correction/">Peter Shor on Quantum Error Correction</a> (based on a guest lecture by Peter Shor as scribed by Annie Wei)</li>
</ul>
<h2>Black Holes and the Firewall Paradox</h2>
<p>(See also Boaz’s <a href="https://windowsontheory.org/2018/08/22/black-holes-paradoxes-and-computational-complexity/">introductory post</a>)</p>
<h4>Background on black holes and the Firewall Paradox:</h4>
<ul>
<li><a href="https://windowsontheory.org/2019/01/20/the-firewall-paradox-in-context/">Why physicists care about the Firewall Paradox</a> (by Noah Miller)</li>
<li><a href="https://windowsontheory.org/2019/01/30/black-hole-paradoxes-a-conservative-yet-radical-journey/">Black hole paradoxes: A conservative yet radical journey</a> (by Abhishek Anand and Noah Miller)</li>
</ul>
<h4>Firewall Paradox meets Computational Complexity:</h4>
<ul>
<li><a href="https://windowsontheory.org/2019/02/01/black-holes-a-complexity-theory-perspective/">Black Holes, a complexity theory perspective</a> (by Chi-Ning Chou and Parth Mehta)</li>
</ul></div>







<p class="date">
by tselilschramm <a href="https://windowsontheory.org/2019/03/30/physics-computation-blog-post-round-up/"><span class="datestr">at March 30, 2019 08:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15708">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">Integer Multiplication in NlogN Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>A win for multi-variable polynomials</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/harveyvanderhoeven2/" rel="attachment wp-att-15709"><img src="https://rjlipton.files.wordpress.com/2019/03/harveyvanderhoeven2.png?w=201&amp;h=150" alt="" width="201" class="alignright wp-image-15709" height="150" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop from <a href="https://web.maths.unsw.edu.au/~davidharvey/">src1</a>, <a href="https://www.polytechnique.edu/en/content/researchers-lx-international-congress-mathematicians-brazil">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
David Harvey and Joris van der Hoeven are computational mathematicians. They have just released a <a href="https://web.maths.unsw.edu.au/~davidharvey/papers/nlogn/">paper</a> showing how to multiply two <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit integers in <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\log n)}" class="latex" title="{O(n\log n)}" /> time. A companion <a href="http://www.texmacs.org/joris/ffnlogn/ffnlogn-abs.html">paper</a> gives details of a simpler second algorithm that is <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\log n)}" class="latex" title="{O(n\log n)}" /> time pending a widely-believed conjecture about primes.</p>
<p>
Today we discuss what makes these new results possible.</p>
<p>
The first paper leads off with a nice history of algorithms that beat the <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n^2)}" class="latex" title="{O(n^2)}" />-time method all of us learned in school. Far from being <a href="https://rjlipton.wordpress.com/2010/10/23/galactic-algorithms/">galactic</a>, the longtime-champion <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n+%5Clog%5C%21%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\log n \log\!\log n)}" class="latex" title="{O(n\log n \log\!\log n)}" /> algorithm of Arnold Schönhage and Volker Strassen is a workhorse of the GNU Multiple Precision Library (<a href="https://en.wikipedia.org/wiki/GNU_Multiple_Precision_Arithmetic_Library">GMP</a>). The <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5C%21%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log\!\log n}" class="latex" title="{\log\!\log n}" /> factor was <a href="http://en.wikipedia.org/wiki/Furer's_algorithm">improved</a> by Martin Fürer in 2007 and <a href="https://arxiv.org/abs/1407.3360?context=cs">further</a> in 2014 by Harvey and van der Hoeven with Grégoire Lecerf. Now it is gone altogether.</p>
<p>
Their algorithm is currently not practical, but it is also not yet tuned. At the start of section 5, they note that their estimates take effect for <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+2%5E%7Bd%5E%7B12%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \geq 2^{d^{12}}}" class="latex" title="{n \geq 2^{d^{12}}}" /> where they use <img src="https://s0.wp.com/latex.php?latex=%7Bd+%3D+1%2C%5C%21729%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d = 1,\!729}" class="latex" title="{d = 1,\!729}" />. When they note that <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bd%5E%7B12%7D%7D+%3E+2%5E%7B4%2C%5C%21096%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{d^{12}} &gt; 2^{4,\!096}}" class="latex" title="{2^{d^{12}} &gt; 2^{4,\!096}}" /> they don’t mean the numbers need at least <img src="https://s0.wp.com/latex.php?latex=%7B4%2C%5C%21096%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4,\!096}" class="latex" title="{4,\!096}" /> bits, rather <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B4%2C%5C%21096%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{4,\!096}}" class="latex" title="{2^{4,\!096}}" /> is the number of bits. Since there are only <a href="https://www.popularmechanics.com/space/a27259/how-many-particles-are-in-the-entire-universe/">about</a> <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B270%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{270}}" class="latex" title="{2^{270}}" /> particles in the observable universe, this puts the term <a href="https://rjlipton.wordpress.com/2010/10/23/galactic-algorithms/">galactic</a> to shame. </p>
<p>
The number <img src="https://s0.wp.com/latex.php?latex=%7B1%2C%5C%21729%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1,\!729}" class="latex" title="{1,\!729}" /> recalls a famous <a href="http://mathworld.wolfram.com/Hardy-RamanujanNumber.html">story</a> about Godfrey Hardy and Srinivasa Ramanujan. This is not wholly a coincidence. They get a bounding multiplier of <img src="https://s0.wp.com/latex.php?latex=%7B36%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{36}" class="latex" title="{36}" /> from one place, another factor of <img src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{6}" class="latex" title="{6}" /> from another, and finally a factor of <img src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{8}" class="latex" title="{8}" /> giving <img src="https://s0.wp.com/latex.php?latex=%7B1%2C%5C%21728%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1,\!728}" class="latex" title="{1,\!728}" /> which equals <img src="https://s0.wp.com/latex.php?latex=%7B12%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{12^3}" class="latex" title="{12^3}" />. Then they just make <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> be higher by <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, setting up <img src="https://s0.wp.com/latex.php?latex=%7B1%2C%5C%21729+%3D+12%5E3+%2B+1%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1,\!729 = 12^3 + 1^3}" class="latex" title="{1,\!729 = 12^3 + 1^3}" /> which happens to equal <img src="https://s0.wp.com/latex.php?latex=%7B9%5E3+%2B+10%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{9^3 + 10^3}" class="latex" title="{9^3 + 10^3}" />. But there is much flex in the choices and they sketch how to improve the needed bound from <img src="https://s0.wp.com/latex.php?latex=%7B1%2C%5C%21728%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1,\!728}" class="latex" title="{1,\!728}" /> to just <img src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{8}" class="latex" title="{8}" />. They also uncover some new tricks for calculating in certain large finite rings defined via multi-variable polynomials.</p>
<p>
</p><p></p><h2> Polynomials and Tricks </h2><p></p>
<p></p><p>
When we heard the news on Tuesday, both of us thought of the famous primality <a href="https://en.wikipedia.org/wiki/AKS_primality_test">test</a> of Manindra Agrawal, Neeraj Kayal, and Nitin Saxena (AKS), which placed deciding primality into deterministic polynomial time. We stated the message as the title of an old <a href="https://rjlipton.wordpress.com/2011/02/26/polynomials-are-easier-than-integers/">post</a> on other joint work by Kayal: “Polynomials Are Easier Than Integers.” </p>
<p>
The crux of the AKS test is to employ the theorem that for any co-prime <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2CN%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,N)}" class="latex" title="{(a,N)}" />, the polynomial congruence relation </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x+%2B+a%29%5EN+%5Cequiv+x%5EN+%2B+a+%5Cpmod%7BN%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (x + a)^N \equiv x^N + a \pmod{N} " class="latex" title="\displaystyle  (x + a)^N \equiv x^N + a \pmod{N} " /></p>
<p>holds in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}[x]}" class="latex" title="{\mathbb{Z}[x]}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> is prime. This is tested in the quotient ring <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%2F%28x%5Er+-+1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}[x]/(x^r - 1)}" class="latex" title="{\mathbb{Z}[x]/(x^r - 1)}" />. The game becomes finding <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> small enough and minimizing the number of <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> that need to be checked in order for the body of tests in the quotient ring to be conclusive. </p>
<p>
We take time to note that the case <img src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+N-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a = N-1}" class="latex" title="{a = N-1}" /> is possibly sufficient while testing a small set of <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />. Agrawal has <a href="https://en.wikipedia.org/wiki/Agrawal's_conjecture">conjectured</a> that if <img src="https://s0.wp.com/latex.php?latex=%7B%28x+-+1%29%5EN+%5Cequiv+x%5EN+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(x - 1)^N \equiv x^N - 1}" class="latex" title="{(x - 1)^N \equiv x^N - 1}" /> modulo both <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Er+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^r - 1}" class="latex" title="{x^r - 1}" /> then either <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> is prime or <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> divides <img src="https://s0.wp.com/latex.php?latex=%7BN%5E2+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N^2 - 1}" class="latex" title="{N^2 - 1}" />. This conjecture is <a href="https://aimath.org/WWN/primesinp/primesinp.pdf">doubted</a> on heuristic counting grounds but it has been verified for <img src="https://s0.wp.com/latex.php?latex=%7BN+%3C+10%5E%7B12%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N &lt; 10^{12}}" class="latex" title="{N &lt; 10^{12}}" /> and can be <a href="https://eprint.iacr.org/2009/008.pdf">modified</a> by including the case <img src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a = 2}" class="latex" title="{a = 2}" />. It would improve the polynomial time in the number <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> of bits in <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> from <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E6%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{O}(n^6)}" class="latex" title="{\tilde{O}(n^6)}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{O}(n^3)}" class="latex" title="{\tilde{O}(n^3)}" /> and also improve the constants. We mention this because Harvey and van der Hoeven have a number-theoretic conjecture that (as shown in their companion paper) improves both their constant on <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\log n}" class="latex" title="{n\log n}" /> and the simplicity of the proof.</p>
<p>
The further message of the new papers is added power from giving the polynomials more variables. They use <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> variables: <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%2C%5Cdots%2Cx_%7Bd-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1,\dots,x_{d-1}}" class="latex" title="{x_1,\dots,x_{d-1}}" /> plus a nominal <img src="https://s0.wp.com/latex.php?latex=%7Bx_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_d}" class="latex" title="{x_d}" /> that is later substituted by <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Cpi+i%2Fr%7D+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{\pi i/r} y}" class="latex" title="{e^{\pi i/r} y}" />. Here <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> is a certain power of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> and combined with the <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-th variable <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> to build the base ring <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> of complex polynomials in <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> modulo <img src="https://s0.wp.com/latex.php?latex=%7By%5Er+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y^r + 1}" class="latex" title="{y^r + 1}" />. The other variables are used to mod out by <img src="https://s0.wp.com/latex.php?latex=%7B%28x_1%5E%7Bt_1%7D+-+1%2C%5Cdots%2Cx_%7Bd-1%7D%5E%7Bt_%7Bd-1%7D%7D+-+1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(x_1^{t_1} - 1,\dots,x_{d-1}^{t_{d-1}} - 1)}" class="latex" title="{(x_1^{t_1} - 1,\dots,x_{d-1}^{t_{d-1}} - 1)}" /> where the <img src="https://s0.wp.com/latex.php?latex=%7Bt_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_i}" class="latex" title="{t_i}" /> are powers of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> no higher than <img src="https://s0.wp.com/latex.php?latex=%7B2r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2r}" class="latex" title="{2r}" />. Operations in quotient rings of this type are especially efficient. They are used to emulate operations in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%2F%28x%5Es+-+1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}[x]/(x^s - 1)}" class="latex" title="{\mathbb{Z}[x]/(x^s - 1)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> is a product of primes <img src="https://s0.wp.com/latex.php?latex=%7Bs_1%5Ccdots+s_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_1\cdots s_d}" class="latex" title="{s_1\cdots s_d}" /> that are near powers of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />. The emulation is done via the isomorphism</p>
<p>
<a name="CRT"></a></p><a name="CRT">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbb%7BZ%7D%5Bx%5D%2F%28x%5E%7Bs_1%5Ccdots+s_d%7D+-+1%29+%5Ccong+%5Cmathbb%7BZ%7D%5Bx_1%2C%5Cdots%2Cx_d%5D%2F%28x_1%5E%7Bs_1%7D+-+1%2C%5Cdots%2Cx_d%5E%7Bs_d%7D+-+1%29%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathbb{Z}[x]/(x^{s_1\cdots s_d} - 1) \cong \mathbb{Z}[x_1,\dots,x_d]/(x_1^{s_1} - 1,\dots,x_d^{s_d} - 1), \ \ \ \ \ (1)" class="latex" title="\displaystyle  \mathbb{Z}[x]/(x^{s_1\cdots s_d} - 1) \cong \mathbb{Z}[x_1,\dots,x_d]/(x_1^{s_1} - 1,\dots,x_d^{s_d} - 1), \ \ \ \ \ (1)" /></p>
</a><p><a name="CRT"></a> which follows from the Chinese remainder theorem. </p>
<p>
They start with Schönhage and Strassen’s original trick of splitting the two <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit integers into <img src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Theta(\log n)}" class="latex" title="{\Theta(\log n)}" />-sized pieces so that the problem reduces to multiplying polynomials of degree <img src="https://s0.wp.com/latex.php?latex=%7B%5CTheta%28n%2F%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Theta(n/\log n)}" class="latex" title="{\Theta(n/\log n)}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}[x]}" class="latex" title="{\mathbb{Z}[x]}" /> with coefficients of <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" /> size. They use the <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-dimensional Discrete Fourier Transform over <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{C}}" class="latex" title="{\mathbb{C}}" /> with complex operations that need only <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" /> bits of precision individually. This setting also gives leeway for approximative methods in their final algorithm. But first we describe what was evidently their original strategy.</p>
<p>
</p><p></p><h2> The Recursive Strategy </h2><p></p>
<p></p><p>
Their first task in either case is to find <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-many distinct primes <img src="https://s0.wp.com/latex.php?latex=%7Bs_1%2C%5Cdots%2Cs_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_1,\dots,s_d}" class="latex" title="{s_1,\dots,s_d}" /> of order <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2F%5Clog+n%29%5E%7B1%2Fd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n/\log n)^{1/d}}" class="latex" title="{(n/\log n)^{1/d}}" /> in magnitude. Now when <img src="https://s0.wp.com/latex.php?latex=%7Bd+%3D+1%2C%5C%21729%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d = 1,\!729}" class="latex" title="{d = 1,\!729}" /> the exponent <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/d}" class="latex" title="{1/d}" /> makes the primes quite small indeed, and the need to find distinct ones already drives <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> up quite high before their algorithm can even go into effect. Moreover, for the approximation to work, the primes need to be congruent to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> modulo <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />. </p>
<p>
Their original strategy—detailed in the companion paper—builds on a <a href="https://ieeexplore.ieee.org/document/1448407">result</a> of Charles Rader to reduce the DFT computation to multiplications in </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbb%7BC%7D%5Bx_1%2C%5Cdots%2Cx_d%5D%2F%28x_1%5E%7Bs_1+-+1%7D+-+1%2C%5Cdots%2Cx_d%5E%7Bs_d+-+1%7D+-+1%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathbb{C}[x_1,\dots,x_d]/(x_1^{s_1 - 1} - 1,\dots,x_d^{s_d - 1} - 1), " class="latex" title="\displaystyle  \mathbb{C}[x_1,\dots,x_d]/(x_1^{s_1 - 1} - 1,\dots,x_d^{s_d - 1} - 1), " /></p>
<p>where compared to (<a href="https://rjlipton.wordpress.com/feed/#CRT">1</a>) they have reduced the exponents by one. Using <img src="https://s0.wp.com/latex.php?latex=%7Bs_i+%5Cequiv+1+%5Cpmod%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_i \equiv 1 \pmod{r}}" class="latex" title="{s_i \equiv 1 \pmod{r}}" />, they next reduce this to multiplications in </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbb%7BC%7D%5Bx_1%2C%5Cdots%2Cx_d%5D%2F%28x_1%5E%7Br%7D+-+1%2C%5Cdots%2Cx_d%5E%7Br%7D+-+1%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathbb{C}[x_1,\dots,x_d]/(x_1^{r} - 1,\dots,x_d^{r} - 1). " class="latex" title="\displaystyle  \mathbb{C}[x_1,\dots,x_d]/(x_1^{r} - 1,\dots,x_d^{r} - 1). " /></p>
<p>Then the above-mentioned substitution of <img src="https://s0.wp.com/latex.php?latex=%7Bx_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_d}" class="latex" title="{x_d}" /> by <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Cpi+i%2Fr%7D+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{\pi i/r} y}" class="latex" title="{e^{\pi i/r} y}" /> makes them into products over </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%5Bx_1%2C%5Cdots%2Cx_%7Bd-1%7D%5D%2F%28x_1%5E%7Bt_1%7D+-+1%2C%5Cdots%2Cx_%7Bd-1%7D%5E%7Bt_%7Bd-1%7D%7D+-+1%29+%5Cqquad%5Ctext%7Bwith%7D%5Cqquad+R+%3D+%5Cmathbb%7BC%7D%5By%5D%2F%28y%5Er+%2B+1%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  R[x_1,\dots,x_{d-1}]/(x_1^{t_1} - 1,\dots,x_{d-1}^{t_{d-1}} - 1) \qquad\text{with}\qquad R = \mathbb{C}[y]/(y^r + 1). " class="latex" title="\displaystyle  R[x_1,\dots,x_{d-1}]/(x_1^{t_1} - 1,\dots,x_{d-1}^{t_{d-1}} - 1) \qquad\text{with}\qquad R = \mathbb{C}[y]/(y^r + 1). " /></p>
<p>These last products are at last amenable to the usual Fast Fourier Transform trick of applying FFT for each <img src="https://s0.wp.com/latex.php?latex=%7Bt_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_i}" class="latex" title="{t_i}" /> by pretending that <img src="https://s0.wp.com/latex.php?latex=%7By%5E%7B2r%2Ft_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y^{2r/t_i}}" class="latex" title="{y^{2r/t_i}}" /> is a primitive <img src="https://s0.wp.com/latex.php?latex=%7Bt_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_i}" class="latex" title="{t_i}" />-th root of unity, multiplying pointwise in <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />, and doing the inverse FFT. Finally the products in <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> can be converted into <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" />-bit integer products, and this sets up the vast recursion from multiplying the original <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit integers to a batch of <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" />-bit ones. </p>
<p>
</p><p></p><h2> Finding Good Primes </h2><p></p>
<p></p><p>
In order for the recursion to solve to <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\log n)}" class="latex" title="{O(n\log n)}" />, they need the values <img src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+%28s_i+-+1%29%2Fr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i = (s_i - 1)/r}" class="latex" title="{q_i = (s_i - 1)/r}" /> to be not too large. Viewing this task from the bottom up, they want to choose a single value <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> and choose small <img src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i}" class="latex" title="{q_i}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bs_i+%3D+rq_i+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_i = rq_i + 1}" class="latex" title="{s_i = rq_i + 1}" /> is prime. Since <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> is a power of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />, there is some resemblance to the harder task of finding Sophie Germain primes, which are also relevant to the AKS algorithm. In this case, however, all they need is a sufficiently small <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0}" class="latex" title="{\epsilon &gt; 0}" /> such that:</p>
<blockquote><p><b> </b> <em> For all coprime <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Ck%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{a,k}" class="latex" title="{a,k}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> sufficiently large, there is a prime <img src="https://s0.wp.com/latex.php?latex=%7Bq+%3C+k%5E%7B1%2B%5Cepsilon%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{q &lt; k^{1+\epsilon}}" class="latex" title="{q &lt; k^{1+\epsilon}}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bq+%5Cequiv+a+%5Cpmod%7Bk%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{q \equiv a \pmod{k}}" class="latex" title="{q \equiv a \pmod{k}}" />. </em>
</p></blockquote>
<p></p><p>
This is, however, only known for “<img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />” <img src="https://s0.wp.com/latex.php?latex=%7B%3D+4.18%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{= 4.18}" class="latex" title="{= 4.18}" /> and the Generalized Riemann Hypothesis is only known to improve the bound to <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7B2%2B%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k^{2+\delta}}" class="latex" title="{k^{2+\delta}}" /> for any <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" />. The above is conjectured to hold for any <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0}" class="latex" title="{\epsilon &gt; 0}" /> but it hasn’t been proved. They currently need it for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+1%2F303%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon = 1/303}" class="latex" title="{\epsilon = 1/303}" />.</p>
<p>
The companion paper uses the conjecture to improve multiplication in the field <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BF%7D_%7Bp%5E%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{F}_{p^\ell}}" class="latex" title="{\mathbb{F}_{p^\ell}}" /> to time <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Cell+%5Clog%28p%29%28%5Clog%28n%29+%2B+%5Clog%28%5Cell%29+%2B+%5Clog%5C%21%5Clog%28p%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\ell \log(p)(\log(n) + \log(\ell) + \log\!\log(p))}" class="latex" title="{O(n\ell \log(p)(\log(n) + \log(\ell) + \log\!\log(p))}" />. This uses a single algorithm over any prime <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and power <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" />; of course if they are fixed, then this time likewise becomes <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\log n)}" class="latex" title="{O(n\log n)}" />. This currently needs <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+1%2F2%5E%7B1%2C%5C%21162%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon = 1/2^{1,\!162}}" class="latex" title="{\epsilon = 1/2^{1,\!162}}" />. </p>
<p>
The companion <a href="http://www.texmacs.org/joris/ffnlogn/ffnlogn-abs.html">paper</a> has full details of how all this works and many more numerical tricks than we’ve mentioned—a <em>tour de force</em>. Getting the result for integer multiplication unconditionally, however, requires one more major tool in their arsenal. To use it they set up the primes <img src="https://s0.wp.com/latex.php?latex=%7Bs_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_i}" class="latex" title="{s_i}" /> to be slightly below respective powers of 2 <img src="https://s0.wp.com/latex.php?latex=%7Bt_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_i}" class="latex" title="{t_i}" /> (rather than be above a single power of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> by the aforementioned factors <img src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i}" class="latex" title="{q_i}" />) while retaining <img src="https://s0.wp.com/latex.php?latex=%7Bt_1%5Ccdots+t_d+%3D+O%28s_1+%5Ccdots+s_d%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_1\cdots t_d = O(s_1 \cdots s_d)}" class="latex" title="{t_1\cdots t_d = O(s_1 \cdots s_d)}" />. </p>
<p>
Their innovation compared to the translations in the first strategy is that one can still reduce the DFT computation in dimensions <img src="https://s0.wp.com/latex.php?latex=%7Bs_1%2C%5Cdots%2Cs_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_1,\dots,s_d}" class="latex" title="{s_1,\dots,s_d}" /> needing <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" /> precision to a complex DFT in dimensions <img src="https://s0.wp.com/latex.php?latex=%7Bt_1%2C%5Cdots%2Ct_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_1,\dots,t_d}" class="latex" title="{t_1,\dots,t_d}" /> by employing approximation. Their algorithm is completely deterministic but it employs weights that conform to Gaussian distributions to effect the approximation. The preservation of Gaussians under Fourier transforms enables close enough approximations to be obtained by solving relatively small and easily-specified systems of linear equations. The resulting complex DFT is then massaged in a manner similar to the first strategy. The resulting recursion is not quite as steep—it goes from <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bn%27+%3D+n%5E%7B1%2Fd+%2B+o%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n' = n^{1/d + o(1)}}" class="latex" title="{n' = n^{1/d + o(1)}}" />—but it gives </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%28n%29+%3D+%5Cfrac%7BKn%7D%7Bn%27%7D+M%28n%27%29+%2B+O%28n%5Clog+n%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M(n) = \frac{Kn}{n'} M(n') + O(n\log n) " class="latex" title="\displaystyle  M(n) = \frac{Kn}{n'} M(n') + O(n\log n) " /></p>
<p>with <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> and the <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\log n)}" class="latex" title="{O(n\log n)}" /> term independent of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> (indeed, <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> becomes the aforementioned <img src="https://s0.wp.com/latex.php?latex=%7B1%2C%5C%21729%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1,\!729}" class="latex" title="{1,\!729}" />). This gives <img src="https://s0.wp.com/latex.php?latex=%7BM%28n%29+%3D+O%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(n) = O(n\log n)}" class="latex" title="{M(n) = O(n\log n)}" />. The approximation technique does not work for multiplication in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BF%7D_%7Bp%5E%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{F}_{p^\ell}}" class="latex" title="{\mathbb{F}_{p^\ell}}" />, however. As usual, here is where we say to consult the papers for further details—there is a wealth of them.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Will the <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n\log n)}" class="latex" title="{O(n\log n)}" /> time be concretely improvable? Will it tell us anything about the <a href="https://rjlipton.wordpress.com/2009/02/24/a-conjecture-of-hartmanis/">problem</a> of <a href="https://rjlipton.wordpress.com/2012/06/15/why-the-hartmanis-stearns-conjecture-is-still-open/">proving</a> a super-linear lower bound? And short of those two goals, what new results will become possible through the multi-variable polynomial techniques they employ?</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/"><span class="datestr">at March 29, 2019 01:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/045">TR19-045 |  On the Fine-grained Complexity of Least Weight Subsequence in Graphs | 

	Jiawei Gao</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Least Weight Subsequence (LWS) is a type of highly sequential optimization problems with form $F(j) = \min_{i &lt; j} [F(i) + c_{i,j}]$. They can be solved in quadratic time using dynamic programming, but it is not known whether these problems can be solved faster than $n^{2-o(1)}$ time. Surprisingly, each such problem is subquadratic time reducible to a highly parallel, non-dynamic programming problem [KPS17]. In other words, if a "static"  problem is faster than quadratic time, so is an LWS problem. For many instances of LWS, the sequential versions are equivalent to their static versions by subquadratic time reductions. The previous result applies to LWS on linear structures, and this paper extends this result to LWS on paths in sparse graphs. When the graph is a multitree (i.e. a DAG where any pair vertices can have at most one path) or when the graph is a DAG whose underlying undirected graph has constant treewidth, we show that LWS on this graph is still subquadratically reducible to their corresponding static problems. For many instances, the graph versions are still equivalent to their static versions.

Moreover, this paper shows that on these graphs, property testing of form $\exists x \exists y (\text{TC}_E(x,y) \wedge P(x,y))$ is subquadratically reducible to property testing of form $\exists x \exists y P(x,y)$, where $P$ is a property checkable in time linear to the sizes of $x$ and $y$, and $\text{TC}_E$ is the transitive closure of relation $E$. Furthermore, when $P$ is definable by a first-order logic formula with at most one quantified variable, then the above two problems are equivalent to each other by subquadratic reductions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/045"><span class="datestr">at March 28, 2019 08:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=345">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/03/28/tcs-talk-wednesday-april-3rd-richard-peng-georgia-tech/">TCS+ talk: Wednesday, April 3rd — Richard Peng, Georgia Tech</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, April 3rd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). <strong>Richard Peng</strong> from Georgia Tech will speak about “<em>Fully Dynamic Spectral Vertex Sparsifiers and Applications</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Problems arising from analyzing and understanding graph structures have motivated the development of many powerful tools for storing and compressing graphs and networks. Many, if not most, of these massive graphs are accumulations of updates over time. Maintaining updates and queries on dynamically changing graphs more efficiently than recomputing from scratch is a well-studied topic, with several important open problems related to global, optimization related queries.</p>
<p>We study dynamic graph algorithms for maintaining spectral vertex sparsifiers with respect to a subset of terminal vertices. Such sparsifiers preserve key structures in spectral algorithms, including effective resistances (which can be viewed as a numerical generalization of connectivity), solutions to systems of Laplacian linear equations, and energy of electrical flows between terminal vertices. We give data structures that maintain, in sublinear time, these sparsifiers under insertions/deletions of edges, as well as terminal additions.</p>
<p>This primitive in turn leads to sublinear time data structures for key primitives in spectral graph algorithms, including ones at the core of the “Laplacian paradigm” for designing graph optimization algorithms. In particular, we obtain <img src="https://s0.wp.com/latex.php?latex=O%28m%5E%7B4%2F3%7D%5Cepsilon%5E%7B-4%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(m^{4/3}\epsilon^{-4})" class="latex" title="O(m^{4/3}\epsilon^{-4})" /> time per query/update for effective resistances on unweighted graphs, and <img src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B11%2F12%7D%5Cepsilon%5E%7B-5%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(n^{11/12}\epsilon^{-5})" class="latex" title="O(n^{11/12}\epsilon^{-5})" /> time per query/update for implicit access to linear system solutions, where <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> is the relative approximation accuracy.</p>
<p>The majority of the talk will focus on key components of this data structure: (1) an interpretation of vertex sparsifiers as a sum of random walks, (2) a suitable choice of terminals to keep these walks local, and (3) maintenance of local walks and numerical solutions. Potential avenues in generalizing these techniques to provide new building blocks for dynamic graph algorithms will also be discussed.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/03/28/tcs-talk-wednesday-april-3rd-richard-peng-georgia-tech/"><span class="datestr">at March 28, 2019 05:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7487">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/03/28/nominate-tcs-papers-for-research-highlights/">Nominate TCS papers for research highlights</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>[Guest post by Aleksander Mądry]</em></p>



<p>To me, one of the best things about working in theoretical computer <br />science has always the exciting rate of progress we make as a community. <br />On (what appears to be) a regular basis, we produce breakthroughs on <br />problems that are absolutely fundamental to our field. Problems that <br />often look impossible to tackle, right up until someone actually tackles <br />them.</p>



<p>However, as inspiring as all these developments were to me, I also <br />always felt that we, as a community, could do more to properly recognize <br />and highlight them, both internally and to the outside world. This kind <br />of outreach would make it easier for us to capitalize on the <br />breakthroughs as well as to accelerate the impact of the underlying <br />ideas on the other areas of computer science, and beyond.</p>



<p>Fortunately, this is about to change!</p>



<p>One of the first decisions of our newly (re-)elected <a href="https://www.sigact.org/">SIGACT committee</a> was to create a committee (as committees are wont to do <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" alt="🙂" style="height: 1em;" class="wp-smiley" /> whose mission will be to help  promote top computer science theory research. This <strong>SIGACT Research Highlights Committee</strong> – consisting of <a href="https://www.boazbarak.org/">Boaz Barak</a>, <a href="https://omereingold.wordpress.com/">Omer Reingold</a>,  <a href="https://sites.google.com/site/marywootters/">Mary Wootters</a> and <a href="https://people.csail.mit.edu/madry/">myself</a> – will, in particular, work to identify results to be recommended for consideration for the <a href="http://cacm.acm.org/">CACM </a>Research Highlights section as well  as other general-audience research outlets in computer science and other  fields.</p>



<p>Of course, to do a proper job here we require your help! To this end, <br />the committee solicits two types of nominations:</p>



<p>1) Conference nominations. Each year, the committee will ask the PC <br />chairs of a broad set of theoretical computer science conferences to <br />send a selection of up to three top papers from these conferences <br />(selected based on both their technical merit and the potential <br />significant interest to non-theory audiences) and forwarding them to the <br />committee for consideration.</p>



<p>2) Community nominations. The committee will accept nominations from the  members of the community. Each such nomination should summarize the  contribution of the nominated (and recently published) paper and also <br />argue why this paper particularly merits a broader outreach. The <br />nomination should be no more than a page in length and can be submitted <br />at any time by emailing it to <a href="mailto:sigact.cacm.nominations@gmail.com" target="_blank" rel="noreferrer noopener">sigact.cacm.nominations@gmail.com</a>. <br />Self-nominations are discouraged.</p>



<p>To be considered in the upcoming round of our deliberations, we need to <br />receive your nomination by <strong>April 30</strong>.</p>



<p>Looking forward to learning about all the new exciting research that you <br />all are doing!

</p></div>







<p class="date">
by windowsontheory <a href="https://windowsontheory.org/2019/03/28/nominate-tcs-papers-for-research-highlights/"><span class="datestr">at March 28, 2019 03:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4213">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/03/28/and-now-for-something-completely-different/">And now for something completely different</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
 After 22 years in the United States, 19 of which spent in the San Francisco Bay Area, this Summer I will move to Milan to take a job at <a href="https://en.wikipedia.org/wiki/Bocconi_University">Bocconi University</a>.</p>
<p>
Like a certain well-known Bay Area institution, Bocconi is a private university that was endowed by a rich merchant in memory of his dead son. Initially characterized by an exclusive focus on law, economics and business, it has had for a while a high domestic recognition for the quality of teaching and, more recently, a good international profile both in teaching and research. Despite its small size, compared to Italy’s giant public universities, in 2017 Bocconi was the Italian university which had received the most ERC grants during the first ten years of existence of the European Research Council (in second place was my Alma Mater, the Sapienza University of Rome, which has about nine times more professors) <a href="https://milano.repubblica.it/cronaca/2017/03/07/news/in_bocconi_i_fuoriclasse_della_ricerca-159919972/">(source)</a>.</p>
<p>
About three years ago, Bocconi started planning for a move in the space of computing, in the context of their existing efforts in <a href="http://www.bidsa.unibocconi.eu/wps/wcm/connect/Site/Bidsa/Home">data science</a>. As a first step, they recruited <a href="https://sites.google.com/view/riccardozecchina/home">Riccardo Zecchina</a>. You may remember Riccardo from his work providing a non-rigorous calculation of the threshold of random 3-SAT, his work on the “survey propagation” algorithm for SAT and other constraint satisfaction problems, as well as other work that brought statistical physics techniques to computer science. Currently, Riccardo and his group are doing very exciting work on the theory of deep learning.</p>
<p>
Though I knew of his work, I had never met Riccardo until I attended a 2017 workshop at the Santa Fe Institute on <a href="https://www.santafe.edu/events/thermodynamics-and-computation-towards-new-synthes">“Thermodynamics and computation,”</a> an invitation that I had accepted on whim, mostly based on the fact that I had never been to New Mexico and I had really liked Breaking Bad. Riccardo had just moved to Bocconi, he told me about their future plans, and he asked me if I was interested. I initially politely declined, but one thing led to another, and now here I am putting up my San Francisco house for sale.</p>
<p>
Last August, as I was considering this move, I applied for an <a href="https://lucatrevisan.wordpress.com/2018/07/31/erc-vs-nsf/">ERC grant</a> from the European Union, and I just learned that the <a href="https://erc.europa.eu/news/erc-2018-advanced-grants-results">grant has been approved</a>. This grant is approximately the same amount as the total of all the grants that I have received from the NSF over the past twenty years, and it will support several postdoc positions, as well as visitors ranging from people coming for a week to give a talk and meet with my group to a full-year sabbatical visit.</p>
<p>
 Although it’s a bit late for that, I am looking for postdocs starting as early as this September: if you are interested please contact me. The postdoc positions will pay a highly competitive salary, which will be free of Italian income tax (<s>although American citizens will owe federal income tax to the IRS</s> correction: American citizens would not owe anything to IRS either). As a person from Rome, I am not allowed to say good things about Milan or else I will have to return my Roman card (it’s kind of a NY versus LA thing), but I think that the allure of the city speaks for itself.</p>
<p>
Likewise, if you are a senior researcher, and you have always wanted to visit me and work together on spectral methods, approximation algorithms, graph theory or graph algorithms, but you felt that Berkeley had insufficiently many Leonardo mural paintings and opera houses, and that it was too far from the Alps, then now you are in luck!</p>
<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/03/28/and-now-for-something-completely-different/"><span class="datestr">at March 28, 2019 12:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2959222585780083759">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/scooped.html">Scooped</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
At Dagstuhl I got a few ideas for future posts but then...<br />
<br />
We had some discussions about STOC allowing program committee members to submit papers that I planned to post about. But then Suresh wrote a <a href="http://blog.geomblog.org/2019/03/on-pc-submissions-at-soda-2020.html">fine post</a> on the same issue for SODA. My thoughts: PC members should not submit--no matter how you try to avoid the conflict of interest, there will always be a cloud on the process. Suresh suggest blind reviews that other non-theory conferences use, but I prefer the tiered PC system. It's fine to have PC members submit papers if the top of the tier, a senior PC or the PC chairs, makes the final calls.<br />
<br />
I was also going to post about Yann LeCun's <a href="https://www.facebook.com/story.php?story_fbid=10152719972317143&amp;id=722677142">Facebook rant</a> about stodgy CS departments but then Yann goes ahead and <a href="https://www.nytimes.com/2019/03/27/technology/turing-award-ai.html">wins a Turing award</a> with Geoffrey Hinton and Yoshua Bengio for their work on machine learning. I knew Yann from when we worked together at NEC Research in the early 2000's and let's just congratulate him and the others and let them bask in glory for truly transforming how we think of computing today. I'll get back to his post soon enough.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/scooped.html"><span class="datestr">at March 28, 2019 11:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/044">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/044">TR19-044 |  DEEP-FRI: Sampling Outside the Box Improves Soundness | 

	Eli Ben-Sasson, 

	Lior Goldberg, 

	Swastik Kopparty, 

	Shubhangi Saraf</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Motivated by the quest for scalable and succinct zero knowledge arguments, we revisit worst-case-to-average-case reductions for linear spaces, raised by [Rothblum, Vadhan, Wigderson, STOC 2013]. The previous state of the art by [Ben-Sasson, Kopparty, Saraf, CCC 2018] showed that if some member of an affine space $U$ is $\delta$-far in relative Hamming distance from a linear code $V$ — this is the worst-case assumption — then most elements of $U$ are almost-$\delta$-far from $V$ — this is the average case. However, this result was known to hold only below the “double Johnson” function of the relative distance $\delta_V$ of the code $V$ , i.e., only when $\delta &lt; 1 ? (1 ? \delta_V)^{1/4}$.
First, we increase the soundness-bound to the “one-and-a-half Johnson” function of $\delta_V$ and show that the average distance of $U$ from $V$ is nearly $\delta$ for any worst-case distance $\delta$ smaller than $1 ? (1 ? \delta_V)^{1/3}$. This bound is tight, which is somewhat surprising because the one-and-a-half Johnson function is unfamiliar in the literature on error correcting codes.
To improve soundness further for Reed Solomon codes we sample outside the box. We suggest a new protocol in which the verifier samples a single point $z$ outside the box $D$ on which codewords are evaluated, and asks the prover for the value at $z$ of the interpolating polynomial of a random element of $U$. Intuitively, the answer provided by the prover “forces” it to choose one codeword from a list of “pretenders” that are close to $U$. We call this technique Domain Extending for Eliminating Pretenders (DEEP).
The DEEP method improves the soundness of the worst-case-to-average-case reduction for RS codes up their list decoding radius. This radius is bounded from below by the Johnson bound, implying average distance is approximately $\delta$ for all $\delta &lt; 1 ? (1 ? \delta_V)^{1/2}$. Under a plausible conjecture about the list decoding radius of Reed-Solomon codes, average distance from $V$ is approximately $\delta$ for all $\delta$. The DEEP technique can be generalized to all linear codes, giving improved reductions for capacity-achieving list-decodable codes.
Finally, we use the DEEP technique to devise two new protocols:
• An Interactive Oracle Proof of Proximity (IOPP) for RS codes, called DEEP-FRI. This soundness of the protocol improves upon that of the FRI protocol of [Ben-Sasson et al., ICALP 2018] while retaining linear arithmetic proving complexity and logarithmic verifier arithmetic complexity.
• An Interactive Oracle Proof (IOP) for the Algebraic Linking IOP (ALI) protocol used to construct zero knowledge scalable transparent arguments of knowledge (ZK-STARKs) in [Ben-Sasson et al., eprint 2018]. The new protocol, called DEEP-ALI, improves soundness of this crucial step from a small constant $&lt; 1/8$ to a constant arbitrarily close to $1$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/044"><span class="datestr">at March 28, 2019 07:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4211">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/03/27/tested-by-time/">Tested by time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I was delighted (and not at all surprised) to hear that this year’s Turing Award will go to <a href="https://amturing.acm.org/">LeCun, Hinton, and Y. Bengio</a> for their work on deep learning.</p>
<p>Like public-key cryptography, deep learning was ahead of its time when first studied, but, thanks to the pioneering efforts of its founders, it was ready to be used when the technology caught up. </p>
<p>Mathematical developments take a long time to mature, so it is essential that applied mathematical research be done ahead of the time of its application, that is, at a time when it is basic research. Maybe quantum computing will be the next example to teach this lesson.</p>
<p>By the way, this summer the Simons Institute will host a <a href="https://simons.berkeley.edu/programs/dl2019">program on the foundations of deep learning</a>, co-organized by Samy Bengio, Aleks Madry, Elchanan Mossel and Matus Telgarsky.</p>
<p>Sometimes, it is not just the practical applications of a mathematical advance that take time to develop: the same can be true even for its <i>theoretical</i> applications! Which brings me to the next announcement of this post, namely that the call for nominations for the <a href="http://focs2019.cs.jhu.edu/tota/">FOCS test of time award</a> is out. Nominations are due in about four weeks.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/03/27/tested-by-time/"><span class="datestr">at March 27, 2019 08:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3381">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2019/03/27/call-for-papers-workshop-on-behavioral-economics-and-computation-at-ec-2019/">Call for Papers: Workshop on Behavioral Economics and Computation at EC 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<pre class="aLF-aPX-K0-aPE">-------------------------------------------------------------------------------------
Call for Papers:

Workshop on Behavioral Economics and Computation
<a href="https://sites.google.com/view/behavioralec/">https://sites.google.com/view/behavioralec/</a>
June 28, 2019, Phoenix, AZ
In conjunction with the 20th ACM Conference on Economics and Computation 
(ACM EC '19)

SUBMISSIONS DUE May 1, 2019, 11:59pm PDT.
-------------------------------------------------------------------------------------
We solicit research contributions and participants for The 1st
Workshop on Behavioral Economics and Computation, to be held in
conjunction with the 20th ACM Conference on Economics and Computation 
(ACM EC '19). The workshop will bring together researchers and
practitioners from diverse subareas of EC, who are interested in the 
intersection of human economic behavior and computation, to share new 
results and to discuss future directions for behavioral research 
related to economics and computation. It will be a full-day workshop, 
and will feature invited speakers, contributed paper presentations and 
a panel discussion.

The gap between rationality-based analysis that assumes utility-maximizing 
agents and the actual human behavior in the real world has been well 
recognized in economics, psychology and other social sciences. In recent 
years, there has been a growing interest in conducting behavioral research 
across many of the sub-areas related to economics and computation to 
address this gap. In one direction, some of these studies leverage insights 
on human decision making from behavioral economics and social psychology 
literature to study economic and computational systems with human users. 
In the other direction, computational tools are used to study and gain 
insights on human behavior and a data-driven approach is sometimes used to 
learn behavior models from user-generated data.

The Behavioral EC workshop aims to bring together researchers and 
practitioners from diverse fields, including but not limited to computer 
science, economics, psychology and sociology, to exchange ideas related to 
behavioral research in economics and computation. In addition to sharing new 
results, we hope the workshop will foster a lively discussion of future 
directions and methodologies for behavioral research related to economics 
and computation as well as fruitful cross-pollination of behavioral 
economics, cognitive psychology and computer science. 

We welcome studies at the intersection of economic behavior and computation 
from a rich set of theoretical, experimental and empirical perspectives. The 
topics of interest for the workshop are behavioral research in all settings 
covered by EC, including but not limited to:

Behavioral mechanism design and applied mechanism design
Empirical studies of economic behavior
Boundedly-rational models of economic decision making
Model evaluation and selection based on behavioral data
Online prediction markets, experiments, and crowdsourcing platforms
Hybrid human-machine systems
Models and experiments about social considerations (e.g. fairness) in 
decision making 
Methods for behavioral EC: information aggregation, probability elicitation, 
quality control


Submission Instructions
=======================

Submission deadline: May 1, 2019, 11:59pm PDT.

Notification: May 20, 2019

We will give priority to new (unpublished) research papers, but will 
also consider ongoing research and recently published papers that may 
be of interest to the workshop audience. For submissions of published 
papers, authors must clearly state the venue of publication. Papers 
will be reviewed for relevance, significance, originality, research 
contribution, and likelihood to catalyze discussion. The workshop will 
not have archival proceedings but will post accepted papers on the 
workshop website. Position papers and panel discussion proposals are also 
welcome. At least one author of each accepted paper will be expected 
to attend and present their findings at the workshop.

Submissions can be in any format and can be up to 18 pages long (plus 
a title page and excluding appendices that can be arbitrarily long). We 
recommend the format of the EC submissions. The limit of 18 pages on 
the main body is an upper bound, and papers can be significantly shorter. 

Submissions should be uploaded to the submission server no later 
than May 1, 2019, 11:59pm PDT.


Organizing Committee
====================
Yiling Chen, Harvard University
Dan Goldstein, Microsoft Research 
Kevin Leyton-Brown, University of British Columbia
Shengwu Li, Harvard University
Gali Noti, Hebrew University


More Information
================
For more information or questions, visit the workshop website:
<a href="https://sites.google.com/view/behavioralec/">https://sites.google.com/view/behavioralec/</a>
or email the organizing committee: <a href="mailto:behavioralec2019@easychair.org">behavioralec2019@easychair.org</a></pre></div>







<p class="date">
by Kevin Leyton-Brown <a href="https://agtb.wordpress.com/2019/03/27/call-for-papers-workshop-on-behavioral-economics-and-computation-at-ec-2019/"><span class="datestr">at March 27, 2019 01:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-6555947.post-3721224241252487082">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/suresh.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://feedproxy.google.com/~r/TheGeomblog/~3/PTrXNVY99dg/on-pc-submissions-at-soda-2020.html">On PC submissions at SODA 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
SODA 2020 (in SLC!!) is experimenting with a new submission guideline: PC members will be allowed to submit papers. I had a conversation about this with Shuchi Chawla (the PC chair) and she was kind enough (thanks Shuchi!) to share the guidelines she's provided to PC members about how this will work.<br /><br />  <br /><blockquote class="tr_bq"><span class="s1">SODA is allowing PC members (but not the PC chair) to submit papers this year. To preserve the integrity of the review process, we will handle PC member submissions as follows.</span> </blockquote><blockquote class="tr_bq"><span class="s1">1. PC members are required to declare a conflict for papers that overlap in content with their own submissions (in addition to other CoI situations). These will be treated as hard conflicts. If necessary, in particular if we don't have enough confidence in our evaluation of a paper, PC members will be asked to comment on papers they have a hard conflict with. However, they will not have a say in the final outcome for such papers. </span> </blockquote><blockquote class="tr_bq"><span class="s1">2. PC submissions will receive 4 reviews instead of just 3. This is so that we have more confidence on our evaluation and ultimate decision.</span> </blockquote><blockquote class="tr_bq"><span class="s1">3. We will make early accept/reject decisions on PC members submissions, that is, before we start considering "borderline" papers and worrying about the total number of papers accepted. This is because the later phases of discussion are when subjectivity and bias tend to creep in the most.</span> </blockquote><blockquote class="tr_bq"><span class="s1">4. In order to be accepted, PC member submissions must receive no ratings below "weak accept" and must receive at least two out of four ratings of "accept" or above.</span>  </blockquote><blockquote class="tr_bq">5. PC member submissions will not be eligible for the best paper award.</blockquote><br />My understanding is that this was done to solve the problem of not being able to get people to agree to be on the PC - this year's PC has substantially more members than prior years.<br /><br />And yet....<br /><br />Given all the discussion about conflicts of interest, implicit bias, and double blind review, this appears to be a bizarrely retrograde move, and in fact one that sends a very loud message that issues of implicit bias aren't really viewed as a problem. As one of my colleagues put it sarcastically when I described the new plan:<br /><br /><blockquote class="tr_bq">"why don't they just cut out the reviews and accept all PC submissions to start with?"</blockquote>and as another colleague pointed out:<br /><br /><blockquote class="tr_bq">"It's mostly ridiculous that they seem to be tying themselves in knots trying to figure out how to resolve COIs when there's a really easy solution that they're willfully ignoring..."</blockquote><br />Some of the arguments I've been hearing in support of this policy frankly make no sense to me.<br /><br />First of all, the idea that a more heightened scrutiny of PC papers can alleviate the bias associated with reviewing papers of your colleagues goes against basically all of what we know about implicit bias in reviewing. The most basic tenet of human judgement is that we are very bad at filtering our own biases and this only makes it worse. The one thing that theory conferences (compared to other venues) had going for them regarding issues of bias was that PC members couldn't submit papers, but now....<br /><br />Another claim I've heard is that the scale of SODA makes double blind review difficult. It's hard to hear this claim without bursting out into hysterical laughter (and from the reaction of the people I mentioned this to, I'm not the only one).  Conferences that manage with double blind review (and PC submissions btw) are at least an order of magnitude bigger (think of all the ML conferences). Most conference software (including easy chair) is capable of managing the conflicts of interest without too much trouble. Given that SODA (and theory conferences in general) are less familiar with this process, I’ve recommended in the past that there be a “workflow chair” whose job it is to manage the unfamiliarity associated with dealing the software. Workflow chairs are common at bigger conferences that typically deal with 1000s of reviewers and conflicts.<br /><br />Further, as a colleague points out, what one should really be doing is "aligning nomenclature and systems with other fields: call current PC as SPC or Area Chairs, or your favorite nomenclature, and add other folks as reviewers. This way you (i) get a list of all conflicts entered into the system, and (ii) recognize the work that the reviewers are doing more officially as labeling the PC members. "<br /><br /><br />Changes in format (and culture) take time, and I'm still hopeful that the SODA organizing team  will take a lesson from <a href="https://algo2019.ak.in.tum.de/index.php/menue-esa/esa-call">ESA 2019</a>  (and their own resolution to look at DB review more carefully that was passed a year or so ago) and consider exploring DB review. But this year's model is certainly not going to help.<br /><div><br /><b>Update: </b><a href="https://twitter.com/stevemblackburn/status/1111068299796705280?s=20">Steve Blackburn outlines how PLDI handles PC submissions</a> (in brief, double blind + external review committee)<br /><br /><b>Update: </b><a href="https://md.ekstrandom.net/blog/2019/03/anonymous-reviewing">Michael Ekstrand</a> takes on the question that Thomas Steinke asks in the comments below: "How is double blind review different from fairness-through-blindness?".<br /></div><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=PTrXNVY99dg:dU6PgEFG5Fg:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=yIl2AUoC8zA" border="0" /></a> <a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=PTrXNVY99dg:dU6PgEFG5Fg:63t7Ie-LG7Y"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=63t7Ie-LG7Y" border="0" /></a>
</div><img width="1" alt="" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/PTrXNVY99dg" height="1" /></div>







<p class="date">
by Suresh Venkatasubramanian (noreply@blogger.com) <a href="http://feedproxy.google.com/~r/TheGeomblog/~3/PTrXNVY99dg/on-pc-submissions-at-soda-2020.html"><span class="datestr">at March 26, 2019 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7484">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/03/26/news-addicts-sign-up-for-the-catcs-newsletter/">News addicts: Sign up for the CATCS newsletter</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>If, like others following <a href="https://xkcd.com/1227/">the pace of modern life</a>, you’re the kind of person that needs to get just on time updates on the state of theoretical computer science, consider signing up for the newsletter of CATCS.  You can get information about funding opportunities, advocacy efforts, and more. Sure, at the hectic rate of two messages per year, it might flood your inbox, but it is worth it.</p>



<p></p>



<p>Dear Theoretical Computer Scientist,</p>



<p><br />The <a href="https://thmatters.wordpress.com/catcs/">Committee for the Advancement of Theoretical Computer Science </a>(CATCS) was established by SIGACT to deal with funding, outreach, and advocacy issues for our community. If you would like to receive our newsletter (no more than twice annually) we encourage you to sign up for the Google group below:<br /><a href="https://groups.google.com/forum/#!forum/catcs-news" target="_blank" rel="noreferrer noopener">https://groups.google.com/forum/#!forum/catcs-news</a><br />(Navigate to the page above and click “Join group.” You can unsubscribe at any time from the same page.)<br />Best wishes, CATCS </p></div>







<p class="date">
by windowsontheory <a href="https://windowsontheory.org/2019/03/26/news-addicts-sign-up-for-the-catcs-newsletter/"><span class="datestr">at March 26, 2019 04:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/">postdoc at Bar Ilan University (apply by May 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In the our big data lab, we have several postdoctoral positions in Algorithms, Data Structures, Distributed, and Compress Sensing.</p>
<p>Website: <a href="http://www.cs.biu.ac.il/~porately/">http://www.cs.biu.ac.il/~porately/</a><br />
Email: porately@cs.biu.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/03/25/postdoc-at-bar-ilan-university-apply-by-may-1-2019/"><span class="datestr">at March 25, 2019 08:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2572656159267507055">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/random-thoughts-on-admissions-scandal.html">Random Thoughts on the admissions scandal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In light of the recent academic scandal I am going to list ways I've heard to help get your kid into college and thoughts on how ethical they are (hint: bribing a coach to claim your kid is on the rowing team is not ethical).<br />
<br />
1) Your kid likes (1) helping the homeless and (2)  Ramsey Theory and (3)  helping the homeless learn Ramsey Theory. Or perhaps they like  rowing or Latin or fencing or Pig Latin or....  Great! encourage them, get them books and tutors,  and whatever they need. You have an eye towards how this will look on for college admissions; however, it is your kids choice as to what they like. Also note that these activities are in addition to doing well in school, SATs, etc, not instead of it.  Perfectly ethical, though I note that this avenue is not open to poor families and in some cases even middle class families.<br />
<br />
2) Item 1 is the extreme on a spectrum in terms of how much are the extra things the kid does there idea OR planned by you to GET INTO A GOOD COLLEGE. This item will be the other extreme, but realize there is a continuum (actually I doubt there are a continuum number of options here, but there are many in between. Maybe its omega + omega*.) You have heard that being on the <a href="https://en.wikipedia.org/wiki/Chess_boxing">chess boxing</a> teams is good on a college application so you TELL YOUR KID that they  likes both Chess AND Boxing and should be on the team. You also hear this about being on the fencing team and knowing <a href="https://en.wikipedia.org/wiki/Pig_Latin">pig latin</a>, so your kid can taunt their opponents like this:<br />
<br />
youah, aint-kay ence-fay orth-way eans-bay<br />
<br />
This might not be as bad as it sounds if the kid learns to like Chess-Boxing.  But it may be worse than it sounds if the kid rebels against all of this and becomes a crack whore.<br />
<br />
Is this ethical? It may be bad for the kid, but it may push him into things he ends up liking. One drawback: you've HEARD that being on the chess boxing team is good for college admissions, but is it true?<br />
<br />
And again, not open to some families.<br />
<br />
3) Item 2 (or even 1) but with an addition: Hire a college adviser to help you. Someone who knows (or claims to know) what colleges look for- Trombone, Latin, Chess-boxing, whatever. Still ethical but I again worry about the kids future rehab bills.<br />
<br />
4) Here is where it gets murky. The college adviser helps:<br />
<br />
a) Polish the kids essay (my parents, who are both in English, helped polish my essay to get into graduate school (I don't recall if there was one for ugrad). They told me to use lots of `ing' words so it sounds like I am actively doing things. They also helped me figure out when recursion-theoretic is hyphenated. I got into Harvard but not MIT, so make of that what you will.) Polishing, proofreading, that could be okay. But it can slip into b or c below.<br />
<br />
b) The adviser (or the parents) talk to the kids to find out what to write, but then writes it. Maybe the kid proofreads and polishes. Maybe not even. The adviser is  a ghostwriter. Clearly unethical but the line between helping-to-polish and adviser-wrote-it is again a continuum.<br />
<br />
c) Adviser writes it and it is completely fictional. I once heard a rumor that a particular sample of an essay to get into med school was used  by several  med school applicant. Gee,they can't all have gotten inspired by watching their grandfather in his pajamas die of cancer. This is awful of course, but I wonder- what if the student writes a fictional essay all by themselves! Some combination of how much the essay is true and how much help you got on it is unethical. But some might be okay. Is it bad to polish stories that are basically true to make them flow more easily?  Prob not. But there is a 2-dim continuum based on both accuracy and how much help the student got.<br />
<br />
As a side note- how much does the personal statement matter for admissions? I suspect that if an elite school gets LOTS of REALLY QUALIFIED applicants, the essay may be all that distinguishes them.So it can be important. I also wonder if people on admissions can tell if an essay is not written by the applicant. Or maybe if there is an interview that can help detect it.<br />
<br />
5) Parents give X amount of money to the college and the kid gets in. This is talked about a lot though I don't know how common it is for someone NOT qualified to GET IN based on money. College admissions has many factors so its not quite so clear cut what NOT qualified means. Even so, if seems odd that this is not in any way shape or form illegal. It IS transparent, so I guess thats a plus. The argument I've heard is that the money is used for scholarships to fund students who get in but can't afford to go. I do not know if this is true. And this one  is only available to the top Z %, not sure what Z is, but there are people who can do 1,2,3,4 who can't do 5. I would call this unethical though colleges don't seem to think so. Or they do but they do it anyway.<br />
<br />
6) Before I list the current scandal I want to list another issue: having a psychologist (or whoever it is who judges these things) say your kid is Learning Disabled so they get more time on the SATs. Perhaps bribing them, or perhaps its understood what you want.  Again, I do not know how common this is.  An alternative if you can't afford some of the above options, or done in conjunction with a lot of the above options.<br />
<br />
7) The current scandal. Obviously unethical. A few things I wonder about:<br />
<br />
a) One story was that they bribed someone to say their daughter was Learning Disabled and had to take the SAT (or whatever it was) in a separate room, making it easier to change the answers to the correct ones.  So twice unethical.<br />
<br />
b) Some of the students  were clearly NOT qualified.<br />
<br />
c) A parent does unethical things to get the kid into college.<br />
<br />
The kid later lies to the parents about their grades or their plans<br />
<br />
The parents are SHOCKED that their kids lie and wonder where the learned such behaviour!<br />
<br />
8) Actually Item 2 --Parent has kid do things to plan to get into college-- is interesting for another reason. Are you your resume?<br />
<br />
Imagine that Alice helps the homeless her Sophmore year in High School NOT because she cares about the homeless but because its good for college admissions.<br />
<br />
Alice goes on to do other things that look good for college, NOT because she likes them or cares, but just to get into a good college.<br />
<br />
She gets into an elite college<br />
<br />
Did they take her in the hope she would KEEP doing these things or because she is the KIND OF PERSON who does these things?<br />
<br />
And it gets weirder- she DOES keep doing these things since she's heard its good for Business School (disclaimer- I do not know if its good for B-school)<br />
<br />
More generally, she keeps doing things she doesn't care about to advance. So her outward self really is doing good deeds and such, but her heart is not in it. So if her college or B-school or Job hired her because she DOES these things, that is NOT a lie. If they hired her because they want this KIND OF PERSON then... its a lie but I'm not sure what to make of that.<br />
<br />
9) Is there ANY reason to have legacy matter for admissions? This seems like the dumbest and most easily fixed aspect of the whole process.  I have never heard a good argument for it. Ever.<br />
<br />
10) College Sports--- that's an entire blog post or book all by itself, so I won't go there.<br />
<br />
11) One can argue whether helping the homeless, or being on the rowing team, or teaching the homeless how to row, should matter for college anyway. But lets assume that its legit to want people at your college who have lead interesting lives. So charity work or sports might be a MEASURE of that. But beware Goodhart's law:<br />
<br />
                         <i> When a measure becomes a target is ceases to be a measure.</i><br />
<i><br /></i>
The recent scandal is Goodhart's law on steroids.<br />
(NOTE- I had in earlier version `Goodwin's law' but a commenter corrected me and reminded me that Goodwin's law is that if an internet discussion goes on long enough someone will be compared to Hitler. I wonder if that also applies in discussions by Nazi's.)<br />
<br />
12) Does getting into an Elite College really increase your income or happiness (these are two very different questions) over the course of your life? I do not know-- if you do, please comment.<br />
<br />
13) (ADDED LATER) A commenter pointed out that one could also go to a school outside of  the USA that values proficiency in the chosen discipline over the items above. Excellent question that raises a few more:<br />
<br />
Do schools outside of the USA hold Americans (or for that matter any non-citizen of their country) to a higher standard for admissions? I ask non-rhetorically.<br />
<br />
If you get a degree from outside of the USA will that help or hurt your job prospects in the USA? Of course this depends on the school you goto, but even with that I do not know the answer.<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/random-thoughts-on-admissions-scandal.html"><span class="datestr">at March 24, 2019 09:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/043">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/043">TR19-043 |  Nondeterministic and Randomized Boolean Hierarchies in Communication Complexity | 

	Toniann Pitassi, 

	Morgan Shirley, 

	Thomas Watson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the Boolean Hierarchy in the context of two-party communication complexity, as well as the analogous hierarchy defined with one-sided error randomness instead of nondeterminism. Our results provide a complete picture of the relationships among complexity classes within and across these two hierarchies. In particular, we prove a query-to-communication lifting theorem for all levels of the Boolean Hierarchy and use it to resolve an open problem stated in the paper by Halstenberg and Reischuk (CCC 1988) which initiated this topic.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/043"><span class="datestr">at March 24, 2019 07:12 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17209">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/">Danny Nguyen and Igor Pak: Presburger Arithmetic Problem Solved!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h2>Short Presburger arithmetic is hard!</h2>
<p>This is a belated report on a remarkable breakthrough from 2017. The paper is <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">Short Presburger arithmetic is hard</a>, by Nguyen and Pak.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/03/ngoyen.jpg"><img src="https://gilkalai.files.wordpress.com/2019/03/ngoyen.jpg?w=640" alt="" class="alignnone size-full wp-image-17213" /></a></p>
<p><strong><span style="color: #ff0000;">Danny Nguyen</span></strong></p>
<h3>Integer programming in bounded dimension: Lenstra’s Theorem</h3>
<p>Algorithmic tasks are often intractable. But there are a few miracles where efficient algorithms exist: Solving systems of linear equations, linear programming, testing primality,  and solving integer programming problems when the number of variables is bounded. The last miracle is a historic 1983 theorem of Hendrik Lenstra (Here <a href="https://people.csail.mit.edu/rrw/presentations/Lenstra81.pdf">is the paper</a>) and it is the starting point of this post.</p>
<p><strong>Lensra’s theorem:</strong> Consider a system of linear inequalities</p>
<h3 style="text-align: center;"><em>Ax ≤ b</em></h3>
<p>where <img src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2Cx_2%2C%5Cdots+x_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=(x_1,x_2,\dots x_k)" class="latex" title="x=(x_1,x_2,\dots x_k)" /> is a vector of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> variables, <em>A</em> is an integral <em>k</em> by <em>n</em> matrix and <em>b</em> is an integral vector of length <em>n</em>.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> be a fixed integer. There is a polynomial time algorithm to determine if the system has an integral solution.</p>
<p>Of course, the full Integer Programming problem when <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is part of the input, is <strong>NP-complete</strong>. This problem came already (second in Karp’s list!) in<a href="https://people.eecs.berkeley.edu/~luca/cs172/karp.pdf"> the Mayflower of NP-complete problems –  Karp’s paper</a>.</p>
<p>Sasha Barvinok famously showed in 1993 that even counting the number of solutions is in <strong>P</strong>. (Barvinok utilized the short generating function approach pioneered by Brion, Vergne and others.)</p>
<h3>Kannan’s theorem</h3>
<p>Next,  I want to describe an amazing 1990 theorem of Ravi Kannan,</p>
<p>Kannan’s theorem considers formulas with one quantifier alternation in the Presburger arithmetic and it asserts that when the number of variables is fixed,  there is a polynomial time algorithm to decide if the formula is satisfiable.</p>
<p>(Here is a free version of <a href="http://www.cs.yale.edu/homes/kannan/Papers/forall.pdf">Kannan’s paper</a>.) Also here the counting problems were tackled with great success. Barvinok and Kevin Woods remarkably showed <a href="http://www.ams.org/journals/jams/2003-16-04/S0894-0347-03-00428-4/S0894-0347-03-00428-4.pdf">how to count projections of integer points in a (single) polytope in polynomial time</a>, and subsequently Woods <a href="http://www2.oberlin.edu/faculty/kwoods/research/Presburger_full.pdf">extended this approach</a> to general Presburger expressions Φ with a fixed number of inequalities!</p>
<p>An important strengthening was achieved by Friedrich Eisenbrand and  Gennady Shmonin in the 2008 paper <a href="https://arxiv.org/abs/0801.4336">Parametric integer programming in fixed dimension</a>. See also the survey chapter by Barvinok <a href="https://www.csun.edu/~ctoth/Handbook/chap7.pdf">Lattice points and lattice polytopes</a>.</p>
<p>You can find the formulation of Kannan’s theorem in full generality a little further but let me present now a special case related to the famous Frobenius coin problem. (See <a href="https://rjlipton.wordpress.com/2009/03/07/finite-state-automata-binary-decision-diagrams-and-presburger-arithmetic/">this post on GLL</a> for more on Presburger arithmetic)</p>
<h3>Frobenius coin problem</h3>
<p>Given <em>k</em> coins with integral values, the <a href="https://en.wikipedia.org/wiki/Coin_problem">Frobinius coin problem</a> is to determine the largest integer that cannot be described as positive integer combinations of the values of the coins. (See also <a href="https://rjlipton.wordpress.com/2011/04/30/congrats-ravi-kannan/">this post</a> on GLL.)</p>
<p><strong>Theorem (Kannan):</strong> There is a polynomial time algorithm to solve the Frobenius coin problem for every fixed number of coins.</p>
<p>The issue of the way theory meets practice for the problems discussed in this post is very interesting but we will not discuss it. Let me remark that Herb Scarf (who along with Kannan played a role in B-L (Before Lenstra) developments) offered another approach for the solution of the Frobenius coin problem and related IP (Integer Programming)  problems based on his theory of maximal lattice-free convex bodies. See <a href="https://gilkalai.wordpress.com/2013/02/22/ann-lehmans-sculpture-based-on-herb-scarfs-maximal-lattice-free-convex-bodies/">this related post</a>.</p>
<h3>More than one quantifier</h3>
<p>Given the result of Kannan and later that of Barvinok and Woods, many people expected that also for two alternations, or even for any other fixed number of alternations, Presburger arithmetic would be in polynomial time. Nguyen and Pak proved that the problem is <strong>NP-complete</strong> already for two quantifier alternations! Here is the link to the paper <a href="http://www.math.ucla.edu/~pak/papers/hard_presburger3.pdf">Short Presburger arithmetic is hard</a>. Igor Pak’s homepage has a few other <a href="http://www.math.ucla.edu/~pak/papers/research.htm#ip">related papers</a>.</p>
<p>Let me bring here Sasha Barvinok’s <a href="http://www.math.ucla.edu/~pak/papers/PA-Barv-rev.pdf">MathSciNet featured review</a> of Nguyen and Pak’s paper which tells the story better than I could.</p>
<h2>Barvinok’s featured review to Nguyen and Pak’s paper</h2>
<p>Presburger arithmetic allows integer variables, integer constants, Boolean operations (&amp;, ∧, ¬), quantifiers (∃, ∀), equations and inequalities (=, &lt;, &gt;, ≤, ≥), addition and subtraction (+, −) and multiplication by integer constants. It does not allow multiplication of variables (if we allow multiplication of variables, we get Peano arithmetic).</p>
<p>Geometrically, a quantifier-free formula of Presburger arithmetic describes the set of integer points in a Boolean combination of rational polyhedra (that is, in the set obtained from finitely many rational polyhedra by taking unions, intersections and complements). Similarly, a formula of Presburger arithmetic with existential quantifiers only describes the set of integer points obtained from the set of integer points in a Boolean combination of polyhedra by a projection along some coordinates.</p>
<p>Unlike Peano arithmetic, Presburger arithmetic is decidable. Here the authors zoom in on the computational complexity of Presburger arithmetic, once the combinatorial complexity of the formula is bounded in advance. If we fix the number of variables, the validity of a formula with no quantifier alternations (that is, of the type ∃<img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /> . . . ∃<img src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_k" class="latex" title="x_k" />Φ(<img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+latex+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \dots , latex x_k" class="latex" title="x_1, \dots , latex x_k" />) or of the type ∀<img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /> . . . ∀<img src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_k" class="latex" title="x_k" />Φ(<img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \dots , x_k" class="latex" title="x_1, \dots , x_k" />)) can be established in polynomial time by Lenstra’s integer programming algorithm [see H. W. Lenstra Jr., Math. Oper. Res. 8 (1983), no. 4, 538–548; MR0727410].</p>
<p>For a fixed number of variables, formulas with one quantifier alternation (∃<img src="https://s0.wp.com/latex.php?latex=x_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1" class="latex" title="x_1" /> . . . ∃<img src="https://s0.wp.com/latex.php?latex=x_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_k" class="latex" title="x_k" />∀<img src="https://s0.wp.com/latex.php?latex=y_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_1" class="latex" title="y_1" /> . . . ∀<img src="https://s0.wp.com/latex.php?latex=y_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_m" class="latex" title="y_m" />Φ(<img src="https://s0.wp.com/latex.php?latex=x_1%2C+%5Cdots+%2C+x_k%2C+y_1%2C+%5Cdots+%2C+y_m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_1, \dots , x_k, y_1, \dots , y_m" class="latex" title="x_1, \dots , x_k, y_1, \dots , y_m" />)) can also be solved in polynomial time, as shown by R. Kannan [in Polyhedral combinatorics (Morristown, NJ, 1989), 39–47, DIMACS Ser. Discrete Math. Theoret. Comput. Sci., 1, Amer. Math. Soc., Providence, RI, 1990; MR1105115]. The decision procedure can be characterized as a polynomial time algorithm for parametric integer programming.</p>
<p>Suppose now that we fix the number of variables and the number of Boolean operations in advance (and hence get what is called a short formula of Presburger arithmetic). Thus the only parameters of the formula are the numerical values of the constants in the formula. The authors show that deciding validity becomes <strong>NP-complete</strong> if one allows<br />
two quantifier alternations. Remarkably, they present an example of a formula</p>
<p>∃z ∈ <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z" class="latex" title="\mathbb Z" /> ∀y ∈ <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^2" class="latex" title="\mathbb Z^2" /> ∃x ∈ <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^2" class="latex" title="\mathbb Z^2" /> Φ(x, y, z)</p>
<p>with an <strong>NP-complete</strong> decision problem, even though Φ contains at most 10 inequalities.<br />
Another remarkable example is an <strong>NP-complete</strong> decision problem for a formula of the<br />
type</p>
<p>∃z ∈ <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z" class="latex" title="\mathbb Z" /> ∀y ∈ <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^2" class="latex" title="\mathbb Z^2" /> ∃x ∈ <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z%5E6&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z^6" class="latex" title="\mathbb Z^6" />: <em>Ax + By + Cz ≤ b,  </em></p>
<p>with at most 24 inequalities.</p>
<p>As the number of quantifier alternations is allowed to increase, the computational complexity in the polynomial hierarchy also moves up. The authors also describe the computational complexity of corresponding counting problems.</p>
<p>The proof is very clever; it uses the continued fraction expansion of a rational number to encode a growing family of intervals, with the help of which the authors build an <strong>NP-complete</strong> problem.</p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/03/22/danny-nguyen-and-igor-pak-presburger-arithmetic-problem-solved/"><span class="datestr">at March 22, 2019 09:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/">Workshop on Algebraic Complexity Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
March 25-29, 2019 The International Centre for Theoretical Sciences (ICTS), Bengaluru (India) https://www.icts.res.in/discussion-meeting/wact2019 The primary objective of this workshop is to bring together experts in the field of algebraic complexity and related areas to present their research, initiate collaborations etc. The idea is to continue the tradition of having a Workshop on Algebraic Complexity Theory … <a href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/" class="more-link">Continue reading <span class="screen-reader-text">Workshop on Algebraic Complexity Theory</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/03/22/workshop-on-algebraic-complexity-theory/"><span class="datestr">at March 22, 2019 09:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://corner.mimuw.edu.pl/?p=1076">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/banach.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://corner.mimuw.edu.pl/?p=1076">The Curse of Euclidean Metric: Square Roots</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p style="text-align: justify;"><a href="https://duch.mimuw.edu.pl/~tugboat/wp-content/uploads/2019/03/curseOfMetricIsland.png"><img src="https://duch.mimuw.edu.pl/~tugboat/wp-content/uploads/2019/03/curseOfMetricIsland_small.png" align="right" class="wp-image-587 alignright" alt="The Curse of Metric Island" /></a></p>
<p>The deadline was approaching without mercy and there was, of course, still some polishing to be done for <a href="https://doi.org/10.1137/1.9781611975482.67">our SODA paper</a>. But then we run into an issue. To make things worse, this issue turned out to be a hard one, a fundamental known open problem in computational geometry. The good thing is, I liked the problem so much that I decided to dedicate it this post. This is the story about the Sum of Square Roots problem and how we bypassed (ignored) it without solving it.</p>
<p></p>
<p></p>
<p style="text-align: justify;">Everything began in the haze of the 70's of the last millennium. It is nebulous who stumbled first upon this enigma. <a href="https://www.ics.uci.edu/~eppstein/junkyard/small-dist.html">Some say</a> that Ron Graham has discussed the problem in public lectures, <a href="https://www.jstor.org/stable/2321488">some others</a> say that Joseph O'Rourke has posed it as an open question in the American Mathematical Monthly, while <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">some others</a> suspect that the problem had been already hiding in older different formulations. However, it is a historical fact that one shinny/cloudy day, three computer scientists finished polishing a manuscript that became a classical paper known as "<a href="https://doi.org/10.1145/800113.803626">Some NP-complete geometric problems</a>". In this paper, Michael Garey, Ron Graham and David Johnson showed the NP-hardness of two important problems in geometric metrics: Steiner Tree and Traveling Salesman. For the Euclidean plane, they showed only NP-hardness as they did not manage to show that these problems are contained in NP. Moreover, they accentuated that we cannot even rule out that the decision version of Euclidean Minimum Spanning Tree is outside of NP. What a seeming paradox given that we can compute such a minimum tree in polynomial time! So, whom did they blame? The short answer: The Euclidean metric. Garey and his coauthors explain that all these problems have a common hidden issue: They rely on comparing Euclidean lengths, that is, they rely on comparing irrational numbers based on square roots. Whereas this task is trivial if we just want to compare two line segments (e.g. by comparing the radicands), the problem starts when we want to compare two polygonal paths. Even assuming rational (or, after scaling, integer) coordinates, this problem translates into a question that is fundamental in computational geometry: Given two lists of integers, <em>a<sub>1</sub></em> ... and <em>b<sub>1</sub></em> ..., can we decide whether "<em>∑ √a<sub>i</sub> ≥ ∑ √b<sub>i</sub></em>" in P? Put into words: <strong>Can we efficiently compare two sums of square roots over integers?</strong></p>
<p><span id="more-1076"></span></p>
<p></p>
<p></p>
<p style="text-align: justify;">To emphasize the significance of this question, let me cite <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">David Eppstein</a>: "A major bottleneck in proving NP-completeness for geometric problems is a mismatch between the real-number and Turing machine models of computation: one is good for geometric algorithms but bad for reductions, and the other vice versa. Specifically, it is not known on Turing machines how to quickly compare a sum of distances (square roots of integers) with an integer or other similar sums, so even (decision versions of) easy problems such as the minimum spanning tree are not known to be in NP."</p>
<p></p>
<p></p>
<p style="text-align: justify;">"Is this problem computable at all?" - might the curious reader ask after realizing that the approach of iteratively increasing the precision until the first difference in digits will never terminate if both numbers happen to be equal. Luckily, <a href="https://doi.org/10.1016/S0747-7171(85)80013-4">Allan Borodin et al.</a> and <a href="https://refubium.fu-berlin.de/handle/fub188/18449">Johannes Blömer</a> showed that polynomial time is enough to decide whether two such sums have the same value. Therefore, it is astonishing that the problem of deciding the sign of their difference, a question that seems only slightly harder, has been only recently spotted by <a href="https://doi.org/10.1137/070697926">Eric Allender et al</a> on an island of the counting hierarchy CH (3rd level) located in the wide ocean of PSPACE. Thus, it is still far far away from the needle head of P, where <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.44.5325">Gregorio Malajovich</a> conjectured it to live. Until this will be shown, <a href="https://cstheory.stackexchange.com/questions/4053/sum-of-square-roots-hard-problems">Jeff Erickson</a> proposes to study which problems are (<a href="https://cstheory.stackexchange.com/questions/4053/sum-of-square-roots-hard-problems">non-boringly</a>) Σ√-hard.</p>
<p></p>
<p></p>
<p style="text-align: justify;">Oh, if we could only sufficiently bound the difference of the sums from below! Then we could bound from above the precision required to determine the correct sign of the difference: Just image that <em>B</em> is such a lower bound on the difference. Now, take a precision that allows us to compute an approximate difference being only <em>B/2</em> away from the real one. Then it is easy to verify that the following procedure determines the correct sign: Output the sign of the approximate difference if it is outside of <em>[-B/2,B/2]</em>, otherwise output <em>0</em>. What is the run time of this procedure? It is proportional to the precision, which corresponds to the length of <em>B</em>, that is, to <em>-log B</em>. Hence, if <em>-log B</em> is bounded from above by a polynomial in the length of the input, then we are in P! So, is there any reasonable lower bound for the worst case? That is, <strong>what is the smallest positive difference between any two sums of <em>k</em> square roots of integers of size at most <em>n</em>?</strong> Welcome to <a href="http://cs.smith.edu/~jorourke/TOPP/P33.html">Problem 33</a> of <a href="http://cs.smith.edu/~jorourke/TOPP/Welcome.html">The Open Problems Project</a>! Let <em>r(n,k)</em> denote such a minimum difference as a function of <em>n</em> and <em>k</em>. For instance, consider <em>n=20</em> and <em>k=2</em>. Then <em>r(n,k)</em> is roughly <em>0.0002</em> and it is attained by <em>√{10} + √{11} - √{5} - √{18}</em>. As being an open problem, there is no tight bound known for <em>r(n,k)</em>. <a href="https://doi.org/10.1016/j.ipl.2006.05.002">Jianbo Qian and Cao An Wang</a> as well as <a href="https://doi.org/10.1016/j.tcs.2011.06.014">Qi Cheng and Yu-Hsin Li</a> proved(*) that there are sums where <em>-log r(n,k)</em> is at least in the order of magnitude of <em>k log n</em>. However, these lower bounds constitute an exponentially gap to the best known upper bounds which are <em>O(2<sup>2k</sup> log n)</em> [<a href="https://doi.org/10.1007/s004530010005">Christoph Burnikel et al.</a>(**)] and <em>2<sup>O(n/log n)</sup></em> [<a href="https://doi.org/10.1016/j.tcs.2011.06.014">Qi Cheng et al.</a>]. So, maybe you, dear reader, will be the one to close the gap?</p>
<p></p>
<p></p>
<p style="text-align: justify;">In the dramatic opening of this post, I mentioned <a href="https://doi.org/10.1137/1.9781611975482.67">our paper</a>, where the problem of Sum of Square Roots appeared. There, we design a PTAS for the Traveling Salesman problem (TSP) with hyperplane neighborhoods, that is, we look for a <em>(1+ε)</em>-approximation of a minimum-length tour that, instead of points, visits a given set of hyperplanes in ℝ<sup><em>d</em></sup> with <em>d</em> being fixed. The basis of our algorithm is an integer grid of constant size (depending on <em>ε</em> and <em>d</em>). Our key observation is that there is a translation and scaling of the grid such that snapping an (adequately sparsified) optimum solution to the grid results in a <em>(1+ε</em>)-approximation. Using this insight, we let our algorithm enumerate all (reasonable) TSP tours lying in our integer grid. With a simple LP, we translate and scale each tour such that it visits all the hyperplanes of the input whilst minimizing its tour length (i.e., the scaling factor). At the end, we obtain a set of feasible TSP tours and output the shortest one. And here we were confronted with the Sum of Square Roots problem. Which of the tours is the shortest one? Was all our work devastated, all our blood, sweat and tears in vain? Just because the very last line of our algorithm had unknown complexity? Our solution was simple: We just skipped the issue and our paper got accepted. Why? Well, the issue wasn't one for the following three reasons:</p>
<ul>
<li>We could be lazy and assume the real RAM computational model with constant time for square root operations (as often done in computational geometry).</li>
<li>We could be industrious and approximate the real tour lengths with a sufficiently small error since we look anyway for an approximation in overall.</li>
<li>We could think and then realize that our candidate tours consist of only constant many vertices as our integer grid has constant size. Indeed, the best known lower bound on the difference <em>r(n,k)</em> implies the following nice take-away which shall conclude this epilogue:</li>
</ul>
<p><strong>We can compare two sums of square roots in polynomial time if the number of square roots is constant!</strong></p>
<p></p>
<p><em><a href="https://duch.mimuw.edu.pl/~tugboat/about-us/krzysztof-fleszar/">Krzysztof Fleszar</a></em></p>
<p></p>
<p style="text-align: justify;">-------------------------</p>
<p>Proof sketches for the interested reader of the lower and upper bounds on <em>r(n,k)</em>:</p>
<p>(*) <em>Ω(k log n)</em> [<a href="https://doi.org/10.1016/j.tcs.2011.06.014">Cheng et al.</a>]: The interval <em>[k, k √{n}]</em> contains so many distinct sums of square roots (over square-free integers) that, by a pigeonhole argument, there are two sums with very small distance.</p>
<p>(**) <em>O(2<sup>2k</sup> log n)</em> [<a href="https://doi.org/10.1007/s004530010005">Burnikel et al.</a>]: The difference is an algebraic integer and, consequently, the root of a polynomial with integer coefficients and degree at most <em>2<sup>2k</sup></em>. A simple inequality yields the bound.</p>
<p></p></div>







<p class="date">
by Renata Czarniecka <a href="http://corner.mimuw.edu.pl/?p=1076"><span class="datestr">at March 22, 2019 08:54 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15698">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/03/21/the-shortest-path-to-the-abel-prize/">The Shortest Path To The Abel Prize</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>While melding topology, geometry, and analysis</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/03/uhlenbeckias.jpg"><img src="https://rjlipton.files.wordpress.com/2019/03/uhlenbeckias.jpg?w=150&amp;h=180" alt="" width="150" class="alignright wp-image-15699" height="180" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">IAS <a href="https://www.ias.edu/scholars/karen-uhlenbeck">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Karen Uhlenbeck is a mathematician who has won a number of awards in the past and has just now been announced as winner of the 2019 Abel Prize. </p>
<p>
Today Ken and I want to explain a tiny bit about what Uhlenbeck did.<br />
<span id="more-15698"></span></p>
<p>
The Abel Prize <a href="http://www.abelprize.no/c73996/seksjon/vis.html?tid=74013">citation</a> says that Uhlenbeck won for</p>
<blockquote><p><b> </b> <em> “pioneering achievements in geometric partial differential equations, gauge theory, and integrable systems, and for the fundamental impact on analysis, geometry and mathematical physics.” </em>
</p></blockquote>
<p></p><p>
A <a href="https://www.quantamagazine.org/karen-uhlenbeck-uniter-of-geometry-and-analysis-wins-abel-prize-20190319/">story</a> in <em>Quanta</em> and <a href="https://www.scientificamerican.com/article/soap-bubble-pioneer-is-first-woman-to-win-prestigious-math-prize/">another</a> in <em>Scientific American</em> are among those with readable summaries of the general nature of this work. The latter describes Uhlenbeck’s discovery with the mathematician Jonathan Sacks of a phenomenon called <em>bubbling</em> as follows: </p>
<blockquote><p><b> </b> <em> Sacks and Uhlenbeck were studying ‘minimal surfaces,’ the mathematical theory of how soap films arrange themselves into shapes that minimize their energy. But the theory had been marred by the appearance of points at which energy appeared to become infinitely concentrated. Uhlenbeck’s insight was to “zoom in” on those points to that this were caused by a new bubble splitting off the surface. </em>
</p></blockquote>
<p></p><p>
Some of the coolest comments are by Uhlenbeck’s doctoral graduate Mark Haskins in the <a href="https://www.nature.com/articles/d41586-019-00932-1">story</a> in the current issue of <em>Nature</em>. </p>
<blockquote><p><b> </b> <em> Haskins says Uhlenbeck is one of those mathematicians who have ‘an innate sense of what should be true,’ even if they cannot always explain why. </em>
</p></blockquote>
<p></p><p>
The story recounts his often being baffled by answers to his questions, thinking Uhlenbeck had misheard them. But</p>
<blockquote><p><b> </b> <em> “maybe weeks later, you would realize that you had not asked the correct question.” </em>
</p></blockquote>
<p>
</p><p></p><h2> Calculus Of Variations </h2><p></p>
<p></p><p>
Simon Donaldson wrote a <a href="https://www.ams.org/journals/notices/201903/rnoti-p303.pdf">piece</a> in the current issue of <i>AMS Notices</i> that explains Uhlenbeck’s research in the Calculus of Variations. The article starts with 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28u%29+%3D+%5Cint+%5CPhi%28u%2Cu%27%29+dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F(u) = \int \Phi(u,u') dx. " class="latex" title="\displaystyle  F(u) = \int \Phi(u,u') dx. " /></p>
<p>You can think of <img src="https://s0.wp.com/latex.php?latex=%7BF%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(u)}" class="latex" title="{F(u)}" /> as assigning a cost to a function <img src="https://s0.wp.com/latex.php?latex=%7Bu%3Du%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u=u(x)}" class="latex" title="{u=u(x)}" />. The goal of the calculus of variations is to find the best <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> that minimizes <img src="https://s0.wp.com/latex.php?latex=%7BF%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(u)}" class="latex" title="{F(u)}" /> subject to some conditions on <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" />. This is a huge generalization of simple minimization problems that arise in basic calculus. He then goes on to explain that in order to study the minimum solutions of such a function one quickly needs to examine partial differential equations. The math gets complex and beautiful very quickly. </p>
<p>
As computer scientists who like discrete structures this is not our sweet spot. We rarely use partial derivatives in our work. Well not very often. See <a href="https://rjlipton.wordpress.com/2010/03/27/fast-matrix-products-and-other-amazing-results/">these</a> two <a href="https://rjlipton.wordpress.com/2010/08/19/projections-can-be-tricky/">posts</a> for an example. </p>
<p>
To get a taste of this area, we will consider a classic variation problem coming out of these helpful online <a href="http://farside.ph.utexas.edu/teaching/336k/Newtonhtml/node86.html">notes</a>. It leads to integrals such as 	 </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cint_%7B0%7D%5E%7Ba%7D+%281%2Bu%27%28x%29%5E%7B2%7D%29%5E%7B1%2F2%7D+dx.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \int_{0}^{a} (1+u'(x)^{2})^{1/2} dx. " class="latex" title="\displaystyle  \int_{0}^{a} (1+u'(x)^{2})^{1/2} dx. " /></p>
<p>Well, we take to integrals even less than partial derivatives. </p>
<p>
</p><p></p><h2> Straight-line Shortest Path </h2><p></p>
<p></p><p>
We will change things up by starting with a discrete approach—as is our wont. Our given task is to prove in general that a straight line is the shortest path from the origin to a given point <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p = (a,b)}" class="latex" title="{p = (a,b)}" />. We first consider polygonal paths with <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> line segments. </p>
<p>
First, if <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 1}" class="latex" title="{n = 1}" /> then the only option allowed is to go from <img src="https://s0.wp.com/latex.php?latex=%7B%280%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(0,0)}" class="latex" title="{(0,0)}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,b)}" class="latex" title="{(a,b)}" /> in one line segment. Thus the conclusion holds trivially: the Euclidean distance <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,p)}" class="latex" title="{d(0,p)}" /> is the minimum length of a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />-segment path.</p>
<p>
Now let <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \geq 2}" class="latex" title="{n \geq 2}" />. Let </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P+%3D+%280%2C0%29+%5Crightarrow+x_1+%5Crightarrow+x_2+%5Crightarrow+%5Ccdots+%5Crightarrow+x_n+%3D+%28a%2Cb%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  P = (0,0) \rightarrow x_1 \rightarrow x_2 \rightarrow \cdots \rightarrow x_n = (a,b) " class="latex" title="\displaystyle  P = (0,0) \rightarrow x_1 \rightarrow x_2 \rightarrow \cdots \rightarrow x_n = (a,b) " /></p>
<p>be a series of line segments that form the shortest path from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />. Now by induction, the minimum length of a path of up to <img src="https://s0.wp.com/latex.php?latex=%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n-1}" class="latex" title="{n-1}" /> segments from <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> is <img src="https://s0.wp.com/latex.php?latex=%7Bd%28x_1%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(x_1,p)}" class="latex" title="{d(x_1,p)}" /> via a straight line from <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />. And the length of the segment from the origin <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> of course is <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,x_1)}" class="latex" title="{d(0,x_1)}" />. Now the Euclidean triangle inequality says that the length <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cx_1%29+%2B+d%28x_1%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,x_1) + d(x_1,p)}" class="latex" title="{d(0,x_1) + d(x_1,p)}" /> which bounds the length of this path from below is not less than <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,p)}" class="latex" title="{d(0,p)}" />. Thus we have proved it for <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> and the induction goes through.</p>
<p>
What we really want to do, however, is prove that <img src="https://s0.wp.com/latex.php?latex=%7Bd%280%2Cp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(0,p)}" class="latex" title="{d(0,p)}" /> is the shortest length for any path, period. The path need not have any straight segments. It may go in circular arcs, continually changing direction. The arcs need not be circular per-se; they could be anything.</p>
<p>
The idea that occurs to us computer scientists is to let <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> go to infinity. That is, we want to consider any path as being a limit of polygonal paths. But is this really legitimate? We can certainly approximate any path by paths of segments. But real analysis is littered with examples of complicated curves—themselves defined by limits—that defeat many intuitive expectations about continuity and limits. So how can we make such an infinitistic proof go through rigorously? This is where the calculus of variations takes over.</p>
<p>
</p><p></p><h2> Minimizers of Functionals </h2><p></p>
<p></p><p>
To set up the problem for fully general paths, we could represent them as functions <img src="https://s0.wp.com/latex.php?latex=%7Bf%28t%29+%3D+%28x%28t%29%2Cy%28t%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(t) = (x(t),y(t))}" class="latex" title="{f(t) = (x(t),y(t))}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bf%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(0) = 0}" class="latex" title="{f(0) = 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bf%281%29+%3D+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(1) = p}" class="latex" title="{f(1) = p}" />. The length of the path is then obtained by integrating all the horizontal and vertical displacements: <a name="length1"></a></p><a name="length1">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cell%28f%29%280%2Cp%29+%3D+%5Cint_%7Bt%3D0%7D%5E%7Bt%3D1%7D+%5Csqrt%7B%5Cleft%28%5Cfrac%7Bdx%28t%29%7D%7Bdt%7D%5Cright%29%5E2+%2B+%5Cleft%28%5Cfrac%7Bdy%28t%29%7D%7Bdt%7D%5Cright%29%5E2%7D+dt.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \ell(f)(0,p) = \int_{t=0}^{t=1} \sqrt{\left(\frac{dx(t)}{dt}\right)^2 + \left(\frac{dy(t)}{dt}\right)^2} dt. \ \ \ \ \ (1)" class="latex" title="\displaystyle  \ell(f)(0,p) = \int_{t=0}^{t=1} \sqrt{\left(\frac{dx(t)}{dt}\right)^2 + \left(\frac{dy(t)}{dt}\right)^2} dt. \ \ \ \ \ (1)" /></p>
</a><p><a name="length1"></a> Wrangling this integral seems daunting enough, but the real action involving <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f)}" class="latex" title="{\ell(f)}" /> only begins after doing so. Both the length <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f)}" class="latex" title="{\ell(f)}" /> and the body of the integral are <em>functionals</em>—that is, functions of a function. We need to minimize <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f)}" class="latex" title="{\ell(f)}" /> over all functions <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" />. This is a higher-order task than minimizing a function at a point. </p>
<p>
Our source simplifies the problem by assuming without loss of generality that <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> increases from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" />, giving the function <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> as <img src="https://s0.wp.com/latex.php?latex=%7By%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y(x)}" class="latex" title="{y(x)}" /> instead. Then the problem becomes to minimize <a name="length21"></a></p><a name="length21">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cell%28f%29+%3D+%5Cint_%7Bx%3D0%7D%5E%7Bx%3Da%7D+%5Csqrt%7B1+%2B+%5Cleft%28%5Cfrac%7Bdy%28x%29%7D%7Bdx%7D%5Cright%29%5E2%7D+dx.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \ell(f) = \int_{x=0}^{x=a} \sqrt{1 + \left(\frac{dy(x)}{dx}\right)^2} dx. \ \ \ \ \ (2)" class="latex" title="\displaystyle  \ell(f) = \int_{x=0}^{x=a} \sqrt{1 + \left(\frac{dy(x)}{dx}\right)^2} dx. \ \ \ \ \ (2)" /></p>
</a><p><a name="length21"></a> The body can be abstracted as a functional <img src="https://s0.wp.com/latex.php?latex=%7BF%28u%2Cu%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(u,u')}" class="latex" title="{F(u,u')}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> and its derivative <img src="https://s0.wp.com/latex.php?latex=%7Bu%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u'}" class="latex" title="{u'}" /> are functions of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. Here we have <img src="https://s0.wp.com/latex.php?latex=%7Bu+%3D+y%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u = y(x)}" class="latex" title="{u = y(x)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bu%27+%3D+%5Cfrac%7Bdy%7D%7Bdx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u' = \frac{dy}{dx}}" class="latex" title="{u' = \frac{dy}{dx}}" />. The condition for <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> to minimize <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D+%3D+%5Cint_x+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F} = \int_x F}" class="latex" title="{\mathcal{F} = \int_x F}" /> was derived by Leonhard Euler and Joseph Lagrange: <a name="EL"></a></p><a name="EL">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7Bd%7D%7Bdx%7D%5Cleft%28%5Cfrac%7B%5Cpartial+F%7D%7B%5Cpartial+u%27%7D%5Cright%29+%3D+%5Cfrac%7B%5Cpartial+F%7D%7B%5Cpartial+u%7D%5C%3B.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{d}{dx}\left(\frac{\partial F}{\partial u'}\right) = \frac{\partial F}{\partial u}\;. \ \ \ \ \ (3)" class="latex" title="\displaystyle  \frac{d}{dx}\left(\frac{\partial F}{\partial u'}\right) = \frac{\partial F}{\partial u}\;. \ \ \ \ \ (3)" /></p>
</a><p><a name="EL"></a> We won’t reproduce here how our source derives this but give some interpretation. This is a kind of regularity property that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> must obey in order to minimize <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}}" class="latex" title="{\mathcal{F}}" />. To quote Donaldson’s survey:</p>
<blockquote><p><b> </b> <em> Then the condition that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is stationary with respect to compactly supported variations of <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> is a second order differential equation—the Euler-Lagrange equation associated to the functional. </em>
</p></blockquote>
<p></p><p>
However you slice it, the point is that the equation (<a href="https://rjlipton.wordpress.com/feed/#EL">3</a>), when applied to cases like the above, is attackable. In the minimum-length path example, our source—after doing eight more equation lines of work—deduces that <img src="https://s0.wp.com/latex.php?latex=%7Bu%27+%3D+%5Cfrac%7Bdy%7D%7Bdx%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u' = \frac{dy}{dx}}" class="latex" title="{u' = \frac{dy}{dx}}" /> must be constant. Any function argument <img src="https://s0.wp.com/latex.php?latex=%7BF+%3D+y%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F = y(x)}" class="latex" title="{F = y(x)}" /> that yields this must be a straight line. The initial conditions force this to be the straight line from <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />.</p>
<p>
</p><p></p><h2> Some of Uhlenbeck’s Work </h2><p></p>
<p></p><p>
The point we are emphasizing is that this simple case of paths in the plane—and its abstraction via functionals <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}}" class="latex" title="{\mathcal{F}}" /> that are ultimately founded on one variable <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />—have a ready-made minimization scheme, thanks to Euler and Lagrange. The scheme is fully general—not subject to the caveats about our simple approximation by line segments.</p>
<p>
What happens in higher-dimensional cases? We can quote from the wonderful two-page <a href="http://www.abelprize.no/c73996/binfil/download.php?tid=74177">essay</a> accompanying the Abel Prize citation. It first notes the importance of a <a href="https://en.wikipedia.org/wiki/Palais-Smale_compactness_condition">condition</a> on functionals and their ambient spaces named for Richard Palais and Stephen Smale, which however fails for many cases of interest including harmonic maps.</p>
<blockquote><p><b> </b> <em> [T]he Palais-Smale compactness condition … guarantees existence of minimizers of geometric functionals and is successful in the case of 1-dimensional domains, such as closed geodesics. Uhlenbeck realized that the condition of Palais-Smale fails in the case of surfaces due to topological reasons. </em>
</p></blockquote>
<p></p><p>
The papers with Sacks explored the roots of these breakdowns and found a way to patch them. The violation of the Palais-Smale condition allows minimizing sequences of functionals to converge with dependence on points outside the space being analyzed. But those loci are governed by a finite set of singular points within the space. This enables the calculus outside the space to be treated as a re-scaling of what goes on inside the space. </p>
<p>
In general cases the view of the process from inside to outside can be described and analyzed as bubbles emerging from the singular locations. More than this picture and interpretation, the Sacks-Uhlenbeck papers produced a now-standard tool-set for higher-dimensional minimization of functionals. It is also another successful marriage of topology—determining the singularities—and analysis.</p>
<p>
This work was extensible to more-general kinds of functionals such as a central one of Yang-Mills theory in physics. Geometric properties of a Riemannian manifold <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> are expressed via the concept of a <a href="https://en.wikipedia.org/wiki/Connection_(mathematics)">connection</a> <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and the functional associates to <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> its <em>curvature</em> <img src="https://s0.wp.com/latex.php?latex=%7BF%28A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(A)}" class="latex" title="{F(A)}" />. This is the body for the Yang-Mills functional </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathcal%7BF%7D+%3D+%5Cint_M+%7CF%28A%29%7C%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathcal{F} = \int_M |F(A)|^2. " class="latex" title="\displaystyle  \mathcal{F} = \int_M |F(A)|^2. " /></p>
<p>There is a corresponding lifting of the Euler-Lagrange equation. This led to developments very much along lines of the previous work with Sacks and more besides. There was particular success analyzing cases where <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> has dimension 4 that were soon relevant to Donaldson’s own Fields Medal-winning research on these spaces. Most in particular, Uhlenbeck working solo proved that these cases were immune to the “bubbling” issue—with the consequence as related in <em>Quanta</em> that</p>
<blockquote><p><b> </b> <em> any finite-energy solution to the Yang-Mills equations that is well-defined in the neighborhood of a point will also extend smoothly to the point itself. </em>
</p></blockquote>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We’ve been happy to report that Uhlenbeck has won the prestigious Abel Prize. We have avoided referencing one aspect—despite giving numerous quotes verbatim—that can be appreciated in subsequent fullness <a href="https://www.ias.edu/news/2018/women-and-mathematics-twenty-five-years">here</a> and <a href="https://www.ias.edu/pcmi">here</a> and in <a href="https://impa.br/en_US/page-noticias/karen-uhlenbeck-the-struggle-for-a-place-in-the-sun/">this</a>. By so doing we’ve abided the desire stated in the twelfth paragraph of this <a href="https://web.ma.utexas.edu/users/uhlen/vita/pers.html">essay</a>. We wonder if this is the right way to do things. What do you think?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/03/21/the-shortest-path-to-the-abel-prize/"><span class="datestr">at March 22, 2019 02:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2570215373323645628">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html">Back at Dagstuhl</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div style="clear: both; text-align: center;" class="separator">
<a href="https://www.dagstuhl.de/Gruppenbilder/19121.01.l.jpg"><img width="320" src="https://www.dagstuhl.de/Gruppenbilder/19121.01.l.jpg" border="0" height="212" /></a></div>
<table cellpadding="0" align="center" style="margin-left: auto; margin-right: auto; text-align: center;" cellspacing="0" class="tr-caption-container"><tbody>
<tr><td style="text-align: center;"><a style="margin-left: auto; margin-right: auto;" href="https://4.bp.blogspot.com/-GEp5KM-SUA4/XJJZrdR0SrI/AAAAAAABmzo/-77gRJWCTY814teJFCINLxABFNIohHF8QCKgBGAs/s1600/IMG_20190320_090009.jpg"><img width="320" src="https://4.bp.blogspot.com/-GEp5KM-SUA4/XJJZrdR0SrI/AAAAAAABmzo/-77gRJWCTY814teJFCINLxABFNIohHF8QCKgBGAs/s320/IMG_20190320_090009.jpg" border="0" height="240" /></a></td></tr>
<tr><td style="text-align: center;" class="tr-caption">Participants and Their Research Interests</td></tr>
</tbody></table>
<br />
This week I'm in Germany for the Dagstuhl workshop on <a href="https://www.dagstuhl.de/en/program/calendar/semhp/?semnr=19121">Computational Complexity of Discrete Problems</a> well timed for Georgia Tech spring break. No Bill, so no <a href="https://blog.computationalcomplexity.org/2018/09/still-typecasting-from-dagstuhl.html">typecast</a>, no <a href="https://blog.computationalcomplexity.org/2017/03/the-dagstuhl-family.html">family</a>, just a bunch of fellow theorists. New this year, beer.<br />
<br />
Dagstuhl always had bottled beer (and wine), after all this is Germany. However, Ronen Shaltiel is living his lifelong dream of bringing a keg to Dagstuhl. Turns out Dagstuhl had a refrigerator/tap for a beer keg, one only needs to order and pay for the beer. Ronen's daughter designed a special logo, though the keg contains Bitburger, a fine German pilsner. Prost to Ronen and thanks for the beer.<br />
<br />
<div style="clear: both; text-align: center;" class="separator">
<a style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;" href="https://3.bp.blogspot.com/-L7gbzTPK6t8/XJIeFNgMlwI/AAAAAAABmyU/8HxYbP69pVI91P9I-m3y4aXhlYEzwWqxwCKgBGAs/s1600/MVIMG_20190318_181047.jpg"><img width="150" src="https://3.bp.blogspot.com/-L7gbzTPK6t8/XJIeFNgMlwI/AAAAAAABmyU/8HxYbP69pVI91P9I-m3y4aXhlYEzwWqxwCKgBGAs/s200/MVIMG_20190318_181047.jpg" border="0" height="200" /></a><a style="clear: left; float: left; margin-bottom: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-3yFv9qZFvkM/XJIeFPPmYSI/AAAAAAABmyU/iF8pnxyAO7wh8owT8A3RhFnMsCmvlzySgCKgBGAs/s1600/IMG_20190318_193159.jpg"><img width="150" src="https://1.bp.blogspot.com/-3yFv9qZFvkM/XJIeFPPmYSI/AAAAAAABmyU/iF8pnxyAO7wh8owT8A3RhFnMsCmvlzySgCKgBGAs/s200/IMG_20190318_193159.jpg" border="0" height="200" /></a><a style="margin-left: 1em; margin-right: 1em;" href="https://2.bp.blogspot.com/-XLdHqofvmbQ/XJIfEQ3YBSI/AAAAAAABmyg/sfQphG1tRLQruYk30IytbJ_yKYYxpWAdQCLcBGAs/s1600/shaltieliner.jpg"><img width="200" src="https://2.bp.blogspot.com/-XLdHqofvmbQ/XJIfEQ3YBSI/AAAAAAABmyg/sfQphG1tRLQruYk30IytbJ_yKYYxpWAdQCLcBGAs/s200/shaltieliner.jpg" border="0" height="200" /></a></div>
<br />
Of course the fun is hanging with colleagues old and new. Talking about open problems old and new. Used to solve more of them back in the day, now it seems harder.<br />
<br />
I did learn a new old theorem, planarity testing, whether you can embed a given graph in the plane so no two edges cross, is computable in log space. In 2000 Eric Allender and Meena Mahajan <a href="https://doi.org/10.1016/j.ic.2003.09.002">showed</a> that you can test for planarity in symmetric log space, basically the complexity class whose complete problem is undirected connectivity. In 2005, Omer Reingold <a href="https://doi.org/10.1145/1391289.1391291">famously showed</a> that undirected connectivity is computable in log-space. Thus planarity testing is in log-space, a result you might have missed if you didn't know both papers.<br />
<br />
This came out in Eric's talk on his work with Archit Chauhan, Samir Datta and Anish Mukherjee <a href="https://eccc.weizmann.ac.il/report/2019/039/">showing</a> that checked whether there is a directed path from a given node s to a given node t in planar graphs can be computed by concurrent-read exclusive-write on parallel random-access machines in logarithmic time, and thus likely weaker than directed s-t paths on general graphs.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/back-at-dagstuhl.html"><span class="datestr">at March 21, 2019 10:11 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2019/03/19/CURL/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2019/03/19/CURL/">Contrastive Unsupervised Learning of Semantic Representations&amp;#58; A Theoretical Framework</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><em>Semantic representations</em> (aka  <em>semantic embeddings</em>) of complicated data types (e.g. images, text, video) have become central in machine learning, and also crop up in machine translation, language models, GANs, domain transfer, etc. 
These involve learning a <em>representation function</em> $f$ such that for any data point $x$ its representation $f(x)$ is “high level” (retains semantic information while discarding low level details, such as color of individual pixels in an image) and “compact” (low dimensional). 
The test of a good representation is that it should greatly simplify solving <em>new</em> classification tasks, by allowing them to be solved via linear classifiers (or other low-complexity classifiers) using small amounts of labeled data.</p>

<p>Researchers are most interested in <em>unsupervised</em> representation learning using unlabeled data. A popular approach is to use objectives similar to the <strong>word2vec</strong> algorithm for word embeddings, which work well for diverse data types such as molecules, social networks, images, text etc. 
See the <a href="https://en.wikipedia.org/wiki/Word2vec">wikipage of word2vec</a> for references. 
Why do such objectives succeed in such diverse settings? 
This post is about an explanation for these methods by using our <a href="https://arxiv.org/abs/1902.09229">new theoretical framework</a> with coauthor Misha Khodak. 
The framework makes minimalistic assumptions, which is a good thing, since word2vec-like algorithms apply to vastly different data types and it is unlikely that they can share a common Bayesian generative model for the data. 
(An example of generative models in this space is described in an earlier <a href="http://www.offconvex.org/2016/02/14/word-embeddings-2/">blog post on the RAND-WALK model</a>.)
As a bonus this framework also yields principled ways to design new variants of the training objectives.</p>

<h2 id="semantic-representations-learning">Semantic representations learning</h2>
<p>Do good, broadly useful representations even <em>exist</em> in the first place? 
In domains such as computer vision, we know the answer is “yes” because deep convolutional neural networks (CNNs), when  trained to high accuracy on large multiclass labeled datasets such as <a href="http://www.image-net.org/">ImageNet</a>, end up learning very powerful and succinct representations along the way. The penultimate layer of the net — the input into the final <a href="https://en.wikipedia.org/wiki/Softmax_function">softmax layer</a> — serves as a good semantic embedding of the image in new unrelated visual tasks. 
(Other layers from the trained net can also serve as good embeddings.) 
In fact the availability of such embeddings from pre-trained (on large multiclass datasets) nets has led to a revolution in computer vision, allowing a host of new classification tasks to be solved with low-complexity classifiers (e.g. linear classifiers) using very little labeled data. 
Thus they are the gold standard to compare to if we try to learn embeddings via unlabeled data.</p>

<p style="text-align: center;">
<img width="50%" src="http://www.offconvex.org/assets/CURLheadless1.svg" />
</p>

<h3 id="word2vec-like-methods-curl">word2vec-like methods: CURL</h3>

<p>Since the success of <a href="https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf">word2vec</a>, similar approaches were used to learn embeddings for <a href="https://arxiv.org/pdf/1803.02893.pdf">sentences and paragraphs</a>, <a href="https://arxiv.org/abs/1505.00687">images</a> and <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4640716/">biological sequences</a>.
All of these methods share a key idea: they leverage access to pairs of similar data points $x, x^+$, and learn an embedding function $f$ such that the inner product of $f(x)$ and $f(x^+)$ is on average higher than the inner product of $f(x)$ and $f(x^-)$, where $x^{-}$ is a random data point (and thus presumably dissimilar to $x$). 
In practice similar data points are usually found heuristically, often using co-occurrences, e.g. consecutive sentences in a large text corpus, nearby frames in a video clip, different patches in the same image, etc.</p>

<p>A good example of such methods is <strong>Quick Thoughts</strong> (QT) from <a href="https://arxiv.org/pdf/1803.02893.pdf">Logeswaran and Lee</a>, which is the state-of-the-art unsupervised text embedding on many tasks. To learn a representation function $f$, QT minimizes the following loss function on a large text corpus</p>



<p>where $(x, x^+)$ are consecutive sentences and presumably “semantically similar” and $x^-$ is a random negative sample.
For images $x$ and $x^+$ could be <a href="https://arxiv.org/abs/1505.00687">nearby frames</a> from a video.
For text, two successive sentences serve as good candidates for a similar pair: for example, the following are two successive sentences in the Wikipedia page on word2vec: <em>“High frequency words often provide little information.”</em> and <em>“Words with frequency above a certain threshold may be subsampled to increase training speed.”</em>
Clearly they are much more similar than a random pair of sentences, and the learner exploits this. 
From now on we use <em>Contrastive Unsupervised Representation Learning (CURL)</em> to refer to  methods that leverage similar pairs of data points and our goal is to analyze these methods.</p>

<h3 id="need-for-a-new-framework">Need for a new framework</h3>

<p>The standard framework for machine learning involves minimizing some loss function, and learning is said to succeed (or <em>generalize</em>) if the loss is roughly the same on the average training data point and the average test data point.
In contrastive learning, however, the objective used at test time is very different from the training objective: generalization error is not the right way to think about this.</p>

<blockquote>
  <p><strong>Main Hurdle for Theory:</strong> We have to show that doing well on task A (minimizing the word2vec-like objective) allows the representation to do well on task B (i.e., classification tasks revealed later).</p>
</blockquote>

<p>Earlier methods along such lines include <em>kernel learning</em> and <em>semi-supervised learning</em>, but there training typically requires at least a few labeled examples from the classification tasks of future interest. Bayesian approaches using generative models are also well-established in simpler settings, but have proved difficult for complicated data such as images and text. 
Furthermore, the simple word2vec-like learners described above do not appear to operate like Bayesian optimizers in any obvious way, and also work for very different data types.</p>

<p>We tackle this problem by proposing a framework that formalizes the notion of semantic similarity that is implicitly used by these algorithms and use the framework to show why contrastive learning gives good representations, while defining what <em>good representations</em> mean in this context.</p>

<h2 id="our-framework">Our framework</h2>

<p>Clearly, the implicit/heuristic notion of similarity used in contrastive learning is connected to the downstream tasks in some way — e.g., similarity carries a strong <em>hint</em> that on average the “similar pairs” tend to be assigned the same labels in many downstream tasks (though there is no hard guarantee per se). We present a simple and minimalistic framework to formalize such a notion of similarity. 
For purposes of exposition we’ll refer to data points as “images”.</p>

<h3 id="semantic-similarity">Semantic similarity</h3>

<p>We assume nature has many <em>classes</em> of images, and has a measure $\rho$ on a set of classes $\mathcal{C}$, so that if asked to pick a class it selects $c$  with probability $\rho(c)$. 
Each class $c$ also has an associated distribution $D_c$ on images i.e. if nature is asked to furnish examples of class $c$ (e.g., the class “dogs”) then it picks image $x$ with probability $D_c(x)$. 
Note that classes can have arbitrary overlap, including no overlap. 
To formalize a notion of <em>semantic similarity</em> we assume that when asked to provide “similar” images, nature picks a class $c^+$ from $\mathcal{C}$ using measure $\rho$ and then picks two i.i.d. samples $x, x^{+}$ from the distribution $D_{c^+}$. 
The dissimilar example $x^{-}$ is picked by selecting another class $c^-$ from measure $\rho$ and picking a random sample $x^{-}$ from $D_{c^-}$.</p>

<p style="text-align: center;">
<img width="80%" src="http://www.offconvex.org/assets/CURLframework.svg" />
</p>

<p>The training objective for learning the representation is exactly the QT objective from earlier, but now inherits the following interpretation from the framework
</p>

<p>Note that the function class $\mathcal{F}$ is an arbitrary deep net architecture mapping images to embeddings (neural net sans the final layer), and one would learn $f$ via gradient descent/back-propagation as usual. 
Of course, no theory currently exists for explaining when optimization succeeds for complicated deep nets, so our framework will simply assume that gradient descent has already resulted in some representation $f$ that achieves low loss, and studies how well this does in downstream classification tasks.</p>

<h3 id="testing-representations">Testing representations</h3>

<p>What defines a good representation? 
We assume that the quality of the representation is tested by using it to solve a binary (i.e., two-way) classification task using a linear classifier. 
(The paper also studies extensions to $k$-way classification in the downstream task.) 
How is this binary classification task selected? 
Nature picks two classes $c_1, c_2$ randomly according to measure $\rho$ and picks data points for each class according to the associated probability distributions $D_{c_1}$ and $D_{c_2}$. 
The representation is then used to solve this binary task via logistic regression: namely, find two vectors $w_1, w_2$ so as to minimize the following loss
</p>

<p>The quality of the representation is estimated as the <em>average</em> loss over nature’s choices of binary classification tasks.
</p>

<p>It is important to note that the latent classes present in the unlabeled data are the <em>same</em> classes present in the classification tasks. 
This allows us to formalize a sense of ‘semantic similarity’ as alluded to above: the classes from which data points appear together more frequently are the classes that make up <em>relevant</em> classification tasks. 
Note that if the number of classes is large, then typically the data used in unsupervised training may involve <em>no samples</em> from the classes used at test time. 
Indeed, we are hoping to show that the learned representations are useful for classification on potentially unseen classes.</p>

<h2 id="provable-guarantees-for-unsupervised-learning">Provable guarantees for unsupervised learning</h2>

<p>What would be a dream result for theory? Suppose we fix a class of representation functions ${\mathcal F}$, say those computable by a ResNet 50 architecture with some choices of layer sizes etc.</p>

<blockquote>
  <p><strong>Dream Theorem:</strong> Minimizing the unsupervised loss (using modest amount of unlabeled data) yields a representation function $f \in {\mathcal F}$ that is competitive with the <strong>best</strong> representation from ${\mathcal F}$ on downstream classification tasks, even with very few labeled examples per task.</p>
</blockquote>

<p>While the number of unlabeled data pairs needed to learn an approximate minimizer can be controlled using Rademacher complexity arguments (see paper), we show that the dream theorem is impossible as phrased: we can exhibit a simple class ${\mathcal F}$ where the contrastive objective does not yield representations even remotely competitive with the best in the class.
This should not be surprising and only suggests that further progress towards such a dream result would require making more assumptions than the above minimalistic ones.</p>

<p>Instead, our paper makes progress by showing that under the above framework, if the unsupervised loss happens to be small at the end of contrastive learning then the resulting representations perform well on downstream classification.</p>

<blockquote>
  <p><strong>Simple Lemma:</strong> The average classification loss on downstream binary tasks is upper bounded by the unsupervised loss.

where $\alpha$ depends on $\rho$. ($\alpha\rightarrow 1$ when $|\mathcal{C}|\rightarrow\infty$, for uniform $\rho$)</p>
</blockquote>

<p>This says that the unsupervised loss function can be treated as a <strong>surrogate</strong> for the performance on downstream supervised tasks solved using linear classification, so minimizing it makes sense.
Furthermore, just a few labeled examples are needed to learn the linear classifiers in future downstream tasks.
Thus our minimalistic framework lets us show guarantees for contrastive learning and also highlights the labeled sample complexity benefits provided by it. For details as well as more finegrained analysis see <a href="https://arxiv.org/abs/1902.09229">the paper</a>.</p>

<h2 id="extensions-of-the-theoretical-analysis">Extensions of the theoretical analysis</h2>

<p>This conceptual framework not only allows us to reason about empirically successful variants of (1), but also leads to the design of new, theoretically grounded unsupervised objective functions. 
Here we give a high level view; details are in  <a href="https://arxiv.org/abs/1902.09229">our paper</a>.</p>

<p><em>A priori,</em> one might imagine that the log and exponentials in (1) have some information-theoretic interpretation; here we relate the functional form to the fact that logistic regression is going to be used in the downstream classification tasks. 
Analogously, if the classification is done via hinge loss, then (2) is true for a different unsupervised loss that uses a hinge-like loss instead. 
This objective, for instance, was used to learn image representations from videos by <a href="https://arxiv.org/abs/1505.00687">Wang and Gupta</a>. 
Also, usually in practice $k&gt;1$ negative samples are contrasted with each positive sample $(x,x^+)$ and the unsupervised objective looks like the $k$-class cross-entropy loss. 
We prove a statement similar to (2) for this setting, where the supervised loss now is the average $(k+1)$-way classification loss.</p>

<p>Finally, the framework provides guidelines for designing new unsupervised objectives when <em>blocks</em> of similar data are available (e.g., sentences in a paragraph). 
Replacing $f(x^+)$ and $f(x^-)$ in (1) with the average of the representations from the positive and the negative block respectively, we get a new objective which comes with stronger guarantees and better performance in practice. 
We experimentally verify the effectiveness of this variant in our paper.</p>

<h2 id="experiments">Experiments</h2>

<p>We report some controlled experiments to verify the theory. Lacking a canonical multiclass problem for text, we constructed a new 3029-class labeled dataset where a class is one of 3029 articles from Wikipedia,  and datapoints are one of $200$ sentences in these articles. Representations will be tested on a random binary classification task that involves two articles, where the labels of the data point is which of the two articles it belongs to. (A 10-way classification task is similarly defined.)  Datapoints for the test tasks will be held out while training representations. The class of sentence representation ${\mathcal F}$ is a simple multilayer architecture one based on Gated Recurrent Unit (GRU).</p>

<p>The supervised method for learning representations trains a multiclass classifier on the 3029-way task and the representation is taken from the layer before the final softmax output. This was the gold standard in above discussions.</p>

<p>The unsupervised method is fed pairs of similar data points generated according to our theory: similar data points are just pairs of sentences sampled from the same article. Representations are learnt by minimizing the above unsupervised loss objectives.</p>

<p style="text-align: center;">
<img width="60%" src="http://www.offconvex.org/assets/CURLexperiment.svg" />
</p>
<p>The highlighted parts in the table show that the unsupervised representations compete well with the supervised representations on the average $k$-way classification task ($k=2, 10$).</p>

<p>Additionally, even though not covered by our theory, the representation also performs respectably on the full  multiclass problem.
We find some support for a suggestion of our theory that the mean (centroid) of the unsupervised representations in each class should be good classifiers for average $k$-way supervised tasks. We find this to be true for unsupervised representations, and surprisingly for supervised representations as well.</p>

<p>The paper also has other experiments studying the effect of number of negative samples and larger blocks of similar data points, including experiments on the CIFAR-100 image dataset.</p>

<h2 id="conclusions">Conclusions</h2>
<p>While contrastive learning is a well-known <em>intuitive</em> algorithm, its practical success has been a mystery for theory. 
Our conceptual framework lets us formally show guarantees for representations learnt using such algorithms. 
While shedding light on such algorithms, the framework also lets us come up with and analyze variants of it. 
It also provides insights into what guarantees are provable and shapes the search for new assumptions that would allow stronger guarantees. 
While this is a first cut, possible extensions include imposing a metric structure among the latent classes.
Connections to meta-learning and transfer learning may also arise.
We hope that this framework influences and guides practical implementations in the future.</p></div>







<p class="date">
<a href="http://offconvex.github.io/2019/03/19/CURL/"><span class="datestr">at March 19, 2019 07:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/042">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/042">TR19-042 |  Determinant equivalence test over finite fields and over $\mathbf{Q}$ | 

	Ankit Garg, 

	Nikhil Gupta, 

	Neeraj Kayal, 

	Chandan Saha</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The determinant polynomial $Det_n(\mathbf{x})$ of degree $n$ is the determinant of a $n \times n$ matrix of formal variables. A polynomial $f$ is equivalent to $Det_n$ over a field $\mathbf{F}$ if there exists a $A \in GL(n^2,\mathbf{F})$ such that $f = Det_n(A \cdot \mathbf{x})$. Determinant equivalence test over $\mathbf{F}$ is the following algorithmic task: Given black-box access to a $f \in \mathbf{F}[\mathbf{x}]$, check if $f$ is equivalent to $Det_n$ over $\mathbf{F}$, and if so then output a transformation matrix $A \in GL(n^2,\mathbf{F})$. In Kayal (2012), a randomized polynomial time determinant equivalence test was given over $\mathbf{C}$. But, to our knowledge, the complexity of the problem over finite fields and over rationals was not well understood. 

In this work, we give a randomized $poly(n,\log |\mathbf{F}|)$ time determinant equivalence test over finite fields $\mathbf{F}$ (under mild restrictions on the characteristic and size of $\mathbf{F}$). Over rationals, we give an efficient randomized reduction from factoring square-free integers to determinant equivalence test for quadratic forms (i.e. the $n=2$ case), assuming GRH. This shows that designing a polynomial-time determinant equivalence test over rationals is a challenging task. Nevertheless, we show that determinant equivalence test over rationals is decidable: For bounded $n$, there is a randomized polynomial-time determinant equivalence test over rationals with access to an oracle for integer factoring. Moreover, for any $n$, there is a randomized polynomial-time algorithm that takes input black-box access to a rational polynomial $f$ and if $f$ is equivalent to $Det_n$ over rationals then it returns a $A \in GL(n^2,\mathbf{L})$ such that $f = Det_n(A \cdot \mathbf{x})$, where $\mathbf{L}$ is an extension field of $\mathbf{Q}$ of degree at most $n$. 

The above algorithms over finite fields and over rationals are obtained by giving a polynomial-time randomized reduction from determinant equivalence test to another problem, namely the full matrix algebra isomorphism problem. We also show a reduction in the converse direction which is efficient if $n$ is bounded. These reductions, which hold over any $\mathbf{F}$ (under mild restrictions on the characteristic and size of $\mathbf{F}$), establish a close connection between the complexity of the two problems. This then lead to our results via applications of known results on the full algebra isomorphism problem over finite fields and over $\mathbf{Q}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/042"><span class="datestr">at March 18, 2019 12:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4318994903152354716">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/03/third-poll-on-p-vs-np-and-related.html">Third Poll on P vs NP and related Questions is out now! And the winner is Harambe!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
I took a poll of the theory community (and others) about P vs NP and related issues in 2002, 2012, and 2019 (sorry its not an arithmetic  sequence --- read the third poll article to see why).  The 2002 and 2012 polls are on the web (see <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper1.pdf">here</a> and <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper2.pdf">here</a> ), and now the third poll is out and its <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper3.pdf">here</a> or <a href="https://dl.acm.org/citation.cfm?doid=3319627.3319636">here</a> . All three appear in Lane's Complexity Column in SIGACT News.<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/pollpaper1.pdf"></a><br />
<br />
I'll give some highlights and thought about the third poll, but for more read the article. Or read all three and see how opinions have changed over time.<br />
<br />
0) How many respondents: 100 the first time, and 152 the second time, 124 the third time.<br />
<br />
1) P≠NP is at about 80%. When restricted to people who have thought about the problem a lot (my judgement) then it goes to 99%. The strongest P≠NP is by Lance who says<br />
<br />
                                People who think P=NP are like people who believe Elvis is alive.<br />
<br />
I disagree. I think Elvis is alive and is trying to prove P=NP.<br />
<br />
2) When will it be solved? 66% thought it would be solved before 2100, a bit more than in prior years. But also more thought it would never be solved. Some commented that a computer might solve it.  I doubt that, but I do think this poll will be done by a computer in 10 years.<br />
<br />
3) Because I used Survey monkey (1) each question got more answers, and (2) most  questions got a forced YES or NO  so less funny comments or room for creative answers. People could still leave comments, and some did.<br />
<br />
4) Related to point (3): The last time I did the poll P=BPP was thought by everyone <i>who answered</i> <i>the question</i>. This year far more people answered it and quite a few thought P≠BPP. This may be because Survey monkey had a psychological affect of making people vote even if they didn't really know (people who have thought a lot about P vs NP  all thought P=BPP). Has  there been evidence that P≠BPP that I am unaware of? Or since there has not been that much progress on it maybe they are unequal.  10  years ago I would have thought we would have L=RL by now.<br />
<br />
5) The last time I did the poll 10 people thought factoring IS in P and the NSA or the KGB knows that. This time around nobody thought that. Why? Those 10 people have vanished mysteriously.<br />
<br />
6) Five people thought P vs NP will be resolved by Harambe. That is more than any person got.<br />
<br />
7)  Is this poll worth doing? I would say yes (gee, I have to having done his poll three times) because it is good to have an objective record of subjective opinion. <br />
<br />
8) I'll give some of my answers: P≠NP, Elvis is dead, and both will be proven in the year 2525. For more about the future see <a href="https://www.youtube.com/watch?v=yesyhQkYrQM">this</a>.<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/03/third-poll-on-p-vs-np-and-related.html"><span class="datestr">at March 17, 2019 10:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/041">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/041">TR19-041 |  Quantum hardness of learning shallow classical circuits | 

	Srinivasan Arunachalam, 

	Alex Bredariol Grilo, 

	Aarthi Sundaram</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper we study the quantum learnability of constant-depth classical circuits under the uniform distribution and in the distribution-independent framework of PAC learning.  In order to attain our results, we  establish connections between quantum learning and quantum-secure  cryptosystems. We then achieve the following results. 

1) Hardness of learning $AC^0$ and $TC^0$ under the uniform distribution. Our first result concerns the concept class $TC^0$ (resp. $AC^0$), the class of constant depth and polynomial-sized circuits with unbounded fan-in majority gates (resp. AND, OR, NOT gates). We show that if there exists no quantum polynomial time (resp. sub-exponential time) algorithm to solve the Learning with Errors (LWE) problem, then there exists no polynomial time quantum learning algorithm for $TC^0$ (resp. $AC^0$) under the uniform distribution (even with access to quantum membership queries). The main technique in this result uses explicit pseudo-random generators that are believed to be quantum-secure to construct concept classes that are hard to learn quantumly under the uniform distribution. 


2) Hardness of learning $TC^0_2$ in the PAC setting. Our second result shows that if there exists no quantum polynomial time algorithm for the LWE problem, then there exists no polynomial time quantum PAC learning algorithm for the class $TC^0_2$, i.e., depth-$2$ $TC^0$ circuits. The main technique in this result is to establish a connection between the quantum security of public-key cryptosystems and the learnability of a concept class that consists of decryption functions of the cryptosystem. 


This gives a strong conditional negative answer to one of the "Ten Semi-Grand Challenges for Quantum Computing Theory" raised by Aaronson, who asked if $AC^0$ and $TC^0$ can be PAC-learned in quantum polynomial time.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/041"><span class="datestr">at March 17, 2019 07:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
