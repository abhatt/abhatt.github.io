<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at July 26, 2020 10:23 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=3843">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/">Gradient descent for wide two-layer neural networks – II: Generalization and implicit bias</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">In this blog post, we continue our investigation of gradient flows for wide two-layer “relu” neural networks. In the <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">previous post</a>, Francis explained that under suitable assumptions these dynamics converge to global minimizers of the training objective. Today, we build on this to understand qualitative aspects of the predictor learnt by such neural networks. The content is mostly based on our recent joint work [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</p>



<h2>1. Generalization with weight decay regularization</h2>



<p class="justify-text">Let us start our journey with the comfortable case where the training objective includes an explicit <em>weight decay</em> regularization (i.e. \(\ell_2\)-regularization on the parameters). Using the notations of the previous post, this consists in the following objective function on the space of probability measures on \(\mathbb{R}^{d+1}\):  $$ \underbrace{R\Big(\int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w)\Big)}_{\text{Data fitting term}} + \underbrace{\frac{\lambda}{2} \int_{\mathbb{R}^{d+1}} \Vert w \Vert^2_2d\mu(w)}_{\text{Regularization}} \tag{1}$$ where \(R\) is the loss and \(\lambda&gt;0\) is the regularization strength. Remember that a  neural network of finite width with \(m\) neurons is recovered with an empirical measure \(\mu = \frac1m \sum_{j=1}^m\delta_{w_j}\), in which case this regularization is proportional to the sum of the squares of all the parameters \(\frac{\lambda}{2m}\sum_{j=1}^m \Vert w_j\Vert^2_2\).</p>



<p class="justify-text"><strong>Variation norm.</strong> In the previous post, we have seen that the Wasserstein gradient flow of this objective function — an idealization of the gradient descent training dynamics in the large width limit — converges to a global minimizer \(\mu^*\) when initialized properly. An example of an admissible initialization is the hidden weights \(b_j\) distributed according to the uniform distribution \(\tau\) on the unit sphere \(\mathbb{S}^{d-1}\subset \mathbb{R}^d\) and the output weights \(a_j\) uniform in \(\{-1,1\}\). What does this minimizer look like in predictor space when the objective function is as in Eq. (1) ? </p>



<p class="justify-text">To answer this question, we define for a predictor \(h:\mathbb{R}^d\to \mathbb{R}\), the quantity $$ \Vert h \Vert_{\mathcal{F}_1} := \min_{\mu \in \mathcal{P}(\mathbb{R}^{d+1})} \frac{1}{2} \int_{\mathbb{R}^{d+1}} \Vert w\Vert^2_2 d\mu(w) \quad \text{s.t.}\quad h = \int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w).\tag{2} $$ As the notation suggests, \(\Vert \cdot \Vert_{\mathcal{F}_1}\) is a norm in the space of predictors. It is known as the <em>variation norm</em> [<a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">2</a>, <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">3</a>]. We call \(\mathcal{F}_1\) the space of functions with finite norm, which is a Banach space. By construction, the learnt predictor \(h^* = \int \Phi(w)d\mu^*(w)\) is a minimizer of the \(\mathcal{F}_1\)-regularized regression: $$ \min_{h:\mathbb{R}^d\to \mathbb{R}} R(h) + \lambda \Vert h \Vert_{\mathcal{F}_1} \tag{3}.$$ This \(\mathcal{F}_1\)-norm regularization shares similarity with \(\ell_1\) regularization [<a href="https://arxiv.org/pdf/1412.6614.pdf">4</a>]. To see this, observe that the “magnitude” \(\vert a\vert \Vert b\Vert_2\) of a relu function \(x\mapsto a(b^\top x)_+\) with parameter \(w=(a,b)\) equals \(\Vert w\Vert^2_2/2\) if \(\vert a\vert = \Vert b\Vert_2\) and is smaller otherwise. Thus parameterizing the relus by their direction \(\theta = b/\Vert b\Vert_2\) and optimizing over their signed magnitude \(r(\theta) = a\Vert b\Vert_2\)  we have $$ \Vert h \Vert_{\mathcal{F}_1} = \inf_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).\tag{4}$$</p>



<p class="justify-text"><strong>Conjugate RKHS norm.</strong> The regression in the space \(\mathcal{F}_1\) is best understood when compared with the regression obtained by only training the output weights. We consider the same training dynamics with weight decay except that we fix the hidden weights to their initial value, where they are distributed according to the uniform distribution \(\tau\) on the sphere. In that case, the Wasserstein gradient flow also converges to the solution of a regularized regression as in Eq. (3) — this is in fact a convex problem —  but the regularizing norm is different and now defined as $$ \Vert h \Vert_{\mathcal{F}_2}^2 := \min_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert^2 d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).$$ We call \(\mathcal{F}_2\) the set of functions with finite norm. It can be shown to be a <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">Reproducing Kernel Hilbert Space</a> (RKHS), with kernel  $$ K(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+ d\tau(\theta),$$ which has a closed form expression [<a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">5</a>]. In this context, taking a finite width neural network corresponds to a random feature approximation of the kernel [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf">6</a>, <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines">7</a>].</p>



<p class="justify-text">Let us informally compare the properties of these spaces \(\mathcal{F}_1\) and \(\mathcal{F}_2\) (see [<a href="https://arxiv.org/abs/1412.8690">2</a>] for details):</p>



<ul class="justify-text"><li><strong>Approximation power.</strong> In high dimension, only very smooth functions have small \(\mathcal{F}_2\)-norm (in rough terms, the \(\lceil (d+3)/2\rceil\) first derivatives should be small). In contrast, there exists non-smooth functions with small \(\mathcal{F}_1\)-norm, an example being the relu function \(x\mapsto (\theta^\top x)_+\). Remarkably, if we define \(f(x)=g(Ux)\) where \(U\) is an orthogonal projection then \(\Vert f\Vert_{\mathcal{F}_1} \leq  \Vert g\Vert_{\mathcal{F}_2}\). This shows in particular that \(\mathcal{F}_1\) contains \(\mathcal{F}_2\) and that \(\mathcal{F}_1\) is <em>adaptive</em> to lower dimensional structures.</li><li><strong>Statistical complexity.</strong> It could be feared that the good approximation properties of \(\mathcal{F}_1\) come at the price of being “too large” as a hypothesis space, making it difficult to estimate a predictor in \(\mathcal{F}_1\) from few samples. But, as measured by their Rademacher complexities, the unit ball of \(\mathcal{F}_1\) is only \(O(\sqrt{d})\) larger than that of \(\mathcal{F}_2\). By going from \(\mathcal{F}_2\) to \(\mathcal{F}_1\), we thus add some nicely structured predictors to our hypothesis space, but not too much garbage that could fit unstructured noise.</li><li><strong>Generalization guarantees.</strong> By combining the two previous points, it is possible to prove that supervised learning in \(\mathcal{F}_1\) breaks the curse of dimensionality when the output depends on a lower dimensional projection of the input: the required number of training samples only depends mildly on the dimension \(d\).</li><li><strong>Optimization guarantees.</strong> However \(\mathcal{F}_1\) has a strong drawback : there is no known algorithm that solves the problem of Eq. (3) in polynomial time. On practical problems, gradient descent seems to behave well, but in general only qualitative results such as presented in the previous post are known. In contrast, various provably efficient algorithms can solve regression in \(\mathcal{F}_2\), which is a classical kernel ridge regression problem [Chap. 14.4.3, <a href="https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf">8</a>].</li></ul>



<p class="justify-text">In the plot below, we compare the predictor learnt by gradient descent for a 2-D regression with the square loss and weight decay, after training (a) both layers — which is regression in \(\mathcal{F}_1\) — or (b) just the output layer — which is regression in \(\mathcal{F}_2\). This already illustrates some distinctive features of both spaces, although the differences become more stringent in higher dimensions. In particular, observe that in (a) the predictor is the combination of few relu functions, which illustrates  the sparsifying effect of the \(L^1\)-norm in Eq. (4). To simplify notations, we do not include a bias/intercept in the formulas but our numerical experiments include it, so in this plot the input is of the form \(x=(x_1,x_2,1)\) and \(d=3\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="564" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/regularized-2.png" class="wp-image-4231" height="293" />Predictor learnt by the gradient flow on the square loss with weight decay, when training (a) both layers (b) only the output layer. The markers indicate the location of the training samples  \((x_i)_{i=1}^n\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_weightdecay.jl">[code]</a></figure></div>



<p class="justify-text">The qualitative picture is quite clear so far, but something is a bit unsettling: weight decay is often not needed to obtain a good performance in practice. Our line of reasoning however completely falls apart without such a regularization: if the objective function depends on the predictor only via its values on the training set, being a minimizer does not guarantee anything about generalization outside of the training set (remember that wide relu neural networks are <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximators</a>). Why does it still work in the unregularized case? There must be something in the algorithm…</p>



<h2>2. Implicit bias: linear classification</h2>



<p class="justify-text">This something is called the <em>implicit bias</em> : when there are several minimizers, the optimization algorithm makes a specific choice. In the unregularized case, the “quality” of this choice is a crucial property of an algorithm; much more crucial than, say, its convergence speed on the training objective. To gradually build our intuition of the implicit bias of gradient flows, let us put neural networks aside for a moment and consider, following Soudry, Hoffer, Nacson, Gunasekar and Srebro [<a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">9</a>], a linear classification task.</p>



<p class="justify-text"><strong>Gradient flow of the smooth-margin.</strong> Let \((x_i,y_i)_{i=1}^n\) be a training set of \(n\) pairs of inputs \(x_i\in \mathbb{R}^d\) and outputs \(y_i\in \{-1,1\}\) and let us choose the exponential loss. The analysis that follows also apply to the logistic loss (which is the same as the cross-entropy loss after a sigmoid non-linearity) because only the “tail” of the loss matters, but it is more straightforward with the exponential loss. In order to give a natural “scale” to the problem, we  renormalize the empirical risk by taking minus its logarithm and consider the concave objective $$ F_\beta(a) = -\frac{1}{\beta}\log\Big( \frac1n \sum_{i=1}^n \exp(-\beta y_i \ x_i^\top a) \Big).\tag{5}$$ </p>



<p class="justify-text">Here \(\beta&gt;0\) is a parameter that will be useful in a moment. For now, we take \(\beta=1\) and we note \(F(a)=F_1(a)\).  In this context, the <em>margin</em> of a vector \(a\in \mathbb{R}^d\) is the quantity \(\min_{i} y_i\ x_i^\top a\) which quantifies how far this linear predictor is from making a wrong prediction on the training set.  </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="453" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/max_margin-4.png" class="wp-image-4274" height="386" />The margin of the linear predictor \(x \mapsto a^\top x\) with parameters \(a \in \mathbb{S}^{d-1}\) is the smallest distance of a training point to the decision boundary. We show here the max-margin predictor.</figure></div>



<p class="justify-text">Obtained via simple manipulations, the inequalities  $$ \min_i y_i\ x_i^\top a \leq F_\beta(a) \leq \min_i y_i\ x_i^\top a +\frac{\log(n)}{\beta}, \tag{6}$$ suggest to call \(F_\beta\) the <em>smooth-margin</em> because, well, it is smooth and converges to the margin \(F_\infty(a) := \min_i y_i x_i^\top a\) as \(\beta\to \infty\). Let us look at the gradient flow in the ascent direction that maximizes the smooth-margin: $$ a'(t) = \nabla F(a(t))$$ initialized with \(a(0)=0\) (here the initialization does not matter so much). The path followed by this gradient flow is exactly the same as the gradient flow on the empirical risk: taking the logarithm only changes the time parameterization or, in practice, the step-size.</p>



<p class="justify-text"><strong>Convergence to the max-margin.</strong> Assume that the data set is linearly separable, which means that the \(\ell_2\)-max-margin $$ \gamma := \max_{\Vert a\Vert_2 \leq 1} \min_i y_i x_i^\top a$$ is positive. In this case \(F\) is unbounded (indeed \(\lim_{\alpha \to \infty} F(\alpha a) =\infty\) whenever \(a\)  has a positive margin) and thus \(a(t)\) diverges. This is not an issue as such, since for classification, only the sign of the prediction matters.  This just means that the relevant question is not “where does \(a(t)\) converge?” but rather “towards which direction does it diverge?”. In other words, we are interested in the limit of \(\bar a(t):= a(t)/\Vert a(t)\Vert_2\) (in convex analysis, this is called the <em>cosmic limit</em> of \(a(t)\) [Chap. 3, <a href="https://www.springer.com/gp/book/9783540627722">10</a>], isn’t it beautiful ?).</p>



<p class="justify-text">The argument that follows is adapted from [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>] and can be traced back to [<a href="http://proceedings.mlr.press/v28/telgarsky13-supp.pdf">13</a>] for coordinate ascent. It can be shown by looking at the structure of the gradient (see the end of the blog post) that \(\Vert \nabla F(a)\Vert_2\geq \gamma\) for all \(a\in \mathbb{R}^d\). By the inequality of Eq. (6) and the gradient flow property \(\frac{d}{dt}F(a(t))=\Vert \nabla F(a(t))\Vert_2^2\), it follows $$\begin{aligned}\min_i y_i x_i^\top a(t) \geq F(a(t)) \  – \log(n) \geq \gamma \int_0^t \Vert \nabla F(a(s))\Vert_2ds -\log (n).\end{aligned}$$  For \(t&gt; \log(n)/\gamma^2\), this lower bound is positive. We can then divide the left-hand side by \(\Vert a(t)\Vert_2\) and the right-hand side by the larger quantity \(\int_0^t \Vert\nabla F(a(s))\Vert_2ds\), and we get $$\min_i y_i x_i^\top \bar a(t) \geq \gamma -\frac{\log(n)}{\int_0^t \Vert\nabla F(a(s))\Vert_2ds} \geq \gamma -\frac{\log(n)}{\gamma t}.$$ This shows that the margin of \(\bar a(t) := a(t)/\Vert a(t)\Vert_2\) converges to the \(\ell_2\)-max-margin at a rate \(\log(n)/\gamma t\). That’s it, the implicit bias of this gradient flow is exposed!</p>



<p class="justify-text"><strong>Stability to step-size choice.</strong> To translate this argument to discrete time, we need decreasing step-sizes of order \(1/\sqrt{t}\) which deteriorates the convergence rate to \(\tilde O(1/\sqrt{t})\), see [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>]. In [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>], we proposed a different proof strategy (based on an online optimization interpretation of \(\bar a(t)\), as below) which recovers the same convergence rate \(O(1/\sqrt{t})\) with <em>exponentially larger</em> step-sizes. This suggests that these diverging trajectories are extremely robust to the choice of step-size.</p>



<p class="justify-text"><strong>Illustration. </strong>In the figure below, we plot on the left the evolution of the parameter \(a(t)\) and on the right the predictor \(x\mapsto (x,1)^\top a(t)\) with \(x\in \mathbb{R}^2\). In parameter space, we apply the hyperbolic tangent to the radial component which allows to easily visualize diverging trajectories. This way, the unit sphere represents the <em>horizon</em> of \(\mathbb{R}^d\), i.e., the set of directions at infinity [Chap. 3 in <a href="https://www.springer.com/gp/book/9783540627722">9</a>]. We will use the same convention in the other plots below.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="586" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/linear.gif" class="wp-image-4106" height="288" />Implicit bias of gradient descent for a linear classification task with the exponential loss: (left) parameter space, (right) predictor space.</figure></div>



<h2>3. Implicit bias:  training only the output layer</h2>



<p class="justify-text">Despite its apparently restrictive setting, the previous result already tells us something about wide neural networks. Consider the situation touched upon earlier where we only train the output weights \(a_j\) and the hidden weights \(b_j\) are picked uniformly at random on the sphere. This corresponds to learning a linear classifier on top of the random feature \([(b_j^\top x)_+]_{j=1}^m\). </p>



<p class="justify-text">As we have just shown, if the training set is separable, the normalized gradient flow of the unregularized exponential loss (or logistic loss) converges to a solution to  $$ \max_{\Vert a\Vert_2 \leq 1}\min_i y_i \sum_{j=1}^m  a_j (b_j^\top x_i)_+.$$ </p>



<p class="justify-text">This is a random feature approximation for the unregularized kernel support vector machine problem in the RKHS \(\mathcal{F}_2\), which is recovered in the large width limit \(m\to \infty\):  $$\max_{\Vert h\Vert_{\mathcal{F}_2}\leq 1} \min_i y_i h(x_i).$$ Notice that if \(m\) is large enough, the linear separability assumption is not even needed anymore, because any training set is separable in \(\mathcal{F}_2\) (at least if all \(x_i\)s are distinct and if we do not forget to include the bias/intercept).</p>



<p class="justify-text"><strong>Illustration.</strong> In the animation below, we plot on the left the evolution of the parameters and on the right the predictor for a 2-D classification task. In parameter space, each particle represents a neuron: their direction is fixed, their distance to \(0\) is their absolute weight and the color is red (+) or blue (-) depending on the sign of the weight. As above, the unit sphere is at infinity and the particles diverge. In predictor space, the markers represent the training samples of both classes, the color shows the predictor and the black line is the decision boundary. The fact that the predictor has a smooth decision boundary is in accordance with the properties of \(\mathcal{F}_2\) given above. </p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://francisbach.com/wp-content/uploads/2020/07/film_output_comp-1.gif" alt="" class="wp-image-4275" />Gradient descent on the output layer of a two-layer relu neural network with the exponential loss: (left) parameter space, (right) predictor space. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_output.jl">[code]</a></figure></div>



<h2>4. Implicit bias: 2-homogeneous linear classifiers</h2>



<p class="justify-text">Although the analyses where neural networks behave like kernel methods are pleasant for us theoreticians because we are in conquered territory, they miss essential aspects of neural networks such as their adaptivity and their ability to learn a representation. Let us see if we can characterize the implicit bias of the gradient flow of the unregularized exponential loss when training <em>both</em> layers of the neural network.</p>



<p class="justify-text"><strong>A 2-homogeneous linear model.</strong> From an optimization point of view, an important property of two layer relu neural networks is that \(\Phi(\alpha w)= \alpha^2 \Phi(w)\) for all \(\alpha&gt;0\), i.e., they are positively 2-homogeneous in the training parameters. In contrast, a linear model is 1-homogeneous in the parameters. This seemingly little difference leads to drastic changes in the gradient flow dynamics. </p>



<p class="justify-text">Let us again build our intuition with a simplified model that captures key aspects of the dynamics, namely the linear classification setting of above. This time, we take any initialization \(r(0)\in \mathbb{R}^d\) with positive entries and the gradient flow in the ascent direction of the function \( F(r\odot r)\) where \(\odot\) is the pointwise product between two vectors and \(F\) is defined in Eq. (5). This is just a trick to obtain a 2-homogeneous parameterization of a linear model. This gradient flow satisfies $$ r'(t) = 2 r(t)\odot \nabla F(r(t)\odot r(t)).$$ </p>



<p class="justify-text"><strong>Normalized dynamics.</strong> Let us define \(\bar a(t):=(r(t)\odot r(t))/\Vert r(t)\Vert_2^2\) the normalized predictor associated to our dynamics which, by definition, belongs to the simplex \(\Delta_d\), i.e., the set of nonnegative vectors in \(\mathbb{R}^d\) that sum to one. Using the fact that \(\nabla F(\beta a) = \nabla F_\beta (a)\) for all \(\beta&gt;0\), we obtain $$\begin{aligned} \bar a'(t) &amp;= 2\frac{r(t)\odot r'(t)}{\Vert r(t)\Vert_2^2} -2 (r(t)^\top r'(t))\frac{r(t)\odot r(t)}{\Vert r(t)\Vert_2^4}\\ &amp;=4\bar a(t) \odot \nabla F_{\Vert r(t)\Vert_2^2}(\bar a(t))\ – \alpha(t) \bar a(t)\end{aligned}$$ where \(\alpha(t)\) is the scalar such that \(\sum_{i=1}^d a’_i(t) =0\). Online optimization experts might have recognized that this is (continuous time) <em>online mirror ascent in the simplex</em> for the sequence of smooth-margin functions \(F_{\Vert r(t)\Vert_2^2}\). Notice in particular the multiplicative updates: they correspond to the entropy mirror function, and they are particularly well suited for optimization in the high dimensional simplex [Chap.4, <a href="https://arxiv.org/pdf/1405.4980.pdf">14</a>].</p>



<p>What do we learn from this reformulation? </p>



<ul class="justify-text"><li>We can prove (by similar means) that if the data set is linearly separable then \(\Vert r(t)\Vert_2^2\) diverges. So the sequence of functions \(F_{\Vert r\Vert_2^2}\) converges to the margin \(F_\infty\) which means that \(\bar a(t)\) just ends up optimizing the function \(F_\infty\). As a consequence, we have $$\lim_{t\to \infty} y_i x_i^\top \bar a(t) = \max_{a\in \Delta_d} \min_{i} y_i x_i^\top a.$$ This exposes another implicit bias of gradient flow. Notice the key difference with the implicit bias obtained with a linear parameterization: we obtain here the \(\ell_1\)-max-margin (over classifiers with non-negative entries) instead of the \(\ell_2\)-max-margin.  </li><li>Beyond exposing the implicit bias, this reformulation shows that \(\bar a(t)\) implicitly optimizes a sequence of smooth objectives which converge to the margin \(F_\infty\). Unknowingly, we have recovered the well-principled optimization method that consists in approximating a non-smooth objective with smooth functions [<a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">15</a>].</li><li>While the conclusion above was only formal, this point of view leads to rigorous proofs of convergence and convergence rates in discrete time in \(\tilde O(1/\sqrt{t})\) with a step-size in \(O(1/\sqrt{t})\), by  exploiting tools from online optimization, see [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</li></ul>



<h2>5. Implicit bias: fully trained 2-layer neural networks</h2>



<p class="justify-text">Once again this argument about linear predictors applies to neural networks: if we train both layers but only the magnitude of the hidden weights and not their direction, then this is equivalent to learning a 2-homogeneous linear model on top of the random feature \([  a_j(0) (x_i^\top b_j(0))_+]_{j=1}^m\). If each feature appears twice with opposite signs — which is essentially the case in the large width limit — then the simplex constraint can be equivalently replaced by an \(\ell_1\)-norm constraint on the weights. Recalling the definition of the \(\mathcal{F}_1\)-norm from Eq. (4), we thus obtain that, in the infinite-width limit, the normalized predictor converges to a solution to $$ \max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">This result is correct, but it is not relevant. In contrast to functions in \(\mathcal{F}_2\), functions in \(\mathcal{F}_1\) <em>can not</em> in general be approximated with few <em>random</em> features in high dimension. In fact, lower bounds that are exponential in the dimension exist in certain settings [Sec. X, <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">16</a>]. They can be approximated with a small number of features but those need to be data-dependent: in that sense, it is necessary to learn a representation – here,  a distribution over the hidden weights — in order to learn in \(\mathcal{F}_1\). </p>



<p class="justify-text">This raises the following question: do we obtain the same implicit bias when training both layers of the neural network, without fixing the direction of the input weights? In the following result, which is the main theorem of our paper [<a href="https://arxiv.org/abs/2002.04486">1</a>], we answer by the affirmative.</p>



<p class="justify-text"><strong>Theorem</strong> (C. and Bach [<a href="https://arxiv.org/abs/2002.04486">1</a>], informal). Assume that for some \(\sigma&gt;0\), the hidden weights \(b_j\) are initialized uniformly on the sphere of radius \(\sigma\) and the output weights \(a_j\) are uniform in \(\{-\sigma,\sigma\}\). Let \(\mu_t\) be the Wasserstein gradient flow for the unregularized exponential loss and \(h_t = \int \Phi(w)d\mu_t(w)\) be the corresponding dynamics in predictor space. Under some technical assumptions, the normalized predictor \(h_t/\Vert h_t\Vert_{\mathcal{F}_1}\) converges to a solution to the \(\mathcal{F}_1\)-max-margin problem: $$\max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">Giving an idea of proof would be a bit too technical for this blog post, but let us make some remarks:</p>



<ul class="justify-text"><li>The strength of this result is that although this dynamics could get trapped towards limit directions which are not optimal, this choice of initialization allows to avoid them all and to only converge to <em>global</em> minimizers of this max-margin problem. The principle behind this is similar to the global convergence result in the previous blog post. </li><li>The fact that optimizing on the direction of the hidden weights is compatible with the global optimality conditions of the \(\mathcal{F}_1\)-max-margin problem is very specific to the structure of positively 2-homogeneous problems, and should not be taken for granted for other architectures of neural networks.</li><li>Although at a formal level this result works for any initialization that is diverse enough (such as the standard Gaussian initialization), the initialization proposed here yields dynamics with a better behavior for relu networks: by initializing the hidden and output weights with equal norms – a property preserved by the dynamics – we avoid some instabilities in the gradient. Also notice that this result applies to any scale \(\sigma&gt;0\) of the initialization (we’ll see an intriguing consequence of this in the next section).</li></ul>



<p class="justify-text"><strong>Illustration.</strong> In the figure below, we plot the training dynamics when both layers are trained. In parameter space (left), each particle represents a neuron: its position is \(\vert a_j\vert b_j\) and its color depends on the sign of \(a_j\).  Here again the unit sphere is at infinity. The inactive neurons at the bottom correspond to those with a bias that is “too negative” at initialization. We observe that all the other neurons gather into few clusters: this is the sparsifying effect of the \(L^1\)-norm in Eq. (4). In predictor space, we obtain a polygonal classifier, as expected for a \(\mathcal{F}_1\)-max-margin classifier. See the paper [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>] for experiments that illustrate the strengths of this classifier in terms of generalization.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://francisbach.com/wp-content/uploads/2020/07/film_both_comp.gif" alt="" class="wp-image-4194" />Training both layers of a wide relu neural network with the exponential loss: (left) space of parameters, (right) space of predictors. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_bothlayers.jl">[code]</a></figure></div>



<h2>6. Lazy regime and the neural tangent kernel</h2>



<p class="justify-text">This blog post would not be complete without mentioning the <em>lazy regime</em>. This is yet another kind of implicit bias which, in our context, takes place when at initialization the weights have a large magnitude and the step-size is small. It was first exhibited in [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] for deep neural networks.</p>



<p class="justify-text"><strong>Lazy training via scaling.</strong> This phenomenon is in fact very general so let us present it with a generic parametric predictor \(h(W)\) with differential \(Dh(W)\). We introduce a scaling factor \(\alpha&gt;0\) and look at the gradient flow of \(F(W) := R(\alpha h(W))\) with a step-size \(1/\alpha^2\), that is $$ W'(t) = \ – \frac{1}{\alpha}Dh(W(t))^\top \nabla R(\alpha h(W(t))),$$ with initialization \(W(0)\). In terms of the predictor \(\alpha h(W)\), this yields the dynamics $$\frac{d}{dt} \alpha h(W(t)) = \ – Dh(W(t))Dh(W(t))^\top \nabla R(\alpha h(W(t)).$$ </p>



<p class="justify-text">Lazy training [<a href="https://arxiv.org/pdf/1812.07956.pdf">18</a>] happens when we take \(\alpha\) large while making sure that \(\alpha h(W(0))\) stays bounded. In this case, we see that the parameters change at a rate \(O(1/\alpha)\), while the predictor changes at a rate independent of \(\alpha\). On any bounded time interval, in the limit of  a large \(\alpha\), the parameters only move infinitesimally, while the predictor still makes significant progress, hence the name <em>lazy training</em>.</p>



<p class="justify-text"><strong>Equivalent linear model.</strong> Since the parameters hardly move, if we assume that \(Dh(W(0))\neq 0\) then we can replace the map \(h\) by its linearization \(W \mapsto h(W(0))+Dh(W(0))(W-W(0))\). This means that the training dynamics essentially follows the gradient flow of the  objective $$ R\big ( \alpha h(W(0)) + \alpha Dh(W(0))(W-W(0)) \big)$$ which is a convex function of \(W\) as soon as \(R\) is convex.</p>



<p class="justify-text">If this objective admits a minimizer that is not too far away from \(W(0)\), then \(W(t)\) converges to this minimizer. If in contrast all  the minimizers are too far away (think of the exponential loss where they are at infinity), then the parameters will eventually move significantly and the lazy regime is just a transient regime in the early phase of training.  Of course, all these behaviors can be quantified and made more precise, because this phenomenon brings us back to the realm of linear models. </p>



<p class="justify-text">What all of this has to do with two-layer neural networks? As it happens, this scale factor appears implicit in various situations for these models; let us detail two of them. </p>



<p class="justify-text"><strong>Neural networks with \(1/\sqrt{m}\) scaling.</strong> For two-layer neural networks, lazy training occurs if we define \(h = \frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j)\) instead of \(h=\frac{1}{m} \sum_{j=1}^m \Phi(w_j)\) before taking the infinite width limit. Indeed:</p>



<ul class="justify-text"><li>This induces a scaling factor \(\alpha = \sqrt{m} \to \infty\) compared to \(1/m\) which, as we have already seen, is the “correct” scaling that leads to a non-degenerate dynamics in parameter space as \(m\) increases. </li><li>Moreover, by the central limit theorem,  \(\frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j(0)) = O(1)\) for typical random initializations of the parameters. So the initial predictor stays bounded.</li></ul>



<p class="justify-text">To take the Wasserstein gradient flow limit, the step-size has to be of order \(m\) (see previous blog post). So here we should take a step-size of order \(m/\alpha^2 = 1\). With such a step-size, all the conditions for lazy training are gathered when \(m\) is large. Intuitively, each neuron only moves infinitesimally, but they collectively produce a significant movement in predictor space.</p>



<p class="justify-text"><strong>Neural networks with large initialization.</strong> Coming back to our scaling in \(1/m\) and our Wasserstein gradient flow that is obtained in the large width limit, there is another way to enter the lazy regime: by increasing the variance of the initialization. </p>



<p class="justify-text">To see this, assume that \(h\) is a positively \(p\)-homogeneous parametric predictor, which means that \(h(\sigma W)=\sigma^p h(W)\) for all \(\sigma&gt;0\) and some \(p&gt;1\) (remember that this is true with \(p=2\) for our two-layer relu neural network). Take an initialization of the form \(W(0) = \sigma \bar W_0\) where \(\sigma&gt;0\) and \(h(\bar W_0)=0\) (which is also satisfied for our infinite width neural networks with the initialization considered previously). Consider the gradient flow of \(R(h(W))\) with step-size \(\sigma^{2-2p}\).   By defining \(\bar W(t) = W(t)/\sigma\) and using the fact that the differential of a p-homogeneous function <a href="https://en.wikipedia.org/wiki/Homogeneous_function#Positive_homogeneity">is (p-1)-homogeneous</a>, we have, on the one hand $$ \bar W'(t) = -\sigma^{-p} Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))), $$ and on the other hand $$\frac{d}{dt} \sigma^p h(\bar W(t)) =\  – Dh(\bar W(t))Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))).$$ So in terms of the dynamics \(\bar W(t)\), the situation is exactly equivalent to having a scaling factor \(\alpha=\sigma^p\). This implies that as the magnitude \(\sigma\) of the initialization increases, we enter the lazy regime, provided the step-size is of order \(\sigma^{2-2p}\).</p>



<p class="justify-text"><strong>Neural tangent kernel. </strong>What does the lazy regime tell us about the learnt predictor for two-layer neural networks? Assuming for simplicity that the predictor at initialization is \(0\), this regime amounts to learning a linear model on top of the feature \([(b_j^\top x)_+]_{j=1}^m\) — the derivative with respect to the output weights — concatenated with the feature \([x a_j 1_{b_j^\top x &gt; 0} ]_{j=1}^m\)  — the derivative with respect to the input weights. Compared to training only the output layer, this thus simply adds some features. </p>



<p class="justify-text">Assume for concreteness, that at initialization the hidden weights \(b_j\) are uniform on a sphere of large radius \(\sigma&gt;0\) and the output weights are uniform on \(\{-\kappa\sigma, \kappa\sigma\}\) where \(\kappa\geq 0\). For a large width and a large \(\sigma\), we enter the lazy regime which amounts to learning in a RKHS — let us call it \(\mathcal{F}_{2,\kappa}\) — that is slightly different from \(\mathcal{F}_2 = \mathcal{F}_{2,0}\), since its kernel \(K_\kappa\) contains another term: $$ K_\kappa(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+d\tau(\theta) + \kappa^2 \int_{\mathbb{S}^{d-1}} (x^\top x’) 1_{\theta^\top x &gt; 0}1_{\theta^\top x’ &gt; 0}d\tau(\theta). $$</p>



<p class="justify-text">This kernel is called the Neural Tangent Kernel [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] and the properties of the associated RKHS have been studied in [<a href="https://arxiv.org/pdf/1904.12191.pdf">19</a>, <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels.pdf">20</a>], where it is shown to include functions that are slightly less smooth than those of \(\mathcal{F}_2\) when \(\kappa\) increases. This is illustrated in the plot below, obtained by training a wide neural network with \(\sigma\) large (to reach the lazy regime) on the square loss, and various values of \(\kappa\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="574" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/interp-4.png" class="wp-image-4213" height="287" />1-D regression with a wide two-layer relu neural network (gradient descent on square loss, in the lazy regime) with 4 training samples (black dots). At initialization, output weights have \(\kappa\) times the (large) magnitude of the hidden weights. This implicitly solves kernel ridgeless regression for a kernel that depends on \(\kappa\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_NTK.jl">[code]</a></figure></div>



<p class="justify-text"><strong>Two implicit biases in one shot.</strong> The attentive reader might have noticed that for large initialization scale \(\sigma\gg 1\), when training both layers on the unregularized exponential loss, two of our analyses apply:  lazy training — that leads to a max-margin predictor in \(\mathcal{F}_{2,\kappa}\) — and the asymptotic implicit bias — that leads to a max-margin predictor in \(\mathcal{F}_{1}\).  So, where is the catch? </p>



<p class="justify-text">There is none! Since the minimizers of this loss are at infinity, the lazy regime is just a transient phase and we will observe both implicit biases along the training dynamics! Take a look at the video below: we observe that in early phases of training, the neurons do not move while learning a smooth classifier — this is the lazy regime and the classifier approaches the \(\mathcal{F}_{2,\kappa}\)-max-margin classifier. In later stages of training, the neurons start moving and the predictor converges to a \(\mathcal{F}_1\)-max-margin classifier as stated by the main theorem. The predictor jitters a little bit during training because I have chosen rather aggressive step-sizes.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large"><img src="https://francisbach.com/wp-content/uploads/2020/07/film_lazy2sparse_ns_comp-1.gif" alt="" class="wp-image-4219" />Training both layers with gradient descent for the unregularized exponential loss. The only difference with the previous video is that at initialization the variance \(\sigma^2\) is larger and the step-size smaller \(\approx \sigma^{-2}\). First the network learns a classifier in the lazy regime (a kernel max-margin classifier) and eventually converges to the \(\mathcal{F}_1\)-max-margin classifier.</figure></div>



<h2>Discussion</h2>



<p class="justify-text">In this blog post, I described how analyses of the training dynamics can help us understand the properties of the predictor learnt by neural networks even in the absence of an explicit regularization. Already for the simplest algorithm one can think of — gradient descent — we have found a variety of behaviors depending on the loss, the initialization or the step-size. </p>



<p class="justify-text">To achieve this description, the infinite width limit is of great help. It allows to obtain synthetic and precise characterizations of the learnt predictor, that can be used to derive generalization bounds. Yet, there are many interesting non-asymptotic effects caused by having a finite width.  In that sense, we were only concerned with the end of the curve of double descent [<a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">21</a>].</p>



<h2>References</h2>



<p class="justify-text">[1] Lénaïc Chizat, Francis Bach. <a href="https://arxiv.org/pdf/2002.04486.pdf">Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss.</a> <em>To appear in Conference On Learning Theory</em>, 2020.<br />[2] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the curse of dimensionality with convex neural networks.</a> <em>The Journal of Machine Learning Research</em>, <em>18</em>(1), 629-681, 2017.<br />[3]  Vera Kurková, Marcello Sanguineti. <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">Bounds on rates of variable-basis and neural-network approximation.</a> <em>IEEE Transactions on Information Theory</em>, 47(6):2659-2665, 2001.  <br />[4] Behnam Neyshabur, Ryota Tomioka, Nathan Srebro. <a href="https://arxiv.org/pdf/1412.6614.pdf">In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning.</a> <em>ICLR (Workshop)</em>. 2015.<br />[5] Youngmin Cho, Lawrence K. SAUL.  <a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">Kernel methods for deep learning.</a> <em>Advances in neural information processing systems</em>. 342-350, 2009.<br />[6] Radford M. Neal. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf"><em>Bayesian learning for neural networks</em>.</a> Springer Science &amp; Business Media, 2012.<br />[7] Ali Rahimi, Benjamin Recht. <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">Random features for large-scale kernel machines.</a> <em>Advances in neural information processing systems</em>. 1177-1184, 2008.<br />[8] Kevin P. Murphy. Machine Learning: A Probabilistic Perspective. <em>The MIT Press</em>, 2012<br />[9] Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar, Nathan Srebro. <a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">The Implicit Bias of Gradient Descent on Separable Data.</a><em> The Journal of Machine Learning Research</em>, <em>19</em>(1), 2822-2878, 2018.<br />[10] R. Tyrrell Rockafellar, Roger J-B. Wets. <a href="https://www.springer.com/gp/book/9783540627722"><em>Variational analysis</em>.</a> Springer Science &amp; Business Media, 2009.<br />[11] Suriya Gunasekar,  Jason D. Lee, Daniel Soudry, Nathan Srebro.  <a href="https://par.nsf.gov/servlets/purl/10107856">Characterizing implicit bias in terms of optimization geometry.</a> <em>International Conference on Machine Learning</em>, 2018.<br />[12] Ziwei Ji, Matus Telgarsky. <a href="https://arxiv.org/pdf/1803.07300.pdf">Risk and parameter convergence of logistic regression.</a> 2018.<br />[13] Matus Telgarsky. <a href="https://arxiv.org/abs/1303.4172">Margins, Shrinkage, and Boosting.</a> <em>International Conference on Machine Learning</em>, 307-315, 2013.<br />[14] Sébastien Bubeck. <a href="https://arxiv.org/pdf/1405.4980.pdf">Convex Optimization: Algorithms and Complexity.</a> Foundations and Trends in Machine Learning, 8(3-4):231-357, 2015.<br />[15] Yuri Nesterov. <a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">Smooth minimization of non-smooth functions.</a> <em>Mathematical programming</em>, 103(1):127-152, 2005.<br />[16] Anrew R. Barron. <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">Universal approximation bounds for superpositions of a sigmoidal function.</a> <em>IEEE Transactions on Information theory. </em>39(3), 930-945, 1993.<br />[17] Jacot, Arthur, Franck Gabriel, Clément Hongler. <a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">Neural tangent kernel: Convergence and generalization in neural networks.</a> <em>Advances in neural information processing systems.</em> 8571-8580, 2018.<br />[18] Lénaïc Chizat, Édouard Oyallon, Francis Bach. <a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">On lazy training in differentiable programming.</a> <em>Advances in Neural Information Processing Systems.</em> 2937-2947, 2019.<br />[19] Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, Andrea Montanari. <a href="https://arxiv.org/pdf/1904.12191.pdf">Linearized two-layers neural networks in high dimension.</a> To appear in <em>Annals of Statistics</em>. 2019.<br />[20] Alberto Bietti, Julien Mairal. <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels">On the Inductive Bias of Neural Tangent Kernels</a>. <em>Advances in Neural Information Processing Systems.</em> p. 12893-12904, 2019.<br />[21] Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal. <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">Reconciling modern machine-learning practice and the classical bias–variance trade-off.</a> <em>Proceedings of the National Academy of Sciences.</em> <em>116</em>(32), 15849-15854, 2019.</p>



<h3>Lower bound on the gradient norm for linear classification with the exponential loss</h3>



<p class="justify-text">In the context of Section 2, we want to prove that \(\Vert \nabla F(a)\Vert_2\geq \gamma\). For this, let \(Z\in \mathbb{R}^{n\times d}\) be the matrix with rows \(y_i x_i\) and let \(\Delta_n\) be the simplex in \(\mathbb{R}^n\). We have by duality $$ \gamma = \max_{\Vert a\Vert_2\leq 1}\min_{p\in \Delta_n} p^\top Z a =   \min_{p\in \Delta_n} \max_{\Vert a\Vert_2\leq 1} a^\top Z^\top p = \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 .$$  Also, notice that \(\nabla F(a) = Z^\top p\) with \(p_i = \frac{e^{-y_ix_i^\top a}}{\sum_{j=1}^n e^{-y_{j}x_{j}^\top a}}\). Since \(p \in \Delta_n\), we conclude that \(\Vert \nabla F(a)\Vert_2\geq \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 = \gamma\).</p></div>







<p class="date">
by Lénaïc Chizat <a href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/"><span class="datestr">at July 13, 2020 07:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=188">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/">Virtual STOC 2020 – Behind the Screens</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have gone, and despite many moving parts, there were minimal technical difficulties.</p>



<p>The guide is available here: <a href="https://docs.google.com/document/d/1nzyvfdsXLzqYXxxdjw1y_OHAYwGolHCZUkRVmlxG9BE/edit?ts=5efa758c" target="_blank" rel="noreferrer noopener">Virtual STOC 2020 – Behind the Screens</a>.</p>



<p>If you have any questions or comments, feel free to comment below, or join in the conversation on <a href="https://twitter.com/thegautamkamath/status/1277959908168695808">Twitter</a>.</p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/"><span class="datestr">at June 30, 2020 01:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=180">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/">STOC 2020 Goes Virtual!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Starting on Monday, STOC is joining the trend of conferences going online, I believe the biggest theory conference to do so thus far. Given my experience with <a href="https://sites.google.com/site/plustcs/">TCS+</a>, I volunteered to lend a hand with the organization and logistics. It’s been a journey (with some <a href="https://twitter.com/thegautamkamath/status/1273055827092549634">unusual technical challenges</a>), but I think we have something which I hope will be engaging and generally a lot of fun. In addition to the typical academic component, we also have a social component planned as well. We learnt from the work of others, including the <a href="https://www.acm.org/virtual-conferences">ACM virtual conferences guide</a>, <a href="https://iclr.cc/Conferences/2020">ICLR 2020</a>, and <a href="https://www.daniellitt.com/blog/2020/4/20/wagon-lessons-learned">WAGON</a>. I may make some version of our logistics docs available to others after the conference, so others can learn from our experience as well. Anyway, read on for an announcement from me and the other General Chairs, Konstantin Makarychev, Yury Makarychev, and Madhur Tulsiani. See also the <a href="http://acm-stoc.org/stoc2020/">main STOC page</a> for a more complete list of credits.</p>



<hr class="wp-block-separator" />



<p>Dear fellow theorists,</p>



<p>As you already know, STOC 2020 this year will be a virtual conference. If you are interested in attending the conference, but haven’t registered yet, <a href="http://www.cvent.com/events/52nd-annual-acm-symposium-on-theory-of-computing-stoc-2020-/event-summary-ea5fa7861d1a476d82bc10f667a1c0f4.aspx">please do so soon</a> (students: $25, regular: $50). This will help us ensure we have capacity for various online events. </p>



<p>Upon registration, you should receive a confirmation email from CVENT, also containing access information for various conference events. Also, if you are a student looking to register for STOC but the cost is a burden, please email us at <a href="mailto:stoc2020@ttic.edu">stoc2020@ttic.edu</a>.</p>



<p><strong>How will the conference work?</strong></p>



<ul><li><strong>Videos</strong>: The videos for all conference talks are now available on YouTube, and can be accessed through the links in the <a href="http://acm-stoc.org/stoc2020/STOCprogram.html">conference program</a>. Registration is <em>not required</em> to view the talks on Youtube.</li></ul>



<ul><li><strong>Slack</strong>: The conference has a Slack workspace, with one channel for every paper and workshop, and additional channels for information, announcements, social events, help, etc. The invitations for the Slack workspace will be sent to registered participants. Authors are also encouraged to monitor the channels for their papers. All access information for the conference will also be available here. The workspace is currently active, and will remain active for at least one week after the conference.</li></ul>



<ul><li><strong>Zoom sessions</strong>: The conference will feature Zoom sessions with short presentations by the speakers. The total time for each paper is 10 minutes. Given that participants have access to the full talks by the speakers on Youtube, these can be thought of as being analogues of poster sessions. The workshops will also be held as separate sessions. The links for the Zoom session via information in the confirmation email.</li></ul>



<ul><li><strong>Social events</strong>: The conference will include junior/senior “lunches”, breakout tables for impromptu and scheduled hangouts, and a group event using <a href="https://gather.town">gather.town</a>. The timings for the events can be found in the conference program. Sign-up links for various events will be sent to all registered participants – please do sign-up soon!</li></ul>



<p>See you all at (virtual) STOC 2020. Please do let us know if you have any questions or suggestions.</p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/06/19/stoc-2020-goes-virtual/"><span class="datestr">at June 19, 2020 08:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=2566">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">Gradient descent for wide two-layer neural networks – I : Global convergence</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">Supervised learning methods come in a variety of flavors. While local averaging techniques such as <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">nearest-neighbors</a> or <a href="https://en.wikipedia.org/wiki/Decision_tree_learning">decision trees</a> are often used with low-dimensional inputs where they can adapt to any potentially non-linear relationship between inputs and outputs, methods based on empirical risk minimization are the most commonly used in high-dimensional settings. Their principle is simple: optimize the (potentially regularized) risk on training data over prediction functions in a pre-defined set of functions.</p>



<p class="justify-text">When the set of a functions is a convex subset of a vector space with a finite-dimensional representation, with standard assumptions, the corresponding optimization problem is convex. This has the benefits of allowing a thorough theoretical understanding of the computational and statistical properties of learning methods, which often come with strong theoretical guarantees, in terms of running time [<a href="https://arxiv.org/pdf/1405.4980">1</a>, <a href="https://epubs.siam.org/doi/pdf/10.1137/16M1080173">2</a>, <a href="http://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">3</a>] or prediction performance on unseen data [<a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">4</a>, <a href="http://static.stevereads.com/papers_to_read/all_of_statistics.pdf">5</a>]. In particular, the linear parameterization can be done either explicitly by building a typically large finite set of features, or implicitly through the use of kernel methods and then a series of dedicated algorithms and theories can be leveraged for efficient non-linear predictions [6, <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">7</a>, <a href="http://papers.nips.cc/paper/6978-falkon-an-optimal-large-scale-kernel-method.pdf">8</a>].</p>



<p class="justify-text">However, linearly-parameterized sets of functions do not include neural networks, which lead to state-of-the-art performance in most learning tasks in computer vision, natural language processing, speech processing, in particular through the use of deep and convolutional neural networks [<a href="https://www.deeplearningbook.org/">9</a>].</p>



<h2>Two-layer neural networks with “relu” activations</h2>



<p class="justify-text">The goal of this blog post is to provide some understanding of why supervised machine learning work for the simplest form of such models: $$ h(x) = \frac{1}{m} \sum_{i=1}^m a_i ( b_i^\top x)_+ = \frac{1}{m} \sum_{i=1}^m a_i \max\{ b_i^\top x,0\},$$ where the input \(x\) is a vector in \(\mathbb{R}^d\), and \(m\) is the number of hidden neurons. The weights \(a_i \in \mathbb{R}\), \(i=1,\dots,n\), are the <em>output weights</em>, while the weights \(b_i \in \mathbb{R}^d\), \(i=1,\dots,n\), are the <em>input weights</em>. The rectified linear unit (“relu”) [<a href="http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf">10</a>] activation is used, and our results will depend heavily on its positive homogeneity (that is, for \(\lambda &gt; 0\), \((\lambda u)_+ = \lambda u_+\)).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="407" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/nn_single_blog.png" class="wp-image-3829" height="292" />Two-layer neural network in dimension \(d = 6\) with \(m=4\) hidden neurons, and a single output.</figure></div>



<p class="justify-text">Note that this is an idealized and much simplified set-up for deep learning, as there is a single hidden-layer, no convolutions, no pooling, etc. As I will show below, this simple set-up is already complex to understand, and I believe it captures some of the core difficulties associated with non-convexity.</p>



<p class="justify-text">The first question that one may come to after decades of research in learning theory is: <em>why is it so hard to analyze?</em>  </p>



<p class="justify-text">There are at least two major difficulties:</p>



<ul class="justify-text"><li><strong>Non-linearity</strong>: the dependence on the input weights \(b_i\)’s is non-linear because of the activation function, typically leading to non-convex optimization problems.</li><li><strong>Overparameterization</strong>: The number \(m\) of hidden neurons is very large (often so large that the number of parameters \(m(d+1)\) exceeds the number of observations), which is hard in terms of optimization and potentially generalization to unseen data. </li></ul>



<p class="justify-text">In this blog post, we will leverage the overparameterization and take \(m\) tending to infinity (without any dependence on the number of observations), which will allow us to derive theoretical results. We will leverage two key properties of the problem:</p>



<ul class="justify-text"><li><strong>Separability</strong> of the model in \(w_i = (a_i,b_i)\), that is, the prediction function \(h(x)\) is the sum of terms which are independently parameterized, as \(h = \frac{1}{m} \sum_{i=1}^m \Phi(w_i)\), where \(\Phi: \mathbb{R}^p \to \mathcal{F}\), with \(\mathcal{F}\) a space of functions. In our situation, \(p = d+1\) and: $$ \Phi(w)(x) = a (b^\top x)_+. $$ In other words,  there is no parameter sharing among hidden neurons. Unfortunately, this does not generalize to more than a single hidden layer.</li><li><strong>Homogeneity</strong>: the relu activation is positively homogeneous so that as as function of \(w = (a,b) \in \mathbb{R} \times \mathbb{R}^d\), \(\Phi(w)(x) = a (b^\top x)_+\) is positively 2-homogeneous, that is, \(\Phi(\lambda w) = \lambda^2 \Phi(w)\) for \(\lambda &gt; 0\).</li></ul>



<p class="justify-text">In this sequence of two blog posts, following a recent trend in optimization and machine learning theory [<a href="http://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">11</a>, <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">12</a>], optimization and statistics cannot be separated and need to be tackled together. I will focus on gradient flows on empirical or expected risks.</p>



<p class="justify-text">In this blog post, I will cover optimization and how over-parameterization leads to global convergence for 2-homogeneous models, a recent result obtained two years ago with <a href="https://lchizat.github.io/">Lénaïc Chizat</a> [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>]. This requires tools from optimal transport which I will briefly describe (for more details, see, e.g., [<a href="https://arxiv.org/abs/1803.00567">14</a>]).</p>



<p class="justify-text">Next month, I will focus on generalization capabilities and the several implicit biases associated with gradient descent in this context [<a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">15</a>, <a href="https://arxiv.org/pdf/2002.04486">16</a>].</p>



<h2>Infinitely wide limit and probability measures</h2>



<p class="justify-text">Following the standard learning set-up, our goal will be to minimize with respect to the prediction function \(h\) the functional \(R\) defined as $$ R(h) = \mathbb{E}_{p(x,y)} \big[ \ell( y, h(x) ) \big],$$ where \(\ell(y,h(x))\) is the loss incurred by outputting \(h(x)\) when \(y\) is the true label. Even within deep learning, this loss is most often convex in its second argument, such as for least-squares or <a href="https://en.wikipedia.org/wiki/Loss_functions_for_classification">logistic</a> losses. Thus, I will assume that \(R\) is convex.</p>



<p>The expectation can be considered in two scenarios:</p>



<ul class="justify-text"><li><strong>Empirical risk</strong>: this corresponds to the situation where we have observations \((x_j,y_j)\), \(j=1,\dots,n\), coming from some joint distribution on \((x,y) \in \mathbb{R}^d \times \mathbb{R}\). Minimizing \(R\) then may not lead to any guarantee on unseen data unless some explicit or implicit regularization is used. In next blog post, I will consider the implicit regularization effect of gradient-based algorithms.</li><li><strong>Expected risk (or generalization performance)</strong>: The expectation is taken with respect to unseen data, and thus its value (or a gradient) cannot be computed. However, any training observation \((x_j,y_j)\) can lead to an unbiased estimate, and if single pass stochastic gradient is used, our guarantees will be on the expected risk.</li></ul>



<p class="justify-text">The main and very classical idea is to consider the minimization of $$ G(W) = G(w_1,\dots,w_m) = R \Big( \frac{1}{m} \sum_{i=1}^m \Phi(w_i) \Big),$$ and see it as the minimization of $$ F(\mu) = R \Big( \int_{\mathbb{R}^p} \Phi(w) d\mu(w) \Big),$$ with respect to a probability measure \(\mu\), with the equivalence for $$ \mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i),$$ where \(\delta(w_i)\) is the Dirac measure at \(w_i\). See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="615" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/diracs_measures-1-1024x156.png" class="wp-image-3852" height="93" />Left: discrete probability measure. Right: measure with density.</figure></div>



<p class="justify-text">When \(m\) is large, we can represent any measure in the <a href="https://en.wikipedia.org/wiki/Convergence_of_measures#Weak_convergence_of_measures">weak sense</a> (that is, expectations of any continuous and bounded functions can be approximated). The benefits of considering the space of all measures instead of discrete measures have been used already in variety of contexts in machine learning, statistics and signal processing [<a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">17</a>, <a href="http://papers.nips.cc/paper/2800-convex-neural-networks.pdf">18</a>, <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">19</a>]. In this blog post, the key benefit is that the set of measures in convex and \(h = \int_{\mathbb{R}^p} \Phi(w) d\mu(w) \) is linear in the measure \(\mu\), so that our optimization problem has become convex.</p>



<p class="justify-text">However, (1) It does not buy much in practice, as the set of probability measures is infinite-dimensional. <a href="https://en.wikipedia.org/wiki/Frank–Wolfe_algorithm">Frank-Wolfe algorithms</a> can be used, but the choice of new neurons is a difficult optimization problem, NP-hard for the threshold activation function [<a href="https://epubs.siam.org/doi/pdf/10.1137/070685798">20</a>], with polynomial potentially high complexity for the relu activation [<a href="http://proceedings.mlr.press/v65/goel17a/goel17a.pdf">21</a>], and (2) this is not what is used in practice, which is (stochastic) gradient descent.</p>



<h2>Finite-dimensional gradient flow</h2>



<p class="justify-text">In this post, I will consider the gradient flow $$\dot{W} = \ – m \nabla G(W),$$ (where \(m\) is added as a normalization factor to allow a well-defined limit when \(m\) tends to infinity). This is still not exactly what is used in practice, but, as explained in <a href="https://francisbach.com/gradient-flows/">last month post</a>, this is a good approximation of gradient descent (if using the empirical risk, then leading to guarantees of global convergence on the empirical risk only), or stochastic gradient descent (if doing a single pass on the data, then leading to guarantees of global convergence on unseen data). This is a non-convex dynamics, with stationary points and local minima, even when \(m\) is large (see, e.g., [<a href="http://proceedings.mlr.press/v80/safran18a/safran18a.pdf">27</a>]).</p>



<p class="justify-text">Two main questions arise: (1) what does the gradient flow dynamics converge to when the number of neurons \(m\) tends to infinity, and (2) can we get any global convergence guarantees for the limiting dynamics?</p>



<h2>Mean-field limit and Wasserstein gradient flows</h2>



<p class="justify-text">When \(m\) tends to infinity, since we want to use the measure representation, we need to understand the effect of performing the gradient flow jointly on \(w_1,\dots,w_m\) on the measure $$ \mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i),$$ and see if we can take a limit when \(m\) tends to infinity. This process of taking limits is common in physics and often referred to as the “mean-field” limit, and has been considered in a series of recent works [<a href="https://arxiv.org/pdf/1712.05438">22</a>, <a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>, <a href="https://www.pnas.org/content/pnas/115/33/E7665.full.pdf">23</a>, <a href="https://arxiv.org/pdf/1805.00915">24</a>]. To avoid too much technicality, I will assume that the map \(\Phi\) is sufficiently differentiable, which unfortunately exclude the relu activation; for dedicated results, see [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>].</p>



<p class="justify-text"><strong>Gradient flows on metric spaces.</strong> In order to understand the dynamics in the space of probability measures, we need to take a step backward and realize that gradient flows can be defined for many functions \(f\) on any metric space \(\mathcal{X}\). Indeed, it can be seen as the limit of taking infinitesimal steps of length \(\gamma\), where each new iterate \(x_{k+1}\) (corresponding to the value at time \(k\gamma\)) is defined recursively from \(x_k\) as $$x_{k+1} \in \arg\min_{x \in \mathcal{X}}\  f(x) + \frac{1}{2\gamma} d(x,x_k)^2.$$ As shown in [<a href="http://www2.stat.duke.edu/~sayan/ambrosio.pdf">25</a>, <a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">26</a>], with some form of interpolation, this defines a curve with prescribed values \(x_k\) at each \(\gamma k\), and when the step-size \(\gamma\) goes to zero, this curves “converges” to the gradient flow.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="419" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/euler-1024x520.png" class="wp-image-3960" height="212" />Gradient flow in bold black, with interpolating curve in red from 14 points \(x_0,\dots,x_{13}\).</figure></div>



<p class="justify-text">For the space \(\mathcal{X} = \mathbb{R}^d\) with the Euclidean distance and a continuously differentiable function \(f\), we obtain that $$x_{k+1} = x_k – \gamma f'(x_k) + o(\gamma),$$ and we get the usual gradient flow associated to \(f\), and the scheme above is nothing less than <a href="https://en.wikipedia.org/wiki/Euler_method">Euler discretization</a> that was described <a href="https://francisbach.com/gradient-flows/">last month</a>.</p>



<p class="justify-text"><strong>Vector space gradient flows on probability measures.</strong> Probability measures are a convex subset of measures with finite <a href="https://en.wikipedia.org/wiki/Total_variation#Total_variation_of_probability_measures">total variation</a>, which is equal to the \(\ell_1\)-norm between densities when the two probability measures have densities with respect to the same base measure. It is a normed vector space for which we could derive our first type of gradient flow, which can be seen as a continuous version of Frank-Wolfe algorithm, where atoms are added one by one, until convergence.  </p>



<p class="justify-text">As mentioned above, the fact that atoms are created sequentially seems attractive computationally. However, (1) deciding which one to add is a computationally hard problem, and (2) the flow on measures cannot be approximated by a finite evolving set of “particles” (here hidden neurons each defined by a vector \(w \in \mathbb{R}^{d+1}\)).</p>



<p class="justify-text"><strong>Wasserstein gradient flows on probability measures.</strong> There is another natural distance here, namely the <a href="https://en.wikipedia.org/wiki/Wasserstein_metric">Wasserstein distance</a> (sometimes called the Kantorovich–Rubinstein distance). In order to remain short, I will only define it between empirical measures $$\mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i) \mbox{ and } \nu = \frac{1}{m} \sum_{i=1}^m \delta(v_i)$$ with the same number of points. The squared 2-Wasserstein distance is obtained by minimizing $$\frac{1}{m} \sum_{i=1}^m \| w_j – v_{\sigma(j)} \|_2^2$$ over all permutations \(\sigma: \{1,\dots,m\} \to \{1,\dots,m\}\). See illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="573" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/Wasserstein-2-1024x307.png" class="wp-image-3886" height="171" />Wasserstein distance between two empirical measures: (left) original observations of two empirical measures with \(m = 11\) points, (right) assigning all black points to red points by minimizing the sum of squared distances between assigned points.</figure></div>



<p class="justify-text">This can be extended to any pair of probability measures, and used within gradient flows, it has a very natural decoupling property: if \(\mu\) is fixed, and \(\nu\) is within a small distance of \(\mu\) in Wasserstein distance, then the optimal permutation above will always be the same, that is, locally, the Wasserstein distance is a sum of squared Euclidean distances. Then, the Wasserstein gradient flow will lead to \(m\) independent local regular Euclidean gradient flows, which interact through the gradient term as: $$ \dot{w}_i = \ –  \nabla \Phi(w_i)  \nabla R\Big(\int_{\mathbb{R}^p} \Phi d\mu \Big),$$ where the Jacobian \(\nabla \Phi(w_i)\) is a linear operator from \(\mathcal{F}\) to \(\mathbb{R}^p\), and \( \nabla R: \mathbb{R}^p \to \mathcal{F}\) the gradient operator of \(R\). Since \(\mu = \frac{1}{m} \sum_{i=1}^m \delta(w_i)\), the dynamics of each particle interacts through the gradient of \(R\). </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="456" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/Wasserstein_flows-1024x508.png" class="wp-image-3890" height="225" />Gradient flow for \(m=7\) interacting particles.</figure></div>



<p class="justify-text">The intuitive reasoning above is behind the formal result for the function $$ F(\mu) = R \Big( \int_{\mathbb{R}^p} \Phi(w) d\mu(w) \Big),$$ that the limit of the Euclidean gradient flow on each particle when \(m\) tends to infinity, is exactly the Wasserstein gradient flow of \(F\). While I have proposed an intuitive explanation, this can be made more formal in particular through the use of partial differential equations on the density of the measure [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>] (see also nice <a href="http://web.math.ucsb.edu/~kcraig/math/curriculum_vitae_files/NIPS_120917.pdf">slides</a> from Katy Craig on Wasserstein gradient flows).</p>



<p class="justify-text"><strong>Stationary points.</strong> Since \(R\) is assumed convex over the convex set of probability measures, all local minima of \(R\) are global, and we should expect the gradient flow to converge to global optimum from any initial measure. This is true for the gradient flow associated with the total variation metric. However this is not true for the Wasserstein gradient flow, for which stationary points which are not global minimizers exist (given that for discrete measures this corresponds to classical backpropagation, this is well known to anybody who has ever trained a neural network). Note that there exists a notion of convexity for Wasserstein gradient flows, namely <a href="https://en.wikipedia.org/wiki/Geodesic_convexity">geodesic convexity</a>, but the function \(F\) is not geodesically convex in general.</p>



<h2>Global convergence</h2>



<p class="justify-text">We can now describe the main result from our recent work with Lénaïc [<a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">13</a>]: under assumptions described below, for the function \(F\) defined above, if the Wasserstein gradient flow converges to a measure, this measure has to be a global minimum of \(F\) (note that we cannot prove it is always convergent).</p>



<p class="justify-text">On top of technical regularity assumptions that I will not describe here, we need two crucial broad assumptions:</p>



<ul class="justify-text"><li><strong>Homogeneity</strong> of the function \(\Phi: \mathbb{R}^{d+1} \to \mathcal{F}\). We need a condition of this form, since if \(R\) is a linear function, then \(F(\mu)\) is of the form \(F(\mu) = \int_{\mathbb{R}^p} \psi(w)d\mu(w)\) with \(\psi(w) = R(\Phi(w))\), and the Wasserstein gradient flow will converge to a weighted some of Diracs at all local minimizers of \(\psi\), which is typically not a global minimizer.</li><li><strong>Initialization with positive mass in all directions</strong>. That is, \(w_i\)’s are uniformly distributed on the sphere or Gaussian, which is the de facto choice in practice. </li></ul>



<p class="justify-text"><strong>Illustration</strong>. We illustrate the result above by considering \(R\) as the square loss and \(y\) being generated from \(x\) through a neural network with \(m_0=5\) neurons. When running the gradient flow above, as soon as \(m \geqslant 5\), the model is sufficiently flexible to attain zero loss, which is thus the global optimum of the cost function. However, the gradient flow may not reach it, as it gets trapped in a local optimum. Our theoretical result suggests that when \(m\) is large, we should converge to the original neurons, which we see below. The surprising (and still unexplained) phenomenon is that \(m\) does not need to be much larger than \(m_0\) to see practical global convergence.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="389" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m5-1024x683.png" class="wp-image-3942" height="259" />Position of \(m = 5\) neurons, plotted as \(|a_i| b_i \in \mathbb{R}^2\) for a two-dimensional problem. The five dotted lines are the directions of the generating neurons. Although \(m\) is large enough to lead to the global optimum, the flow gets stuck in a local optimum.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="365" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m10-1024x683.png" class="wp-image-3943" height="243" />Position of \(m = 10\) neurons; same setting as above. The flow converges to the global optimum, although \(m\) is not large.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="379" alt="" src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m100-1024x683.png" class="wp-image-3944" height="252" />Position of \(m = 100\) neurons; same setting as above. The flow converges to the global optimum, with \(m\) large. See video below.</figure></div>



<figure class="wp-block-video aligncenter justify-text"><video src="https://francisbach.com/wp-content/uploads/2020/05/ReLU_m100.mp4"></video>Position of \(m = 100\) neurons; exact same setting as above.</figure>



<h2>Discussion and open problems</h2>



<p class="justify-text">In this blog post, I described theoretical results showing the benefits of overparameterization: when the number of hidden neurons \(m\) tends to infinity, then the corresponding gradient flow converges to the global optimum of the cost function. The proof relies notably on homogeneity properties of the relu activation. </p>



<p class="justify-text">The main weakness of  this result is that is only <em>qualitative</em>: we cannot quantify how big \(m\) need to be to be close to the infinite width limit, or how fast the gradient flow converges to the global optimum. These are still open problems. Additional interesting areas of research are to extend these results to convolutional and/or deep networks.</p>



<p class="justify-text">Now that we know that we can obtain global convergence, I will describe next month the generalization properties when interpolating the training data with an overparameterized relu network [<a href="https://arxiv.org/pdf/2002.04486">16</a>].</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Lénaïc Chizat for producing the nice figures and video of neural networks, proofreading this blog post, and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Sébastien Bubeck. <a href="https://arxiv.org/pdf/1405.4980">Convex Optimization: Algorithms and Complexity</a>. <em>Foundations and Trends in Machine Learning</em>, <em>8</em>(3-4), 231-357, 2015.<br />[2] Léon Bottou, Frank E. Curtis, Jorge Nocedal. <a href="https://epubs.siam.org/doi/pdf/10.1137/16M1080173">Optimization methods for large-scale machine learning</a>. SIAM Review, 60(2):223-311, 2018.<br />[3] Francis Bach, Rodolphe Jenatton, Julien Mairal, Guillaume Obozinski. <a href="http://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">Optimization with sparsity-inducing penalties</a>. <em>Foundations and Trends in Machine Learning, </em>4(1):1-106, 2012.<br />[4] Shai Shalev-Shwartz, Shai Ben-David. <a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/understanding-machine-learning-theory-algorithms.pdf">Understanding machine learning: From theory to algorithms</a>. Cambridge University Press, 2014.<br />[5] Larry Wasserman. <a href="http://static.stevereads.com/papers_to_read/all_of_statistics.pdf">All of statistics: a concise course in statistical inference</a>. Springer Science &amp; Business Media, 2013.<br />[6] Bernhard Schölkopf, Alexander J. Smola. Learning with kernels: support vector machines, regularization, optimization, and beyond. MIT press, 2002.<br />[7] Ali Rahimi and Benjamin Recht. <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">Random features for large-scale kernel machines</a>. <em>Advances in neural information processing systems</em>, 2008.<br />[8] Alessandro Rudi, Luigi Carratino, Lorenzo Rosasco. <a href="http://papers.nips.cc/paper/6978-falkon-an-optimal-large-scale-kernel-method.pdf">Falkon: An optimal large scale kernel method</a>. <em>Advances in Neural Information Processing Systems</em>, 2017.<br />[9] Ian Goodfellow, Yoshua Bengio, Aaron Courville. <a href="https://www.deeplearningbook.org/">Deep learning</a>. MIT Press, 2016.<br />[10] Xavier Glorot, Antoine Bordes, and Yoshua Bengio. <a href="http://www.jmlr.org/proceedings/papers/v15/glorot11a/glorot11a.pdf">Deep sparse rectifier neural networks</a>. <em>International Conference on Artificial Intelligence and Statistics</em>, 2011.<br />[11] Francis Bach and Eric Moulines. <a href="http://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate O(1/n)</a>. <em>Advances in Neural Information Processing Systems</em>, 2013.<br />[12] MIkhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal. <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">Reconciling modern machine-learning practice and the classical bias–variance trade-off</a>. <em>Proceedings of the National Academy of Sciences</em>, 116(32), 15849-15854, 2019.<br />[13] Lénaïc Chizat, Francis Bach. <a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport</a>. <em>Advances in Neural Information Processing Systems</em>, 2018.<br />[14] Gabriel Peyré, Marco Cututi. <em><a href="https://arxiv.org/abs/1803.00567">Computational Optimal Transport</a></em>. Foundations and Trends in Machine Learning, 51(1):1–44, 2019.<br />[15] Lénaïc Chizat, Edouard Oyallon, Francis Bach. <a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">On Lazy Training in Differentiable Programming</a>. <em>Advances in Neural Information Processing Systems</em>, 2019.<br />[16] Lénaïc Chizat, Francis Bach. <a href="https://arxiv.org/pdf/2002.04486">Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss</a>. Technical report, arXiv:2002.04486, 2020.<br />[17] Andrew R. Barron. <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">Universal approximation bounds for superpositions of a sigmoidal function</a>. <em>IEEE Transactions on Information theory</em>, <em>39</em>(3), 930-945, 1993.<br />[18] Yoshua Bengio, Nicolas Le Roux, Pascal Vincent, Olivier Delalleau, Patrice Marcotte. <a href="http://papers.nips.cc/paper/2800-convex-neural-networks.pdf">Convex neural networks</a>. <em>Advances in neural information processing systems</em>, 2006.<br />[19] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the Curse of Dimensionality with Convex Neural Networks</a>.<strong> </strong><em>Journal of Machine Learning Research</em>, 18(19):1-53, 2017.<br />[20] Venkatesan Guruswami, Prasad Raghavendra. <a href="https://epubs.siam.org/doi/pdf/10.1137/070685798">Hardness of learning halfspaces with noise</a>. <em>SIAM Journal on Computing</em>, 39(2):742-765, 2009.<br />[21] Surbhi Goel, Varun Kanade, Adam Klivans, Justin Thaler. <a href="http://proceedings.mlr.press/v65/goel17a/goel17a.pdf">Reliably Learning the ReLU in Polynomial Time</a>. <em>Conference on Learning Theory</em>, 2017.<br />[22] Atsushi Nitanda, Taiji Suzuki. <a href="https://arxiv.org/pdf/1712.05438">Stochastic particle gradient descent for infinite ensembles</a>. Technical report, arXiv:1712.05438, 2017.<br />[23] Song Mei, Andrea Montanari, Phan-Minh Nguyen. <a href="https://www.pnas.org/content/pnas/115/33/E7665.full.pdf">A mean field view of the landscape of two-layer neural networks</a>. <em>Proceedings of the National Academy of Sciences</em> 115(33):E7665-E7671, 2018.<br />[24] Grant M. Rotskoff, Eric Vanden-Eijnden. <a href="https://arxiv.org/pdf/1805.00915">Neural networks as interacting particle systems: Asymptotic convexity of the loss landscape and universal scaling of the approximation error</a>. Technical report, arXiv:1805.00915, 2018.<br />[25] Luigi Ambrosio, Nicola Gigli, Giuseppe Savaré. <a href="http://www2.stat.duke.edu/~sayan/ambrosio.pdf">Gradient flows: in metric spaces and in the space of probability measures</a>. Springer Science &amp; Business Media, 2008<br />[26] Filippo Santambrogio. <a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">{Euclidean, metric, and Wasserstein} gradient flows: an overview</a>. <em>Bulletin of Mathematical Sciences</em>, <em>7</em>(1), 87-154, 2017.<br />[27] Itay Safran, Ohad Shamir. <a href="http://proceedings.mlr.press/v80/safran18a/safran18a.pdf">Spurious Local Minima are Common in Two-Layer ReLU Neural Networks</a>. <em>International Conference on Machine Learning</em>, 2018.</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/"><span class="datestr">at June 01, 2020 07:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=48">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/">Friday, May 15 — Amin Karbasi from Yale University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Amin Karbasi </strong>from Yale University will speak about “<em>User-Friendly Submodular Maximization</em>”.</p>



<p class="has-text-align-left"><strong>Abstract</strong>: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they have been rediscovered in many fields such as information theory, operations research, statistical physics, economics, and machine learning. They also enjoy computational tractability as they can be minimized exactly or maximized approximately.</p>



<p>The goal of this talk is simple. We see how a little bit of randomness, a little bit of greediness, and the right combination can lead to pretty good methods for offline, streaming, and distributed solutions. I do not assume any background on submodularity and try to explain all the required details during the talk.</p>



<p><a href="https://sites.google.com/view/dstheory" target="_blank" rel="noreferrer noopener">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/"><span class="datestr">at May 05, 2020 01:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=3460">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/gradient-flows/">Effortless optimization through gradient flows</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">Optimization algorithms often rely on simple intuitive principles, but their analysis quickly leads to a lot of algebra, where the original idea is not transparent. In last month <a href="https://francisbach.com/computer-aided-analyses/">post</a>, <a href="https://www.di.ens.fr/~ataylor/">Adrien Taylor</a> explained how convergence proofs could be automated. This month, I will show how proof sketches can be obtained easily for algorithms based on gradient descent. This will be done using vanishing step-sizes that lead to <em>gradient flows</em>.</p>



<h2>Gradient as local information</h2>



<p class="justify-text">The intuitive principle behind gradient descent is the quest for <em>local</em> descent. We thus need to characterize the local behavior of the function we aim to optimize. This is what gradients are for.</p>



<p class="justify-text">In this blog post, I will consider minimizing a function \(f\) over \(\mathbb{R}^d\). Assuming \(f\) is differentiable, a first order Taylor expansion of \(f\) around a point \(x\) leads to $$f(x+\delta) = f(x) + \nabla f(x) ^\top \delta + o(\| \delta\|),$$ for any norm \(\| \cdot \|\) on \(\mathbb{R}^d\), where \(\nabla f(x) \in \mathbb{R}^d\) is  the gradient of \(f\) at \(x\), composed of partial derivatives of \(f\). Therefore, around \(x\), \(f\) is approximately affine.</p>



<p class="justify-text">Since we have a local affine approximation around \(x\), we can look for the direction of steepest descent, that is, the unit norm vector \(u \in \mathbb{R}^d\) such that \(f\) decays the most along \(u\), that is such that $$  u^\top \nabla f(x)$$ is minimized. This steepest descent direction depends on the choice of norm (assuming that the gradient is not zero at \(x\)).</p>



<p class="justify-text">For the \(\ell_2\)-norm, then minimizing \(u^\top \nabla f(x)\) such that \(\|u\|_2 = 1\), leads to $$ \displaystyle u = \ – \frac{\nabla f(x)}{ \| \nabla f(x) \|_2},$$ that is the steepest descent is along the negative gradient (see an illustration below). In this blog post I will only focus on this steepest descent direction. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="428" alt="" src="https://francisbach.com/wp-content/uploads/2020/04/gradient_contours-1024x358.png" class="wp-image-3542" height="149" />Function \(f\) represented through its contour lines for values 1, 2, 3, 4 and 5. Negative gradient \(– \nabla f(x)\) as the steepest descent direction at point \(x\), which is orthogonal to the contour lines.</figure></div>



<p class="justify-text">As as side note, for the \(\ell_1\)-norm, then minimizing \(u^\top \nabla f(x)\) such that \(\|u\|_1 = 1\), leads to $$u \in\  – \arg\max_{ v \in \{-e_1,\, e_1,\, -e_2,\, e_2,\dots,\, -e_d,\, e_d \}} v^\top \nabla f(x),$$ where \(e_i\) is the \(i\)-th canonical basis vector of \(\mathbb{R}^d\). Here the steepest descent is along a coordinate axis (along the positive or negative side), and this leads to various forms of <a href="https://en.wikipedia.org/wiki/Coordinate_descent">coordinate descent</a> (this will probably be a topic for another post). </p>



<p class="justify-text">Given that the negative gradient leads to the steepest descent direction (for the Euclidean norm), it is natural to use this as a direction for an iterative algorithm, an idea that dates back to <a href="https://en.wikipedia.org/wiki/Augustin-Louis_Cauchy">Cauchy</a> in 1847 [<a href="http://gallica.bnf.fr/ark:/12148/bpt6k90190w/f406">1</a>] (see the nice summary by Claude Le Maréchal [<a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf">2</a>]).</p>



<h2>From gradient descent to gradient flows</h2>



<p class="justify-text"><a href="https://en.wikipedia.org/wiki/Gradient_descent">Gradient descent</a> is the most classical iterative algorithm to minimize differentiable functions. It takes the form $$x_{n+1} = x_{n} \, – \gamma \nabla f(x_{n})$$ at iteration \(n\), where \(\gamma &gt; 0 \) is a step-size.  </p>



<p class="justify-text">Gradient descent comes in many flavors, steepest, stochastic, pre-conditioned, conjugate, proximal, projected, accelerated, etc. There are lots of papers and books [e.g., 3, 4, 5] analyzing it in various settings.</p>



<p class="justify-text">In this post, to simplify its analysis and setting the stage for later posts, I will present the gradient flow, which is essentially the limit of gradient descent when the step-size \(\gamma\) tends to zero.</p>



<p class="justify-text">More precisely, this is obtained by considering that our iterates \(x_n\) are sampled at each multiple of \(\gamma\), from a function \(X: \mathbb{R}_+ \to \mathbb{R}^d\), as $$x_n = X(n\gamma).$$ We can then use a piecewise affine interpolation to define a function defined on all points. We then have for \(t = n\gamma\), $$X(t + \gamma) = x_{n+1} =x_{n} \, – \gamma \nabla f(x_{n}) = X(t)\, – \gamma \nabla f(X(t)).$$ Dividing by \(\gamma\), we get $$ \frac{1}{\gamma} \big[ X(t + \gamma) \, – X(t) \big] = \, – \nabla f(X(t)).$$</p>



<p class="justify-text">When \(\gamma\) tends to zero (and with simple additional regularity assumptions), the left hand side tends to the derivative of \(X\) at \(t\), and thus the function \(X\) tends to the solution of the following <a href="https://en.wikipedia.org/wiki/Ordinary_differential_equation">ordinary differential equation</a> $$ \dot{X}(t) = \ – \nabla f (X(t)).$$ See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="348" alt="" src="https://francisbach.com/wp-content/uploads/2020/04/logistic_2d_flow.gif" class="wp-image-3479" height="271" />Gradient descent (with piece-wise affine interpolation between iterates) vs. gradient flow on the same time scale for a logistic regression problem.</figure></div>



<p class="justify-text">Studying the gradient flow in lieu of the gradient descent recursions comes with pros and cons.</p>



<p class="justify-text"><strong>Simplified analyses</strong>. The gradient flow has no step-size, so all the traditional annoying issues regarding the choice of step-size, with line-search, constant, decreasing or with a weird schedule are unnecessary. Moreover, the use of differential calculus makes proving properties really simple (see examples below). We can thus focus on the essence of the algorithm rather than on technicalities.</p>



<p class="justify-text"><strong>From (continuous) flow to actual (discrete) algorithms</strong>. A flow cannot be run on a computer as it is a continuous-time object. The traditional discretization is the <a href="https://en.wikipedia.org/wiki/Euler_method">Euler method</a>, that exactly replaces the flow by a piecewise-affine interpolation of the gradient descent iterates, where as shown above, we see \(x_n\) as \(X(n\gamma)\), where \(\gamma\) is the time increment between two samples. Four interesting observations:</p>



<ul class="justify-text"><li><em>No direct proof transfer</em> : While Euler discretization always provides an algorithm, the generic convergence proofs do not allow to transfer immediately continuous-time proofs to convergence results for the discrete analysis. A key difficulty is to set-up the step-size \(\gamma\). However, the analysis can often be mimicked, i.e., similar <a href="https://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov functions</a> can be used (see examples below).</li><li><em>Proximal algorithms</em> : Faced with non-continuous gradient functions, the <em>forward</em> version of Euler discretization \(x_{n+1} = x_{n} – \gamma \nabla f(x_{n})\) can be replaced by the <em>backward</em> version $$x_{n+1} = x_{n} \, –  \gamma \nabla f(x_{n+1}),$$ which is only implicit as it can be solved by minimizing $$ f(x) + \frac{1}{2\gamma}\|x-x_{n}\|_2^2,$$ thus leading to the <a href="https://fr.wikipedia.org/wiki/Algorithme_proximal_(optimisation)">proximal point algorithm</a>. Forward-backward schemes can also be recovered when \(f\) is the sum of a smooth and a non-smooth term.</li><li><em>Stochastic gradient descent</em> : There are two ways to deal with stochastic gradient descent, leading to two very different continuous limits. Adding independent and identically distributed (for simplicity) zero-mean noise \(\varepsilon_n\) to the gradient leads to the recursion $$x_{n+1} = x_{n} – \gamma \big[ \nabla f(x_{n}) + \varepsilon_n\big] = x_{n}\, – \gamma \nabla f(x_{n}) \,- \gamma \varepsilon_n,$$ where the noise is multiplied by the step-size \(\gamma\). Surprisingly, taking the limit when \(\gamma\) tends to zero leads to the deterministic gradient flow equation. A more detailed argument is presented at the end of post, but the main hand-waving reason is that the noise contribution vanishes because it is multiplied by the step-size. Note that this limiting behavior is consistent with a convergence to a minimizer of \(f\).</li><li><em>Convergence to a Langevin diffusion</em> : When instead the noise is added with magnitude proportional to the square root \(\sqrt{2 \gamma}\) of the step-size (which is asymptotically larger than \(\gamma\)), when \(\gamma\) tends to zero, and if the covariance of the noise is identity, we converge to a <a href="https://en.wikipedia.org/wiki/Diffusion_process">diffusion process</a> which is the solution of a <a href="https://en.wikipedia.org/wiki/Stochastic_differential_equation">stochastic differential equation</a>: $$ dX(t) = \ – \nabla f(X(t)) + \sqrt{2} dB(t),$$ where \(B\) is a standard <a href="https://en.wikipedia.org/wiki/Brownian_motion">Brownian motion</a>. Moreover, as \(t\) tends to infinity, \(X(t)\) happens to tend in distribution to a random variable with density proportional to \(\exp( – f(x) )\). See more details at the end of the post and in [6]. The difference in behavior is illustrated below.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="359" alt="" src="https://francisbach.com/wp-content/uploads/2020/04/logistic_2d_flow_SGD-3.gif" class="wp-image-3527" height="318" /> Comparison of flow and diffusion, for the same small \(\gamma\). The flow is deterministic and converges to a stationary point of \(f\) (here the global minimum), while the diffusion is stochastic and converges to a distribution (which is typically not a point mass)</figure></div>



<h2>Properties of gradient flows</h2>



<p class="justify-text">The gradient flow $$ \dot{X}(t) = \ – \nabla f (X(t)) $$ is well-defined for a wide variety of conditions on the function \(f\). The most classical ones are <a href="https://en.wikipedia.org/wiki/Picard%E2%80%93Lindel%C3%B6f_theorem">Lipschitz-continuity</a> of the gradient, or semi-convexity [<a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">7</a>].</p>



<p class="justify-text">The most obvious property is that the function decreases along the flow; in other words, \(f(X(t))\) is decreasing, which is a simple consequence of $$ \frac{d}{dt} f(X(t)) =  \nabla f(X(t))^\top \frac{dX(t)}{dt} =\  – \| \nabla f (X(t) )\|_2^2 \leqslant 0.$$</p>



<p class="justify-text">If \(f\) is bounded from below, then \(f(X(t))\) will always converge (as a non-increasing function which is bounded from below, see <a href="https://en.wikipedia.org/wiki/Monotone_convergence_theorem">here</a>). However, in general, \(X(t)\) may not always converge without any further assumptions, e.g., it may oscillate forever. This is however rare and there are a variety of sufficient conditions for convergence of gradient flows, that date back to Lojasiewicz [8], and are based on “Lojasiewicz inequalities” that state that for \(y\) and \(x\) close enough, \(|f(x) – f(y)|^{1-\theta} \leqslant C \| \nabla f(x)\|\) for some \(C &gt; 0 \) and \(\theta \in (0,1)\). These are satisfied for “sub-analytical functions”, that include most functions one can imagine [<a href="https://www.sciencedirect.com/sdfe/reader/pii/S0022247X05006864/pdf">9</a>].</p>



<p class="justify-text">Once \(X(t)\) converges to some \(X(\infty) \in \mathbb{R}^d\), assuming \(\nabla f\) is continuous, we must have \(\nabla f(X(\infty))=0\), that is, \(X(\infty)\) is a stationary point of \(f\). Among all stationary points (that can be local minima, local maxima, or saddle-points), the one to which \(X(t)\) converges to depends on \(X(0)\).</p>



<p class="justify-text">Given any stationary point, one can look at the set of initializations that lead to it. Typically, only local minima are stable, that is, the attraction basins of other stationary points has typically zero Lebesgue measure (see, e.g., [<a href="http://www.jmlr.org/proceedings/papers/v49/lee16.pdf">10</a>]). See examples below. </p>



<p class="justify-text">We start with a simple function defined on the two-dimensional plane, with several local minima and saddle-points.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="511" alt="" src="https://francisbach.com/wp-content/uploads/2020/04/plot_non_convex-1.png" class="wp-image-3490" height="401" />Various gradient flows trajectories, starting from green points and ending in black points. Note the proximity of the three top starting points, all ending in different local minima. See the motion below.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="519" alt="" src="https://francisbach.com/wp-content/uploads/2020/04/logistic_2d_flow_noncvx-1.gif" class="wp-image-3492" height="500" />Various gradient flows trajectories, in motion! All flows share the same time scale. Some seem “slower” than others (because the gradient norm is small).</figure></div>



<p class="justify-text">Before moving on, I cannot resist presenting a “real” two-dimensional example that probably all skiers, hikers, and cyclists with some form of mathematical abilities have thought of, the topographic map. Here is an example below:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="458" alt="" src="https://francisbach.com/wp-content/uploads/2020/04/glandon_croix_de_fer-1-1024x1024.jpg" class="wp-image-3751" height="458" />Extract from <a href="https://www.geoportail.gouv.fr/">IGN</a> topographic map, around <a href="https://en.wikipedia.org/wiki/Col_du_Glandon">Col du Glandon</a> and <a href="https://en.wikipedia.org/wiki/Col_de_la_Croix_de_Fer">Col de la Croix de Fer</a> (French Alps).</figure></div>



<p class="justify-text">Given the topographic map, how would gradient descent or gradient flow perform? Clearly, this corresponds to a non convex function, but it is quite well-behaved, as following water flows will typically lead to sea level. I chose two starting points famous to cyclists, <a href="https://en.wikipedia.org/wiki/Col_du_Glandon">Col du Glandon</a> and <a href="https://en.wikipedia.org/wiki/Col_de_la_Croix_de_Fer">Col de la Croix de Fer</a>, and ran gradient descent with a small step-size (to approximate the gradient flow), without noise (left) and with noise (right), on the topographic map (thanks to <a href="http://recherche.ign.fr/labos/matis/cv.php?nom=Landrieu">Loïc Landrieu</a> for the data extraction).</p>



<figure class="wp-block-image size-large"><img src="https://francisbach.com/wp-content/uploads/2020/04/flows_final_square_small-1024x394.png" alt="" class="wp-image-3753" /></figure>



<p class="justify-text">Without noise, the descent from la Croix de Fer ends up getting stuck quickly in a local minimum, while the one from Glandon goes down to the valley, but then is not able to follow the almost flat slope. When noise is added, the two flows go a bit lower, highlighting the benefits of noise to escape local minima.</p>



<h2>Gradient flows for optimization and machine learning</h2>



<p class="justify-text">There are (at least) two key questions in optimization and machine learning related to gradient flows: </p>



<ul class="justify-text"><li>When can we have global guarantees for convergence? That is, can we make sure that we choose an initialization point well enough to get the the global optimum <em>without knowing where the global optimum is</em>. A key difficulty is that the volume of the attraction basin of the global optimum can be made arbitrarily small, even for infinitely differentiable functions (imagine a function equal to zero everywhere except on a small ball where it is negative).</li><li>How fast can we get there? “there” can be a stationary point or a global optimum. This is an important question as mere convergence in the limit may be arbitrarily slow [<a href="https://papers.nips.cc/paper/6707-gradient-descent-can-take-exponential-time-to-escape-saddle-points.pdf">11</a>].</li></ul>



<p class="justify-text">An important class of function is <a href="https://en.wikipedia.org/wiki/Convex_function">convex functions</a>, where everything works out very well. We will study them below. Other functions will be studied in future posts.</p>



<h2>Convex functions</h2>



<p class="justify-text">We now assume that the function \(f\) is <a href="https://en.wikipedia.org/wiki/Convex_function">convex</a> and differentiable. Within machine learning, this corresponds to objective functions encountered for supervised learning which are based on empirical risk minimization with a prediction function which is linearly parameterized, such as <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a>.</p>



<p class="justify-text">There are various definitions of convexity, which are based on global properties (the function is always “below its chords”, or it is always “above its tangents”) or local properties (the Hessian is always positive semi-definite). The one which we need here is to be above its tangents, that is, for any \(x, y \in \mathbb{R}^d\), $$f(x) \geqslant f(y)  + \nabla f(y)^\top ( x \, – y).$$ Applying this to any stationary point \(y\) such that \(\nabla f(y)=0\) shows that for all \(x\), \(f(x) \geqslant f(y)\), that is, \(y\) is a global minimizer of \(f\). This is the classical benefit of convexity: no need to worry about local minima.</p>



<p class="justify-text">Another property we will need is the Lojasiewicz inequality, which is in particular satisfied when \(f\) is \(\mu\)-<a href="https://en.wikipedia.org/wiki/Convex_function#Strongly_convex_functions">strongly convex</a> (that is, \(f – \frac{\mu}{2} \| \cdot \|_2^2\) is convex): $$ f(x) \ – f(x_\ast) \leqslant \frac{1}{2 \mu} \| \nabla f (x)\|^2$$ for any minimizer \(x_\ast\) of \(f\) and any \(x\). This property allows to go from a bound on the gradient norm to a bound on function values.</p>



<p class="justify-text">We then obtain the convergence rate <em>in one line</em> as follows (see more details in [<a href="http://papers.nips.cc/paper/6711-integration-methods-and-optimization-algorithms.pdf">12</a>]): $$ \frac{d}{dt} \big[ f(X(t))\ – f(x_\ast) \big] =\  \nabla f(X(t))^\top \dot{X}(t) =  \ – \| \nabla f(X(t))\|_2^2 \leqslant \ – 2\mu  \big[ f(X(t)) \ – f(x_\ast) \big]$$ using the Lojasiewicz inequality above, leading to by simple integration of the derivative of \(\log \big[ f(X(t)) \ – f(x_\ast) \big]\): $$f(X(t)) \ – f(x_\ast) \leqslant \exp( – 2\mu t ) \big[ f(X(0))\  – f(x_\ast) \big], $$ that is, the convergence is exponential and the characteristic time is proportional to \(1/\mu\).</p>



<p class="justify-text">The gradient flow gives the main insight (exponential convergence); and applying the result above to \(t = \gamma n\), we seem to recover the traditional rate proportional to \(\exp( – \gamma \mu n)\); HOWEVER, this is only true asymptotically for \(\gamma\) tending to zero, and proving a result for gradient descent requires extra steps to deal with having a constant step-size. This requires typically \(\gamma \leqslant 1/L\), where \(L\) is the smoothness constant of \(f\), and the simplest proof happens to use the same structure (see [<a href="https://arxiv.org/pdf/1608.04636">13</a>] and references therein, as well as [<a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=zvmmf&amp;paperid=7813&amp;what=fullt&amp;option_lang=eng">14</a>]).</p>



<p class="justify-text">Without strong convexity, we have, using the tangent property at \(X(t)\) and \(x_\ast\): $$ \frac{d}{dt}\big[   \| X(t)\ – x_\ast \|^2 \big] = \ –   2 ( X(t) \ – x_\ast )^\top \nabla f(X(t)) \leqslant \ – 2 \big[ f(X(t)) \ – f(x_\ast) \big],$$  leading to, by integrating from \(0\) to \(t\), and using the monotonicity of \(f(X(t))\): $$  f(X(t)) \ – f(x_\ast) \leqslant \frac{1}{t} \int_0^t \big[ f(X(u)) \ – f(x_\ast) \big] du \leqslant \frac{1}{2t} \| X(0) \ – x_\ast \|^2 \ – \frac{1}{2t} \| X(t) \ – x_\ast \|^2.$$ We recover the usual rates in \(O(1/n)\), with \(t = \gamma n\), with the same caveat as above (the step-size needs to be bounded).</p>



<h2>Conclusion</h2>



<p class="justify-text">In this blog post, I covered the basic aspects of gradient flows, in particular their relationships with various forms of gradient descent, and their use in obtaining simple convergence justifications. Next months, I will cover extensions of the analyses above, in particular in terms of (1) acceleration for convex functions, where several flows and discretizations are interesting beyond the gradient flow and Euler method [12, 15], and (2) another class of functions which includes non-convex functions as encountered when learning with neural networks [16].</p>



<h2>References</h2>



<p class="justify-text">[1] Augustin Louis Cauchy. <a href="http://gallica.bnf.fr/ark:/12148/bpt6k90190w/f406">Méthode générale pour la résolution des systèmes d’équations simultanées</a>. Compte Rendu à l’Académie des Sciences, 25:536–538, 1847.<br />[2] Claude Lemaréchal. <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/40_lemarechal-claude.pdf">Cauchy and the Gradient Method</a>. <em>Documenta Mathematica</em>, <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/vol-ismp.html">Extra Volume: Optimization Stories</a>, 251–254, 2012.<br />[3] Yurii Nesterov. <em>Introductory lectures on convex optimization: A basic course</em> (Vol. 87). Springer Science &amp; Business Media, 2013.<br />[4] Dimitri P. Bertsekas, <em>Nonlinear programming</em>. Athena Scientific, 1999.<br />[5] Jorge Nocedal and Stephen Wright. <em>Numerical optimization</em>. Springer Science &amp; Business Media, 2006.<br />[6] Arnak S. Dalalyan. <a href="https://rss.onlinelibrary.wiley.com/doi/epdf/10.1111/rssb.12183">Theoretical guarantees for approximate sampling from smooth and log‐concave densities</a>. <em>Journal of the Royal Statistical Society: Series B (Statistical Methodology)</em>, 79(3), 651-676, 2017.<br />[7] Filippo Santambrogio. <a href="https://link.springer.com/content/pdf/10.1007/s13373-017-0101-1.pdf">{Euclidean, metric, and Wasserstein} gradient flows: an overview</a>. <em>Bulletin of Mathematical Sciences</em>, <em>7</em>(1), 87-154, 2017.<br />[8] Stanislaw Lojasiewicz. Sur les trajectoires du gradient d’une fonction analytique. <em>Seminari di Geometria</em>, 1983:115–117, 1982.<br />[9] Jérôme Bolte, Aris Daniilidis, and Adrian Lewis. <a href="https://www.sciencedirect.com/sdfe/reader/pii/S0022247X05006864/pdf">A nonsmooth Morse–Sard theorem for subanalytic functions</a>. <em>Journal of Mathematical Analysis and Applications</em>, 321(2):729–740, 2006.<br />[10] Jason D. Lee, Max Simchowitz, Michael I. Jordan, Benjamin Recht. <a href="http://www.jmlr.org/proceedings/papers/v49/lee16.pdf">Gradient descent only converges to minimizers</a>. <em>Conference on learning theory</em>, 1246-1257, 2016.<br />[11] Simon S. Du, Chi Jin, Jason D. Lee, Michael I. Jordan, Barnabas Poczos, Aarti Singh. <a href="https://papers.nips.cc/paper/6707-gradient-descent-can-take-exponential-time-to-escape-saddle-points.pdf">Gradient descent can take exponential time to escape saddle points</a>. <em>Advances in neural information processing systems</em>, 1067-1077, 2017.<br />[12] Damien Scieur, Vincent Roulet, Francis Bach, Alexandre d’Aspremont,. <a href="http://papers.nips.cc/paper/6711-integration-methods-and-optimization-algorithms.pdf">Integration methods and optimization algorithms</a>. <em>Advances in Neural Information Processing Systems</em>, 1109-1118, 2017.<br />[13] Hamed Karimi, Julie Nutini, Mark Schmidt. <a href="https://arxiv.org/pdf/1608.04636">Linear convergence of gradient and proximal-gradient methods under the Polyak-Lojasiewicz condition</a>. <em>Joint European Conference on Machine Learning and Knowledge Discovery in Databases</em>, 795-811, 2016.<br />[14] Boris T. Polyak. <a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=zvmmf&amp;paperid=7813&amp;what=fullt&amp;option_lang=eng">Gradient methods for minimizing functionals</a>. <em>Zh. Vychisl. Mat. Mat. Fiz.</em>, 3(4):643–653, 1963. <br />[15] Weijie Su, Stephen Boyd, Emmanuel J. Candès. <a href="http://www.jmlr.org/papers/volume17/15-084/15-084.pdf">A differential equation for modeling Nesterov’s accelerated gradient method: theory and insights</a>. <em>Journal of Machine Learning Research</em>, 17(1), 5312-5354, 2017.<br />[16] Lénaïc Chizat, Francis Bach. <a href="http://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">On the global convergence of gradient descent for over-parameterized models using optimal transport</a>. <em>Advances in Neural Information Processing Systems</em>, 3036-3046, 2018.</p>



<h2>Limits of stochastic gradient descent for vanishing step-sizes</h2>



<p class="justify-text"><strong>Convergence to gradient flow. </strong>We consider fixed times \(t = n \gamma \) and \(s = m \gamma\), and we let \(\gamma\) tend to zero, with thus \(m\) and \(n\) tending to infinity. Starting from the recursion $$x_{n+1} = x_{n}\, – \gamma \nabla f(x_{n})\  – \gamma \varepsilon_n,$$ we get the following by applying it \(m\) times: $$X(t+s) \ – X(t) = x_{n+m}-x_n = \ – \gamma \sum_{k=0}^{m-1} \nabla f\Big(X\Big(t+\frac{sk}{m}\Big)\Big)\  – \gamma \sum_{k=0}^{m-1} \varepsilon_{k+n}.$$ The term \(\displaystyle \gamma \sum_{k=0}^{m-1} \nabla f\Big(X\Big(t+\frac{sk}{m}\Big)\Big)\) converges to \(\displaystyle \int_{t}^{t+s}\!\!\! \nabla f(X(u)) du\), while the term \(\gamma \sum_{k=0}^{m-1} \varepsilon_{k+n}\) has zero expectation and variance equal to \(\gamma^2 m = \gamma s \) times the variance of each \(\varepsilon_{k+n}\), and thus it tends to zero (since \(\gamma\) tends to zero). Thus, in the limit, $$X(t+s)\  – X(t) = \ – \int_{t}^{t+s} \!\!\! \nabla f(X(u)) du,$$ which is equivalent to the gradient flow equation.</p>



<p class="justify-text"><strong>Convergence to diffusion.</strong> We consider the recursion $$x_{n+1} = x_{n}\,  – \gamma \nabla f(x_{n}) + \sqrt{2\gamma} \varepsilon_n.$$ With the same argument as above, we now get $$X(t+s) \ – X(t) = x_{n+m}-x_n =\ – \gamma \sum_{k=0}^{m-1} \nabla f\Big(X\Big(t+\frac{sk}{m}\Big)\Big)\ – \sqrt{2\gamma} \sum_{k=0}^{m-1} \varepsilon_{k+n}.$$ Now the second term has zero mean but a variance proportional to \(2s\) (<em>which does not go to zero when \(\gamma\) goes to zero</em>). We can then use when \(m\) tends to infinity the <a href="https://en.wikipedia.org/wiki/Wiener_process#Wiener_process_as_a_limit_of_random_walk">limit of the sum of independent variables as a Wiener process</a>, to get $$X(t+s)\ – X(t) =\  – \int_{t}^{t+s} \!\!\! \nabla f(X(u)) du + \sqrt{2} \big[ B(t+s)-B(t) \big].$$ The <a href="https://en.wikipedia.org/wiki/It%C3%B4_diffusion#Invariant_measures">limiting distribution</a> of \(X(t)\) happens to be the so-called <a href="https://en.wikipedia.org/wiki/Gibbs_measure">Gibbs</a> distribution, with density \(\exp(-f(x))\) (the factor of \(\sqrt{2}\) was added to avoid an extra constant factor in the Gibbs distribution). More on this in a future post.</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/gradient-flows/"><span class="datestr">at May 01, 2020 05:15 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=118">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/">A Primer on Private Statistics – Part II</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>The second part of our brief survey of differentially private statistics. This time, we show how to privately estimate the CDF of a distribution (i.e., estimate the distribution in Kolmogorov distance), and conclude with pointers to some other work in the space.</p>
<p>The first part of this series is <a href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">here</a>, and you can download both parts in PDF form <a href="http://www.gautamkamath.com/writings/primer.pdf">here</a>.</p>
<p><b>1. CDF Estimation for Discrete, Univariate Distributions </b></p>
<p>Suppose we have a distribution <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> over the ordered, discrete domain <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,\dots,D\}}" class="latex" title="{\{1,\dots,D\}}" /> and let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> be the family of all such distributions. The CDF of the distribution is the function <img src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BP%7D+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D+%5Crightarrow+%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}" class="latex" title="{\Phi_{P} : \{1,\dots,D\} \rightarrow [0,1]}" /> given by</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BP%7D%28j%29+%3D+%5Cmathop%7B%5Cmathbb+P%7D%28P+%5Cleq+j%29.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)" class="latex" title="\displaystyle \Phi_{P}(j) = \mathop{\mathbb P}(P \leq j). \ \ \ \ \ (1)" /></p>
<p>A natural measure of distance between CDFs is the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_\infty}" class="latex" title="{\ell_\infty}" /> distance, as this is the sort of convergence guarantee that the empirical CDF satisfies. That is, in the non-private setting, the empirical CDF will achieve the minimax rate, which it known by [<a href="https://kamathematics.wordpress.com/feed/#DKW56">DKW56</a>, <a href="https://kamathematics.wordpress.com/feed/#Mas90">Mas90</a>] to be <a name="eqdkw"></a></p>
<p><a name="eqdkw"></a></p>
<p><a name="eqdkw"></a></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} \right). \ \ \ \ \ (2)" /></p>
<p><a name="eqdkw"></a><a name="eqdkw"></a><a name="eqdkw"></a></p>
<p><b> 1.1. Private CDF Estimation </b></p>
<blockquote><p><b>Theorem 1</b> <em> <a name="thmcdf-ub"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \in {\mathbb N}}" class="latex" title="{n \in {\mathbb N}}" /> and every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon,\delta &gt; 0}" class="latex" title="{\epsilon,\delta &gt; 0}" />, there exists an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> such that </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%5Cleft%28%5Csqrt%7B%5Cfrac%7B1%7D%7Bn%7D%7D+%2B+%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = O\left(\sqrt{\frac{1}{n}} + \frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (3)" /></p>
</blockquote>
<p><em>Proof:</em> Assume without loss of generality that <img src="https://s0.wp.com/latex.php?latex=%7BD+%3D+2%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D = 2^{d}}" class="latex" title="{D = 2^{d}}" /> for an integer <img src="https://s0.wp.com/latex.php?latex=%7Bd+%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d \geq 1}" class="latex" title="{d \geq 1}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1 \cdots n} \sim P}" class="latex" title="{X_{1 \cdots n} \sim P}" /> be a sample. By the triangle inequality, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%7B%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%7D+%26%5Cleq%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5CPhi_%7BX%7D+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D+%2B+%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%5C%5C+%26%5Cleq%7B%7D+O%28%5Csqrt%7B1%2Fn%7D%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} " class="latex" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}{\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}} &amp;\leq{} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \Phi_{X} - \Phi_{P} \|_{\infty} + \| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) \\ &amp;\leq{} O(\sqrt{1/n}) + \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}), \end{array} " /></p>
<p>so we will focus on constructing <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> to approximate <img src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Phi_{X}}" class="latex" title="{\Phi_{X}}" />.</p>
<p>For any <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+0%2C%5Cdots%2Cd-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell = 0,\dots,d-1}" class="latex" title="{\ell = 0,\dots,d-1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2C2%5E%7Bd+-+%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j = 1,\dots,2^{d - \ell}}" class="latex" title="{j = 1,\dots,2^{d - \ell}}" />, consider the statistics</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_%7B%5Cell%2Cj%7D%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Cfrac%7B1%7D%7Bn%7D+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%7B%5Cbf+1%7D%5C%7B+%28j-1%292%5E%7B%5Cell%7D+%2B+1+%5Cleq+X_i+%5Cleq+j+2%5E%7B%5Cell%7D+%5C%7D.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)" class="latex" title="\displaystyle f_{\ell,j}(X_{1 \cdots n}) = \frac{1}{n} \sum_{i=1}^{n} {\bf 1}\{ (j-1)2^{\ell} + 1 \leq X_i \leq j 2^{\ell} \}. \ \ \ \ \ (4)" /></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7Bf+%3A+%5C%7B1%2C%5Cdots%2CD%5C%7D%5En+%5Crightarrow+%5B0%2C1%5D%5E%7B2D+-+2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}" class="latex" title="{f : \{1,\dots,D\}^n \rightarrow [0,1]^{2D - 2}}" /> be the function whose output consists of all <img src="https://s0.wp.com/latex.php?latex=%7B2D-2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2D-2}" class="latex" title="{2D-2}" /> such counts. To decipher this notation, for a given <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" />, the counts <img src="https://s0.wp.com/latex.php?latex=%7Bf_%7B%5Cell%2C%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_{\ell,\cdot}}" class="latex" title="{f_{\ell,\cdot}}" /> form a histogram of <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1 \cdots n}}" class="latex" title="{X_{1 \cdots n}}" /> using consecutive bins of width <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cell%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{\ell}}" class="latex" title="{2^{\ell}}" />, and we consider the <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log(D)}" class="latex" title="{\log(D)}" /> histograms of geometrically increasing width <img src="https://s0.wp.com/latex.php?latex=%7B1%2C2%2C4%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1,2,4,\dots,D}" class="latex" title="{1,2,4,\dots,D}" />. First, we claim that the function <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has low sensitivity—for adjacent samples <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'}" class="latex" title="{X'}" />,</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2%5E2+%5Cleq+%5Cfrac%7B2+%5Clog%28D%29%7D%7Bn%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)" class="latex" title="\displaystyle \| f(X) - f(X') \|_2^2 \leq \frac{2 \log(D)}{n^2}. \ \ \ \ \ (5)" /></p>
<p>Thus, we can use the Gaussian mechanism:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%27%28X_%7B1+%5Ccdots+n%7D%29+%3D+f%28X_%7B1+%5Ccdots+n%7D%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+%5Clog%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7B2D+%5Ctimes+2D%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)" class="latex" title="\displaystyle M'(X_{1 \cdots n}) = f(X_{1 \cdots n}) + \mathcal{N}\left(0, \frac{2 \log(D) \log(1/\delta)}{\epsilon^2 n^2} \cdot \mathbb{I}_{2D \times 2D}\right). \ \ \ \ \ (6)" /></p>
<p>As we will argue, there exists a matrix <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Cin+%7B%5Cmathbb+R%7D%5E%7B2D+%5Ctimes+2D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \in {\mathbb R}^{2D \times 2D}}" class="latex" title="{A \in {\mathbb R}^{2D \times 2D}}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D+%3D+A+%5Ccdot+f%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}" class="latex" title="{\Phi_{X} = A \cdot f(X_{1 \cdots n})}" />. We will let <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%3D+A+%5Ccdot+M%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}" class="latex" title="{M(X_{1 \cdots n}) = A \cdot M'(X_{1 \cdots n})}" />. Since differential privacy is closed under post-processing, <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> inherits the privacy of <img src="https://s0.wp.com/latex.php?latex=%7BM%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M'}" class="latex" title="{M'}" />.</p>
<p>We will now show how to construct the matrix <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and analyze the error of <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />. For any <img src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+1%2C%5Cdots%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j = 1,\dots,D}" class="latex" title="{j = 1,\dots,D}" />, we can form the interval <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2Cj%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,\dots,j\}}" class="latex" title="{\{1,\dots,j\}}" /> as the union of at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log D}" class="latex" title="{\log D}" /> disjoint intervals of the form we’ve computed, and therefore we can obtain <img src="https://s0.wp.com/latex.php?latex=%7B%5CPhi_%7BX%7D%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Phi_{X}(j)}" class="latex" title="{\Phi_{X}(j)}" /> as the sum of at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log D}" class="latex" title="{\log D}" /> of the entries of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" />. For example, if <img src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j = 5}" class="latex" title="{j = 5}" /> then we can write</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7B1%2C%5Cdots%2C7%5C%7D+%3D+%5C%7B1%2C%5Cdots%2C4%5C%7D+%5Ccup+%5C%7B5%2C6%5C%7D+%5Ccup+%5C%7B7%5C%7D+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)" class="latex" title="\displaystyle \{1,\dots,7\} = \{1,\dots,4\} \cup \{5,6\} \cup \{7\} \ \ \ \ \ (7)" /></p>
<p>and</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%285%29+%3D+f_%7B2%2C1%7D+%2B+f_%7B1%2C3%7D+%2B+f_%7B0%2C7%7D.+%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)" class="latex" title="\displaystyle \Phi_{X}(5) = f_{2,1} + f_{1,3} + f_{0,7}. \ \ \ \ \ (8)" /></p>
<p>See the following diagram for a visual representation of the decomposition.</p>
<p><img width="547" alt="bin-tree-mech" src="https://kamathematics.files.wordpress.com/2020/04/bin-tree-mech.png" class=" wp-image-142 aligncenter" height="300" /></p>
<p>This shows hierarchical decomposition of the domain <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C8%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,\dots,8\}}" class="latex" title="{\{1,\dots,8\}}" /> using 14 intervals. The highlighted squares represent the interval <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2C7%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,\dots,7\}}" class="latex" title="{\{1,\dots,7\}}" /> and the highlighted circles show the decomposition of this interval into a union of <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" /> intervals in the tree.</p>
<p>Thus we can construct the matrix <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> using this information. Note that each entry of <img src="https://s0.wp.com/latex.php?latex=%7BA+f%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A f(X)}" class="latex" title="{A f(X)}" /> is the sum of at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log(D)}" class="latex" title="{\log(D)}" /> entries of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" />. Thus, if we use the output of <img src="https://s0.wp.com/latex.php?latex=%7BM%27%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M'(X_{1 \cdots n})}" class="latex" title="{M'(X_{1 \cdots n})}" /> in place of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X_%7B1+%5Ccdots+n%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X_{1 \cdots n})}" class="latex" title="{f(X_{1 \cdots n})}" />, for every <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> we obtain</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPhi_%7BX%7D%28j%29+%2B+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2%29+%5Cquad+%5Ctextrm%7Bfor%7D+%5Cquad+%5Csigma%5E2+%3D+%5Cfrac%7B+2+%5Clog%5E2%28D%29+%5Clog%281%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)" class="latex" title="\displaystyle \Phi_{X}(j) + \mathcal{N}(0, \sigma^2) \quad \textrm{for} \quad \sigma^2 = \frac{ 2 \log^2(D) \log(1/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (9)" /></p>
<p>Applying standard bounds on the expected supremum of a Gaussian process, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BX%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+O%28+%5Csigma+%5Csqrt%7B%5Clog+D%7D%29+%3D+O%5Cleft%28%5Cfrac%7B%5Clog%5E%7B3%2F2%7D%28D%29+%5Clog%5E%7B1%2F2%7D%281%2F%5Cdelta%29%7D%7B%5Cepsilon+n%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)" class="latex" title="\displaystyle \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \Phi_{X} \|_{\infty}) = O( \sigma \sqrt{\log D}) = O\left(\frac{\log^{3/2}(D) \log^{1/2}(1/\delta)}{\epsilon n} \right). \ \ \ \ \ (10)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p><b> 1.2. Why Restrict the Domain? </b></p>
<p>A drawback of the estimator we constructed is that it only applies to distributions of finite support <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C2%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,2,\dots,D\}}" class="latex" title="{\{1,2,\dots,D\}}" />, albeit with a relatively mild dependence on the support size. If privacy isn’t a concern, then no such restriction is necessary, as the bound <a href="https://kamathematics.wordpress.com/feed/#eqdkw">(2)</a> applies equally well to any distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}}" class="latex" title="{{\mathbb R}}" />. Can we construct a differentially private estimator for distributions with infinite support?</p>
<p>Perhaps surprisingly, the answer to this question is no! Any differentially private estimator for the CDF of the distribution has to have a rate that depends on the support size, and cannot give non-trivial rates for distributions with infinite support.</p>
<blockquote><p><b>Theorem 2 ([<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>])</b> <em> <a name="thmcdf-lb"></a> If <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> consists of all distributions on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2CD%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,\dots,D\}}" class="latex" title="{\{1,\dots,D\}}" />, then </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B1%2C+%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5CPhi_%7BP%7D+%5C%7C_%7B%5Cinfty%7D%29+%3D+%5COmega%5Cleft%28%5Cfrac%7B%5Clog%5E%2A+D%7D%7Bn%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)" class="latex" title="\displaystyle \min_{M \in \mathcal{M}_{1, \frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \Phi_{P} \|_{\infty}) = \Omega\left(\frac{\log^* D}{n} \right). \ \ \ \ \ (11)" /></p>
</blockquote>
<p>The notation <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log^* D}" class="latex" title="{\log^* D}" /> refers to the <a href="https://en.wikipedia.org/wiki/Iterated_logarithm">iterated logarithm</a>.</p>
<p>We emphasize that this theorem shouldn’t meet with too much alarm, as <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%5E%2A+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log^* D}" class="latex" title="{\log^* D}" /> grows remarkably slowly with <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />. There are differentially private CDF estimators that achieve very mild dependence on <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> [<a href="https://kamathematics.wordpress.com/feed/#BNS13">BNS13</a>, <a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>], including one nearly matching the lower bound in Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a>. Moreover, if we want to estimate a distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}}" class="latex" title="{{\mathbb R}}" />, and are willing to make some mild regularity conditions on the distribution, then we can approximate it by a distribution with finite support and only increase the rate slightly. However, what Theorem <a href="https://kamathematics.wordpress.com/feed/#thmcdf-lb">2</a> shows is that there is no “one-size-fits-all” solution to private CDF estimation that achieves similar guarantees to the empirical CDF. That is, the right algorithm has to be tailored somewhat to the application and the assumptions we can make about the distribution.</p>
<p><b>2. More Private Statistics </b></p>
<p>Of course, the story doesn’t end here! There’s a whole wide world of differentially private statistics beyond what we’ve mentioned already. We proceed to survey just a few other directions of study in private statistics.</p>
<p><b> 2.1. Parameter and Distribution Estimation </b></p>
<p>A number of the early works in differential privacy give methods for differentially private statistical estimation for i.i.d. data. The earliest works [<a href="https://kamathematics.wordpress.com/feed/#DN03">DN03</a>, <a href="https://kamathematics.wordpress.com/feed/#DN04">DN04</a>, <a href="https://kamathematics.wordpress.com/feed/#BDMN05">BDMN05</a>, <a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>], which introduced the Gaussian mechanism, among other foundational results, can be thought of as methods for estimating the mean of a distribution over the hypercube <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0,1\}^d}" class="latex" title="{\{0,1\}^d}" /> in the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_\infty}" class="latex" title="{\ell_\infty}" /> norm. Tight lower bounds for this problem follow from the tracing attacks introduced in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>]. A very recent work of Acharya, Sun, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#ASZ20">ASZ20</a>] adapts classical tools for proving estimation and testing lower bounds (lemmata of Assouad, Fano, and Le Cam) to the differentially private setting. Steinke and Ullman [<a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>] give tight minimax lower bounds for the weaker guarantee of selecting the largest coordinates of the mean, which were refined by Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] to give lower bounds for sparse mean-estimation problems.</p>
<p>Nissim, Raskhodnikova, and Smith introduced the highly general sample-and-aggregate paradigm, which they apply to several learning problems (e.g., learning mixtures of Gaussians) [<a href="https://kamathematics.wordpress.com/feed/#NRS07">NRS07</a>]. Later, Smith [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>] showed that this paradigm can be used to transform any estimator for any asymptotically normal, univariate statistic over a bounded data domain into a differentially private one with the same asymptotic convergence rate.</p>
<p>Subsequent work has focused on both relaxing the assumptions in [<a href="https://kamathematics.wordpress.com/feed/#Smi11">Smi11</a>], particularly boundedness, and on giving finite-sample guarantees. Karwa and Vadhan investigated the problem of Gaussian mean estimation, proving the first near-optimal bounds for this setting [<a href="https://kamathematics.wordpress.com/feed/#KV18">KV18</a>]. In particular, exploiting concentration properties of Gaussian data allows us to achieve non-trivial results even with unbounded data, which is impossible in general. Following this, Kamath, Li, Singhal, and Ullman moved to the multivariate setting, investigating the estimation of Gaussians and binary product distributions in total variation distance [<a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. In certain cases (i.e., Gaussians with identity covariance), this is equivalent to mean estimation in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2}" class="latex" title="{\ell_2}" />-distance, though not always. For example, for binary product distribution, one must estimate the mean in a type of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi^2}" class="latex" title="{\chi^2}" />-distance instead. The perspective of distribution estimation rather than parameter estimation can be valuable. Bun, Kamath, Steinke, and Wu [<a href="https://kamathematics.wordpress.com/feed/#BKSW19">BKSW19</a>] develop a primitive for private hypothesis selection, which they apply to learn any coverable class of distributions under pure differential privacy. Through the lens of distribution estimation, their work implies an upper bound for mean estimation of binary product distributions that bypasses lower bounds for the same problem in the empirical setting. In addition to work on mean estimation in the sub-Gaussian setting, such as the results discussed earlier, mean estimation has also been studied under weaker moment conditions [<a href="https://kamathematics.wordpress.com/feed/#BS19">BS19</a>, <a href="https://kamathematics.wordpress.com/feed/#KSU20">KSU20</a>]. Beyond these settings, there has also been study of estimation of discrete multinomials, including estimation in Kolmogorov distance [<a href="https://kamathematics.wordpress.com/feed/#BNSV15">BNSV15</a>] and in total variation distance for structured distributions [<a href="https://kamathematics.wordpress.com/feed/#DHS15">DHS15</a>], and parameter estimation of Markov Random Fields [<a href="https://kamathematics.wordpress.com/feed/#ZKKW20">ZKKW20</a>].</p>
<p>A different approach to constructing differentially private estimators is based on robust statistics. This approah begins with the influential work of Dwork and Lei [<a href="https://kamathematics.wordpress.com/feed/#DL09">DL09</a>], which introduced the propose-test-release framework, and applied to estimating robust statistics such as the median and interquartile range. While the definitions in robust statistics and differential privacy are semantically similar, formal connections between the two remain relatively scant, which suggests a productive area for future study.</p>
<p><b> 2.2. Hypothesis Testing </b></p>
<p>An influential work of Homer et al. [<a href="https://kamathematics.wordpress.com/feed/#HSRDTMPSNC08">HSRDTMPSNC08</a>] demonstrated the vulnerability of classical statistics in a genomic setting, showing that certain <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi^2}" class="latex" title="{\chi^2}" />-statistics on many different variables could allow an attacker to determine the presence of an individual in a genome-wide association study (GWAS). Motivated by these concerns, an early line of work from the statistics community focused on addressing these issues [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>, <a href="https://kamathematics.wordpress.com/feed/#USF13">USF13</a>, <a href="https://kamathematics.wordpress.com/feed/#YFSU14">YFSU14</a>].</p>
<p>More recently, work on private hypothesis testing can be divided roughly into two lines. The first focuses on the minimax sample complexity, in a line initiated by Cai, Daskalakis, and Kamath [<a href="https://kamathematics.wordpress.com/feed/#CDK17">CDK17</a>], who give an algorithm for privately testing goodness-of-fit (more precisely, a statistician might refer to this problem as one-sample testing of multinomial data). A number of subsequent works have essentially settled the complexity of this problem [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>], giving tight upper and lower bounds. Other papers in this line study related problems, including the two-sample version of the problem, independence testing, and goodness-of-fit testing for multivariate product distributions [<a href="https://kamathematics.wordpress.com/feed/#ASZ18">ASZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADR18">ADR18</a>, <a href="https://kamathematics.wordpress.com/feed/#ADKR19">ADKR19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMUZ19">CKMUZ19</a>]. A related paper studies the minimax sample complexity of property <em>estimation</em>, rather than testing of discrete distributions, including support size and entropy [<a href="https://kamathematics.wordpress.com/feed/#AKSZ18">AKSZ18</a>]. Other recent works in this vein focus on testing of simple hypotheses [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>]. In particular [<a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>] proves an analogue of the Neyman-Pearson Lemma for differentially private testing of simple hypotheses. A paper of Awan and Slavkovic [<a href="https://kamathematics.wordpress.com/feed/#AS18">AS18</a>] gives a universally optimal test when the domain size is two, however Brenner and Nissim [<a href="https://kamathematics.wordpress.com/feed/#BN14">BN14</a>] shows that such universally optimal tests cannot exist when the domain has more than two elements. A related problem in this space is private change-point detection [<a href="https://kamathematics.wordpress.com/feed/#CKMTZ18">CKMTZ18</a>, <a href="https://kamathematics.wordpress.com/feed/#CKMSU19">CKMSU19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKLZ19">CKLZ19</a>] — in this setting, we are given a time series of datapoints which are sampled from a distribution, which at some point, changes to a different distribution. The goal is to (privately) determine when this point occurs.</p>
<p>Complementary to minimax hypothesis testing, a line of work [<a href="https://kamathematics.wordpress.com/feed/#WLK15">WLK15</a>, <a href="https://kamathematics.wordpress.com/feed/#GLRV16">GLRV16</a>, <a href="https://kamathematics.wordpress.com/feed/#KR17">KR17</a>, <a href="https://kamathematics.wordpress.com/feed/#KSF17">KSF17</a>, <a href="https://kamathematics.wordpress.com/feed/#CBRG18">CBRG18</a>, <a href="https://kamathematics.wordpress.com/feed/#SGGRGB19">SGGRGB19</a>, <a href="https://kamathematics.wordpress.com/feed/#CKSBG19">CKSBG19</a>] designs differentially private versions of popular test statistics for testing goodness-of-fit, closeness, and independence, as well as private ANOVA, focusing on the performance at small sample sizes. Work by Wang et al. [<a href="https://kamathematics.wordpress.com/feed/#WKLK18">WKLK18</a>] focuses on generating statistical approximating distributions for differentially private statistics, which they apply to hypothesis testing problems.</p>
<p><b> 2.3. Differential Privacy on Graphs </b></p>
<p>There is a significant amount of work on differentially private analysis of graphs. We remark that these algorithms can satisfy either edge or node differential privacy. The former (easier) guarantee defines a neighboring graph to be one obtained by adding or removing a single edge, while in the latter (harder) setting, a neighboring graph is one that can be obtained by modifying the set of edges connected to a single node. The main challenge in this area is that most graph statistics can have high sensitivity in the worst-case.</p>
<p>The initial works in this area focused on the empirical setting, and goals range from counting subgraphs [<a href="https://kamathematics.wordpress.com/feed/#KRSY11">KRSY11</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>, <a href="https://kamathematics.wordpress.com/feed/#CZ13">CZ13</a>, <a href="https://kamathematics.wordpress.com/feed/#RS16">RS16</a>] to outputting a privatized graph which approximates the original [<a href="https://kamathematics.wordpress.com/feed/#GRU12">GRU12</a>, <a href="https://kamathematics.wordpress.com/feed/#BBDS12">BBDS12</a>, <a href="https://kamathematics.wordpress.com/feed/#Upa13">Upa13</a>, <a href="https://kamathematics.wordpress.com/feed/#AU19">AU19</a>, <a href="https://kamathematics.wordpress.com/feed/#EKKL20">EKKL20</a>]. In contrast to the setting discussed in most of this series, it seems that there are larger qualitative differences between the study of empirical and population statistics due to the fact that many graph statistics have high worst-case sensitivity, but may have smaller sensitivity on typical graphs from many natural models.</p>
<p>In the population statistics setting, recent work has focused on parameter estimation of the underlying random graph model. So far this work has given estimators for the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta}" class="latex" title="{\beta}" />-model [<a href="https://kamathematics.wordpress.com/feed/#KS16">KS16</a>] and graphons [<a href="https://kamathematics.wordpress.com/feed/#BCS15">BCS15</a>,<a href="https://kamathematics.wordpress.com/feed/#BCSZ18">BCSZ18</a>]. Graphons are a generalization of the stochastic block model, which is, in turn, a generalization of the Erdös-Rényi model. Interestingly, the methods of Lipschitz-extensions introduced in the empirical setting by [<a href="https://kamathematics.wordpress.com/feed/#BBDS13">BBDS13</a>, <a href="https://kamathematics.wordpress.com/feed/#KNRS13">KNRS13</a>] are the main tool used in the statistical setting as well. While the first works on private graphon estimation were not computationally efficient, a recent focus has been on obviating these issues for certain important cases, such as the Erdös-Rényi setting [<a href="https://kamathematics.wordpress.com/feed/#SU19">SU19</a>].</p>
<p><b>Bibliography</b></p>
<p><a name="ADKR19"></a>[ADKR19] Maryam Aliakbarpour, Ilias Diakonikolas, Daniel M. Kane, and Ronitt Rubinfeld. Private testing of distributions via sample permutations. NeurIPS ’19.</p>
<p><a name="ADR18"></a>[ADR18] Maryam Aliakbarpour, Ilias Diakonikolas, and Ronitt Rubinfeld. Differentially private identity and closeness testing of discrete distributions. ICML ’18.</p>
<p><a name="AKSZ18"></a>[AKSZ18] Jayadev Acharya, Gautam Kamath, Ziteng Sun, and Huanyu Zhang. Inspectre: Privately estimating the unseen. ICML ’18.</p>
<p><a name="AS18"></a>[AS18] Jordan Awan and Aleksandra Slavković. Differentially private uniformly most powerful tests for binomial data. NeurIPS ’18.</p>
<p><a name="ASZ18"></a>[ASZ18] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private testing of identity and closeness of discrete distributions. NeurIPS ’18.</p>
<p><a name="ASZ20"></a>[ASZ20] Jayadev Acharya, Ziteng Sun, and Huanyu Zhang. Differentially private Assouad, Fano, and Le Cam. arXiv, 2004.06830, 2020.</p>
<p><a name="AU19"></a>[AU19] Raman Arora and Jalaj Upadhyay. On differentially private graph sparsification and applications. NeurIPS ’19.</p>
<p><a name="BBDS12"></a>[BBDS12] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. The Johnson-Lindenstrauss transform itself preserves differential privacy. FOCS ’12.</p>
<p><a name="BBDS13"></a>[BBDS13] Jeremiah Blocki, Avrim Blum, Anupam Datta, and Or Sheffet. Differentially private data analysis of social networks via restricted sensitivity. ITCS ’13.</p>
<p><a name="BCS15"></a>[BCS15] Christian Borgs, Jennifer Chayes, and Adam Smith. Private graphon estimation for sparse graphs. NIPS ’15.</p>
<p><a name="BCSZ18"></a>[BCSZ18] Christian Borgs, Jennifer Chayes, Adam Smith, and Ilias Zadik. Revealing network structure, confidentially: Improved rates for node-private graphon estimation. FOCS ’18.</p>
<p><a name="BDMN05"></a>[BDMN05] Avrim Blum, Cynthia Dwork, Frank McSherry, and Kobbi Nissim. Practical privacy: The SuLQ framework. PODS ’05.</p>
<p><a name="BKSW19"></a>[BKSW19] Mark Bun, Gautam Kamath, Thomas Steinke, and Zhiwei Steven Wu. Private hypothesis selection. NeurIPS ’19.</p>
<p><a name="BN14"></a>[BN14] Hai Brenner and Kobbi Nissim. Impossibility of differentially private universally optimal mechanisms. SIAM Journal on Computing, 43(5), 2014.</p>
<p><a name="BNS13"></a>[BNS13] Amos Beimel, Kobbi Nissim, and Uri Stemmer. Private learning and sanitization: Pure vs. approximate differential privacy. APPROX-RANDOM ’13.</p>
<p><a name="BNSV15"></a>[BNSV15] Mark Bun, Kobbi Nissim, Uri Stemmer, and Salil Vadhan. Differentially private release and learning of threshold functions. FOCS ’15.</p>
<p><a name="BS19"></a>[BS19] Mark Bun and Thomas Steinke. Average-case averages: Private algorithms for smooth sensitivity and mean estimation. NeurIPS ’19.</p>
<p><a name="BSU17"></a>[BSU17] Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p><a name="BUV14"></a>[BUV14] Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p><a name="CBRG18"></a>[CBRG18] Zachary Campbell, Andrew Bray, Anna Ritz, and Adam Groce. Differentially private ANOVA testing. ICDIS ’18.</p>
<p><a name="CDK17"></a>[CDK17] Bryan Cai, Constantinos Daskalakis, and Gautam Kamath. Priv’it: Private and sample efficient identity testing. ICML ’17.</p>
<p><a name="CKLZ19"></a>[CKLZ19] Rachel Cummings, Sara Krehbiel, Yuliia Lut, and Wanrong Zhang. Privately detecting changes in unknown distributions. arXiv, 1910.01327, 2019.</p>
<p><a name="CKMSU19"></a>[CKMSU19] Clément L. Canonne, Gautam Kamath, Audra McMillan, Adam Smith, and Jonathan Ullman. The structure of optimal private tests for simple hypotheses. STOC ’19.</p>
<p><a name="CKMTZ18"></a>[CKMTZ18] Rachel Cummings, Sara Krehbiel, Yajun Mei, Rui Tuo, and Wanrong Zhang. Differentially private change-point detection. NeurIPS ’18.</p>
<p><a name="CKMUZ19"></a>[CKMUZ19] Clément L. Canonne, Gautam Kamath, Audra McMillan, Jonathan Ullman, and Lydia Zakynthinou. Private identity testing for high-dimensional distributions. arXiv, 1905.11947, 2019.</p>
<p><a name="CKSBG19"></a>[CKSBG19] Simon Couch, Zeki Kazan, Kaiyan Shi, Andrew Bray, and Adam Groce. Differentially private nonparametric hypothesis testing. CCS ’19.</p>
<p><a name="CWZ19"></a>[CWZ19] T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p><a name="CZ13"></a>[CZ13] Shixi Chen and Shuigeng Zhou. Recursive mechanism: Towards node differential privacy and unrestricted joins. SIGMOD ’13.</p>
<p><a name="DHS15"></a>[DHS15] Ilias Diakonikolas, Moritz Hardt, and Ludwig Schmidt. Differentially private learning of structured discrete distributions. NIPS ’15.</p>
<p><a name="DKW56"></a>[DKW56] Aryeh Dvoretzky, Jack Kiefer, and Jacob Wolfowitz. Asymptotic minimax character of the sample distribution function and of the classical multinomial estimator. The Annals of Mathematical Statistics, 27(3), 1956.</p>
<p><a name="DL09"></a>[DL09] Cynthia Dwork and Jing Lei. Differential privacy and robust statistics. STOC ’09.</p>
<p><a name="DMNS06"></a>[DMNS06] Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p><a name="DN03"></a>[DN03] Irit Dinur and Kobbi Nissim. Revealing information while preserving privacy. PODS ’03.</p>
<p><a name="DN04"></a>[DN04] Cynthia Dwork and Kobbi Nissim. Privacy-preserving datamining on vertically partitioned databases. CRYPTO ’04.</p>
<p><a name="DSSUV15"></a>[DSSUV15] Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p><a name="EKKL20"></a>[EKKL20] Marek Eliáš, Michael Kapralov, Janardhan Kulkarni, and Yin Tat Lee. Differentially private release of synthetic graphs. SODA ’20.</p>
<p><a name="GLRV16"></a>[GLRV16] Marco Gaboardi, Hyun-Woo Lim, Ryan M. Rogers, and Salil P. Vadhan. Differentially private chi-squared hypothesis testing: Goodness of fit and independence testing. ICML ’16.</p>
<p><a name="GRU12"></a>[GRU12] Anupam Gupta, Aaron Roth, and Jonathan Ullman. Iterative constructions and private data release. TCC ’12.</p>
<p><a name="HSRDTMPSNC08"></a>[HSRDTMPSNC08] Nils Homer, Szabolcs Szelinger, Margot Redman, David Duggan, Waibhav Tembe, Jill Muehling, John V. Pearson, Dietrich A. Stephan, Stanley F. Nelson, and David W. Craig. PLoS Genetics, 4(8), 2008.</p>
<p><a name="KLSU19"></a>[KLSU19] Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p><a name="KNRS13"></a>[KNRS13] Shiva Prasad Kasiviswanathan, Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Analyzing graphs with node differential privacy. TCC ’13.</p>
<p><a name="KR17"></a>[KR17] Daniel Kifer and Ryan M. Rogers. A new class of private chi-square tests. AISTATS ’17.</p>
<p><a name="KRSY11"></a>[KRSY11] Vishesh Karwa, Sofya Raskhodnikova, Adam Smith, and Grigory Yaroslavtsev. Private analysis of graph structure. VLDB ’11.</p>
<p><a name="KS16"></a>[KS16] Vishesh Karwa and Aleksandra Slavković. Inference using noisy degrees: Differentially private β-model and synthetic graphs. The Annals of Statistics, 44(1), 2016.</p>
<p><a name="KSF17"></a>[KSF17] Kazuya Kakizaki, Jun Sakuma, and Kazuto Fukuchi. Differentially private chi-squared test by unit circle mechanism. ICML ’17.</p>
<p><a name="KSU20"></a>[KSU20] Gautam Kamath, Vikrant Singhal, and Jonathan Ullman. Private mean estimation of heavy-tailed distributions. arXiv, 2002.09464, 2020.</p>
<p><a name="KV18"></a>[KV18] Vishesh Karwa and Salil Vadhan. Finite sample differentially private confidence intervals. ITCS ’18.</p>
<p><a name="Mas90"></a>[Mas90] Pascal Massart. The tight constant in the Dvoretzky-Kiefer-Wolfowitz inequality. The Annals of Probability, 18(3), 1990.</p>
<p><a name="NRS07"></a>[NRS07] Kobbi Nissim, Sofya Raskhodnikova, and Adam Smith. Smooth sensitivity and sampling in private data analysis. STOC ’07.</p>
<p><a name="RS16"></a>[RS16] Sofya Raskhodnikova and Adam D. Smith. Lipschitz extensions for node-private graph statistics and the generalized exponential mechanism. FOCS ’16.</p>
<p><a name="Smi11"></a>[Smi11] Adam Smith. Privacy-preserving statistical estimation with optimal convergence rates. STOC ’11.</p>
<p><a name="SGGRGB19"></a>[SGGRGB19] Marika Swanberg, Ira Globus-Harris, Iris Griffith, Anna Ritz, Adam Groce, and Andrew Bray. Improved differentially private analysis of variance. PETS ’19.</p>
<p><a name="SU17a"></a>[SU17a] Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p><a name="SU17b"></a>[SU17b] Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p><a name="SU19"></a>[SU19] Adam Sealfon and Jonathan Ullman. Efficiently estimating Erdos-Renyi graphs with node differential privacy. NeurIPS ’19.</p>
<p><a name="Upa13"></a>[Upa13] Jalaj Upadhyay. Random projections, graph sparsification, and differential privacy. ASIACRYPT ’13.</p>
<p><a name="USF13"></a>[USF13] Caroline Uhler, Aleksandra Slavković, and Stephen E. Fienberg. Privacy-preserving data sharing for genome-wide association studies. The Journal of Privacy and Confidentiality, 5(1), 2013.</p>
<p><a name="VS09"></a>[VS09] Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>
<p><a name="WKLK18"></a>[WKLK18] Yue Wang, Daniel Kifer, Jaewoo Lee, and Vishesh Karwa. Statistical approximating distributions under differential privacy. The Journal of Privacy and Confidentiality, 8(1), 2018.</p>
<p><a name="WLK15"></a>[WLK15] Yue Wang, Jaewoo Lee, and Daniel Kifer. Revisiting differentially private hypothesis tests for categorical data. arXiv, 1511.03376, 2015.</p>
<p><a name="YFSU14"></a>[YFSU14] Fei Yu, Stephen E. Fienberg, Aleksandra B. Slavković, and Caroline Uhler. Scalable privacy-preserving data sharing methodology for genome-wide association studies. Journal of Biomedical Informatics, 50, 2014.</p>
<p><a name="ZKKW20"></a>[ZKKW20] Huanyu Zhang, Gautam Kamath, Janardhan Kulkarni, and Zhiwei Steven Wu. Privately learning Markov random fields. arXiv, 2002.09463, 2020.</p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/04/21/a-primer-on-private-statistics-part-ii/"><span class="datestr">at April 21, 2020 01:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=49">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">A Primer on Private Statistics – Part I</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>Differentially private statistics is a very lively research area, and has seen a lot of activity in the last couple years. While the phrasing is a slight departure from previous work which focused on estimation with worst-case datasets, it turns out that the differences are often superficial. In a short series of blog posts, we hope to educate readers on some of the recent advancements in this area, as well as shed light on some of the connections between the old and the new. We’ll describe the settings, cover a couple of technical examples, and give pointers to some other directions in the area. Thanks to <a href="https://cs-people.bu.edu/ads22/">Adam Smith</a> for helping kick off this project, <a href="http://www.cs.columbia.edu/~ccanonne/">Clément Canonne</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, and <a href="http://www.thomas-steinke.net/">Thomas Steinke</a> for helpful comments, and <a href="https://lucatrevisan.github.io/">Luca Trevisan</a> for his <a href="https://lucatrevisan.wordpress.com/latex-to-wordpress/">LaTeX2WP script</a>.</p>
<p><b>1. Introduction </b></p>
<p>Statistics and machine learning are now ubiquitous in data analysis. Given a dataset, one immediately wonders what it allows us to infer about the underlying population. However, modern datasets don’t exist in a vacuum: they often contain sensitive information about the individuals they represent. Without proper care, statistical procedures will result in gross violations of privacy. Motivated by the shortcomings of ad hoc methods for data anonymization, Dwork, McSherry, Nissim, and Smith introduced the celebrated notion of differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>].</p>
<p>From its inception, some of the driving motivations for differential privacy were applications in statistics and the social sciences, notably disclosure limitation for the US Census. And yet, the lion’s share of differential privacy research has taken place within the computer science community. As a result, the specific applications being studied are often not formulated using statistical terminology, or even as statistical problems. Perhaps most significantly, much of the early work in computer science (though definitely not all) focus on estimating some property <em>of a dataset</em> rather than estimating some property <em>of an underlying population</em>.</p>
<p>Although the earliest works exploring the interaction between differential privacy and classical statistics go back to at least 2009 [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>,<a href="https://kamathematics.wordpress.com/feed/#FRY10">FRY10</a>], the emphasis on differentially private statistical inference in the computer science literature is somewhat more recent. However, while earlier results on differential privacy did not always formulate problems in a statistical language, statistical inference was a key motivation for most of this work. As a result many of the techniques that were developed have direct applications in statistics, for example establishing minimax rates for estimation problems.</p>
<p>The purpose of this series of blog posts is to highlight some of those results in the computer science literature, and present them in a more statistical language. Specifically, we will discuss:</p>
<ul>
<li>Tight minimax lower bounds for privately estimating the mean of a multivariate distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" />, using the technique of <em>tracing attacks</em> developed in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>,<a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>].
<p> </p>
</li>
<li>Upper bounds for estimating a distribution in Kolmogorov distance, using the ubiquitous <em>binary-tree mechanism</em> introduced in [<a href="https://kamathematics.wordpress.com/feed/#DNPR10">DNPR10</a>,<a href="https://kamathematics.wordpress.com/feed/#CSS11">CSS11</a>].</li>
</ul>
<p>In particular, we hope to encourage computer scientists working on differential privacy to pay more attention to the applications of their methods in statistics, and share with statisticians many of the powerful techniques that have been developed in the computer science literature.</p>
<p> </p>
<p><b> 1.1. Formulating Private Statistical Inference </b></p>
<p>Essentially every differentially private statistical estimation task can be phrased using the following setup. We are given a dataset <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C+%5Cdots%2C+X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1, \dots, X_n)}" class="latex" title="{X = (X_1, \dots, X_n)}" /> of size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, and we wish to design an algorithm <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Cin+%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \in \mathcal{M}}" class="latex" title="{M \in \mathcal{M}}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}}" class="latex" title="{\mathcal{M}}" /> is the class of mechanisms that are both:</p>
<ol>
<li>differentially private, and</li>
<li>accurate, either in expectation or with high probability, according to some task-specific measure.</li>
</ol>
<p>A few comments about this framework are in order. First, although the accuracy requirement is stochastic in nature (i.e., an algorithm might not be accurate depending on the randomness of the algorithm and the data generation process), the privacy requirement is worst-case in nature. That is, the algorithm must protect privacy for every dataset <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, even those we believe are very unlikely.</p>
<p>Second, the accuracy requirement is stated rather vaguely. This is because the notion of accuracy of an algorithm is slightly more nuanced, depending on whether we are concerned with <em>empirical</em> or <em>population</em> statistics. A particular emphasis of these blog posts is to explore the difference (or, as we will see, the lack of a difference) between these two notions of accuracy. The former estimates a quantity of the observed dataset, while the latter estimates a quantity of an unobserved distribution which is assumed to have generated the dataset.</p>
<p>More precisely, the former can be phrased in terms of empirical loss, of the form:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BX+%5Cin+%5Cmathcal%7BX%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_M%28%5Cell%28M%28X%29%2C+f%28X%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " class="latex" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}}" class="latex" title="{\mathcal{M}}" /> is some class of <em>randomized estimators</em> (e.g., differentially private estimators), <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{X}}" class="latex" title="{\mathcal{X}}" /> is some class of <em>datasets</em>, <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is some quantity of interest, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> is some <em>loss function</em>. That is, we’re looking to find an estimator that has small expected loss on <em>any dataset</em> in some class.</p>
<p>In contrast, statistical minimax theory looks at statements about population loss, of the form:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_%7BX+%5Csim+P%2C+M%7D%28%5Cell%28M%28X%29%2Cf%28P%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " class="latex" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> is some family of <em>distributions</em> over datasets (typically consisting of i.i.d. samples). That is, we’re looking to find an estimator that has small expected loss on random data from <em>any distribution</em> in some class. In particular, note that the randomness in this objective additionally includes the data generating procedure <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim P}" class="latex" title="{X \sim P}" />.</p>
<p>These two formulations are formally very different in several ways. First, the empirical formulation requires an estimator to have small loss on <em>worst-case</em> datasets, whereas the statistical formulation only requires the estimator to have small loss <em>on average</em> over datasets drawn from certain distributions. Second, the statistical formulation requires that we estimate the unknown quantity <img src="https://s0.wp.com/latex.php?latex=%7Bf%28P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(P)}" class="latex" title="{f(P)}" />, and thus necessitates a solution to the non-private estimation problem. On the other hand, the empirical formulation only asks us to estimate the known quantity <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" />, and thus if there were no privacy constraint it would always be possible to compute <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" /> exactly. Third, typically in the statistical formulation, we require that the dataset is drawn i.i.d., which means that we are more constrained when proving lower bounds for estimation than we are in the empirical problem.</p>
<p>However, in practice (more precisely, in the practice of doing theoretical research), these two formulations are more alike than they are different, and results about one formulation often imply results about the other formulation. On the algorithmic side, classical statistical results will often tell us that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f(X),f(P))}" class="latex" title="{\ell(f(X),f(P))}" /> is small, in which case algorithms that guarantee <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(M(X),f(X))}" class="latex" title="{\ell(M(X),f(X))}" /> is small also guarantee <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(M(X),f(P))}" class="latex" title="{\ell(M(X),f(P))}" /> is small.</p>
<p>Moreover, typical lower bound arguments for empirical quantities are often statistical in nature. These typically involving constructing some simple “hard distribution” over datasets such that no private algorithm can estimate well on average for this distribution, and thus these lower bound arguments also apply to estimating population statistics for some simple family of distributions. We will proceed to give some examples of estimation problems that were originally studied by computer scientists with the empirical formulation in mind. These results either implicitly or explicitly provide solutions to the corresponding population versions of the same problems—our goal is to spell out and illustrate these connections.</p>
<p><b>2. DP Background </b></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2CX_2%2C%5Cdots%2CX_n%29+%5Cin+%5Cmathcal%7BX%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" class="latex" title="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" /> be a collection of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> samples where each individual sample comes from the domain <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{X}}" class="latex" title="{\mathcal{X}}" />. We say that two samples <img src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27+%5Cin+%5Cmathcal%7BX%7D%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,X' \in \mathcal{X}^*}" class="latex" title="{X,X' \in \mathcal{X}^*}" /> are <em>adjacent</em>, denoted <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim X'}" class="latex" title="{X \sim X'}" />, if they differ on at most one individual sample. Intuitively, a randomized algorithm <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, which is often called a <em>mechanism</em> for historical reasons, is <em>differentially private</em> if the distribution of <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X')}" class="latex" title="{M(X')}" /> are similar for every pair of adjacent samples <img src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,X'}" class="latex" title="{X,X'}" />.</p>
<blockquote>
<p><b>Definition 1 ([<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> A mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" /> is <em><img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private</em> if for every pair of adjacent datasets <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim X'}" class="latex" title="{X \sim X'}" />, and every (measurable) <img src="https://s0.wp.com/latex.php?latex=%7BR+%5Csubseteq+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R \subseteq R}" class="latex" title="{R \subseteq R}" /> </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%29+%5Cin+R%29+%5Cleq+e%5E%7B%5Cepsilon%7D+%5Ccdot+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%27%29+%5Cin+R%29+%2B+%5Cdelta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " class="latex" title="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " /></p>
<p> </p>
</blockquote>
<p>We let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}_{\epsilon,\delta}}" class="latex" title="{\mathcal{M}_{\epsilon,\delta}}" /> denote the set of mechanisms that satisfy <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy.</p>
<blockquote>
<p><b>Remark 1</b> <em> To simplify notation, and to maintain consistency with the literature, we adopt the convention of defining the mechanism only for a fixed sample size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. What this means in practice is that the mechanisms we describe treat the sample size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is <em>public information</em> that need not be kept private. While one could define a more general model where <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is not fixed, it wouldn’t add anything to this discussion other than additional complexity. </em></p>
</blockquote>
<blockquote>
<p><b>Remark 2</b> <em> In these blog posts, we stick to the most general formulation of differential privacy, so-called <em>approximate differential privacy</em>, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" /> essentially because this is the notion that captures the widest variety of private mechanisms. Almost all of what follows would apply equally well, with minor technical modifications, to slightly stricter notions of <em>concentrated differential privacy [</em><a href="https://kamathematics.wordpress.com/feed/#DR16">DR16</a>, <a href="https://kamathematics.wordpress.com/feed/#BS16">BS16</a>, <a href="https://kamathematics.wordpress.com/feed/#BDRS18">BDRS18</a>], Rényi differential privacy [<a href="https://kamathematics.wordpress.com/feed/#Mir17">Mir17</a>], or <em>Gaussian differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DRS19">DRS19</a>]</em>. While so-called <em>pure differential privacy</em>, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,0)}" class="latex" title="{(\epsilon,0)}" />-differential privacy has also been studied extensively, this notion is artificially restrictive and excludes many differentially private mechanisms. </em></p>
</blockquote>
<p>A key property of differential privacy that helps when desinging efficient estimators is <em>closure under postprocessing</em>:</p>
<blockquote>
<p><b>Lemma 2 (Post-Processing [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> <a name="lempost-processing"></a> If <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private and <img src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccolon+%5Cmathcal%7BR%7D+%5Crightarrow+%5Cmathcal%7BR%7D%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" class="latex" title="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" /> is any randomized algorithm, then <img src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccirc+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M' \circ M}" class="latex" title="{M' \circ M}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private. </em></p>
</blockquote>
<p>The estimators we present in this work will use only one tool for achieving differential privacy, the <em>Gaussian Mechanism</em>.</p>
<blockquote>
<p><b>Lemma 3 (Gaussian Mechanism)</b> <em> <a name="lemgauss-mech"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" class="latex" title="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" /> be a function and let </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CDelta_%7Bf%7D+%3D+%5Csup_%7BX%5Csim+X%27%7D+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " class="latex" title="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " /></p>
<p>denote its <em><img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2}" class="latex" title="{\ell_2}" />-sensitivity</em>. The <em>Gaussian mechanism</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X%29+%3D+f%28X%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280+%2C+%5Cfrac%7B2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2%7D+%5Ccdot+%5CDelta_%7Bf%7D%5E2+%5Ccdot+%7B%5Cmathbb+I%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " class="latex" title="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " /></p>
<p><em> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy. </em></p>
</blockquote>
<p><b>3. Mean Estimation in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" /> </b></p>
<p>Let’s take a dive into the problem of <em>private mean estimation</em> for some family <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> of multivariate distributions over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" />. This problem has been studied for various families <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> and various choices of loss function. Here we focus on perhaps the simplest variant of the problem, in which <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> contains distributions of bounded support <img src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[\pm 1]^d}" class="latex" title="{[\pm 1]^d}" /> and the loss is the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2^2}" class="latex" title="{\ell_2^2}" /> error. We emphasize, however, that the methods we discuss here are quite versatile and can be used to derive minimax bounds for other variants of the mean-estimation problem.</p>
<p>Note that, by a simple argument, the non-private minimax rate for this class is achieved by the empirical mean, and is</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" /></p>
<p>The main goal of this section is to derive the minimax bound <a name="eqRd-minimax"></a></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Ctilde%5CTheta%5Cleft%28%5Cfrac%7Bd%5E2%7D%7B%5Cepsilon%5E2+n%5E2%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" class="latex" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" /></p>
<p><a name="eqRd-minimax"></a> Recall that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+%5CTheta%28f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde \Theta(f(n))}" class="latex" title="{\tilde \Theta(f(n))}" /> refers to a function which is both <img src="https://s0.wp.com/latex.php?latex=%7BO%28f%28n%29+%5Clog%5E%7Bc_1%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(f(n) \log^{c_1} f(n))}" class="latex" title="{O(f(n) \log^{c_1} f(n))}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28f%28n%29+%5Clog%5E%7Bc_2%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(f(n) \log^{c_2} f(n))}" class="latex" title="{\Omega(f(n) \log^{c_2} f(n))}" /> for some constants <img src="https://s0.wp.com/latex.php?latex=%7Bc_1%2C+c_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_1, c_2}" class="latex" title="{c_1, c_2}" />. The proof of this lower bound is based on <em>robust tracing attacks</em>, also called <em>membership inference attacks</em>, which were developed in a chain of papers [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. We remark that this lower bound is almost identical to the minimax bound for mean estimation proven in the much more recent work of Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>], but it lacks tight dependence on the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, which we discuss in the following remark.</p>
<blockquote>
<p><b>Remark 3</b> <em> The choice of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3D+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta = 1/n}" class="latex" title="{\delta = 1/n}" /> in <a href="https://kamathematics.wordpress.com/feed/#eqRd-minimax">(2)</a> may look strange at first. For the upper bound this choice is arbitrary—as we will see, we can upper bound the rate for any <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" /> at a cost of a factor of <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog%281%2F%5Cdelta%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log(1/\delta))}" class="latex" title="{O(\log(1/\delta))}" />. The lower bound applies only when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cleq+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \leq 1/n}" class="latex" title="{\delta \leq 1/n}" />. Note that the rate is qualitatively different when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \gg 1/n}" class="latex" title="{\delta \gg 1/n}" />. However, we emphasize that <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy is not a meaningful privacy notion unless <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \ll 1/n}" class="latex" title="{\delta \ll 1/n}" />. In particular, the mechanism that randomly outputs <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta n}" class="latex" title="{\delta n}" /> elements of the sample satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%280%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(0,\delta)}" class="latex" title="{(0,\delta)}" />-differential privacy. However, when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \gg 1/n}" class="latex" title="{\delta \gg 1/n}" />, this mechanism completely violates the privacy of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\gg 1}" class="latex" title="{\gg 1}" /> person in the dataset. Moreover, taking the empirical mean of these <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta n}" class="latex" title="{\delta n}" /> samples gives rate <img src="https://s0.wp.com/latex.php?latex=%7Bd%2F%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d/\delta n}" class="latex" title="{d/\delta n}" />, which would violate our lower bound when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> is large enough. On the other hand, we would expect the minimax rate to become slower when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \ll 1/n}" class="latex" title="{\delta \ll 1/n}" />. This expectation is, in fact, correct, however the proof we present does not give the tight dependence on the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />. See [<a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>] for a refinement that can obtain the right dependence on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, and [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] for the details of how to apply this refinement in the i.i.d. setting. </em></p>
</blockquote>
<p><b> 3.1. A Simple Upper Bound </b></p>
<blockquote>
<p><b>Theorem 4</b> <em> For every <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \in {\mathbb N}}" class="latex" title="{n \in {\mathbb N}}" />, and every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon,\delta &gt; 0}" class="latex" title="{\epsilon,\delta &gt; 0}" />, there exists an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private private mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> such that <a name="eqmean-est-ub"></a></em></p>
<p><em><em><a name="eqmean-est-ub"></a></em></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%5Cleq+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" /></p>
<p><em><a name="eqmean-est-ub"></a></em></p>
<p><em><a name="eqmean-est-ub"></a> </em></p>
</blockquote>
<p><em>Proof:</em> Define the mechanism</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Coverline%7BX%7D+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" class="latex" title="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" /></p>
<p>This mechanism satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy by Lemma <a href="https://kamathematics.wordpress.com/feed/#lemgauss-mech">3</a>, noting that for any pair of adjacent samples <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1 \cdots n}}" class="latex" title="{X_{1 \cdots n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX%27_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'_{1 \cdots n}}" class="latex" title="{X'_{1 \cdots n}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C+%5Coverline%7BX%7D+-+%5Coverline%7BX%7D%27%5C%7C_2%5E2+%5Cleq+%5Cfrac%7Bd%7D%7Bn%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" class="latex" title="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%5E2+%3D+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" class="latex" title="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" />. Note that since the Gaussian noise has mean <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and is independent of <img src="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7BX%7D+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\overline{X} - \mu}" class="latex" title="{\overline{X} - \mu}" />, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu+%5C%7C_2%5E2%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%5Cleq%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D%29+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Csigma%5E2+d+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p> </p>
<p><b> 3.2. Minimax Lower Bounds via Tracing </b></p>
<blockquote>
<p><b>Theorem 5</b> <em> <a name="thmmean-lb"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bn%2C+d+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n, d \in {\mathbb N}}" class="latex" title="{n, d \in {\mathbb N}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0}" class="latex" title="{\epsilon &gt; 0}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3C+1%2F96n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &lt; 1/96n}" class="latex" title="{\delta &lt; 1/96n}" />, if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> is the class of all product distributions on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}^{d}}" class="latex" title="{\{\pm 1\}^{d}}" />, then for some constant <img src="https://s0.wp.com/latex.php?latex=%7BC+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C &gt; 0}" class="latex" title="{C &gt; 0}" />, </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%2CM%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5COmega%5Cleft%28%5Cmin+%5Cleft%5C%7B+%5Cfrac%7Bd%5E2%7D%7B+%5Cepsilon%5E2+n%5E2%7D%2C+d+%5Cright%5C%7D%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " class="latex" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " /></p>
<p> </p>
</blockquote>
<p>Note that it is trivial to achieve error <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> for any distribution using the mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%5Cequiv+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{1 \cdots n}) \equiv 0}" class="latex" title="{M(X_{1 \cdots n}) \equiv 0}" />, so the result says that the error must be <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28d%5E2%2F%5Cepsilon%5E2+n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(d^2/\epsilon^2 n^2)}" class="latex" title="{\Omega(d^2/\epsilon^2 n^2)}" /> whenever this error is significantly smaller than the trivial error of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />.</p>
<p><b>Tracing Attacks.</b></p>
<p>Before giving the formal proof, we will try to give some intuition for the high-level proof strategy. The proof can be viewed as constructing a <em>tracing attack </em>[<a href="https://kamathematics.wordpress.com/feed/#DSSU17">DSSU17</a>] (sometimes called a <em>membership inference attack</em>) of the following form. There is an attacker who has the data of some individual <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> chosen in one of the two ways: either <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a random element of the sample <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, or <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is an independent random sample from the population <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" />. The attacker is given access to the true distribution <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> and the outcome of the mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" />, and wants to determine which of the two is the case. If the attacker can succeed, then <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> cannot be differentially private. To understand why this is the case, if <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a member of the dataset, then the attacker should say <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is in the dataset, but if we consider the adjacent dataset <img src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'}" class="latex" title="{X'}" /> where we replace <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> with some independent sample from <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" />, then the attacker will now say <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is independent of the dataset. Thus, <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X')}" class="latex" title="{M(X')}" /> cannot be close in the sense required by differential privacy.</p>
<p>Thus, the proof works by constructing a test statistic <img src="https://s0.wp.com/latex.php?latex=%7BZ+%3D+Z%28M%28X%29%2CY%2CP%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z = Z(M(X),Y,P),}" class="latex" title="{Z = Z(M(X),Y,P),}" /> that the attacker can use to distinguish the two possibilities for <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />. In particular, we show that there is a distribution over populations <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z)}" class="latex" title="{\mathop{\mathbb E}(Z)}" /> is small when <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is independent of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, but for <em>every</em> sufficiently accurate mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z)}" class="latex" title="{\mathop{\mathbb E}(Z)}" /> is large when <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a random element of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />.</p>
<p><b>Proof of Theorem <a href="https://kamathematics.wordpress.com/feed/#thmmean-lb">5</a>.</b></p>
<p>The proof that we present closely follows the one that appears in Thomas Steinke’s Ph.D. thesis [<a href="https://kamathematics.wordpress.com/feed/#Ste16">Ste16</a>].</p>
<p>We start by constructing a “hard distribution” over the family of product distributions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%3D+%28%5Cmu%5E1%2C%5Cdots%2C%5Cmu%5Ed%29+%5Cin+%5B-1%2C1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" class="latex" title="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" /> consist of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> independent draws from the uniform distribution on <img src="https://s0.wp.com/latex.php?latex=%7B%5B-1%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[-1,1]}" class="latex" title="{[-1,1]}" /> and let <img src="https://s0.wp.com/latex.php?latex=%7BP_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_{\mu}}" class="latex" title="{P_{\mu}}" /> be the product distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}^{d}}" class="latex" title="{\{\pm 1\}^{d}}" /> with mean <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Csim+P_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_1,\dots,X_n \sim P_{\mu}}" class="latex" title="{X_1,\dots,X_n \sim P_{\mu}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1,\dots,X_n)}" class="latex" title="{X = (X_1,\dots,X_n)}" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5E%7Bn+%5Ctimes+d%7D+%5Crightarrow+%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" class="latex" title="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" /> be any <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private mechanism and let</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5C%7C+M%28X%29+-+%5Cmu%5C%7C_2%5E2+%29+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" class="latex" title="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" /></p>
<p>be its expected loss. We will prove the desired lower bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" />.</p>
<p>For every element <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, we define the random variables</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+Z_i+%3D+Z_i%28M%28X%29%2CX_i%2C%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle+%5C%5C+Z%27_%7Bi%7D+%3D+Z%27_i%28M%28X_%7B%5Csim+i%7D%29%2C+X_i%2C+%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " class="latex" title="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B%5Csim+i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{\sim i}}" class="latex" title="{X_{\sim i}}" /> denotes <img src="https://s0.wp.com/latex.php?latex=%7B%28X_1%2C%5Cdots%2CX%27_i%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X_1,\dots,X'_i,\dots,X_n)}" class="latex" title="{(X_1,\dots,X'_i,\dots,X_n)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BX%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'_i}" class="latex" title="{X'_i}" /> is an independent sample from <img src="https://s0.wp.com/latex.php?latex=%7BP_%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_\mu}" class="latex" title="{P_\mu}" />. Our goal will be to show that, privacy and accuracy imply both upper and lower bounds on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_i+Z_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_i Z_i)}" class="latex" title="{\mathop{\mathbb E}(\sum_i Z_i)}" /> that depend on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />, and thereby obtain a bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" />.</p>
<p>The first claim says that, when <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> is <em>not</em> in the sample, then the likelihood random variable has mean <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and variance controlled by the expected <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2^2}" class="latex" title="{\ell_2^2}" /> error of the mechanism.</p>
<blockquote>
<p><b>Claim 1</b> <em> <a name="clmmean-lb-1"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z'_i) = 0}" class="latex" title="{\mathop{\mathbb E}(Z'_i) = 0}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" class="latex" title="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7CZ%27_i%5C%7C_%5Cinfty+%5Cleq+4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|Z'_i\|_\infty \leq 4d}" class="latex" title="{\|Z'_i\|_\infty \leq 4d}" />. </em></p>
</blockquote>
<p><em>Proof:</em> Conditioned on any value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />, <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{\sim i})}" class="latex" title="{M(X_{\sim i})}" /> is independent from <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" />. Moreover, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28X_i+-+%5Cmu%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(X_i - \mu) = 0}" class="latex" title="{\mathop{\mathbb E}(X_i - \mu) = 0}" />, so we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28X_i+-+%5Cmu%29+%5Cright+%5Crangle+%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+0+%5Cright+%5Crangle+%29+%5C%5C+%3D+%260.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " /></p>
<p>For the second part of the claim, since <img src="https://s0.wp.com/latex.php?latex=%7B%28X_i+-+%5Cmu%29%5E2+%5Cleq+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X_i - \mu)^2 \leq 4}" class="latex" title="{(X_i - \mu)^2 \leq 4}" />, we have <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4+%5Ccdot+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" class="latex" title="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" />. The final part of the claim follows from the fact that every entry of <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{\sim i}) - \mu}" class="latex" title="{M(X_{\sim i}) - \mu}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX_i+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i - \mu}" class="latex" title="{X_i - \mu}" /> is bounded by <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> in absolute value, and <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_i}" class="latex" title="{Z'_i}" /> is a sum of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> such entries, so its absolute value is always at most <img src="https://s0.wp.com/latex.php?latex=%7B4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4d}" class="latex" title="{4d}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>The next claim says that, because <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is differentially private, <img src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_i}" class="latex" title="{Z_i}" /> has similar expectation to <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_i}" class="latex" title="{Z'_i}" />, and thus its expectation is also small.</p>
<blockquote>
<p><b>Claim 2</b> <em><a name="clmmean-lb-2"></a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" class="latex" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" /> </em></p>
</blockquote>
<p><em>Proof:</em> The proof is a direct calculation using the following inequality, whose proof is relatively simple using the definition of differential privacy:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%2B+2%5Cepsilon+%5Csqrt%7B%5Cmathrm%7BVar%7D%28Z%27_i%29%7D+%2B+2%5Cdelta+%5C%7C+Z%27_i+%5C%7C_%5Cinfty.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " class="latex" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " /></p>
<p>Given the inequality and Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-1">1</a>, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+0+%2B+%282%5Cepsilon%29%282%5Calpha%29+%2B+%282%5Cdelta%29%282d%29+%3D+4%5Cepsilon+%5Calpha+%2B+8+%5Cdelta+d+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " class="latex" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " /></p>
<p>The claim now follows by summing over all <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>The final claim says that, because <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is accurate, the expected sum of the random variables <img src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_i}" class="latex" title="{Z_i}" /> is large.</p>
<blockquote>
<p><b>Claim 3</b> <em> <a name="clmmean-lb-3"></a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cgeq+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" class="latex" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" /> </em></p>
</blockquote>
<p>The proof relies on the following key lemma, whose proof we omit.</p>
<blockquote>
<p><b>Lemma 6 (Fingerprinting Lemma [<a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>])</b><em> <a name="lemfp"></a> If <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%5Cin+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu \in [\pm 1]}" class="latex" title="{\mu \in [\pm 1]}" /> is sampled uniformly, <img src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Cin+%5C%7B%5Cpm+1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" class="latex" title="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" /> are sampled independently with mean <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />, and <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5En+%5Crightarrow+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" class="latex" title="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" /> is any function, then </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i+-+%5Cmu%29%29+%5Cgeq+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29%5E2%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " class="latex" title="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " /></p>
<p> </p>
</blockquote>
<p>The lemma is somewhat technical, but for intuition, consider the case where <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%7D+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X) = \frac{1}{n}\sum_{i} X_i}" class="latex" title="{f(X) = \frac{1}{n}\sum_{i} X_i}" /> is the empirical mean. In this case we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5En+%28X_i+-+%5Cmu%29%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cfrac%7B1%7D%7Bn%7D+%5Csum_i+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%7D%28+%28X_i+-+%5Cmu%29%5E2%29+%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathrm%7BVar%7D%28X_i%29%29+%3D+%5Cfrac%7B1%7D%7B3%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " /></p>
<p>The lemma says that, when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" /> is sampled this way, then any modification of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> that reduces the correlation between <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_i X_i}" class="latex" title="{\sum_i X_i}" /> will increase the mean-squared-error of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> proportionally.</p>
<p>We now prove Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a>.</p>
<p><em>Proof:</em> We can apply the lemma to each coordinate of the estimate <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" />.</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%29+%5C%5C+%3D%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i%5Ej+-+%5Cmu%5Ej%29%29+%5C%5C+%5Cgeq%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cleft%28+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5E2%29+%5Cright%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " /></p>
<p>The inequality is Lemma <a href="https://kamathematics.wordpress.com/feed/#lemfp">6</a>. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>Combining Claims <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-2">2</a> and <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a> gives</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" class="latex" title="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" /></p>
<p>Now, if <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \geq \frac{d}{6}}" class="latex" title="{\alpha^2 \geq \frac{d}{6}}" /> then we’re done, so we’ll assume that <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cleq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \leq \frac{d}{6}}" class="latex" title="{\alpha^2 \leq \frac{d}{6}}" />. Further, by our assumption on the value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, <img src="https://s0.wp.com/latex.php?latex=%7B8n+%5Cdelta+d+%5Cleq+%5Cfrac%7Bd%7D%7B12%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{8n \delta d \leq \frac{d}{12}}" class="latex" title="{8n \delta d \leq \frac{d}{12}}" />. In this case we can rearrange terms and square both sides to obtain</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%5Cgeq%7B%7D+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+-+8+n%5Cdelta+d%5Cright%29%5E2+%5Cgeq+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B12%7D%5Cright%29%5E2+%3D+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" class="latex" title="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" /></p>
<p>Combining the two cases for <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" /> gives <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cmin%5C%7B+%5Cfrac%7Bd%7D%7B6%7D%2C+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" class="latex" title="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" />, as desired.</p>
<p><b>Bibliography</b></p>
<p>[BDRS18]<a name="BDRS18"></a> Mark Bun, Cynthia Dwork, Guy N. Rothblum, and Thomas Steinke. Composable and versatile privacy via truncated CDP. STOC ’18.</p>
<p>[BS16]<a name="BS16"></a> Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. TCC ’16-B.</p>
<p>[BSU17]<a name="BSU17"></a> Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p>[BUV14]<a name="BUV14"></a> Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p>[CSS11]<a name="CSS11"></a> T-H Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. ACM Transactions on Information and System Security, 14(3):26, 2011.</p>
<p>[CWZ19]<a name="CWZ19"></a> T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p>[DMNS06]<a name="DMNS06"></a> Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p>[DNPR10]<a name="DNPR10"></a> Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. STOC ’10.</p>
<p>[DR16]<a name="DR16"></a> Cynthia Dwork and Guy N. Rothblum. Concentrated differential privacy. arXiv, 1603.01887, 2016.</p>
<p>[DRS19]<a name="DRS19"></a> Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy. arXiv, 1905.02383, 2019.</p>
<p>[DSSU17]<a name="DSSU17"></a> Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p>[DSSUV15]<a name="DSSUV15"></a> Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. Exposed! a survey of attacks on private data. Annual Review of Statistics and Its Application, 4:61–84, 2017.</p>
<p>[FRY10]<a name="FRY10"></a> Stephen E. Fienberg, Alessandro Rinaldo, and Xiaolin Yang. Differential privacy and the risk-utility tradeoff for multi-dimensional contingency tables. PSD ’10.</p>
<p>[KLSU19]<a name="KLSU19"></a> Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p>[Mir17]<a name="Mir17"></a> Ilya Mironov. Rényi differential privacy. CSF ’17.</p>
<p>[Ste16]<a name="Ste16"></a> Thomas Alexander Steinke. Upper and Lower Bounds for Privacy and Adaptivity in Algorithmic Data Analysis. PhD thesis, 2016.</p>
<p>[SU17a]<a name="SU17a"></a> Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p>[SU17b]<a name="SU17b"></a> Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p>[VS09]<a name="VS09"></a> Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>


<p></p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/"><span class="datestr">at April 14, 2020 02:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=43">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/">Friday, April 17 — Shachar Lovett from UC San Diego</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The third Foundations of Data Science virtual talk will take place next Friday, April 17th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Shachar Lovett</strong> from UC San Diego will speak about “<em>The power of asking more informative questions about the data</em>”.</p>



<p><strong>Abstract</strong>: Many supervised learning algorithms (such as deep learning) need a large collection of labelled data points in order to perform well. However, what is easy to get are large amounts of unlabelled data. Labeling data is an expensive procedure, as it usually needs to be done manually, often by a domain expert. Active learning provides a mechanism to bridge this gap. Active learning algorithms are given a large collection of unlabelled data points. They need to smartly choose a few data points to query their label. The goal is then to automatically infer the labels of many other data points.</p>



<p>In this talk, we will explore the option of giving active learning algorithms additional power, by allowing them to have richer interaction with the data. We will see how allowing for even simple types of queries, such as comparing two data points, can exponentially improve the number of queries needed in various settings. Along the way, we will see interesting connections to both geometry and combinatorics, and a surprising application to fine grained complexity.</p>



<p>Based on joint works with Daniel Kane, Shay Moran and Jiapeng Zhang.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/"><span class="datestr">at April 11, 2020 08:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=2445">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/computer-aided-analyses/">Computer-aided analyses in optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">In this blog post, I want to illustrate how computers can be great allies in designing (and verifying) convergence proofs for first-order optimization methods. This task can be daunting, and highly non-trivial, but nevertheless usually unavoidable when performing complexity analyses. A notable example is probably the convergence analysis of the stochastic average gradient (SAG) [<a href="https://arxiv.org/pdf/1309.2388.pdf">1</a>], whose original proof was computer assisted.</p>



<p class="justify-text">To this end, we will mostly spend time on what is referred to as <em>performance estimation problems</em> (PEPs), introduced by Yoel Drori and Marc Teboulle [<a href="https://link.springer.com/article/10.1007/s10107-013-0653-0">2</a>]. Performance estimation is also closely related to the topic of <em>integral quadratic constraints</em> (IQCs), introduced in the context of optimization by Laurent Lessard, Benjamin Recht and Andrew Packard [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>]. In terms of presentations, IQCs  leverages control theory, whereas PEPs might seem more natural in the optimization community. This blog post essentially presents PEPs from the point of view of [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>], instantiated on a running example.</p>



<h2>Overview, motivations</h2>



<p class="justify-text">First-order methods for continuous optimization belong to the large panel of algorithms that are usually approached via worst-case analyses. In this context, analyses rely on combining inequalities (that are due to assumptions on the problem classes), in potentially long, non-intuitive, and technical, proofs. For the insiders, those proofs all look very similar. For the outsiders, those proofs all look rather repelling, technical (long pages of chained inequalities), probably not interesting, and like computer codes: usually intuitive mostly for their authors.</p>



<p class="justify-text">In what follows, I want to show how (and why) those proofs are indeed all very similar. On the way, I want to emphasize how those combinations of inequalities are related to the “true essence” of worst-case analyses (which rely on computing worst-case scenarios), and to provide examples on how to constructively obtain them.</p>



<p class="justify-text">We take the stand of illustrating the PEP approach on a single iteration of gradient descent, as it essentially contains all necessary ingredients to understand the methodology in other contexts as well. Certain details of the following text are (probably unavoidably) a bit technical. However, going through the detailed computations is not essential, and the text should contain the necessary ingredients for understanding the essence of the methodology.</p>



<h2>Running example: gradient descent</h2>



<p class="justify-text">Let us consider a naive, but standard, example: unconstrained convex minimization $$x_\star= \underset{x\in\mathbb{R}^d}{\mathrm{arg min}} f(x)$$with gradient descent: \(x_{k+1}=x_k-\gamma \nabla f(x_k)\). Let us assume \(f(\cdot)\) to be continuously differentiable, to have a \(L\)-Lipschitz gradient (a.k.a., \(L\)-smoothness), and to be \(\mu\)-strongly convex. Those functions satisfy, for all \(x,y\in\mathbb{R}^d\):<br />– strong convexity, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Definition 2.1.2]: $$\tag{1}f(x) \geqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{\mu}{2} \lVert x-y\rVert^2,$$- smoothness, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.5]: $$\tag{2} f(x) \leqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{L}{2}\lVert x-y\rVert^2.$$Let us recall that in the case of twice continuously differentiable functions, smoothness and strong convexity amount to requiring  that $$\mu I \preccurlyeq \nabla^2 f(x) \preccurlyeq L I,$$ for some \(0&lt; \mu&lt;L&lt; \infty\) and for all \(x\in\mathbb{R}^d\) (in other words, all eigenvalues of \(\nabla^2 f(x)\) are between \(\mu\) and \(L\)). In what follows, we denote by \(\mathcal{F}_{\mu,L}\) the class of \(L\)-smooth \(\mu\)-strongly convex functions (irrespective of the dimension \(d\)).</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="473" alt="" src="https://www.di.ens.fr/~ataylor/BlogPost/SmoothStronglyConvex.png" height="204" />Figure 1: the blue function is \(L\)-smooth and \(\mu\)-strongly convex (it is possible to create respectively global upper and lower quadratic bounds from every \(x\in\mathbb{R}^d\) with respectively curvatures \(L\) and \(\mu\)).</figure></div>
</div></div>



<p class="justify-text">In this context, convergence of gradient descent can be studied in many ways. Here, for the sake of the example, we will do it in terms of two base quantities: distance to optimality \(\lVert x_k-x_\star\rVert\), and function value accuracy \(f(x_k)-f(x_\star)\). There are, of course, infinitely many other possibilities, such as gradient norm \(\rVert \nabla f(x_k)\lVert\), Bregman divergence \(f(x_\star)-f(x_k)-\langle{\nabla f(x_k)};{x_\star-x_k}\rangle\), or even best function value observed throughout the iterations \(\min_{0\leq i\leq k} \{f(x_i)-f(x_\star)\}\): the reader can adapt the lines below for his/her favorite criterion. </p>



<p class="justify-text">For later reference, let us provide another inequality that is known to  hold for all \(x,y\in\mathbb{R}^d\) for any \(L\)-smooth \( \mu\)-strongly convex function: <br />– bound on inner product, see, e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>,  Theorem 2.1.11]: $$\langle{\nabla f(x)-\nabla f(y)};{x-y}\rangle  \geqslant        \tfrac{1}{L+\mu} \lVert{\nabla f(x)-\nabla f(y)}\rVert^2+\tfrac{\mu  L}{L+\mu}\lVert{x-y}\rVert^2.\tag{3}$$ In the case \(\mu=0\) this inequality is known as “cocoercivity”. This (perhaps mysterious) inequality happens to play an important role in convergence proofs.</p>



<h3>A standard convergence result</h3>



<p class="justify-text">Let us start by stating two known results along with their simple proofs (see, e.g.,  [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.14] or [6, Section 1.4.2, Theorems 2 &amp; 3]):<br />– convergence in distance:  $$\begin{array}{rl}    \rVert{x_{k+1}-x_\star}\lVert^2&amp;= \lVert{x_k-x_\star}\rVert^2+\gamma^2\lVert{\nabla f(x_k)}\rVert^2-2\gamma\langle{\nabla f(x_k)};{x_k-x_\star}\rangle \\ \     &amp; \leqslant      \left(1-\tfrac{2\gamma L \mu}{L+\mu}\right)\lVert{x_k-x_\star}\rVert^2+\gamma\left(\gamma-\tfrac2{L+\mu}\right)\lVert{\nabla f(x_k)}\rVert^2, \end{array} $$ where the second line follows from smoothness and strong convexity of \(f\) via the bound (3) on the inner product (with \(x=x_k\) and \(y=x_\star\)). For the particular choice \(\gamma=\tfrac2{L+\mu}\), the second term on the right hand side disappears, and we end up with<br />     $$\lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^2\lVert{x_k-x_\star}\rVert^2,$$ which, following from \(0&lt;\mu&lt;L&lt;\infty\), satisfies \(0&lt; \tfrac{L-\mu}{L+\mu}&lt;1\), hence proving linear convergence of gradient descent in this setup, by recursively applying the previous inequality: $$ \lVert{x_{k}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^{2k}\lVert{x_0-x_\star}\rVert^2.$$ – Convergence in function values: one can simply use the result in distance along with the previous basic inequalities (1) and (2) characterizing smoothness and strong convexity (both with \(y=x_\star\)):<br />     $$f(x_k)-f(x_\star) \leqslant \hspace{-.15cm}\tfrac{L}{2}\hspace{-.1cm}\rVert{x_k-x_\star}\lVert^2  \leqslant  \hspace{-.15cm}    \tfrac{L}{2}\hspace{-.1cm}\left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k} \rVert{x_0-x_\star}\lVert^2 \leqslant  \hspace{-.15cm}     \tfrac{L}{\mu}\hspace{-.1cm} \left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k}(f(x_0)-f(x_\star)).$$  It is also possible to directly look for convergence in terms of function values, but it is then usually unclear in the literature what inequalities to use, and I am not aware of any such proof leading to the same rate without the leading \(\tfrac{L}{\mu}\) (except the proof presented below).</p>



<p class="justify-text">At this point, even in this toy example, a few very legitimate questions can be raised:<br />– can we improve anything? Can gradient descent really behaves like that on this class of functions?<br />– How could we have guessed the inequality to use, and the shape of the corresponding proof? Obviously, the obscure fact is to arrive to inequality (1).  Therefore, is there a principled way for choosing the right inequalities to use, for example for studying convergence in terms of other quantities, such as  function values?<br />– Is this the unique way to arrive to the desired result? If yes, how likely are we to find such proofs for more complicated cases (algorithms and/or function class)?</p>



<p class="justify-text">For the specific step size choice \(\gamma=\tfrac2{L+\mu}\), a partial answer to the first question is obtained by the observation that the rate is actually achieved on the quadratic function<br /> $$f(x)=\tfrac12 \, x^\top \begin{bmatrix}<br /> L &amp; 0\\ 0 &amp; \mu<br /> \end{bmatrix}x.$$ The following lines precisely target the missing answers.</p>



<h2>Worst-case analysis through worst-case scenarios</h2>



<p class="justify-text">Let us start by rephrasing our goal, and restrict ourselves to the study of a single iteration. We fix our target to finding the smallest possible value of \(\rho\) such that the inequality<br /> $$ \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant       \rho^2 \lVert{x_k-x_\star}\rVert^2 $$ is valid for all \(x_k\) and \(x_{k+1}=x_k-\gamma \nabla f(x_k)\) (hence \(\rho\) is a function of \(\gamma\)). In other words, our goal is to solve<br />$$ \rho^2(\gamma):= \sup \left\{ \frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0\right\}.$$<br />Alternatively, we could be interested in studying convergence in other forms: for function values, we could target to solve the slightly modified problem:<br /> $$ \sup  \left\{ \frac{f(x_{k+1})-f(x_\star)}{f(x_{k})-f(x_\star)}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0 \right\}.$$ It turns out that in both cases, the problem can be solved both numerically to high precision, and analytically, and that the answer is \(\rho^2(\gamma)=\max\{(1-\mu\gamma)^2,(1-L\gamma)^2\}\).</p>



<p class="justify-text">The only thing we did, so far, was to explicitly reformulate the problem of finding the best (smallest) convergence rate as the problem of finding the worst-case scenario, nothing more. In what follows, some parts might become slightly technical, but the overall idea is only to reformulate this problem of finding the worst-case scenarios, for solving it.</p>



<h3>Dealing with an infinite-dimensional variable: the function \(f\)</h3>



<p class="justify-text">The first observation is that the problem of computing \(\rho\) is stated as an infinite-dimensional optimization problem: we are looking for the worst possible problem instance (a function \(f\) and an initial point \(x_k\)) within a predefined class of problems. The first step we take to work around this is to reformulate it in the following equivalent  form (note that we maximize also over the dimension \(d\)—we discuss later how to remove it):<br />$$\begin{array}{rl} \rho^2:= \underset{f,\, x_k,\,x_\star,\, g_k,\,d}{\sup} &amp;\displaystyle \frac{\lVert{x_{k}-\gamma g_k-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\\<br /> \text{s.t. }    &amp; \exists f\in\mathcal{F}_{\mu,L}:\, g_k= \nabla f(x_k),\, 0=\nabla f(x_\star).<br />\end{array}$$<br />This problem intrinsically does not look better (it contains an  existence constraint), but it allows using mathematical tools which are referred to as  <em>interpolation,</em> or <em>extension</em>, theorems [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1603.00241.pdf">7</a>, <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">8</a>]. The problem is depicted on Figure 2:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="490" alt="" src="https://www.di.ens.fr/~ataylor/BlogPost/Interpolation.png" height="209" />Figure 2: discrete interpolation (or extension) problem: given a set of triplets \(\{(\text{coordinate}, \text{gradient}, \text{function value})\}\) can we recover a function within a determined class that explains those triplets?</figure></div>



<p class="justify-text">It turns out that convex interpolation (that is, neglecting smoothness and strong convexity) is actually rather simple:</p>



<ul class="justify-text"><li>given a convex function and an index set \(I\), any set of samples \(\{(x_i,g_i,f_i)\}_{i\in I}\) of the form \(\{(\text{coordinate}, \text{(sub)gradient}, \text{function value})\}\)) satisfies, for all \(i,j\in I\): $$f_i \geqslant      f_j+\langle g_j; x_i-x_j\rangle,$$ by definition of subgradient, as illustrated on Figure 3.</li></ul>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="485" alt="" src="https://www.di.ens.fr/~ataylor/BlogPost/SamplingCvx.png" height="205" />Figure 3: sampling from a convex function.</figure></div>



<ul class="justify-text"><li>In the other direction, given a set of triplets \(\{(x_i,g_i,f_i)\}_{i\in I}\) satisfying the previous inequality for all pairs \(i,j\in I\), one can simply recover a  convex function by the following construction: $$f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\},$$ which is depicted on Figure 4.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="487" alt="" src="https://www.di.ens.fr/~ataylor/BlogPost/InterpolateCvx.png" height="207" />Figure 4: some set \(\{(x_i,g_i,f_i)\}_{i\in I}\) and its piecewise affine interpolant \(f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\}\).</figure></div>



<ul class="justify-text"><li>Formally, the reasoning allows arriving to the following “convex interpolation” (or “convex extension”) result, where we denote the set of (closed, proper) convex functions by \(\mathcal{F}_{0,\infty}\) (to be understood as \(L\)-smooth \(\mu\)-strongly convex functions with \(\mu=0\) and \(L=\infty\)): $$\begin{array}{c}\exists f\in\mathcal{F}_{0,\infty}: \,  g_k\in\partial f(x_k) \text{ and } f_k=f(x_k) \ \ \forall k\in  I\\ \Leftrightarrow\\ f_i \geqslant       f_j+\langle{g_j};{x_i-x_j}\rangle\quad \forall i,j\in I,\end{array}$$ where \(\partial f(x)\) denotes the subdifferential of \(f\) at \(x\).</li></ul>



<p class="justify-text">In the next section, we use a similar interpolation result for taking smoothness and strong convexity into account. The result is a bit more technical, but follows from similar constructions as those for convex interpolation—the main difference being that the interpolation is done on the Fenchel conjugate instead, in order to incorporate smoothness, see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Section 2].</p>



<h3>Reformulation through convex interpolation</h3>



<p class="justify-text">Back to the problem of computing worst-case scenarios, we can now reformulate the existence constraint <em>exactly</em> using the following result (see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>,  Theorem 4]): let \(I\) be a finite index set and let \( S=\{(x_i,g_i,f_i)\}_{i\in I}\) be a set of triplets, then<br />  $$\begin{array}{c}\exists f\in\mathcal{F}_{\mu,L}: \,  g_i=\nabla f(x_i) \text{ and } f_i=f(x_i) \text{ for all } i\in  I\\ \Leftrightarrow\\  f_i \geqslant      f_j+\langle{g_j};{x_i-x_j}\rangle+\frac{1}{2L}\lVert{g_i-g_j}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_i-x_j-\frac{{1}}{L}(g_i-g_j)}\rVert^2  \,\,\, \forall i,j\in I.\end{array}$$ Therefore, the previous problem can be reformulated as (recalling that \(g_\star=0\))<br />$$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle\frac{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}{\rVert{x_k-x_\star}\lVert^2}\\<br />      \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br />      &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2.<br />\end{array}$$ </p>



<h3>Quadratic reformulation</h3>



<p class="justify-text">The next step is to remove the ratio appearing in the objective function, which we do via an homogeneity argument, as follows.</p>



<p class="justify-text">Starting from a feasible point, scale \(x_k,\,x_\star,g_k\) by some \(\alpha&gt;0\) and \(f_k,\,f_\star\) by \(\alpha^2\) and observe it does not change the value of the objective, while still being a feasible point. Therefore, the problem can be reformulated as a nonconvex QCQP (quadratically constrained quadratic program): $$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}\\<br />       \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br />       &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\ &amp;{\rVert{x_k-x_\star}\lVert^2} \leqslant      1,<br /> \end{array}$$  which is quadratic in \(x_k\), \(x_\star\) and  \(g_k\), and linear in \(f_\star\) and \(f_k\). Actually, in the current form, nonconvexity comes from the term “\(\langle{g_k};{x_\star-x_k}\rangle\)” in the second constraint (and from the objective, due to maximization). It turns out that this problem can be reformulated <em>losslessly</em> using semidefinite programming (this is due to the maximization over \(d\), as commented at the end of the next section). </p>



<h3>Semidefinite reformulation</h3>



<p class="justify-text">At the end of this section, we will be able to compute, numerically, the values of the rate \(\rho^2(\gamma)\) for given values of the parameters \(\mu,\,L\), and \(\gamma\).</p>



<p class="justify-text">The last step in the reformulation goes as follows: the previous problem can be reformulated as a semidefinite program, as it is linear in terms of the entries of the following Gram matrix<br />$$G = \begin{pmatrix}<br />     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle \\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2<br />     \end{pmatrix}\succcurlyeq 0,$$ and in terms of the function values \(f_k\) and \(f_\star\). From those variables, one reformulate the previous problem as $$\begin{array}{rl} \underset{f_k,\,f_\star,\, G\succeq 0}{\sup} \, &amp;{\mathrm{Tr} (A_\text{num} G)}\\<br />      \text{s.t. }    &amp; f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0\\<br />      &amp;  f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0 \\<br />      &amp;\mathrm{Tr} (A_\text{denom} G) \leqslant      1,\end{array}$$ which is a gentle semidefinite program where we picked matrices \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) for encoding the previous terms. That is, we choose those matrices such that<br /> $$\begin{array}{rl}<br />\mathrm{Tr}(A_{\text{denom}} G)&amp;=\lVert{x_k-x_\star}\rVert^2,\\  \mathrm{Tr}(A_{\text{num}} G)&amp;=\lVert{x_k-\gamma g_k-x_\star}\rVert^2,\\ \mathrm{Tr}(A_1G)&amp;=\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2,\\ \mathrm{Tr}(A_2G)&amp;=\tfrac{1}{2L}\lVert g_k\rVert^2+\tfrac{\mu}{2(1-\mu/L)}\lVert x_k-x_\star-\tfrac1L g_k\rVert^2.\end{array}$$ One possibility is to choose \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) as symmetric matrices, as follows: $$\begin{array}{cc}<br /> A_{\text{denom}}=\begin{pmatrix}     1 &amp; 0\\ 0 &amp; 0     \end{pmatrix}, &amp; A_{\text{num}}=\begin{pmatrix}     1 &amp; -\gamma\\ -\gamma &amp; \gamma^2     \end{pmatrix}, \\ A_1=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac12-\tfrac{\mu}{2(L-\mu)} \\ -\tfrac12-\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)}\end{pmatrix}, &amp;  A_2=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac{\mu}{2(L-\mu)} \\ -\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)} \end{pmatrix}.\end{array}$$</p>



<p class="justify-text">All those steps can be carried out in the exact same way for the problem of computing the convergence rate for function values, reaching a similar problem with \(6\) inequality constraints instead—because interpolation conditions have to be imposed on all pairs of points in a set of \(3\) points: \(x_k\), \(x_{k+1}\) and \(x_\star\), instead of only \(2\) for the distance problem. The objective function is then \(f_{k+1}-f_\star\), the de-homogenization constraint (arising from the denominator of the objective function) is \(f_{k}-f_\star \leqslant     1\), and the Gram matrix is \(3\times 3\):<br />$$G=\begin{pmatrix}<br />     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle&amp; \langle{g_{k+1}};{x_k-x_\star}\rangle\\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2 &amp; \langle{g_k};{g_{k+1}}\rangle \\<br />     \langle{g_{k+1}};{x_k-x_\star}\rangle &amp; \langle{g_{k+1}};{g_k}\rangle &amp; \lVert{g_{k+1}}\rVert^2<br />     \end{pmatrix}\succcurlyeq 0, $$ and the function values variables are \(f_k\), \(f_{k+1}\) and \(f_\star\).</p>



<p class="justify-text">We provide the numerical optimal values of those semidefinite programs on Figure 5 for both convergence in distances and in function values. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="534" alt="" src="https://www.di.ens.fr/~ataylor/BlogPost/ObjectiveValues.png" height="324" />Figure 5: worst-cases of the ratio \(\frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\) (red) and \(\frac{f(x_{k+1})-f_\star}{f(x_k)-f_\star}\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match exactly the expected \(\max\{(1-\gamma L)^2,(1-\gamma\mu)^2\}\) in both cases. Note that the corresponding SDPs can be solved both for “good and bad” choices of step sizes: if the step size is chosen wisely then \(\rho(\gamma)&lt;1\), and otherwise \(\rho(\gamma)\geqslant 1\). The SDP confirms the common knowledge that \(\gamma\in (0,2/L)\Rightarrow \rho(\gamma)&lt; 1\). Numerical values obtained through YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p class="justify-text">As a conclusion for this section, let us note that we showed how to compute the “best” rates that are dimension independent. In general, requiring the iterates and gradient (e.g., \(x_k\) and \(g_k\) for the problem in terms of distance, and \(x_k\), \(g_k\) and \(g_{k+1}\) for function values, and potentially more vectors when dealing with more complex settings) to lie in \(\mathbb{R}^d\) is equivalent to adding a rank constraint in the SDP. </p>



<h2>Duality between worst-case scenarios and combinations of inequalities</h2>



<p class="justify-text">Any feasible point to the previous SDP corresponds to a <em>lower bound</em>: a sampled version of a potentially difficult function for gradient descent. If we want to find <em>upper bounds</em> on the rate, a natural way to proceed is to go to the dual side of the previous SDPs, where any feasible point will naturally correspond to an upper bound on the convergence rate (by <em>weak duality</em>). As the primal problems were SDPs, their Lagrangian duals are SDPs as well. Let us associate one multiplier per constraint: $$ \begin{array}{rl}<br />f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0&amp;:\lambda_1\\<br />f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0&amp;:\lambda_2\\<br />\mathrm{Tr}(A_\text{denom} G) \leqslant 1&amp;: \tau.<br />\end{array}$$The dual is then<br />$$\begin{array}{rl}<br /> \underset{\tau,\,\lambda_1,\,\lambda_2}{\min} &amp; \, \tau \\<br /> \text{s.t. } &amp; \lambda_1=\lambda_2,\\<br /> &amp; S:=A_\text{num}-\tau A_\text{denom}-\lambda_1A_1-\lambda_2A_2 \preccurlyeq 0,\\<br /> &amp;\tau,\lambda_1,\lambda_2 \geqslant  0.<br /> \end{array}$$ Hence, by weak duality, any feasible point to this last SDP corresponds to an upper bound on the rate: \(\tau \geqslant \rho^2\). A mere rephrasing of weak duality can be obtained through the following reasoning: assume we received some feasible \(\tau,\lambda_1,\lambda_2\) (and hence \(\lambda_1=\lambda_2\) and a corresponding \(S\preccurlyeq 0\)), we then get, for any primal feasible \(G\succcurlyeq0\):<br />$$\begin{array}{rl}\mathrm{Tr}(SG)&amp;=\mathrm{Tr}(A_{\text{num}}G)-\tau\mathrm{Tr}(A_{\text{denom}}G)-\lambda_1\mathrm{Tr}(A_1G)-\lambda_2\mathrm{Tr}(A_2G)\\&amp;=\lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\\ \,&amp;\,\,\,-\lambda_1[     f_k-f_\star+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\,\,\,-\lambda_2 [f_\star-f_k+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\geqslant \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2, \end{array}$$ where the first equality follows from the definition of \(S\), the second equality corresponds to the definitions of \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\), and the last inequality follows from the sign of the interpolation inequalities (constraints in the primal) for any primal feasible point. Hence, we indeed have that any feasible \(\tau\) corresponds to a valid upper bound on the convergence rate, as $$S\preccurlyeq 0 \,\,\Rightarrow \,\, \mathrm{Tr}(SG)\leqslant 0\,\,\Rightarrow  \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\leqslant 0.$$ In order to obtain analytical proofs, we therefore need to find analytical dual feasible points, and numerics can of course help in this process! Let’s look at what the optimal dual solutions look like for our two running examples.</p>



<ul class="justify-text"><li> in Figure 6, we provide the numerical values for \(\lambda_1\) and \(\lambda_2\) for the distance problem.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="467" alt="" src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_distance.png" height="316" />Figure 6: numerical values of optimal dual variables: \(\lambda_1\) (red) and \(\lambda_2\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match \(\lambda_1=\lambda_2=2\gamma \rho(\gamma)\) with \(\rho(\gamma)=\max\{|1-\gamma L|,|1-\gamma\mu|\}\). Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<ul class="justify-text"><li>For function values, the SDP is slightly more complicated, as more inequalities are involved (6 interpolation inequalities). We provide raw numerical values for the six multipliers in Figure 7.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="463" alt="" src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_function.png" height="348" />Figure 7: numerical values of optimal dual variables (for the rate in function values): \(\lambda_1,\lambda_2, …,\lambda_6\) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p>For those who want a bit more details, here are a few additional pointers:</p>



<ul class="justify-text"><li>Strong duality holds—a way to prove it is to show that there exists a Slater point in the primal, see e.g., [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Theorem 6]—, and hence primal and dual optimal values match.</li><li>There might be different ways to optimaly combine the interpolation inequalities for proving the desired results. In other words: dual optimal solutions are often not unique—which is, in fact, quite a good news: I am sure nobody want to find the analytical version of the multipliers provided in Figure 7.</li><li>It is often possible to simplify the proofs by using fewer, or weaker, inequalities. This might lead to ”cleaner” results, typically (but not always) at the cost of ”weaker” rates. This was done for designing the proof for function values, later in this text.</li></ul>



<h2>Combinations of inequalities: same proofs without SDPs</h2>



<p class="justify-text">So far, we showed that computing convergence rates can be done in a very principled way. To this end, one can solve semidefinite programs—which may have arbitrarily complicated analytical solutions. Here, I want to emphasize that the process of <em>verifying</em> a solution can be quite different to that of<em> finding</em> a solution. Put in other words, although the dual certificates (a.k.a., the proofs) might have been found by solving SDPs, they can be formulated in ways that do not require the reader to know anything about the PEP methodology, nor on any SDP material, for verifying them. This fact might actually not be very surprising to the reader, as many proofs arising in the first-order optimization literature actually “only consists” in linear combinations of (quadratic) inequalities. On the one hand, those proofs can be seen as feasible points to “dual SDPs”, although generally not explicitely proved as such. On the other hand, proofs arising from the SDPs might therefore be expected to be writable without any explicit reference to semidefinite programing and performance estimation problems.<br /></p>



<p class="justify-text">In what follows, we provide the proofs for gradient descent, using the previous numerical inspiration, but without explicitly relying on any semidefinite program. The reader is not expected to verify any of those computations, as our goal is rather to emphasize that the principles underlying both proofs are exactly the same: reformulating linear combinations of inequalities.</p>



<p class="justify-text">For both proofs below, we limit ourselves to the step size regime \(0\leq   \gamma \leq \tfrac{2}{L+\mu}\), and we prove  that, in  this regime, \(\rho(\gamma)=(1-\gamma\mu)\)—actually we only proof the upper bounds, but one can easily verify that they are <em>tight</em> on simple quadratic functions.  The complete proofs (for the proximal gradient method),  can be found in [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>]. </p>



<h3>Example 1: distance to optimality</h3>



<p class="justify-text">Recall the notations: \(g_k:=\nabla f(x_k)\), \(f_k:= f(x_k)\), \(g_\star:=\nabla f(x_\star)\), and \(f_\star:= f(x_\star)\).</p>



<p class="justify-text">For distance to optimality, sum the following inequalities with their corresponding weights: $$\begin{array}{r}     f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2  :\lambda_1,  \\     f_k \geqslant      f_\star+\langle{g_\star};{x_k-x_\star}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2:\lambda_2.     \end{array}$$ We use the following values for the multipliers: \(\lambda_1=\lambda_2=2\gamma\rho(\gamma) \geqslant      0\) (see Figure 6). </p>



<p class="justify-text">After appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), and with little effort, one can check that the previous weighted sum of inequalities can be written in the form: $$ \begin{array}{rl}    \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant      &amp; \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2 -\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2. \end{array}$$ This statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation) and verifying that all terms indeed match.</p>



<p class="justify-text">Finally, using $$\gamma(2-\gamma (L+\mu)) \geqslant      0,  \text{ and } L-\mu \geqslant      0,$$ which are nonnegative by assumptions on the values of \(L\in(0,\infty)\), \(\mu\in (0,L)\) and \(\gamma\in(0,2/(L+\mu))\), we arrive to the desired $$ \lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2.$$</p>



<p class="justify-text">Note that, by using \(\lambda_1=\lambda_2\), the weighted sum exactly corresponds to the (scaled by a positive constant) inequality introduced in the early stage of this note for studying distance to optimality. However, the resulting expression is tight for all values of the step size here, whereas it was only tight for \(\gamma=2/(L+\mu)\) earlier, due to a different choice of weights! </p>



<p class="justify-text">The curious reader might wonder how to find such a reformulation. Actually, back in terms of SDPs, and using the expressions for the multipliers, it simply corresponds to $$\mathrm{Tr}(SG)=-\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2.$$ In the example below, the reformulation is a bit more tricky—as \(\mathrm{Tr}(SG)\)  has two nonnegative terms, which were simply obtained by doing an analytical Cholesky factorization of the term \(\mathrm{Tr}(SG)\)—, but the idea is exactly the same.</p>



<h3>Example 2: function values</h3>



<p class="justify-text">For function values, we combine the following inequalities after multiplication with their respective coefficients:    </p>



<p class="justify-text">$$\scriptsize \begin{array}{lr}     f_k \geqslant      f_{k+1}+\langle{g_{k+1}};{x_k-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_k-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_{k+1}-\frac{1}{L}(g_k-g_{k+1})}\rVert^2    &amp;:\lambda_1,\\<br />f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{1}{L}(g_k-g_\star)}\rVert^2  &amp;:\lambda_2, \\<br />f_\star \geqslant      f_{k+1}+\langle{g_{k+1}};{x_\star-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_\star-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_\star-x_{k+1}-\frac{1}{L}(g_\star-g_{k+1})}\rVert^2  &amp;:\lambda_3.     \end{array}$$ We use the following multipliers \(\lambda_1=\rho(\gamma)\), \(\lambda_2=(1-\rho(\gamma))\rho(\gamma)\), and  \(\lambda_3=1-\rho(\gamma)\) (obtained by greedily trying to set different combinations of multipliers to \(0\) in the SDP—see Figure 7 for the values without such simplifications).</p>



<p class="justify-text">Again, after appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), we obtain that the weighted sum of inequalities can be reformulated exactly as $$  \begin{array}{rl}          f(x_{k+1})-f_\star \leqslant      &amp;\left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right)\\&amp;-\frac{1}{2 (L-\mu)}\lVert \nabla f(x_{k+1})-(1-\gamma  (L+\mu))\nabla f(x_k) +\gamma  \mu  L (x_\star-x_k)\rVert^2\\<br />&amp;-\frac{\gamma  L(2- \gamma  (L+\mu))}{2 (L-\mu )}\lVert \nabla f(x_k)+\mu  (x_\star-x_k)\rVert^2.\end{array}$$ Again, this statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation), and verifying that all terms match. The desired conclusion $$ f(x_{k+1})-f_\star \leqslant \left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right), $$ follows from the signs of the leading coefficients: \(\gamma(2-\gamma (L+\mu)) \geqslant      0\), and \(L-\mu \geqslant      0\).</p>



<h3>To go further</h3>



<p class="justify-text">Before finishing, let us mention that we only dealt with linear convergence through a single iteration of gradient descent.</p>



<p class="justify-text">There are quite a few ways to handle both more iterations and sublinear convergence rates. Using SDPs, probably the most natural approach is to directly incorporate several iterations in the problem by  studying, for example, ratios of the form  $$\sup_{f\in\mathcal{F}_{\mu,L},\, x_0}  \frac{f(x_{N})-f_\star}{\lVert x_0-x_\star\rVert^2}. $$ This type of approach was used in the work of Drori and Teboulle [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>] and in most consecutive PEP-related works: it has the advantage of providing  comfortable “non-improvable results” [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>]   (by providing matching lower bounds) for any given \(N\), but requires solving larger and larger SDPs. Alternatively, simpler proofs can often be obtained through the use of  Lyapunov (or potential) functions—i.e., study a single iteration to produce recursable inequalities; a nice introduction is provided in [<a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">13</a>]. This idea can be exploited in PEPs [<a href="https://arxiv.org/pdf/1902.00947.pdf">14</a>] by enforcing the proofs to have a certain structure. Those principles are also at the heart of the related approach using integral quadratic constraints [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>, <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">15</a>]. </p>



<h2>Take-home message and conclusions</h2>



<p class="justify-text">The overall message of this note is that first-order methods can often be studied directly using the definition of their “worst-cases” (i.e., by trying to find worst-case scenarios), along with their dual counterparts (linear combinations of inequalities), by translating them into semidefinite programs.</p>



<p class="justify-text">What we saw might look like an overkill for studying gradient descent. However, as long as we deal with Euclidean spaces, the same approach actually works beyond this simple case. In particular, the same technique applies to first-order methods performing explicit, projected, proximal, conditional, and inexact (sub)gradient steps [<a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>].</p>



<p class="justify-text">Finally, let us mention a few previous works illustrating that the use of such computer-assisted proofs allowed obtaining results that are apparently too complicated for us to find bare-handed—even in apparently simple contexts.  Reasonable examples include the direct proof for convergence rates in  function values [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>] presented above, but also proofs arising in the context of optimized numerical schemes [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>, <a href="https://arxiv.org/abs/1409.2636">16</a>, <a href="https://arxiv.org/pdf/1406.5468.pdf">17</a>, <a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>]—in particular [<a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>] presents a method for minimizing the gradient norm at the last iterate, in smooth convex minimization—,  in the context of monotone inclusions [<a href="https://arxiv.org/pdf/1812.00146.pdf">19</a>],  and even for more general fixed-point problems (e.g., for Halpern iterations [<a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">20</a>]).</p>



<h3>Toolbox</h3>



<p class="justify-text">The PErformance EStimation TOolbox (PESTO) [<a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">21</a>, see <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/graphs/traffic">Github</a>] allows a quick access to the methodology without worrying about details of semidefinite reformulations. The toolbox contains many  examples (about 50) in different settings, and include progresses on the approach, and results, by other groups (which are much more thoroughly referenced in the <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/blob/master/UserGuide.pdf">user guide</a>). In particular, we included standard classes of functions and operators, along with examples for analyzing recent optimized methods.</p>



<h2>References</h2>



<p class="justify-text">[1] Mark Schmidt, Nicolas Le Roux, Francis Bach. <a href="https://arxiv.org/pdf/1309.2388.pdf">Minimizing finite sums with the stochastic average gradient</a>. <em>Mathematical Programming</em>, <em>162</em>(1-2), 83-112, 2017.<br />[2] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/pdf/1206.3209.pdf">Performance of first-order methods for smooth convex minimization: a novel approach</a>. <em>Mathematical Programming</em>, 145(1-2), 451-482, 2014.<br />[3] Laurent Lessard, Benjamin Recht, Andrew Packard. <a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">Analysis and design of  optimization algorithms via integral quadratic constraints</a>. <em>SIAM Journal on Optimization</em>, 26(1), 57-95, 2016.<br />[4] Adrien Taylor,  Julien Hendrickx, François Glineur. <a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">Smooth strongly convex interpolation and exact worst-case performance of first-order methods</a>. <em>Mathematical Programming</em>, 161(1-2), 307-345, 2017.<br />[5] Yurii Nesterov. <a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">Introductory Lectures on Convex Optimization : a Basic Course</a>. <em>Applied optimization</em>. Kluwer Academic Publishing, 2004.<br />[6]  Boris Polyak. Introduction to Optimization. Optimization Software New York, 1987.<br />[7] Daniel Azagra, Carlos Mudarra. <a href="https://arxiv.org/pdf/1603.00241.pdf">An extension theorem for convex functions of class \(C^{1,1}\) on Hilbert spaces</a>. <em>Journal of Mathematical Analysis and Applications</em>, 446(2):1167–1182, 2017.<br />[8] Aris Daniilidis, Mounir Haddou, Erwan Le Gruyer, Olivier Ley. <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">Explicit formulas for \(C^{1,1}\) Glaeser-Whitney extensions of 1-Taylor fields in Hilbert spaces</a>. <em>Proceedings of the American Mathematical Society</em>, 146(10):4487–4495, 2018.<br />[9] Johan Löfberg. <a href="https://yalmip.github.io/">YALMIP : A toolbox for modeling and optimization in MATLAB</a>. <em>Proceedings of the CACSD Conference</em>, 2004.<br />[10] APS Mosek. <a href="https://www.mosek.com/">The MOSEK optimization software</a>. Online at http://www.mosek.com, 54, 2010.<br />[11] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1705.04398.pdf">Exact worst-case convergence rates of the proximal gradient method for  composite convex minimization</a>. <em>Journal of Optimization Theory and Applications</em>, vol. 178, no 2, p. 455-476, 2018.<br />[12] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1512.07516.pdf">Exact worst-case performance of first-order methods for composite convex optimization</a>. <em>SIAM Journal on Optimization</em>, vol. 27, no 3, p. 1283-1313, 2017.<br />[13] Nikhil Bansal, Anupam Gupta. <a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">Potential-Function Proofs for Gradient Methods. <em>Theory of Computing</em></a>, <em>15</em>(1), 1-32, 2019.<br />[14] Adrien Taylor, Francis Bach. <a href="https://arxiv.org/pdf/1902.00947.pdf">Stochastic first-order methods: non-asymptotic and computer-aided analyses via potential functions</a>, <em>Proceedings of the 32nd Conference on Learning Theory (COLT)</em>, 99:2934-2992, 2019.  <br />[15] Bin Hu, Laurent Lessard. <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">Dissipativity theory for Nesterov’s accelerated method</a>, <em>Proceedings of the 34th International Conference on Machine Learning</em>, 70:1549-1557, 2017. <br />[16] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/abs/1409.2636">An optimal variant of Kelley’s cutting-plane method</a>. <em>Mathematical Programming</em> 160.1-2: 321-351, 2016.<br />[17] Donghwan<strong> </strong>Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1406.5468.pdf">Optimized first-order methods for smooth convex minimization</a>, <em>Mathematical programming</em>, <em>159</em>(1-2), 81-107, 2016.<br />[18] Donghwan Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1803.06600.pdf">Optimizing the efficiency of first-order methods for decreasing the gradient of smooth convex functions</a>, <em>preprint arXiv:1803.06600</em>, 2018. <br />[19] Ernest Ryu, Adrien Taylor, Carolina Bergeling, Pontus Giselsson. <a href="https://arxiv.org/pdf/1812.00146.pdf">Operator splitting performance estimation: Tight contraction factors and optimal parameter selection</a>, <em><em>SIAM Journal on Optimization</em> (to appear), 2020.</em><br />[20] Felix Lieder. <a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">On the convergence rate of the Halpern-iteration</a>. Technical Report, 2019.<br />[21] Adrien Taylor, Julien Hendrickx, François Glineur.  <a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">Performance estimation toolbox (PESTO): automated worst-case analysis of  first-order optimization methods</a>,<em> Proceedings of the 56th Annual Conference on Decision and Control (CDC)</em>, pp. 1278-1283, 2017.</p></div>







<p class="date">
by Adrien Taylor <a href="https://francisbach.com/computer-aided-analyses/"><span class="datestr">at April 03, 2020 11:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=39">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/03/19/friday-march-27-sujay-sanghavi-from-ut-austin/">Friday, March 27 — Sujay Sanghavi from UT Austin</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The second Foundations of Data Science virtual talk will take place next Friday, March 27th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Sujay Sanghavi</strong> from University of Texas at Austin will speak about “<em>Towards Model Agnostic Robustness</em>”.</p>



<p><strong>Abstract</strong>: It is now common practice to try and solve machine learning problems by starting with a complex existing model or architecture, and fine-tuning/adapting it to the task at hand. However, outliers, errors or even just sloppiness in training data often lead to drastic drops in performance. </p>



<p>We investigate a simple generic approach to correct for this, motivated by a classic statistical idea: trimmed loss. This advocates jointly (a) selecting which training samples to ignore, and (b) fitting a model on the remaining samples. As such this is computationally infeasible even for linear regression. We propose and study the natural iterative variant that alternates between these two steps (a) and (b) – each of which individually can be easily accomplished in pretty much any statistical setting. We also study the batch-SGD variant of this idea. We demonstrate both theoretically (for generalized linear models) and empirically (for vision and NLP neural network models) that this effectively recovers accuracy in the presence of bad training data.</p>



<p>This work is joint with Yanyao Shen and Vatsal Shah and appears in NeurIPS 2019, ICML 2019 and AISTATS 2020.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/03/19/friday-march-27-sujay-sanghavi-from-ut-austin/"><span class="datestr">at March 19, 2020 02:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=2386">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/richardson-extrapolation/">On the unreasonable effectiveness of Richardson extrapolation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">This month, I will follow up on <a href="https://francisbach.com/acceleration-without-pain/">last month’s blog post</a>, and describe classical techniques from numerical analysis that aim at accelerating the convergence of a vector sequence to its limit, by only combining elements of the sequence, and without the detailed knowledge of the iterative process that has led to this sequence. </p>



<p class="justify-text">Last month, I focused on sequences that converge to their limit exponentially fast (which is referred to as <em>linear</em> convergence), and I described <a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">Aitken’s \(\Delta^2\) method</a>, the <a href="https://en.wikipedia.org/wiki/Shanks_transformation">Shanks transformation</a>, Anderson acceleration and its <a href="https://arxiv.org/pdf/1606.04133">regularized version</a>. These methods are called “non-linear” acceleration techniques, because, although they combine linearly iterates as \(c_0 x_k + c_1 x_{k+1} + \cdots + c_m x_{k+m}\), the scalar weights in the linear combination depend non-linearly on \(x_k,\dots,x_{k+m}\).</p>



<p class="justify-text">In this post, I will focus on sequences that converge sublinearly, that is, with a difference to their limit that goes to zero as an inverse power of \(k\), typically in \(O(1/k)\). </p>



<h2>Richardson extrapolation</h2>



<p class="justify-text">We consider a sequence \((x_k)_{k \geq 0} \in \mathbb{R}^d\), with an asymptotic expansion of the form $$ x_k = x_\ast + \frac{1}{k}\Delta + O\Big(\frac{1}{k^2}\Big), $$ where \(x_\ast \in \mathbb{R}^d\) is the limit of \((x_k)_k\) and \(\Delta\) a vector in \(\mathbb{R}^d\).</p>



<p class="justify-text">The idea behind <a href="https://en.wikipedia.org/wiki/Richardson_extrapolation">Richardson extrapolation</a> [<a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.1911.0009">1</a>] is to combine linearly two iterates taken at two different values of \(k\) so that the zero-th order term \(x_\ast\) is left unchanged, but the first order term in \(1/k\) cancels out. For \(k\) even, we can consider $$  2 x_k – x_{k/2} =  2 \Big( x_\ast + \frac{1}{k} \Delta  +O\Big(\frac{1}{k^2}\Big)  \Big) \, – \Big( x_\ast +  \frac{2}{k} \Delta  + O\Big(\frac{1}{k^2}\Big) \Big)  =  x_\ast +O\Big(\frac{1}{k^2}\Big).$$</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><a href="https://arxiv.org/pdf/1707.06386"><img width="404" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/reg_k-1024x454.png" class="wp-image-2421" height="179" /></a>Illustration of Richardson extrapolation. Iterates (in black) with their first-order expansions (in red). The deviations (represented by circles) are of order \(O(1/k^2)\). Adapted from [<a href="https://arxiv.org/pdf/1707.06386">3</a>, <a href="https://arxiv.org/pdf/2002.02835">2</a>].  </figure></div>



<p class="justify-text">The key benefit of Richardson extrapolation is that we only need to know that the leading term in the asymptotic expansion is proportional to \(1/k\), <em>without the need to know the vector \(\Delta\)</em>. See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="332" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/richardson_2d.gif" class="wp-image-2481" height="280" />Richardson extrapolation in two dimensions. The sequence is of the form \(x_k = \frac{1}{k} \Delta_1 + \frac{(-1)^k}{k^2} \Delta_2\). The extrapolated sequence \(2 x_k – x_{k/2}\) is only plotted for \(k\) even.</figure></div>



<p class="justify-text">In this post, following [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>], I will explore situations where Richardson extrapolation can be useful within machine learning. I identified three situations where Richardson extrapolation can be useful (there are probably more):</p>



<ol class="justify-text"><li>Iterates of an optimization algorithms \((x_k)_{k \geq 0}\), and the extrapolation is \( 2x_k – x_{k/2}.\)</li><li>Extrapolation on the step-size of stochastic gradient descent, where we will combine iterates obtained from two different values of the step-size.</li><li>Extrapolation on a regularization parameter.</li></ol>



<p class="justify-text">As we will show, extrapolation techniques come with no significant loss in performance, but in several situations strong gains. It is thus “<a href="https://en.wikipedia.org/wiki/The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences">unreasonably effective</a>“.</p>



<h2>Application to optimization algorithms</h2>



<p class="justify-text">We consider an iterate \(x_k\) of an iterative optimization algorithm which is minimizing a function \(f\), thus converging to a global minimizer \(x_\ast\) of \(f\). Then so is \(x_{k/2}\), and thus also $$  x_k^{(1)} = 2x_k – x_{k/2}.$$ Therefore, performance is never significantly deteriorated (the risk is essentially to lose half of the iterations). The potential gains depend on the way \(x_k\) converges to \(x_\ast\). The existence of a convergence rate of the form \(f(x_k) -f(x_\ast) = O(1/k)\) or \(O(1/k^2)\) is not enough, as Richardson extrapolation requires a specific direction of asymptotic convergence. As illustrated below, some algorithms are oscillating around their solutions, while some converge with a specific direction. Only the latter ones can be accelerated with Richardson extrapolation, while the former ones are good candidates for <a href="https://francisbach.com/acceleration-without-pain/">Anderson acceleration</a>.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="476" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/nonoscillating_oscillating-1024x350.png" class="wp-image-2395" height="162" /> Left: Oscillating convergence, where Richardson extrapolation does not lead to any gain. Right: non-oscillating  convergence, with a main direction \(\Delta\) (in red dotted), where Richardson extrapolation can be beneficial if the oscillations orthogonal to the direction \(\Delta\) are negligible compared to convergence along the direction \(\Delta\). </figure></div>



<p class="justify-text"><strong>Averaged gradient descent.</strong> We consider the usual gradient descent algorithm $$x_k = x_{k-1} – \gamma f'(x_{k-1}),$$ where \(\gamma &gt; 0 \) is a step-size, with Polyak-Ruppert averaging [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">4</a>]: $$ y_k = \frac{1}{k} \sum_{i=0}^{k-1} x_i.$$ Averaging is key to robustness to potential noise in the gradients [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">4</a>, <a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">5</a>]. However it comes with the unintended consequence of losing the exponential forgetting of initial conditions for strongly-convex problems [<a href="https://papers.nips.cc/paper/4316-non-asymptotic-analysis-of-stochastic-approximation-algorithms-for-machine-learning.pdf">6</a>].</p>



<p class="justify-text">A common way to restore exponential convergence (up to the noise level in the stochastic case) is to consider “tail-averaging”, that is, to replace \(y_k\) by the average of only the latest \(k/2\) iterates [<a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">7</a>]. As shown below for \(k\) even, this corresponds exactly to Richardson extrapolation on the sequence \((y_k)_k\): $$ \frac{2}{k} \sum_{i=k/2}^{k-1} x_i = \frac{2}{k} \sum_{i=0}^{k-1} x_i – \frac{2}{k} \sum_{i=0}^{k/2-1} x_i = 2 y_k – y_{k/2}. $$</p>



<p class="justify-text">With basic  assumptions on \(f\), it is shown in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>] that for locally strongly-convex problems: $$y_k = x_\ast + \frac{1}{k} \Delta + O(\rho^k), $$ where  \(\displaystyle \Delta = \sum_{i=0}^\infty (x_i – x_\ast)\) and \(\rho \in (0,1)\) depends on the condition number of \(f”(x_\ast)\). This is illustrated below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="342" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/averaged_gradient.png" class="wp-image-2507" height="250" />Averaged gradient descent on a <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> problem in dimension \(d=400\), and with \(n=4000\) observations. For the regular averaged recursion, the line in the log-log plot has slope \(-2\). See experimental details in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>].</figure></div>



<p class="justify-text">We can make the following observations:</p>



<ul class="justify-text"><li>Before Richardson extrapolation, the asymptotic convergence rate after averaging is of order \(O(1/k^2)\), which is better than the usual \(O(1/k)\) upper-bound for the rate of gradient descent, but with a stronger assumption that in fact leads to exponential convergence before averaging.</li><li>While \(\Delta\) has a simple expression, it cannot be computed in practice (but Richardson extrapolation does not need to know it).</li><li>Richardson extrapolation leads to an exponentially convergent algorithm from an algorithm converging asymptotically in \(O(1/k^2)\).</li></ul>



<p class="justify-text"><strong>Accelerated gradient descent.</strong> Above, we considered averaged gradient descent, which is asymptotically converging as \(O(1/k^2)\), and on which Richardson extrapolation could be used with strong gains. Is it possible also for the accelerated gradient descent method [<a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=dan&amp;paperid=46009&amp;what=fullt&amp;option_lang=eng">8</a>], which has a (non-asymptotic) convergence rate of \(O(1/k^2)\) for convex functions?</p>



<p class="justify-text">It turns out that the behavior of the iterates of accelerated gradient descent is exactly of the form depicted in the left plot of the figure above: that is, the iterates \(x_k\) oscillate around the optimum [<a href="http://jmlr.org/papers/volume17/15-084/15-084.pdf">9</a>, <a href="http://proceedings.mlr.press/v40/Flammarion15.pdf">10</a>], and Richardson extrapolation is of no help, but is not degrading performance too much. See below for an illustration. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="332" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/accelerated_gradient.png" class="wp-image-2509" height="243" />Accelerated gradient descent on a quadratic optimization problem in dimension \(d=1000\). See experimental details in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>].  </figure></div>



<p class="justify-text"><strong>Other algorithms.</strong> It is tempting to test it on other optimization algorithms. For example, as explained in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>], Richardson extrapolation can be used to the <a href="https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm">Frank-Wolfe</a> algorithm, where sometimes it helps, sometimes it doesn’t. Others could be tried.</p>



<h2>Extrapolation on the step-size of stochastic gradient descent</h2>



<p class="justify-text">While above we have focused on Richardson extrapolation applied to the number of iterations of an iterative algorithm, it is most often used in integration methods (for computing integrals or solving ordinary differential equations), and then often referred to as <a href="https://en.wikipedia.org/wiki/Romberg%27s_method">Romberg-Richardson extrapolation</a>. Within machine learning, in a similar spirit, this can be applied to the step-size of stochastic gradient descent [<a href="https://arxiv.org/pdf/1707.06386">3</a>, <a href="http://papers.nips.cc/paper/6514-stochastic-gradient-richardson-romberg-markov-chain-monte-carlo.pdf">11</a>], which I now describe.</p>



<p class="justify-text">We consider the minimization of a function \(F(x)\) defined on \(\mathbb{R}^d\), which can be written as an expectation as $$F(x) = \mathbb{E}_{z} f(x,z).$$ We assume that we have access to \(n\) independent and identically distributed observations (i.i.d.) \(z_1,\dots,z_n\). This is a typical scenario in machine learning, where \(f(x,z)\) represents the loss for the predictor parameterized by \(x\) on the observation \(z\). </p>



<p class="justify-text">The stochastic gradient method is particularly well adapted, and we consider here a single pass, as $$x_i= x_{i-1} – \gamma f'(x_{i-1},z_i),$$ where the gradient is taken with respect to the first variable, for \(i = 1,\dots,n\). It is known that with a constant step-size, when \(n\) tends to infinity, \(x_n\) will <em>not</em> converge to the minimizer \(x_\ast\) of \(F\), as the algorithm always moves [<a href="https://epubs.siam.org/doi/pdf/10.1137/0324039">16</a>], as illustrated below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="403" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/logistic_2d-1.gif" class="wp-image-2488" height="279" />Stochastic gradient descent on a logistic regression problem: (blue) without averaging, (red) with averaging.</figure></div>



<p class="justify-text">One way to damp the oscillations is to consider averaging, that is, $$ y_n = \frac{1}{n+1} \sum_{i=0}^{n} x_i$$ (we consider uniform averaging for simplicity). For least-squares regression, this leads to a converging algorithm [<a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">12</a>] with attractive properties for ill-conditioned problems (see also <a href="https://francisbach.com/the-sum-of-a-geometric-series-is-all-you-need/">January’s blog post</a>). However, for general loss functions, it is shown in [<a href="https://arxiv.org/pdf/1707.06386">3</a>] that \(y_n\) converges to some \(y^{(\gamma)} \neq x_\ast\). There is a bias due to a step-size \(\gamma\) that does not go to zero. In order to apply Richardson extrapolation, together with Aymeric Dieuleveut and Alain Durmus [<a href="https://arxiv.org/pdf/1707.06386">3</a>], we showed that $$ y^{(\gamma)} = x_\ast + \gamma \Delta + O(\gamma^2),$$ for some \(\Delta \in \mathbb{R}^d\) with some complex expression. Thus, we have $$2 y^{(\gamma)} – y^{(2\gamma)} = x_\ast + O(\gamma^2),$$ thus gaining one order. If we consider the iterate \(y_n^{(\gamma)}\) and \(y_n^{(2 \gamma)}\) associated to the two step-sizes \(\gamma\) and \(2 \gamma\), the linear combination $$2 y_n^{(\gamma)} – y_n^{(2\gamma)} $$ has an improved behavior as it tends to \(2 y^{(\gamma)} – y^{(2\gamma)} = x_\ast + O(\gamma^2)\): it remains not convergent, but get to way smaller values. See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="359" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/SGD_logistic-1.png" class="wp-image-2525" height="274" />Averaged stochastic gradient descent on a logistic regression problem in dimension 20.</figure></div>



<p class="justify-text"><strong>Higher-order extrapolation.</strong> If we can accelerate a sequence by extrapolation, why not extrapolate the extrapolated sequence? This is possible if we have an higher-order expansion of the form $$ y^{(\gamma)} = \theta_\ast + \gamma \Delta_1 + \gamma^2 \Delta_2 + O(\gamma^3),$$ for some (typically unknown) vectors \(\Delta_1\) and \(\Delta_2\). Then, the sharp reader can check that $$3 y_n^{(\gamma)} – 3 y_n^{(2\gamma)} +  y_n^{(3\gamma)}, $$ will lead to cancellation of the first two orders \(\gamma\) and \(\gamma^2\). This is illustrated above for SGD.</p>



<p class="justify-text">Then, why not extrapolate the extrapolation of the extrapolated sequence? One can check that $$4 y_n^{(\gamma)} – 6 y_n^{(2\gamma)} + 4  y_n^{(3\gamma)}  -y_n^{(4\gamma)}, $$ will lead to cancellation of the first three orders of an expansion of \(y^{(\gamma)}\). The <a href="https://en.wikipedia.org/wiki/Binomial_coefficient">binomial coefficient</a> aficionados have already noticed the pattern there, and checked that $$ \sum_{i=1}^{m+1} (-1)^{i-1} { m+1 \choose i} y_n^{(i\gamma)}$$ will lead to cancellations of the first \(m\) orders.</p>



<p class="justify-text">Then, why not go on forever? First because \(m+1\) recursions have to be run in parallel, and second, because the constant in front of the term in \(\gamma^{m+1}\) typically explodes, a phenomenon common to many expansion methods.</p>



<h2>Extrapolation on a regularization parameter</h2>



<p class="justify-text">We now explore the application of Richardson extrapolation to regularization methods. In a nutshell, regularization allows to make an estimation problem more stable (less subject to variations for statistical problems) or the algorithm faster (for optimization problems). However, regularization adds a bias that needs to be removed. In this section, we apply Richardson extrapolation to the regularization parameter to reduce this bias. I will only present an application to smoothing for non-smooth optimization (see an application to  ridge regression in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>]).</p>



<p class="justify-text"><strong>Non-smooth optimization problems</strong>. We consider the minimization of a convex function of the form \(f = h + g\), where \(h\) is smooth and \(g\) is non-smooth. These optimization problems are ubiquitous in machine learning and signal processing, where the lack of smoothness can come from (a) non-smooth losses such as max-margin losses used in support vector machines and more generally structured output classification [<a href="https://icml.cc/Conferences/2005/proceedings/papers/113_StructuredPrediction_TaskarEtAl.pdf">13</a>], and (b) sparsity-inducing regularizers (see, e.g., [<a href="https://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">14</a>] and references therein). While many algorithms can be used to deal with this non-smoothness, we consider a classical smoothing technique below.</p>



<p class="justify-text"><strong>Nesterov smoothing</strong>. In this section, we consider the smoothing approach of Nesterov [<a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">15</a>] where the non-smooth term is “smoothed” into \(g_\lambda\), where \(\lambda\) is a regularization parameter, and accelerated gradient descent is used to minimize \(h+g_\lambda\). </p>



<p class="justify-text">A typical way of smoothing the function \(g\) is to add \(\lambda\) times a strongly convex regularizer (such as the squared Euclidean norm) to the Fenchel conjugate of \(g\); this leads to a function \(g_\lambda\) which has a smoothness constant (defined as the maximum of the largest eigenvalues of all Hessians) proportional to \(1/\lambda\), with a uniform error of \(O(\lambda)\) between \(g\) and \(g_\lambda\). Given that accelerated gradient descent leads to an iterate with excess function values proportional to \(1/(\lambda k^2)\) after \(k\) iterations, with the choice of \(\lambda \propto 1/k\), this leads to an excess in function values proportional to \(1/k\), which improves on the subgradient method which converges in \(O(1/\sqrt{k})\). Note that the amount of regularization depends on the number of iterations, so that this smoothing method is not “anytime”.</p>



<p class="justify-text"><strong>Richardson extrapolation.</strong> If we denote by \(x_\lambda\) the minimizer of \(h+g_\lambda\) and \( x_\ast\) the global minimizer of \( f=h+g\), if we can show that \( x_\lambda = x_\ast + \lambda \Delta + O(\lambda^2)\), then \( x^{(1)}_\lambda = 2 x_\lambda – x_{2\lambda} = O(\lambda^2)\) and we can expand \( f(x_\lambda^{(1)})  = f(x_\ast)  + O(\lambda^2)\), which is better than the \(O(\lambda)\) approximation without extrapolation. </p>



<p class="justify-text">Then, given a number of iterations \(k\), with \( \lambda \propto k^{-2/3}\), to balance the two terms \( 1/(\lambda k^2)\) and \( \lambda^2\),  we get an overall convergence rate for the non-smooth problem of \( k^{-4/3}\). </p>



<p class="justify-text"><strong>\(m\)-step Richardson extrapolation</strong>. Like above for the step-size, we can also consider \(m\)-step Richardson extrapolation \(x_{\lambda}^{(m)}\), which leads to a bias proportional to \(\lambda^{m+1}\). Thus, if we consider \(\lambda \propto 1/k^{2/(m+2)}\), to balance the terms \(1/(\lambda k^2)\) and \(\lambda^{m+1}\), we get an error for the non-smooth problem of \(1/k^{2(m+1)/(m+2)}\), which can get arbitrarily close to \(1/k^2\) when \(m\) gets large. The downsides (like for the extrapolation on the step-size above) are that (a) the constants in front of the asymptotic equivalent may blow up (a classical problem in high-order expansions), and (b) \(m\)-step extrapolation requires running the algorithm \(m\) times (this can be down in parallel). In the experiment below, 3-step extrapolation already brings in most of the benefits.</p>



<p class="justify-text">In order to experimentally study the benefits of extrapolation, for the <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">Lasso</a> optimization problem, and for a series of regularization parameters equal to \(2^{i}\) for \(i\) between \(-18\) and \(1\) (sampled every \(1/5\)), we run accelerated gradient descent on \(h+g_\lambda\) and we plot the value of \(f(x)-f(x_\ast)\) for the various estimates, where for each number of iterations, we minimize over the regularization parameter. This is an oracle version of varying \(\lambda\) as a function of the number of iterations. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="351" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/smoothing.png" class="wp-image-2530" height="255" />Excess function values as a function of the number of iterations, <em>taking into account that \(m\)-step Richardson extrapolation requires \(m\)-times more iterations</em>. There is indeed a strong improvement approaching the rate \(1/k^2\).</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">These last two blog posts were dedicated to acceleration techniques coming from numerical analysis. They are cheap to implement, typically do not interfere with the underlying algorithm, and when used in the appropriate situation, can bring in significant speed-ups.</p>



<p class="justify-text">Next month, I will most probably host an invited post by my colleague <a href="https://www.di.ens.fr/~ataylor/">Adrien Taylor</a>, who will explain how machines can <s>replace</s> help researchers that prove bounds on optimization algorithms.</p>



<h2>References</h2>



<p class="justify-text">[1] Lewis Fry Richardson. <a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.1911.0009">The approximate arithmetical solution by finite differences of physical problems involving differential equations, with an application to the stresses in a masonry dam</a>. <em>Philosophical Transactions of the Royal Society of London, Series A</em>, 210(459-470):307–357, 1911.<br />[2] Francis Bach. <a href="https://arxiv.org/pdf/2002.02835">On the Effectiveness of Richardson Extrapolation in Machine Learning</a>. Technical report, arXiv:2002.02835, 2020.<br />[3] Aymeric Dieuleveut, Alain Durmus, Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the Gap between Constant Step Size Stochastic Gradient Descent and Markov Chains</a>. To appear in <em>The Annals of Statistics</em>, 2019.<br />[4] Boris T. Polyak,  Anatoli B. Juditsky. <a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">Acceleration of stochastic approximation by averaging</a>. <em>SIAM journal on control and optimization</em> 30(4):838-855, 1992.<br />[5] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, Alexander Shapiro<em>. </em><a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">Robust stochastic approximation approach to stochastic programming</a>. <em>SIAM Journal on optimization</em>, 19(4):1574-1609, 2009.<br />[6] Francis Bach, Eric Moulines. <a href="https://papers.nips.cc/paper/4316-non-asymptotic-analysis-of-stochastic-approximation-algorithms-for-machine-learning.pdf">Non-asymptotic analysis of stochastic approximation algorithms for machine learning</a>. <em>Advances in Neural Information Processing Systems</em>, 2011.<br />[7] Prateek Jain, Praneeth Netrapalli, Sham Kakade, Rahul Kidambi, Aaron Sidford. <a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">Parallelizing stochastic gradient descent for least squares regression: mini-batching, averaging, and model misspecification</a>. <em>The Journal of Machine Learning Research</em>, 18(1), 8258-8299, 2017.<br />[8] Yurii E. Nesterov. <a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=dan&amp;paperid=46009&amp;what=fullt&amp;option_lang=eng">A method of solving a convex programming problem with convergence rate \(O(1/k^2)\)</a>, <em>Doklady Akademii Nauk SSSR</em>, 269(3):543–547, 1983.<br />[9] Weijie Su, Stephen Boyd, and Emmanuel J. Candes. <a href="http://jmlr.org/papers/volume17/15-084/15-084.pdf">A differential equation for modeling Nesterov’s accelerated gradient method: theory and insights</a>. <em>Journal of Machine Learning Research</em>, 17(1):5312-5354, 2016.<br />[10] Nicolas Flammarion, and Francis Bach. <a href="http://proceedings.mlr.press/v40/Flammarion15.pdf">From Averaging to Acceleration, There is Only a Step-size</a>. <em>Proceedings of the International Conference on Learning Theory (COLT)</em>, 2015. <br />[11] Alain Durmus, Umut Simsekli, Eric Moulines, Roland Badeau, and Gaël Richard. <a href="http://papers.nips.cc/paper/6514-stochastic-gradient-richardson-romberg-markov-chain-monte-carlo.pdf">Stochastic gradient Richardson-Romberg Markov chain Monte Carlo</a>. In <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2016.<br />[12] Francis Bach and Eric Moulines. <a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate \(O(1/n)\)</a>. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2013.<br />[13] Ben Taskar, Vassil Chatalbashev, Daphne Koller, and Carlos Guestrin. <a href="https://icml.cc/Conferences/2005/proceedings/papers/113_StructuredPrediction_TaskarEtAl.pdf">Learning structured prediction models: A large margin approach</a>. <em>Proceedings of the International Conference on Machine Learning (ICML)</em>, 2005.<br />[14] Francis Bach, Rodolphe Jenatton, Julien Mairal, and Guillaume Obozinski. <a href="https://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">Optimization with sparsity-inducing penalties</a>. Foundations and Trends in Machine Learning, 4(1):1–106, 2012<br />[15] Yurii Nesterov. <a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">Smooth minimization of non-smooth functions</a>. Mathematical Programming , 103(1):127–152, 2005.<br />[16] Georg Ch. Pflug. <a href="https://epubs.siam.org/doi/pdf/10.1137/0324039">Stochastic minimization with constant step-size: asymptotic laws</a>. <em>SIAM Journal on Control and Optimization</em>, (24)4:655-666, 1986.</p>



<p></p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/richardson-extrapolation/"><span class="datestr">at March 01, 2020 12:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=26">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/">Friday, February 28 — Jon Kleinberg from Cornell University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The first Foundations of Data Science virtual talk will take place this coming Friday, February 28th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC). <strong>Jon Kleinberg</strong> from Cornell University will speak about “<em>Fairness and Bias in Algorithmic Decision-Making</em>”.</p>



<p><strong>Abstract</strong>: As data science has broadened its scope in recent years, a number of domains have applied computational methods for classification and prediction to evaluate individuals in high-stakes settings. These developments have led to an active line of recent discussion in the public sphere about the consequences of algorithmic prediction for notions of fairness and equity. In part, this discussion has involved a basic tension between competing notions of what it means for such classifications to be fair to different groups. We consider several of the key fairness conditions that lie at the heart of these debates, and in particular how these properties operate when the goal is to rank-order a set of applicants by some criterion of interest, and then to select the top-ranking applicants. The talk will be based on joint work with Sendhil Mullainathan and Manish Raghavan.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/"><span class="datestr">at February 27, 2020 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=40">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/02/08/icalp-and-lics-2020-relocation-and-extended-deadline/">ICALP (and LICS) 2020 – Relocation and Extended Deadline</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Due to the Wuhan coronavirus outbreak, the organizers of ICALP and LICS have made the difficult decision to relocate both (co-located) conferences from Beijing, China, to Saarbrücken, Germany. Speaking specifically about ICALP now (I do not have further information about LICS): As a result of previous uncertainty regarding the situation, the deadline has been extended by about six days, until Tuesday February 18, 2020, at 6 AM GMT. The dates of the conference remain (roughly) the same, July 8 – 11, 2020. <br />The following is a more official message from ICALP Track A Chair, Artur Czumaj.</p>



<hr class="wp-block-separator" />



<p>The ICALP and the LICS steering committee have agreed together with the conference chairs in Beijing to relocate the two conferences.<br />ICALP and LICS 2020 will take place in <strong>Saarbrücken</strong>, Germany, July 8 – 11 2020 (with satellite workshops on July 6 – 7 2020).<br />The deadline is extended, see below.</p>



<p><strong>Call for Papers – ICALP 2020</strong><br /><strong>July 8 – 11 2020, Saarbrücken, Germany</strong></p>



<p><strong>NEW Paper submission deadline: Tuesday February 18, 2020, 6am GMT</strong><br /><a href="https://easychair.org/conferences/?conf=icalp2020">https://easychair.org/conferences/?conf=icalp2020</a></p>



<p>ICALP (International Colloquium on Automata, Languages and Programming) is the main European conference in Theoretical Computer Science and annual meeting of the European Association for Theoretical Computer Science (EATCS). ICALP 2020 will be hosted on the Saarland Informatics Campus in Saarbrücken, in co-location with LICS 2020 (ACM/IEEE Symposium on Logic in Computer Science).</p>



<p><strong>Invited speakers:</strong><br />Track A: Virginia Vassilevska (MIT), Robert Krauthgamer (Weizmann)<br />Track B: Stefan Kiefer (Oxford)<br />Joint ICALP-LICS: Andrew Yao (Tsinghua), Jérôme Leroux (Bordeaux)</p>



<p><strong>Submission Guidelines:</strong> see <a href="https://easychair.org/conferences/?conf=icalp2020">https://easychair.org/conferences/?conf=icalp2020</a></p>



<p><strong>NEW Paper submission deadline: February 18</strong>, 2020, 6am GMT<br />notifications: April 15, 2020<br />camera ready: April 28, 2020</p>



<p>Topics: ICALP 2020 will have the two traditional tracks<br />A (Algorithms, Complexity and Games – including Algorithmic Game Theory, Distributed Algorithms and Parallel, Distributed and External Memory Computing) and<br />B (Automata, Logic, Semantics and Theory of Programming).<br /><strong><em>    (Notice that the old tracks A and C have been merged into a single track A.)</em></strong><br />Papers presenting original, unpublished research on all aspects of theoretical computer science are sought.</p>



<p>Typical, but not exclusive topics are:</p>



<p>Track A — Algorithmic Aspects of Networks and Networking, Algorithms for Computational Biology, Algorithmic Game Theory, Combinatorial Optimization, Combinatorics in Computer Science, Computational Complexity, Computational Geometry, Computational Learning Theory, Cryptography, Data Structures, Design and Analysis of Algorithms, Foundations of Machine Learning, Foundations of Privacy, Trust and Reputation in Network, Network Models for Distributed Computing, Network Economics and Incentive-Based Computing Related to Networks, Network Mining and Analysis, Parallel, Distributed and External Memory Computing, Quantum Computing, Randomness in Computation, Theory of Security in Networks</p>



<p>Track B — Algebraic and Categorical Models, Automata, Games, and Formal Languages, Emerging and Non-standard Models of Computation, Databases, Semi-Structured Data and Finite Model Theory, Formal and Logical Aspects of Learning, Logic in Computer Science, Theorem Proving and Model Checking, Models of Concurrent, Distributed, and Mobile Systems, Models of Reactive, Hybrid and Stochastic Systems, Principles and Semantics of Programming Languages, Program Analysis and Transformation, Specification, Verification and Synthesis, Type Systems and Theory, Typed Calculi</p>



<p><strong>PC Track A chair: Artur Czumaj</strong> (University  of Warwick)<br /><strong>PC Track B chair: Anuj Dawar</strong> (University of Cambridge)</p>



<p>Contact<br />All questions about submissions should be emailed to the PC Track chairs:<br />Artur Czumaj <a href="mailto:A.Czumaj@warwick.ac.uk">A.Czumaj@warwick.ac.uk&lt;mailto:A.Czumaj@warwick.ac.uk&gt;</a><br />Anuj Dawar <a href="mailto:Anuj.Dawar@cl.cam.ac.uk">Anuj.Dawar@cl.cam.ac.uk&lt;mailto:Anuj.Dawar@cl.cam.ac.uk&gt;</a></p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/02/08/icalp-and-lics-2020-relocation-and-extended-deadline/"><span class="datestr">at February 08, 2020 03:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=2109">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/acceleration-without-pain/">Acceleration without pain</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">I don’t know of any user of iterative algorithms who has not complained one day about their convergence speed. Whether the data are too big, the processors not fast or numerous enough, waiting for an algorithm to converge unfortunately remains a core practical component of computer science and applied mathematics. This was already a concern long before computers were invented (and most of the techniques I will describe date back to the early 19th century): imagine you are doing all the operations (multiplications, additions, divisions) by hand, wouldn’t you want some cheap way to accelerate your algorithm (and here literally reduce your pain)?</p>



<p class="justify-text">Acceleration is a key concept in numerical analysis and can be carried through in two main ways. The first way is to modify some steps of the algorithm (such as Nesterov acceleration for gradient descent, or <a href="https://francisbach.com/chebyshev-polynomials/">Chebyshev</a> / <a href="https://francisbach.com/jacobi-polynomials/">Jacobi</a> acceleration for linear recursions). This requires a good knowledge of the inner structure of the underlying algorithm. A second way is to totally ignore the specifics of the algorithm, and see the acceleration problem as trying to find good “combinations” of the observed iterates that converge faster.</p>



<p class="justify-text">In this blog post, I thus consider a sequence of iterates \((x_k)_{k \geq 0}\) in \(\mathbb{R}^d\) obtained from an iterative algorithm \(x_{k+1} = T(x_k)\), which will typically be an optimization algorithm. The main question I will address is: Can we do better than outputting the last iterate?</p>



<p class="justify-text">This has a long history in numerical analysis, where many techniques have been developed for uni-dimensional sequences. Acceleration techniques vary according to the <a href="https://en.wikipedia.org/wiki/Rate_of_convergence">type of convergence</a> of the original sequence (quadratic, linear, sublinear), the amount of knowledge about the asymptotic behavior, and the possibility of extensions to high-dimensional and noisy problems.</p>



<p class="justify-text">Acceleration techniques are often based on an explicit or implicit modelling of the sequence \(x_k\), either through a model of the function \(T: \mathbb{R}^d \to \mathbb{R}^d\) (the iteration of the algorithm) or through an asymptotic expansion of \(x_k\). In this post, I will focus on linearly convergent sequences, that is, sequences \(x_k\) converging to some \(x_\ast\) at an exponential rate. As we will see, this will done through modelling \(x_k\) as an autoregressive process.</p>



<p class="justify-text">I will first start from the simplest scheme, the <a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">Aitken’s \(\Delta^2\) process</a> from 1926 [1], then look at higher order generalizations still in one dimension, and finally to the general vector case. We will then apply all that to gradient descent.</p>



<h2>Aitken’s \(\Delta^2\) process</h2>



<p class="justify-text">This is the simplest of all techniques and the source of all others in this post. We try to model \(x_k\in \mathbb{R}\) as first-order auto-regressive sequence, that is, \(x_{k+1} = ax_{k}+b\), for \(a,b \in \mathbb{R}\). The method works by (a) estimating \(a\) and \(b\) from a sequence of few consecutive (here three) iterates, and (b) extrapolating by computing the limit \(x_{\rm acc}\) of the estimated model. Given that we fit the model to consecutive iterates \((x_k,x_{k+1},x_{k+2})\), the model \((a,b)\) will also depend on \(k\), as well as its limit \(x_{\rm acc}\). In order to avoid having too many \(k\)’s in my notations, I will drop the dependence in \(k\) of the model parameters.</p>



<p class="justify-text">In this situation, the model recursion has a limit when \(a \neq 1\), and the limit is \(x_{\rm acc} =  \frac{b}{1-a}\). In order to fit the two parameters, we need two equations, which can be obtained by considering two consecutive evaluations of the recursions (which require three iterates). That is, we consider the linear system in \((a,b)\): $$ \Big\{ \begin{array}{ll} ax_{k}+b  &amp; = x_{k+1} \\    ax_{k+1}+b &amp; = x_{k+2} \end{array}$$ which can be solved in a variety of ways. All of them are equivalent, but naturally lead to different extensions.</p>



<p class="justify-text"><strong>Solving by elimination.</strong> We can eliminate \(b\) by subtracting the two equations, leading to $$ x_{k+2}  – x_{k+1} = a ( x_{k+1} – x_{k}),$$  and thus $$a = \frac{ x_{k+2}  – x_{k+1}}{ x_{k+1} – x_{k}}.$$ We then get $$b = x_{k+1} – a x_{k} = x_{k+1} –  \frac{ x_{k+2}  – x_{k+1}}{ x_{k+1} – x_{k}} x_{k} =  \frac{  x_{k+1}^2 – x_{k} x_{k+2}}{ x_{k+1} – x_{k}}, $$ and the extrapolating sequence $$x_{\rm acc} = \frac{b}{1-a} = \frac{x_{k} x_{k+2} – x_{k+1}^2 }{-2 x_{k+1} + x_{k+2} + x_{k}},$$ which we denote \(x^{(1)}_k\), to highlight its dependence on \(k\). Note that to compute \(x^{(1)}_k\), we need access to the three iterates \((x_k,x_{k+1},x_{k+2})\), and thus, when comparing the original sequence to the extrapolated one, we will compare \(x_k\) and \(x^{(1)}_{k-2}\).</p>



<p class="justify-text"><strong>Asymptotic auto-regressive model</strong>. A key feature of the acceleration techniques that I describe in this post is that although they implicitly or explicitly model sequence with auto-regressive processes, the models do not need to be correct, that is, they also work if the autoregressive recursion is true only asymptotically, for example \(\displaystyle \frac{x_{k+1}-x_\ast}{x_k – x_\ast}\) converging to a constant \(a \in [-1,1)\). Then we also get some acceleration, which can be quantified (see the end of the post for details), and for which we present a classical example below.</p>



<p class="justify-text"><strong>Approximating \(\pi\).</strong> We consider the <a href="https://en.wikipedia.org/wiki/Leibniz_formula_for_%CF%80">Leibniz formula</a>, which is one of many ways of <a href="https://en.wikipedia.org/wiki/Approximations_of_%CF%80">approximating \(\pi\)</a>: $$ \pi = \lim_{k \to +\infty} x_k  \mbox{ with } x_k = 4 \sum_{i=0}^{k} \frac{(-1)^i}{2i+1}.$$ This formula can be proved by expanding the derivative \(x \mapsto \frac{1}{1+x^2}\) of \(x \mapsto \arctan x\) as a power series and then integrating it. We can check that $$\frac{x_{k+1}-x_\ast}{x_k – x_\ast} =  \ – 1 + \frac{1}{k} + o( \frac{1}{k}), $$ and as detailed at the end of the post, we should expect the error to go from \(1/k\) to \(1/k^3\).  Below, we show the first 10 iterates of the two sequences, with the correct significant digits in bold. $$ \begin{array}{|l|l|l|} \hline k &amp; x_k &amp;  x_k^{(1)} \\ \hline  1  &amp;   4.0000   &amp;  \times \\      2  &amp;  2.6667     &amp;    \times \\  3  &amp;  \mathbf{3}.4667   &amp; \mathbf{3.1}667 \\   4 &amp;   2.8952  &amp;  \mathbf{3.1}333 \\     5  &amp;  \mathbf{3}.3397  &amp;  \mathbf{3.14}52 \\  6 &amp;   2.9760 &amp;   \mathbf{3.1}397 \\   7  &amp;  \mathbf{3}.2837  &amp;  \mathbf{3.14}27 \\   8  &amp;  \mathbf{3}.0171  &amp;  \mathbf{3.14}09 \\  9  &amp;  \mathbf{3}.2524  &amp;  \mathbf{3.14}21 \\   10  &amp;  \mathbf{3}.0418 &amp;  \mathbf{3.141}3 \\ \hline \end{array}$$ We see that the extrapolated sequence converges much faster. This is confirmed in the convergence plot below:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="335" alt="" src="https://francisbach.com/wp-content/uploads/2020/01/deltasquared.png" class="wp-image-2148" height="283" />\(\Delta^2\) method on the Leibniz series.  Notice the improvement from \(O(1/k)\) to \(O(1/k^3)\).</figure></div>



<h2>Higher-order one-dimensional extensions</h2>



<p class="justify-text">The Aitken’s \(\Delta^2\) process relies on fitting a first-order auto-regressive model, or on assuming that \(x_{k+1} – x_\ast – a (x_k – x_\ast) \to 0\) asymptotically. This can be extended to \(m\)-th order constant recursions. This corresponds to modelling \(x_k\) as the sum of \(m\) exponentials.</p>



<p class="justify-text">We thus try to fit the model $$x_{k+m} = a_0 x_k + a_1 x_{k+1} + \cdots + a_{m-1} x_{k+m-1} + b = \sum_{i=0}^{m-1} a_i x_{k+i} + b, $$ which has \(m+1\) parameters. We thus need \(m + 1\) equations, that is we consider the recursion for \(k, k+1,\dots, k+m\), which requires the knowledge of the \(2m+1\) iterates \(x_k, x_{k+1},\dots,x_{k+2m}\). This leads to the \(m+1\) equations: $$x_{k+m+j} = a_0 x_{k+j} + a_1 x_{k+j+1} + \cdots + a_{m-1} x_{k+j+m-1} + b = \sum_{i=0}^{m-1} a_i x_{k+j+i} + b,$$ for \(j \in \{0,\dots,m\}\). This is a system with \(m+1\) unknowns and \(m+1\) equations, from which we could get all \(a_j\)’s and \(b\), and then the model limit as the extrapolated sequence \(x^{(m)}_k = \frac{b}{1 – a_0 – a_1 – \cdots – a_{m-1}}\). </p>



<p class="justify-text">This linear system can be solved in a variety of ways. At the end of the blog post, I show how it can be solved using determinants of Hankel-like matrices, often referred to as the <a href="https://en.wikipedia.org/wiki/Shanks_transformation">Shanks transformation</a>, which then leads to an iterative algorithm dating back from Wynn [2], which is called the <a href="https://fr.wikipedia.org/wiki/Epsilon_algorithme">\(\varepsilon\)-algorithm</a>. In order to smooth our way to the vector case extension, I will present it in a slightly non-standard way. See [3] for a detailed survey on acceleration and extrapolation.</p>



<p class="justify-text">Instead of learning the model parameters to estimate \(x_{k+m}\) from the past iterates, we focus directly on the prediction of the limit \(x_{\rm acc}\) by looking for real numbers \(c_0,\dots,c_m\) such that for all \(k\), $$\sum_{i=0}^m c_i ( x_{k+i} – x_{\rm acc} ) = 0,$$ with the arbitrary normalization \(\sum_{i=0}^m c_i = 1\). The \(c_i\)’s can be obtained from the \(a_i\)’s and \(b\) as \((c_0,c_1,\dots,c_{m-1},c_m)\propto (a_0,a_1,\dots,a_{m-1},-1)\). We then have $$x_{\rm acc} = \sum_{i=0}^m c_{i} x_{k+i}.$$ Again, the parameters \(c_i\)’s depend on \(k\), but we omit this dependence.</p>



<p class="justify-text">In order to estimate the \(m+1\) parameters \(c_0,\dots,c_m\), we subtract two versions of the equality for \(k\) and \(k+1\), leading to $$\sum_{i=0}^m c_i ( x_{k+1+i} – x_{k+i} ) = 0.$$ Defining the matrix \(U \in \mathbb{R}^{m \times (m+1)}\) by $$U_{ji} = x_{k+1+i+j} – x_{k+i+j},$$ for \(i \in \{0,\dots,m\}\) and \(j \in \{0,\dots,m-1\}\), we have $$ U c = 0. $$ Together with the constraint \(1_{m+1}^\top c = 1\), this leads to the correct number of equations to estimate \(c\), from \(2m+1\) iterates \(x_k,\dots,x_{k+2m}\). The extrapolated iterate \(x^{(m)}_k\) is then $$x^{(m)}_k = x_{\rm acc} =   \sum_{i=0}^m c_{i} x_{k+i}.$$ Note that the extrapolation is exact when the sequence is exactly following a \(m\)-th order recursion. See an example of application on the Leibniz formula below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="424" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/shanks_Uc.png" class="wp-image-2320" height="330" />Higher-order acceleration through the Shanks transformation for the Leibniz formula. Acceleration is possible only up to machine precision.</figure></div>



<h2>Extension to vectors</h2>



<p class="justify-text">We now consider accelerating vector sequences \(x_k \in \mathbb{R}^d\). There are multiple approaches to extend acceleration from real numbers to vectors, as presented in [4, 5]. The simplest way is to apply high-order extrapolation to all coordinates separately (which is often called the vector \(\varepsilon\)-algorithm [10]); this depends however a lot on the chosen basis, requires too many linear systems to solve, and performs worse (see examples below for gradient descent). We now present a vector extension which exists under many names: the Eddy-Mesina method [6,7], reduced rank extrapolation [4, 11, 12], or Anderson acceleration [8]. </p>



<p class="justify-text">We want to model the sequence \(x_k \in \mathbb{R}^d\) as $$x_{k+1} = A x_{k} + b,$$ where \(A \in \mathbb{R}^{d \times d}\) and \(b \in \mathbb{R}^d\). By a simple variable / equation counting arguments, there are \(d^2+d\) parameters, and we thus need \(d+1\) equations in \(\mathbb{R}^d\), and thus \(d+2\) consecutive iterates, to estimate \(A\) and \(b\). </p>



<p class="justify-text">In order to use only \(m+2\) iterates, with \(m \) much less than \(d\), we will focus directly on the extrapolation equation $$x_{\rm acc} = c_0 x_k + c_1 x_{k+1}+  \cdots +c_m x_{k+m}, $$ with the constraint that \(c_0+c_1+\cdots+c_m =1\). Therefore, we will not try to explicitly fit the model parameters \(A\) and \(b\).</p>



<p class="justify-text">A sufficient condition for good extrapolation weights is that the extrapolated version is close for two consecutive \(k\)’s, that is $$c_0 x_k + c_1 x_{k+1}+  \cdots +c_m x_{k+m} \approx c_0 x_{k+1} + c_1 x_{k+2}+  \cdots +c_m x_{k+m+1},$$ which can be rewritten as $$c_0 (x_{k}-x_{k+1}) + c_1 ( x_{k+1} -x_{k+2}) + \cdots + c_m (x_{k+m} – x_{k+m+1}) \approx 0.$$ A natural criterion is thus to minimize the \(\ell_2\)-norm $$ \big\| c_0 \Delta x_{k} + c_1  \Delta x_{k+1} + \cdots + c_m \Delta x_{k+m} \big\|_2 \mbox{ such that } c_0+c_1+\cdots+c_m = 1,$$ where \(\Delta x_{i} = x_{i} -x_{i+1}\). Denoting \(U \in \mathbb{R}^{d \times (m+1)}\) the matrix with columns \(\Delta x_{k}, \dots,  \Delta x_{k+m}\), we need to minimize \(\| U c \|_2\) such that \(c^\top 1_{m+1} = 1\), whose solution is $$ c \propto ( U^\top U)^{-1} 1_{m+1}, \mbox{ that is, } c = \frac{1}{1_{m+1}^\top (U^\top U)^{-1} 1_{m+1}}  ( U^\top U)^{-1} 1_{m+1}.$$ Note that while the weights \(c_0,\dots,c_m\) sum to one, they may be negative, that is, the extrapolated sequence is not always a convex combination (hence the name extrapolation). Moreover, note that unless \(m\) is large enough, the optimal \(U c\) is in general not equal to zero (it is when modelling real sequences, see below).</p>



<p class="justify-text">For \(m=1\), the solution is particularly simple, as we need to minimize $$ \|\Delta x_{k+1}  – c_0 ( \Delta x_{k+1} – \Delta x_k ) \|^2,$$ leading to $$c_0 = \frac{\Delta x_{k+1}^\top ( \Delta x_{k+1} – \Delta x_k )}{ \|  \Delta x_{k+1} – \Delta x_k \|^2} \mbox{ and } c_1 = \frac{\Delta x_{k}^\top ( \Delta x_{k} – \Delta x_{k+1} )}{ \|  \Delta x_{k+1} – \Delta x_k \|^2}.$$ The acute reader can check that when \(d=1\), we recover Aitken’s formula. See an example in two dimensions below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="380" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/anderson_2d.gif" class="wp-image-2276" height="319" />Anderson acceleration in two dimensions. The sequence is following an auto-regressive process with a symmetric \(A\) with eigenvalues in \((-1,1)\). Anderson acceleration cancels the oscillation due to the eigenvalue with largest magnitude.</figure></div>



<p class="justify-text"><strong>Recovering one-dimensional sequence acceleration.</strong> Given a real sequence \(y_k \in \mathbb{R}\), we can define the vector \(x_k\) in \(\mathbb{R}^m\) as $$x_k = \left( \begin{array}{c} y_k \\  y_{k+1} \\ \vdots \\ y_{k+m-1} \end{array} \right).$$ One can then check that the matrix \(U\) defined for this vector sequence is exactly the same as the matrix \(U\) defined earlier for the real valued sequence. The optimal \(\| Uc \|\) is then equal to zero (which is not the case in general).</p>



<p class="justify-text"><strong>When is it exact?</strong> The derivation I followed is only intuitive, and as for the other acceleration mechanisms, a natural question is: when is it exact? We will consider linear recursions.</p>



<p class="justify-text"><strong>Analysis for linear recursions.</strong> Assuming that \(x_{k+1} = A x_{k} + b\) is exact for all \(k \geq 0\), then \(x_k – x_\ast = A^{k} ( x_0 – x_\ast)\), and thus, following [13], $$\sum_{i=0}^m c_i (x_{k+i}-x_{k+i+1}) = \sum_{i=0}^m c_i A^{i} A^{k}(I – A )(x_0 -x_\ast) = P_m(A)(I – A) A^{k}(x_0 -x_\ast) ,$$ for \(P_m(\sigma)  =  \sum_{i=0}^m c_i \sigma^{i}\) a \(m\)-th order polynomial such that \(P_m(1) = 1\). We can write \(Uc\)  as $$ Uc = P_m(A) ( x_k – x_{k+1}) = ( I – A)  P_m(A)  (x_k – x_\ast) .$$ The error between the true limit and the extrapolation is equal to: $$  x_\ast – \sum_{i=0}^m c_i x_{k+i} = \sum_{i=0}^m c_i ( x_\ast – x_{k+i}  ) = P_m(A) (   x_\ast -x_{k}) = (I-A)^{-1} Uc.$$ Thus, we have $$ \Big\| x_\ast – \sum_{i=0}^m c_i x_{k+i} \Big\|_2 \leq \| U c \|_2 \times  \|(I – A)^{-1}\|_{\rm op} \leq \|(I – A)^{-1}\|_{\rm op}  \|I – A\|_{\rm op} \|P_m(A) ( x_k – x_\ast)\|.  $$</p>



<p class="justify-text">The method will be exact when one can find a degree \(m\) polynomial so that \(P_m(A) (x_{k} – x_\ast) = 0 \), and a sufficient condition is that \(P_m(A)=0\), which is only possible if \(A\) had only \(m\) distinct eigenvalues. This is exactly minimal polynomial extrapolation [9]. Another situation is when \(m = d\) (like for the special case of real sequences above). </p>



<p class="justify-text">Otherwise, the method will be inexact, but the method can find a good polynomial \(P_m\), and the error is less than the infimum of \( \|P_m(A) ( x_k – x_\ast)\|\) over all polynomial of degree \(m\) such that \(P_m(1)=1\). Assuming that the matrix \(A\) is symmetric and with all eigenvalues between \(-\rho\) and \(\rho\) (which will be the case for the gradient method below), then the error is less than the infimum of \(\sup_{\sigma \in [-\rho,\rho]} |P_m(\sigma)|\),  which is attained for the Chebyshev polynomial (see a <a href="https://francisbach.com/chebyshev-polynomials/">previous post</a>). The improvement in terms of convergence is similar to Chebyshev acceleration, but (a) without the need to know \(\rho\) in advance (the method is totally adaptive), and (b) with a provable robustness when the iterates deviate from following an autoregressive process (see [13] for details).</p>



<p class="justify-text"><strong>Going beyond linear recursions. </strong>As presented, Anderson acceleration does not lead to stable acceleration (see the experiment below for gradient descent). The main reason is that when iterates deviate from an autoregressive process, or when the recursion is naturally noisy, the estimation of the parameters \(c\) is unstable, in particular because the matrix \(U^\top U\) which has to be inverted is severely ill-conditioned [14]. In a joint work with Damien Scieur and Alexandre d’Aspremont, we considered regularizing  the estimation of \(c\) by penalizing its \(\ell_2\)-norm. We thus minimize  \( \| U c \|_2^2 + \lambda \| c\|_2^2\) such that \(c^\top 1_{m+1} = 1\), whose solution is $$ c \propto ( U^\top U + \lambda I)^{-1} 1_{m+1}, \mbox{ that is, } c = \frac{1}{1_{m+1}^\top (U^\top U + \lambda I)^{-1} 1_{m+1}}  ( U^\top U +  \lambda I)^{-1} 1_{m+1}.$$ This simple modification leads to theoretical guarantees for non-linear recursions, and I will refer to it as regularized non-linear acceleration (RNA, see [13] for details; the “non-linearity” comes from the non-linear dependence of \(c\) on the iterates).</p>



<h2>Application to gradient descent</h2>



<p class="justify-text">We can apply RNA to the recursion, $$x_{k+1}  = x_k – \gamma \nabla f(x_k),$$ where \(f: \mathbb{R}^d \to \mathbb{R}^d\) is a differentiable function, and \(\gamma\) a step-size. In the plot below, we consider accelerating gradient descent with \(m\)-th order RNA, with \(m=8\). We compare this acceleration with applying RNA to each variable separately (“RNA-univ.”), and to the unregularized version (“Anderson”). We can see the benefits of our simple extrapolation steps, and in particular the instability of unregularized acceleration.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="419" alt="" src="https://francisbach.com/wp-content/uploads/2020/02/anderson_grad_nonest.png" class="wp-image-2331" height="326" />Gradient descent on a regularized <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> problem, with 1000 observations in dimension 100. We compare regular gradient descent, to plain Anderson acceleration (with no regularization), RNA [13] applied to each variable separately, and RNA. All accelerations are with order \(m =8\).</figure></div>



<p class="justify-text">In order to obtain stronger benefits from non-linear acceleration, several extensions are considered in [13]; in particular line search to find the good regularization parameter \(\lambda\) is quite useful. Another interesting extension is the <em>online</em> version of the algorithm [16, section 2.5], where the extrapolated sequence is used directly within the acceleration procedure, and not as a separate sequence with no interaction with the original gradient method: this corresponds to using RNA to accelerate iterates coming from RNA!</p>



<p class="justify-text">Moreover, while the simplest theoretical guarantees come for deterministic convex optimization problems and gradient descent, RNA can be extended to stochastic algorithms [15] and to non-convex optimization problems such as the ones encountered in deep learning [16].</p>



<h2>Conclusion</h2>



<p class="justify-text">In this post, I described acceleration techniques that combine iterates of an existing algorithm, without the need to understand finely the inner structure of the original algorithm. They come at little extra-cost and can provide strong benefits.</p>



<p class="justify-text">This month’s post was dedicated to algorithms which converge linearly, that is, the iterates are asymptotically equivalent to sums of exponentials. Next month, I will consider situations where the convergence is sublinear, where <a href="https://en.wikipedia.org/wiki/Richardson_extrapolation">Richardson extrapolation</a> excels.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. This post is based on joint work with Damien Scieur and Alexandre d’Aspremont, and in particular on their presentation slides. I would also like to thank them for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Alexander Aitken, On Bernoulli’s numerical solution of algebraic equations, <em>Proceedings of the Royal Society of Edinburgh</em>, 46:289–305, 1926.<br />[2] Peter Wynn. On a device for computing the \(e_m(S_n)\) transformation. <em>Mathematical Tables and Other Aids to Computation</em>, 91-96, 1956.<br />[3] Claude Brezinski. <em>Accélération de la convergence en analyse numérique</em>. Lecture notes in mathematics, Springer (584), 1977.<br />[4] David A. Smith, William F. Ford, Avram Sidi. Extrapolation methods for vector sequences. <em>SIAM review</em>, 29(2):199-233, 1987<br />[5] Allan J. Macleod. Acceleration of vector sequences by multi‐dimensional \(\Delta^2\) methods. <em>Communications in Applied Numerical Methods</em>, 2(4):385-392, 1986.<br />[6] Marián Mešina. Convergence acceleration for the iterative solution of the equations X= AX+ f. <em>Computer Methods in Applied Mechanics and Engineering</em>, <em>10</em>(2), 1977.<br />[7] Robert P. Eddy. Extrapolating to the limit of a vector sequence. <em>Information linkage between applied mathematics and industry</em>, 387-396, 1979.<br />[8] Homer F. Walker, Peng Ni. Anderson acceleration for fixed-point iterations. <em>SIAM Journal on Numerical Analysis</em>, 49(4):1715-1735, 2011.<br />[9] Sidi, Avram, William F. Ford, and David A. Smith. Acceleration of convergence of vector sequences. <em>SIAM Journal on Numerical Analysis</em> 23(1):178-196, 1986.<br />[10] Peter Wynn. Acceleration techniques for iterated vector and matrix problems. <em>Mathematics of Computation</em>, 16(79), 301-322,  1962.<br />[11] Stan Cabay,  L. W. Jackson. A polynomial extrapolation method for finding limits and antilimits of vector sequences. <em>SIAM Journal on Numerical Analysis</em>, 13(5), 734-752, 1976.<br />[12] Stig Skelboe. Computation of the periodic steady-state response of nonlinear networks by extrapolation methods. <em>IEEE Transactions on Circuits and Systems</em>, 27(3), 161-175, 1980.<br />[13] Damien Scieur, Alexandre d’Aspremont, Francis Bach. Regularized Nonlinear Acceleration. <em>Mathematical Programming</em>, 2018.<br />[14] Evgenij E. Tyrtyshnikov. How bad are Hankel matrices? <em>Numerische Mathematik</em>, 67(2):261-269, 1994.<br />[15] Damien Scieur, Alexandre d’Aspremont, Francis Bach. Nonlinear Acceleration of Stochastic Algorithms. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2017.<br />[16] Damien Scieur, Edouard Oyallon, Alexandre d’Aspremont, Francis Bach. Nonlinear Acceleration of Deep Neural Networks. Technical report, arXiv-1805.09639, 2018.</p>



<h2>Asymptotic analysis for Aitken’s \(\Delta^2\) process</h2>



<p class="justify-text">In one dimension, we do not need the auto-regressive model to be exact, and an asymptotic analysis is possible. The asymptotic condition corresponds to \(\displaystyle \frac{x_{k+1}-x_\ast}{x_k – x_\ast}\) converging to a constant \(a \in [-1,1)\). More precisely if $$\frac{x_{k+1}-x_\ast}{x_k – x_\ast} = a + \varepsilon_{k+1},$$ with \(\varepsilon_k\) tending to zero, then we can estimate \(a\) through the <a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">Aitkens \(\Delta^2\) method</a> [1] as, $$ a_{k+1} = \frac{x_{k+1}-x_k}{x_{k}-x_{k-1}} = \frac{(x_{k+1}-x_\ast) – (x_k-x_\ast) }{(x_{k} – x_\ast) -( x_{k-1}-x_\ast) } = \frac{ a + \varepsilon_{k+1} – 1}{1 – 1/(a+\varepsilon_{k})} = a + \varepsilon_{k+1} + o( \varepsilon_{k+1}).$$ A closer Taylor expansion leads to $$ a + \varepsilon_{k} + \frac{1}{a-1}( \varepsilon_{k+1}- \varepsilon_{k}) + O(\varepsilon_{k}^2).$$ We can then provide a better estimate of \(x_\ast\) as $$ \frac{x_{k+1} – a_{k+1}x_k}{1- a_{k+1}} = x_\ast + \frac{x_{k+1} -x_\ast – a_{k+1}( x_k-x_\ast)}{1- a_{k+1}} = x_\ast + \frac{(a+\varepsilon_{k+1}-a_{k+1}) ( x_k – x_\ast)}{1-a_{k+1}},$$ whose difference with \(x_\ast\) is equivalent to $$ \frac{(a+\varepsilon_k-a_{k+1}) ( x_k – x_\ast)}{1-a }  \sim \frac{\varepsilon_{k+1}- \varepsilon_{k}}{(1-a)^2} ( x_k – x_\ast).$$ We have thus provided an acceleration of order \(\displaystyle \frac{\varepsilon_{k+1}- \varepsilon_{k}}{(1-a)^2} \).</p>



<h2>High-order Shanks transformation</h2>



<p>In order to relate our formulas to classical expressions, we first rewrite the recursion for \(m=1\) and then \(m=2\), and then to general \(m\).</p>



<p class="justify-text"><strong>First-order recursion (Aitken’s \(\Delta^2\)).</strong> We write the autorecursive recursion as $$ (x_{k+1} – x_\ast) = a ( x_{k} – x_\ast) \Leftrightarrow c_0(x_k – x_\ast) + c_1 (x_{k+1}-x_\ast) = 0 ,$$ with the constraint \(c_0 + c_1 = 1\), that is, \(c_0 = \frac{-a}{1-a}\) and \(c_1 = \frac{1}{1-a}\). We can then write \(x_\ast = c_0 x_k + c_1 x_{k+1}\), and we have the linear system in \((c_0,c_1,x_\ast)\): $$  \left( \begin{array}{ccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; 0 \\ 1 &amp; 1 &amp; 0 \\ x_k &amp; x_{k+1} &amp; – 1  \end{array}\right)  \left( \begin{array}{c} c_0 \\ c_1 \\ x_\ast  \end{array}\right) =  \left( \begin{array}{c} 0 \\ 1 \\ 0 \end{array}\right), $$ which can be solved using Cramer’s formula $$x_{\rm acc} = x_\ast = \frac{\left| \begin{array}{cc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2}  \\ x_{k} &amp; x_{k+1} \end{array}\right|}{\left| \begin{array}{cc}  x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2}  \\ 1 &amp; 1 \end{array}\right|},$$  which leads to the same formula for \(x^{(1)}_k\).</p>



<p class="justify-text"><strong>Second-order recursion.</strong> Here, we only consider the case \(m=2\) for simplicity. We consider the model, $$c_0 (x_k – x_\ast) + c_1 (x_{k+1} – x_\ast)+ c_{2} (x_{k+2} – x_\ast) = 0, $$ with the normalization \(c_0 + c_1 + c_2 = 1\). We can then extract \(x_\ast\) as $$ x_\ast = c_0 x_k + c_1 x_{k+1} +  c_2 x_{k+2}.$$ In order to provide the extra \(2\) equations that are necessary to estimate the three parameters, we take first order differences and get $$c_0 (x_k -x_{k+1}) + c_1 (x_{k+1}-x_{k+2}) +  c_2 ( x_{k+2} – x_{k+3} ) =0,$$ for \(k\) and \(k+1\). This leads to the linear system in \((c_0,c_1, c_2, x_\ast)\): $$  \left( \begin{array}{cccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; x_{k+2} – x_{k+3} &amp; 0 \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp;  x_{k+3} – x_{k+4} &amp; 0 \\ 1 &amp; 1 &amp; 1 &amp; 0  \\ x_{k} &amp; x_{k+1} &amp; x_{k+2} &amp;  – 1  \end{array}\right)  \left( \begin{array}{c} c_0 \\ c_1 \\ c_2 \\ x_\ast  \end{array}\right) =  \left( \begin{array}{c}  0  \\ 0 \\ 1 \\ 0 \end{array}\right), $$ which can be solved using <a href="https://en.wikipedia.org/wiki/Cramer%27s_rule">Cramer’s rule</a> (and classical manipulations of determinants) as $$x_k^{(2)} = \frac{\left| \begin{array}{ccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; x_{k+2} – x_{k+3}   \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp;  x_{k+3} – x_{k+4}   \\ x_{k} &amp; x_{k+1} &amp; x_{k+2}    \end{array} \right|}{\left| \begin{array}{ccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; x_{k+2} – x_{k+3}     \\ x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp;  x_{k+3} – x_{k+4}   \\ 1 &amp; 1 &amp; 1 &amp;  \end{array} \right|}.$$  </p>



<p class="justify-text">The formula extends to order \(m\) (see below) and is often called the Shanks transformation; it is cumbersome and not easy to use. However, the coefficients can be computed recursively (which is to be expected for a Hankel matrix, but rather tricky to derive), through Wynn’s \(\varepsilon\)-algorithm.  See [3] for a survey on acceleration and extrapolation.</p>



<p class="justify-text"><strong>Higher-order recursion.</strong> We consider the model, for \(m \geq 1\), $$c_0 (x_k – x_\ast) + c_1 (x_{k+1} – x_\ast) + \cdots + c_{m} (x_{k+m} – x_\ast) = 0, $$ with the normalization \(c_0 + c_1 + \cdots + c_m = 1\). We can then extract \(x_\ast\) as $$ x_\ast = c_0 x_k + c_1 x_{k+1} + \cdots + c_m x_{k+m}.$$ In order to provide the extra \(m\) equations, we take first order differences and get $$c_0 (x_k -x_{k+1}) + c_1 (x_{k+1}-x_{k+2}) + \cdots + c_m ( x_{k+m} – x_{k+m+1} ) =0,$$ for \(k, k+1,\dots, k+m-1\). This leads to the linear system in \((c_0,c_1,\cdots, c_m, x_\ast)\): $$  \left( \begin{array}{ccccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; \cdots &amp; x_{k+m} – x_{k+m+1} &amp; 0 \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp; \cdots &amp; x_{k+m+1} – x_{k+m+2} &amp; 0 \\ \vdots &amp; \vdots &amp;  &amp; \vdots  &amp; \vdots \\ x_{k+m-1}-x_{k+m} &amp; x_{k+m}-x_{k+m+1} &amp; \cdots &amp; x_{k+2m-1} – x_{k+2m} &amp; 0 \\ 1 &amp; 1 &amp; \dots &amp; 1 &amp; 0  \\ x_{k+m} &amp; x_{k+m+1} &amp; \cdots &amp; x_{k+2m} &amp;  – 1  \end{array}\right)  \left( \begin{array}{c} c_0 \\ c_1 \\ \vdots \\ c_m \\ x_\ast  \end{array}\right) =  \left( \begin{array}{c} 0 \\ 0 \\ \vdots \\ 0 \\ 1 \\ 0 \end{array}\right), $$ which can be solved using Cramer’s formula $$x_\ast = \frac{\left|\begin{array}{cccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; \cdots &amp; x_{k+m} – x_{k+m+1} \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp; \cdots &amp; x_{k+m+1} – x_{k+m+2}   \\ \vdots &amp; \vdots &amp;  &amp; \vdots  \\ x_{k+m-1}-x_{k+m} &amp; x_{k+m}-x_{k+m+1} &amp; \cdots &amp; x_{k+2m-1} – x_{k+2m} \\ x_{k+m} &amp; x_{k+m+1} &amp; \cdots &amp; x_{k+2m}  \end{array} \right|}{\left|\begin{array}{cccc} x_{k}-x_{k+1} &amp; x_{k+1}-x_{k+2} &amp; \cdots &amp; x_{k+m} – x_{k+m+1} \\  x_{k+1}-x_{k+2} &amp; x_{k+2}-x_{k+3} &amp; \cdots &amp; x_{k+m+1} – x_{k+m+2}   \\ \vdots &amp; \vdots &amp;  &amp; \vdots  \\ x_{k+m-1}-x_{k+m} &amp; x_{k+m}-x_{k+m+1} &amp; \cdots &amp; x_{k+2m-1} – x_{k+2m} \\ 1 &amp; 1 &amp; \cdots &amp; 1 \end{array}  \right|}.$$  </p>



<p class="justify-text">Like for \(m=1\), Wynn’s \(\varepsilon\)-algorithm can be used to compute the iterates recursively.</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/acceleration-without-pain/"><span class="datestr">at February 04, 2020 07:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1234">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">A Masters project</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In a <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">previous post</a> I reported on the beautiful <a href="https://arxiv.org/abs/1904.05870">recent result</a> by Natarajan and Wright showing the astounding power of multi-prover interactive proofs with quantum provers sharing entanglement: in letters, <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEEXP%7D+%5Csubseteq+%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{NEEXP} \subseteq \text{MIP}^\star}" class="latex" title="{\text{NEEXP} \subseteq \text{MIP}^\star}" />. In this post I want to report on follow-up work with Ji, Natarajan, Wright, and Yuen, that we just posted to <a href="https://arxiv.org/abs/2001.04383">arXiv</a>. This time however I will tell the story from a personal point of view, with all the caveats that this implies: the “hard science” will be limited (but there could be a hint as to how “science”, to use a big word, “progresses”, to use an ill-defined one), the story is far too long, and it might be mostly of interest to me only. It’s a one-sided story, but that has to be. (In particular below I may at times attribute credit in the form “X had this idea”. This is my recollection only, and it is likely to be inaccurate. Certainly I am ignoring a lot of important threads.) I wrote this because I enjoyed recollecting some of the best moments in the story just as much as some the hardest; it is fun to look back and find meanings in ideas that initially appeared disconnected. Think of it as an example of how different lines of work can come together in unexpected ways; a case for open-ended research. It’s also an antidote against despair that I am preparing for myself: whenever I feel I’ve been stuck on a project for far too long, I’ll come back to this post and ask myself if it’s been 14 years yet — if not, then press on.</p>
<p>It likely comes as a surprise to me only that I am no longer fresh out of the cradle. My academic life started in earnest some 14 years ago, when in the Spring of 2006 I completed my Masters thesis in Computer Science under the supervision of Julia Kempe, at Orsay in France. I had met Julia the previous term: her class on quantum computing was, by far, the best-taught and most exciting course in the Masters program I was attending, and she had gotten me instantly hooked. Julia agreed to supervise my thesis, and suggested that I look into some interesting recent result by Stephanie Wehner that linked the study of entanglement and nonlocality in quantum mechanics to complexity-theoretic questions about interactive proof systems (specifically, this was Stephanie’s <a href="https://arxiv.org/abs/quant-ph/0508201">paper</a> showing that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar+%5Csubseteq+%5Ctext%7BQIP%7D%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{XOR-MIP}^\star \subseteq \text{QIP}(2)}" class="latex" title="{\text{XOR-MIP}^\star \subseteq \text{QIP}(2)}" />).</p>
<p>At the time the topic was very new. It had been initiated the previous year with a beautiful <a href="https://arxiv.org/abs/quant-ph/0404076">paper</a> by Cleve et al. (that I have recommended to many a student since!). It was a perfect fit for me: the mathematical aspects of complexity theory and quantum computing connected to my undergraduate background, while the relative concreteness of quantum mechanics (it is a physical theory after all) spoke to my desire for real-world connection (not “impact” or even “application” — just “connection”). Once I got myself up to speed in the area (which consisted of three papers: the two I already mentioned, together with a <a href="https://arxiv.org/abs/cs/0102013">paper</a> by Kobayashi and Matsumoto where they studied interactive proofs with quantum messages), Julia suggested looking into the the “entangled-prover” class <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> introduced in the aforementioned paper by Cleve et al. Nothing was known about this class! Nothing besides the trivial inclusion of single-prover interactive proofs, IP, and the containment in…ALL, the trivial class that contains all languages.<br />
Yet the characterization MIP=NEXP of its classical counterpart by Babai et al. in the 1990s had led to one of the most productive lines of work in complexity of the past few decades, through the PCP theorem and its use from hardness of approximation to efficient cryptographic schemes. Surely, studying <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> had to be a productive direction? In spite of its well-established connection to classical complexity theory, via the formalism of interactive proofs, this was a real gamble. The study of entanglement from the complexity-theoretic perspective was entirely new, and bound to be fraught with difficulty; very few results were available and the existing lines of works, from the foundations of nonlocality to more recent endeavors in device-independent cryptography, provided little other starting point than strong evidence that even the simplest examples came with many unanswered questions. But my mentor was fearless, and far from a novice in terms of defraying new areas, having done pioneering work in areas ranging from quantum random walks to Hamiltonian complexity through adiabatic computation. Surely this would lead to something?</p>
<p>It certainly did. More sleepless nights than papers, clearly, but then the opposite would only indicate dullness. Julia’s question led to far more unexpected consequences than I, or I believe she, could have imagined at the time. I am writing this post to celebrate, in a personal way, the latest step in 15 years of research by dozens of researchers: today my co-authors and I uploaded to the quant-ph arXiv what we consider a complete characterization of the power of entangled-prover interactive proof systems by proving the equality <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star = \text{RE}}" class="latex" title="{\text{MIP}^\star = \text{RE}}" />, the class of all recursively enumerable languages (a complete problem for RE is the halting problem). Without goign too much into the result itself (if you’re interested, we have a long introduction waiting for you), and since this is a personal blog, I will continue on with some personal thoughts about the path that got us there.</p>
<p>When Julia &amp; I started working on the question, our main source of inspiration were the results by Cleve et al. showing that the nonlocal correlations of entanglement had interesting consequences when seen through the lens of interactive proof systems in complexity theory. Since the EPR paper a lot of work in understanding entanglement had already been accomplished in the Physics community, most notably by Mermin, Peres, Bell, and more recently the works in device-indepent quantum cryptography by Acin, Pironio, Scarani and many others stimulated by Ekert’s proposal for quantum key distribution and Mayers and Yao’s idea for “device-independent cryptography”. By then we certainly knew that “spooky action-at-a-distance” did not entail any faster-than-light communication, and indeed was not really “action-at-a-distance” in the first place but merely “correlation-at-a-distance”. What Cleve et al. recognized is that these “spooky correlations-at-a-distance” were sufficiently special so as to not only give numerically different values in “Bell inequalities”, the tool invented by Bell to evidence nonlocality in quantum mechanics, but also have some potentially profound consequences in complexity theory. In particular, examples such as the “Magic Square game” demonstrated that enough correlation could be gained from entanglement so as to defeat basic proof systems whose soundness relied only on the absence of communication between the provers, an assumption that until then had been wrongly equated with the assumption that any computation performed by the provers could be modeled entirely locally. I think that the fallacy of this implicit assumption came as a surprise to complexity theorists, who may still not have entirely internalized it. Yet the perfect quantum strategy for the Magic Square game provides a very concrete “counter-example” to the soundness of the “clause-vs-variable” game for 3SAT. Indeed this game, a reformulation by Aravind and Cleve-Mermin of a Bell Inequality discovered by Mermin and Peres in 1990, can be easily re-framed as a 3SAT system of equations that is <em>not</em> satisfiable and yet is such that the associated two-player clause-vs-variable game has a <em>perfect</em> quantum strategy. It is this observation, made in the paper by Cleve et al., that gave the first strong hint that the use of entanglement in interactive proof systems could make many classical results in the area go awry.</p>
<p>By importing the study of non-locality into complexity theory Cleve et al. immediately brought it into the realm of asymptotic analysis. Complexity theorists don’t study fixed objects, they study families of objects that tend to have a uniform underlying structure and whose interesting properties manifest themselves “in the limit”. As a result of this new perspective focus shifted from the study of single games or correlations to infinite families thereof. Some of the early successes of this translation include the “unbounded violations” that arose from translating asymptotic separations in communication complexity to the language of Bell inequalities and correlations (e.g. this <a href="https://arxiv.org/abs/1012.5043">paper</a>). These early successes attracted the attention of some physicists working in foundations as well as some mathematical physicists, leading to a productive exploration that combined tools from quantum information, functional analysis and complexity theory.</p>
<p>The initial observations made by Cleve et al. had pointed to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> as a possibly interesting complexity class to study. Rather amazingly, nothing was known about it! They had shown that under strong restrictions on the verifier’s predicate (it should be an XOR of two answer bits), a collapse took place: by the work of Hastad, XOR-MIP equals NEXP, but <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{XOR-MIP}^\star}" class="latex" title="{\text{XOR-MIP}^\star}" /> is included in EXP. This seemed very fortuitous (the inclusion is proved via a connection with semidefinite programming that seems tied to the structure of XOR-MIP protocols): could entanglement induce a collapse of the entire, unrestricted class? We thought (at this point mostly Julia thought, because I had no clue) that this ought not to be the case, and so we set ourselves to show that the equality <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star=\text{NEXP}}" class="latex" title="{\text{MIP}^\star=\text{NEXP}}" />, that would directly parallel Babai et al.’s characterization MIP=NEXP, holds. We tried to show this by introducing techniques to “immunize” games against entanglement: modify an interactive proof system so that its structure makes it “resistant” to the kind of “nonlocal powers” that can be used to defeat the clause-vs-variable game (witness the Magic Square). This was partially successful, and led to one of the papers I am most proud of — I am proud of it because I think it introduced elementary techniques (such as the use of the Cauchy-Schwarz inequality — inside joke — more seriously, basic things such as “prover-switching”, “commutation tests”, etc.) that are now routine manipulations in the area. The paper was a hard sell! It’s good to remember the first rejections we received. They were not unjustified: the main point of criticism was that we were only able to establish a hardness result for exponentially small completeness-soundness gap. A result for such a small gap in the classical setting follows directly from a very elementary analysis based on the Cook-Levin theorem. So then why did we have to write so many pages (and so many applications of Cauchy-Schwarz!) to arrive at basically the same result (with a <img src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^\star}" class="latex" title="{^\star}" />)?</p>
<p>Eventually we got lucky and the paper was accepted to a conference. But the real problem, of establishing any non-trivial lower bound on the class <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> with constant (or, in the absence of any parallel repetition theorem, inverse-polynomial) completeness-soundness gap, remained. By that time I had transitioned from a Masters student in France to a graduate student in Berkeley, and the problem (pre-)occupied me during some of the most difficult years of my Ph.D. I fully remember spending my first year entirely thinking about this (oh and sure, that systems class I had to pass to satisfy the Berkeley requirements), and then my second year — yet, getting nowhere. (I checked the arXiv to make sure I’m not making this up: two full years, no posts.) I am forever grateful to my fellow student Anindya De for having taken me out of the cycle of torture by knocking on my door with one of the most interesting questions I have studied, that led me into quantum cryptography and quickly resulted in an enjoyable <a href="https://arxiv.org/abs/0911.4680">paper</a>. It was good to feel productive again! (Though the paper had fun reactions as well: after putting it on the arXiv we quickly heard from experts in the area that we had solved an irrelevant problem, and that we better learn about information theory — which we did, eventually leading to another <a href="https://arxiv.org/abs/0912.5514">paper</a>, etc.) The project had distracted me and I set interactive proofs aside; clearly, I was stuck.</p>
<p>About a year later I visited IQC in Waterloo. I don’t remember in what context the visit took place. What I do remember is a meeting in the office of Tsuyoshi Ito, at the time a postdoctoral scholar at IQC. Tsuyoshi asked me to explain our result with Julia. He then asked a very pointed question: the bedrock for the classical analysis of interactive proof systems is the “linearity test” of Blum-Luby-Rubinfeld (BLR). Is there any sense in which we could devise a quantum version of that test?</p>
<p>What a question! This was great. At first it seemed fruitless: in what sense could one argue that quantum provers apply a “linear function”? Sure, quantum mechanics is linear, but that is besides the point. The linearity is a property of the prover’s answers as a function of their question. So what to make of the quantum state, the inherent randomness, etc.?</p>
<p>It took us a few months to figure it out. Once we got there however, the answer was relatively simple — the prover should be making a question-independent measurement that returns a linear function that it applies to its question in order to obtain the answer returned to the verifier — and it opened the path to our subsequent <a href="https://arxiv.org/abs/1207.0550">paper</a> showing that the inclusion of NEXP in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> indeed holds. Tsuyoshi’s question about linearity testing had allowed us to make the connection with PCP techniques; from there to MIP=NEXP there was only one step to make, which is to analyze multi-linearity testing. That step was suggested by my Ph.D. advisor, Umesh Vazirani, who was well aware of the many pathways towards the classical PCP theorem (indeed a lot of the activity that led to the proof of the theorem took place in Berkeley, with many of Umesh’s current or former students making substantial contributions). It took a lot of technical work, yet conceptually a single question from my co-author had sufficed to take me out of a 3-year slumber.</p>
<p>This was in 2012, and I thought we were done. For some reason the converse inclusion, of <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> in NEXP, seemed to resist our efforts, but surely it couldn’t resist much longer. Navascues et al. had introduced a hierarchy of semidefinite programs that seemed to give the right answer (technically they could only show convergence to a relaxation, the commuting value, but that seemed like a technicality; in particular, the values coincide when restricted to finite-dimensional strategies, which is all we computer scientists cared about). There were no convergence bounds on the hierarchy, yet at the same time commutative SDP hierarchies were being used to obtain very strong results in combinatorial optimization, and it seemed like it would only be a matter of time before someone came up with an analysis of the quantum case. (I had been trying to solve a related “dimension reduction problem” with Oded Regev for years, and we were making no progress; yet it seemed <em>someone</em> ought to!)</p>
<p>In Spring 2014 during an open questions session at a <a href="https://simons.berkeley.edu/workshops/qhc2014-1">workshop</a> at the Simons Institute in Berkeley Dorit Aharonov suggested that I ask the question of the possible inclusion of QMA-EXP, the exponential-sized-proofs analogue of QMA, in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />. A stronger result than the inclusion of NEXP (under assumptions), wouldn’t it be a more natural “fully quantum” analogue of MIP=NEXP? Dorit’s suggestion was motivated by research on the “quantum PCP theorem”, that aims to establish similar hardness results in the realm of the local Hamiltonian problem; see e.g. <a href="https://mycqstate.wordpress.com/2014/10/31/quantum-pcp-conjectures/">this post</a> for the connection. I had no idea how to approach the question — I also didn’t really believe the answer could be positive — but what can you do, if Dorit asks you something… So I reluctantly went to the board and asked the question. Joe Fitzsimons was in the audience, and he immediately picked it up! Joe had the fantastic ideas of using quantum error-correction, or more specifically secret-sharing, to distribute a quantum proof among the provers. His enthusiasm overcame my skepticism, and we eventually <a href="https://arxiv.org/abs/1409.0260">showed</a> the desired inclusion. Maybe <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> <em>was</em> bigger than <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{NEXP}}" class="latex" title="{\text{NEXP}}" /> after all.</p>
<p>Our result, however, had a similar deficiency as the one with Julia, in that the completeness-soundness gap was exponentially small. Obtaining a result with a constant gap took 3 years of couple more years of work and the fantastic energy and insights of a Ph.D. student at MIT, Anand Natarajan. Anand is the first person I know of to have had the courage to dive in to the most technical aspects of the analysis of the aforementioned results, while also bringing in the insights of a “true quantum information theorist” that were supported by Anand’s background in Physics and upbringing in the group of Aram Harrow at MIT. (In contrast I think of myself more as a “raw” mathematician; I don’t really understand quantum states other than as psd matrices…not that I understand math either of course; I suppose I’m some kind of a half-baked mish-mash.) Anand had many ideas but one of the most beautiful ones led to what he poetically called the “Pauli braiding test”, a “truly quantum” analogue of the BLR linearity test that amounts to doing <em>two</em> linearity tests in conjugate bases and piecing the results together into a robust test for <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit entanglement (I wrote about our work on this <a href="https://mycqstate.wordpress.com/2017/06/28/pauli-braiding/">here</a>).</p>
<p>At approximately the same time Zhengfeng Ji had another wonderful idea, that was in some sense orthogonal to our work. (My interpretation of) Zhengfeng’s idea is that one can see an interactive proof system as a computation (verifier-prover-verifier) and use Kitaev’s circuit-to-Hamiltonian construction to transform the entire computation into a “quantum CSP” (in the same sense that the local Hamiltonian problem is a quantum analogue of classical constraint satisfaction problems (CSP)) that could then itself be verified by a quantum multi-prover interactive proof system…with exponential gains in efficiency! Zhengfeng’s result implied an exponential improvement in complexity compared to the result by Julia and myself, showing inclusion of NEEXP, instead of NEXP, in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />. However, Zhengfeng’s technique suffered from the same exponentially small completeness-soundness gap as we had, so that the best lower bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> per se remained NEXP.</p>
<p>Both works led to follow-ups. With Natarajan we promoted the Pauli braiding test into a “<a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a>” that allowed us to show the inclusion of QMA-EXP into <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />, with constant gap, thereby finally answering the question posed by Aharonov 4 years after it was asked. (I should also say that by then all results on <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> started relying on a sequence of parallel repetition results shown by Bavarian, Yuen, and others; I am skipping this part.) In parallel, with Ji, Fitzsimons, and Yuen we showed that Ji’s compression technique could be “iterated” an arbitrary number of times. In fact, by going back to “first principles” and representing verifiers uniformly as Turing machines we realized that the compression technique could be used iteratively to (up to small caveats) give a new proof of the fact (first <a href="https://arxiv.org/abs/1703.08618">shown</a> by Slofstra using an embedding theorem for finitely presented group) that the zero-gap version of <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> contains the halting problem. In particular, the entangled value is uncomputable! This was not the first time that uncomputability crops in to a natural problem in quantum computing (e.g. the <a href="https://arxiv.org/abs/1502.04573">spectral gap paper</a>), yet it still surprises when it shows up. Uncomputable! How can anything be uncomputable!</p>
<p>As we were wrapping up our paper Henry Yuen realized that our “iterated compression of interactive proof systems” was likely optimal, in the following sense. Even a mild improvement of the technique, in the form of a slower closing of the completeness-soundness gap through compression, would yield a much stronger result: undecidability of the constant-gap class <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />. It was already known by work of Navascues et al., Fritz, and others, that such a result would have, if not surprising, certainly consequences that seemed like they would be taking us out of our depth. In particular, undecidability of any language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> would imply a negative resolution to a series of equivalent conjectures in functional analysis, from Tsirelson’s problem to Connes’ Embedding Conjecture through Kirchberg’s QWEP conjecture. While we liked our result, I don’t think that we believed it could resolve any conjecture(s) in functional analysis.</p>
<p>So we moved on. At least I moved on, I did some cryptography for a change. But Anand Natarajan and his co-author John Wright did not stop there. They had the last major insight in this story, which underlies their recent STOC best paper described in the previous <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">post</a>. Briefly, they were able to combine the two lines of work, by Natarajan &amp; myself on low-degree testing and by Ji et al. on compression, to obtain a compression that is specially tailored to the existing <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> protocol for NEXP and compresses that protocol without reducing its completeness-soundness gap. This then let them show Ji’s result that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> contains NEEXP, but this time with constant gap! The result received well-deserved attention. In particular, it is the first in this line of works to not suffer from any caveats (such as a closing gap, or randomized reductions, or some kind of “unfair” tweak on the model that one could attribute the gain in power to), and it implies an unconditional separation between MIP and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />.</p>
<p>As they were putting the last touches on their result, suddenly something happened, which is that a path towards a much bigger result opened up. What Natarajan &amp; Wright had achieved is a one-step gapless compression. In our iterated compression paper we had observed that iterated gapless compression would lead to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star=\text{RE}}" class="latex" title="{\text{MIP}^\star=\text{RE}}" />, implying negative answers to the aforementioned conjectures. So then?</p>
<p>I suppose it took some more work, but in some way all the ideas had been laid out in the previous 15 years of work in the complexity of quantum interactive proof systems; we just had to put it together. And so a decade after the characterization <a href="https://arxiv.org/abs/0907.4737">QIP = PSPACE</a> of single-prover quantum interactive proof systems, we have arrived at a characterization of quantum multiprover interactive proof systems, <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star = \text{RE}}" class="latex" title="{\text{MIP}^\star = \text{RE}}" />. With one author in common between the two papers: congratulations Zhengfeng!</p>
<p>Even though we just posted a paper, in a sense there is much more left to do. I am hopeful that our complexity-theoretic result will attract enough interest from the mathematicians’ community, and especially operator algebraists, for whom CEP is a central problem, that some of them will be willing to devote time to understanding the result. I also recognize that much effort is needed on our own side to make it accessible in the first place! I don’t doubt that eventually complexity theory will not be needed to obtain the purely mathematical consequences; yet I am hopeful that some of the ideas may eventually find their way into the construction of interesting mathematical objects (such as, who knows, a non-hyperlinear group).</p>
<p>That was a good Masters project…thanks Julia!</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/"><span class="datestr">at January 14, 2020 01:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=1734">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/the-sum-of-a-geometric-series-is-all-you-need/">The sum of a geometric series is all you need!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">I sometimes joke with my students about one of the main tools I have been using in the last ten years: the explicit sum of a geometric series. <em>Why is this?</em></p>



<h2>From numbers to operators</h2>



<p class="justify-text">The simplest version of this basic result for real numbers is the following: $$ \forall r \neq 1, \ \forall n \geq 0, \   \sum_{k=0}^n r^k = \frac{1-r^{n+1}}{1-r},$$ and is typically proved by multiplying the two sides by \(1-r\) and forming a telescoping sum. When \(|r|&lt;1\), we can let \(n\) tend to infinity and get $$ \forall |r| &lt;  1, \  \sum_{k=0}^\infty r^k = \frac{1}{1-r}.$$</p>



<p class="justify-text"><strong>Proofs without words.</strong> There is a number of classical proofs of the last identities, many of them <a href="https://en.wikipedia.org/wiki/Proof_without_words">without words</a>, presented in the beautiful series of books by Roger Nelsen [1, 2, 3]. I particularly like the two below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="478" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/triangles-1-1024x447.png" class="wp-image-1916" height="209" />Proof of the infinite sum of a geometric series with \(r=\frac{1}{2}.\) The area of the right triangle which is the half of a square with side length equal to \(2\), is equal to \(2\) and to the sum of the areas of the smaller triangles, that is, \(2 = \frac{1}{1- \frac{1}{2}}= 1 + \frac{1}{2} + \frac{1}{4} + \frac{1}{8} + \cdots\). Adapted from [3, p. 155].</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="430" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/rectangles_r.png" class="wp-image-2005" height="390" />Proof of the finite sum of a geometric series, started at \(k=0\) up to \(k=n=5\). The area of the full square of unit side length is equal to the sum of the areas of all yellow rectangles plus the pink one, that is, \(1 = (1-r) \sum_{k=0}^n r^k + r^{n+1}\). Adapted from [1, p. 118].</figure></div>



<p class="justify-text"><strong>High school: from philosophy to trigonometry.</strong> Before looking at extensions beyond real numbers, I can’t resist mentioning some of <a href="https://en.wikipedia.org/wiki/Zeno%27s_paradoxes">Zeno’s paradoxes</a>, like Achilles and the tortoise, which are intimately linked with the sum of a geometric series (and which were a highlight of my high school philosophy “career”).</p>



<p class="justify-text">Speaking of high school, it is interesting to note that there, the core identity of this blog post, is often used as \(a^{n+1}-b^{n+1} = (a-b)(a^n+a^{n-1}b+\cdots+ab^{n-1}+b^{n})\) in order to factorize polynomials (and not in the other way around like done later in this post).</p>



<p class="justify-text">Another nice elementary use of geometric series comes up with complex numbers, in order to compute sum of cosines, such as: $$\! \sum_{k=0}^n \! \cos k\theta = {\rm Re} \Big(\!\sum_{k=0}^n e^{ i k \theta}\!\Big) = {\rm Re} \Big(\!\frac{e^{i(n+1)\theta}-1}{e^{i\theta}-1}\!\Big) =  {\rm Re} \Big(\! \frac{ \sin \frac{n+1}{2} \theta e^{i(n+1)\theta/2}}{ \sin \frac{\theta}{2} e^{i\theta/2} }\!\Big) = \frac{  \sin \frac{n+1}{2} \theta}{\sin \frac{\theta}{2}} \cos \frac{n\theta}{2}. $$</p>



<p class="justify-text"><strong>Square matrices and operators.</strong> Within applied mathematics, the matrix and operator versions are the most useful. For \(A\) a square matrix or any linear operator, we have $$ \forall A \mbox{ such that } I-A \mbox{ is invertible}, \  \sum_{k=0}^n A^k = (I-A)^{-1}(I-A^{n+1}),$$ with the classical proof: \(\displaystyle (I – A)\sum_{k=0}^n A^k = \sum_{k=0}^n A^k – \sum_{k=1}^{n+1} A^k = I – A^{n+1}.\)</p>



<p class="justify-text">When \(\| A\| &lt;1\) for any <a href="https://en.wikipedia.org/wiki/Matrix_norm">matrix norm</a> induced from a vector norm, we can let \(n\) go to infinity, to obtain the <a href="https://en.wikipedia.org/wiki/Neumann_series">Neumann series</a> \(\displaystyle \sum_{k=0}^{+\infty} A^k = (I-A)^{-1}\).</p>



<p class="justify-text">We are now ready to talk about machine learning and optimization!</p>



<h2>Stochastic gradient for quadratic functions</h2>



<p class="justify-text">Matrix geometric series come up naturally when analyzing iterative algorithms based on linear recursions. In this blog post, I will focus on stochastic gradient descent (SGD) techniques to solve the following problem: $$ \min_{\theta \in \mathbb{R}^d} F(\theta) = \frac{1}{2} \mathbb{E} \big[ y – \theta^\top \Phi(x) \big]^2,$$ where the expectation is taken with respect to some joint distribution on \((x,y)\). We denote by \(\theta_\ast \in \mathbb{R}^d\) the minimizer of the objective function above (which is assumed to exist). We assume the feature vector \(\Phi(x)\) is high-dimensional, so that the moment matrix \(H = \mathbb{E} \big[ \Phi(x)\Phi(x)^\top \big]\) cannot be assumed to be invertible.</p>



<p class="justify-text"><strong>Stochastic gradient descent recursion. </strong>Starting from some initial guess \(\theta_0 \in \mathbb{R}^d\), typically \(\theta_0 =0\), the SGD recursion is: $$  \theta_n = \theta_{n-1} – \gamma ( \theta_{n-1}^\top \Phi(x_n) \, – y_n) \Phi(x_n),$$ where \((x_n,y_n)\) is an independent sample from the distribution mentioned above, and \(\gamma &gt; 0\) is the step-size. This algorithm dates back to <a href="https://en.wikipedia.org/wiki/Stochastic_approximation">Robbins and Monro</a> in the 50’s and is particularly adapted to machine learning as it updates the parameter \(\theta\) after each observation \((x_n,y_n)\) (as opposed to waiting for a full pass over the data).</p>



<p class="justify-text">Denoting \(\varepsilon_n = y_n – \theta_\ast^\top \Phi(x_n)\) the residual between the observation \(y_n\) and the optimal linear prediction \(\theta_\ast^\top \Phi(x_n)\), we can rewrite the SGD recursion as $$\theta_n = \theta_{n-1} – \gamma ( \theta_{n-1}^\top \Phi(x_n) \, – \theta_{\ast}^\top \Phi(x_n) -\, \varepsilon_n) \Phi(x_n),$$ leading to $$\theta_n \, – \theta_\ast = \big[ I – \gamma \Phi(x_n) \Phi(x_n)^\top \big] ( \theta_{n-1}- \theta_\ast) + \gamma \varepsilon_n \Phi(x_n).$$</p>



<p class="justify-text">This is a stochastic linear recursion on the deviation to optimum \(\theta_n \, – \theta_\ast\). The expectation of the SGD recursion is: $$\mathbb{E} [ \theta_n] \, – \theta_\ast = \big[ I – \gamma H \big] ( \mathbb{E}[ \theta_{n-1}] – \theta_\ast), $$ where \(H = \mathbb{E} \big[ \Phi(x) \Phi(x)^\top \big]\), and where we have used that  \(\gamma \varepsilon_n \Phi(x_n)\) has zero expectation (as a consequence of optimality conditions for \(\theta_\ast\)). This is exactly the gradient descent recursion on the expected loss (which cannot be run in practice because we only have access to a finite amount of data).</p>



<p class="justify-text"><strong>Simplification. </strong>The main difficulty in analyzing the stochastic recursion is the presence of two sources of randomness when compared to the gradient descent recursion: (A) some additive noise \(\gamma \varepsilon_n \Phi(x_n)\) independent of the current iterate \(\theta_{n-1}\) and with zero expectation, and (B) some multiplicative noise \(\gamma \big[  H – \Phi(x_n) \Phi(x_n)^\top \big] (\theta_{n-1} – \theta_\ast)\), which comes from the use of \(  I – \gamma \Phi(x_n) \Phi(x_n)^\top  \) instead of \(I – \gamma H\), and depends on the current iterate \(\theta_{n-1}\).</p>



<p class="justify-text">In this blog post, for simplicity, I will ignore the multiplicative noise and only focus on the additive noise, and thus consider the recursion $$\theta_n\, – \theta_\ast = ( I – \gamma H )  ( \theta_{n-1}- \theta_\ast) + \gamma \varepsilon_n \Phi(x_n).$$ Detailed studies with multiplicative noise can be found in [<a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">4</a>, <a href="http://proceedings.mlr.press/v38/defossez15.pdf">5</a>, <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">6</a>, <a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">7</a>], and lead to similar results. Moreover, I will assume (again for simplicity) that \(\varepsilon_n\) and \(\Phi(x_n)\) are independent, and that \(\mathbb{E} [ \varepsilon_n^2 ] = \sigma^2\) (which corresponds to uniform noise of variance \(\sigma^2\) on top of the optimal linear predictions); again, results directly extends without this assumption.</p>



<p class="justify-text"><strong>Bias / variance decomposition. </strong>Having a constant multiplicative term \(I – \gamma H\) in the recursion leads to an explicit formula: $$\theta_n – \theta_\ast = ( I – \gamma H ) ^n ( \theta_{0}- \theta_\ast) + \sum_{k=1}^n \gamma  ( I – \gamma H ) ^{n-k} \varepsilon_k \Phi(x_k),$$ which is now easy to analyze. It is the sum of a deterministic term depending on initial conditions,  and a zero mean term which is the sum of independent zero-mean terms due to the noise in the gradients. Thus, we can compute the expectation of the excess risk \(F(\theta_n)\, – F(\theta_\ast) = \frac{1}{2} ( \theta_n – \theta_\ast)^\top H ( \theta_n – \theta_\ast)\), as follows: $$\! \mathbb{E} \big[ F(\theta_n) \,- F(\theta_\ast)\big] = {\rm Bias} + { \rm Variance}, $$ where the bias term characterizes the forgetting of initial conditions: $$ {\rm Bias} = \frac{1}{2}  ( \theta_0 – \theta_\ast)^\top ( I – \gamma H ) ^{2n} H ( \theta_0 – \theta_\ast),  $$ and the variance term characterizes the effect of the noise: $${\rm Variance} =  \frac{\gamma^2 }{2}\! \sum_{k=1}^n \! \mathbb{E} \big[ \varepsilon_k^2 \Phi(x_k)^\top ( I – \gamma H ) ^{2n-2k}H  \Phi(x_k) \big] = \frac{\gamma^2  \sigma^2}{2}\! \sum_{k=1}^n \! {\rm tr} \big[  ( I – \gamma H ) ^{2n-2k}H^2   \big] .$$</p>



<p class="justify-text">The bias term is exactly the convergence rate of gradient descent on the expected risk, and can be controlled by upper-bounding the eigenvalues of the matrix  \(( I – \gamma H ) ^{2n} H\). As shown at the end of the post, when \(\gamma \leq \frac{1}{L}\), where \(L\) is the largest eigenvalue of \(H\), then this matrix has all eigenvalues less than \(1/(4n\gamma)\), leading to a bound on the bias term of $$ \frac{1}{8 \gamma n} \|\theta_0 – \theta_\ast\|^2.$$ We recover the traditional \(O(1/n)\) convergence rate of gradient descent. For the variance term we use the sum of a geometric series, to obtain the bound $$\frac{\gamma^2  \sigma^2}{2}   {\rm tr} \big[ H^2( I – (I – \gamma H)^2 )^{-1}  \big] = \frac{\gamma^2  \sigma^2}{2}  {\rm tr} \big[ H^2( 2\gamma H – \gamma^2 H^2 )^{-1}  \big] \leq \frac{\gamma  \sigma^2}{2}  {\rm tr}(H) .$$ While the bias term that characterizes the forgetting of initial conditions goes to zero as \(n\) goes to infinity, this is not the case for the variance term. This is the traditional lack of convergence of SGD with a constant step-size. In the left plot of the figure below, we compare deterministic gradient descent to stochastic gradient with a constant step-size. For convergence rates in higher dimension, see further below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="564" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/paths_video-1.gif" class="wp-image-2039" height="236" />Gradient descent algorithms run from the same starting point. Left plot: plain gradient descent (GD), plain (non-averaged) gradient descent (SGD). Right plot: averaged SGD with uniform weights (ASGD-1) and with weights proportional to the iteration index (ASGD-k).</figure></div>



<p class="justify-text">Convergence can be obtained by using a decreasing step-size, typically of the order \(1 / \sqrt{n},\) leading to an overall convergence rate proportional to \(1 / \sqrt{n}.\) This can be improved through averaging, which I now present.</p>



<h2>Impact of averaging</h2>



<p class="justify-text">We consider the averaged iterate \(\bar{\theta}_n = \frac{1}{n+1} \sum_{k=0}^n \theta_k\), an off-line (no interaction with the stochastic recursion) averaging often referred to as Polyak–Ruppert averaging, after [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">8</a>, 9]. The averaged iterate can also be expressed as a linear function of initial conditions and noise variables as $$\bar{\theta}_n -\theta_\ast = \frac{1}{n+1} \sum_{k=0}^n  ( I – \gamma H ) ^k ( \theta_{0}- \theta_\ast) + \frac{\gamma}{n+1}   \sum_{k=1}^n \sum_{j=k}^n   ( I – \gamma H ) ^{j-k} \varepsilon_k \Phi(x_k).$$ Geometric series come in again! We can get a closed form for \(\bar{\theta}_n -\theta_\ast\) as: $$\frac{1}{n+1} (\gamma H)^{-1} \big[ I – ( I – \gamma H ) ^{n+1} \big] ( \theta_{0}- \theta_\ast) + \frac{\gamma}{n+1} (\gamma H)^{-1} \sum_{k=1}^n \big[ I – ( I – \gamma H ) ^{n-k+1} \big] \varepsilon_k \Phi(x_k).$$</p>



<p class="justify-text">The bound on \(\mathbb{E} \big[ F(\bar{\theta}_n) \,- F(\theta_\ast)\big] \), will here also be composed of a bias term and a variance term. </p>



<p class="justify-text"><strong>Bias.</strong> The bias term is equal to $$\frac{1}{2(n+1)^2}( \theta_{0}- \theta_\ast) ^\top   (\gamma H)^{-2} H \big[ I – ( I – \gamma H ) ^{n+1} \big]^2 ( \theta_{0}- \theta_\ast).$$ Using the fact that the eigenvalues of the matrix \( (\gamma H)^{-2} H \big[ I – ( I – \gamma H ) ^{n+1} \big]^2\) are all less than \((n+1)/\gamma\) (see proof at the end of the post), we obtain the upper bound $$ \frac{1}{2 (n+1)\gamma} \| \theta_0 – \theta_\ast\|^2,$$ which is essentially the same than with averaging (but, see an important difference in the discussion below, regarding the behavior for large \(n\)).</p>



<p class="justify-text"><strong>Variance.</strong> The variance term is equal to $$ \frac{\gamma^2}{2 (n+1)^2}  \sum_{k=1}^n \sigma^2 {\rm tr} \Big( \big[ I – ( I – \gamma H ) ^{n-k+1} \big]^2 (\gamma H)^{-2} H^2 \Big).$$ Using the positivity of the matrix \(( I – \gamma H )\), we finally obtain the following bound for variance term: $$  \frac{ \sigma^2 n {\rm tr}(I)}{2(n+1)^2}\leq \frac{\sigma^2 d}{2n}.$$ We now have a convergent algorithm, and we recover traditional quantities from the statistical analysis of <a href="https://en.wikipedia.org/wiki/Least_squares">least-squares regression</a>.</p>



<p class="justify-text"><strong>Experiments.</strong> Now, both bias and variance are converging at rate \(1/n\). See an illustration in two dimensions in the right plot of the figure above, as well as a convergence rates below. In these two figures, what differs is the decay of eigenvalues of \(H\) (fast in the first figure, slower in the second).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="533" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/rates_d3-1-1024x453.png" class="wp-image-2029" height="235" />Bias (left) and variance (right) terms for plain SGD, averaged SGD with uniform averaging (ASGD-1) and non-uniform averaging (ASGD-k). The matrix \(H\) is of dimension \(100 \times 100\) and has eigenvalues \(1/k^3\), \(k \in \{1,\dots,100\}\). Averaged over 100 replications.</figure></div>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="549" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/rates_d-1-1024x453.png" class="wp-image-2030" height="242" />Bias (left) and variance (right) terms for plain SGD, averaged SGD with uniform averaging (ASGD-1) and non-uniform averaging (ASGD-k). The matrix \(H\) is of dimension \(100 \times 100\) and has eigenvalues \(1/k\), \(k \in \{1,\dots,100\}\). Averaged over 100 replications.</figure></div>



<p>We can make the following observations:</p>



<ul class="justify-text"><li>Depending on the amount of noise in the gradients, the sum of the variance and the bias terms will either be dominated by one of the two; typically the bias term in early iterations, and then the variance term (see more  details in [<a href="http://proceedings.mlr.press/v38/defossez15.pdf">5</a>]).</li><li>The variance term of non-averaged SGD is converging to a constant (while the bias term is exactly the one of regular gradient descent).</li><li>With averaging, the variance terms decay as a line in a log-log plot. The reader with good eyes can check that the slope is indeed -1, thus illustrating the convergence rate in \(1/n\) (here the bound is tight). For the variance terms (right plots), there is no significant difference between the two eigenvalue decays.</li><li>The bias terms have different behaviors for the two decays. For the fast decays (top plot), the bounds in \(1/n\) are reasonably tight (lines of slope -1). For slower decay, we see some strong-convexity behavior entering the scene, as the slowest eigenvalue is 1/100 and the number of iterations is far larger than 100, and thus the optimization problem looks strongly convex, and then the bias term of plain SGD (which corresponds to deterministic gradient descent) converges exponentially fast, while the two averaging techniques decay as powers of \(n\) (again, the acute reader can spot slopes of -2 and -4, and the smart reader can explain why; more on this in a future post dedicated to SGD).</li></ul>



<p class="justify-text"><strong>Pros and cons of averaging.</strong> Overall, we can see that averaging may slow down the forgetting of initial conditions, while it makes the method robust to noise in the gradients. The trade-off depends on the amount of noise, but in most high-dimensional learning problems and for the accuracies practitioners are interested in (no need to have an excess risk of \(10^{-5}\) then the best risk is of order \(10^{-1}\)), the bias term is the one which is seen the most. Thus, a less-aggressive form of averaging that puts more weights on later iterates seems advantageous (pink curve above). More on this in a future blog post.</p>



<p class="justify-text"><strong>Beyond least-squares.</strong> In this blog post, to illustrate the use of sums of geometric series, I have focused on an idealized version (no multiplicative noise) of least-squares regression. For other losses, e.g., logistic loss, the analysis is more involved, and averaging does not lead to a converging algorithm, but transforms a term in \(\gamma\) into a term in \(\gamma^2\), which is still a significant improvement when the step-size \(\gamma\) is small (see [<a href="https://arxiv.org/pdf/1707.06386">10</a>] for more details).</p>



<h3>Extensions</h3>



<p class="justify-text">The sum of a geometric series can be extended in a variety of ways. For example, we can take the derivative with respect to \(r\), to get $$ \forall r \neq 1, \  \sum_{k=1}^n k r^{k-1} = \frac{1-r^{n+1}}{(1-r)^2} – \frac{ (n+1) r^n}{1-r} = \frac{1 + n r^{n+1} – (n+1) r^n }{(1-r)^2}.$$ This is useful for example to compute the performance of the weighted average \(\frac{2}{n(n+1)} \sum_{k=1}^n k \theta_k\). This can be extended further with the <a href="https://en.wikipedia.org/wiki/Binomial_series">binomial series</a> $$ (1-r)^{-1-\beta} = \sum_{k=0}^\infty { k + \beta \choose k} r^k. $$</p>



<h2>Conclusion</h2>



<p class="justify-text">In this blog post, I have essentially used the sum of a geometric series as an excuse to talk about stochastic gradient descent, but there are other places where such series pop out, such as in the analysis of Markov chains and the associated ergodic theorems [11], which are ubiquitous in the analysis of simulation algorithms.</p>



<p class="justify-text">This year, I am still planning to post every first Monday of the month. Expect additional posts on acceleration, stochastic gradient, and orthogonal polynomials, but also new topics should be covered, always with connections with machine learning. </p>



<p class="justify-text">Happy new year!</p>



<h2>References</h2>



<p class="justify-text">[1] Roger B. Nelsen, <em>Proofs without Words: Exercises in Visual Thinking</em>, Mathematical Association of America, 1997.<br />[2] Roger B. Nelsen, <em>Proofs without Words II: More Exercises in Visual Thinking</em>, Mathematical Association of America, 2000.<br />[3] Roger B. Nelsen, <em>Proofs Without Words III: Further Exercises in Visual Thinking</em>, Mathematical Association of America, 2015.<br />[4] Francis Bach and Eric Moulines. <a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate \(O(1/n)\)</a>. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2013.<br />[5] Alexandre Defossez, Francis Bach. <a href="http://proceedings.mlr.press/v38/defossez15.pdf">Averaged Least-Mean-Square: Bias-Variance Trade-offs and Optimal Sampling Distributions</a>. <em>Proceedings of the International Conference on Artificial Intelligence and Statistics (AISTATS)</em>, 2015.<br />[6] Aymeric Dieuleveut, Nicolas Flammarion, and Francis Bach. <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression</a>. <em>Journal of Machine Learning Research</em>, 18(101):1−51, 2017.<br />[7] Prateek Jain, Sham M. Kakade, Rahul Kidambi, Praneeth Netrapalli, Aaron Sidford. <a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">Parallelizing Stochastic Gradient Descent for Least Squares Regression: Mini-batching, Averaging, and Model Misspecification</a>. <em>Journal of Machine Learning Research</em>, 18(223):1−42, 2018.<br />[8] Boris T. Polyak, Anatoli B. Juditsky. <a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">Acceleration of Stochastic Approximation by Averaging</a>. <em>SIAM Journal on Control and Optimization</em>. 30(4):838-855, 1992.<br />[9] David Ruppert. Efficient estimations from a slowly convergent Robbins-Monro process. Technical Report 781, Cornell University Operations Research and Industrial Engineering, 1988.<br />[10] Aymeric Dieuleveut, Alain Durmus, Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the Gap between Constant Step Size Stochastic Gradient Descent and Markov Chains</a>. To appear in <em>Annals of Statistics</em>, 2020.<br />[11] Sean Meyn and Richard L. Tweedie. <em><a href="https://www.cambridge.org/fr/academic/subjects/statistics-probability/applied-probability-and-stochastic-networks/markov-chains-and-stochastic-stability-2nd-edition?format=PB">Markov Chains and Stochastic Stability</a></em>. Cambridge University Press, 2009.</p>



<h2>Detailed computations</h2>



<p><strong>Bounds on eigenvalues – I.</strong> In order to show the first desired inequality on eigenvalues, we simply need to show that \((1-t)^{2n} t \leq 1/(4n)\) for any \(t \in [0,1]\), which is the consequence of $$(1-t)^{2n} t \leq (e^{-t})^{2n} t \leq \frac{1}{2n} \sup_{u \geq 0} e^{-u} u = \frac{1}{2e n} \leq \frac{1}{4n}.$$</p>



<p class="justify-text"><strong>Bounds on eigenvalues – II.</strong> In order to show the second desired inequality on eigenvalues, we simply need to show that \(( 1 – ( 1 – t)^{n+1}) \leq \sqrt{n+1} \sqrt{t}\), for any \(t \in [0,1]\). This is a simple consequence of the straightforward inequality \(( 1 – ( 1 – t)^{n+1}) \leq 1\) and the inequality \(( 1 – ( 1 – t)^{n+1}) \leq (n+1) t \), which itself can be obtained by integrating the inequality \((1-u)^n \leq 1\) between \(0\) and \(t\).</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/the-sum-of-a-geometric-series-is-all-you-need/"><span class="datestr">at January 06, 2020 10:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=1391">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/jacobi-polynomials/">Polynomial magic II : Jacobi polynomials</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">Following up my last post on Chebyshev polynomials, another piece of polynomial magic this month. This time, Jacobi polynomials will be the main players.</p>



<p class="justify-text">Since definitions and various formulas are not as intuitive as for Chebyshev polynomials, I will start by the machine learning / numerical analysis motivation, which is an elegant refinement of Chebyshev acceleration.</p>



<h2>Spectral measures and polynomial acceleration</h2>



<p class="justify-text">Like in the previous post, we consider the iteration in \(\mathbb{R}^n\) $$x_{k+1} = Ax_{k} – b,$$ with \(A \in \mathbb{R}^{n \times n}\) a symmetric matrix with spectrum \({\rm Spec}(A) \subset (-1,1)\), with unique fixed point \(x_\ast\) such that \(x_\ast = A x_\ast – b\), that is, \(x_\ast = ( A – I)^{-1} b\).  These recursions naturally come up in gradient descent for quadratic functions or gossip algorithms (as described later).</p>



<p class="justify-text">In order to speed-up convergence, a classical idea explored in the <a href="https://francisbach.com/chebyshev-polynomials/">last post</a> is to take linear combinations of all past iterates. That is, we consider \(y_k = \sum_{i=0}^k \nu_i^k x_i\) for some weights \(\nu_i^k\) such that \(\sum_{i=0}^k \nu_i^k=1\) (so that if all iterates are already at \(x_\ast\), then the weighted average stays there). We have $$ y_k – x_\ast =  \sum_{i=0}^k \nu_i^k ( x_i – x_\ast) = \sum_{i=0}^k \nu_i^k A^i (x_0-x_\ast) = P_k(A) (x_0-x_\ast),$$ where \(P_k(X) = \sum_{i=0}^k \nu_i^k X^i\) is a polynomial such that \(P_k(1)=1\).  </p>



<p class="justify-text">For Chebyshev acceleration, we used the following bound: $$  \frac{1}{n} \| y_k – x_\ast\|_2^2 =   \frac{1}{n} ( x_0 – x_\ast)^\top P_k(A)^2 (x_0 -x_\ast)   \leq \max_{\lambda \in {\rm Spec}(A)} |P_k(\lambda)|^2 \cdot \frac{1}{n}\|x_0 – x_\ast\|_2^2.$$ Using the fact that  \({\rm Spec}(A) \subset [-1\!+\!\delta,1\!-\!\delta]\) for some \(\delta&gt;0\), minimizing \(\max_{\lambda \in {\rm Spec}(A)} |P_k(\lambda)|^2\) subject to \(P_k(1)=1\) led to a rescaled Chebyshev polynomials. This allowed to go from a convergence rate proportional to \((1\!-\!\delta)^k\) to a convergence rate proportional to \((1 – \sqrt{2\delta})^k\).</p>



<p class="justify-text">When \(\delta\) is small, this is a significant gain. But when \(\delta\) is really small, none of the two techniques converge quickly enough, in particular in early iterations where the exponential convergence regime has not been reached. However, only a few eigenvalues are close to \(-1\) or \(1\)  (see examples in gossip matrices below), and using more information about eigenvalues beyond the smallest and largest ones can be advantageous.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter is-resized"><img width="613" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/comparing_spectra-1-1024x266.png" class="wp-image-1600" height="159" />Histogram of eigenvalues of gossip matrices for gossiping within the 1D, 2D and 3D grid, with the same number of nodes \(n = 4096\): the eigengap \(1-\rho\) is small, and the eigenvalues are well-spread. See more details in the gossip section below.</figure></div>



<p class="justify-text">We will use the spectral decomposition \(A = \sum_{i=1}^n\! \lambda_i u_i u_i^\top\), where \(\lambda_i\) is an eigenvalue of \(A\) with orthonormal eigenvectors \(u_i\), \(i=1,\dots,n\). We thus have $$  \frac{1}{n} \| y_k – x_\ast\|_2^2 = \frac{1}{n} ( x_0 – x_\ast)^\top P_k\Big( \sum_{i=1}^n \lambda_i u_i u_i^\top \Big)^2 ( x_0 – x_\ast) =  \frac{1}{n}\! \sum_{i=1}^n P_k(\lambda_i)^2 \big[ (x_0 – x_\ast)^\top u_i \big]^2.$$ Assuming \(\big[ (x_0 – x_\ast)^\top u_i \big]^2 \leq \tau^2\) for all \(i=1,\dots,n\) (that is, the initial deviation from the optimum has uniform magnitude on all eigenvectors), we need to minimize $$ e(P_k) = \frac{1}{n} \! \sum_{i=1}^n \! P_k(\lambda_i)^2  = \int_{-1}^1 \!\! P_k(\lambda)^2 d \sigma(\lambda)$$ with respect to \(P_k\), where \(d\sigma = \frac{1}{n} \sum_{i=1}^n\! \delta_{\lambda_i}\) is the spectral probability measure of \(A\).</p>



<p class="justify-text">Now, the new goal is to minimize \(\displaystyle \int_{-1}^1 \!\! P_k(\lambda)^2 d \sigma(\lambda)\) with respect to a polynomial \(P_k\) with degree \(k\) and such that \(P_k(1)=1\). This is where orthogonal polynomials naturally come in. Their use in creating acceleration mechanisms dates back from numerical analysis in the 1980’s and 1990’s (with a very nice and detailed account in [1]).</p>



<h2>Orthogonal polynomials and kernel polynomials</h2>



<p class="justify-text">We consider a sequence of <a href="https://en.wikipedia.org/wiki/Orthogonal_polynomials">orthogonal polynomials</a> \(Q_k\) for the probability measure \(d\sigma\) in support within \([-1,1]\), each of degree \(k\), which we do not assume normalized. They are essentially unique (up to rescaling); see, e.g., the very good books by Gábor Szegő [2] and Theodore Seio Chihara [3].</p>



<p class="justify-text">We denote by \(\alpha_i = \int_{-1}^1 \! Q_i^2(\lambda)d\sigma(\lambda)\), for \(i \geq 0\), the squared norm of \(Q_i\), so that the sequence of polynomials \(({\alpha_i^{-1/2}} Q_i)\) is <em>orthonormal</em>. We can then solve the optimization problem above for \(P_k\), by writing it \(P_k(X) = \sum_{i=0}^k u_i {\alpha_i^{-1/2}} Q_i(X)\), and the problem in \(u \in\mathbb{R}^{k+1}\) becomes: $$\min_{u \in \mathbb{R}^{k+1}} \sum_{i=0}^k u_i^2 \mbox{ such that }  \sum_{i=0}^k u_i {\alpha_i^{-1/2}} Q_i(1) = 1.$$ This optimization problem can be solved in closed form, and the solution is such that \(\displaystyle u_i = \frac{{\alpha_i^{-1/2}} Q_i(1)}{\sum_{j=0}^k \!{\alpha_j^{-1}} Q_j(1)^2}\) for all \(i\), with the optimal polynomial $$P_k(X) =  \frac{\sum_{i=0}^k \! {\alpha_i^{-1}} Q_i(1) Q_i(X) }{\sum_{i=0}^k \!{\alpha_i^{-1}} Q_i(1)^2}.$$ The optimal value is thus equal to $$\big({\sum_{i=0}^k \alpha_i^{-1} Q_i(1)^2 } \big)^{-1}.$$</p>



<p class="justify-text">The polynomials \(\sum_{i=0}^k \alpha_i^{-1} Q_i(X)Q_i(Y)\) are called the <em>kernel polynomials</em> [3, Chapter I, Section 7] associated to \(d\sigma\), and have many properties (beyond the optimality property which we just proved) that we will use below. </p>



<p class="justify-text">At this point, the problem seems essentially solved: one can construct iteratively the polynomials \(Q_k\) using classical second-order recursions for orthogonal polynomials, and thus compute \(P_k(X)\) which is proportional to \(\sum_{i=0}^k \frac{1}{\alpha_i} Q_i(1) Q_i(X)\). This leads however to a somewhat complicated algorithm, and some additional polynomial magic can be invoked.</p>



<p class="justify-text">It turns out that kernel polynomials, of which \(P_k\) is a special case, are themselves proportional to orthogonal polynomials for the modified measure \((1-\lambda) d \sigma(\lambda)\) (see proof at the end of the post). This is useful to generate the optimal polynomial with a second-order recursion.</p>



<p class="justify-text">To summarize, if we know the spectral measure \(d\sigma\), then we can derive a sequence of polynomials \(P_k\) that leads to an optimal value for \(\displaystyle \int_{-1}^1 \!\! P_k(\lambda)^2 d \sigma(\lambda)\). However, knowing precisely the spectral density is typically as hard as finding the fixed point of the recursion.</p>



<p class="justify-text">Since convergence properties are dictated by the behavior of the spectral measure around \(-1\) and \(1\), i.e., by the number of eigenvalues around \(-1\) and \(1\), we can model the spectral measure by simple distributions with varied behavior at the two ends of the spectrum. A known family is the rescaled Beta distribution, with density proportional to \((1-x)^\alpha (1+x)^\beta\). This will lead to Jacobi polynomials and “simple” formulas below.</p>



<h2>Jacobi polynomials</h2>



<p class="justify-text">For \(\alpha, \beta &gt; -1\), the \(k\)-th <a href="https://en.wikipedia.org/wiki/Jacobi_polynomials">Jacobi polynomial</a> \(J_k^{(\alpha,\beta)}\) is equal to $$J_k^{(\alpha,\beta)}(x) = \frac{(-1)^k}{2^k k!} (1-x)^{-\alpha} (1+x)^{-\beta} \frac{d^k}{dx^k} \Big\{ (1-x)^{\alpha + k} (1+x)^{\beta + k} \Big\}.$$ </p>



<p class="justify-text">Denoting \(\displaystyle d\sigma(x) =   \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} ( 1 -x )^\alpha (1+x)^\beta dx\) the rescaled <a href="https://en.wikipedia.org/wiki/Beta_distribution">Beta distribution</a> (with \(\Gamma(\cdot)\) the <a href="https://en.wikipedia.org/wiki/Gamma_function">Gamma function</a>), the Jacobi polynomials are orthogonal for the probability measure \(d\sigma\). That is, $$ \int_{-1}^1  \! J_k^{(\alpha,\beta)}(x) J_\ell^{(\alpha,\beta)}(x) d\sigma(x) = 0, $$ if \(k \neq \ell\), and equal to \(\displaystyle \alpha_k = \frac{1}{2k+\alpha + \beta + 1} \frac{\Gamma(\alpha+\beta +2) \Gamma(k+\alpha+1) \Gamma(k+\beta+1)}{\Gamma(\alpha+1) \Gamma(\beta +1)  \Gamma(k+1) \Gamma(k+\alpha+\beta+1)}\) if \(k=\ell\). We have the following equivalent \( \displaystyle \alpha_k \sim \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1) }\frac{1}{2k}\) when \(k\) tends to infinity. All the formulas in these sections can be obtained from standard references on orthogonal polynomials [2, 3] (with a summary on <a href="https://en.wikipedia.org/wiki/Jacobi_polynomials">Wikipedia</a>) and are presented without proofs.</p>



<p class="justify-text">The value at 1 is an important quantity for acceleration, and is equal to: $$ J_k^{(\alpha,\beta)}(1) = {k+\alpha \choose k} = \frac{\Gamma(k+\alpha+1)}{\Gamma(k+1) \Gamma(\alpha+1)} \sim \frac{ (k/e)^\alpha}{\Gamma(\alpha+1)},$$ while the value at -1 is equal to $$ J_k^{(\alpha,\beta)}(-1) =(-1)^k {k+\beta \choose k} = \frac{\Gamma(k+\beta+1)}{\Gamma(k+1) \Gamma(\beta+1)} \sim \frac{ (k/e)^\beta}{\Gamma(\beta+1)}.$$ </p>



<p class="justify-text">In order to compute the polynomials, the following recursion is key: $$  J_{k+1}^{(\alpha,\beta)}(X) = (a_k^{(\alpha,\beta)} X + \tilde{b}_k^{(\alpha,\beta)})J_k^{(\alpha,\beta)} – c_k J_{k-1}^{(\alpha,\beta)}(X),$$ with coefficients with explicit (and slightly complicated) formulas (in the case you wonder why I use \(\tilde{b}\) instead of \(b\), this is to avoid overloading the notation with the iteration \(x_{k+1}= Ax_{k}-b\)): $$a_k^{(\alpha,\beta)} =   \frac{(2k+\alpha+\beta+1)  (2k+2+\alpha+\beta)  }{(2k+2)(k+1+\alpha+\beta)  },\ \ \ \ \ \ \ \ \ $$ $$ \tilde{b}_k^{(\alpha,\beta)}  =   \frac{(2k+\alpha+\beta+1) ( \alpha^2 – \beta^2 )}{(2k+2)(k+1+\alpha+\beta) (2k + \alpha+\beta )},$$ $$c_k^{(\alpha,\beta)}  =\frac{ 2 (k+\alpha)(k+\beta)(2k +2+\alpha+\beta) }{(2k+2)(k+1+\alpha+\beta) (2k + \alpha+\beta )}.  $$ It can be started with \(J_0^{(\alpha,\beta)}(X) = 1\) and \(J_1^{(\alpha,\beta)}(X) = \frac{\alpha – \beta}{2} +\frac{ \alpha + \beta +2}{2} X\).</p>



<p class="justify-text">The class of Jacobi polynomials includes many of other important polynomials, such as <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomials</a> (\(\alpha = \beta = -1/2\)), <a href="https://en.wikipedia.org/wiki/Legendre_polynomials">Legendre polynomials</a> (\(\alpha = \beta = 0\)) and <a href="https://en.wikipedia.org/wiki/Gegenbauer_polynomials">Gegenbauer polynomials </a>(\(\alpha = \beta = d-1/2\)). Here are plots below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter is-resized"><img width="387" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/jacobi-1.gif" class="wp-image-1604" height="202" />Jacobi polynomials, as used for the acceleration of gossip algorithms in one-dimension, with \((\alpha,\beta) = (1/2,-1/2)\).</figure></div>



<h2>Jacobi acceleration</h2>



<p class="justify-text">We can now apply the polynomial acceleration technique above to the Beta distribution, that is for \(\displaystyle d\sigma(x) =   \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} ( 1 -x )^\alpha (1+x)^\beta dx\), we have:</p>



<ul class="justify-text"><li><strong>Regular recursion error</strong> (no acceleration):  the error \(e(X^k) = \displaystyle \int_{-1}^1 \lambda^{2k} d\sigma(\lambda)\) is asymptotically equivalent to \(\displaystyle \frac{C_{\alpha,\beta}}{k^{\alpha+1}}+\frac{C_{\beta,\alpha}}{k^{\beta+1}}\), for some constants \(C_{\alpha,\beta}\) (see details at the end of the post). Before acceleration, there is thus an equivalent impact of the spectrum around \(-1\) and \(1\).</li><li><strong>Jacobi acceleration error</strong>: as shown at the end of the post, the error \(e(P_k)\) is equivalent to \(\displaystyle  \frac{E_{\alpha,\beta}}{k^{2\alpha+2}} \) for some constant \(E_{\alpha,\beta}\). </li></ul>



<p class="justify-text">What’s happening around \(-1\) and \(1\) is important, and particular the behavior around 1, and we thus see that \(\beta\) is less important for the accelerated version (in fact, using \(\beta=0\) to construct the Jacobi polynomial, as done in [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>], leads to a similar acceleration). In particular, when considering distributions where \(\beta = \alpha\), then we see that Jacobi acceleration transforms a rate proportional to \(1/k^{\alpha+1}\) to a rate proportional to \(1/k^{2\alpha+2}\).</p>



<p class="justify-text">The final recursion is then equal to (see detailed computations at the end of the post): $$ y_{k+1} =  \frac{(2k\!+\!\alpha\!+\!\beta\!+\!2)   }{2(k\!+\!2\!+\!\alpha\!+\!\beta)(k\!+\!\alpha\!+\!2)  }  \big[ (2k\!+\!3\!+\!\alpha\!+\!\beta) (Ay_k-b) +  \frac{ (\alpha\!+\!1)^2\! -\! \beta^2  }{  2k \!+\! 1\!+\!\alpha\!+\!\beta }    y_k    \Big] \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  $$ $$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  –  \frac{    (k+\beta)(2k +3+\alpha+\beta) }{ (k+2+\alpha+\beta) (2k + 1+\alpha+\beta )} \frac{ k }{ k+\alpha+2} y_{k-1}, $$ with initialization \(y_0=x_0\) and \(y_1 = \frac{\alpha+\beta+3}{2\alpha+4}(Ax_0 – b) + \frac{\alpha+1-\beta}{2\alpha+4}x_0\). For \(\alpha = \frac{d}{2}-1\) and \(\beta =0\), this exactly recovers the recursion from [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>].</p>



<h2>Application to gossip</h2>



<p class="justify-text">Like in the previous post we consider the gossip problem. For large grid graphs, the gap is small, equivalent to \(\frac{1}{2d} \frac{1}{n^{2/d}}\) for the \(d\)-dimensional grid. The gap is tending to zero with \(n\), and using acceleration techniques for non-zero gaps, such as Chebyshev acceleration, is not efficient for the earlier iterations.</p>



<p class="justify-text">It turns out that for grid graphs, the spectral measure tends to a limit with behavior \((1-x^2)^{d/2-1}\) around \(-1\) and \(1\). This is formerly true for the grid graph, and the behavior around 1 (which is the one that matters for acceleration) is the same for a large class of graphs with an underlying geometric structure [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>]. This thus corresponds to the Beta distribution of parameters \(\alpha = \beta = \frac{d}{2}-1\).</p>



<p class="justify-text">Below, I consider gossiping on a chain graph with \(n=200\) nodes, and compare regular gossip with Chebyshev acceleration and Jacobi acceleration. In early iterations, Jacobi acceleration is much better. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter is-resized"><img width="673" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/gossip_jacobi_1D.gif" class="wp-image-1714" height="204" />Gossiping a one-dimensional white noise signal of length \(n = 200\), converging to its mean, which is zero. (left) regular gossip, (center) Chebyshev acceleration, (right) Jacobi acceleration</figure></div>



<p class="justify-text">When looking at the convergence rate (plot below), for late iterations, the linear convergence of Chebyshev acceleration does take over; for a method that achieves the best of both world (good in early and late iterations), see [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>, Section 7].</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="441" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/gossip_jacobi_1D_double-1024x457.png" class="wp-image-1808" height="196" />Squared gossiping errors (norm between the signal and its average) in natural (left) and logarithmic (right) scale. Chebyshev acceleration is slow at the beginning, and faster at the end (once the error is already quite small).</figure></div>



<p>Similar plots may be made in two dimensions, gossiping a white noise signal, where the stationary behavior is observed much sooner for Jacobi acceleration. Here, Chebyshev acceleration performs worse than the regular iteration because the eigengap is very small (equal to \(6 \times 10^{-4}\)).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="663" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/gossip_jacobi_2D-1.gif" class="wp-image-1859" height="180" />Gossiping a two-dimensional white noise signal of size \(n = 64 \times 64 = 4096\), converging to its mean, which is zero. (left) regular gossip, (center) Chebyshev acceleration, (right) Jacobi acceleration.</figure></div>



<p class="justify-text">When gossiping a Dirac signal, we can also observe the spreading of information from the original position of the Dirac to the rest of the grid.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="661" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/gossip_jacobi_2D_diracs-1.gif" class="wp-image-1858" height="179" />Gossiping a two-dimensional Dirac signal of size \(n = 64 \times 64 = 4096\), converging to its mean. (left) regular gossip, (center) Chebyshev acceleration, (right) Jacobi acceleration. Note that the color scale is different in the three plots.</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">In this post, I tried to move from the worst-case analysis of spectral acceleration which typically focuses on largest and smallest eigenvalues of the involved contracting operators, closer to an average-case analysis that takes into account the whole spectrum. This led to acceleration by Jacobi polynomials rather than Chebyshev polynomials. </p>



<p class="justify-text"><strong>Beyond gossip.</strong> While I have focused primarily on applications to gossip where the spectral measure can be well approximated, this can be extended to other situations. For example, Fabian Pedregosa and Damien Scieur [<a href="https://arxiv.org/pdf/2002.04756.pdf">5</a>] recently considered an application of polynomial acceleration to gradient descent for least-squares regression with independent covariates, where the spectral measure of the covariance matrix tends to the famous <a href="https://en.wikipedia.org/wiki/Marchenko%E2%80%93Pastur_distribution">Marchenko-Pastur</a> distribution (which is close to the rescaled Beta distributions above).</p>



<p class="justify-text"><strong>Jacobi polynomials beyond acceleration.</strong> In this post, I focused only on the acceleration properties of Jacobi polynomials. There are many more interesting applications of these polynomials in machine learning and associated fields. For example, their role in <a href="https://en.wikipedia.org/wiki/Spherical_harmonics">spherical harmonics</a> to provide an orthonormal basis of the square-integrable functions on the unit sphere in any dimension, is quite useful for the theoretical study of neural networks (see, e.g., [<a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">6</a>] and references therein). I would typically say that this is a topic for another post, but this would be even more technical…</p>



<p class="justify-text">Next month, I will probably take a break in the polynomial magic series, and go back to less technical posts.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Raphaël Berthier for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] Bernd Fischer. <em>Polynomial based iteration methods for symmetric linear systems</em>. Springer, 1996. <br />[2] Gábor Szegő. <em>Orthogonal Polynomials</em>. American Mathematical Society, volume 23, 1939.<br />[3] Theodore Seio Chihara. <em>An Introduction to Orthogonal Polynomials</em>. Gordon and Breach, 1978.<br />[4] Raphaël Berthier, Francis Bach, Pierre Gaillard. <a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">Accelerated Gossip in Networks of Given Dimension using Jacobi Polynomial Iterations</a>. To appear in <em>SIAM Journal on Mathematics of Data Science</em>, 2019.<br />[5] Fabian Pedregosa, Damien Scieur.  <a href="https://drive.google.com/open?id=1MSVk90bvK3m-GM1y-RirKdy_HRoJzZwV">Acceleration through Spectral Modeling</a>. NeurIPS workshop “Beyond First Order Methods in ML”, 2019. [04/16/2020] Updated to: Average-case Acceleration Through Spectral Density Estimation,  <a href="https://arxiv.org/pdf/2002.04756.pdf">https://arxiv.org/pdf/2002.04756.pdf</a>.<br />[6] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the Curse of Dimensionality with Convex Neural Networks</a>. <em>Journal of Machine Learning Research</em>, 18(19):1-53, 2017.</p>



<h2>Detailed computations</h2>



<p class="justify-text"><strong>Kernel polynomial as orthogonal polynomial</strong>. We consider a series \((R_k)\) of orthogonal polynomials for the measure \((1-\lambda) d\sigma(\lambda)\). Assuming that \(R_k \neq 0\) (see proof in [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>, Appendix D]), then we show that the polynomial \(\frac{R_k(X)}{R_k(1)}\) is the optimal polynomial of degree \(k\) minimizing \(\int_{-1}^1 P^2(\lambda) d\sigma(\lambda)\) such that \(P(1)=1\). Indeed, taking any polynomial \(P\) of degree \(k\) and such that \(P(1)=1\), the polynomial \(P(X) \, – \frac{R_k(X)}{R_k(1)}\) vanishes at \(1\) and can thus be written as \(A(X)(X-1)\) with \(A(X)\) of degree equal or less than \(k-1\). Then we have: $$\! \int_{-1}^1 \! \! P(\lambda)^2 d\lambda = \! \int_{-1}^1\!\!   \frac{R_k(\lambda)^2}{R_k(1)^2}d\sigma(\lambda) + 2 \! \int_{-1}^1 \!\!  \frac{R_k(\lambda)}{R_k(1)} A(\lambda)(\lambda-1)d\sigma(\lambda)+ \! \int_{-1}^1  \!\! \! A(\lambda)^2(\lambda-1)^2 d\sigma(\lambda).$$ The second term in the right hand side is equal to zero by orthogonality of \((R_k)\), and the third term is non-negative. Therefore, we must have  \(\displaystyle \! \int_{-1}^1 \! \! P(\lambda)^2 d\lambda \geq  \! \int_{-1}^1\!\!   \frac{R_k(\lambda)^2}{R_k(1)^2}d\sigma(\lambda)\), which shows optimality.</p>



<p class="justify-text"><strong>Jacobi recursion</strong>. Given the original recursion \(x_{k+1} = A x_k – b\), we consider \(y_k = \frac{Q_k(A) ( x_0  – x_\ast)}{Q_k(1)} + x_\ast\), where \(Q_k = J_k^{(\alpha+1,\beta)}\). We get: $$ y_{k+1} =  \frac{(a_k^{(\alpha+1,\beta)} A + b_k^{(\alpha+1,\beta)})Q_{k}(A)( x_0  – x_\ast) – c_k^{(\alpha+1,\beta)} Q_{k-1}(A) ( x_0  – x_\ast)}{Q_{k+1}(1)} + x_\ast.$$ This leads to $$ y_{k+1} =  \frac{(a_k^{(\alpha+1,\beta)} A + b_k^{(\alpha+1,\beta)})Q_{k}(1) (y_k – x_\ast) – c_k^{(\alpha+1,\beta)} Q_{k-1}(1) ( y_{k-1}  – x_\ast)}{Q_{k+1}(1)} + x_\ast.$$ Removing all terms in \(x_\ast\) (which have to cancel), we get: $$ y_{k+1} =  a_k^{(\alpha+1,\beta)} \frac{Q_{k}(1)}{Q_{k+1}(1)}(Ay_k-b) + \tilde{b}_k^{(\alpha+1,\beta)} \frac{Q_{k}(1)}{Q_{k+1}(1)}y_k –  c_k^{(\alpha+1,\beta)} \frac{Q_{k-1}(1)}{Q_{k+1}(1)}y_{k-1}. $$ Using the explicit formula for \(Q_{k}(1)\), we get after some calculations: $$ y_{k+1} =  \frac{(2k\!+\!\alpha\!+\!\beta\!+\!2)   }{2(k\!+\!2\!+\!\alpha\!+\!\beta)(k\!+\!\alpha\!+\!2)  }  \big[ (2k\!+\!3\!+\!\alpha\!+\!\beta) (Ay_k-b) +  \frac{ (\alpha\!+\!1)^2\! -\! \beta^2  }{  2k \!+\! 1\!+\!\alpha\!+\!\beta }    y_k    \Big] \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  $$ $$\ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \ \  –  \frac{    (k+\beta)(2k +3+\alpha+\beta) }{ (k+2+\alpha+\beta) (2k + 1+\alpha+\beta )} \frac{ k }{ k+\alpha+2} y_{k-1}, $$ with initialization \(y_0 = x_0\) and \(y_1 = \frac{\alpha+\beta+3}{2\alpha+4}(Ax_0 – b) + \frac{\alpha+1-\beta}{2\alpha+4}x_0\).</p>



<p class="justify-text"><strong>Equivalents of performance</strong>. We first provide an equivalent of $$ \int_{-1}^1 \lambda^{2k} d\sigma(\lambda) = \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)}\int_{-1}^1 \! x^{2k} (1-x)^\alpha(1+x)^\beta dx.$$ By splitting the sum in two, this is equivalent to $$ \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)}\Big\{ 2^\beta\!\! \int_{0}^1 \! x^{2k} (1-x)^\alpha dx  + 2^\alpha \!\! \int_{0}^1 \! x^{2k}(1-x)^\beta dx \Big\},$$ leading to, using the normalizing factor of the Beta distribution, $$\frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} \Big\{ 2^\beta\frac{\Gamma(\alpha+1)\Gamma(2k+1)}{\Gamma(\alpha+2k+2)} +2^\alpha\frac{\Gamma(\beta+1)\Gamma(2k+1)}{\Gamma(\beta+2k+2)}   \Big\}, $$ and finally to  $$ \displaystyle \frac{1}{2^{\alpha+\beta+1} } \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1)} \Big\{ 2^\beta\frac{\Gamma(\alpha+1) }{ (2k/e)^{\alpha+1} }  +2^\alpha\frac{\Gamma(\beta+1) }{ (2k/e)^{\beta+1} }    \Big\} ,$$ which is indeed of the form \(\displaystyle \frac{C_{\alpha,\beta}}{k^{\alpha+1}}+\frac{C_{\beta,\alpha}}{k^{\beta+1}}\). </p>



<p class="justify-text">In order to estimate \(e(P_k)\), since \(P_k(X) = \sum_{i=0}^k \frac{1}{\alpha_i} Q_i(1) Q_i(X)\), we first need an equivalent of the term \(\displaystyle \frac{Q_i(1)^2}{\alpha_i^2} \sim \frac{(i/e)^{2\alpha}}{\Gamma(\alpha+1)^2} \Big( \frac{\Gamma(\alpha+\beta +2)}{\Gamma(\alpha+1) \Gamma(\beta +1) }\frac{1}{2i}\Big)^{-1} \sim E_{\alpha,\beta}’ i^{2\alpha+1}\), for some \(E_{\alpha,\beta}’\), leading to an error of the form \(e(P_k) \displaystyle \sim \frac{1}{ E_{\alpha,\beta}’  \sum_{i=0}^k i^{2\alpha+1}} \sim\frac{2\alpha+2}{ E_{\alpha,\beta}’} \frac{1}{k^{2\alpha+2}} \), which is of the desired form.</p>



<p class="justify-text"><strong>Spectral density of a grid</strong>. As seen at the far end of the <a href="https://francisbach.com/chebyshev-polynomials/">previous blog post</a>, the eigenvalues of \(A\) for the grid in one-dimension, with \(m=n\), is (up to negligible corrections) \(–  \cos \frac{k\pi}{m}\) for \(k =1,\dots,m\). This leads to a limiting spectral measure as \(– \cos \theta\) for \(\theta\) uniformly distributed on \([0,\pi]\). This leads to a spectral density \(\frac{1}{\pi}\frac{1}{\sqrt{1-\lambda^2}}\) supported on \([-1,1]\). In the plot below, we see that the histogram of eigenvalues for a finite \(m\) matches empirically this density.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="308" alt="" src="https://francisbach.com/wp-content/uploads/2019/12/1D_spectral_density.png" class="wp-image-1855" height="234" />Histogram of eigenvalues for 1D gossip matrix for \(m=4096\), with associated limiting spectral density.</figure></div>



<p class="justify-text">For a \(d\)-dimensional grid, with \(n = m^d\), the spectral density is the one of \(\frac{1}{d} (X_1+\cdots X_d)\) for \(X_i\) independent and distributed as \(\frac{1}{\pi}\frac{1}{\sqrt{1-\lambda^2}} d\lambda\) on \([-1,1]\), for each \(i=1,\dots,d\). This leads to a convolution power of the density above, rescaled to have support in \([-1,1]\). This can be shown to lead to behavior as \((1-\lambda^2)^{d/2-1}\) around \(1\) and \(-1\) (see [<a href="https://hal.archives-ouvertes.fr/hal-01797016v2/document">4</a>, Prop. 5.2]).</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/jacobi-polynomials/"><span class="datestr">at December 02, 2019 05:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=1197">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/chebyshev-polynomials/">Polynomial magic I : Chebyshev polynomials</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">Orthogonal polynomials pop up everywhere in applied mathematics and in particular in numerical analysis. Within machine learning and optimization, typically (a) they provide natural basis functions which are easy to manipulate, or (b) they can be used to model various acceleration mechanisms.</p>



<p class="justify-text">In this post, I will describe one class of such polynomials, the Chebyshev polynomials (Tchebychev in French, Чебышёв in Russian), whose extremal properties (beyond being orthogonal) are useful in the analysis of accelerated algorithms. </p>



<h2>Definition and first properties</h2>



<p class="justify-text">The \(k\)-th <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">Chebyshev polynomial</a> \(T_k\) is classically defined as the unique polynomial such that $$\forall  \theta \in [0,2\pi], \  \cos (k\theta) = T_k(\cos \theta).$$ </p>



<p class="justify-text"><strong>Recurrence</strong>. Summing the two equations \(\cos [(k\pm 1)\theta] = \cos (k\theta) \cos \theta \mp \sin (k\theta) \sin \theta\), the following recurrence relationship can be deduced: $$\forall k &gt;0, \ T_{k+1}(X) = 2X T_k(X) \, – T_{k-1}(X).$$</p>



<p class="justify-text">Together with the first two polynomials \(T_0 (X) = 1\) and \(T_1(X) = X\), this leads to \(T_2(X) = 2X^2 – 1\), \(T_3(X) = 4X^3 – 3X\), and so on.</p>



<p class="justify-text">From the recurrence relationships, one can easily deduce that \(T_k\) has the parity of \(k\) and that \(T_k\) has degree \(k\), with leading coefficient \(2^{k-1}\).</p>



<p class="justify-text"><strong>Oscillatory behavior</strong>. For \(k\theta = j \pi\), for \(j\) integer, we have \(\cos (k \theta)=(-1)^j\), while when \(j\) goes from \(k\) to \(0\), \(\cos \theta = \cos\! \big( \frac{ j \pi}{k}\big)\) goes from -1 to 1. Thus, on \([-1,1]\), \(T_k(x)\) oscillates between \(-1\) and \(1\), with equality for \(\cos\! \big(  \frac{j \pi}{k} \big)\) for \(j = 0,\dots,k\). This oscillatory behavior is illustrated below and crucial for the extremal properties below.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="306" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/chebyshev-3.gif" class="wp-image-1592" height="223" />First 33 Chebyshev polynomials, plotted between -1 and 1. Note the stronger oscillatory behavior between -1 and 1 as \(k\) grows.</figure></div>



<p class="justify-text"><strong>Orthogonality</strong>. Using the orthogonality of the Fourier basis on \([0,2\pi]\), we have for \(k \neq \ell\),  \(\int_0^{\pi} \cos (k\theta) \cos (\ell\theta) d\theta=0\), and with the change of variable \(x = \cos \theta\), we obtain $$\int_{-1}^1 \frac{T_k(x) T_\ell(x)}{\sqrt{1-x^2}} dx = 0.$$ Thus the Chebyshev polynomials inherit from many properties from such <a href="https://en.wikipedia.org/wiki/Orthogonal_polynomials">orthogonal polynomials</a> (such as the two-term recursion above, but for the Chebyshev polynomials, these can obtained more directly). For further properties, see [1].</p>



<h2>Extremal properties</h2>



<p class="justify-text">Chebyshev polynomials exhibit many “extremal properties”, of the form: among all polynomials of degree \(k\) with some form of normalization (e.g., fixed \(k\)-th order coefficient or value at given point), the one with smallest specific norm is proportional to \(T_k\).</p>



<p class="justify-text">The most classical one is as follows: the polynomial \(P\) of degree \(k\) with \(k\)-th order coefficient equal to one, and with minimum \(\ell_\infty\)-norm \(\max_{ x \in [-1,1]} \! | P(x)|\) on \([-1,1]\), is \(P = \frac{1}{2^{k-1}}T_k\). The proof is particularly elegant and simple (see <a href="https://en.wikipedia.org/wiki/Chebyshev_polynomials">here</a>). Since this is not the property that we need for optimization, we will consider another one.</p>



<p class="justify-text"><strong>Proposition</strong> (<em>largest value outside of \([-1,1]\)</em>). For any polynomial \(P\) of degree \(k\) such that \(|P(x)| \leq 1\) for \(x \in [-1,1]\), and any \(z &gt; 1\), \(|P(z)| \leq T_k(z)\).</p>



<p class="justify-text"><em>Proof</em>. By contradiction, we assume that there exists \(z &gt; 1\) such that \(P(z)&gt;T_k(z)\) (the other possibility \(P(z) &lt; -T_k(z)\) is done by replacing \(P\) by \(-P\)). Without loss of generality, we can assume that \(\max_{x \in [-1,1]} |P(x) | &lt; 1\) (by potentially rescaling \(P\)). Then, the polynomial \(Q = P – T_k\) of degree \(k\) has alternatively strictly positive and negative values between \(-1\) and \(z&gt;1\). Indeed, \(Q(z) &gt; 0\), and \((-1)^j Q\big(\cos\! \big(\frac{j \pi}{k}\big)\big) &lt; 0 \) for all \(j = 0,\dots,k\). Therefore there are \(k+2\) alternating signs, and thus \(k+1\) zeros, which implies that \(Q=0\) since \(Q\) has degree \(k\). This is a contradiction with the existence of \(z\).</p>



<p class="justify-text">Note that for any \(\theta\), \(T_k( \cosh \theta) = \cosh (k\theta)\) (which can be shown by induction), and \(T_k\) is thus increasing on \([1,+\infty)\) with values quickly increasing as \(k\) grows. See an illustration below.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="303" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/chebyshev_beyong_one-1.gif" class="wp-image-1589" height="221" />First 33 Chebyshev polynomials, plotted between 1 and 4 in logarithmic scale. Note the exploding behavior as \(k\) grows.</figure></div>



<h2>Chebyshev acceleration</h2>



<p class="justify-text">We consider a recursion in \(\mathbb{R}^n\) of the form \(x_k = A x_{k-1} – b\), with \(A \in \mathbb{R}^{n \times n}\) a symmetric matrix and eigenvalues in \([-\rho,\rho]\) with \(\rho \in [0,1)\). Such recursions are ubiquitous in data science, as (1) gradient descent on a strongly-convex quadratic function, or (b) gossip for distributed averaging [<a href="http://www.web.stanford.edu/~boyd/papers/pdf/gossip.pdf">2</a>] (see an example in a section below).</p>



<p class="justify-text">The recursion converges to the unique (because \(\rho \in [0,1)\)) fixed point \(x_\ast \in \mathbb{R}^n\) such that \(x_\ast =  A x_\ast – b\). We have, by unrolling the recursion: $$ x_k – x_\ast = A ( x_{k-1} – x_\ast) = A^k (x_0 – x_\ast).$$</p>



<p class="justify-text">This leads to the usual exponential convergence rate \(\| x_k – x_\ast\|_2 \leq \rho^k \| x_0 – x_\ast\|_2\). In the following, writing \(\rho = 1 – ( 1-\rho)\) makes explicit the importance of \(1-\rho\), which is the gap between \(1\) and the largest eigenvalue of \(A\). Increasing this gap is equivalent to accelerating the convergence rate.</p>



<p class="justify-text">In order to speed-up convergence, a classical idea is to take linear combinations of all past iterates. That is, we consider \(y_k = \sum_{i=0}^k \nu_i^k x_i\) for some weights \(\nu_i^k\) such that \(\sum_{i=0}^k \nu_i^k=1\) (so that if all iterates are already at \(x_\ast\), then the weighted average stays there). We have $$ y_k – x_\ast =  \sum_{i=0}^k \nu_i^k ( x_i – x_\ast) = \sum_{i=0}^k \nu_i^k A^i (x_0-x_\ast) = P_k(A) (x_0-x_\ast),$$ where \(P_k(X) = \sum_{i=0}^k \nu_i^k X^i\) is a polynomial such that \(P_k(1)=1\).  Therefore, we have: $$  \| y_k – x_\ast\|_2 \leq \max_{\lambda \in [-\rho, \rho]} |P_k(\lambda)| \cdot \|x_0 – x_\ast\|_2.$$</p>



<p class="justify-text">In order to select the best polynomial, we are looking for \(P_k\) such that \(P_k(1)=1\) and \(\max_{\lambda \in [-\rho,\rho]}\! |P_k(\lambda)|\) is as small as possible. Up to mapping \([-\rho,\rho]\) to \([-1,1]\), we know from the extremal property above that the optimal polynomial is exactly a rescaled Chebyshev polynomial, that is, $$P_k(X) = \frac{T_k(X/\rho)}{T_k(1/\rho)}.$$</p>



<p class="justify-text">The maximal value on \([-\rho,\rho]\) is then \((T_k(1/\rho))^{-1}\). In order to compare to \(\rho^k\) (no acceleration), we can provide an equivalent of \([T_k(1/\rho)]^{-1/k}\) as \(\frac{\rho}{ 1+ \sqrt{1-\rho^2}}\) (see end of the post). There is no real acceleration when \(\rho\) is bounded away from 1, but as \(\rho\) tends to \(1\), this can be shown (see also the end of the post) to be equivalent to \(1 – \sqrt{2(1\!-\!\rho)}\), with the usual “square root” acceleration: \(1\!-\!\rho\) is essentially replaced by \(\sqrt{1\!-\!\rho}\).</p>



<p class="justify-text">We thus get an acceleration, but as is, computing \(y_k\) seems to require to store all values of \(x_1,\dots,x_k\), which is not practical. Since there is a second-order recursion for Chebyshev polynomials, one can derive one as well, directly for the sequence \((y_k)\).  A somewhat lengthy calculation (see end of the post) leads to the recursion $$ y_{k+1} = \omega_{k+1} ( Ay_{k} – b) + (1-\omega_{k+1}) y_{k-1}, $$<br />with a sequence \(\omega_{k+1}\) also defined by recursion as \(\omega_{k+1} = ( 1 – \frac{\rho^2}{4} \omega_k)^{-1}\), initialized with \(\omega_1 = 2\), \(y_0 = x_0\), \(y_1 = Ax_0 – b\). Therefore, on top of the usual computation of \(A y_k -b\), Chebyshev acceleration comes at no extra computational cost.</p>



<p class="justify-text"><strong>Simpler stationary recursion</strong>. In the recursion above, the parameter \(\omega_k\) varies with \(k\). A similar (then non totally optimal) acceleration can be obtained by replacing all \(\omega_k\)’s by their limit \(\omega\) when \(k\) tends to infinity, which is characterized by the equation \(\omega = ( 1-\frac{\rho^2}{4} \omega)^{-1}\) with smallest solutions \(\frac{ 1/\rho    – \sqrt{1/\rho^2 -1}}{\rho/2}\)  (see end of the post for detailed computations). The now stationary recursion then becomes $$ y_{k+1} = \omega ( Ay_{k} – b) + (1-\omega) y_{k-1}, $$ and is exponentially convergent with rate proportional to \(\rho \omega/2 =  \frac{1}{1/\rho + \sqrt{ 1/\rho^2 – 1}} = \frac{\rho}{1+ \sqrt{ 1 – \rho^2}}\). Thus, the recursion is simpler and the final speed asymptotically the same as full Chebyshev acceleration.</p>



<h2>Relationship with other acceleration mechanisms</h2>



<p class="justify-text"><strong>Non-adaptive schemes</strong>. As seen above for an affine operator \(F:\mathbb{R}^n \to \mathbb{R}^n\) (i.e., \(F(x) = Ax-b\)), Chebyshev acceleration takes a recursion of the form $$x_{k+1} = F(x_{k}),$$ and linearly combines iterates; it ends up creating second-order recursions of the form $$ y_{k+1} = \omega_{k+1} F(y_k) + (1-\omega_{k+1}) y_{k-1}, $$ with the same fixed points. Other formats (with fixed point preservation) can be considered such as $$ y_{k+1} = F(y_k) + \delta_{k+1}(y_k –  y_{k-1}),$$ or $$ y_{k+1} = F(y_k) + \delta_{k+1}(F(y_k) –  F(y_{k-1})), $$ for some constants \(\delta_{k+1}\).</p>



<p class="justify-text">When \(F\) is affine, the format does not matter much (and all end up being essentially equivalent), but for gradient descent algorithms where \(F(x) = x – \gamma f'(x)\) for some non-quadratic function \(f\) and \(\gamma\) a step-size, there is a difference, the last one corresponding to Nesterov acceleration (see a nice post on it <a href="https://blogs.princeton.edu/imabandit/2014/03/06/nesterovs-accelerated-gradient-descent-for-smooth-and-strongly-convex-optimization/">here</a>), and the one before to classical <a href="https://en.wikipedia.org/wiki/Gradient_descent">momentum</a>, also known as the heavy-ball method (see [<a href="https://arxiv.org/pdf/1412.7457">3</a>]).</p>



<p class="justify-text"><strong>Adaptive schemes</strong>. The methods above need to know the bound on the spectrum \(\rho\). They have to commit to such a value (which is typically only known through upper bounds) and cannot “get lucky”, that is, even if the best value \(\rho\) is known, they cannot benefit from additional better properties of the spectrum of \(A\) (e.g., clustered eigenvalues). The <a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">conjugate gradient</a> method, which accesses the matrix \(A\) with the slightly stronger oracle of computing \(Ax\) any \(x\) (and not only \(Ax – b\)), or Anderson acceleration (which does not need a stronger oracle), are adaptive for similar problems [<a href="https://epubs.siam.org/doi/pdf/10.1137/10078356X">4</a>, <a href="https://arxiv.org/pdf/1606.04133">5</a>]. Again, Chebyshev polynomials are present; probably more on this in future posts!</p>



<h2>Application to accelerated gossip</h2>



<p class="justify-text">A interesting linear recursion pops out in distributed optimization, where we assume that computers or processors are placed in \(n\) nodes in a network, and the goal is to minimize an average of function \(f_1,\dots,f_n\), each of them only accessible by the corresponding node. The nodes are allowed to communicate messages along each edge of a network. </p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="255" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/2dgrid.png" class="wp-image-1367" height="221" />Two-dimensional grid with \(d = 8 \times 8 = 64\) nodes.</figure></div>



<p class="justify-text">The simplest of such problem is the network averaging problem where \(f_i(\theta) = \frac{1}{2} (\theta – \xi_i)^2\), for a uni-dimensional parameter \(\theta\) and \(\xi \in \mathbb{R}^n\). The solution of this consensus is \(\theta_\ast = \frac{1}{n} \! \sum_{i=1}^n \! \xi_i\).</p>



<p class="justify-text">The gossip algorithm [<a href="http://www.web.stanford.edu/~boyd/papers/pdf/gossip.pdf">2</a>] consists in iteratively replacing the value \(\theta_i\) at a given node by a weighted average \(\sum_{j \sim i} W_{ij} \theta_j\) of the values at neighboring nodes (and node \(i\)). If all \(n\) nodes communicate simultaneously, then the vector \(\theta \) is replaced by \(W \theta\), hence a linear recursion $$ \theta_{k+1} = W \theta_{k},$$ initialized at \(\theta_0 = \xi\). Assuming that \(W\) is symmetric, with non-negative off-diagonal elements, and such that \(W 1_n = 1_n\) (where \(1_n \in \mathbb{R}^n\) is the vector of all ones), then all eigenvalues of \(W\) except the largest one are included in the interval \([-\rho, \rho]\), with \(\rho \in (0,1)\) for a connected graph. A simple such matrix \(W\) can be obtained from the adjacency matrix \(A\) of the graph, such that \(A_{ij} = 1\) if nodes \(i\) and \(j\) are connected, and zero otherwise, as \(W = I – \alpha L \), with \(L = {\rm Diag}(A 1_n) – A\) the <a href="https://en.wikipedia.org/wiki/Laplacian_matrix">Laplacian matrix</a> and \(\alpha\) selected so that the eigenvalues are all between \(-\rho\) and \(\rho\), except one, which is equal to 1 (see values of \(\rho\) and \(\alpha\) at the end of the post). We will see below that this extra eigenvalue which is equal to one is in fact not a problem for analyzing the convergence of this network averaging procedure.</p>



<p class="justify-text">When applying the gossip matrix \(W\) iteratively to \(\theta_0 = \xi\), the projection on the eigensubspace corresponding to the unit eigenvalue is not changed, while all other projections on the other eigensubspaces converge to zero at rate at most \(\rho^k\). Thus \(\theta_k\) converges to the constant vector \(\frac{1}{n} 1_n 1_n^\top \xi\) at rate \(\rho^k\), and thus to a constant vector, with the average \(\frac{1}{n} \! \sum_{i=1}^n \! \xi_i\) in all components.</p>



<p class="justify-text">Given that we have a linear recursion, we can use Chebyshev acceleration defined above and obtain substantial improvements, as illustrated below. For the use of this acceleration within distributed optimization algorithms, see [<a href="https://hal.archives-ouvertes.fr/hal-01478317/document">6</a>] and references therein.</p>



<figure class="wp-block-image is-resized"><img width="696" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/gossip_threeplots-3.gif" class="wp-image-1636" height="193" />Comparison of gossip algorithms on a two-dimensional grid (each cell correspond to a value \(\xi_i \in [-1,1]\) to average): (left) regular gossip, (center) accelerated second-order recursion with constant coefficients, (right) Chebyshev acceleration. Convergence is much faster with acceleration, (only) slightly better for Chebyshev acceleration, which is the optimal polynomial acceleration.</figure>



<h2>Conclusion</h2>



<p class="justify-text">Among classical classes of orthogonal polynomials, Chebyshev polynomials are special, because beyond being orthogonal, they satisfy extremal properties that are particularly useful in numerical analysis.</p>



<p class="justify-text">In future posts, I plan to go over Jacobi polynomials (which include Legendre, Gegenbauer and Chebyshev polynomials), Hermite polynomials, and finally Bernoulli polynomials (which are not orthogonal but still very special). For all of these, there are natural applications in machine learning.</p>



<p class="justify-text"><strong>Acknowledgements</strong>. I would like to thank Raphaël Berthier for proofreading this blog post and making good clarifying suggestions.</p>



<h2>References</h2>



<p class="justify-text">[1] John C. Mason, and David C. Handscomb. <a href="https://www.crcpress.com/Chebyshev-Polynomials/Mason-Handscomb/p/book/9780849303555">Chebyshev polynomials. Chapman and Hall/CRC</a>, 2002.<br />[2] Stephen Boyd, Arpita Ghosh, Balaji Prabhakar, Devavrat Shah. <a href="http://www.web.stanford.edu/~boyd/papers/pdf/gossip.pdf">Randomized gossip algorithms</a>. <em>IEEE/ACM Transactions on Networking</em>, 14:2508-2530, 2006.<br />[3] Euhanna Ghadimi, Hamid Reza Feyzmahdavian, and Mikael Johansson. <a href="https://arxiv.org/pdf/1412.7457">Global convergence of the heavy-ball method for convex optimization</a>. <em>European Control Conference (ECC)</em>, 2015.<br />[4] Homer F. Walker, Peng Ni. <a href="https://epubs.siam.org/doi/pdf/10.1137/10078356X">Anderson acceleration for fixed-point iterations</a>. <em>SIAM Journal on Numerical Analysis</em>, 49(4):1715-1735, 2011.<br />[5] Damien Scieur, Alexandre d’Aspremont, Francis Bach. <a href="https://arxiv.org/pdf/1606.04133">Regularized Nonlinear Acceleration</a>. <em>Mathematical Programming</em>, 2018.<br />[6] Kevin Scaman, Francis Bach, Sébastien Bubeck, Yin-Tat Lee, Laurent Massoulié. <a href="https://hal.archives-ouvertes.fr/hal-01478317/document">Optimal algorithms for smooth and strongly convex distributed optimization in networks</a>.  <em>Proceedings of the International Conference on Machine Learning (ICML)</em>, 2017.<br />[7] Mieczysław A. Kłopotek. <a href="https://arxiv.org/pdf/1707.05210">Spectral Analysis of Laplacians of an Unweighted and Weighted Multidimensional Grid Graph — Combinatorial versus Normalized and Random Walk Laplacians</a>. Technical report, ArXiv:1707.05210, 2019.</p>



<h2>Detailed Computations</h2>



<p class="justify-text"><strong>Limit of </strong>\([T_k(1/\rho)]^{-1/k}\). For \(z \geq 1\), then a well-known property of Chebyshev polynomials is that \(T_k(z) = \cosh [ k \, {\rm acosh} (z)]\) (which can be shown by induction using basic <a href="https://en.wikipedia.org/wiki/Hyperbolic_function">hyperbolic trigonometry</a> identities). Moreover, we have \({\rm acosh} (z) = \log( z + \sqrt{z^2-1} )\) and thus $$T_k(z) = \frac{1}{2} \big[ \big( z + \sqrt{z^2-1} \big)^k + \big(z – \sqrt{z^2-1}\big)^k  \big].$$ For \(z = 1/\rho\), and taking limits, we get that \([T_k(z)]^{1/k}\) tends to \( z + \sqrt{z^2-1}\), which leads to the limit \(\frac{\rho}{ 1+ \sqrt{1-\rho^2}}\) for \([T_k(z)]^{-1/k}\). Then a classical Taylor expansion in \(1-\rho\) leads to \(1 – \sqrt{2(1-\rho)}\).</p>



<p class="justify-text"><strong>Recurrence for Chebyshev acceleration</strong>. We have, using the recursion for Chebyshev polynomials $$y_{k+1} – x_\ast = \frac{ 2 }{T_{k+1}(1/\rho)} (A/\rho) T_k(A/\rho) ( x_0 – x_\ast) \ – \frac{ 1  }{T_{k+1}(1/\rho)} T_{k-1}(A/\rho) ( x_0 – x_\ast).$$ Using the equality \(x_\ast = A x_\ast -b\), the terms in \(x_\ast\) cancel (they have to anyway, because \(P_k(1)=1\)). We then get $$y_{k+1}  = \frac{  (2/\rho) T_{k}(1/\rho)}{T_{k+1}(1/\rho)}  ( A y_k – b) \, – \frac{ T_{k-1}(1/\rho)  }{T_{k+1}(1/\rho)} y_{k-1}.$$</p>



<p>Using \(T_{k-1}(1/\rho) = (2/\rho) T_{k}(1/\rho) – T_{k+1}(1/\rho)\), and denoting \(\omega_{k+1} =  \frac{  (2/\rho) T_{k}(1/\rho)}{T_{k+1}(1/\rho)}\), we get $$y_{k+1} = \omega_{k+1} ( A y_{k} – b) + ( 1- \omega_{k+1}) y_{k-1}.$$ Reusing one last time the Chebyshev recursion, we get $$\omega_{k+1}^{-1} = \frac{T_{k+1}(1/\rho)}{  (2/\rho) T_{k}(1/\rho)}= 1 – \frac{T_{k-1}(1/\rho)}{  (2/\rho) T_{k}(1/\rho)} =1  – \frac{\rho^2}{4} \omega_{k},$$ which is the desired recursion.</p>



<p class="justify-text"><strong>Convergence of stationary recursion</strong>. The roots of \(\omega = ( 1-\frac{\rho^2}{4} \omega)^{-1}\) are the ones of \(\frac{\rho^2}{4} \omega^2 – \omega + 1 = 0\), with smallest solutions \(\omega = \frac{ 1/\rho   – \sqrt{1/\rho^2 -1}}{\rho/2}\). In order to study the second-order recursion $$ y_{k+1} = \omega ( Ay_{k} – b) + (1-\omega) y_{k-1}, $$ with constant coefficient, we need to compute the roots of \(r^2 = \omega \lambda r + (1-\omega)\), for \(|\lambda| \leq \rho\). The discriminant of this equation is \(\lambda^2 \omega^2 + 4 (1-\omega) \leq \rho^2 \omega^2 + 4(1-\omega) = 0\), and thus the roots are complex conjugate with squared modulus \((\omega\ – 1) = \frac{1}{4} \rho^2 \omega^2\) independent of \(\lambda\). Thus, as \(k\) tends to infinity, \(\| y_k  – x_\ast\|_2^{1/k}\) tends to \(\frac{1}{2} \rho \omega =   ( 1/\rho – \sqrt{ 1/\rho^2 – 1} ) = \frac{1}{1/\rho + \sqrt{ 1/\rho^2 – 1}}\), which is exactly the rate for Chebyshev acceleration.</p>



<p class="justify-text"><strong>Eigenvalues of the Laplacian matrix of a square grid</strong>. Given a chain of length \(m\) such as depicted below, the \(m \times m\) Laplacian matrix can be shown (see [<a href="https://arxiv.org/pdf/1707.05210">7</a>]) to have eigenvalues \(2 + 2 \cos \frac{k\pi}{m}\) for \(k =1,\dots,m\).</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="350" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/1dgrid.png" class="wp-image-1562" height="24" />One-dimensional grid with \(m = 8\).</figure></div>



<p class="justify-text">For a two-dimensional grid of size \(m \times m\), then the \(m^2 \times m^2\) Laplacian matrix can be shown (see [<a href="https://arxiv.org/pdf/1707.05210">7</a>]) to have eigenvalues \(4 + 2\cos \frac{k_1\pi}{m} + 2\cos \frac{k_2\pi}{m}\) for \(k_1,k_2 =1,\dots,m\). Therefore, the second smallest eigenvalue is \(\lambda_\min = 2 – 2 \cos \frac{\pi}{m}\) and the largest eigenvalue is \(\lambda_\max = 4 + 4  \cos \frac{\pi}{m}\). We then select \(\alpha\) such that \(1-\alpha \lambda_\min = \rho\) and \(1-\alpha \lambda_\max = -\rho\), leading to \(\alpha = \frac{2}{\lambda_\min + \lambda_\max} = \frac{2}{6 + 2 \cos \frac{\pi}{m}}\) and finally \(\rho = \frac{\lambda_\max – \lambda_\min}{\lambda_\max + \lambda_\min} = \frac{2 +6  \cos \frac{\pi}{m} }{6 + 2 \cos \frac{\pi}{m}}\sim \frac{8 – 3 \frac{\pi^2}{m^2}}{8 –  \frac{\pi^2}{m^2}}\sim 1 – \frac{\pi^2}{4 m^2}\). Thus, as a function of \(n = m^2\), the eigengap is proportional to \(1/n\).</p>



<p class="justify-text">More generally, for the grid of size \(m\) in dimension \(d\), then we get \(\lambda_\min = 2 – 2 \cos \frac{\pi}{m}\) and \(\lambda_\max = 2d + 2d  \cos \frac{\pi}{m}\), and \(\rho = \frac{\lambda_\max – \lambda_\min}{\lambda_\max + \lambda_\min} = \frac{2d-2 +(2d+2)  \cos \frac{\pi}{m} }{2d+2 + (2d-2) \cos \frac{\pi}{m}}\sim \frac{4d – (d+1) \frac{\pi^2}{m^2}}{4d –  (d-1)\frac{\pi^2}{m^2}}\sim 1 – \frac{\pi^2}{2d m^2}.\) Thus, as a function of \(n = m^d\), the eigengap is proportional to \(1/n^{2/d}\). Moreover, when \(m\) is large, the normalizing factor \(\alpha\) tends to \(1/(2d)\).</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/chebyshev-polynomials/"><span class="datestr">at November 04, 2019 07:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=860">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/cursed-kernels/">Are all kernels cursed?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">The word “kernel” appears in many areas of science (it is even worse in French with “noyau”); it can have different meanings depending on context (see <a href="http://jeff560.tripod.com/k.html">here</a> for a nice short historical review for mathematics).</p>



<p class="justify-text">Within machine learning and statistics, kernels are used in two related but different contexts, with different definitions and some kernels like the beloved and widely used Gaussian kernel being an example of both. This has been and still is a source of confusion that I would like to settle for good with this post! In particular, these two types of kernels have different properties regarding their resistance (or lack thereof) to the curse of dimensionality.</p>



<p class="justify-text">Throughout this post, for simplicity, I will assume that data live in \(\mathbb{R}^d\), noting that most concepts can be extended to any space (e.g., images, graphs, etc.): this is the beauty of the (positive-definite) kernel trick but this is for another post. </p>



<p class="justify-text">I will consider a kernel function \(k\), which is a real-valued function defined on \(\mathbb{R}^d \times \mathbb{R}^d\). I will always assume that the kernel \(k\) is <strong>symmetric</strong>, that is, \(k(x,y) = k(y,x)\) for any \(x,y \in \mathbb{R}^d\).</p>



<p class="justify-text">An important object of study will be the <strong>kernel matrix</strong> \(K \in \mathbb{R}^{n \times n}\) obtained from \(n\) observations \(x_1,\dots,x_n \in\mathbb{R}^d\), which is defined through $$K_{ij} = k(x_i,x_j).$$ Given the symmetry assumption on \(k\), it will be a symmetric matrix (hence with real eigenvalues).</p>



<p class="justify-text">I will now present the two types of kernels, (1) <strong>non-negative</strong> kernels and (2) <strong>positive-definite</strong> kernels. For kernels of the form \(k(x,y) = q(x-y)\) for a function \(q: \mathbb{R}^d \to\mathbb{R}\), the two definitions will correspond to (1) \( q \) has non-negative values, and (2) the <em>Fourier transform</em> of \(q\) has non-negative values. This leads to different types of algorithms that I now present.</p>



<h2>I. Non-negative kernels</h2>



<p class="justify-text"><strong>Definition</strong> (<em>non-negative kernels</em>). A kernel \(k: \mathbb{R}^d \times \mathbb{R}^d \to \mathbb{R}\) is non-negative, if $$\forall x,y \in \mathbb{R}^d, \ k(x,y) \geq 0.$$</p>



<p class="justify-text">An equivalent definition is that all kernel matrices have non-negative elements. The explicit terminology <em>pointwise</em> non-negativity is sometimes used.</p>



<p class="justify-text">The most classical example is the Gaussian kernel, defined as $$k(x,y) =  \exp\Big( -\frac{1}{2 \sigma^2} \| x – y\|_2^2\Big),$$ where \(\| z\|_2^2 = \sum_{i=1}^d z_i^2\) is the squared \(\ell_2\)-norm (I have not added any normalizing constant because most algorithms ignore it). Other examples are shown below for \(d=1\).</p>



<figure class="wp-block-image is-resized"><img width="759" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/windows-1024x229.png" class="wp-image-1024" height="169" />Various kernels plotted at \(y = 0\): Gaussian kernel \(\exp\big( – \frac{1}{2\sigma^2} (x-y)^2\big)\), Exponential kernel \(\exp\big( – \frac{1}{\sigma} |x-y|\big)\), Cauchy kernel \(\frac{1}{1+(x-y)^2 / \sigma^2}\), and triangular kernel \(\max \big\{ 0, 1 – \frac{|x-y| }{2 \sigma} \big\}\).</figure>



<p class="justify-text"> There are many more choices (see <a href="https://en.wikipedia.org/wiki/Kernel_(statistics)#Kernel_functions_in_common_use">here</a>), but the functions below all also have a non-negative Fourier transform, which will make them also a member of the other class of kernels (see the second part of the post). </p>



<h3>Kernel smoothing (a.k.a. <a href="https://en.wikipedia.org/wiki/Kernel_regression">Nadaraya-Watson estimator</a>)</h3>



<p class="justify-text">This is a version of <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density estimation</a> for supervised problems, which for simplicity I will describe with real-valued outputs (it can directly be extended to any <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">generalized linear model</a> to tackle other types of outputs). Given \(n\) observations \((x_i,y_i) \in \mathbb{R}^d \times \mathbb{R}\), \(i=1,\dots,n\), the goal of kernel smoothing is to estimate a function \(\hat{f}: \mathbb{R}^d \to \mathbb{R}\) that can predict \(y\) from \(x\). It is defined at any test point \({x} \in \mathbb{R^d}\): $$\hat{f}(x) = \frac{\sum_{i=1}^n k(x,x_i) y_i}{\sum_{i=1}^n k(x,x_i)}.$$</p>



<p class="justify-text">See an illustrative example below in one dimension for the Gaussian kernel. The non-negativity of the kernel is important to make sure the denominator above is positive.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="500" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/nadaraya-2-1024x447.png" class="wp-image-988" height="218" />Nadaraya-Watson estimation. Left: function \(f\), with noisy observations \(y_i = f(x_i) + \varepsilon_i\). Right: kernel regression estimate \(\hat{f}\).</figure></div>



<p class="justify-text"><strong>Algorithms</strong>. In terms of computational complexity, computing \(\hat{f}(x)\) for a single \(x\) takes naively time \(O(n)\) to go through the \(n\) data points, but efficient indexing techniques such as <a href="https://en.wikipedia.org/wiki/K-d_tree">k-d trees</a> can be used to reduce this cost when \(d\) is not too large. The vector of prediction \(\hat{y}\) for the \(n\) observations, can be obtained as $$ \hat{y} = {\rm Diag}(K 1_n)^{-1} K y .$$ The complexity is \(O(n^2)\) but can also be made linear in \(n\) (in particular when the kernel matrix is in addition positive semi-definite, i.e., when the kernel is both non-negative and positive-definite).</p>



<p class="justify-text">It is important to note that the only free parameter is the bandwidth \(\sigma\), while there will be an extra regularization parameter for positive definite kernels.</p>



<p class="justify-text"><strong>Choice of bandwidth</strong>. As illustrated below, for kernels of the form \(k(x,y) = q\big( \frac{x-y}{\sigma} \big)\), like the Gaussian kernel, the choice of the <em>bandwidth</em> parameter \(\sigma\) is crucial.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="257" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/nadaraya.gif" class="wp-image-989" height="228" />Varying \(\sigma\) from small (leading to overfitting when \(\sigma\) is too small) to large (leading to underfitting when \(\sigma\) is too large).</figure></div>



<p class="justify-text">Note here that when \(\sigma\) tends to zero, then the estimated function \(\hat{f}\) interpolates the data (but without any wild behavior between input observations), while when \(\sigma\) grows, the function \(\hat{f}\) tends to a constant. We now consider only these translation-invariant kernels.</p>



<p class="justify-text"><strong>Statistical properties</strong>. Kernel smoothing is a simple instance of a <a href="https://en.wikipedia.org/wiki/Nonparametric_statistics">non-parametric</a> estimation procedure, that can in principle adapt to any underlying function \(f\) that generated the outputs (after additive noise is added, so that the observations are \(y_i = f(x_i) + \varepsilon_i\), with \(\varepsilon_i\) being zero-mean). This estimator is commonly used in low dimensions (e.g., \(d\) less than \(10\) or \(20\)). In higher dimensions however, it suffers from the <em>curse of dimensionality</em> common to most methods based on non-negative kernels.</p>



<p class="justify-text"><strong>Consistency and curse of dimensionality</strong>. Kernel regression is one instance of local averaging techniques such as <a href="https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm">k-nearest-neighbors</a>, where for any test point \(x\), the outputs \(y_i\) corresponding to inputs \(x_i\) which are closer to \(x\) are given higher weights. For simplicity, I will only consider the kernel \(k(x,y) = 1_{\| x – y\|_\infty \leq \sigma}\) where \(\| z\|_\infty = \max\{ |z_1|,\dots,|z_d|\}\) is the \(\ell_\infty\)-norm of \(z\). The discussion below extends with more technicalities to all translation-invariant kernels.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="389" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/filling_space_cube-3.png" class="wp-image-1086" height="178" />\(n=11\) observations in dimension \(d=2\), with a test point \(\hat{x}\). Only three observations within distance \(\sigma\) in \(\ell_\infty\)-norm are counted for computing \(\hat{f}(x)\).</figure></div>



<p class="justify-text">In order to obtain a <em>consistent</em> estimator \(\hat{f}\) that converges to the true underlying function \(f\) when \(n\) tends to infinity, the bandwidth \(\sigma\) should depend on \(n\) (and hence denoted \(\sigma_n\)), with two potentially conflicting goals:</p>



<ul class="justify-text"><li><em>Vanishing bias</em>: The bandwidth \(\sigma_n\) should be small enough so that the underlying function \(f\) does not vary much in a ball of radius \(\sigma_n\) around \(x\). When \(f\) is assumed Lipschitz-continuous, the deviation is proportional to \(\sigma_n\). Therefore, the error in estimating \(f\) is proportional to \(\sigma_n\) and we thus need $$ \sigma_n \to 0.$$ </li><li><em>Vanishing variance</em>: Since the observations \(y_i = f(x_i) + \varepsilon_i\) are noisy, around some test point \(\hat{x}\), we need to average sufficiently many of them so that the noise is averaged out, that is, for any test point \(\hat{x}\), the number of observations that are in a ball of radius \(\sigma_n\) should tend to infinity with \(n\). With a simple covering argument, this requires (at least) $$ n \sigma_n^d \to +\infty.$$ This illustrated below for the specific kernel I chose, which is based on the \(\ell_\infty\)-norm.</li></ul>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="456" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/covering_cube-2.png" class="wp-image-1093" height="211" />Assuming the support of the distribution of inputs is an \(\ell_\infty\)-ball of radius \(1/2\) in dimension \(d=2\), then with \(\sigma_n = 1/8\), in order to have a consistent estimation for each of the \((2\sigma_n)^{-d} = 16\) candidate test points \(\hat{x}_1,\dots,\hat{x}_{16}\), the number of points in each of the \(m = (2\sigma_n)^{-d}\) balls has to grow unbounded and thus \(n/m = n (2\sigma_n)^{d}\) has to grow unbounded.</figure></div>



<p class="justify-text">Therefore,  in order to obtain a consistent estimator, the bandwidth of translation-invariant kernels has to go to zero slowly enough, slower than \(n^{-1/d}\), and the final estimation error is converging to zero, but slower than \(n^{-1/d}\).  This is the usual <a href="https://en.wikipedia.org/wiki/Curse_of_dimensionality">curse of dimensionality</a>: in order to obtain a certain error \(\epsilon\), the number of observations has to grow at least as \(\epsilon^{-d}\), and thus exponentially in dimension. When the underlying function has weak smoothness properties (here just Lipschitz-continuous), such a dependence in \(d\) is provably unavoidable in general [1, 2].</p>



<p class="justify-text"><strong>Resistance to the curse of dimensionality</strong>. If the true function \(f\) happens to be more regular (i.e., with bounded higher order derivatives), kernel smoothing cannot adapt to it, that is, the rates of convergence still have the bad dependence on \(d\), while other techniques can have an improved dependence, such as positive-definite kernel methods below, or improved local averaging techniques based on local polynomials [1, 2].</p>



<p class="justify-text">Note that since the curse of dimensionality comes primarily from a covering argument of the input space, if the distribution of inputs is supported on a low-dimensional manifold, the dependence in \(d\) can be replaced by the same dependence, but now in the dimension of the manifold (see, e.g., [<a href="https://projecteuclid.org/download/pdf_1/euclid.lnms/1196794952">7</a>]).</p>



<p class="justify-text">Kernel smoothing is one particular instance of methods based on negative-kernels. <a href="https://en.wikipedia.org/wiki/Kernel_density_estimation">kernel density estimation</a> is also commonly used. Spectral methods for <a href="https://en.wikipedia.org/wiki/Spectral_clustering">clustering</a> and <a href="https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction">non-linear dimensionality reduction</a>, and Laplacian-based semi-supervised learning [<a href="https://www.aaai.org/Papers/ICML/2003/ICML03-118.pdf">8</a>], also use non-negative kernels, with similar conditions on the bandwidth \(\sigma\) (see [<a href="http://www.jmlr.org/papers/volume8/hein07a/hein07a.pdf">3</a>]) and similar curses of dimensionality.</p>



<p>I now turn to the other type of kernels.</p>



<h2>II. Positive-definite kernels</h2>



<p class="justify-text"><strong>Definition</strong> (<em>positive-definite kernels</em>). A kernel \(k: \mathbb{R}^d \times \mathbb{R}^d \to \mathbb{R}\) is positive-definite, if for any finite set of elements \(x_i,\dots,x_n\) in \(\mathbb{R}^d\), the kernel matrix is positive-semidefinite (that is, all its eigenvalues are non-negative).</p>



<p>The classical examples are:</p>



<ul class="justify-text"><li><em>Polynomial kernels</em>: \(k(x,y) = (x^\top y)^r\) for \(r\) a positive integer.</li><li><em>Translation-invariant kernels</em>: they are of the form \(k(x,y) = q(x-y)\) for a function \(q: \mathbb{R}^d \to \mathbb{R}\) with a (pointwise) <strong>non-negative <a href="https://en.wikipedia.org/wiki/Fourier_transform">Fourier transform</a></strong>, which is equal to\(\displaystyle \hat{q}(\omega) = \int_{\mathbb{R}^d} \! \! q(x) e^{-i \omega^\top x} dx\), and assumed to exist. For these, we see a clear distinction between non-negative kernels of that form, for which \(q\) (and not \(\hat{q}\)) has to have non-negative elements (note that all examples given at the beginning of the post are both, and that there are two hidden Fourier transform pairs).</li><li><em>Kernels on structured objects</em>: when the observations are not vectors in \(\mathbb{R}^d\), such as graphs, trees,  measures, on in fact any objects, specific kernels can be designed with nice properties and many applications, see, e.g., [4].</li></ul>



<p class="justify-text"></p>



<h3>Kernel trick and representer theorem</h3>



<p class="justify-text">The key consequence of positive-definiteness (with surprisingly no other assumptions needed regarding \(k\)) is the existence of an (essentially unique) Hilbert space \(\mathcal{F}\), called the <em>feature space</em>, and a function \(\Phi: \mathbb{R}^d \to \mathcal{F}\), called the <em>feature map</em>, such that $$\forall x,y \in \mathbb{R}^d, \ k(x,y) = \langle \Phi(x), \Phi(y) \rangle_\mathcal{F}.$$ This is non-trivial to show and due to <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">Aronszajn and Moore</a> in the 1950s.</p>



<p class="justify-text">From a positive-definite kernel, it is to common to define the space of functions \(f\) which are linear in the feature vector \(\Phi\), that is, of the form \(f(x) = \langle w, \Phi(x) \rangle_{\mathcal{F}}\), for a certain \(w \in \mathcal{F}\). When minimizing an empirical risk on \(n\) observations \(x_1,\dots,x_n \in \mathbb{R}^d\), regularized by the norm \(\| w\|_\mathcal{F}\), the celebrated <a href="https://en.wikipedia.org/wiki/Representer_theorem">representer theorem</a> (which is a direct consequence of Pythagoras’ theorem) states that \(w\) is of the form \(w = \sum_{j=1}^n \alpha_j \Phi(x_j)\), and thus \(f\) is of the form $$f(x) = \sum_{j=1}^n \alpha_j \langle \Phi(x), \Phi(x_j) \rangle_\mathcal{F} =  \sum_{j=1}^n \alpha_j k(x,x_j),$$ for a certain vector \(\alpha \in \mathbb{R}^n\).</p>



<h3>Regularization through positive-definite kernels</h3>



<p class="justify-text">Given the function \(f\) defined as \(f(x) =  \langle w, \Phi(x) \rangle_{\mathcal{F}}\), the regularizer \(\| w\|_\mathcal{H}\) defines a regularization on the prediction function \(f\). This is a key property of positive-definite kernels: they lead to an <em>explicit</em> regularization \(\Omega(f)^2\) on the prediction function (this in fact defines a Hilbert space of functions, which is often referred to as the <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">reproducing kernel Hilbert space</a>).</p>



<p class="justify-text">For the translation-invariant kernels \(k(x,y) = q(x-y)\), it happens to be equal to (see [4]) $$ \Omega(f)^2 =\frac{1}{(2\pi)^d} \int_{\mathbb{R}^d} \!\! \frac{|\hat{f}(\omega)|^2 }{\hat{q}(\omega)} d\omega,$$ where \(\hat{f}\) and \(\hat{q}\) are the Fourier transforms of \(f\) and \(q\). For example, for \(d=1\) and the exponential kernel \(q(x-y) = \exp(-|x-y|/\sigma)\), we have \(\hat{q}(\omega) = 2 \sigma / ( 1 + \sigma^2 \omega^2)\), and \(\displaystyle \Omega(f)^2= \frac{1}{2\sigma} \int_{\mathbb{R}} \! |f(x)|^2 dx +\frac{ \sigma}{2} \int_{\mathbb{R}}\! |f'(x)|^2 dx \), which is a squared <a href="https://en.wikipedia.org/wiki/Sobolev_space">Sobolev norm</a> (this extends to higher dimensions as well).</p>



<p class="justify-text">In addition, for the Gaussian kernel \(q(x-y) = \exp \big(-(x-y)^2/(2\sigma^2) \big)\), we have \(\hat{q}(\omega) = \sigma \sqrt{2\pi} \exp( – \sigma^2 \omega^2 / 2)\), and \(\displaystyle \Omega(f)^2 = \frac{1}{\sigma \sqrt{2\pi}}\sum_{k=0}^\infty \frac{\sigma^{2k}}{2^k k!}\! \int_{\mathbb{R}} \!|f^{(k)}(x)|^2 dx\), and all derivatives are penalized (also, this extends in higher dimensions). </p>



<p class="justify-text">Finally, some versions of splines can be obtained from positive-definite kernels (and kernel ridge regression below exactly leads to <a href="https://en.wikipedia.org/wiki/Smoothing_spline">smoothing splines</a>).</p>



<h3>Kernel ridge regression</h3>



<p class="justify-text">As a consequence of the representer theorem above, when using the square loss, and for a vector of outputs / responses \(y \in \mathbb{R}^n\), when minimizing $$ \frac{1}{n} \sum_{i=1}^n \big( y_i – \langle w, \Phi(x_i) \rangle_{\mathcal{F}} \big)^2 + \lambda \| w\|_\mathcal{F}^2,$$ the \(i\)-th prediction \( \langle w, \Phi(x_i) \rangle_{\mathcal{F}}\) is equal to \(\sum_{j=1}^n \alpha_j \langle \Phi(x_j),\Phi(x_i)\rangle_{\mathcal{F}}=(K\alpha)_i\) and \(\| w\|_\mathcal{F}^2\) is equal to \(\sum_{i,j=1}^n \alpha_i \alpha_j K_{ij} = \alpha^\top K \alpha\). This leads to the equivalent problem of minimizing $$ \frac{1}{n} \| y – K \alpha \|_2^2 + \lambda \alpha^\top K \alpha,$$ with a solution \(\alpha = ( K + n\lambda I)^{-1} y \in \mathbb{R}^n\), and prediction vector \(\hat{y} = K ( K+ n\lambda  I)^{-1} y \in \mathbb{R}^n\).</p>



<p>See an illustration below for the Gaussian kernel.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="444" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/krr-1-1024x415.png" class="wp-image-1127" height="180" />Kernel ridge regression estimation. Left: function \(f(x)\), with noisy observations. Right: kernel ridge regression estimate.</figure></div>



<p class="justify-text"><strong>Running-time complexity</strong>. Implemented naively in a few lines of code, the complexity will be \(O(n^2)\) for computing the kernel matrix \(K\) and \(O(n^3)\) for solving the linear system to obtain \(\alpha\). This can be greatly reduced using <a href="https://en.wikipedia.org/wiki/Low-rank_matrix_approximations">low-rank approximations</a> (a.k.a. Nyström’s method) or random features [<a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">5</a>]. More on these in future posts.</p>



<p class="justify-text"><strong>Do we really need positive-definiteness?</strong> In the objective function above, the only place where positive-definiteness seems needed is for the the regularization term \(\alpha^\top K \alpha\) to be convex, which automatically leads to a well-behaved optimization problem. We could do the same by replacing it by \(\| \alpha\|_2^2\) and no need for \(K\) to be positive-semidefinite. While this is implementable, it lacks a clear interpretation in terms of regularization of the prediction function and some of the techniques designed to avoid a running time complexity of \(O(n^2)\) cannot be used.</p>



<p class="justify-text"><strong>Choice of bandwidth</strong>. Compared to the Nadaraya-Watson estimator, for translation-invariant kernels, there are two parameters, the kernel bandwidth \(\sigma\) and the regularization parameter \(\lambda\). Below, we vary \(\lambda\) for two fixed values of \(\sigma\). A few points to note:</p>



<ul class="justify-text"><li><em>Strong overfitting for small \(\lambda\)</em>: compared to Nadaraya-Watson, which was interpolating nicely for small \(\sigma\), kernel ridge regression overfits a lot for small \(\lambda\), with a wild behavior between observed inputs.</li><li><em>Robustness to larger \(\sigma\)</em>: with a proper regularization parameter \(\lambda\), larger values of \(\sigma\) can still lead to good predictions (as opposed to Nadaraya-Watson estimation). Another illustration of the robustness to larger \(\sigma\) is the possibility of having consistent estimation without a vanishing bandwidth \(\sigma\) (see below).</li></ul>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="438" alt="" src="https://francisbach.com/wp-content/uploads/2019/10/krr-1.gif" class="wp-image-1128" height="177" />Varying \(\lambda\) from small (leading to overfitting when \(\lambda\) is too small) to large (leading to underfitting when \(\lambda\) is too large). Two values of the bandwidth \(\sigma\).</figure></div>



<h3>Consistency and curse of dimensionality</h3>



<p class="justify-text">Positive-definite kernel methods are also non-parametric estimation procedures. They can adapt to any underlying function, if the kernel is <em><a href="https://en.wikipedia.org/wiki/Kernel_embedding_of_distributions#Universal_kernels">universal</a></em>.  For translation-invariant kernels, a sufficient condition is a <em>strictly positive</em> Fourier transform (which is typically true for all bandwidths).</p>



<p class="justify-text">In most analyses, the bandwidth \(\sigma\) is <em>fixed</em>, and the regularization parameter \(\lambda\) goes to zero with \(n\) (a notable exception is the nice paper from the Vert brothers [<a href="http://www.jmlr.org/papers/volume7/vert06a/vert06a.pdf">6</a>]). With the proper decay of \(\lambda\), as \(n\) grows, we obtain a consistent estimator.</p>



<p class="justify-text">When only assuming Lipschitz-continuity of the true underlying function, the rate of convergence also has a bad behavior in dimension \(d\), typically of the form \(O(n^{-1/d})\) (any way, such dependence is provably unavoidable, this is the usual curse of dimensionality for regression in high dimension).</p>



<p class="justify-text"><strong>Adaptivity to smooth functions</strong>. A key benefit of using positive-definite kernels is that if the underlying function is smoother than simply Lipschitz-continuous, then the convergence rates do improve with a proper choice of \(\lambda\). In the most favorable situation where the true regression function \(f\) belongs to the space of functions defined by the kernel, then the convergent rate is less than \(O(n^{-1/4})\). This may however require functions which are too smooth (in particular for the Gaussian kernel, these functions are infinitely differentiable). </p>



<p class="justify-text">However, kernel methods also lead to consistent estimation beyond this favorable situation, and such methods are adaptive to all functions which are in between Lipschitz-continuous functions (essentially bounded first order derivatives) and these potentially very smooth functions. For example, for the Gaussian kernel, as soon as it is \(s\)-times differentiable with bounded \(s\)-th order derivative, with \(s&gt;d/2\), then the convergence rate does not exhibit any more a dependence in \(d\) in the power of \(n\), i.e., the convergence rate is also less than \(O(n^{-1/4})\). If \(s\) is smaller than \(d/2\), then the convergence rate is in between \(O(n^{-1/4})\) and \(O(n^{-1/d})\), essentially of the form \(O(n^{-2s/d})\) or \(O(n^{-s/d})\) (for precise details, see [1, 2]).</p>



<p class="justify-text">This adaptivity requires the proper regularization parameter \(\lambda\). For the Gaussian kernel, as outlined in [<a href="http://www.jmlr.org/proceedings/papers/v30/Bach13.pdf">9</a>], it may need to be very small (e.g., exponentially decaying with \(n\)), leading to optimization problems which are strongly ill-conditioned. More on this in a future post.</p>



<h2>Conclusion</h2>



<p class="justify-text"><em>Are all kernels cursed?</em> In this post, I have tried to highlight the difference between the two types of kernels, (1) the (pointwise) non-negative ones, which lead to local averaging techniques that cannot avoid the curse of dimensionality, even in favorable situations, and (2) the positive-definite ones, which exhibit some form of adaptivity.</p>



<p class="justify-text">If you went that far into the post, you are probably a kernel enthusiast, but if you are not and wondering why you should care about kernels in the neural network age, a few final thoughts: </p>



<ul class="justify-text"><li><strong>What are the adaptivity properties of neural networks</strong>? They are indeed superior; for example, with a single hidden layer, neural networks are adaptive to linear structures, such as dependence on a subset of variables, while kernels with similar architectures are not [<a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">10</a>]. However, neural networks do not lead (yet) to precise guarantees on the solvability of the corresponding optimization problems.</li><li><strong>Can we learn with positive-definite kernels with lots of data</strong>? Yes! With proper tools such as random features [<a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">5</a>] or column sampling, and with the proper and very nice pre-conditioning of [<a href="https://papers.nips.cc/paper/6978-falkon-an-optimal-large-scale-kernel-method.pdf">11</a>], kernels can be used with ten millions of observations or more.</li><li><strong>Can we apply kernels to computer vision</strong>? Yes! See the nice <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">blog post</a> of Julien Mairal.</li><li><strong>Kernel methods as “theoretically tractable” high-dimensional models</strong>. In recent years, new ideas have emerged from training overparameterized neural networks, with (1) global convergence guarantees [<a href="https://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">12</a>, <a href="https://arxiv.org/pdf/1804.06561">13</a>], some of them related to kernel methods [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">14</a>, <a href="https://arxiv.org/pdf/1812.07956">15</a>], and (2) a new phenomenon called “double descent” [<a href="https://arxiv.org/pdf/1812.11118">16</a>], which has a nice theoretical explanation / illustration with kernel methods. Again topics for future (shorter) posts.</li></ul>



<h2>References</h2>



<p class="justify-text">[1] László Györfi, Michael Kohler, Adam Krzyzak, Harro Walk. <a href="https://www.springer.com/gp/book/9780387954417">A distribution-free theory of nonparametric regression</a>. Springer, 2006.<br />[2] Alexandre B. Tsybakov. <a href="https://www.springer.com/gp/book/9780387790510">Introduction to Nonparametric Estimation</a>. Springer, 2009.<br />[3] Matthias Hein, Jean-Yves Audibert, Ulrike von Luxburg, <a href="http://www.jmlr.org/papers/volume8/hein07a/hein07a.pdf">Graph Laplacians and their convergence on random neighborhood graphs</a>. <em>Journal of Machine Learning Research</em>, 8(Jun):1325-1368, 2007.<br />[4] Nello Cristianini and John Shawe-Taylor. <a href="https://www.cambridge.org/core/books/kernel-methods-for-pattern-analysis/811462F4D6CD6A536A05127319A8935A">Kernel Methods for Pattern Analysis</a>. Cambridge University Press, 2004.<br />[5] Ali Rahimi, Benjamin Recht. <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">Random Features for Large-Scale Kernel Machines</a>. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2007.<br />[6] Régis Vert, Jean-Philippe Vert. <a href="http://www.jmlr.org/papers/volume7/vert06a/vert06a.pdf">Consistency and Convergence Rates of One-Class SVMs and Related Algorithms</a>. <em>Journal of Machine Learning Research</em>, 7(May):817-854, 2006.<br />[7] Peter J. Bickel, and Bo Li. <a href="https://projecteuclid.org/download/pdf_1/euclid.lnms/1196794952">Local polynomial regression on unknown manifolds</a>. Complex datasets and inverse problems. <em>Institute of Mathematical Statistics</em>, 177-186, 2007.<br />[8] Xiaojin Zhu, Zoubin Ghahramani, John D. Lafferty. <a href="https://www.aaai.org/Papers/ICML/2003/ICML03-118.pdf">Semi-supervised learning using gaussian fields and harmonic functions</a>. <em>Proceedings of the International conference on Machine learning (ICML)</em>. 2003.<br />[9] Francis Bach.  <a href="http://www.jmlr.org/proceedings/papers/v30/Bach13.pdf">Sharp analysis of low-rank kernel matrix approximations</a>. <em>Proceedings of the International Conference on Learning Theory (COLT)</em>, 2003.<br />[10] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the Curse of Dimensionality with Convex Neural Networks</a>. <em>Journal of Machine Learning Research</em>, 18(19):1-53, 2017.<br />[11] Alessandro Rudi, Luigi Carratino, Lorenzo Rosasco. <a href="https://papers.nips.cc/paper/6978-falkon-an-optimal-large-scale-kernel-method.pdf">FALKON: An Optimal Large Scale Kernel Method</a>. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2017.<br />[12] Lénaïc Chizat, Francis Bach. <a href="https://papers.nips.cc/paper/7567-on-the-global-convergence-of-gradient-descent-for-over-parameterized-models-using-optimal-transport.pdf">On the Global Convergence of Gradient Descent for Over-parameterized Models using Optimal Transport</a>. <em>Advances in Neural Information Processing Systems (NeurIPS)</em>, 2018.<br />[13] Song Mei, Andrea Montanari, and Phan-Minh Nguyen. <a href="https://arxiv.org/pdf/1804.06561">A mean field view of the landscape of two-layer neural networks</a>. <em>Proceedings of the National Academy of Sciences (PNAS)</em>, 115(33):E7665–E7671, 2018.<br />[14] Arthur Jacot, Franck Gabriel, Clément Hongler. <a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">Neural tangent kernel: Convergence and generalization in neural networks</a>. <em>Advances in neural information processing systems (NeurIPS)</em>, 2018.<br />[15] Lénaïc Chizat, Edouard Oyallon, Francis Bach. <a href="https://arxiv.org/pdf/1812.07956">On Lazy Training in Supervised Differentiable Programming</a>. <em>Arxiv</em>-1812.07956, 2018.<br />[16] Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal. <a href="https://arxiv.org/pdf/1812.11118">Reconciling modern machine learning practice and the bias-variance trade-off</a>. <em>Proceedings of the National Academy of Sciences (PNAS)</em>, 116 (32), 2019.</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/cursed-kernels/"><span class="datestr">at October 08, 2019 07:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=34">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2019/06/20/theory-and-practice-of-differential-privacy-2019/">Theory and Practice of Differential Privacy 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>While I’m a relative newcomer to differential privacy (my <a href="https://arxiv.org/abs/1703.10127">first paper</a> on it was only in 2017), I’ve found the community to be a pleasure to interact with: paradoxically, simultaneously tight-knit yet highly welcoming to newcomers. I partially credit this culture to the number of workshops and programs which bring people together, including, but not limited to, <a href="https://www.birs.ca/events/2018/5-day-workshops/18w5189">a BIRS workshop</a>, <a href="https://privacytools.seas.harvard.edu/">the Privacy Tools project at Harvard</a>, <a href="https://simons.berkeley.edu/programs/privacy2019">a semester at the Simons Institute</a>, <a href="https://shonan.nii.ac.jp/seminars/164/">the forthcoming Shonan workshop</a>, and <a href="https://tpdp.cse.buffalo.edu/">the Theory and Practice of Differential Privacy (TPDP) Workshop</a>.</p>



<p>I’m writing this post to draw attention to the imminent deadline of <a href="https://tpdp.cse.buffalo.edu/2019/">TPDP 2019</a>, co-located with CCS 2019 in London. I’ll spare you the full details (click the link for more information), but most pressing is the deadline tomorrow, June 21, 2019, anywhere on Earth (let me know if this presents hardship for you, and I can pass concerns on to the chair). Essentially anything related to the theory or practice of differential privacy is welcome. Submissions are limited to four pages in length and are lightly refereed, based on originality, relevance, interest, and clarity. There are no published proceedings, and previously published results are welcome. If you’ve been looking to get to know the community, consider either submitting or attending the workshop! </p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2019/06/20/theory-and-practice-of-differential-privacy-2019/"><span class="datestr">at June 20, 2019 06:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=23">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2019/06/17/hello-world/">Hello World!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Welcome to my blog! My name is Gautam Kamath, and I just started as an assistant professor in computer science at the University of Waterloo (for more info, see <a href="https://kamathematics.wordpress.com/about/">About</a>).</p>



<p>This blog will, broadly speaking, be about topics relevant to those interested in the the theory of computer science, statistics, and machine learning. Posts will range from technical, to informational, to meta (read: basically whatever I want to write about, but I’ll do my best to keep it topical). Stay tuned!</p>



<p>The unofficial theme song of this blog is <a href="https://www.youtube.com/watch?v=8Ir-zFC9nFE">“Mathematics” by Mos Def</a>.</p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2019/06/17/hello-world/"><span class="datestr">at June 17, 2019 11:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1229">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">Randomness and interaction? Entanglement ups the game!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>[05/25/19 Update: Kevin Hartnett has a nice article at Quanta explaining Natarajan &amp; Wright’s result in slightly more layman terms than I’d be able to…see here: <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">Computer Scientists Expand the Frontier of Verifiable Knowledge</a>]</em></p>
<p>The study of entanglement through the length of interactive proof systems has been one of the most productive applications of complexity theory to the physical sciences that I know of. Last week Anand Natarajan and John Wright, postdoctoral scholars at Caltech and MIT respectively, added a <a href="https://arxiv.org/abs/1904.05870">major stone</a> to this line of work. Anand &amp; John (hereafter “NW”) establish the following wild claim: it is possible for a classical polynomial-time verifier to decide membership in any language in <em>non-deterministic doubly exponential time</em> by asking questions to two infinitely powerful, but untrusted, provers sharing entanglement. In symbols, NEEXP <img src="https://s0.wp.com/latex.php?latex=%7B%5Csubseteq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\subseteq}" class="latex" title="{\subseteq}" /> MIP<img src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^\star}" class="latex" title="{^\star}" />! (The last symbol is for emphasis — no, we don’t have an MIP<img src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^\star}" class="latex" title="{^\star}" />! class — yet.)</p>
<p>What is amazing about this result is the formidable gap between the complexity of the verifier and the complexity of the language being verified. We know since the 90s that the use of interaction and randomness can greatly expand the power of polynomial-time verifiers, from NP to <a href="https://dl.acm.org/citation.cfm?id=146609">PSPACE</a> (with a single prover) and <a href="https://dl.acm.org/citation.cfm?id=2794945">NEXP</a> (with two provers). As a result of the work of Natarajan and Wright, we now know that yet an additional ingredient, the use of <em>entanglement</em> between the provers, can be leveraged by the verifier — the same verifier as in the previous results, a classical randomized polynomial-time machine — to obtain an exponential increase in its verification power. Randomness and interaction brought us one exponential; entanglement gives us another.</p>
<p>To gain intuition for the result consider first the structure of a classical two-prover one-round interactive proof system for non-deterministic doubly exponential time, with exponential-time verifier. Cutting some corners, such a protocol can be obtained by “scaling up” a standard two-prover protocol for non-deterministic singly exponential time. In the protocol, the verifier would sample a pair of exponential-length questions <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,Y)}" class="latex" title="{(X,Y)}" />, send <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> to each prover, receive answers <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />, and perform an exponential-time computation that verifies some predicate about <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%2CA%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,Y,A,B)}" class="latex" title="{(X,Y,A,B)}" />.</p>
<p>How can entanglement help design an <em>exponentially more efficient</em> protocol? At first it may seem like a polynomial-time verifier has no way to even get started: if it can only communicate polynomial-length messages with the provers, how can it leverage their power? And indeed, if the provers are classical, it can’t: it is known that even with a polynomial number of provers, and polynomially many rounds of interaction, a polynomial-time verifier cannot decide any language beyond NEXP.</p>
<p>But the provers in the NW protocol are not classical. They can share entanglement. How can the verifier exploit this to its advantage? The key property that is needed is know as the <em>rigidity</em> of entanglement. In words, rigidity is the idea that by verifying the presence of certain statistical correlations between the provers’ questions and answers the verifier can determine precisely (up to a local change of basis) the quantum state and measurements that the provers must have been using to generate their answers. The most famous example of rigidity is the <em>CHSH game</em>: as already shown by <a href="http://www.numdam.org/item/AIHPA_1988__49_2_215_0/">Werner and Summers</a> in 1982, the CHSH game can only be optimally, or even near-optimally, won by measuring a maximally entangled state using two mutually unbiased bases for each player. No other state or measurements will do, unless they trivially imply an EPR pair and mutually unbiased bases (such as a state that is the tensor product of an EPR pair with an additional entangled state).</p>
<p>Rigidity gives the verifier control over the provers’ use of their entanglement. The simplest use of this is for the verifier to force the provers to share a certain number <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> of EPR pairs and measure them to obtain identical uniformly distributed <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />-bit strings. Such a test for <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> EPR pairs can be constructed from <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> CHSH games. In a <a href="https://arxiv.org/abs/1801.03821">paper</a> with Natarajan we give a more efficient test that only requires questions and answers of length that is poly-logarithmic in <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />. Interestingly, the test is built on classical machinery — the low-degree test — that plays a central role in the analysis of some classical multi-prover proof systems for NEXP.</p>
<p>At this point we have made an inch of progress: it is possible for a polynomial-time (in <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D%5Clog+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=\log N}" class="latex" title="{n=\log N}" />) verifier to “command” two quantum provers sharing entanglement to share <img src="https://s0.wp.com/latex.php?latex=%7BN%3D2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N=2^n}" class="latex" title="{N=2^n}" /> EPR pairs, and measure them in identical bases to obtain identical uniformly random <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />-bit strings. What is this useful for? Not much — yet. But here comes the main insight in NW: suppose we could similarly force the provers to generate, not identical uniformly random strings, but a pair of <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />-bit strings <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,Y)}" class="latex" title="{(X,Y)}" /> that is distributed as a pair of questions from the verifier in the aforementioned interactive proof system for NEEXP with exponential-time (in <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />) verifier. Then we could use a polynomial-time (in <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />) verifier to “command” the provers to generate their exponentially-long questions <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,Y)}" class="latex" title="{(X,Y)}" /> by themselves. The provers would then compute answers <img src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(A,B)}" class="latex" title="{(A,B)}" /> as in the NEEXP protocol. Finally, they would prove to the verifier, using a polynomial interaction, that <img src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(A,B)}" class="latex" title="{(A,B)}" /> is a valid pair of answers to the pair of questions <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,Y)}" class="latex" title="{(X,Y)}" /> — indeed, the latter verification is an NEXP problem, hence can be verified using a protocol with polynomial-time verifier.</p>
<p>Sounds crazy? Yes. But they did it! Of course there are many issues with the brief summary above — for example, how does the verifier even know the questions <img src="https://s0.wp.com/latex.php?latex=%7BX%2CY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,Y}" class="latex" title="{X,Y}" /> sampled by the provers? The answer is that it doesn’t need to know the entire question; only that it was sampled correctly, and that the quadruple <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%2CA%2CB%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,Y,A,B)}" class="latex" title="{(X,Y,A,B)}" /> satisfies the verification predicate of the exponential-time verifier. This can be verified using a polynomial-time interactive proof.</p>
<p>Diving in, the most interesting insight in the NW construction is what they call “introspection”. What makes multi-prover proof systems powerful is the ability for the verifier to send correlated questions to the provers, in a way such that each prover has only partial information about the other’s question — informally, the verifier plays a variant of prisonner’s dilemma with the provers. In particular, any interesting distribution <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,Y)}" class="latex" title="{(X,Y)}" /> will have the property that <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> are not fully correlated. For a concrete example think of the “planes-vs-lines” distribution, where <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is a uniformly random plane and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> a uniformly random line in <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. The aforementioned test for <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> EPR pairs can be used to force both provers to sample the same uniformly random plane <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. But how does the verifier ensure that one of the provers “forgets” parts of the plane, to only remember a uniformly random line <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> that is contained in it? NW’s insight is that the information present in a quantum state — such as the prover’s half-EPR pairs — can be “erased” by commanding the prover to perform a measurement in the <em>wrong</em> basis — a basis that is mutually unbiased with the basis used by the other prover to obtain its share of the query. Building on this idea, NW develop a battery of delicate tests that provide the verifier the ability to control precisely what information gets distributed to each prover. This allows a polynomial-time verifier to perfectly simulate the local environment that the exponential-time verifier would have created for the provers in a protocol for NEEXP, thus simulating the latter protocol with exponentially less resources.</p>
<p>One of the aspects of the NW result I like best is that they showed how the “history state barrier” could be overcome. Previous works attempting to establish strong lower bounds on the class MIP<img src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^\star}" class="latex" title="{^\star}" />, such as the <a href="https://arxiv.org/abs/1805.12166">paper</a> by Yuen et al., relies on a compression technique that requires the provers to share a history state of the computation performed by a larger protocol. Unfortunately, history states are very non-robust, and as a result such works only succeeded in developing protocols with vanishing completeness-soundness gap. NW entirely bypass the use of history states, and this allows them to maintain a constant gap.</p>
<p>Seven years ago Tsuyoshi Ito and I showed that <a href="https://arxiv.org/abs/1207.0550">MIP<img src="https://s0.wp.com/latex.php?latex=%7B%7D%5E%5Cstar&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{}^\star" class="latex" title="{}^\star" /> contains NEXP</a>. At the time, we thought this may be the end of the story — although it seemed challenging, surely someone would eventually prove a matching upper bound. Natarajan and Wright have defeated this expectation by showing that MIP<img src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^\star}" class="latex" title="{^\star}" /> contains NEEXP. What next? NEEEXP? The halting problem? I hope to make this the topic of a future post.</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/"><span class="datestr">at April 14, 2019 04:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://nisheethvishnoi.wordpress.com/?p=78">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/nisheeth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://nisheethvishnoi.wordpress.com/2018/09/19/the-dynamics-of-lagrange-and-hamilton/">The dynamics of Lagrange and Hamilton</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In 1788, Lagrange presented a set of equations of motion that, unlike Newtonian mechanics, are independent of the choice of coordinates of the physical system, and ultimately led to the formulation of <a href="https://en.wikipedia.org/wiki/Einstein%E2%80%93Hilbert_action">general relativity</a>. Hamilton came up with a different set of equations of motion in 1833 that arguably led to the development of <a href="https://en.wikipedia.org/wiki/Hamiltonian_(quantum_mechanics)">quantum mechanics</a>. Remarkably, in classical mechanics, these sets of equations turn out to be <em>equivalent</em> via a beautiful duality due to <strong>Legendre</strong>.</p>
<p><img src="https://nisheethvishnoi.files.wordpress.com/2018/09/aduc_057_legendre_l-_1756-1797.jpg?w=1008" alt="AduC_057_Legendre_(L.,_1756-1797)" class="alignnone size-full wp-image-82" /></p>
<p><span style="color: #999999;"><em>A portrait of Legendre by H. Rousseau, E. Thomas, Augustin Challamel, and Desire Lacroix via Wikimedia Commons</em></span></p>
<p>Lagrangian and Hamiltonian dynamics have inspired several promising optimization and sampling algorithms such as <a href="https://arxiv.org/pdf/1603.04245.pdf">first-order methods in optimization</a>,  <a href="http://arogozhnikov.github.io/2016/12/19/markov_chain_monte_carlo.html">Hamiltonian Monte Carlo</a> (see also this <a href="https://arxiv.org/abs/1802.08898">paper</a> that will appear in NIPS 2018). Legendre duality also appears in convex optimization as <a href="https://en.wikipedia.org/wiki/Fenchel%27s_duality_theorem">Fenchel</a> <a href="https://nisheethvishnoi.wordpress.com/convex-optimization/">duality</a>.  <a href="https://nisheethvishnoi.files.wordpress.com/2018/09/lagrangehamiltonian.pdf" title="LagrangeHamiltonian">This</a> note, written primarily for optimization folks, introduces Lagrangian dynamics, Hamiltonian dynamics, and proves the duality that connects them.</p>
<p>I hope that these fundamental ideas inspire you as well to think about optimization from a physics perspective!</p>
<p> </p>
<p> </p></div>







<p class="date">
by nisheethvishnoi <a href="https://nisheethvishnoi.wordpress.com/2018/09/19/the-dynamics-of-lagrange-and-hamilton/"><span class="datestr">at September 19, 2018 10:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://nisheethvishnoi.wordpress.com/?p=63">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/nisheeth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://nisheethvishnoi.wordpress.com/2018/09/16/fair-elections/">Fair Elections</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p style="text-align: center;"><em><a href="https://theory.epfl.ch/celis/HOME.html">Elisa Celis</a> and Nisheeth Vishnoi</em></p>
<p>Elections are the nervous system of a democracy and, hence, issues related to their transparency and fairness are central to healthy societies. However, the number of <a href="https://en.wikipedia.org/wiki/List_of_controversial_elections">controversial elections</a> has exploded since 2000, and the more recent ones involve the use of the Internet and algorithms — a good excuse for computer scientists to get involved in elections to save democracy!</p>
<p>Last year, the two of us and Lingxao Huang revisited the question of <em>fairness</em> in <em>multi-winner</em> elections<em>. </em>A multi-winner election is one where the objective is to select a committee from a set of candidates based on voter preferences. However, election systems for multi-winner elections have been shown to be <a href="https://www.representwomen.org/voting_rules_pose_barrier_for_women">biased against minorities</a> by giving preference to committees that under-represent their already-small numbers. When the candidates have certain sensitive attributes (such as gender), and different types (e.g., male, female and non-binary) we may instead wish to impose additional requirement so that the winning committee is <em>fair</em>. We considered the problem of finding the committee with the maximum number of votes, subject to such additional fairness requirements.</p>
<p style="text-align: center;"><em>But what does it mean to be fair?</em></p>
<p>Is a committee fair when types are equally represented? Or <a href="https://en.wikipedia.org/wiki/Proportional_representation">proportionally represented</a>? These questions have received more than a century’s worth of attention in social choice theory and are deeply entangled with culture and politics. In short, fairness means different things in different contexts and rather than addressing a specific instance of this question, we asked ourselves — <em>can we provide a framework in which a user can specify fairness constraints according to their needs and design algorithms that can compute the winning committee accordingly?</em></p>
<p>Because such a framework must handle general classes of constraints, the algorithmic task became more challenging than the usual unconstrained case. If you are interested in understanding our algorithmic and complexity results, they appear in our recent <a href="https://arxiv.org/pdf/1710.10057.pdf">paper</a> that was presented at IJCAI-ECAI this year.</p>
<p>Clearly, however, there are real merits to providing such generality — earlier this year, our paper caught the eye of members of a <a href="https://appelcitoyen.ch/">people’s movement</a> from the <a href="https://en.wikipedia.org/wiki/Canton_of_Valais">Valais</a> canton in Switzerland, who were in the process of rethinking elections in their region. They were happy to know that we had solved the exact problem they needed for a primary election and asked us if we would be willing to help them conduct their elections. We were, of course, thrilled!</p>
<p>After an intense collaboration for more than four months, 8 elections that used our framework concluded on September 9, 2018. For us, there were several eye-opening aspects of taking our algorithmic framework from theory to practice. Perhaps the most interesting one was coming up with an answer to:</p>
<p style="text-align: center;"><em>Who decides what is fair?</em></p>
<p>In this case, it was the voters! Before voting on the committee, a vote to determine the fairness constraints was conducted in each of the eight districts. This vote was in mid-June and also checked if the voters agree to use our algorithmic framework. Since transparency was the key motivation, prior to this vote,  we were invited to a press conference to educate the people about the whole process that resulted in coverage in newspapers <a href="https://www.letemps.ch/suisse/listes-ideales-constituante-valaisanne?itm_source=homepage&amp;itm_medium=position-12">Le Temps</a>,  <a href="https://www.lenouvelliste.ch/articles/valais/canton/appel-citoyen-lance-sa-primaire-digitale-en-vue-de-la-constituante-les-passionnes-de-democratie-ont-jusqu-a-jeudi-pour-s-inscrire-763669">Le Nouvelliste</a>, TV channel <a href="https://www.google.com/url?q=http://canal9.ch/appel-citoyen-va-choisir-ses-candidats-pour-la-lassemblee-constituante-en-deux-etapes-et-par-internet/&amp;source=gmail&amp;ust=1537194868256000&amp;usg=AFQjCNGQkC-CmcI2n0iBfAAzxP4GWbiBzQ">Canal 9</a>, and radio channels <a href="http://www.rhonefm.ch/fr/podcasts/journal-du-soir-une-election-primaire-digitale--c-est-l-aventure-dans-laquelle-se-lance-le-mouvement-apolitique-appel-citoyen-en-premiere-mondiale-1107827">Rhone FM</a> and  <a href="http://radiochablais.ch//podcast/mp3/info_12h_13062018.mp3">Radio Chablais</a>.</p>
<p><img src="https://nisheethvishnoi.files.wordpress.com/2018/09/20180612_142435.jpg?w=1008" alt="20180612_142435" class="alignnone size-full wp-image-65" /></p>
<p><em>An image from the press conference in Sion on June 12, 2018. Elisa Celis (center), accompanied by members of Appel Citoyen.</em></p>
<p>In the end, the voters decided to place constraints on the gender balance, age demographics, and regions. While all districts approved these same three attributes, the specific constraints varied by district according to their demographics and pre-defined regions. This was a truly open and democratic way to determine the criteria by which the committee was to be balanced. The constraints not only ensured that the outcome would be fair (as defined by the voters) but also encouraged many more women to run for election than the party originally anticipated — in fact, in several districts there were more women than men contesting the election!</p>
<p><img src="https://nisheethvishnoi.files.wordpress.com/2018/09/20180909_153659.jpg?w=1008" alt="20180909_153659" class="alignnone size-full wp-image-64" /></p>
<p style="text-align: left;"><em>Computing the winning committees in Sion on September 9, 2018. From L to R: Lingxiao Huang, Vijay Keswani, Elisa Celis, Florian Evequoz, Bernadette Morand-Aymon.</em></p>
<p>Everything about these elections, from votes, candidates, constraints, and code, to the output, is open for all to <a href="https://appelcitoyen.ch/blog/on-ouvre-les-urnes-donnees-brutes-de-la-primaire/">verify</a>. We have also made available a <a href="http://valais-elections.herokuapp.com/">demo</a> with pre-loaded constraints, candidate information, and votes for anyone to test and compute the results. To know more about the use of our algorithm in these elections, take a look at <a href="https://www.youtube.com/watch?v=X6M1fpcEBQE">this video</a>. A few links to the coverage of these elections can be found here: <a href="http://canal9.ch/constituante-appel-citoyen-a-designe-ses-96-candidats-une-primaire-digitale-realisee-grace-a-une-methode-concue-par-lepfl/">Canal 9</a>,  <a href="https://www.letemps.ch/suisse/valais-appel-citoyen-lance-primaire-constituante">Le Temps</a>, <a href="https://www.lenouvelliste.ch/dossiers/tout-savoir-sur-la-constituante/articles/constituante-la-primaire-numerique-d-appel-citoyen-a-rendu-son-verdict-782906">Le Nouvelliste</a>.</p>
<p>We feel fortunate that we were given this unique opportunity to take tools from computer science to the heart of a democratic process. It was an unparalleled learning experience for all of us and something that we increasingly look forward to in the future.</p>
<p><img src="https://nisheethvishnoi.files.wordpress.com/2018/09/constraints.gif?w=1008" alt="constraints" class="alignnone size-full wp-image-70" /></p>
<p><img src="https://nisheethvishnoi.files.wordpress.com/2018/09/candidates.gif?w=1008" alt="candidates" class="alignnone size-full wp-image-69" /></p>
<p>You can also use our <a href="https://theory.epfl.ch/bias/elections/">demo</a> to design your own elections and play around with our algorithms. This demo was developed with the help of Abhibhav Garg and Vijay Keswani and has limited functionality. If you are interested in using our full framework and/or working with us,  please feel free to <a href="https://theory.epfl.ch/bias/contact.html">contact us</a>.</p>
<p> </p>
<p> </p></div>







<p class="date">
by nisheethvishnoi <a href="https://nisheethvishnoi.wordpress.com/2018/09/16/fair-elections/"><span class="datestr">at September 16, 2018 08:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1226">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2018/08/06/the-cryptographic-leash/">The cryptographic leash</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This post is meant as a companion to an introductory post I wrote on the <a href="https://quantumfrontiers.com/">blog</a> of Caltech’s IQIM (<a href="http://iqim.caltech.edu/">Institute for Quantum Information and Matter</a>), of which I am a member. The post describes a “summer cluster” on quantum computation that I co-organized with Andrew Childs, Ignacio Cirac, and Umesh Vazirani at the Simons Institute in Berkeley over the past couple months. The IQIM post also describes one of the highlights of the workshop we organized as part of this program: the recent result by Mahadev on <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html">classical verification of quantum computation</a>. The present post is a continuation of <a href="https://quantumfrontiers.com/2018/08/05/the-quantum-wave-in-computing/">that one</a>, so that I would encourage you to read it first. In this post my goal is to give additional detail on Mahadev’s result. For the real thing you should of course read the <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html">paper</a> (you may want to start by watching the author’s <a href="https://simons.berkeley.edu/talks/urmila-mahadev-06-15-18">beautiful talk</a> at our workshop). What follows is my attempt at an introduction, in great part written for the sake of clarifying my own understanding. I am indebted to Urmila for multiple conversations in which she indefatigably answered my questions and cleared my confusions — of course, any remaining inaccuracies in this post are entirely mine.</p>
<p><b>The result </b></p>
<p><a name="the-result"></a></p>
<p>Let’s start by recalling Mahadev’s result. She shows that from any quantum computation, specified by a polynomial-size quantum circuit <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, it is possible to efficiently compute a <em>classical-verifier quantum-prover protocol</em>, i.e.~a prescription for the actions of a classical probabilistic polynomial-time verifier interacting with a quantum prover, that has the following properties. For simplicity, assume that <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> produces a deterministic outcome <img src="https://s0.wp.com/latex.php?latex=%7Bo%28C%29%5Cin%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{o(C)\in\{0,1\}}" class="latex" title="{o(C)\in\{0,1\}}" /> when it is executed on qubits initialized in the state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| 0 \rangle}" class="latex" title="{| 0 \rangle}" /> (any input can be hard-coded in the circuit). At the end of the protocol, the verifier always makes one of three possible decisions: “reject”; “accept, 0”; “accept, 1”. The <em>completeness</em> property states that for any circuit <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> there is a “honest” behavior for the prover that can be implemented by a polynomial-time quantum device and that will result in the verifier making the decision “accept, <img src="https://s0.wp.com/latex.php?latex=%7Bo%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{o(C)}" class="latex" title="{o(C)}" />”, where <img src="https://s0.wp.com/latex.php?latex=%7Bo%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{o(C)}" class="latex" title="{o(C)}" /> is the correct outcome, with probability <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. The <em>soundness</em> property states that for any behavior of the quantum prover in the protocol, either the probability that the verifier returns the outcome “accept, <img src="https://s0.wp.com/latex.php?latex=%7B1-o%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-o(C)}" class="latex" title="{1-o(C)}" />” is negligibly small, or the quantum prover has the ability to break a post-quantum cryptographic scheme with non-negligible advantage. Specifically, the proof of the soundness property demonstrates that a prover that manages to mislead the verifier into making the wrong decision (for any circuit) can be turned into an efficient attack on the learning with errors (LWE) problem (with superpolynomial noise ratio).</p>
<p>The fact that the protocol is only sound against computationally bounded provers sets it apart from previous approaches, which increased the power of the verifier by allowing her to dispose of a miniature quantum computer, but established soundness against computationally unbounded provers. The magic of Mahadev’s result is that she manages to leverage this sole assumption, computational boundnedness of the prover, to tie a very tight “leash” around its neck, by purely classical means. My use of the word “leash” is <a href="https://arxiv.org/abs/1209.0448">not innocent</a>: informally, it seems that the cryptographic assumption allows Mahadev to achieve the kind of feats that were previously known, for classical verifiers, in the model where there are two quantum provers sharing entanglement. I am not sure how far the analogy extends, and would like to explore it further; this has already started with a collaboration with Brakerski, Christiano, Mahadev and Vazirani that led to <a href="https://arxiv.org/abs/1804.00640">a single-prover protocol for certifiable randomness expansion</a>. Nevertheless, the main open question left open by Mahadev’s work remains whether the computational assumption is even necessary: could a similar result hold, where the honest prover can perform the required actions in quantum polynomial-time, but the protocol remains sound against arbitrarily powerful provers? (Experts will have recognized that the existence of a protocol where the honest prover is as powerful as PSPACE follows from the classical results that BQP is in PSPACE, and that PSPACE=IP. Unfortunately, we currently don’t expect even a supercharged AWS cloud to be able to implement PSPACE-complete computations.)</p>
<p><b> Encoding computation in ground states </b></p>
<p><a name="encoding-computation-in-ground-states"></a></p>
<p>Let’s get to business: how does this work? Fix a quantum circuit <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> that the verifier is interested in. Assume the description of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> known to both the verifier and the prover. As earlier, assume further that when <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> is executed on a state initialized to <img src="https://s0.wp.com/latex.php?latex=%7B%7C+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| 0 \rangle}" class="latex" title="{| 0 \rangle}" /> a measurement of the output qubit of the circuit returns either the outcome <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> or the outcome <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, deterministically. The verifier wishes to determine which case holds.</p>
<p>The first step that the verifier performs is a classical polynomial-time reduction from this <em>circuit output decision problem</em> to the following <em>Hamiltonian energy decision problem</em>. In the Hamiltonian energy decision problem the input is the description of a pair of classical polynomial-time randomized circuits. The first circuit, <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, takes as input a random string <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />, and returns a string <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%5Cin%5C%7BX%2CZ%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\theta\in\{X,Z\}^n}" class="latex" title="{\theta\in\{X,Z\}^n}" />. The second circuit, <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" />, takes as input a string <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%5Cin%5C%7BX%2CZ%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\theta\in\{X,Z\}^n}" class="latex" title="{\theta\in\{X,Z\}^n}" /> of the kind returned by the first circuit, as well as an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit string <img src="https://s0.wp.com/latex.php?latex=%7Ba%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a\in\{0,1\}^n}" class="latex" title="{a\in\{0,1\}^n}" />, and returns a “decision bit” <img src="https://s0.wp.com/latex.php?latex=%7Bb%5Cin+%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b\in \{0,1\}}" class="latex" title="{b\in \{0,1\}}" />. The goal of the verifier is to distinguish between the following two cases. Either there exists an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit state <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> such that, when a string <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\theta}" class="latex" title="{\theta}" /> is sampled according to <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> (choosing a uniformly random <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> as input), the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> qubits of <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> are measured in the bases specified by <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\theta}" class="latex" title="{\theta}" /> (i.e.~the <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />-th qubit is measured in the computational basis in case <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta_i%3DZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\theta_i=Z}" class="latex" title="{\theta_i=Z}" />, and in the Hadamard basis in case <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctheta_i%3DX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\theta_i=X}" class="latex" title="{\theta_i=X}" />), the resulting <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit outcome <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7BV%28%5Ctheta%2Ca%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V(\theta,a)=1}" class="latex" title="{V(\theta,a)=1}" /> with probability at least <img src="https://s0.wp.com/latex.php?latex=%7B3%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3/4}" class="latex" title="{3/4}" />. Or, for any state <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" />, the same procedure results in <img src="https://s0.wp.com/latex.php?latex=%7BV%28%5Ctheta%2Ca%29%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V(\theta,a)=0}" class="latex" title="{V(\theta,a)=0}" /> with probability at most <img src="https://s0.wp.com/latex.php?latex=%7B2%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2/3}" class="latex" title="{2/3}" />.</p>
<p>I called this problem the Hamiltonian energy decision problem because the circuits <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> implicitly specify a Hamiltonian, whose minimal energy the verifier aims to approximate. Note that the Hamiltonian is not required to be local, and furthermore it may involve an average of exponentially many terms (as many as there are random strings <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />). The problem is still in QMA, because the verifier is efficient. It is not hard to show that the problem is QMA-hard. What the formulation above buys us, compared to using the usual QMA-complete formulation of the local Hamiltonian problem, is the constant energy gap — which comes at the cost of exponentially many terms and loss of locality. (Open question: I would like to know if it is possible to achieve a constant gap with only one of these caveats: local with exponentially many terms, or nonlocal with polynomially terms.) Of course here we only care that the problem is BQP-hard, and that the witness can be computed by a BQP prover; this is indeed the case. We also don’t really care that there is a constant gap – the soundness of the final protocol could be amplified by other means – but it is convenient that we are able to assume it.</p>
<p>The reduction that achieves this is a combination of Kitaev’s history state construction with some gadgetry from perturbation theory and an amplification trick. The first step reduces the verification that <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> returns outcome <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> (resp. <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />) on input <img src="https://s0.wp.com/latex.php?latex=%7B%7C+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| 0 \rangle}" class="latex" title="{| 0 \rangle}" /> to the verification that a local Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> (computed from <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />) has ground state energy exponentially close to <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> (resp. at least some positive inverse polynomial). The second step consists in applying perturbation theory to reduce to the case where <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> is a weighted linear combination of terms of the form <img src="https://s0.wp.com/latex.php?latex=%7BX_iX_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_iX_j}" class="latex" title="{X_iX_j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ_iZ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_iZ_j}" class="latex" title="{Z_iZ_j}" />, where <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" />, <img src="https://s0.wp.com/latex.php?latex=%7BZ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_j}" class="latex" title="{Z_j}" /> are the Pauli <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> operators on the <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />-th and <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" />-th qubit respectively. The final step is an amplification trick, that produces a nonlocal Hamiltonian whose each term is a tensor product of single-qubit <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> observables and has ground state energy either less than <img src="https://s0.wp.com/latex.php?latex=%7B1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/4}" class="latex" title="{1/4}" /> or larger than <img src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/3}" class="latex" title="{1/3}" /> (when the Hamiltonian is scaled to be non-negative with norm at most <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />).</p>
<p>These steps are fairly standard. The first two are combined in a <a href="https://arxiv.org/abs/1603.06046">paper</a> by Fitzsimons and Morimae to obtain a protocol for “post-hoc” verification of quantum computation: the prover prepares the ground state of an <img src="https://s0.wp.com/latex.php?latex=%7BXZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{XZ}" class="latex" title="{XZ}" /> local Hamiltonian whose energy encodes the outcome of the computation, and sends it to the verifier one qubit at a time; the verifier only needs to perform single-qubit <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> measurements to estimate the energy. The last step, amplification, is described in a <a href="https://arxiv.org/abs/1610.03574">paper</a> with Natarajan, where we use it to obtain a multi-prover interactive proof system for QMA.</p>
<p>For the remainder of this post, I take the reduction for granted and focus on the core of Mahadev’s result, a verification protocol for the following problem: given a Hamiltonian of the form described in the previous paragraph, decide whether the ground state energy of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> is smaller than <img src="https://s0.wp.com/latex.php?latex=%7B1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/4}" class="latex" title="{1/4}" />, or larger than <img src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/3}" class="latex" title="{1/3}" />.</p>
<p><b> Stitching distributions into a qubit </b></p>
<p><a name="stitching-distributions-into-a-qubit"></a></p>
<p>In fact, for the sake of presentation I’ll make one further drastic simplification, which is that the verifier’s goal has been reduced to verifying the existence of a <em>single-qubit</em> state <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" />, whose existence is claimed by the prover. Specifically, suppose that the prover claims that it has the ability to prepare a state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle}" class="latex" title="{| \psi \rangle}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+%5Cpsi+%7CX%7C+%5Cpsi+%5Crangle+%3D+E_X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle \psi |X| \psi \rangle = E_X}" class="latex" title="{\langle \psi |X| \psi \rangle = E_X}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+%5Cpsi+%7CZ%7C+%5Cpsi+%5Crangle%3DE_Z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle \psi |Z| \psi \rangle=E_Z}" class="latex" title="{\langle \psi |Z| \psi \rangle=E_Z}" />, for real parameters <img src="https://s0.wp.com/latex.php?latex=%7BE_X%2CE_Z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_X,E_Z}" class="latex" title="{E_X,E_Z}" />. In other words, that the Hamiltonian <img src="https://s0.wp.com/latex.php?latex=%7BH+%3D+%5Cfrac%7B1%7D%7B2%7D%28X%2BZ%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H = \frac{1}{2}(X+Z)}" class="latex" title="{H = \frac{1}{2}(X+Z)}" /> has minimal energy at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D%28E_X%2BE_Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{1}{2}(E_X+E_Z)}" class="latex" title="{\frac{1}{2}(E_X+E_Z)}" />. How can one verify this claim? (Of course we could do it analytically\ldots{}but that approach would break apart as soon as expectation values on larger sets of qubits are considered.)</p>
<p>We could ask the prover to measure in the <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> basis, or the <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> basis, repeatedly on identical copies of <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle}" class="latex" title="{| \psi \rangle}" />, and report the outcomes. But how do we know that all these measurements were performed on the same state, and that the prover didn’t choose e.g. <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%3D%7C+1+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle=| 1 \rangle}" class="latex" title="{| \psi \rangle=| 1 \rangle}" /> to report the <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" />-basis outcomes, and <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%3D%7C+-+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle=| - \rangle}" class="latex" title="{| \psi \rangle=| - \rangle}" /> to report the <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />-basis outcomes? We need to find a way to prevent the prover from measuring a different state depending on the basis it is asked for — as well as to ensure the measurement is performed in the right basis.</p>
<p><b> Committing to a qubit </b></p>
<p><a name="committing-to-a-qubit"></a></p>
<p>The key idea in Mahadev’s protocol is to use cryptographic techniques to force the prover to “commit” to the state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle}" class="latex" title="{| \psi \rangle}" /> in a way that, once the commitment has been performed, the prover no longer has the liberty to “decide” which measurement it performs on the commited qubit (unless it breaks the cryptographic assumption).</p>
<p>I described the commitment scheme in the companion post <a href="https://quantumfrontiers.com/2018/08/05/the-quantum-wave-in-computing/">here</a>. For convenience, let me quote from that post. Recall that the scheme is based on a pair of trapdoor permutations <img src="https://s0.wp.com/latex.php?latex=%7Bf_0%2Cf_1%3A%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_0,f_1:\{0,1\}^n \rightarrow \{0,1\}^n}" class="latex" title="{f_0,f_1:\{0,1\}^n \rightarrow \{0,1\}^n}" /> that is <em>claw-free</em>. Informally, this means that it is hard to produce any pair <img src="https://s0.wp.com/latex.php?latex=%7B%28x_0%2Cx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(x_0,x_1)}" class="latex" title="{(x_0,x_1)}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bf_0%28x_0%29%3Df_1%28x_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_0(x_0)=f_1(x_1)}" class="latex" title="{f_0(x_0)=f_1(x_1)}" />.</p>
<p>The commitment phase of the protocol works as follows. Starting from a state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%3D%5Calpha%7C+0+%5Crangle%2B%5Cbeta%7C+1+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle=\alpha| 0 \rangle+\beta| 1 \rangle}" class="latex" title="{| \psi \rangle=\alpha| 0 \rangle+\beta| 1 \rangle}" /> of its choice, the prover is supposed to perform the following steps. First, the prover creates a uniform superposition over the common domain of <img src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_0}" class="latex" title="{f_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1}" class="latex" title="{f_1}" />. Then it evaluates either function, <img src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_0}" class="latex" title="{f_0}" /> or <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1}" class="latex" title="{f_1}" />, in an additional register, by controlling on the qubit of <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle}" class="latex" title="{| \psi \rangle}" />. Finally, the prover measures the register that contains the image of <img src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_0}" class="latex" title="{f_0}" /> or <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1}" class="latex" title="{f_1}" />. This achieves the following sequence of transformations:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%5Calpha%7C+0+%5Crangle%2B%5Cbeta%7C+1+%5Crangle+%26%5Cmapsto%26+%28%5Calpha%7C+0+%5Crangle+%2B+%5Cbeta%7C+1+%5Crangle%29+%5Cotimes+%5CBig%282%5E%7B-n%2F2%7D+%5Csum_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D+%7C+x+%5Crangle%5CBig%29+%5C%5C+%26%5Cmapsto+%26+2%5E%7B-n%2F2%7D+%5Csum_x+%5Calpha+%7C+0+%5Crangle%7C+x+%5Crangle%7C+f_0%28x%29+%5Crangle+%2B+%5Cbeta+%7C+1+%5Crangle%7C+f_1%28x%29+%5Crangle%5C%5C+%26%5Cmapsto+%26+%5Cbig%28%5Calpha%7C+0+%5Crangle%7C+x_0+%5Crangle%2B%5Cbeta%7C+1+%5Crangle%7C+x_1+%5Crangle%5Cbig%29%7C+y+%5Crangle%5C%3B%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} \alpha| 0 \rangle+\beta| 1 \rangle &amp;\mapsto&amp; (\alpha| 0 \rangle + \beta| 1 \rangle) \otimes \Big(2^{-n/2} \sum_{x\in\{0,1\}^n} | x \rangle\Big) \\ &amp;\mapsto &amp; 2^{-n/2} \sum_x \alpha | 0 \rangle| x \rangle| f_0(x) \rangle + \beta | 1 \rangle| f_1(x) \rangle\\ &amp;\mapsto &amp; \big(\alpha| 0 \rangle| x_0 \rangle+\beta| 1 \rangle| x_1 \rangle\big)| y \rangle\;, \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} \alpha| 0 \rangle+\beta| 1 \rangle &amp;\mapsto&amp; (\alpha| 0 \rangle + \beta| 1 \rangle) \otimes \Big(2^{-n/2} \sum_{x\in\{0,1\}^n} | x \rangle\Big) \\ &amp;\mapsto &amp; 2^{-n/2} \sum_x \alpha | 0 \rangle| x \rangle| f_0(x) \rangle + \beta | 1 \rangle| f_1(x) \rangle\\ &amp;\mapsto &amp; \big(\alpha| 0 \rangle| x_0 \rangle+\beta| 1 \rangle| x_1 \rangle\big)| y \rangle\;, \end{array} " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y\in\{0,1\}^n}" class="latex" title="{y\in\{0,1\}^n}" /> is the measured image. The string <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> is the prover’s <em>commitment string</em>, that it reports the verifier.</p>
<p>The intuition for this commitment procedure is that it introduces asymmetry between prover and verifier: the prover knows <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> (it had to report it to the verifier) but not <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> (this is the claw-free assumption on the pair <img src="https://s0.wp.com/latex.php?latex=%7B%28f_0%2Cf_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(f_0,f_1)}" class="latex" title="{(f_0,f_1)}" />), which seems to prevent it from recovering the original state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle}" class="latex" title="{| \psi \rangle}" />, since it does not have the ability to “uncompute” <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" />. In contrast, the verifier can use the trapdoor information to recover both preimages.</p>
<p>In a little more detail, how is this used? Note that at this point, from the verifier’s point of view the only information that has been received is the prover’s commitment string <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />. In general there are multiple ways a prover could have come up with a value <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />: for example, by selecting an <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in\{0,1\}^n}" class="latex" title="{x\in\{0,1\}^n}" /> and returning <img src="https://s0.wp.com/latex.php?latex=%7By%3Df_0%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y=f_0(x)}" class="latex" title="{y=f_0(x)}" />. Or, by directly selecting an arbitrary string <img src="https://s0.wp.com/latex.php?latex=%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y\in\{0,1\}^n}" class="latex" title="{y\in\{0,1\}^n}" />. At this stage of the protocol, any of these strategies look fine.</p>
<p>Let’s modify the commitment phase by adding a little test. With some probability, the verifier, upon receiving the commitment string <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, decides to challenge the prover by asking it to report a valid preimage of <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, either under <img src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_0}" class="latex" title="{f_0}" /> or under <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1}" class="latex" title="{f_1}" /> (to the prover’s choice). Since both <img src="https://s0.wp.com/latex.php?latex=%7Bf_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_0}" class="latex" title="{f_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bf_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_1}" class="latex" title="{f_1}" /> are presumed to be hard to invert, the only way the prover can answer this challenge is if it already “knows” a valid preimage — or at a minimum, if it has a superposition on preimages that it can measure when tested. Thus the fact that the prover is required to succeed in the commitment test, when it is performed, guarantees that after the prover has returned the commitment string <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> we may without loss of generality assume that the prover’s state can be written as</p>
<p><a name="eqdef-psi"></a></p>
<p align="center"><a name="eqdef-psi"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%3D%5Ctilde%7B%5Calpha%7D%7C+0%2Cx_0+%5Crangle%7C+%5Cphi_0+%5Crangle%2B%5Ctilde%7B%5Cbeta%7D%7C+1%2Cx_1+%5Crangle%7C+%5Cphi_1+%5Crangle%5C%3B%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle | \tilde{\psi} \rangle=\tilde{\alpha}| 0,x_0 \rangle| \phi_0 \rangle+\tilde{\beta}| 1,x_1 \rangle| \phi_1 \rangle\;, \ \ \ \ \ (1)" class="latex" title="\displaystyle | \tilde{\psi} \rangle=\tilde{\alpha}| 0,x_0 \rangle| \phi_0 \rangle+\tilde{\beta}| 1,x_1 \rangle| \phi_1 \rangle\;, \ \ \ \ \ (1)" /></p>
<p><a name="eqdef-psi"></a></p>
<p>where we have purposefully spelled out the two possible preimages that the prover could return if challenged. Note that aside from the fact that it gives the ability to obtain <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> or <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" />, this format does not make any assumption on <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" />; in particular the register containing the preimage can be entangled with other private registers of the prover.</p>
<p>We have defined a four-message commitment protocol: the verifier sends the security parameters to prover; the prover sends a commitment string <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> back; an optional one-round preimage test is executed. Now is the time to give a first definition for the single qubit to which the prover has “committed” by returning <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />. This <em>committed qubit</em> is the state <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> that we ultimately aim to show has the claimed expectation values under <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> measurements.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> be the qubit obtained from <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" /> by erasing <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> (which is possible given knowledge of <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />) and returning the first qubit of the resulting state. (Later we will slightly modify this definition, but it is a good placeholder to get us started.) Note that the verifier does not know the state <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" />; in fact, strictly speaking <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> is not present on the prover’s workspace either. The point is that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> exists, and this is all we need. Our remaining task is to find a way for the verifier to extract from the prover measurement outcomes that are distributed as would be a measurement of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> in the <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> basis, without the prover having the ability to deviate. If the verifier can do this, for a basis of her choice, she can choose a basis at random, estimate the expectation value, and check the prover’s claim (the values <img src="https://s0.wp.com/latex.php?latex=%7BE_X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_X}" class="latex" title="{E_X}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BE_Z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_Z}" class="latex" title="{E_Z}" />).</p>
<p>As already mentioned, the key point that we’ll use in order to achieve this is that at the end of the commitment phase, the verifier has obtained some leverage over the prover: given <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> and the trapdoor information, the verifier can recover both <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" />. In contrast, the prover, while it holds the state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" />, is not able to freely operate on it. Without the trapdoor, it can no longer uncompute <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> to recover the initial state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle}" class="latex" title="{| \psi \rangle}" />, and so it can’t obviously apply, say, the unitary on <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" /> that would amount to performing a single-qubit rotation on <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Cpsi+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \psi \rangle}" class="latex" title="{| \psi \rangle}" />.</p>
<p><b> Measuring in the computational basis </b></p>
<p><a name="measuring-in-the-computational-basis"></a></p>
<p>We need to explain how the verifier extracts measurement outcomes in the X (Hadamard) or Z (computational) basis from the prover. For each basis there is a small sub-protocol. At the end of the sub-protocol the verifier records a single bit, that it considers is the outcome obtained by a measurement of the committed qubit, <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" />, in the corresponding basis. We call this bit the verifier’s “decoded bit” for that basis.</p>
<p>The protocol for extracting the outcome of a measurement in the computational basis is straightforward. Recall that by definition the prover’s state after the commitment phase has ended is the state <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" /> in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqdef-psi">(1)</a>. Moreover, recall that we made a choice of basis for the provers’ space such that when the prover is challenged for a preimage of <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, it measures the first <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n+1)}" class="latex" title="{(n+1)}" /> qubits of <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" /> in the computational basis and returns the outcome. Now observe that the first bit of this outcome is <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Ctilde%7B%5Calpha%7D%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\tilde{\alpha}|^2}" class="latex" title="{|\tilde{\alpha}|^2}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Ctilde%7B%5Cbeta%7D%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\tilde{\beta}|^2}" class="latex" title="{|\tilde{\beta}|^2}" />. This is exactly the distribution of the outcome of a measurement of the committed qubit <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> in the computational basis, by definition! Thus to extract a measurement outcome in the computational basis the verifier simply executes the preimage test and records the first bit returned by the prover as the decoded bit.</p>
<p><b> Measuring in the Hadamard basis </b></p>
<p><a name="measuring-in-the-hadamard-basis"></a></p>
<p>Extracting a measurement outcome in the Hadamard basis is more delicate. Recall the form of the prover’s state in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqdef-psi">(1)</a>. Given our definition of the committed qubit <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" />, the natural way to obtain a measurement of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> in the Hadamard basis, starting from <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" />, is to first erase the register containing <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" />, and then perform a Hadamard measurement of the first qubit. But even an honest prover cannot accomplish this, as it does not have the trapdoor information that would allow to erase <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> (of course we purposefully set things up this way). What the prover <em>can</em> do, however, is measure all <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> qubits of the register containing <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0}" class="latex" title="{x_0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_1}" class="latex" title="{x_1}" /> in the Hadamard basis. The result of this measurement is an <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit string <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\in\{0,1\}^n}" class="latex" title="{d\in\{0,1\}^n}" />. The corresponding post-measurement state is, up to global phase,</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ctilde%7B%5Calpha%7D%7C+0+%5Crangle%7C+%5Cphi_0+%5Crangle%2B%28-1%29%5E%7Bd%5Ccdot%28x_0%2B+x_1%29%7D%5Ctilde%7B%5Cbeta%7D%7C+1+%5Crangle%7C+%5Cphi_1+%5Crangle%5C%3B%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \tilde{\alpha}| 0 \rangle| \phi_0 \rangle+(-1)^{d\cdot(x_0+ x_1)}\tilde{\beta}| 1 \rangle| \phi_1 \rangle\;," class="latex" title="\displaystyle \tilde{\alpha}| 0 \rangle| \phi_0 \rangle+(-1)^{d\cdot(x_0+ x_1)}\tilde{\beta}| 1 \rangle| \phi_1 \rangle\;," /></p>
<p>where the addition <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%2Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0+x_1}" class="latex" title="{x_0+x_1}" /> is taken bitwise, modulo <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />. Observe that this state is almost exactly the committed qubit <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> — except for a phase flip, <img src="https://s0.wp.com/latex.php?latex=%7BZ%5E%7Bd%5Ccdot%28x_0%5Coplus+x_1%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z^{d\cdot(x_0\oplus x_1)}}" class="latex" title="{Z^{d\cdot(x_0\oplus x_1)}}" />, applied on the first qubit. If the prover measures the remaining qubit in the Hadamard basis, the phase flip leads to a bit flip on the outcome <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> of the measurement. So the verifier can ask the prover to report both <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" />; if she recourds the decoded bit <img src="https://s0.wp.com/latex.php?latex=%7Bb%3Dm%5Coplus+d%5Ccdot+%28x_0%5Coplus+x_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b=m\oplus d\cdot (x_0\oplus x_1)}" class="latex" title="{b=m\oplus d\cdot (x_0\oplus x_1)}" /> then this bit matches the outcome of a measurement of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> in the Hadamard basis.</p>
<p>This completes the description of the measurement sub-protocol for the Hadamard basis. It is clear that a honest prover, performing the actions described above, will induce the verifier into recording the correct outcome. Now of course in general the prover may act in an arbitrary way! It could report any values for <img src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(m,d)}" class="latex" title="{(m,d)}" />: the verifier accepts any outcomes on faith. How could this possibly work out? There is magic in Mahadev’s proof.</p>
<p><b> Malicious provers </b></p>
<p><a name="malicious-provers"></a></p>
<p>Let’s assume, as we already have, that the prover is arbitrary but that, if tested in the commitment phase, it succeeds with certainty. According to the discussion around <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqdef-psi">(1)</a> this implies that at the end of the commitment phase the prover holds a state of the form <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" />. Moreover, by definition, when asked for a computational basis measurement the prover measures the first <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n+1)}" class="latex" title="{(n+1)}" /> qubits of <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" /> in the computational basis and reports the outcome; the verifier records the first bit as its decoded bit.</p>
<p>As we already argued, our earlier definition of the committed qubit <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> ensures that the verifier’s decoded bit for the case of a computational basis measurement matches the outcome of a measurement of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> in the computational basis. Unfortunately for the case of a Hadamard basis measurement we are in trouble. Since the prover may in principle report an arbitrary pair <img src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(m,d)}" class="latex" title="{(m,d)}" /> there is no chance to argue that this matches (in distribution) the outcome of a measurement of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> in the Hadamard basis. To find a state that is consistent with the verifier’s decoded bit in both bases we need to change our definition of the committed qubit to take into account the prover’s action in the case it is asked for a Hadamard measurement.</p>
<p>Recall that the main leverage that the verifier has over the prover is that, while the prover does have the possibility of reporting arbitrary outcomes <img src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(m,d)}" class="latex" title="{(m,d)}" />, it <em>does not</em> have control over the verifier’s decoding, i.e.~the operation <img src="https://s0.wp.com/latex.php?latex=%7Bb%5Cleftarrow+m%5Coplus+%28d%5Ccdot%28x_0%2B+x_1%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b\leftarrow m\oplus (d\cdot(x_0+ x_1))}" class="latex" title="{b\leftarrow m\oplus (d\cdot(x_0+ x_1))}" />. Let’s work a little bit and spell out the distribution of the verifier’s Hadamard basis decoded bit, <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />. Towards this it is convenient to think of the prover in the following way: the prover first applies an arbitrary unitary “attack” <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" />, then “honestly” measures the first <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n+1)}" class="latex" title="{(n+1)}" /> qubits in the Hadamard basis, and finally reports the <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n+1)}" class="latex" title="{(n+1)}" />-bit outcome <img src="https://s0.wp.com/latex.php?latex=%7B%28m%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(m,d)}" class="latex" title="{(m,d)}" />. An arbitrary <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n+1)}" class="latex" title="{(n+1)}" />-bit-outcome measurement can always be expressed in this way. With this setup we can write the probability that the decoded bit is some value <img src="https://s0.wp.com/latex.php?latex=%7Bb%5Cin%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b\in\{0,1\}}" class="latex" title="{b\in\{0,1\}}" /> as</p>
<p><a name="eqprb-1"></a></p>
<p align="center"><a name="eqprb-1"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%28b%29+%5C%2C%3D%5C%2C+%5Csum_%7Bd%5Cin%5C%7B0%2C1%5C%7D%5En%7D+%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+U%5E%5Cdagger+H+%5Cbig%28%28X%5E%7Bd%5Ccdot%28x_0%2Bx_1%29%7D+%7C+b+%5Crangle%5C%21%5Clangle+b+%7CX%5E%7Bd%5Ccdot%28x_0%2Bx_1%29%7D%29+%5Cotimes+%7C+d+%5Crangle%5C%21%5Clangle+d+%7C%5Cbig%29HU%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5C%3B.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Pr(b) \,=\, \sum_{d\in\{0,1\}^n} \langle \tilde{\psi} | U^\dagger H \big((X^{d\cdot(x_0+x_1)} | b \rangle\!\langle b |X^{d\cdot(x_0+x_1)}) \otimes | d \rangle\!\langle d |\big)HU| \tilde{\psi} \rangle\;. \ \ \ \ \ (2)" class="latex" title="\displaystyle \Pr(b) \,=\, \sum_{d\in\{0,1\}^n} \langle \tilde{\psi} | U^\dagger H \big((X^{d\cdot(x_0+x_1)} | b \rangle\!\langle b |X^{d\cdot(x_0+x_1)}) \otimes | d \rangle\!\langle d |\big)HU| \tilde{\psi} \rangle\;. \ \ \ \ \ (2)" /></p>
<p><a name="eqprb-1"></a></p>
<p>Before we can proceed we should say a little more about the computational assumptions that are placed on the pair of functions <img src="https://s0.wp.com/latex.php?latex=%7B%28f_0%2Cf_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(f_0,f_1)}" class="latex" title="{(f_0,f_1)}" />. Earlier we mentioned this pair of functions should be claw-free, but in fact a little more is needed — though all requirements can ultimately be met by a construction based on the Learning With Errors problem. Rather than state the exact assumptions, I will mention two important consequences. The first is that the pair of functions is “collapsing”, a notion introduced by Unruh in his investigations of <a href="https://link.springer.com/chapter/10.1007/978-3-662-49896-5_18">collision-resistance against quantum attacks</a>. In our context this property implies that it is computationally hard to distinguish between an arbitrary superposition over preimages, as in <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" />, and the “collapsed” state obtained by measuring the control register (the first qubit). The second is that for any <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit string <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> that can be obtained as the outcome of an arbitrary, but computationally efficient, measurement on the collapsed state, the bit <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Ccdot%28x_0%2Bx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\cdot(x_0+x_1)}" class="latex" title="{d\cdot(x_0+x_1)}" /> is computationally indistinguishable from uniform. (This is analogous to a “hardcore bit” property, since <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%2Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0+x_1}" class="latex" title="{x_0+x_1}" /> encodes information about both preimages simultaneously, and such information should not be accessible if the pair <img src="https://s0.wp.com/latex.php?latex=%7B%28f_0%2Cf_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(f_0,f_1)}" class="latex" title="{(f_0,f_1)}" /> is claw-free.)</p>
<p>These two assumptions taken together justify the following two modifications to the expression for <img src="https://s0.wp.com/latex.php?latex=%7B%5CPr%28b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Pr(b)}" class="latex" title="{\Pr(b)}" /> in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqprb-1">(2)</a>, that will lead to a computationally indistinguishable distribution. First, we can “collapse” the first <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n+1)}" class="latex" title="{(n+1)}" /> qubits of <img src="https://s0.wp.com/latex.php?latex=%7B%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{| \tilde{\psi} \rangle}" class="latex" title="{| \tilde{\psi} \rangle}" /> by measuring them in the computational basis. Second, we can replace the bit <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Ccdot%28x_0%2Bx_1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\cdot(x_0+x_1)}" class="latex" title="{d\cdot(x_0+x_1)}" /> by a uniformly random bit <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />. Using that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_d+%7C+d+%5Crangle%5C%21%5Clangle+d+%7C%3D%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_d | d \rangle\!\langle d |=\ensuremath{\mathop{\rm Id}\nolimits}}" class="latex" title="{\sum_d | d \rangle\!\langle d |=\ensuremath{\mathop{\rm Id}\nolimits}}" />, the expression simplifies to</p>
<p><a name="eqprb-3"></a></p>
<p align="center"><a name="eqprb-3"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%7B%5CPr%7D%5E%7B%27%7D%28b%29+%5C%2C%3D%5C%2C+%5Cfrac%7B1%7D%7B4%7D%5Csum_%7Br%5Cin%5C%7B0%2C1%5C%7D%7D+%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+%28Z%5Er+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+%28U%5E%5Cdagger%29+%28Z%5Er+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+H+%5Cbig%28+%7C+b+%5Crangle%5C%21%5Clangle+b+%7C%29+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%5Cbig%29+%28Z%5E%7Br%7D+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+HU+%28Z%5E%7Br%7D+%5Cotimes+%5Censuremath%7B%5Cmathop%7B%5Crm+Id%7D%5Cnolimits%7D%29+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5C%3B%2C+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle {\Pr}^{'}(b) \,=\, \frac{1}{4}\sum_{r\in\{0,1\}} \langle \tilde{\psi} | (Z^r \otimes \ensuremath{\mathop{\rm Id}\nolimits}) (U^\dagger) (Z^r \otimes \ensuremath{\mathop{\rm Id}\nolimits}) H \big( | b \rangle\!\langle b |) \otimes \ensuremath{\mathop{\rm Id}\nolimits}\big) (Z^{r} \otimes \ensuremath{\mathop{\rm Id}\nolimits}) HU (Z^{r} \otimes \ensuremath{\mathop{\rm Id}\nolimits}) | \tilde{\psi} \rangle\;, \ \ \ \ \ (3)" class="latex" title="\displaystyle {\Pr}^{'}(b) \,=\, \frac{1}{4}\sum_{r\in\{0,1\}} \langle \tilde{\psi} | (Z^r \otimes \ensuremath{\mathop{\rm Id}\nolimits}) (U^\dagger) (Z^r \otimes \ensuremath{\mathop{\rm Id}\nolimits}) H \big( | b \rangle\!\langle b |) \otimes \ensuremath{\mathop{\rm Id}\nolimits}\big) (Z^{r} \otimes \ensuremath{\mathop{\rm Id}\nolimits}) HU (Z^{r} \otimes \ensuremath{\mathop{\rm Id}\nolimits}) | \tilde{\psi} \rangle\;, \ \ \ \ \ (3)" /></p>
<p><a name="eqprb-3"></a></p>
<p>where the outermost <img src="https://s0.wp.com/latex.php?latex=%7BZ%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z^r}" class="latex" title="{Z^r}" /> were inserted thanks to the first assumption (the collapsing property), and the innermost <img src="https://s0.wp.com/latex.php?latex=%7BZ%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z^r}" class="latex" title="{Z^r}" /> come from commuting <img src="https://s0.wp.com/latex.php?latex=%7BX%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X^r}" class="latex" title="{X^r}" /> past the Hadamard. I should clarify that obtaining <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqprb-3">(3)</a> formally requires more care. In particular, I made use of computational indistinguishability in an expression that involves a quantity that is hard to compute (the parity <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%2Bx_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0+x_1}" class="latex" title="{x_0+x_1}" />). This is illegal, and to work around the difficulty Mahadev has to introduce some additional ingenious manipulations that I am skipping here.</p>
<p>Note the key effect that the random <img src="https://s0.wp.com/latex.php?latex=%7BZ%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z^r}" class="latex" title="{Z^r}" /> operator has in <a href="https://mycqstate.wordpress.com/Users/Thomas/Dropbox/www/myCQstate/verification2-clean.html#eqprb-3">(3)</a>: it effectively trivializes the action of the prover’s “attack” <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> on the first qubit <em>with respect to the computational basis</em>. Thus the result of this argument is that we have managed to argue that the verifier’s decoded bit <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> associated with the Hadamard basis is <em>computationally indistinguishable</em> from the outcome of a Hadamard measurement on the state</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csigma%27+%3D+%5Cmbox%7B%5Crm+Tr%7D_E%5Cbig%28%28I+%5Cotimes+U_I%29+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+%28I%5Cotimes+U_I%29%5E%5Cdagger%2B+%28X%5Cotimes+U_X%29+%7C+%5Ctilde%7B%5Cpsi%7D+%5Crangle%5Clangle+%5Ctilde%7B%5Cpsi%7D+%7C+%28X+%5Cotimes+U_X%29%5E%5Cdagger+%5Cbig%29+%5C%3B%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \sigma' = \mbox{\rm Tr}_E\big((I \otimes U_I) | \tilde{\psi} \rangle\langle \tilde{\psi} | (I\otimes U_I)^\dagger+ (X\otimes U_X) | \tilde{\psi} \rangle\langle \tilde{\psi} | (X \otimes U_X)^\dagger \big) \;," class="latex" title="\displaystyle \sigma' = \mbox{\rm Tr}_E\big((I \otimes U_I) | \tilde{\psi} \rangle\langle \tilde{\psi} | (I\otimes U_I)^\dagger+ (X\otimes U_X) | \tilde{\psi} \rangle\langle \tilde{\psi} | (X \otimes U_X)^\dagger \big) \;," /></p>
<p>where we expanded the first qubit of the unitary <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> as <img src="https://s0.wp.com/latex.php?latex=%7BU+%3D+I%5Cotimes+U_I+%2B+X+%5Cotimes+U_X+%2B+Z%5Cotimes+U_Z+%2B+XZ+%5Cotimes+U_%7BXZ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U = I\otimes U_I + X \otimes U_X + Z\otimes U_Z + XZ \otimes U_{XZ}}" class="latex" title="{U = I\otimes U_I + X \otimes U_X + Z\otimes U_Z + XZ \otimes U_{XZ}}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> represents all registers except the first qubit. Note that the second term involves an <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> on the first qubit, which has no effect on a measurement in the Hadamard basis. Thus, <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma'}" class="latex" title="{\sigma'}" /> can be updated to a state <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma''}" class="latex" title="{\sigma''}" /> where we have “erased” the <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> operator on the first qubit. Moreover, by definition, a measurement of the first (and only) qubit of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma''}" class="latex" title="{\sigma''}" /> in the computational basis yields an outcome distributed exactly as it would on <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" />. In particular, it is consistent with the verifier’s decoded bit in the computational basis measurement protocol.</p>
<p>We are done! The state <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma'}" class="latex" title="{\sigma'}" /> is a well-defined single-qubit state such that the distribution of decoded bits recorded by the verifier for either basis is computationally indistinguishable from the distribution of outcomes of a measurement of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma'}" class="latex" title="{\sigma'}" /> in the same basis. Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma'}" class="latex" title="{\sigma'}" /> may not “exist” at any point of the protocol. But this is besides the point: as long as <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma'}" class="latex" title="{\sigma'}" /> is a well-defined quantum state, and the verifier correctly records decoded measurement outcomes, this eventually leads to a valid certificate for the prover’s claim that the XZ Hamiltonian that encodes the computation has low enough energy.</p>
<p>Phew. Catch your breath, read this post again (and please do ask for clarifications as needed), and then move on to the beautiful <a href="https://arxiv.org/abs/1804.01082">paper</a>, whose introduction already has more depth than I could provide here, and whose body fills in all the remaining gaps. (This includes how to deal with states that are more than a single qubit, an issue that my presentation of the single-qubit case may make seem more thorny than it is — in fact, it is possible to express the argument given here in a way that makes it relatively straightforward to extend to multiple qubits, though there are some technical issues, explained in Mahadev’s paper.) And then – use the idea to prove something!</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2018/08/06/the-cryptographic-leash/"><span class="datestr">at August 06, 2018 01:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://nisheethvishnoi.wordpress.com/?p=55">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/nisheeth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://nisheethvishnoi.wordpress.com/2018/06/06/an-exposition-on-geodesic-convexity/">An Exposition on Geodesic Convexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I arrived at the Institute for Advanced Study to attend a workshop on <a href="https://www.math.ias.edu/ocit2018/agenda">Optimization, Complexity and Invariant Theory</a> organized by Avi Wigderson. The workshop has an incredibly diverse agenda, also reflected in the participants.</p>
<p>I will talk about <em>Geodesic Convexity: </em>Sometimes, functions that are non-convex in the Euclidean space turn out to be convex if one introduces a suitable metric (or differential structure) and redefines convexity with respect to the induced straight lines — <em>geodesics</em>. Such a function is called <em>geodesically convex. </em>Unlike standard convexity,<em>  w</em>hen does a function have this property and how to optimize it, is not well-understood. My talk will focus on introducing geodesic convexity and <a href="https://arxiv.org/abs/1804.04051">show</a> that the problem of computing the Brascamp-Lieb constant has a succinct geodesically convex formulation.</p>
<p>And, accompanying my talk are <a href="https://nisheethvishnoi.files.wordpress.com/2018/06/geodesicconvexity.pdf" title="GeodesicConvexity">these</a> self-contained and expository notes on differentiation on manifolds, geodesics, and geodesic convexity that are prepared with the help of my student Ozan Yildiz.</p></div>







<p class="date">
by nisheethvishnoi <a href="https://nisheethvishnoi.wordpress.com/2018/06/06/an-exposition-on-geodesic-convexity/"><span class="datestr">at June 06, 2018 10:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://nisheethvishnoi.wordpress.com/?p=30">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/nisheeth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://nisheethvishnoi.wordpress.com/2018/05/26/algorithms-for-convex-optimization/">Lecture Notes on Algorithms for Convex Optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I have been teaching convex optimization methods to students of computer science and machine learning over four years in various forms and styles. Finally, the notes are online <a href="https://nisheethvishnoi.wordpress.com/convex-optimization/">here</a>!</p></div>







<p class="date">
by nisheethvishnoi <a href="https://nisheethvishnoi.wordpress.com/2018/05/26/algorithms-for-convex-optimization/"><span class="datestr">at May 26, 2018 11:12 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1224">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2018/01/23/ucsd-spring-school-on-quantum-computation/">UCSD Spring school on Quantum Computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A couple months from now <a href="http://www.cs.huji.ac.il/~doria/">Dorit Aharonov</a>, <a href="http://www.davidgosset.com/">David Gosset</a> and myself will be giving a short 3.5-day “Spring School” that is meant to be an introduction to recent topics in quantum computing, directed at young researchers in theoretical computer science at large. The <a href="http://cseweb.ucsd.edu/~slovett/workshops/quantum-computation-2018/">school</a> is organized by Shachar Lovett at the University of California in San Diego, from March 19th to 22nd (these dates coincide with Spring break at many universities). Shachar has been organizing such schools successfully for multiple years now (<a href="http://cseweb.ucsd.edu/~slovett/workshops/sum-of-squares-2017/">last year’s school</a> was taught by Boaz Barak and David Steurer on Sums of Squares), and we hope that this year’s will be just as fun (and instructive). The (free) registration deadline is on February 1st, and we have limited funds available to support travel for a few needy students apply <a href="http://cseweb.ucsd.edu/~slovett/workshops/quantum-computation-2018/">here</a> by February 1st.</p>
<p>The past two years, and possibly even more so the coming couple years, may well be remembered as the moment when quantum computing entered the mainstream. Most of us have heard of IBM’s <a href="https://quantumexperience.ng.bluemix.net/qx">quantum computer in the cloud</a>, of Google’s effort in <a href="https://research.google.com/pubs/QuantumAI.html">, and of Microsoft’s naturally fault-tolerant \href</a>. Some of us might also have encountered a few of the <a href="https://en.wikipedia.org/wiki/List_of_companies_involved_in_quantum_computing_or_communication">dozens of startups</a> promising everything from quantum hardware to quantum learning, that seem to be appearing out of nowhere, raising capital in just a few months.</p>
<p>It is an interesting question, better left for wiser times, whether these events will be remembered as the initial sparks of a revolution in computing, or as the height of a “quantum bubble”. Bubble or no bubble, quantum information science is here to stay: while current developments make topics such as the computational power of small-scale quantum computers, the possibilities for testing quantum mechanics, all the more exciting, quantum cryptography, the theory of quantum error-correction, the ever-increasing applications of “quantum techniques” to problems from theoretical computer science, do not hinge on the success of current experiments.</p>
<p>In guise of teaser, our plan for the school is roughly as follows. Each day will have about 6 hours of lecture, a couple hours of informal “TA sessions” (to learn a language, one needs to practice it!), and some time for social interaction. This is a fairly heavy schedule, but if these are the 3.5 days you are going to spend learning about quantum information in your career, we want them to be useful. What this means is that we’ll simultaneously aim to cover the basics, so as to establish a common language, while quickly zooming in to a selection of the most interesting questions, such as the power of alternate models of quantum computation, the theory of quantum error-correction and fault-tolerance, or problems in quantum testing and quantum delegation.</p>
<p>In a little more detail, and although you should not treat this as contractual information, here is a sketch of our program for the school:</p>
<p><b>Day 1:</b> Introduction to quantum information: one qubit, <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />qubits, the quantum circuit model, simple algorithms and computational speed-ups in the query model. Introduction to quantum complexity: the class QMA and the local Hamiltonian problem.</p>
<p><b>Day 2:</b> Protocols for delegating quantum computations. The adiabatic model of computation and its equivalence to the circuit model. Quantum error-correction, stabilizer codes, and fault tolerance.</p>
<p><b>Day 3:</b> Restricted models of computation (shallow circuits, commuting circuits). Testing quantum systems. The quantum PCP conjecture and connection to many-body entanglement. Multi-prover interactive proofs with multiple provers sharing entanglement. Quantum linearity testing.</p>
<p><b>Day 4:</b> More restricted models of computation. Quantum optimization algorithms. Stoquastic Hamiltonians. Quantum Monte-Carlo and simulation.</p>
<p>If you’re not an expert in quantum information, a lot of these topics might not make much sense a priori. This is why you should come! Our goal in these 3.5 days is to summarize what we believe ought to be the highlights of a couple semesters’ worth of graduate courses in quantum information. Aside from the basics in the first day, each lecture will cover a topic of current interest, giving you the ability to understand the importance of recent progress, and start thinking about some of the more TCS-friendly problems. Towards this, we’ll highlight as many open problems as we can think of (and fit in the alloted time), and allow ample time for questions, discussions, and hands-on exercise sessions. Join us: register <a href="http://cseweb.ucsd.edu/~slovett/workshops/quantum-computation-2018/">here</a>!</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2018/01/23/ucsd-spring-school-on-quantum-computation/"><span class="datestr">at January 23, 2018 04:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1218">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2017/08/07/a-beginners-guide-to-pc-chairing/">A beginner’s guide to PC chairing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I recently had the privilege to serve as program committee (PC) chair for the yearly conference on quantum cryptography, <a href="http://2017.qcrypt.net/">QCRYPT’17</a> (note: for obvious public-relations reasons all names of conferences, PC members and authors in this post have been replaced by <em>entirely</em> fictional aliases). Although I had served on the PC of QCRYPT (and other conferences and workshops in quantum information and theoretical computer science) before, this was my first experience as chair. Since I am not aware of any publicly available resources that would help prepare one for this task, I thought I would share selected aspects of my experience here.</p>
<p>It is easiest to organize the discussion in chronological order: I will go through all the steps (and missteps), from the initial invitation email to the final notification to authors (probably safer to stop there – the next step would drag me into a discussion of the authors’ reaction, the consequences of which even the use of aliases may not save me from).</p>
<h2><b>Lights:</b></h2>
<p>You just received that glowing email — “Dear XX, would you be interested to serve as PC chair for ConfY’18?”. Followed by the obligatory series of flattering comments. Such an honor… who would refuse? But don’t jump on that reply-send button just now. Here are a few points to take into consideration before making the decision.</p>
<p>First off, carefully consider the reviewing schedule. The dates of the conference are likely decided already, giving you a good sense of when the submission and notification deadlines will fall. The period in-between represents two to four months of your working life. Are you ready to give them up? I estimate that most days within that period you will have to allocate one to two hours’ work to the PC reviewing process (the load is not evenly spread: during the reviewing phase, it depends how many papers you assign yourself to review; during the discussion phase, it depends on how active you are, whether there is an in-person meeting, etc.). This is a serious commitment, comparable in load to taking on an additional 12-week teaching job. So if you’re already planning on teaching two courses during the same period – think twice.</p>
<p>A second point to consider discussing upfront with the steering committee (SC) is your “mission”. The SC probably has its own idea of the scope of the conference (there might even be a charter), how many papers they would like to be accepted, what justifies a “ConfY-worthy paper”, etc. How rigid are they going to be regarding these points? How much interference can you expect — do you have full latitude in deciding final acceptances (should be)? How flexible is the final number of accepts?</p>
<p>Last but not least, make sure this is something you <em>want</em> to do. How good is ConfY? Does it serve a specific purpose that you value? How often have you attended, or served on the PC? Do you feel competent to make decisions across all areas covered by the conference? Check the past couple years’ accepts. Many conferences are broader than we think, just because when we attend we tend to unconsciously apply a selective bias towards those talks for which we can at least parse the title. This time you’ll have to understand the contents of every single one of the submitted (let alone accepted) papers. So again, is this something you {\textit want} to do?</p>
<h2><b>Camera,</b></h2>
<p><b>Selecting the PC.</b> Now that the fatal decision has been made, my first piece of advice is all too simple: <em>seek advice</em>. Your first task is to form a PC. This is clearly the most influential decision you will make, both in terms of the quality and content of the final program, as well as the ease with which you and your “team” will get there. Choosing a PC is a delicate balancing act. A good mix of seniority and young blood is needed: seniority for the experience, the perspective, and the credibility; young blood for the energy, the taste for novelty, the muscle power. It is a good idea to involve a PC member from the previous installment of the conference; this may in particular help with the more difficult cases of resubmission.</p>
<p>I was fortunate to receive multiple recommendations from the SC, past conference chairs, and colleagues. While you obviously want to favor diversity and broad representation of topic areas, I also recommend selecting PC members with whom one has a personal connection. My experience has been that the amount of effort any one person is willing to put into the PC process varies hugely. It is inevitable that some PC members will eventually drift away. The more connection you have to them the easier it will be to handle irresponsiveness or divergences of opinion.</p>
<p>The more important comment I will make, one which I wish I had been more keenly aware of, is to <em>know your PC</em>. You will eventually select a team of researchers with complementary qualities, not only in terms of the areas that they are familiar with but also in more human terms: some will be good at responding to “quick opinion” calls on difficult papers, while others will have insightful comments about the overall balance of papers in the emerging list of accepted papers, or generate thoughtful advice on the handling of the more tricky cases, etc. At multiple points in the process you will need help; it is crucial to know the right person to turn to, lest you waste precious days or make ill-informed decisions.</p>
<p>With a list of names in hand, you are ready to send out invitations. (Before doing so, consider forming a rough schedule for the reviewing process. This will be needed for PC members to decide whether they will be sufficiently available during the requisite periods.) In my experience this part went smoothly. About <img src="https://s0.wp.com/latex.php?latex=%7B75%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{75\%}" class="latex" title="{75\%}" /> of those on my initial list accepted the invitation (thanks!!). Filling in the remaining slots took a little more time. A small tip: if a researcher does not respond to your invitation within a reasonable delay, or is slow to decide whether to join or not, don’t push too hard: while you need a strong PC, you also need a responsive PC. It is not a good idea to start off in a situation where someone is “doing you a favor” by accepting the invitation as a result of some heavy arm-twisting.</p>
<p><b>Drafting a CFP.</b> The second main item on your pre-submission agenda is the drafting of a call for papers (CFP). This may be done in cooperation with the SC. CFP from previous years can serve as a starting point. Check with last year’s PC chair if they were happy with the wording used, or if they have a posteriori recommendations: did they omit an important area of interest? Were the submission instructions, including formatting guidelines, clear?</p>
<p>A good CFP balances out two conflicting desirata: first, it should make your life easier by ensuring that submissions follow a reasonably homogeneous format, and are presented in a way that facilitates the reviewing process; second, it should not place an unreasonable burden on the authors who, as we all know, have better things to do (and will read the instructions, if they ever read them, no earlier than 23:59 in any timezone – making an overly precise CFP a sure recipe for disaster).</p>
<p>One place where precision <em>is</em> needed is in the formulation of the requirements for rigor and completeness. Are full proofs expected, or will a short 3-page abstract suffice? Or should it be both – a short abstract clearly presenting the main ideas, together with a full paper providing precise complete proofs? Be warned that, whatever the guidelines, they will be stretched, forcing you into quick judgment calls as to whether a submission fits the CFP guidelines.</p>
<p>You should also pay attention to the part of the CFP that concerns the scope of the conference: although for all I know this is all but ignored by most authors, and varies little from year to year, it does play an important role in carving out an inch of originality and specificity for the conference.</p>
<p>Another item on the CFP is the “key dates” that will bound the time available for the reviewing process: the submission deadline and the notification date. Here again there are conflicting requirements: the submission date should be as late as possible (to ensure accepted papers are as fresh as possible by the time the conference takes place), the reviewing phase as long as possible (you’re going to need it…), and the notification as early as possible (so there is time to compile proceedings, when they exist, and for authors to make travel arrangements). In my experience as PC member the time allocated for reviewing almost invariably felt too long – yes, I did write <em>too long</em>. However much time is allocated for the reviewing phase invariably ends up divided into <img src="https://s0.wp.com/latex.php?latex=%7B%5Csim+90%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sim 90\%}" class="latex" title="{\sim 90\%}" /> procrastination and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csim+20%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sim 20\%}" class="latex" title="{\sim 20\%}" /> actual reviewing effort (obviously the actual reviewing gets under way too late for it to be completed by the reviewing deadline, which typically gets overstretched by some <img src="https://s0.wp.com/latex.php?latex=%7B%5Csim+10%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sim 10\%}" class="latex" title="{\sim 10\%}" />). I suggest that a good calendar should allocate a month for collecting reviews, and a month for discussion. This is tight but sufficient, and will ensure that everyone remains engaged throughout. A month for reviewing allows a week for going through papers and identifying those for which external help should be sought; 2-3 weeks for actual reviewing; and a week for collecting reviews, putting the scores together, and scrambling through the last-minute calls for help. Similarly, a month of discussion would allow a week for score homogenization, two weeks to narrow down on the <img src="https://s0.wp.com/latex.php?latex=%7B20%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{20\%}" class="latex" title="{20\%}" /> (say) borderline papers, and a final week to make those tough ultimate decisions. Tight, but feasible. Remember: however much time you allocate, will be taken up!</p>
<p>Now, as good a calendar you may have come up with, <em>plan for delays</em>. In my case I typically informed PC members that “reviews have to be completed by April 29th” and “the discussion phase will start on May 1st”. The “hidden” three days in-between the two dates were more than needed to track down missing reviews. Don’t ask PC members to complete a task the day you need the task completed, as it simply won’t happen: people have busy schedules, operate in different (and sometimes shifting) timezones, and have other deadlines to deal with. To respect your PC you ought to give them a precise calendar that you will follow, so they are able to plan ahead; but you also need to allow for the unavoidable time conflicts, last-minute no-shows, and other unpredictable events.</p>
<p>One last item before you break off. To set up the submissions webpage you’ll need to decide on a reviewing management software. I (quite mistakenly) didn’t give much thought to this. As PC member I had had a decent experience with <a href="http://easychair.org/">easychair</a>, and was under the impression that it was the most commonly used software – and would therefore be easiest to work with for the PC. Even though things went, on the whole, fairly smoothly, I had more than one occasion to regret the decision. The topic would deserve a blog post in itself, and I won’t expand here. Just make sure you carefully consider how easy the software will make different parts of the reviewing process, such as computing statistics, tracking missing reviews, ordering papers based on various criteria, allowing an efficient tagging system to keep track of memos or tentative decisions, handling communication with authors (including possibly the compilation of proceedings), etc.</p>
<h2><b>Action!</b></h2>
<p>Alright, so you went for a stroll and enjoyed your most leisurely conference submission deadline ever – as PC chair, you’re probably not allowed to submit – but the bell has rung, the submission sever closed…now it’s your turn!</p>
<p><b>The last few hours.</b> Actually, maybe this wasn’t quite your most leisurely submission deadline after all. I was advised to elect a “midnight <a href="https://www.timeanddate.com/time/zones/aoe">anywhere on earth</a>” deadline, as this supposedly made the guideline easier to comprehend for everyone. Not only do I now have strong evidence that I am not the only one to find this denomination absurdly confusing – where on earth is this place anyways, anywhere on earth?? – I would in any case strongly suggest setting a deadline that falls at a reasonable time in the PC chair’s timezone. You <em>will</em> get email from people unable to access the submission server (for whatever reason), unsure whether their submission fits the guidelines, asking whether they can get an extension, etc. It is more helpful if you can deal with such email as they arrive, rather than the next day.</p>
<p><b>Paper bidding.</b> Before reviewing can get under way you need to assign papers to PC members. And before you can assign papers, PC members need to express their preferences. The resulting allocation is critical. It determines how many headaches you will face later on: how many papers will have low confidence reviews, how many closely related papers will have been reviewed by disjoint sets of PC members, how many papers will live on the enthusiastic scores of expert <em>sub</em>reviewers. I found this phase challenging. An automatic assignment can be completed in milliseconds, but doesn’t take into account related submissions or expertise of PC members aside from their declared preference, which is a single noisy bit of information. I highly recommend (I realize I am “highly recommending” a lot of things for a first-timer – I only wish I had been told some of these ahead of time!) taking the process very seriously, and spending enough time to review, and tweak, the automatic assignment before it is made final.</p>
<p><b>Refereeing.</b> Each PC member now has a healthy batch of papers assigned, and a deadline by which to submit reviews. What kind of guidelines can you give to make the process as smooth as possible? Discrepancies in scores are always an issue: whichever reviewing software you use, it is bound to produce some kind of score-based ranking; this initial ranking, although it will change during the discussion phase, induces a huge bias in final decisions (this effect is exacerbated for conferences, such as QCRYPT, where there is no in-person meeting). I don’t have a magic solution to this, but establishing clear guidelines in terms of the significance and expected proportion for each numerical score helps. I eventually found it necessary to prod outliers to modify their scores. This is one of the things easychair did not make particularly easy, forcing me to download data in Excel format and run some basic home-made scripts on the spreadsheet.</p>
<p>Aside from scoring, it is useful to include precise guidelines on the use of sub-referees and conflicts of interest (COIs). I allowed sub-refereeing but insisted that the final opinion should be the PC member’s. (It is not ok to copy-paste a sub-review while barely having gone through it!) Unfortunately sub-reviewers tend to be experts, and experts tend to be overly enthusiastic: watch out for papers that received three high scores, each of which with high confidence: easychair will rank those right at the top, but they may well be worth a second look.</p>
<p>Regarding COIs, I did not set overly strict rules (with the idea that “everyone knows when it is appropriate to declare a COI”), and regretted it. It is simply too uncomfortable to realize at a late stage that this very enthusiastic review was written by a PC member who happens to be a close collaborator of one of the authors, but chose not to disclose the COI. Do you discard the review? I don’t know. It depends: maybe the source of the COI played a role in the PC member’s vocal defense of the paper, and maybe not. Better not let it happen. It is not necessarily that even weak COI should forbid reviewing, but rather that COIs should be made explicit. As long as everyone states their position, things are in the open and can be taken into account.</p>
<p><b>Discussion.</b> With all the reviews in (dream on… some reasonable fraction of the reviews in) begins the second phase of the reviewing process, the discussion phase. Success of this phase rests almost entirely on engagement of the PC chair and a few dedicated, dynamic PC members. Among PCs I have sat on the most satisfying were ones where the chair visibly spent large amounts of energy in the stimulation of online discussion. This is no trivial task: we all lead busy lives, and it is easy to let things slip; papers with high scores get in, low scores get out; a few days to discuss the few in the middle and we’ll be done…not so! Unfortunately, the initial ranking is bound to be <em>abysmal</em>. It is necessary to work to straighten things up. Some basic tricks apply: search for papers with high discrepancies in scores, low confidence, missing, very short, or uninformative reviews, etc. It is useful to individually prod PC members to keep the discussion going. This is a place where the “know your PC” recommendation comes in: for each submission, you need to be able to identify who will be able to clarify the arguments in favor and against the paper; who will have the technical expertise to clarify the relationship between papers X and Y, etc. It’s an exhausting, but highly rewarding process: I learned a lot by listening to my colleagues and trying to grasp at times rather subtle – and opinionated – arguments that could reach quite far from my expertise.</p>
<p><b>Decisions!</b> The discussion has been going on for a couple weeks, and you already only have little time left: it is time to start making decisions. Proceeding in phases seems popular, and effective. It helps to progressively sharpen the acceptance threshold. As long as there are too many papers in play it is very hard to get a sense of where the boundary will lie; typically, far too many papers will have positive scores and enthusiastic proponents than can ultimately be accepted.</p>
<p>However much ahead of time you get started, the real decisions will take place in the last few days. I found it helpful to set a clear calendar for the process, marking days when decisions would be made, identifying clear categories (accept, accept?, discuss!, etc.), and setting explicit targets for each phase (accept X/reject Y many more papers, etc.), even if I wasn’t always able to meet them. It is also important that the PC as a whole be aware of the target number of papers that is to be accepted. I have frequently been on PC where the chair gave us the information that “we will accept all great papers”, only to learn later that a hard limit had (of course) been set. Conversely, I’ve also been extremely annoyed at last-minute decisions along the lines of, well, we accepted about as much we could, but there’s 4 left undecided cases, and, well, they’re all really good, so why don’t we just stretch the program a bit and accept all 4 at the last minute. To me this is the PC not doing its job… be prepared to make difficult decisions! Make it clear to the PC (and to yourself) what your goal is. Is it to serve the authors, the conference attendees, the advancement of science – all of the above (good luck)?</p>
<h2><b>Post-mortem</b></h2>
<p>This was fun. Exhausting, but fun. Of course not all authors (or PC members) were happy. There will be complaints. And some of them will be justified: there is no perfect allocation. Mistakes happen. We did our best!</p>
<p>Some tasks lie down the road. Put a program together. Help select a best (student) paper. Gather statistics for the business meeting. But first things first: take a deep breath. This was fun.</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2017/08/07/a-beginners-guide-to-pc-chairing/"><span class="datestr">at August 07, 2017 11:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1209">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2017/06/28/pauli-braiding/">Pauli braiding</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><span style="color: #ff0000;">[<strong>7/9/17 Update</strong>: Following a suggestion by Oded Regev I upgraded Section 1 from “probabilistic functions” to “matrix-valued functions”. This hopefully makes it a more useful, and interesting, mid-point between the classical analysis of BLR and the non-abelian extension discussed afterwards. I also fixed a bunch of typos — I apologize for the many remaining ones. The <a href="http://users.cms.caltech.edu/~vidick/pauli_braiding_1.pdf">pdf</a> has also been fixed.]</span></p>
<p>Last week Anand Natarajan from MIT presented our joint work on “<a href="https://arxiv.org/abs/1610.03574">A Quantum Linearity Test for Robustly Verifying Entanglement</a>” at the <a href="http://acm-stoc.org/stoc2017/">STOC’17</a> conference in Montreal. Since we first posted our paper on the quant-ph arXiv, Anand and I discovered that the test and its analysis could be reformulated in a more general framework of tests for group relations, and rounding of approximate group representations to exact group representations. This reformulation is stimulated by a beautiful paper by Gowers and Hatami on “<a href="https://arxiv.org/abs/1510.04085">Inverse and stability theorems for approximate representations of finite groups</a>”, which was first pointed to me by William Slofstra. The purpose of this post is to present the Gowers-Hatami result as a natural extension of the Blum-Luby-Rubinfeld linearity test to the non-abelian setting, with application to entanglement testing. (Of course Gowers and Hatami are well aware of this — though maybe not of the application to entanglement tests!) My hope in doing so is to make our result more accessible, and hopefully draw some of my readers from theoretical computer science into a beautiful area.</p>
<p>I will strive to make the post self-contained and accessible, with no quantum information background required — indeed, most of the content is purely — dare I say elegantly — mathematical. In the interest of being precise (and working out better parameters for our result than appear in our paper) I include essentially full proofs, though I may allow myself to skip a line or two in some of the calculations.</p>
<p>Given the post remains rather equation-heavy, here is a <a href="http://users.cms.caltech.edu/~vidick/pauli_braiding_1.pdf">pdf</a> with the same contents; it may be more convenient to read.</p>
<p>I am grateful to Anand, and Oded Regev and John Wright, for helpful comments on a preliminary version of this post.</p>
<p><b>1. Linearity testing</b></p>
<p>The Blum-Luby-Rubinfeld linearity test provides a means to certify that a function <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A%7B%5Cmathbb+Z%7D_2%5En%5Crightarrow%5C%7B%5Cpm1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f:{\mathbb Z}_2^n\rightarrow\{\pm1 \}}" class="latex" title="{f:{\mathbb Z}_2^n\rightarrow\{\pm1 \}}" /> is close to a linear function. The test can be formulated as a two-player game:</p>
<p><b>BLR linearity test:</b></p>
<ul>
<li>(a) The referee selects <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%5Cin%7B%5Cmathbb+Z%7D_2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b\in{\mathbb Z}_2^n}" class="latex" title="{a,b\in{\mathbb Z}_2^n}" /> uniformly at random. He sends the pair <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,b)}" class="latex" title="{(a,b)}" /> to one player, and either <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />, or <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a+b}" class="latex" title="{a+b}" /> (chosen uniformly at random) to the other.</li>
<li>(b) The first player replies with two bits, and the second player with a single bit. The referee accepts if and only if the player’s answers satisfy the natural consistency constraint.</li>
</ul>
<p>This test, as all others considered here, treats both players symmetrically. This allows us to restrict our attention to the case of players who both apply the same strategy, an assumption I will systematically make from now on.</p>
<p>Blum et al.’s result states that any strategy for the players in the linearity test must provide answers chosen according to a function that is close to linear. In this section I will provide a slight “matrix-valued” extension of the BLR result, that follows almost directly from the usual Fourier-analytic proof but will help clarify the extension to the non-abelian case.</p>
<p><b>1.1. Matrix-valued strategies</b></p>
<p>The “classical” analysis of the BLR test starts by modeling an arbitrary strategy for the players as a pair of functions <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A%7B%5Cmathbb+Z%7D_2%5En%5Crightarrow+%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f:{\mathbb Z}_2^n\rightarrow \{\pm 1\}}" class="latex" title="{f:{\mathbb Z}_2^n\rightarrow \{\pm 1\}}" /> (for the second player, who receives a single string as query) and <img src="https://s0.wp.com/latex.php?latex=%7Bf%27%3A%7B%5Cmathbb+Z%7D_2%5En+%5Ctimes+%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+%5C%7B%5Cpm+1%5C%7D%5Ctimes%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow \{\pm 1\}\times\{\pm 1\}}" class="latex" title="{f':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow \{\pm 1\}\times\{\pm 1\}}" /> (for the first player, who receives a pair of strings as query). In doing so we are making an assumption: that the players are deterministic. More generally, we should allow “probabilistic strategies”, which can be modeled via “probabilistic functions” <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A%7B%5Cmathbb+Z%7D_2%5En+%5Ctimes+%5COmega+%5Crightarrow+%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f:{\mathbb Z}_2^n \times \Omega \rightarrow \{\pm 1\}}" class="latex" title="{f:{\mathbb Z}_2^n \times \Omega \rightarrow \{\pm 1\}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bf%27%3A%7B%5Cmathbb+Z%7D_2%5En+%5Ctimes+%7B%5Cmathbb+Z%7D_2%5En+%5Ctimes%5COmega%5Crightarrow+%5C%7B%5Cpm+1%5C%7D%5Ctimes%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \times\Omega\rightarrow \{\pm 1\}\times\{\pm 1\}}" class="latex" title="{f':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \times\Omega\rightarrow \{\pm 1\}\times\{\pm 1\}}" /> respectively, where <img src="https://s0.wp.com/latex.php?latex=%7B%28%5COmega%2C%5Cmu%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\Omega,\mu)}" class="latex" title="{(\Omega,\mu)}" /> is an arbitrary probability space which plays the role of shared randomness between the players. Note that the usual claim that “probabilistic strategies are irrelevant because they can succeed no better than deterministic strategies” is somewhat moot here: the point is not to investigate success probabilities — it is easy to pass the BLR test with probability <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> — but rather derive structural consequences from the assumption that a certain strategy passes the test. In this respect, enlarging the kinds of strategies we consider valid can shed new light on the strengths, and weaknesses, of the test.</p>
<p>Thus, and with an eye towards the “quantum” analysis to come, let us consider an even broader set of strategies, which I’ll refer to as “matrix-valued” strategies. A natural matrix-valued analogue of a function <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f:{\mathbb Z}_2^n \rightarrow \{\pm 1\}}" class="latex" title="{f:{\mathbb Z}_2^n \rightarrow \{\pm 1\}}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BF%3A%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+O_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F:{\mathbb Z}_2^n \rightarrow O_d({\mathbb C})}" class="latex" title="{F:{\mathbb Z}_2^n \rightarrow O_d({\mathbb C})}" />, where <img src="https://s0.wp.com/latex.php?latex=%7BO_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O_d({\mathbb C})}" class="latex" title="{O_d({\mathbb C})}" /> is the set of <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\times d}" class="latex" title="{d\times d}" /> Hermitian matrices that square to identity (equivalently, have all eigenvalues in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}}" class="latex" title="{\{\pm 1\}}" />); these matrices are called “observables” in quantum mechanics. Similarly, we may generalize a function <img src="https://s0.wp.com/latex.php?latex=%7Bf%27%3A%7B%5Cmathbb+Z%7D_2%5En+%5Ctimes+%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+%5C%7B%5Cpm+1+%5C%7D+%5Ctimes+%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow \{\pm 1 \} \times \{\pm 1\}}" class="latex" title="{f':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow \{\pm 1 \} \times \{\pm 1\}}" /> to a function <img src="https://s0.wp.com/latex.php?latex=%7BF%27%3A%7B%5Cmathbb+Z%7D_2%5En+%5Ctimes+%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+O_d%28%7B%5Cmathbb+C%7D%29+%5Ctimes+O_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow O_d({\mathbb C}) \times O_d({\mathbb C})}" class="latex" title="{F':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow O_d({\mathbb C}) \times O_d({\mathbb C})}" />. Here we’ll impose an additional requirement: any pair <img src="https://s0.wp.com/latex.php?latex=%7B%28B%2CC%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(B,C)}" class="latex" title="{(B,C)}" /> in the range of <img src="https://s0.wp.com/latex.php?latex=%7BF%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F'}" class="latex" title="{F'}" /> should be such that <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> commute. The latter condition is important so that we can make sense of the function as a strategy for the provers: we should be able to ascribe a probability distribution on outcomes <img src="https://s0.wp.com/latex.php?latex=%7B%28a%2C%28b%2Cc%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a,(b,c))}" class="latex" title="{(a,(b,c))}" /> to any query <img src="https://s0.wp.com/latex.php?latex=%7B%28x%2C%28y%2Cz%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(x,(y,z))}" class="latex" title="{(x,(y,z))}" /> sent to the players. This is achieved by defining<a name="eqmatrixprob"></a></p>
<p align="center"><a name="eqmatrixprob"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%5Cbig%28%28F%28x%29%2C+F%27%28y%2Cz%29%29%3D%28a%2C%28b%2Cc%29%29%5Cbig%29%5C%2C%3D%5C%2C%5Cfrac%7B1%7D%7Bd%7D%5C%2C%5Cmathrm%7BTr%7D%5Cbig%28+F%28x%29%5EaF%27%28y%2Cz%29_1%5Eb+F%27%28y%2Cz%29_2%5Ec%5Cbig%29%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Pr\big((F(x), F'(y,z))=(a,(b,c))\big)\,=\,\frac{1}{d}\,\mathrm{Tr}\big( F(x)^aF'(y,z)_1^b F'(y,z)_2^c\big), \ \ \ \ \ (1)" class="latex" title="\displaystyle \Pr\big((F(x), F'(y,z))=(a,(b,c))\big)\,=\,\frac{1}{d}\,\mathrm{Tr}\big( F(x)^aF'(y,z)_1^b F'(y,z)_2^c\big), \ \ \ \ \ (1)" /></p>
<p><a name="eqmatrixprob"></a>where for any observable <img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O}" class="latex" title="{O}" /> we denote <img src="https://s0.wp.com/latex.php?latex=%7BO%5E%7B%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O^{+1}}" class="latex" title="{O^{+1}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BO%5E%7B-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O^{-1}}" class="latex" title="{O^{-1}}" /> the projections on the <img src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+1}" class="latex" title="{+1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> eigenspaces of <img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O}" class="latex" title="{O}" />, respectively (so <img src="https://s0.wp.com/latex.php?latex=%7BO%3DO%5E%7B%2B1%7D-O%5E%7B-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O=O^{+1}-O^{-1}}" class="latex" title="{O=O^{+1}-O^{-1}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BO%5E%7B%2B1%7D%2BO%5E%7B-1%7D%3DI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O^{+1}+O^{-1}=I}" class="latex" title="{O^{+1}+O^{-1}=I}" />). The condition that <img src="https://s0.wp.com/latex.php?latex=%7BF%27%28y%2Cz%29_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F'(y,z)_1}" class="latex" title="{F'(y,z)_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BF%27%28y%2Cz%29_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F'(y,z)_2}" class="latex" title="{F'(y,z)_2}" /> commute ensures that this expression is always non-negative; moreover it is easy to check that for all <img src="https://s0.wp.com/latex.php?latex=%7B%28x%2C%28y%2Cz%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(x,(y,z))}" class="latex" title="{(x,(y,z))}" /> it specifies a well-defined probability distribution on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5Ctimes+%28%5C%7B%5Cpm1%5C%7D%5Ctimes+%5C%7B%5Cpm1%5C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}\times (\{\pm1\}\times \{\pm1\})}" class="latex" title="{\{\pm 1\}\times (\{\pm1\}\times \{\pm1\})}" /> . Observe also that in case <img src="https://s0.wp.com/latex.php?latex=%7Bd%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d=1}" class="latex" title="{d=1}" /> we recover the classical deterministic case, for which with our notation <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%5Ea+%3D+1_%7Bf%28x%29%3Da%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)^a = 1_{f(x)=a}}" class="latex" title="{f(x)^a = 1_{f(x)=a}}" />. If all <img src="https://s0.wp.com/latex.php?latex=%7BF%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(x)}" class="latex" title="{F(x)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BF%27%28y%2Cz%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F'(y,z)}" class="latex" title="{F'(y,z)}" /> are simultaneously diagonal matrices we recover the probabilistic case, with the role of <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega}" class="latex" title="{\Omega}" /> (the shared randomness) played by the rows of the matrices (hence the normalization of <img src="https://s0.wp.com/latex.php?latex=%7B1%2Fd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/d}" class="latex" title="{1/d}" />; we will see later how to incorporate the use of non-uniform weights).</p>
<p>With these notions in place we establish the following simple lemma, which states the only consequence of the BLR test we will need.</p>
<blockquote><p><b>Lemma 1</b> <em><a name="lemblr-test"></a>Let <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> be an integer, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon\geq 0}" class="latex" title="{\varepsilon\geq 0}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BF%3A%7B%5Cmathbb+Z%7D_2%5En%5Crightarrow+O_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F:{\mathbb Z}_2^n\rightarrow O_d({\mathbb C})}" class="latex" title="{F:{\mathbb Z}_2^n\rightarrow O_d({\mathbb C})}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BF%27%3A%7B%5Cmathbb+Z%7D_2%5En+%5Ctimes+%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+O_d%28%7B%5Cmathbb+C%7D%29%5Ctimes+O_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow O_d({\mathbb C})\times O_d({\mathbb C})}" class="latex" title="{F':{\mathbb Z}_2^n \times {\mathbb Z}_2^n \rightarrow O_d({\mathbb C})\times O_d({\mathbb C})}" /> a matrix strategy for the BLR test, such that players determining their answers according to this strategy (specifically, according to <a href="https://mycqstate.wordpress.com/feed/#eqmatrixprob">(1)</a>) succeed in the test with probability at least <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" />. Then</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D%5C%2C%5Cfrac%7B1%7D%7Bd%7D%5C%2C+%5CRe%5C%2C%5Cmathrm%7BTr%7D%5Cbig%28+F%28x%29F%28y%29F%28x%2By%29%5Cbig%29+%5C%2C%5Cgeq%5C%2C+1-O%28%5Cvarepsilon%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n}\,\frac{1}{d}\, \Re\,\mathrm{Tr}\big( F(x)F(y)F(x+y)\big) \,\geq\, 1-O(\varepsilon). " class="latex" title="\displaystyle \mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n}\,\frac{1}{d}\, \Re\,\mathrm{Tr}\big( F(x)F(y)F(x+y)\big) \,\geq\, 1-O(\varepsilon). " /></p>
</blockquote>
<p>Introducing a normalized inner product <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+A%2CB%5Crangle_f+%3D+d%5E%7B-1%7D+%5Cmathrm%7BTr%7D%28AB%5E%2A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle A,B\rangle_f = d^{-1} \mathrm{Tr}(AB^*)}" class="latex" title="{\langle A,B\rangle_f = d^{-1} \mathrm{Tr}(AB^*)}" /> on the space of <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\times d}" class="latex" title="{d\times d}" /> matrices with complex entries (the <img src="https://s0.wp.com/latex.php?latex=%7B%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^*}" class="latex" title="{^*}" /> designates the conjugate-transpose), the conclusion of the lemma is that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5Clangle+F%28x%29F%28y%29%2C%5C%2CF%28x%2By%29%5Crangle_f+%5C%2C%3D%5C%2C+1-O%28%5Cvarepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \langle F(x)F(y),\,F(x+y)\rangle_f \,=\, 1-O(\varepsilon)}" class="latex" title="{\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \langle F(x)F(y),\,F(x+y)\rangle_f \,=\, 1-O(\varepsilon)}" />.</p>
<p><em>Proof:</em> Success with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" /> in the test implies the three conditions</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%26%26%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C+%5Clangle+F%27%28x%2Cy%29_1%2CF%28x%29%5Crangle_f+%5C%2C%5Cgeq%5C%2C+1-3%5Cvarepsilon%2C%5C%5C+%26%26%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C+%5Clangle+F%27%28x%2Cy%29_2%2CF%28y%29%5Crangle_f+%5C%2C%5Cgeq%5C%2C+1-3%5Cvarepsilon%2C%5C%5C+%26%26%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C+%5Clangle+F%27%28x%2Cy%29_1F%27%28x%2Cy%29_2%2CF%28x%2By%29%5Crangle_f+%5C%2C%5Cgeq%5C%2C+1-3%5Cvarepsilon.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} &amp;&amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \langle F'(x,y)_1,F(x)\rangle_f \,\geq\, 1-3\varepsilon,\\ &amp;&amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \langle F'(x,y)_2,F(y)\rangle_f \,\geq\, 1-3\varepsilon,\\ &amp;&amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \langle F'(x,y)_1F'(x,y)_2,F(x+y)\rangle_f \,\geq\, 1-3\varepsilon. \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} &amp;&amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \langle F'(x,y)_1,F(x)\rangle_f \,\geq\, 1-3\varepsilon,\\ &amp;&amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \langle F'(x,y)_2,F(y)\rangle_f \,\geq\, 1-3\varepsilon,\\ &amp;&amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \langle F'(x,y)_1F'(x,y)_2,F(x+y)\rangle_f \,\geq\, 1-3\varepsilon. \end{array} " /></p>
<p>To conclude, use the triangle inequality as</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%26+%5Cbig%5C%7CF%28x%29F%28y%29-F%28x%2By%29+%5Cbig%5C%7C_f%5E2+%5C%5C+%26+%26%5Cqquad%5Cleq+%5C%2C3%5CBig%28%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C+%5Cbig%5C%7C%28F%28x%29-F%27%28x%2Cy%29_1%29F%28y%29+%5Cbig%5C%7C_f%5E2%5C%5C+%26%26+%5Cqquad%5Cqquad+%2B+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C+%5Cbig%5C%7C%28F%28y%29-F%27%28x%2Cy%29_2%29F%27%28x%2Cy%29_1+%5Cbig%5C%7C_f%5E2%5C%5C+%26%26%5Cqquad%5Cqquad%2B%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C+%5Cbig%5C%7CF%27%28x%2Cy%29_1F%27%28x%2Cy%29_2-F%28x%2By%29+%5Cbig%5C%7C_f%5E2%5CBig%29%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} &amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} &amp; \big\|F(x)F(y)-F(x+y) \big\|_f^2 \\ &amp; &amp;\qquad\leq \,3\Big(\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \big\|(F(x)-F'(x,y)_1)F(y) \big\|_f^2\\ &amp;&amp; \qquad\qquad + \mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \big\|(F(y)-F'(x,y)_2)F'(x,y)_1 \big\|_f^2\\ &amp;&amp;\qquad\qquad+\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \big\|F'(x,y)_1F'(x,y)_2-F(x+y) \big\|_f^2\Big), \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} &amp;\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} &amp; \big\|F(x)F(y)-F(x+y) \big\|_f^2 \\ &amp; &amp;\qquad\leq \,3\Big(\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \big\|(F(x)-F'(x,y)_1)F(y) \big\|_f^2\\ &amp;&amp; \qquad\qquad + \mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \big\|(F(y)-F'(x,y)_2)F'(x,y)_1 \big\|_f^2\\ &amp;&amp;\qquad\qquad+\mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \big\|F'(x,y)_1F'(x,y)_2-F(x+y) \big\|_f^2\Big), \end{array} " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7CA%5C%7C_f%5E2+%3D+%5Clangle+A%2CA%5Crangle_f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|A\|_f^2 = \langle A,A\rangle_f}" class="latex" title="{\|A\|_f^2 = \langle A,A\rangle_f}" /> denotes the dimension-normalized Frobenius norm. Expanding each squared norm and using the preceding conditions and <img src="https://s0.wp.com/latex.php?latex=%7BF%28x%29%5E2%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(x)^2=1}" class="latex" title="{F(x)^2=1}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> proves the lemma. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p><b>1.2. The BLR theorem for matrix-valued strategies</b></p>
<p>Before stating a BLR theorem for matrix-valued strategies we need to define what it means for such a function <img src="https://s0.wp.com/latex.php?latex=%7BG%3A+%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+O_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G: {\mathbb Z}_2^n \rightarrow O_d({\mathbb C})}" class="latex" title="{G: {\mathbb Z}_2^n \rightarrow O_d({\mathbb C})}" /> to be <em>linear</em>. Consider first the case of probabilistic functions, i.e. <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> such that all <img src="https://s0.wp.com/latex.php?latex=%7BG%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G(x)}" class="latex" title="{G(x)}" /> are diagonal, in the same basis. Any such <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> whose every diagonal entry is of the form <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7BS%7D%28x%29+%3D+%28-1%29%5E%7BS+%5Ccdot+x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{S}(x) = (-1)^{S \cdot x}}" class="latex" title="{\chi_{S}(x) = (-1)^{S \cdot x}}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7BS%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S\in\{0,1\}^n}" class="latex" title="{S\in\{0,1\}^n}" /> <em>which may depend on the row/column number</em> will pass the BLR test. This shows that we cannot hope to force <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> to be a single linear function, we must allow “mixtures”. Formally, call <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> linear if <img src="https://s0.wp.com/latex.php?latex=%7BG%28x%29+%3D+%5Csum_S+%5Cchi_S%28x%29+P_S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G(x) = \sum_S \chi_S(x) P_S}" class="latex" title="{G(x) = \sum_S \chi_S(x) P_S}" /> for some decomposition <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BP_S%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{P_S\}}" class="latex" title="{\{P_S\}}" /> of the identity, i.e. the <img src="https://s0.wp.com/latex.php?latex=%7BP_S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_S}" class="latex" title="{P_S}" /> are pairwsie orthogonal projections such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_S+P_S%3DI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_S P_S=I}" class="latex" title="{\sum_S P_S=I}" />. Note that this indeed captures the probabilistic case; in fact, up to a basis change it is essentially equivalent to it. Thus the following may come as a surprise.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="thmblr"></a>Let <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> be an integer, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon\geq 0}" class="latex" title="{\varepsilon\geq 0}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BF%3A%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+O_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F:{\mathbb Z}_2^n \rightarrow O_d({\mathbb C})}" class="latex" title="{F:{\mathbb Z}_2^n \rightarrow O_d({\mathbb C})}" /> such that<a name="eqapprox-linear"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C+%5Cfrac%7B1%7D%7Bd%7D%5C%2C%5CRe%5C%2C%5Clangle+F%28x%29F%28y%29%2CF%28x%2By%29%5Crangle_f+%5C%2C%5Cgeq%5C%2C+1-%5Cvarepsilon.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \frac{1}{d}\,\Re\,\langle F(x)F(y),F(x+y)\rangle_f \,\geq\, 1-\varepsilon. \ \ \ \ \ (2)" class="latex" title="\displaystyle \mathop{\mathbb E}_{x,y\in {\mathbb Z}_2^n} \, \frac{1}{d}\,\Re\,\langle F(x)F(y),F(x+y)\rangle_f \,\geq\, 1-\varepsilon. \ \ \ \ \ (2)" /></p>
<p><em><a name="eqapprox-linear"></a>Then there exists a <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%5Cgeq+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'\geq d}" class="latex" title="{d'\geq d}" />, an isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%3A%7B%5Cmathbb+C%7D%5Ed%5Crightarrow%7B%5Cmathbb+C%7D%5E%7Bd%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V:{\mathbb C}^d\rightarrow{\mathbb C}^{d'}}" class="latex" title="{V:{\mathbb C}^d\rightarrow{\mathbb C}^{d'}}" />, and a linear <img src="https://s0.wp.com/latex.php?latex=%7BG%3A%7B%5Cmathbb+Z%7D_2%5En+%5Crightarrow+O_%7Bd%27%7D%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G:{\mathbb Z}_2^n \rightarrow O_{d'}({\mathbb C})}" class="latex" title="{G:{\mathbb Z}_2^n \rightarrow O_{d'}({\mathbb C})}" /> such that</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%5Cin%7B%5Cmathbb+Z%7D_2%5En%7D+%5C%2C%5Cbig%5C%7C+F%28x%29+-+V%5E%2A+G%28x%29V%5Cbig%5C%7C_f%5E2+%5C%2C%5Cleq%5C%2C+2%5C%2C%5Cvarepsilon.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{x\in{\mathbb Z}_2^n} \,\big\| F(x) - V^* G(x)V\big\|_f^2 \,\leq\, 2\,\varepsilon." class="latex" title="\displaystyle \mathop{\mathbb E}_{x\in{\mathbb Z}_2^n} \,\big\| F(x) - V^* G(x)V\big\|_f^2 \,\leq\, 2\,\varepsilon." /></p>
</blockquote>
<p>Note the role of <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> here, and the lack of control on <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" /> (more on both aspects later). Even if <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is a deterministic function <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" />, i.e. <img src="https://s0.wp.com/latex.php?latex=%7Bd%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d=1}" class="latex" title="{d=1}" />, the function <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> returned by the theorem may be matrix-valued. In this case the isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> is simply a unit vector <img src="https://s0.wp.com/latex.php?latex=%7Bv%5Cin+%7B%5Cmathbb+C%7D%5E%7Bd%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v\in {\mathbb C}^{d'}}" class="latex" title="{v\in {\mathbb C}^{d'}}" />, and expanding out the squared norm in the conclusion of the theorem yields the equivalent conclusion</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_S+%28v%5E%2A+P_S+v%29%5C%2C%5CBig%28%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%7D+f%28x%29%5C%2C+%5Cchi_S%28x%29+%5CBig%29+%5C%2C%5Cgeq%5C%2C+1-%5Cvarepsilon%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \sum_S (v^* P_S v)\,\Big(\mathop{\mathbb E}_{x} f(x)\, \chi_S(x) \Big) \,\geq\, 1-\varepsilon," class="latex" title="\displaystyle \sum_S (v^* P_S v)\,\Big(\mathop{\mathbb E}_{x} f(x)\, \chi_S(x) \Big) \,\geq\, 1-\varepsilon," /></p>
<p>where we expanded <img src="https://s0.wp.com/latex.php?latex=%7BG%28x%29+%3D+%5Csum_S+%5Cchi_S%28x%29+P_S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G(x) = \sum_S \chi_S(x) P_S}" class="latex" title="{G(x) = \sum_S \chi_S(x) P_S}" /> using our definition of a linear matrix-valued function. Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+v%5E%2A+P_S+v%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ v^* P_S v\}}" class="latex" title="{\{ v^* P_S v\}}" /> defines a probability distribution on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0,1\}^n}" class="latex" title="{\{0,1\}^n}" />. Thus by an averaging argument there must exist an <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3D%5Cchi_S%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)=\chi_S(x)}" class="latex" title="{f(x)=\chi_S(x)}" /> for a fraction at least <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon/2}" class="latex" title="{1-\varepsilon/2}" /> of all <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%7B%5Cmathbb+Z%7D_2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in{\mathbb Z}_2^n}" class="latex" title="{x\in{\mathbb Z}_2^n}" />: the usual conclusion of the BLR theorem is recovered.</p>
<p><em>Proof:</em> The proof of the theorem follows the classic <a href="http://ieeexplore.ieee.org/document/556674/">Fourier-analytic proof</a> of Bellare et al. Our first step is to define the isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" />. For a vector <img src="https://s0.wp.com/latex.php?latex=%7Bu%5Cin+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u\in {\mathbb C}^d}" class="latex" title="{u\in {\mathbb C}^d}" />, define</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+V+u+%3D+%5Csum_S+%5Chat%7BF%7D%28S%29+u+%5Cotimes+e_S+%5Cin+%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5E%7B2%5En%7D%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle V u = \sum_S \hat{F}(S) u \otimes e_S \in {\mathbb C}^d \otimes {\mathbb C}^{2^n}," class="latex" title="\displaystyle V u = \sum_S \hat{F}(S) u \otimes e_S \in {\mathbb C}^d \otimes {\mathbb C}^{2^n}," /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7BF%7D%28S%29+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%7D+%5Cchi_S%28x%29+F%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat{F}(S) = \mathop{\mathbb E}_{x} \chi_S(x) F(x)}" class="latex" title="{\hat{F}(S) = \mathop{\mathbb E}_{x} \chi_S(x) F(x)}" /> is the matrix-valued Fourier coefficient of <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> at <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Be_S%5C%7D_%7BS%5Cin%5C%7B0%2C1%5C%7D%5En%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{e_S\}_{S\in\{0,1\}^n}}" class="latex" title="{\{e_S\}_{S\in\{0,1\}^n}}" /> an arbitrary orthonormal basis of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+C%7D%5E%7B2%5En%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb C}^{2^n}}" class="latex" title="{{\mathbb C}^{2^n}}" />. An easily verified extension of Parseval’s formula shows <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_S+%5Chat%7BF%7D%28S%29%5E2+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_S \hat{F}(S)^2 = I}" class="latex" title="{\sum_S \hat{F}(S)^2 = I}" /> (recall <img src="https://s0.wp.com/latex.php?latex=%7BF%28x%29%5E2%3DI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(x)^2=I}" class="latex" title="{F(x)^2=I}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />), so that <img src="https://s0.wp.com/latex.php?latex=%7BV%5E%2AV+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V^*V = I}" class="latex" title="{V^*V = I}" />: <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> is indeed an isometry.</p>
<p>Next, define the linear probabilistic function <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> by <img src="https://s0.wp.com/latex.php?latex=%7BG%28x%29+%3D+%5Csum_S+%5Cchi_S%28x%29+P_S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G(x) = \sum_S \chi_S(x) P_S}" class="latex" title="{G(x) = \sum_S \chi_S(x) P_S}" />, where <img src="https://s0.wp.com/latex.php?latex=%7BP_S+%3D+I+%5Cotimes+e_Se_S%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_S = I \otimes e_Se_S^*}" class="latex" title="{P_S = I \otimes e_Se_S^*}" /> forms a partition of identity. We can evaluate</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%7D+%5C%2C%5Cfrac%7B1%7D%7Bd%7D%5C%2C%5Clangle+F%28x%29%2CV%5E%2AG%28x%29V+%5Crangle_f+%26%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%7D+%5Csum_%7BS%7D%5C%2C%5Cfrac%7B1%7D%7Bd%7D%5C%2C%5Clangle+F%28x%29%2C%5C%2C+%5Cchi_S%28x%29+%5Chat%7BF%7D%28S%29%5E2+%5Crangle_f+%5C%5C+%26%26%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%7D+%5C%2C%5Cfrac%7B1%7D%7Bd%7D%5C%2C%5Clangle+F%28x%2By%29%2C%5C%2CF%28x%29F%28y%29+%5Crangle_f%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} &amp;\mathop{\mathbb E}_{x} \,\frac{1}{d}\,\langle F(x),V^*G(x)V \rangle_f &amp;= \mathop{\mathbb E}_{x} \sum_{S}\,\frac{1}{d}\,\langle F(x),\, \chi_S(x) \hat{F}(S)^2 \rangle_f \\ &amp;&amp;= \mathop{\mathbb E}_{x,y} \,\frac{1}{d}\,\langle F(x+y),\,F(x)F(y) \rangle_f, \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} &amp;\mathop{\mathbb E}_{x} \,\frac{1}{d}\,\langle F(x),V^*G(x)V \rangle_f &amp;= \mathop{\mathbb E}_{x} \sum_{S}\,\frac{1}{d}\,\langle F(x),\, \chi_S(x) \hat{F}(S)^2 \rangle_f \\ &amp;&amp;= \mathop{\mathbb E}_{x,y} \,\frac{1}{d}\,\langle F(x+y),\,F(x)F(y) \rangle_f, \end{array} " /></p>
<p>where the last equality follows by expanding the Fourier coefficients and noticing the appropriate cancellation. Together with <a href="https://mycqstate.wordpress.com/feed/#eqapprox-linear">(2)</a>, this proves the theorem. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>At the risk of sounding yet more pedantic, it might be useful to comment on the relation between this proof and the usual argument. The main observation in Bellare et al.’s proof is that approximate linearity, expressed by <a href="https://mycqstate.wordpress.com/feed/#eqapprox-linear">(2)</a>, implies a lower bound on the sum of the <em>cubes</em> of the Fourier coefficients of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" />. Together with Parseval’s formula, this bound implies the existence of a large Fourier coefficient, which identifies a close-by linear function.</p>
<p>The proof I gave decouples the argument. Its first step, the construction of the isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> depends on <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />, but does not use anything regarding approximate linearity. It only uses Parseval’s formula to argue that the isometry is well-defined. A noteworthy feature of this step is that the function <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> on the extended space is always well-defined as well: given a function <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />, it is always possible to consider the linear matrix-valued function which “samples <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> according to <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7BF%7D%28S%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat{F}(S)^2}" class="latex" title="{\hat{F}(S)^2}" />” and then returns <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_S%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_S(x)}" class="latex" title="{\chi_S(x)}" />. The second step of the proof evaluates the correlation of <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> with the “pull-back” of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />, and observes that this correlation is precisely our measure of “approximate linearity” of <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />, concluding the proof without having had to explicitly notice that there existed a large Fourier coefficient.</p>
<p><b>1.3. The group-theoretic perspective</b></p>
<p>Let’s re-interpret the proof we just gave using group-theoretic language. A linear function <img src="https://s0.wp.com/latex.php?latex=%7Bg%3A+%7B%5Cmathbb+Z%7D_2%5En%5Crightarrow%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g: {\mathbb Z}_2^n\rightarrow\{\pm 1\}}" class="latex" title="{g: {\mathbb Z}_2^n\rightarrow\{\pm 1\}}" /> is, by definition, a mapping which respects the additive group structure on <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+Z%7D_2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb Z}_2^n}" class="latex" title="{{\mathbb Z}_2^n}" />, namely it is a representation. Since <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%28%7B%5Cmathbb+Z%7D_2%5En%2C%2B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G=({\mathbb Z}_2^n,+)}" class="latex" title="{G=({\mathbb Z}_2^n,+)}" /> is an abelian group, it has <img src="https://s0.wp.com/latex.php?latex=%7B%7CG%7C%3D2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|G|=2^n}" class="latex" title="{|G|=2^n}" /> irreducible <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />-dimensional representations, given by the characters <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_S}" class="latex" title="{\chi_S}" />. As such, the linear function defined in the proof of Theorem <a href="https://mycqstate.wordpress.com/feed/#thmblr">2</a> is nothing but a list of all irreducible representations of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />.</p>
<p>The condition <a href="https://mycqstate.wordpress.com/feed/#eqapprox-linear">(2)</a> derived in the proof of the theorem can be interpreted as the condition that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is an “approximate representation” of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />. Let’s make this a general definition. For <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-dimensional matrices <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B}" class="latex" title="{A,B}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> is positive semidefinite, write</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clangle+A%2CB%5Crangle_%5Csigma+%3D+%5Cmathrm%7BTr%7D%28AB%5E%2A+%5Csigma%29%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \langle A,B\rangle_\sigma = \mathrm{Tr}(AB^* \sigma)," class="latex" title="\displaystyle \langle A,B\rangle_\sigma = \mathrm{Tr}(AB^* \sigma)," /></p>
<p>where we use <img src="https://s0.wp.com/latex.php?latex=%7BB%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B^*}" class="latex" title="{B^*}" /> to denote the conjugate-transpose. The following definition considers arbitrary finite groups (not necessarily abelian).</p>
<blockquote><p><b>Definition 3</b> <em>Given a finite group <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />, an integer <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Cgeq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\geq 1}" class="latex" title="{d\geq 1}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon\geq 0}" class="latex" title="{\varepsilon\geq 0}" />, and a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-dimensional positive semidefinite matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> with trace <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cvarepsilon%2C%5Csigma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\varepsilon,\sigma)}" class="latex" title="{(\varepsilon,\sigma)}" />-representation of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is a function <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A+G+%5Crightarrow+U_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f: G \rightarrow U_d({\mathbb C})}" class="latex" title="{f: G \rightarrow U_d({\mathbb C})}" />, the unitary group of <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\times d}" class="latex" title="{d\times d}" /> matrices, such that<a name="eqgh-condition"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%5Cin+G%7D+%5C%2C%5CRe%5Cbig%28%5Cbig%5Clangle+f%28x%29%5E%2Af%28y%29+%2Cf%28x%5E%7B-1%7Dy%29+%5Cbig%5Crangle_%5Csigma%5Cbig%29+%5C%2C%5Cgeq%5C%2C+1-%5Cvarepsilon%2C+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{x,y\in G} \,\Re\big(\big\langle f(x)^*f(y) ,f(x^{-1}y) \big\rangle_\sigma\big) \,\geq\, 1-\varepsilon, \ \ \ \ \ (3)" class="latex" title="\displaystyle \mathop{\mathbb E}_{x,y\in G} \,\Re\big(\big\langle f(x)^*f(y) ,f(x^{-1}y) \big\rangle_\sigma\big) \,\geq\, 1-\varepsilon, \ \ \ \ \ (3)" /></p>
<p><em><a name="eqgh-condition"></a>where the expectation is taken under the uniform distribution over <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />.</em></p></blockquote>
<p>The condition <a href="https://mycqstate.wordpress.com/feed/#eqgh-condition">(3)</a> in the definition is very closely related to Gowers’s <img src="https://s0.wp.com/latex.php?latex=%7BU%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U^2}" class="latex" title="{U^2}" /> norm</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7Cf%5C%7C_%7BU%5E2%7D%5E4+%5C%2C%3D%5C%2C+%5Cmathop%7B%5Cmathbb+E%7D_%7Bxy%5E%7B-1%7D%3Dzw%5E%7B-1%7D%7D%5C%2C+%5Cbig%5Clangle+f%28x%29f%28y%29%5E%2A+%2Cf%28z%29f%28w%29%5E%2A+%5Cbig%5Crangle_%5Csigma.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|f\|_{U^2}^4 \,=\, \mathop{\mathbb E}_{xy^{-1}=zw^{-1}}\, \big\langle f(x)f(y)^* ,f(z)f(w)^* \big\rangle_\sigma." class="latex" title="\displaystyle \|f\|_{U^2}^4 \,=\, \mathop{\mathbb E}_{xy^{-1}=zw^{-1}}\, \big\langle f(x)f(y)^* ,f(z)f(w)^* \big\rangle_\sigma." /></p>
<p>While a large Gowers norm implies closeness to an affine function, we are interested in testing linear functions, and the condition <a href="https://mycqstate.wordpress.com/feed/#eqgh-condition">(3)</a> will arise naturally from our calculations in the next section.</p>
<p>If <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%28%7B%5Cmathbb+Z%7D_2%5En%2C%2B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G=({\mathbb Z}_2^n,+)}" class="latex" title="{G=({\mathbb Z}_2^n,+)}" />, the product <img src="https://s0.wp.com/latex.php?latex=%7Bxy%5E%7B-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{xy^{-1}}" class="latex" title="{xy^{-1}}" /> should be written additively as <img src="https://s0.wp.com/latex.php?latex=%7Bx-y%3Dx%2By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x-y=x+y}" class="latex" title="{x-y=x+y}" />, so that the condition <a href="https://mycqstate.wordpress.com/feed/#eqapprox-linear">(2)</a> is precisely that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cvarepsilon%2C%5Csigma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\varepsilon,\sigma)}" class="latex" title="{(\varepsilon,\sigma)}" />-representation of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma+%3D+d%5E%7B-1%7DI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma = d^{-1}I}" class="latex" title="{\sigma = d^{-1}I}" />. Theorem <a href="https://mycqstate.wordpress.com/feed/#thmblr">2</a> can thus be reformulated as stating that for any <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cvarepsilon%2C%5Csigma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\varepsilon,\sigma)}" class="latex" title="{(\varepsilon,\sigma)}" />-approximate representation of the abelian group <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%28%7B%5Cmathbb+Z%7D_2%5En%2C%2B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G=({\mathbb Z}_2^n,+)}" class="latex" title="{G=({\mathbb Z}_2^n,+)}" /> there exists an isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%3A%7B%5Cmathbb+C%7D%5Ed+%5Crightarrow+%7B%5Cmathbb+C%7D%5Ed%5Cotimes+%7B%5Cmathbb+C%7D%5E%7B2%5En%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V:{\mathbb C}^d \rightarrow {\mathbb C}^d\otimes {\mathbb C}^{2^n}}" class="latex" title="{V:{\mathbb C}^d \rightarrow {\mathbb C}^d\otimes {\mathbb C}^{2^n}}" /> and an exact representation <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5E%7B2%5En%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb C}^d \otimes {\mathbb C}^{2^n}}" class="latex" title="{{\mathbb C}^d \otimes {\mathbb C}^{2^n}}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is well-approximated by the “pull-back” <img src="https://s0.wp.com/latex.php?latex=%7BV%5E%2AgV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V^*gV}" class="latex" title="{V^*gV}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb C}^d}" class="latex" title="{{\mathbb C}^d}" />. In the next section I will make the words in quotes precise and generalize the result to the case of arbitrary finite groups.</p>
<p><b>2. Approximate representations of non-abelian groups</b></p>
<p><b>2.1. The Gowers-Hatami theorem</b></p>
<p>In their paper Gowers and Hatami consider the problem of “rounding” approximate group representations to exact representations. I highly recommend the paper, which gives a thorough introduction to the topic, including multiple motivations. Here I will state and prove a slightly more general, but quantitatively weaker, variant of their result inspired by the somewhat convoluted analysis of the BLR test given in the previous section.</p>
<blockquote><p><b>Theorem 4 (Gowers-Hatami)</b> <em><a name="thmgh"></a>Let <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> be a finite group, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon\geq 0}" class="latex" title="{\varepsilon\geq 0}" />, and <img src="https://s0.wp.com/latex.php?latex=%7Bf%3AG%5Crightarrow+U_d%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f:G\rightarrow U_d({\mathbb C})}" class="latex" title="{f:G\rightarrow U_d({\mathbb C})}" /> an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cvarepsilon%2C%5Csigma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\varepsilon,\sigma)}" class="latex" title="{(\varepsilon,\sigma)}" />-representation of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />. Then there exists a <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%5Cgeq+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'\geq d}" class="latex" title="{d'\geq d}" />, an isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%3A%7B%5Cmathbb+C%7D%5Ed%5Crightarrow+%7B%5Cmathbb+C%7D%5E%7Bd%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V:{\mathbb C}^d\rightarrow {\mathbb C}^{d'}}" class="latex" title="{V:{\mathbb C}^d\rightarrow {\mathbb C}^{d'}}" />, and a representation <img src="https://s0.wp.com/latex.php?latex=%7Bg%3AG%5Crightarrow+U_%7Bd%27%7D%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g:G\rightarrow U_{d'}({\mathbb C})}" class="latex" title="{g:G\rightarrow U_{d'}({\mathbb C})}" /> such that</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%5Cin+G%7D%5C%2C+%5Cbig%5C%7C+f%28x%29+-+V%5E%2Ag%28x%29V+%5Cbig%5C%7C_%5Csigma%5E2%5C%2C+%5Cleq%5C%2C+2%5C%2C%5Cvarepsilon.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{x\in G}\, \big\| f(x) - V^*g(x)V \big\|_\sigma^2\, \leq\, 2\,\varepsilon." class="latex" title="\displaystyle \mathop{\mathbb E}_{x\in G}\, \big\| f(x) - V^*g(x)V \big\|_\sigma^2\, \leq\, 2\,\varepsilon." /></p>
</blockquote>
<p>Gowers and Hatami limit themselves to the case of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma+%3D+d%5E%7B-1%7DI_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma = d^{-1}I_d}" class="latex" title="{\sigma = d^{-1}I_d}" />, which corresponds to the dimension-normalized Frobenius norm. In this scenario they in addition obtain a tight control of the dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" />, and show that one can always take <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%5C+%3D+%281%2BO%28%5Cvarepsilon%29%29d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'\ = (1+O(\varepsilon))d}" class="latex" title="{d'\ = (1+O(\varepsilon))d}" /> in the theorem. I will give a much shorter proof than theirs (the proof is implicit in their argument) that does not seem to allow to recover this estimate. (It is possible to adapt their proof to keep a control of <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" /> even in the case of general <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" />, but I will not explain this here.) Essentially the same proof as the one sketched below has been extended to some classes of infinite groups by De Chiffre, Ozawa and Thom in a <a href="https://arxiv.org/pdf/1706.04544.pdf">recent preprint</a>.</p>
<p>Note that, contrary to the BLR theorem, where the “embedding” is not strictly necessary (if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" /> is small enough we can identify a single close-by linear function), as noted by Gowers and Hatami Theorem <a href="https://mycqstate.wordpress.com/feed/#thmgh">4</a> does not in general hold with <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%3Dd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'=d}" class="latex" title="{d'=d}" />. The reason is that it is possible for <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> to have an approximate representation in some dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />, but no exact representation of the same dimension: to obtain an example of this, take any group <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> that has all non-trivial irreducible representations of large enough dimension, and create an approximate representation in e.g. dimension one less by “cutting off” one row and column from an exact representation. The dimension normalization induced by the norm <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C%5Ccdot%5C%7C_%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|\cdot\|_\sigma}" class="latex" title="{\|\cdot\|_\sigma}" /> will barely notice this, but it will be impossible to “round” the approximate representation obtained to an exact one without modifying the dimension.</p>
<p>The necessity for the embedding helps distinguish the Gowers-Hatami result from other extensions of the linearity test to the non-abelian setting, such as the work by Ben-Or et al. on <a href="https://eccc.weizmann.ac.il/report/2004/052/">non-Abelian homomorphism testing</a> (I thank Oded Regev for pointing me to the paper). In that paper the authors show that a function <img src="https://s0.wp.com/latex.php?latex=%7Bf%3AG%5Crightarrow+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f:G\rightarrow H}" class="latex" title="{f:G\rightarrow H}" />, where <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> are finite non-abelian groups, which satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5CPr%28+f%28x%29f%28y%29%3Df%28xy%29+%29+%5Cgeq+1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Pr( f(x)f(y)=f(xy) ) \geq 1-\varepsilon}" class="latex" title="{\Pr( f(x)f(y)=f(xy) ) \geq 1-\varepsilon}" />, is <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Cvarepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\varepsilon)}" class="latex" title="{O(\varepsilon)}" />-close to a homomorphism <img src="https://s0.wp.com/latex.php?latex=%7Bg%3AG%5Crightarrow+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g:G\rightarrow H}" class="latex" title="{g:G\rightarrow H}" />. The main difference with the setting for the Gowers-Hatami result is that since <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> is finite, Ben-Or et al. use the Kronecker <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> function as distance on <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />. This allows them to employ combinatorial arguments, and provide a rounding procedure that does not need to modify the range space (<img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />). In contrast, here the unitary group is infinite.</p>
<p>The main ingredient needed to extend the analysis of the BLR test is an appropriate notion of Fourier transform over non-abelian groups. Given an irreducible representation <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%3A+G+%5Crightarrow+U_%7Bd_%5Crho%7D%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho: G \rightarrow U_{d_\rho}({\mathbb C})}" class="latex" title="{\rho: G \rightarrow U_{d_\rho}({\mathbb C})}" />, define<a name="eqfourier"></a></p>
<p align="center"><a name="eqfourier"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Chat%7Bf%7D%28%5Crho%29+%5C%2C%3D%5C%2C+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%5Cin+G%7D+%5C%2Cf%28x%29+%5Cotimes+%5Coverline%7B%5Crho%28x%29%7D.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \hat{f}(\rho) \,=\, \mathop{\mathbb E}_{x\in G} \,f(x) \otimes \overline{\rho(x)}. \ \ \ \ \ (4)" class="latex" title="\displaystyle \hat{f}(\rho) \,=\, \mathop{\mathbb E}_{x\in G} \,f(x) \otimes \overline{\rho(x)}. \ \ \ \ \ (4)" /></p>
<p><a name="eqfourier"></a>In case <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is abelian, we always have <img src="https://s0.wp.com/latex.php?latex=%7Bd_%5Crho%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_\rho=1}" class="latex" title="{d_\rho=1}" />, the tensor product is a product, and <a href="https://mycqstate.wordpress.com/feed/#eqfourier">(4)</a> reduces to the usual definition of Fourier coefficient. The only properties we will need of irreducible representations is that they satisfy the relation<a name="eqortho"></a></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csum_%5Crho+%5C%2Cd_%5Crho%5C%2C%5Cmathrm%7BTr%7D%28%5Crho%28x%29%29+%5C%2C%3D%5C%2C+%7CG%7C%5Cdelta_%7Bxe%7D%5C%3B%2C+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \sum_\rho \,d_\rho\,\mathrm{Tr}(\rho(x)) \,=\, |G|\delta_{xe}\;, \ \ \ \ \ (5)" class="latex" title="\displaystyle \sum_\rho \,d_\rho\,\mathrm{Tr}(\rho(x)) \,=\, |G|\delta_{xe}\;, \ \ \ \ \ (5)" /></p>
<p><a name="eqortho"></a>for any <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in G}" class="latex" title="{x\in G}" />. Note that plugging in <img src="https://s0.wp.com/latex.php?latex=%7Bx%3De%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x=e}" class="latex" title="{x=e}" /> (the identity element in <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />) yields <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%5Crho+d_%5Crho%5E2%3D+%7CG%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_\rho d_\rho^2= |G|}" class="latex" title="{\sum_\rho d_\rho^2= |G|}" />.</p>
<p><em>Proof:</em> } As in the proof of Theorem <a href="https://mycqstate.wordpress.com/feed/#thmblr">2</a> our first step is to define an isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%3A%7B%5Cmathbb+C%7D%5Ed+%5Crightarrow+%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%28%5Coplus_%5Crho+%7B%5Cmathbb+C%7D%5E%7Bd_%5Crho%7D+%5Cotimes+%7B%5Cmathbb+C%7D%5E%7Bd_%5Crho%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V:{\mathbb C}^d \rightarrow {\mathbb C}^d \otimes (\oplus_\rho {\mathbb C}^{d_\rho} \otimes {\mathbb C}^{d_\rho})}" class="latex" title="{V:{\mathbb C}^d \rightarrow {\mathbb C}^d \otimes (\oplus_\rho {\mathbb C}^{d_\rho} \otimes {\mathbb C}^{d_\rho})}" /> by</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+V+%3A%5C%3Bu+%5Cin+%7B%5Cmathbb+C%7D%5Ed+%5C%2C%5Cmapsto%5C%2C+%5Cbigoplus_%5Crho+%5C%2Cd_%5Crho%5E%7B1%2F2%7D+%5Csum_%7Bi%3D1%7D%5E%7Bd_%5Crho%7D+%5C%2C%5Cbig%28%5Chat%7Bf%7D%28%5Crho%29+%28u%5Cotimes+e_i%29%5Cbig%29+%5Cotimes+e_i%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle V :\;u \in {\mathbb C}^d \,\mapsto\, \bigoplus_\rho \,d_\rho^{1/2} \sum_{i=1}^{d_\rho} \,\big(\hat{f}(\rho) (u\otimes e_i)\big) \otimes e_i," class="latex" title="\displaystyle V :\;u \in {\mathbb C}^d \,\mapsto\, \bigoplus_\rho \,d_\rho^{1/2} \sum_{i=1}^{d_\rho} \,\big(\hat{f}(\rho) (u\otimes e_i)\big) \otimes e_i," /></p>
<p>where the direct sum ranges over all irreducible representations <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Be_i%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{e_i\}}" class="latex" title="{\{e_i\}}" /> is the canonical basis. Note what <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> does: it “embeds” any vector <img src="https://s0.wp.com/latex.php?latex=%7Bu%5Cin+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u\in {\mathbb C}^d}" class="latex" title="{u\in {\mathbb C}^d}" /> into a direct sum, over irreducible representations <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" />, of a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-dimensional vector of <img src="https://s0.wp.com/latex.php?latex=%7Bd_%5Crho%5Ctimes+d_%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_\rho\times d_\rho}" class="latex" title="{d_\rho\times d_\rho}" /> matrices. Each (matrix) entry of this vector can be thought of as the Fourier coefficient of the corresponding entry of the vector <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29u%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)u}" class="latex" title="{f(x)u}" /> associated with <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" />. If <img src="https://s0.wp.com/latex.php?latex=%7BG%3D%7B%5Cmathbb+Z%7D_2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G={\mathbb Z}_2^n}" class="latex" title="{G={\mathbb Z}_2^n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> ranges over <img src="https://s0.wp.com/latex.php?latex=%7BO_%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O_({\mathbb C})}" class="latex" title="{O_({\mathbb C})}" /> this recovers the isometry defined in the proof of Theorem <a href="https://mycqstate.wordpress.com/feed/#thmblr">2</a>. And indeed, the fact that <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> is an isometry again follows from the appropriate extension of Parseval’s formula:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%26+V%5E%2A+V+%26%3D+%5Csum_%5Crho+d_%5Crho+%5Csum_i+%28I%5Cotimes+e_i%5E%2A%29+%5Chat%7Bf%7D%28%5Crho%29%5E%2A%5Chat%7Bf%7D%28%5Crho%29+%28I%5Cotimes+e_i%29%5C%5C+%26%26%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%7D%5C%2C+f%28x%29%5E%2Af%28y%29+%5Csum_%5Crho+d_%5Crho+%5Csum_i+%28e_i%5E%2A+%5Crho%28x%29%5ET+%5Coverline%7B%5Crho%28y%29%7D+e_i%29%5C%5C+%26%26%3D+%5Csum_%5Crho+%5Cfrac%7Bd_%5Crho%5E2%7D%7B%7CG%7C%7DI+%3D+I%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} &amp; V^* V &amp;= \sum_\rho d_\rho \sum_i (I\otimes e_i^*) \hat{f}(\rho)^*\hat{f}(\rho) (I\otimes e_i)\\ &amp;&amp;= \mathop{\mathbb E}_{x,y}\, f(x)^*f(y) \sum_\rho d_\rho \sum_i (e_i^* \rho(x)^T \overline{\rho(y)} e_i)\\ &amp;&amp;= \sum_\rho \frac{d_\rho^2}{|G|}I = I, \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} &amp; V^* V &amp;= \sum_\rho d_\rho \sum_i (I\otimes e_i^*) \hat{f}(\rho)^*\hat{f}(\rho) (I\otimes e_i)\\ &amp;&amp;= \mathop{\mathbb E}_{x,y}\, f(x)^*f(y) \sum_\rho d_\rho \sum_i (e_i^* \rho(x)^T \overline{\rho(y)} e_i)\\ &amp;&amp;= \sum_\rho \frac{d_\rho^2}{|G|}I = I, \end{array} " /></p>
<p>where for the second line we used the definition <a href="https://mycqstate.wordpress.com/feed/#eqfourier">(4)</a> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7Bf%7D%28%5Crho%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat{f}(\rho)}" class="latex" title="{\hat{f}(\rho)}" /> and for the third we used <a href="https://mycqstate.wordpress.com/feed/#eqortho">(5)</a> and the fact that <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> takes values in the unitary group.</p>
<p>Following the same steps as in the proof of Theorem <a href="https://mycqstate.wordpress.com/feed/#thmblr">2</a>, we next define</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+g%28x%29+%3D+%5Cbigoplus_%5Crho+%5C%2C%5Cbig%28I_d+%5Cotimes+I_%7Bd_%5Crho%7D+%5Cotimes+%5Crho%28x%29%5Cbig%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle g(x) = \bigoplus_\rho \,\big(I_d \otimes I_{d_\rho} \otimes \rho(x)\big), " class="latex" title="\displaystyle g(x) = \bigoplus_\rho \,\big(I_d \otimes I_{d_\rho} \otimes \rho(x)\big), " /></p>
<p>a direct sum over all irreducible representations of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> (hence itself a representation). Lets’ first compute the “pull-back” of <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> by <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" />: following a similar calculation as above, for any <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in G}" class="latex" title="{x\in G}" />,</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%26+V%5E%2Ag%28x%29+V+%26%3D+%5Csum_%7B%5Crho%7D+d_%5Crho+%5Csum_%7Bi%2Cj%7D+%28I%5Cotimes+e_i%5E%2A%29%5Chat%7Bf%7D%28%5Crho%29%5E%2A+%5Chat%7Bf%7D%28%5Crho%29%28I%5Cotimes+e_j%29+%5Cotimes+e_i%5E%2A+%5Crho%28x%29+e_j+%29+%5C%5C+%26%26+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bz%2Cy%7D%5C%2C+f%28z%29%5E%2Af%28y%29+%5Csum_%7B%5Crho%7D+d_%5Crho+%5Csum_%7Bi%2Cj%7D+%28e_i%5E%2A+%5Crho%28z%29%5ET+%5Coverline%7B%5Crho%28y%29%7D+e_j%29+%5Cbig%28+e_i%5E%2A+%5Crho%28x%29+e_j+%5Cbig%29+%5C%5C+%26%26+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bz%2Cy%7D%5C%2C+f%28z%29%5E%2Af%28y%29+%5Csum_%7B%5Crho%7D+d_%5Crho+%5Cmathrm%7BTr%7D%5Cbig%28+%5Crho%28z%29%5ET+%5Coverline%7B%5Crho%28y%29%7D+%7B%5Crho%28x%29%5ET%7D+%5Cbig%29+%5C%5C+%26%26+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bz%2Cy%7D%5C%2C+f%28z%29%5E%2Af%28y%29+%5Csum_%7B%5Crho%7D+d_%5Crho+%5Cmathrm%7BTr%7D%5Cbig%28+%5Crho%28z%5E%7B-1%7Dy+x%5E%7B-1%7D%29+%5Cbig%29+%5C%5C+%26%26+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bz%7D%5C%2C+f%28z%29%5E%2Af%28zx%29+%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} &amp; V^*g(x) V &amp;= \sum_{\rho} d_\rho \sum_{i,j} (I\otimes e_i^*)\hat{f}(\rho)^* \hat{f}(\rho)(I\otimes e_j) \otimes e_i^* \rho(x) e_j ) \\ &amp;&amp; = \mathop{\mathbb E}_{z,y}\, f(z)^*f(y) \sum_{\rho} d_\rho \sum_{i,j} (e_i^* \rho(z)^T \overline{\rho(y)} e_j) \big( e_i^* \rho(x) e_j \big) \\ &amp;&amp; = \mathop{\mathbb E}_{z,y}\, f(z)^*f(y) \sum_{\rho} d_\rho \mathrm{Tr}\big( \rho(z)^T \overline{\rho(y)} {\rho(x)^T} \big) \\ &amp;&amp; = \mathop{\mathbb E}_{z,y}\, f(z)^*f(y) \sum_{\rho} d_\rho \mathrm{Tr}\big( \rho(z^{-1}y x^{-1}) \big) \\ &amp;&amp; = \mathop{\mathbb E}_{z}\, f(z)^*f(zx) , \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} &amp; V^*g(x) V &amp;= \sum_{\rho} d_\rho \sum_{i,j} (I\otimes e_i^*)\hat{f}(\rho)^* \hat{f}(\rho)(I\otimes e_j) \otimes e_i^* \rho(x) e_j ) \\ &amp;&amp; = \mathop{\mathbb E}_{z,y}\, f(z)^*f(y) \sum_{\rho} d_\rho \sum_{i,j} (e_i^* \rho(z)^T \overline{\rho(y)} e_j) \big( e_i^* \rho(x) e_j \big) \\ &amp;&amp; = \mathop{\mathbb E}_{z,y}\, f(z)^*f(y) \sum_{\rho} d_\rho \mathrm{Tr}\big( \rho(z)^T \overline{\rho(y)} {\rho(x)^T} \big) \\ &amp;&amp; = \mathop{\mathbb E}_{z,y}\, f(z)^*f(y) \sum_{\rho} d_\rho \mathrm{Tr}\big( \rho(z^{-1}y x^{-1}) \big) \\ &amp;&amp; = \mathop{\mathbb E}_{z}\, f(z)^*f(zx) , \end{array} " /></p>
<p>where the last equality uses <a href="https://mycqstate.wordpress.com/feed/#eqortho">(5)</a>. It then follows that</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%7D%5C%2C+%5Cbig%5Clangle+f%28x%29%2C+V%5E%2Ag%28x%29+V+%5Cbig%5Crangle_%5Csigma+%26%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cz%7D+%5Cmathrm%7BTr%7D%5Cbig%28+f%28x%29+f%28zx%29%5E%2A+f%28z%29%5Csigma%5Cbig%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} &amp;\mathop{\mathbb E}_{x}\, \big\langle f(x), V^*g(x) V \big\rangle_\sigma &amp;= \mathop{\mathbb E}_{x,z} \mathrm{Tr}\big( f(x) f(zx)^* f(z)\sigma\big). \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} &amp;\mathop{\mathbb E}_{x}\, \big\langle f(x), V^*g(x) V \big\rangle_\sigma &amp;= \mathop{\mathbb E}_{x,z} \mathrm{Tr}\big( f(x) f(zx)^* f(z)\sigma\big). \end{array} " /></p>
<p>This relates correlation of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> with <img src="https://s0.wp.com/latex.php?latex=%7BV%5E%2AgV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V^*gV}" class="latex" title="{V^*gV}" /> to the quality of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> as an approximate representation and proves the theorem. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p><b>2.2. Application: the Weyl-Heisenberg group</b></p>
<p>In quantum information we care a lot about the <a href="https://en.wikipedia.org/wiki/Pauli_group">Pauli group</a>. For our purposes it will be be sufficient (and much more convenient, allowing us to avoid some trouble with complex conjugation) to consider the Weyl-Heisenberg group <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />, or “Pauli group modulo complex conjugation”, which is the <img src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{8}" class="latex" title="{8}" />-element group <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+%5Csigma_I%2C%5Cpm+%5Csigma_X%2C%5Cpm+%5Csigma_Z%2C%5Cpm+%5Csigma_W%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm \sigma_I,\pm \sigma_X,\pm \sigma_Z,\pm \sigma_W\}}" class="latex" title="{\{\pm \sigma_I,\pm \sigma_X,\pm \sigma_Z,\pm \sigma_W\}}" /> whose multiplication table matches that of the <img src="https://s0.wp.com/latex.php?latex=%7B2%5Ctimes+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2\times 2}" class="latex" title="{2\times 2}" /> matrices<a name="eqdef-pauli"></a></p>
<p align="center"><a name="eqdef-pauli"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csigma_X+%3D+%5Cbegin%7Bpmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bpmatrix%7D%2C%5Cqquad+%5Csigma_Z%3D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%5C%5C+0+%26+-1+%5Cend%7Bpmatrix%7D%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \sigma_X = \begin{pmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{pmatrix},\qquad \sigma_Z= \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{pmatrix}, \ \ \ \ \ (6)" class="latex" title="\displaystyle \sigma_X = \begin{pmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{pmatrix},\qquad \sigma_Z= \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; -1 \end{pmatrix}, \ \ \ \ \ (6)" /></p>
<p><a name="eqdef-pauli"></a><img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_I+%3D+%5Csigma_X%5E2+%3D+%5Csigma_Z%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_I = \sigma_X^2 = \sigma_Z^2}" class="latex" title="{\sigma_I = \sigma_X^2 = \sigma_Z^2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_W%3D%5Csigma_X%5Csigma_Z%3D-%5Csigma_Z%5Csigma_X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_W=\sigma_X\sigma_Z=-\sigma_Z\sigma_X}" class="latex" title="{\sigma_W=\sigma_X\sigma_Z=-\sigma_Z\sigma_X}" />. This group has four <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />-dimensional representations, uniquely specified by the image of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_X%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_X}" class="latex" title="{\sigma_X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_Z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_Z}" class="latex" title="{\sigma_Z}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}}" class="latex" title="{\{\pm 1\}}" />, and a single irreducible <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />-dimensional representation, given by the matrices defined above. We can also consider the “<img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit Weyl-Heisenberg group” <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(n)}}" class="latex" title="{H^{(n)}}" />, the matrix group generated by <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-fold tensor products of the <img src="https://s0.wp.com/latex.php?latex=%7B8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{8}" class="latex" title="{8}" /> matrices identified above. The irreducible representations of <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(n)}}" class="latex" title="{H^{(n)}}" /> are easily computed from those of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />; for us the only thing that matters is that the only irreducible representation which satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%28-I%29%3D-%5Crho%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho(-I)=-\rho(I)}" class="latex" title="{\rho(-I)=-\rho(I)}" /> has dimension <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n}" class="latex" title="{2^n}" /> and is given by the defining matrix representation (in fact, it is the only irreducible representation in dimension larger than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />).</p>
<p>With the upcoming application to entanglement testing in mind, I will state a version of Theorem <a href="https://mycqstate.wordpress.com/feed/#thmgh">4</a> tailored to the group <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(n)}}" class="latex" title="{H^{(n)}}" /> and a specific choice of presentation for the group relations. Towards this we first need to recall the notion of <em>Schmidt decomposition</em> of a bipartite state (i.e. unit vector) <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi+%5Cin+%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi \in {\mathbb C}^d \otimes {\mathbb C}^d}" class="latex" title="{\psi \in {\mathbb C}^d \otimes {\mathbb C}^d}" />. The Schmidt decomposition states that any such vector can be written as<a name="eqschmidt"></a></p>
<p align="center"><a name="eqschmidt"></a><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cpsi+%5C%2C%3D%5C%2C+%5Csum_i+%5C%2C%5Csqrt%7B%5Clambda_i%7D%5C%2C+u_i+%5Cotimes+v_i%2C+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \psi \,=\, \sum_i \,\sqrt{\lambda_i}\, u_i \otimes v_i, \ \ \ \ \ (7)" class="latex" title="\displaystyle \psi \,=\, \sum_i \,\sqrt{\lambda_i}\, u_i \otimes v_i, \ \ \ \ \ (7)" /></p>
<p><a name="eqschmidt"></a>for some orthonomal bases <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bu_i%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{u_i\}}" class="latex" title="{\{u_i\}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bv_i%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{v_i\}}" class="latex" title="{\{v_i\}}" /> of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb C}^d}" class="latex" title="{{\mathbb C}^d}" /> (the “Schmidt vectors”) and non-negative coefficients <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B%5Clambda_i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{\lambda_i}}" class="latex" title="{\sqrt{\lambda_i}}" /> (the “Schmidt coefficients”). The decomposition can be obtained by “reshaping” <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi+%3D+%5Csum_%7Bi%2Cj%7D+%5Cpsi_%7Bi%2Cj%7D+e_i+%5Cotimes+e_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi = \sum_{i,j} \psi_{i,j} e_i \otimes e_j}" class="latex" title="{\psi = \sum_{i,j} \psi_{i,j} e_i \otimes e_j}" /> into a <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\times d}" class="latex" title="{d\times d}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7BK%3D%28%5Cpsi_%7Bi%2Cj%7D%29_%7B1%5Cleq+i%2Cj%5Cleq+d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K=(\psi_{i,j})_{1\leq i,j\leq d}}" class="latex" title="{K=(\psi_{i,j})_{1\leq i,j\leq d}}" /> and performing the singular value decomposition. To <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> we associate the (uniquely defined) positive semidefinite matrix<a name="eqsigma"></a></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csigma+%5C%2C%3D%5C%2C+KK%5E%2A+%5C%2C%3D%5C%2C+%5Csum_i+%5Clambda_i%5C%2Cu_iu_i%5E%2A%5C%3B+%3B+%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \sigma \,=\, KK^* \,=\, \sum_i \lambda_i\,u_iu_i^*\; ; \ \ \ \ \ (8)" class="latex" title="\displaystyle \sigma \,=\, KK^* \,=\, \sum_i \lambda_i\,u_iu_i^*\; ; \ \ \ \ \ (8)" /></p>
<p><a name="eqsigma"></a>note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> has trace <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. The matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> is called the <em>reduced density</em> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> (on the first system).</p>
<blockquote><p><b>Corollary 5</b> <em><a name="corgh"></a>Let <img src="https://s0.wp.com/latex.php?latex=%7Bn%2Cd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n,d}" class="latex" title="{n,d}" /> be integer, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon \geq 0}" class="latex" title="{\varepsilon \geq 0}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi+%5Cin+%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi \in {\mathbb C}^d \otimes {\mathbb C}^d}" class="latex" title="{\psi \in {\mathbb C}^d \otimes {\mathbb C}^d}" /> a unit vector, <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> the positive semidefinite matrix associated to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> as in <a href="https://mycqstate.wordpress.com/feed/#eqsigma">(8)</a>, and <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A+%5C%7BX%2CZ%5C%7D%5Ctimes+%5C%7B0%2C1%5C%7D%5En+%5Crightarrow+U%28%7B%5Cmathbb+C%7D%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f: \{X,Z\}\times \{0,1\}^n \rightarrow U({\mathbb C}^d)}" class="latex" title="{f: \{X,Z\}\times \{0,1\}^n \rightarrow U({\mathbb C}^d)}" />. For <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b\in\{0,1\}^n}" class="latex" title="{a,b\in\{0,1\}^n}" /> let <img src="https://s0.wp.com/latex.php?latex=%7BX%28a%29%3Df%28X%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X(a)=f(X,a)}" class="latex" title="{X(a)=f(X,a)}" />, <img src="https://s0.wp.com/latex.php?latex=%7BZ%28b%29%3Df%28Z%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z(b)=f(Z,b)}" class="latex" title="{Z(b)=f(Z,b)}" />, and assume <img src="https://s0.wp.com/latex.php?latex=%7BX%28a%29%5E2%3DZ%28b%29%5E2%3DI_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X(a)^2=Z(b)^2=I_d}" class="latex" title="{X(a)^2=Z(b)^2=I_d}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b}" class="latex" title="{a,b}" /> (we call such operators, unitaries with eigenvalues in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}}" class="latex" title="{\{\pm 1\}}" />, observables). Suppose that the following inequalities hold: consistency<a name="eqgh-cons"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_a+%5C%2C+%5Cpsi%5E%2A+%5Cbig%28X%28a%29+%5Cotimes+X%28a%29%5Cbig%29+%5Cpsi+%5C%2C%5Cgeq%5C%2C1-%5Cvarepsilon%2C%5Cqquad+%5Cmathop%7B%5Cmathbb+E%7D_b+%5C%2C+%5Cpsi%5E%2A+%5Cbig%28Z%28b%29+%5Cotimes+Z%28b%29+%5Cbig%29%5Cpsi%5C%2C%5Cgeq%5C%2C1-%5Cvarepsilon%2C+%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_a \, \psi^* \big(X(a) \otimes X(a)\big) \psi \,\geq\,1-\varepsilon,\qquad \mathop{\mathbb E}_b \, \psi^* \big(Z(b) \otimes Z(b) \big)\psi\,\geq\,1-\varepsilon, \ \ \ \ \ (9)" class="latex" title="\displaystyle \mathop{\mathbb E}_a \, \psi^* \big(X(a) \otimes X(a)\big) \psi \,\geq\,1-\varepsilon,\qquad \mathop{\mathbb E}_b \, \psi^* \big(Z(b) \otimes Z(b) \big)\psi\,\geq\,1-\varepsilon, \ \ \ \ \ (9)" /></p>
<p><em><a name="eqgh-cons"></a>linearity<a name="eqgh-commute"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Ca%27%7D+%5C%2C%5Cbig%5C%7CX%28a%29X%28a%27%29-X%28a%2Ba%27%29%5Cbig%5C%7C_%5Csigma%5E2+%5Cleq+%5Cvarepsilon%2C%5Cqquad%5Cmathop%7B%5Cmathbb+E%7D_%7Bb%2Cb%27%7D%5C%2C+%5Cbig%5C%7CZ%28b%29Z%28b%27%29-Z%28b%2Bb%27%29%5Cbig%5C%7C_%5Csigma%5E2+%5Cleq+%5Cvarepsilon%2C+%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,a'} \,\big\|X(a)X(a')-X(a+a')\big\|_\sigma^2 \leq \varepsilon,\qquad\mathop{\mathbb E}_{b,b'}\, \big\|Z(b)Z(b')-Z(b+b')\big\|_\sigma^2 \leq \varepsilon, \ \ \ \ \ (10)" class="latex" title="\displaystyle \mathop{\mathbb E}_{a,a'} \,\big\|X(a)X(a')-X(a+a')\big\|_\sigma^2 \leq \varepsilon,\qquad\mathop{\mathbb E}_{b,b'}\, \big\|Z(b)Z(b')-Z(b+b')\big\|_\sigma^2 \leq \varepsilon, \ \ \ \ \ (10)" /></p>
<p><em><a name="eqgh-commute"></a>and anti-commutation<a name="eqgh-ac"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Cb%7D+%5C%2C%5Cbig%5C%7C+X%28a%29Z%28b%29-%28-1%29%5E%7Ba%5Ccdot+b%7D+X%28a%29Z%28b%29%5Cbig%5C%7C_%5Csigma%5E2%5C%2C%5Cleq%5C%2C%5Cvarepsilon.+%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,b} \,\big\| X(a)Z(b)-(-1)^{a\cdot b} X(a)Z(b)\big\|_\sigma^2\,\leq\,\varepsilon. \ \ \ \ \ (11)" class="latex" title="\displaystyle \mathop{\mathbb E}_{a,b} \,\big\| X(a)Z(b)-(-1)^{a\cdot b} X(a)Z(b)\big\|_\sigma^2\,\leq\,\varepsilon. \ \ \ \ \ (11)" /></p>
<p><em><a name="eqgh-ac"></a>Then there exists a <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%5Cgeq+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'\geq d}" class="latex" title="{d'\geq d}" />, an isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%3A%7B%5Cmathbb+C%7D%5Ed%5Crightarrow+%7B%5Cmathbb+C%7D%5E%7Bd%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V:{\mathbb C}^d\rightarrow {\mathbb C}^{d'}}" class="latex" title="{V:{\mathbb C}^d\rightarrow {\mathbb C}^{d'}}" />, and a representation <img src="https://s0.wp.com/latex.php?latex=%7Bg%3AH%5E%7B%28n%29%7D%5Crightarrow+U_%7Bd%27%7D%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g:H^{(n)}\rightarrow U_{d'}({\mathbb C})}" class="latex" title="{g:H^{(n)}\rightarrow U_{d'}({\mathbb C})}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bg%28-I%29%3D-I_%7Bd%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(-I)=-I_{d'}}" class="latex" title="{g(-I)=-I_{d'}}" /> and</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Cb%7D%5C%2C+%5Cbig%5C%7C+X%28a%29Z%28b%29+-+V%5E%2Ag%28%5Csigma_X%28a%29%5Csigma_Z%28b%29%29V+%5Cbig%5C%7C_%5Csigma%5E2+%5C%2C%3D%5C%2C+O%28%5Cvarepsilon%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,b}\, \big\| X(a)Z(b) - V^*g(\sigma_X(a)\sigma_Z(b))V \big\|_\sigma^2 \,=\, O(\varepsilon)." class="latex" title="\displaystyle \mathop{\mathbb E}_{a,b}\, \big\| X(a)Z(b) - V^*g(\sigma_X(a)\sigma_Z(b))V \big\|_\sigma^2 \,=\, O(\varepsilon)." /></p>
</blockquote>
<p>Note that the conditions <a href="https://mycqstate.wordpress.com/feed/#eqgh-commute">(10)</a> and <a href="https://mycqstate.wordpress.com/feed/#eqgh-ac">(11)</a> in the corollary are very similar to the conditions required of an approximate representation of the group <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(n)}}" class="latex" title="{H^{(n)}}" />; in fact it is easy to convince oneself that their exact analogue suffice to imply all the group relations. The reason for including only those relations is that they are the ones that it will be possible to test; see the next section for this. Condition <a href="https://mycqstate.wordpress.com/feed/#eqgh-cons">(9)</a> is necessary to derive the conditions of Theorem <a href="https://mycqstate.wordpress.com/feed/#thmgh">4</a> from <a href="https://mycqstate.wordpress.com/feed/#eqgh-commute">(10)</a> and <a href="https://mycqstate.wordpress.com/feed/#eqgh-ac">(11)</a>, and is also testable; see the proof.</p>
<p><em>Proof:</em> To apply Theorem <a href="https://mycqstate.wordpress.com/feed/#thmgh">4</a> we need to construct an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cvarepsilon%2C%5Csigma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\varepsilon,\sigma)}" class="latex" title="{(\varepsilon,\sigma)}" />-representation <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> of the group <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(n)}}" class="latex" title="{H^{(n)}}" />. Using that any element of <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(n)}}" class="latex" title="{H^{(n)}}" /> has a unique representative of the form <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+%5Csigma_X%28a%29%5Csigma_Z%28b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pm \sigma_X(a)\sigma_Z(b)}" class="latex" title="{\pm \sigma_X(a)\sigma_Z(b)}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b\in\{0,1\}^n}" class="latex" title="{a,b\in\{0,1\}^n}" />, we define <img src="https://s0.wp.com/latex.php?latex=%7Bf%28%5Cpm+%5Csigma_X%28a%29%5Csigma_Z%28b%29%29+%3D+%5Cpm+X%28a%29Z%28b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(\pm \sigma_X(a)\sigma_Z(b)) = \pm X(a)Z(b)}" class="latex" title="{f(\pm \sigma_X(a)\sigma_Z(b)) = \pm X(a)Z(b)}" />. Next we need to verify <a href="https://mycqstate.wordpress.com/feed/#eqgh-condition">(3)</a>. Let <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%5Cin+H%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y\in H^{(n)}}" class="latex" title="{x,y\in H^{(n)}}" /> be such that <img src="https://s0.wp.com/latex.php?latex=%7Bx%3D%5Csigma_X%28a_x%29%5Csigma_Z%28b_x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x=\sigma_X(a_x)\sigma_Z(b_x)}" class="latex" title="{x=\sigma_X(a_x)\sigma_Z(b_x)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%3D%5Csigma_X%28a_y%29%5Csigma_Z%28b_y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y=\sigma_X(a_y)\sigma_Z(b_y)}" class="latex" title="{y=\sigma_X(a_y)\sigma_Z(b_y)}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit strings <img src="https://s0.wp.com/latex.php?latex=%7B%28a_x%2Cb_x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a_x,b_x)}" class="latex" title="{(a_x,b_x)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%28a_y%2Cb_y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a_y,b_y)}" class="latex" title="{(a_y,b_y)}" /> respectively. Up to phase, we can exploit successive cancellations to decompose <img src="https://s0.wp.com/latex.php?latex=%7B%28f%28x%29f%28y%29%5E%2A-f%28xy%5E%7B-1%7D%29%29%5Cotimes+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(f(x)f(y)^*-f(xy^{-1}))\otimes I}" class="latex" title="{(f(x)f(y)^*-f(xy^{-1}))\otimes I}" /> as</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%26%26%5Cbig%28+X%28a_x%29Z%28b_x%29X%28a_y%29Z%28b_y%29+-%28-1%29%5E%7Ba_y%5Ccdot+b_x%7D+X%28a_x%2Ba_y%29+Z%28b_x%2Bb_y%29%5Cbig%29%5Cotimes+I+%5C%5C+%26%26%5Cqquad+%3D+X%28a_x%29Z%28b_x%29X%28a_y%29%5Cbig+%28Z%28b_y%29%5Cotimes+I+-+I%5Cotimes+Z%28b_y%29%5Cbig%29%5C%5C+%26%26+%5Cqquad%5Cqquad%2B+X%28a_x%29%5Cbig%28Z%28b_x%29X%28a_y%29+-+%28-1%29%5E%7Ba_y%5Ccdot+b_x%7D+X%28a_y%29Z%28b_x%29%5Cbig%29%5Cotimes+Z%28b_y%29%5C%5C+%26%26+%5Cqquad%5Cqquad%2B%28-1%29%5E%7Ba_y%5Ccdot+b_x%7D+%5Cbig%28+X%28a_x%29X%28a_y%29%5Cotimes+Z%28b_y%29%5Cbig%29+%5Cbig%28+Z%28b_x%29%5Cotimes+I+-+I%5Cotimes+Z%28b_x%29%5Cbig%29%5C%5C+%26%26+%5Cqquad%5Cqquad%2B+%28-1%29%5E%7Ba_y%5Ccdot+b_x%7D+%5Cbig%28+X%28a_x%29X%28a_y%29%5Cotimes+Z%28b_y%29Z%28b_x%29+-+X%28a_x%2Ba_y%29%5Cotimes+Z%28b_x%2Bb_y%29%5Cbig%29%5C%5C+%26%26+%5Cqquad%5Cqquad%2B+%28-1%29%5E%7Ba_y%5Ccdot+b_x%7D+%5Cbig%28+X%28a_x%2Ba_y%29%5Cotimes+I+%5Cbig%29%5Cbig%28I%5Cotimes+Z%28b_x%2Bb_y%29+-+Z%28b_x%2Bb_y%29%5Cotimes+I%5Cbig%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} &amp;&amp;\big( X(a_x)Z(b_x)X(a_y)Z(b_y) -(-1)^{a_y\cdot b_x} X(a_x+a_y) Z(b_x+b_y)\big)\otimes I \\ &amp;&amp;\qquad = X(a_x)Z(b_x)X(a_y)\big (Z(b_y)\otimes I - I\otimes Z(b_y)\big)\\ &amp;&amp; \qquad\qquad+ X(a_x)\big(Z(b_x)X(a_y) - (-1)^{a_y\cdot b_x} X(a_y)Z(b_x)\big)\otimes Z(b_y)\\ &amp;&amp; \qquad\qquad+(-1)^{a_y\cdot b_x} \big( X(a_x)X(a_y)\otimes Z(b_y)\big) \big( Z(b_x)\otimes I - I\otimes Z(b_x)\big)\\ &amp;&amp; \qquad\qquad+ (-1)^{a_y\cdot b_x} \big( X(a_x)X(a_y)\otimes Z(b_y)Z(b_x) - X(a_x+a_y)\otimes Z(b_x+b_y)\big)\\ &amp;&amp; \qquad\qquad+ (-1)^{a_y\cdot b_x} \big( X(a_x+a_y)\otimes I \big)\big(I\otimes Z(b_x+b_y) - Z(b_x+b_y)\otimes I\big). \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} &amp;&amp;\big( X(a_x)Z(b_x)X(a_y)Z(b_y) -(-1)^{a_y\cdot b_x} X(a_x+a_y) Z(b_x+b_y)\big)\otimes I \\ &amp;&amp;\qquad = X(a_x)Z(b_x)X(a_y)\big (Z(b_y)\otimes I - I\otimes Z(b_y)\big)\\ &amp;&amp; \qquad\qquad+ X(a_x)\big(Z(b_x)X(a_y) - (-1)^{a_y\cdot b_x} X(a_y)Z(b_x)\big)\otimes Z(b_y)\\ &amp;&amp; \qquad\qquad+(-1)^{a_y\cdot b_x} \big( X(a_x)X(a_y)\otimes Z(b_y)\big) \big( Z(b_x)\otimes I - I\otimes Z(b_x)\big)\\ &amp;&amp; \qquad\qquad+ (-1)^{a_y\cdot b_x} \big( X(a_x)X(a_y)\otimes Z(b_y)Z(b_x) - X(a_x+a_y)\otimes Z(b_x+b_y)\big)\\ &amp;&amp; \qquad\qquad+ (-1)^{a_y\cdot b_x} \big( X(a_x+a_y)\otimes I \big)\big(I\otimes Z(b_x+b_y) - Z(b_x+b_y)\otimes I\big). \end{array} " /></p>
<p>(It is worth staring at this sequence of equations for a little bit. In particular, note the “player-switching” that takes place in the 2nd, 4th and 6th lines; this is used as a means to “commute” the appropriate unitaries, and is the reason for including <a href="https://mycqstate.wordpress.com/feed/#eqgh-cons">(9)</a> among the assumptions of the corollary.) Evaluating each term on the vector <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" />, taking the squared Euclidean norm, and then the expectation over uniformly random <img src="https://s0.wp.com/latex.php?latex=%7Ba_x%2Ca_y%2Cb_x%2Cb_y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_x,a_y,b_x,b_y}" class="latex" title="{a_x,a_y,b_x,b_y}" />, the inequality <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C+AB%5Cpsi%5C%7C+%5Cleq+%5C%7CA%5C%7C%5C%7CB%5Cpsi%5C%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\| AB\psi\| \leq \|A\|\|B\psi\|}" class="latex" title="{\| AB\psi\| \leq \|A\|\|B\psi\|}" /> and the assumptions of the theorem let us bound the overlap of each term in the resulting summation by <img src="https://s0.wp.com/latex.php?latex=%7BO%28%7B%5Cvarepsilon%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O({\varepsilon})}" class="latex" title="{O({\varepsilon})}" />. Using <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C+%28A%5Cotimes+I%29+%5Cpsi%5C%7C+%3D+%5C%7CA%5C%7C_%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\| (A\otimes I) \psi\| = \|A\|_\sigma}" class="latex" title="{\| (A\otimes I) \psi\| = \|A\|_\sigma}" /> by definition, we obtain the bound</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Bx%2Cy%7D%5C%2C%5Cbig%5C%7Cf%28x%29f%28y%29%5E%2A+-+f%28xy%5E%7B-1%7D%29%5Cbig%5C%7C_%5Csigma%5E2+%5C%2C%3D%5C%2C+O%28%7B%5Cvarepsilon%7D%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{x,y}\,\big\|f(x)f(y)^* - f(xy^{-1})\big\|_\sigma^2 \,=\, O({\varepsilon})." class="latex" title="\displaystyle \mathop{\mathbb E}_{x,y}\,\big\|f(x)f(y)^* - f(xy^{-1})\big\|_\sigma^2 \,=\, O({\varepsilon})." /></p>
<p>We are thus in a position to apply Theorem <a href="https://mycqstate.wordpress.com/feed/#thmgh">4</a>, which gives an isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> and exact representation <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> such that<a name="eqgi"></a></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Cb%7D%5C%2C%5CBig%5C%7C+X%28a%29Z%28b%29-+%5Cfrac%7B1%7D%7B2%7DV%5E%2A%5Cbig%28+g%28%5Csigma_X%28a%29%5Csigma_Z%28b%29%29+-+g%28-%5Csigma_X%28a%29%5Csigma_Z%28b%29%29%5Cbig%29V%5CBig%5C%7C_%5Csigma%5E2+%5C%2C%3D%5C%2C+O%28%7B%5Cvarepsilon%7D%29.+%5C+%5C+%5C+%5C+%5C+%2812%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,b}\,\Big\| X(a)Z(b)- \frac{1}{2}V^*\big( g(\sigma_X(a)\sigma_Z(b)) - g(-\sigma_X(a)\sigma_Z(b))\big)V\Big\|_\sigma^2 \,=\, O({\varepsilon}). \ \ \ \ \ (12)" class="latex" title="\displaystyle \mathop{\mathbb E}_{a,b}\,\Big\| X(a)Z(b)- \frac{1}{2}V^*\big( g(\sigma_X(a)\sigma_Z(b)) - g(-\sigma_X(a)\sigma_Z(b))\big)V\Big\|_\sigma^2 \,=\, O({\varepsilon}). \ \ \ \ \ (12)" /></p>
<p><a name="eqgi"></a>Using that <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> is a representation, <img src="https://s0.wp.com/latex.php?latex=%7Bg%28-%5Csigma_X%28a%29%5Csigma_Z%28b%29%29+%3D+g%28-I%29g%28%5Csigma_X%28a%29%5Csigma_Z%28b%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(-\sigma_X(a)\sigma_Z(b)) = g(-I)g(\sigma_X(a)\sigma_Z(b))}" class="latex" title="{g(-\sigma_X(a)\sigma_Z(b)) = g(-I)g(\sigma_X(a)\sigma_Z(b))}" />. It follows from <a href="https://mycqstate.wordpress.com/feed/#eqgi">(12)</a> that <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cg%28-I%29+%2B+I+%5C%7C_%5Csigma%5E2+%3D+O%28%7B%5Cvarepsilon%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|g(-I) + I \|_\sigma^2 = O({\varepsilon})}" class="latex" title="{\|g(-I) + I \|_\sigma^2 = O({\varepsilon})}" />, so we may restrict the range of <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> to the subspace where <img src="https://s0.wp.com/latex.php?latex=%7Bg%28-I%29%3D-I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(-I)=-I}" class="latex" title="{g(-I)=-I}" /> without introducing much additional error. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p><b>3. Entanglement testing</b></p>
<p>Our discussion so far has barely touched upon the notion of entanglement. Recall the Schmidt decopmosition <a href="https://mycqstate.wordpress.com/feed/#eqschmidt">(7)</a> of a unit vector <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi+%5Cin+%7B%5Cmathbb+C%7D%5Ed%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi \in {\mathbb C}^d\otimes {\mathbb C}^d}" class="latex" title="{\psi \in {\mathbb C}^d\otimes {\mathbb C}^d}" />, and the associated reduced density matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" /> defined in <a href="https://mycqstate.wordpress.com/feed/#eqsigma">(8)</a>. The state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> is called <em>entangled</em> if this matrix has rank larger than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />; equivalently, if there is more than one non-zero coefficient <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda_i}" class="latex" title="{\lambda_i}" /> in <a href="https://mycqstate.wordpress.com/feed/#eqschmidt">(7)</a>. The <em>Schmidt rank</em> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> is the rank of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma}" class="latex" title="{\sigma}" />, the number of non-zero terms in <a href="https://mycqstate.wordpress.com/feed/#eqschmidt">(7)</a>. It is a crude, but convenient, measure of entanglement; in particular it provides a lower bound on the local dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />. A useful observation is that the Schmidt rank is invariant under local unitary operations: these may affect the Schmidt vectors <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bu_i%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{u_i\}}" class="latex" title="{\{u_i\}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bv_i%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{v_i\}}" class="latex" title="{\{v_i\}}" />, but not the number of non-zero terms.</p>
<p><b>3.1. A certificate for high-dimensional entanglement</b></p>
<p>Among all entangled states in dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />, the <em>maximally entangled state</em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_d}" class="latex" title="{\phi_d}" /> is the one which maximizes entanglement entropy, defined as the Shannon entropy of the distribution induced by the squares of the Schmidt coefficients:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cphi_d+%5C%2C%3D%5C%2C+%5Cfrac%7B1%7D%7B%5Csqrt%7Bd%7D%7D+%5Csum_%7Bi%3D1%7D%5Ed%5C%2C+e_i%5Cotimes+e_i%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \phi_d \,=\, \frac{1}{\sqrt{d}} \sum_{i=1}^d\, e_i\otimes e_i," class="latex" title="\displaystyle \phi_d \,=\, \frac{1}{\sqrt{d}} \sum_{i=1}^d\, e_i\otimes e_i," /></p>
<p>with entropy <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log d}" class="latex" title="{\log d}" />. The following lemma gives a “robust” characterization of the maximally entangled state in dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%3D2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d=2^n}" class="latex" title="{d=2^n}" /> as the unique common eigenvalue-<img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> eigenvector of all operators of the form <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_P+%5Cotimes+%5Csigma_P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_P \otimes \sigma_P}" class="latex" title="{\sigma_P \otimes \sigma_P}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_P}" class="latex" title="{\sigma_P}" /> ranges over the elements of the unique <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n}" class="latex" title="{2^n}" />-dimensional irreducible representation of the Weyl-Heisenberg group <img src="https://s0.wp.com/latex.php?latex=%7BH%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H^{(n)}}" class="latex" title="{H^{(n)}}" />, i.e. the Pauli matrices (taken modulo <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{-1}}" class="latex" title="{\sqrt{-1}}" />).</p>
<blockquote><p><b>Lemma 6</b> <em><a name="lemsr"></a>Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon\geq 0}" class="latex" title="{\varepsilon\geq 0}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> an integer, <img src="https://s0.wp.com/latex.php?latex=%7Bd%3D2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d=2^n}" class="latex" title="{d=2^n}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5Cin+%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi\in {\mathbb C}^d \otimes {\mathbb C}^d}" class="latex" title="{\psi\in {\mathbb C}^d \otimes {\mathbb C}^d}" /> a unit vector such that<a name="eqlem-ass"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Cb%7D%5C%2C+%5Cpsi%5E%2A+%5Cbig%28%5Csigma_X%28a%29+%5Csigma_Z%28b%29%5Cotimes+%5Csigma_X%28a%29+%5Csigma_Z%28b%29+%5Cbig%29+%5Cpsi+%5Cgeq+1-%5Cvarepsilon.+%5C+%5C+%5C+%5C+%5C+%2813%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,b}\, \psi^* \big(\sigma_X(a) \sigma_Z(b)\otimes \sigma_X(a) \sigma_Z(b) \big) \psi \geq 1-\varepsilon. \ \ \ \ \ (13)" class="latex" title="\displaystyle \mathop{\mathbb E}_{a,b}\, \psi^* \big(\sigma_X(a) \sigma_Z(b)\otimes \sigma_X(a) \sigma_Z(b) \big) \psi \geq 1-\varepsilon. \ \ \ \ \ (13)" /></p>
<p><em><a name="eqlem-ass"></a>Then <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5E%2A%5Cphi_%7B2%5En%7D%7C%5E2+%5Cgeq+1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi^*\phi_{2^n}|^2 \geq 1-\varepsilon}" class="latex" title="{|\psi^*\phi_{2^n}|^2 \geq 1-\varepsilon}" />. In particular, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> has Schmidt rank at least <img src="https://s0.wp.com/latex.php?latex=%7B%281-%5Cvarepsilon%29+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1-\varepsilon) 2^n}" class="latex" title="{(1-\varepsilon) 2^n}" />.</em></p></blockquote>
<p><em>Proof:</em> Consider the case <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=1}" class="latex" title="{n=1}" />. The “swap” matrix</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+S+%3D+%5Cfrac%7B1%7D%7B4%7D%5Cbig%28%5Csigma_I+%5Cotimes+%5Csigma_I+%2B+%5Csigma_X+%5Cotimes+%5Csigma_X+%2B+%5Csigma_Z+%5Cotimes+%5Csigma_Z+%2B+%5Csigma_W+%5Cotimes+%5Csigma_W%5Cbig%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle S = \frac{1}{4}\big(\sigma_I \otimes \sigma_I + \sigma_X \otimes \sigma_X + \sigma_Z \otimes \sigma_Z + \sigma_W \otimes \sigma_W\big)" class="latex" title="\displaystyle S = \frac{1}{4}\big(\sigma_I \otimes \sigma_I + \sigma_X \otimes \sigma_X + \sigma_Z \otimes \sigma_Z + \sigma_W \otimes \sigma_W\big)" /></p>
<p>squares to identity and has a unique eigenvalue-<img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> eigenvector, the vector <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_2+%3D+%28e_1%5Cotimes+e_1+%2B+e_2%5Cotimes+e_2%29%2F%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_2 = (e_1\otimes e_1 + e_2\otimes e_2)/\sqrt{2}}" class="latex" title="{\phi_2 = (e_1\otimes e_1 + e_2\otimes e_2)/\sqrt{2}}" /> (a.k.a. “EPR pair”). Thus <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5E%2A+S+%5Cpsi+%5Cgeq+1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi^* S \psi \geq 1-\varepsilon}" class="latex" title="{\psi^* S \psi \geq 1-\varepsilon}" /> implies <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5E%2A+%5Cphi%7C%5E2+%5Cgeq+1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi^* \phi|^2 \geq 1-\varepsilon}" class="latex" title="{|\psi^* \phi|^2 \geq 1-\varepsilon}" />. The same argument for general <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> shows <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5E%2A+%5Cphi_%7B2%5En%7D%7C%5E2+%5Cgeq+1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi^* \phi_{2^n}|^2 \geq 1-\varepsilon}" class="latex" title="{|\psi^* \phi_{2^n}|^2 \geq 1-\varepsilon}" />. Any unit vector <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> of Schmidt rank at most <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%7Cu%5E%2A+%5Cphi_%7B2%5En%7D%7C%5E2+%5Cleq+r2%5E%7B-n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|u^* \phi_{2^n}|^2 \leq r2^{-n}}" class="latex" title="{|u^* \phi_{2^n}|^2 \leq r2^{-n}}" />, concluding the proof. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>Lemma <a href="https://mycqstate.wordpress.com/feed/#lemsr">6</a> provides an “experimental road-map” for establishing that a bipartite system is in a highly entangled state:</p>
<ul>
<li>(i) Select a random <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_P+%3D+%5Cpm%5Csigma_X%28a%29%5Csigma_Z%28b%29+%5Cin+H%5E%7B%28n%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_P = \pm\sigma_X(a)\sigma_Z(b) \in H^{(n)}}" class="latex" title="{\sigma_P = \pm\sigma_X(a)\sigma_Z(b) \in H^{(n)}}" />;</li>
<li>(ii) Measure both halves of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> using <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_P}" class="latex" title="{\sigma_P}" />;</li>
<li>(iii) Check that the outcomes agree.</li>
</ul>
<p>To explain the connection between the above “operational test” and the lemma I should review what a measurement in quantum mechanics is. For our purposes it is enough to talk about binary measurements (i.e. measurements with two outcomes, <img src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+1}" class="latex" title="{+1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" />). Any such measurement is specified by a pair of orthogonal projections, <img src="https://s0.wp.com/latex.php?latex=%7BM_%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_+}" class="latex" title="{M_+}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM_-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_-}" class="latex" title="{M_-}" />, on <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb C}^d}" class="latex" title="{{\mathbb C}^d}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BM_%2B%2BM_-+%3D+I_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_++M_- = I_d}" class="latex" title="{M_++M_- = I_d}" />. The probability of obtaining outcome <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pm}" class="latex" title="{\pm}" /> when measuring <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7CM_%5Cpm+%5Cpsi%5C%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|M_\pm \psi\|^2}" class="latex" title="{\|M_\pm \psi\|^2}" />. We can represent a binary measurement succinctly through the <em>observable</em> <img src="https://s0.wp.com/latex.php?latex=%7BM%3DM_%2B-M_-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M=M_+-M_-}" class="latex" title="{M=M_+-M_-}" />. (In general, an observable is a Hermitian matrix which squares to identity.) It is then the case that if an observable <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is applied on the first half of a state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5Cin%7B%5Cmathbb+C%7D%5Ed%5Cotimes%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi\in{\mathbb C}^d\otimes{\mathbb C}^d}" class="latex" title="{\psi\in{\mathbb C}^d\otimes{\mathbb C}^d}" />, and another observable <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> is applied on the second half, then the probability of agreement, minus the probability of disagreement, between the outcomes obtained is precisely <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5E%2A%28M%5Cotimes+N%29%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi^*(M\otimes N)\psi}" class="latex" title="{\psi^*(M\otimes N)\psi}" />, a number which lies in <img src="https://s0.wp.com/latex.php?latex=%7B%5B-1%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[-1,1]}" class="latex" title="{[-1,1]}" />. Thus the condition that the test described above accepts with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" /> when performed on a state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> is precisely equivalent to the assumption <a href="https://mycqstate.wordpress.com/feed/#eqlem-ass">(13)</a> of Lemma <a href="https://mycqstate.wordpress.com/feed/#lemsr">6</a>.</p>
<p>Even though this provides a perfectly fine test for entanglement in principle, practitioners in the foundations of quantum mechanics know all too well that their opponents — e.g. “quantum-skeptics” — will not be satisfied with such an experiment. In particular, who is to guarantee that the measurement performed in step (ii) is really <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_P%5Cotimes%5Csigma_P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_P\otimes\sigma_P}" class="latex" title="{\sigma_P\otimes\sigma_P}" />, as claimed? To the least, doesn’t this already implicitly assume that the measured system has dimension <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n}" class="latex" title="{2^n}" />?</p>
<p>This is where the notion of <em>device independence</em> comes in. Briefly, in this context the idea is to obtain the same conclusion (a certificate of high-dimensional entanglement) <em>without</em> any assumption on the measurement performed: the only information to be trusted is classical data (statistics generated by the experiment), but not the operational details of the experiment itself.</p>
<p>This is where Corollary <a href="https://mycqstate.wordpress.com/feed/#corgh">5</a> enters the picture. Reformulated in the present context, the corollary provides a means to <em>verify</em> that arbitrary measurements “all but behave” as Pauli measurements, provided they generate the right statistics. To explain how this can be done we need to provide additional “operational tests” that can be used to certify the assumptions of the corollary.</p>
<p><b>3.2. Testing the Weyl-Heisenberg group relations</b></p>
<p>Corollary <a href="https://mycqstate.wordpress.com/feed/#corgh">5</a> makes three assumptions about the observables <img src="https://s0.wp.com/latex.php?latex=%7BX%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X(a)}" class="latex" title="{X(a)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%28b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z(b)}" class="latex" title="{Z(b)}" />: that they satisfy approximate consistency <a href="https://mycqstate.wordpress.com/feed/#eqgh-cons">(9)</a>, linearity <a href="https://mycqstate.wordpress.com/feed/#eqgh-commute">(10)</a>, and anti-commutation <a href="https://mycqstate.wordpress.com/feed/#eqgh-ac">(11)</a>. In this section I will describe two (somewhat well-known) tests that allow to certify these relations based only on the fact that the measurements generate statistics which pass the tests.</p>
<p><b>Linearity test:</b></p>
<ul>
<li>(a) The referee selects <img src="https://s0.wp.com/latex.php?latex=%7BW%5Cin%5C%7BX%2CZ%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W\in\{X,Z\}}" class="latex" title="{W\in\{X,Z\}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Ca%27%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,a'\in\{0,1\}^n}" class="latex" title="{a,a'\in\{0,1\}^n}" /> uniformly at random. He sends <img src="https://s0.wp.com/latex.php?latex=%7B%28W%2Ca%2Ca%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(W,a,a')}" class="latex" title="{(W,a,a')}" /> to one player and <img src="https://s0.wp.com/latex.php?latex=%7B%28W%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(W,a)}" class="latex" title="{(W,a)}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%28W%2Ca%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(W,a')}" class="latex" title="{(W,a')}" />, or <img src="https://s0.wp.com/latex.php?latex=%7B%28W%2Ca%2Ba%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(W,a+a')}" class="latex" title="{(W,a+a')}" /> to the other.</li>
<li>(b) The first player replies with two bits, and the second with a single bit. The referee accepts if and only if the player’s answers are consistent.</li>
</ul>
<p>As always in this note, the test treats both players simultaneously. As a result we can (and will) assume that the player’s strategy is symmetric, and is specified by a permutation-invariant state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5Cin+%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi\in {\mathbb C}^d \otimes {\mathbb C}^d}" class="latex" title="{\psi\in {\mathbb C}^d \otimes {\mathbb C}^d}" /> and a measurement for each question: an observable <img src="https://s0.wp.com/latex.php?latex=%7BW%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W(a)}" class="latex" title="{W(a)}" /> associated to questions of the form <img src="https://s0.wp.com/latex.php?latex=%7B%28W%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(W,a)}" class="latex" title="{(W,a)}" />, and a more complicated four-outcome measurement <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BW%5E%7Ba%2Ca%27%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{W^{a,a'}\}}" class="latex" title="{\{W^{a,a'}\}}" /> associated with questions of the form <img src="https://s0.wp.com/latex.php?latex=%7B%28W%2Ca%2Ca%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(W,a,a')}" class="latex" title="{(W,a,a')}" /> (It will not be necessary to go into the details of the formalism for such measurements).</p>
<p>The linearity test described above is exactly identical to the BLR linearity test described earlier, but for the use of the basis label <img src="https://s0.wp.com/latex.php?latex=%7BW%5Cin%5C%7BX%2CZ%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W\in\{X,Z\}}" class="latex" title="{W\in\{X,Z\}}" />. The lemma below is a direct analogue of Lemma <a href="https://mycqstate.wordpress.com/feed/#lemblr-test">1</a>, which extends the analysis to the setting of players sharing entanglement. The lemma was first introduced in a joint <a href="http://ieeexplore.ieee.org/abstract/document/6375302/">paper</a> with Ito, where we used an extension of the linearity test, Babai et al.’s multilinearity test, to show the inclusion of complexity classes NEXP<img src="https://s0.wp.com/latex.php?latex=%7B%5Csubseteq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\subseteq}" class="latex" title="{\subseteq}" />MIP<img src="https://s0.wp.com/latex.php?latex=%7B%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^*}" class="latex" title="{^*}" />.</p>
<blockquote><p><b>Lemma 7</b> <em><a name="lemcom"></a>Suppose that a family of observables <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BW%28a%29%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{W(a)\}}" class="latex" title="{\{W(a)\}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BW%5Cin%5C%7BX%2CZ%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W\in\{X,Z\}}" class="latex" title="{W\in\{X,Z\}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Ba%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a\in\{0,1\}^n}" class="latex" title="{a\in\{0,1\}^n}" />, generates outcomes that succeed in the linearity test with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" />, when applied on a bipartite state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5Cin%7B%5Cmathbb+C%7D%5Ed%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi\in{\mathbb C}^d\otimes {\mathbb C}^d}" class="latex" title="{\psi\in{\mathbb C}^d\otimes {\mathbb C}^d}" />. Then the following hold: approximate consistency</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_a+%5C%2C+%5Cpsi%5E%2A+%5Cbig%28X%28a%29+%5Cotimes+X%28a%29%5Cbig%29+%5Cpsi+%5C%2C%3D%5C%2C1-O%28%5Cvarepsilon%29%2C%5Cqquad+%5Cmathop%7B%5Cmathbb+E%7D_b+%5C%2C+%5Cpsi%5E%2A+%5Cbig%28Z%28b%29+%5Cotimes+Z%28b%29+%5Cbig%29%5Cpsi%5C%2C%5Cgeq%5C%2C1-O%28%5Cvarepsilon%29%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_a \, \psi^* \big(X(a) \otimes X(a)\big) \psi \,=\,1-O(\varepsilon),\qquad \mathop{\mathbb E}_b \, \psi^* \big(Z(b) \otimes Z(b) \big)\psi\,\geq\,1-O(\varepsilon)," class="latex" title="\displaystyle \mathop{\mathbb E}_a \, \psi^* \big(X(a) \otimes X(a)\big) \psi \,=\,1-O(\varepsilon),\qquad \mathop{\mathbb E}_b \, \psi^* \big(Z(b) \otimes Z(b) \big)\psi\,\geq\,1-O(\varepsilon)," /></p>
<p><em>and linearity</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Ca%27%7D+%5C%2C%5Cbig%5C%7CX%28a%29X%28a%27%29-X%28a%2Ba%27%29%5Cbig%5C%7C_%5Csigma%5E2+%3D+O%28%5Cvarepsilon%29%2C%5Cqquad%5Cmathop%7B%5Cmathbb+E%7D_%7Bb%2Cb%27%7D%5C%2C+%5Cbig%5C%7CZ%28b%29Z%28b%27%29-Z%28b%2Bb%27%29%5Cbig%5C%7C_%5Csigma%5E2+%5C%2C%3D%5C%2C+O%28%7B%5Cvarepsilon%7D%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,a'} \,\big\|X(a)X(a')-X(a+a')\big\|_\sigma^2 = O(\varepsilon),\qquad\mathop{\mathbb E}_{b,b'}\, \big\|Z(b)Z(b')-Z(b+b')\big\|_\sigma^2 \,=\, O({\varepsilon})." class="latex" title="\displaystyle \mathop{\mathbb E}_{a,a'} \,\big\|X(a)X(a')-X(a+a')\big\|_\sigma^2 = O(\varepsilon),\qquad\mathop{\mathbb E}_{b,b'}\, \big\|Z(b)Z(b')-Z(b+b')\big\|_\sigma^2 \,=\, O({\varepsilon})." /></p>
</blockquote>
<p>Testing anti-commutation is slightly more involved. We will achieve this by using a two-player game called the Magic Square game. This is a fascinating game, but just as for the linearity test I will treat it superficially and only recall the part of the analysis that is useful for us (see e.g. the <a href="https://arxiv.org/abs/1512.02074">paper</a> by Wu et al. for a description of the game and a proof of Lemma <a href="https://mycqstate.wordpress.com/feed/#lemms">8</a> below).</p>
<blockquote><p><b>Lemma 8 (Magic Square)</b> <em><a name="lemms"></a>The Magic Square game is a two-player game with nine possible questions (with binary answers) for one player and six possible questions (with two-bit answers) for the other player which has the following properties. The distribution on questions in the game is uniform. Two of the questions to the first player are labelled <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> respectively. For any strategy for the players that succeeds in the game with probability at least <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" /> using a bipartite state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5Cin%7B%5Cmathbb+C%7D%5Ed%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi\in{\mathbb C}^d\otimes {\mathbb C}^d}" class="latex" title="{\psi\in{\mathbb C}^d\otimes {\mathbb C}^d}" /> and observables <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> for questions <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> respectively, it holds that<a name="eqms-ac"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbig%5C%7C%5Cbig%28+%28XZ%2BZX%29%5Cotimes+I_d+%5Cbig%29%5Cpsi%5Cbig%5C%7C%5E2+%5C%2C%3D%5C%2C+O%5Cbig%28%5Csqrt%7B%5Cvarepsilon%7D%5Cbig%29.+%5C+%5C+%5C+%5C+%5C+%2814%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \big\|\big( (XZ+ZX)\otimes I_d \big)\psi\big\|^2 \,=\, O\big(\sqrt{\varepsilon}\big). \ \ \ \ \ (14)" class="latex" title="\displaystyle \big\|\big( (XZ+ZX)\otimes I_d \big)\psi\big\|^2 \,=\, O\big(\sqrt{\varepsilon}\big). \ \ \ \ \ (14)" /></p>
<p><em><a name="eqms-ac"></a>Moreover, there exists a strategy which succeeds with probability <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in the game, using <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%3D%5Cphi_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi=\phi_4}" class="latex" title="{\psi=\phi_4}" /> and Pauli observables <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_X+%5Cotimes+I_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_X \otimes I_2}" class="latex" title="{\sigma_X \otimes I_2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_Z%5Cotimes+I_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_Z\otimes I_2}" class="latex" title="{\sigma_Z\otimes I_2}" /> for questions <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> respectively.</em></p></blockquote>
<p>Based on the Magic Square game we devise the following “anti-commutation test”.</p>
<p><b>Anti-commutation test:</b></p>
<ul>
<li>(a) The referee selects <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b\in\{0,1\}^n}" class="latex" title="{a,b\in\{0,1\}^n}" /> uniformly at random under the condition that <img src="https://s0.wp.com/latex.php?latex=%7Ba%5Ccdot+b%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a\cdot b=1}" class="latex" title="{a\cdot b=1}" />. He plays the Magic Square game with both players, with the following modifications: if the question to the first player is <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> he sends <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,a)}" class="latex" title="{(X,a)}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B%28Z%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(Z,b)}" class="latex" title="{(Z,b)}" /> instead; in all other cases he sends the original label of the question in the Magic Square game together with both strings <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />.</li>
<li>(b) Each player provides answers as in the Magic Square game. The referee accepts if and only if the player’s answers would have been accepted in the game.</li>
</ul>
<p>Using Lemma <a href="https://mycqstate.wordpress.com/feed/#lemms">8</a> it is straightforward to show the following.</p>
<blockquote><p><b>Lemma 9</b> <em><a name="lemac"></a>Suppose a strategy for the players succeeds in the anti-commutation test with probability at least <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" />, when performed on a bipartite state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi+%5Cin+%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi \in {\mathbb C}^d \otimes {\mathbb C}^d}" class="latex" title="{\psi \in {\mathbb C}^d \otimes {\mathbb C}^d}" />. Then the observables <img src="https://s0.wp.com/latex.php?latex=%7BX%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X(a)}" class="latex" title="{X(a)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%28b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z(b)}" class="latex" title="{Z(b)}" /> applied by the player upon receipt of questions <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2Ca%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X,a)}" class="latex" title="{(X,a)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%28Z%2Cb%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(Z,b)}" class="latex" title="{(Z,b)}" /> respectively satisfy<a name="eqac"></a></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Cb%3A%5C%2Ca%5Ccdot+b%3D1%7D+%5C%2C%5Cbig%5C%7C+X%28a%29Z%28b%29-%28-1%29%5E%7Ba%5Ccdot+b%7D+Z%28b%29X%28a%29%5Cbig%5C%7C_%5Csigma%5E2%5C%2C%3D%5C%2CO%5Cbig%28%5Csqrt%7B%5Cvarepsilon%7D%5Cbig%29.+%5C+%5C+%5C+%5C+%5C+%2815%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,b:\,a\cdot b=1} \,\big\| X(a)Z(b)-(-1)^{a\cdot b} Z(b)X(a)\big\|_\sigma^2\,=\,O\big(\sqrt{\varepsilon}\big). \ \ \ \ \ (15)" class="latex" title="\displaystyle \mathop{\mathbb E}_{a,b:\,a\cdot b=1} \,\big\| X(a)Z(b)-(-1)^{a\cdot b} Z(b)X(a)\big\|_\sigma^2\,=\,O\big(\sqrt{\varepsilon}\big). \ \ \ \ \ (15)" /></p>
<p><em><a name="eqac"></a></em></p></blockquote>
<p><b>3.3. A robust test for high-dimensional entangled states</b></p>
<p>We are ready to state, and prove, our main theorem: a test for high-dimensional entanglement that is “robust”, meaning that success probabilities that are a constant close to the optimal value suffice to certify that the underlying state is within a constant distance from the target state — in this case, a tensor product of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> EPR pairs. Although arguably a direct “quantization” of the BLR result, this is the first test known which achieves constant robustness — all previous <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit tests required success that is inverse polynomially (in <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />) close to the optimum in order to provide any meaningful conclusion.</p>
<p><b><img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit Pauli braiding test:</b> With probability <img src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/2}" class="latex" title="{1/2}" /> each,</p>
<ul>
<li>(a) Execute the linearity test.</li>
<li>(b) Execute the anti-commutation test.</li>
</ul>
<blockquote><p><b>Theorem 10</b> <em>Suppose that a family of observables <img src="https://s0.wp.com/latex.php?latex=%7BW%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W(a)}" class="latex" title="{W(a)}" />, for <img src="https://s0.wp.com/latex.php?latex=%7BW%5Cin%5C%7BX%2CZ%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W\in\{X,Z\}}" class="latex" title="{W\in\{X,Z\}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Ba%5Cin%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a\in\{0,1\}^n}" class="latex" title="{a\in\{0,1\}^n}" />, and a state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%5Cin%7B%5Cmathbb+C%7D%5Ed%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi\in{\mathbb C}^d\otimes {\mathbb C}^d}" class="latex" title="{\psi\in{\mathbb C}^d\otimes {\mathbb C}^d}" />, generate outcomes that pass the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit Pauli braiding test with probability at least <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7Bd%3D+%281-O%28%5Csqrt%7B%5Cvarepsilon%7D%29%292%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d= (1-O(\sqrt{\varepsilon}))2^n}" class="latex" title="{d= (1-O(\sqrt{\varepsilon}))2^n}" />.</em></p></blockquote>
<p>As should be apparent from the proof it is possible to state a stronger conclusion for the theorem, which includes a characterization of the observables <img src="https://s0.wp.com/latex.php?latex=%7BW%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W(a)}" class="latex" title="{W(a)}" /> and the state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> up to local isometries. For simplicity I only recorded the consequence on the dimension of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" />.</p>
<p><em>Proof:</em> Using Lemma <a href="https://mycqstate.wordpress.com/feed/#lemcom">7</a> and Lemma <a href="https://mycqstate.wordpress.com/feed/#lemac">9</a>, success with probability <img src="https://s0.wp.com/latex.php?latex=%7B1-%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-\varepsilon}" class="latex" title="{1-\varepsilon}" /> in the test implies that conditions <a href="https://mycqstate.wordpress.com/feed/#eqgh-cons">(9)</a>, <a href="https://mycqstate.wordpress.com/feed/#eqgh-commute">(10)</a> and <a href="https://mycqstate.wordpress.com/feed/#eqgh-ac">(11)</a> in Corollary <a href="https://mycqstate.wordpress.com/feed/#corgh">5</a> are all satisfied, up to error <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7B%5Cvarepsilon%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt{\varepsilon})}" class="latex" title="{O(\sqrt{\varepsilon})}" />. (In fact, Lemma <a href="https://mycqstate.wordpress.com/feed/#lemac">9</a> only implies <a href="https://mycqstate.wordpress.com/feed/#eqgh-ac">(11)</a> for strings <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b}" class="latex" title="{a,b}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Ba%5Ccdot+b%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a\cdot b=1}" class="latex" title="{a\cdot b=1}" />. The condition for string such that <img src="https://s0.wp.com/latex.php?latex=%7Ba%5Ccdot+b%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a\cdot b=0}" class="latex" title="{a\cdot b=0}" /> follows from the other conditions.) The conclusion of the corollary is that there exists an isometry <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> such that the observables <img src="https://s0.wp.com/latex.php?latex=%7BX%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X(a)}" class="latex" title="{X(a)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%28b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z(b)}" class="latex" title="{Z(b)}" /> satisfy</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Cb%7D%5C%2C+%5Cbig%5C%7C+X%28a%29Z%28b%29+-+V%5E%2Ag%28%5Csigma_X%28a%29%5Csigma_Z%28b%29%29V+%5Cbig%5C%7C_%5Csigma%5E2+%5C%2C%3D%5C%2C+O%28%5Csqrt%7B%5Cvarepsilon%7D%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,b}\, \big\| X(a)Z(b) - V^*g(\sigma_X(a)\sigma_Z(b))V \big\|_\sigma^2 \,=\, O(\sqrt{\varepsilon})." class="latex" title="\displaystyle \mathop{\mathbb E}_{a,b}\, \big\| X(a)Z(b) - V^*g(\sigma_X(a)\sigma_Z(b))V \big\|_\sigma^2 \,=\, O(\sqrt{\varepsilon})." /></p>
<p>Using again the consistency relations <a href="https://mycqstate.wordpress.com/feed/#eqgh-cons">(9)</a> that follow from part (a) of the test together with the above we get</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7Ba%2Cb%7D%5C%2C+%5Cpsi%5E%2A+%28V%5Cotimes+V%29%5E%2A+%5Cbig%28+%5Csigma_X%28a%29%5Csigma_Z%28b%29%5Cotimes+%5Csigma_X%28a%29%5Csigma_Z%28b%29%5Cbig%29%28V%5Cotimes+V%29%5Cpsi+%5C%2C%3D%5C%2C+1-O%28%5Csqrt%7B%5Cvarepsilon%7D%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{a,b}\, \psi^* (V\otimes V)^* \big( \sigma_X(a)\sigma_Z(b)\otimes \sigma_X(a)\sigma_Z(b)\big)(V\otimes V)\psi \,=\, 1-O(\sqrt{\varepsilon})." class="latex" title="\displaystyle \mathop{\mathbb E}_{a,b}\, \psi^* (V\otimes V)^* \big( \sigma_X(a)\sigma_Z(b)\otimes \sigma_X(a)\sigma_Z(b)\big)(V\otimes V)\psi \,=\, 1-O(\sqrt{\varepsilon})." /></p>
<p>Applying Lemma <a href="https://mycqstate.wordpress.com/feed/#lemsr">6</a>, <img src="https://s0.wp.com/latex.php?latex=%7B%28V%5Cotimes+V%29%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(V\otimes V)\psi}" class="latex" title="{(V\otimes V)\psi}" /> has Schmidt rank at least <img src="https://s0.wp.com/latex.php?latex=%7B%281-O%28%5Csqrt%7B%5Cvarepsilon%7D%29%292%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1-O(\sqrt{\varepsilon}))2^n}" class="latex" title="{(1-O(\sqrt{\varepsilon}))2^n}" />. But <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> is a local isometry, which cannot increase the Schmidt rank. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2017/06/28/pauli-braiding/"><span class="datestr">at June 28, 2017 03:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1183">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2017/04/20/unitary-correlation-matrices/">Unitary Correlation Matrices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Today I’d like to sketch a question that’s been pushing me in a lot of different directions over the past few years — some sane, others less so; few fruitful, but all instructive. The question is motivated by the problem of placing upper bounds on the amount of entanglement needed to play a two-player non-local game (near-)optimally. But it can also be stated as a natural mathematical question in itself, so this is how I’ll present it first, and then only briefly discuss some motivation. (I wish I could write I’ll also present results, but these will be quite sparse.) All that is to come is based on discussions with Oded Regev, though all inaccuracies and naïvetés are mine.</p>
<h2>Prelude: Vector Correlation Matrices</h2>
<p>Before jumping to unitary correlation matrices, let’s — rather pedantically — introduce vector correlation matrices. Most of you are already familiar with this simple object: a vector correlation matrix is an <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\times n}" class="latex" title="{n\times n}" /> Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> with complex entries such that there exists an integer <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> and unit vectors <img src="https://s0.wp.com/latex.php?latex=%7Bu_1%2C%5Cldots%2Cu_n%5Cin+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_1,\ldots,u_n\in {\mathbb C}^d}" class="latex" title="{u_1,\ldots,u_n\in {\mathbb C}^d}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BC_%7Bi%2Cj%7D+%3D+%5Clangle+u_i%2Cu_j%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_{i,j} = \langle u_i,u_j\rangle}" class="latex" title="{C_{i,j} = \langle u_i,u_j\rangle}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29%5Cin%5C%7B1%2C%5Cldots%2Cn%5C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(i,j)\in\{1,\ldots,n\}^2}" class="latex" title="{(i,j)\in\{1,\ldots,n\}^2}" />. In other words: a Gram matrix with diagonal entries equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />.</p>
<p>A natural question is, given a vector correlation matrix <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, what is the minimal dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> in which there exists vectors achieving the specified correlations? Clearly <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\leq n}" class="latex" title="{d\leq n}" />, the dimension of the span of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> vectors; moreover the identity matrix implies that <img src="https://s0.wp.com/latex.php?latex=%7Bd%3Dn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d=n}" class="latex" title="{d=n}" /> is sometimes necessary.</p>
<p>If we allow <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" />-approximations, we can do better: the Johnson-Lindenstrauss lemma implies that <img src="https://s0.wp.com/latex.php?latex=%7Bd%3DO%28%5Cvarepsilon%5E%7B-2%7D%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d=O(\varepsilon^{-2}\log n)}" class="latex" title="{d=O(\varepsilon^{-2}\log n)}" /> is sufficient (and <a href="https://arxiv.org/abs/1609.02094">necessary</a>) to find unit vectors such that <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Clangle+u_i%2Cu_j%5Crangle-C_%7Bi%2Cj%7D%7C%5Cleq%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\langle u_i,u_j\rangle-C_{i,j}|\leq\varepsilon}" class="latex" title="{|\langle u_i,u_j\rangle-C_{i,j}|\leq\varepsilon}" /> for each <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i,j}" class="latex" title="{i,j}" />. And if we only require the approximation to hold on the average over the choice of <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" />, then no dependence on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is necessary: <img src="https://s0.wp.com/latex.php?latex=%7Bd+%3D+O%28%5Cepsilon%5E%7B-2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d = O(\epsilon^{-2})}" class="latex" title="{d = O(\epsilon^{-2})}" /> suffices.</p>
<p>This is all good and well. Now onto the interesting stuff!</p>
<h2>Theme: Unitary Correlation Matrices</h2>
<p>Define a unitary correlation matrix to be an an <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\times n}" class="latex" title="{n\times n}" /> Hermitian matrix <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> with complex entries such that there exists an integer <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> and unitary matrices <img src="https://s0.wp.com/latex.php?latex=%7BU_1%2C%5Cldots%2CU_n%5Cin+%7B%5Cmathbb+C%7D%5E%7Bd%5Ctimes+d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U_1,\ldots,U_n\in {\mathbb C}^{d\times d}}" class="latex" title="{U_1,\ldots,U_n\in {\mathbb C}^{d\times d}}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BC_%7Bi%2Cj%7D+%3D+d%5E%7B-1%7D%5Ctextrm%7BTr%7D%28U_i+U_j%5E%5Cdagger%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_{i,j} = d^{-1}\textrm{Tr}(U_i U_j^\dagger)}" class="latex" title="{C_{i,j} = d^{-1}\textrm{Tr}(U_i U_j^\dagger)}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%29%5Cin%5C%7B1%2C%5Cldots%2Cn%5C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(i,j)\in\{1,\ldots,n\}^2}" class="latex" title="{(i,j)\in\{1,\ldots,n\}^2}" />. Considering block matrices shows that the set of unitary correlation matrices is convex.</p>
<p>By forgetting the unitary structure of the <img src="https://s0.wp.com/latex.php?latex=%7BU_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U_i}" class="latex" title="{U_i}" /> we see that a unitary correlation matrix is automatically a vector correlation matrix; in particular it is positive semidefinite with all diagonal entries equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. While the latter is a characterization of vector correlation matrices, however, as soon as <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Cgeq+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\geq 4}" class="latex" title="{n\geq 4}" /> (and not before) there exists vector correlation matrices that are not unitary correlation matrices. This is not completely trivial to see, and appears in a <a href="https://arxiv.org/abs/0901.0288">paper </a>by Dykema and Juschenko; it is a nice exercise to work out. Now for the main question:</p>
<p>(<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7BD%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathfrak{D}}" class="latex" title="{\mathfrak{D}}" />): Dimension reduction for unitaries. Let <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Cin%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\in{\mathbb N}}" class="latex" title="{n\in{\mathbb N}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0 }" class="latex" title="{\epsilon &gt; 0 }" /> be given. Does there exist an explicit <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%3Dd%27%28n%3B%5Cepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'=d'(n;\epsilon)}" class="latex" title="{d'=d'(n;\epsilon)}" /> such that for every <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\times n}" class="latex" title="{n\times n}" /> unitary correlation matrix <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> there are <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" />-dimensional unitaries <img src="https://s0.wp.com/latex.php?latex=%7BV_1%2C%5Cldots%2CV_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V_1,\ldots,V_n}" class="latex" title="{V_1,\ldots,V_n}" /> such that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CBig%7C%5Cfrac%7B1%7D%7Bd%27%7D%5Ctextrm%7BTr%7D%5Cbig%28V_i%5C%2CV_j%5E%5Cdagger%5Cbig%29+-+C_%7Bi%2Cj%7D+%5CBig%7C+%5Cleq+%5Cvarepsilon+%5Cqquad+%5Cforall+%28i%2Cj%29%5Cin%5C%7B1%2C%5Cldots%2Cn%5C%7D%5E2%5C%3B+.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Big|\frac{1}{d'}\textrm{Tr}\big(V_i\,V_j^\dagger\big) - C_{i,j} \Big| \leq \varepsilon \qquad \forall (i,j)\in\{1,\ldots,n\}^2\; ." class="latex" title="\displaystyle \Big|\frac{1}{d'}\textrm{Tr}\big(V_i\,V_j^\dagger\big) - C_{i,j} \Big| \leq \varepsilon \qquad \forall (i,j)\in\{1,\ldots,n\}^2\; ." /></p>
<p>While the analogue question for vectors is trivial for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon=0}" class="latex" title="{\epsilon=0}" />, and a fundamental result in geometry for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon&gt;0}" class="latex" title="{\epsilon&gt;0}" />, extremely little is known on the question for unitaries. Virtually the only general statement that can be made is that, at least, some bound <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" /> exists. This follows by a simple compactness argument, but does not yield any meaningful bound on the growth of <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" /> as a function of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />. In fact no explicit bound, however large, is known to hold in general. Let’s explore the problem a bit.</p>
<h2>Variatio: Equivalent formulations</h2>
<p>A nice feature of question (<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7BD%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathfrak{D}}" class="latex" title="{\mathfrak{D}}" />) is that it is reasonably robust, in the sense that different natural formulations of the question can be shown equivalent, up to simple variations on the precise scaling of <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" />. For example, one can relax the constraint of being unitary to the sole requirement that the matrices have all singular values at most <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. At the opposite end of the spectrum one can consider a more structured problem which considers correlations between projection matrices (so all eigenvalues are <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />). Both these variants can be shown equivalent to the unitary case via some simple reductions.</p>
<p>The one variant which makes a substantial difference is the case of correlation matrices with real entries. A beautiful result of <a href="http://www.math.tau.ac.il/~tsirel/download/qbell87.html">Tsirelson</a> shows that any extremal real correlation matrix can be realized exactly, by Hermitian matrices having all eigenvalues <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B-1%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{-1,1\}}" class="latex" title="{\{-1,1\}}" />,  in dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%27+%3D+2%5E%7B%5Csqrt%7B%5Clfloor+n%2F2%5Crfloor%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d' = 2^{\sqrt{\lfloor n/2\rfloor}}}" class="latex" title="{d' = 2^{\sqrt{\lfloor n/2\rfloor}}}" />, and this bound is tight; relatively precise bounds of the form <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%3D2%5E%7B%5CTheta%28%5Cepsilon%5E%7B-1%7D%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'=2^{\Theta(\epsilon^{-1})}}" class="latex" title="{d'=2^{\Theta(\epsilon^{-1})}}" /> <a href="https://arxiv.org/abs/1609.01652">are known</a> for small enough <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon&gt;0}" class="latex" title="{\epsilon&gt;0}" />. (Note that even though projection matrices are Hermitian, and thus give rise to real correlations, Tsirelson’s result does not imply a positive answer for the case of projections as the dimension-<img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" /> matrices recovered via Tsirelson’s construction will in general be Hermitian, but not projectors, even when the original matrices were.)</p>
<h2>Interlude: Motivation</h2>
<p><strong>Quantum games. </strong>One can arrive at question (<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7BD%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathfrak{D}}" class="latex" title="{\mathfrak{D}}" />) by asking about the minimal dimension of near-optimal strategies in a quantum two-player game. Experts will immediately see the connection, and I will not elaborate on this. Roughly, the easy observation is that correlations that are achievable by entangled players in a nonlocal game take the form</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clangle+%5Cpsi%7C+A+%5Cotimes+B+%7C%5Cpsi%5Crangle+%3D+%5Ctextrm%7BTr%7D%28AKB%5ETK%5E%5Cdagger%29%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \langle \psi| A \otimes B |\psi\rangle = \textrm{Tr}(AKB^TK^\dagger)," class="latex" title="\displaystyle \langle \psi| A \otimes B |\psi\rangle = \textrm{Tr}(AKB^TK^\dagger)," /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi\rangle}" class="latex" title="{|\psi\rangle}" /> is a unit vector in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+C%7D%5Ed+%5Cotimes+%7B%5Cmathbb+C%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb C}^d \otimes {\mathbb C}^d}" class="latex" title="{{\mathbb C}^d \otimes {\mathbb C}^d}" /> (the entanglement), <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> is a complex <img src="https://s0.wp.com/latex.php?latex=%7Bd%5Ctimes+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d\times d}" class="latex" title="{d\times d}" /> matrix that can be computed from <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi\rangle}" class="latex" title="{|\psi\rangle}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B}" class="latex" title="{A,B}" />“observables”, i.e. Hermitian operators that square to identity describing the players’ measurement operators. (A more general formulation considers projections, rather than observables.) In case <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\psi\rangle}" class="latex" title="{|\psi\rangle}" /> is the so-called “maximally entangled state”, <img src="https://s0.wp.com/latex.php?latex=%7BK+%3D+d%5E%7B-1%2F2%7D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K = d^{-1/2} I}" class="latex" title="{K = d^{-1/2} I}" /> and we recover precisely an entry from a correlation matrix. (The case of a general state gives rise to a slight variant of question <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cmathfrak%7BD%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\mathfrak{D})}" class="latex" title="{(\mathfrak{D})}" />, to which I am not sure whether it is equivalent or not.)<br />
Arriving at the question from this “physical” angle, it seems like it “ought” to have a reasonable answer: certainly, if one fixes the size of the game, and an approximation error <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon&gt;0}" class="latex" title="{\epsilon&gt;0}" />, then there must exist some dimension that suffices to implement an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-optimal strategy. No such result is known. If anything existing signs seem to point in the negative direction: for instance, Slofstra <a href="https://arxiv.org/abs/1703.08618">very recently</a> showed that there exists a fixed, constant-sized game such that the optimal winning probability of <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> can only be achieved in the limit of infinite dimension (but it does seem to be the case that, for this game, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-optimal strategies can be found in dimension <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7Bpoly%7D%28%5Cepsilon%5E%7B-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\textrm{poly}(\epsilon^{-1}}" class="latex" title="{\textrm{poly}(\epsilon^{-1}}" />). Note that this result implies that the set of correlation matrices of projections is not closed.</p>
<p><strong>Connes’ conjecture.</strong> A different, though related, way to arrive at question (<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7BD%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathfrak{D}}" class="latex" title="{\mathfrak{D}}" />) is via the famous “Connes embedding conjecture” in the theory of <img src="https://s0.wp.com/latex.php?latex=%7BC%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^*}" class="latex" title="{C^*}" /> algebras. <a href="https://www.jstor.org/stable/1971057?seq=1#page_scan_tab_contents">Connes’ embedding conjecture</a> states, rather informally, that any separable <img src="https://s0.wp.com/latex.php?latex=%7BII_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{II_1}" class="latex" title="{II_1}" /> factor (i.e. a von Neumann algebra with trivial center that is infinite-dimensional as a vector space, but has a finite faithful trace) embeds into a suitable ultrapower of the hyperfinite factor <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{R}}" class="latex" title="{\mathcal{R}}" />. Kirchberg <a href="https://eudml.org/doc/144111">showed that</a> the conjecture is equivalent to the following statement.</p>
<p>Theorem. The validity of Connes’ conjecture for some factor <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is equivalent to the following: For all <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon&gt;0}" class="latex" title="{\epsilon&gt;0}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bn%2Ck%5Cin%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n,k\in{\mathbb N}}" class="latex" title="{n,k\in{\mathbb N}}" /> and unitaries <img src="https://s0.wp.com/latex.php?latex=%7BU_1%2C%5Cldots%2CU_n%5Cin+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U_1,\ldots,U_n\in M}" class="latex" title="{U_1,\ldots,U_n\in M}" /> there is a <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%5Cin%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'\in{\mathbb N}}" class="latex" title="{d'\in{\mathbb N}}" /> and unitaries <img src="https://s0.wp.com/latex.php?latex=%7BV_1%2C%5Cldots%2CV_n%5Cin+M_%7Bd%27%7D%28%7B%5Cmathbb+C%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V_1,\ldots,V_n\in M_{d'}({\mathbb C})}" class="latex" title="{V_1,\ldots,V_n\in M_{d'}({\mathbb C})}" />, such that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CBig%7C%5Ctau%5Cbig%28U_i%5C%2CU_j%5E%2A%5Cbig%29-%5Cfrac%7B1%7D%7Bd%7D%5Ctextrm%7BTr%7D%5Cbig%28V_i%5C%2CV_j%5E%5Cdagger%5Cbig%29%5CBig%7C%5Cleq+%5Cepsilon%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Big|\tau\big(U_i\,U_j^*\big)-\frac{1}{d}\textrm{Tr}\big(V_i\,V_j^\dagger\big)\Big|\leq \epsilon," class="latex" title="\displaystyle \Big|\tau\big(U_i\,U_j^*\big)-\frac{1}{d}\textrm{Tr}\big(V_i\,V_j^\dagger\big)\Big|\leq \epsilon," /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tau}" class="latex" title="{\tau}" /> is the trace on <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />.<br />
This formulation is close to question (<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7BD%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathfrak{D}}" class="latex" title="{\mathfrak{D}}" />), except for two important differences: first, we assume that the target correlations are achievable in finite dimension <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />. This makes the problem easier, and would make it trivial if we were not to introduce a second important difference, which is that we ask for explicit bounds on <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" />. As a result I do not know of any formal implication between (<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathfrak%7BD%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathfrak{D}}" class="latex" title="{\mathfrak{D}}" />) and Connes’ conjecture, in either direction.</p>
<p><strong>Graph limits. </strong>Finally, for the combinatorialist let me mention an analogous (though, as far I can tell, not directly related) question, formulated by Aldous and Lyons in the context of their study of limits of bounded-degree graphs. The distance between two finite graphs of the same constant degree (but not necessarily the same number of vertices) can be measured via the sampling distance <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />: <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%28G%2CG%27%29+%3D+%5Csum_%7Br%3D1%7D%5E%5Cinfty+2%5E%7B-r%7D%5Cdelta_r%28G%2CG%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta(G,G') = \sum_{r=1}^\infty 2^{-r}\delta_r(G,G')}" class="latex" title="{\delta(G,G') = \sum_{r=1}^\infty 2^{-r}\delta_r(G,G')}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta_r%28G%2CG%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta_r(G,G')}" class="latex" title="{\delta_r(G,G')}" /> denotes the total variation distance between the distributions on rooted <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />-neighborhoods obtained by sampling a random vertex from <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> (resp. <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" />) and considering the sub-graph induced on all vertices at distance at most <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> from the sampled vertex. With this notion in place, Question 10.1 in Aldous and Lyons’ <a href="https://arxiv.org/abs/math/0603062">paper on unimodular random networks</a> asks the following:</p>
<p>(Aldous-Lyons:) For every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon&gt;0}" class="latex" title="{\epsilon&gt;0}" /> there is an integer <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> such that for every (finite) graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> there is a graph <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> on <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> vertices such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%28G%2CG%27%29%5Cleq+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta(G,G')\leq \epsilon}" class="latex" title="{\delta(G,G')\leq \epsilon}" />.</p>
<p>In page 1458 the authors mention that the validity of their conjecture for the special class of Cayley graphs would imply that all finitely generated groups are sofic (very roughly, can be embedded into finite-dimensional permutation groups). Even though we do not know of an example of a group that is not sofic, this would be a very surprising result. In particular, it would imply Connes’s Embedding Conjecture for group von Neumann algebras, since the latter is known to hold for sofic groups.</p>
<h2>Development: Results</h2>
<p>Unfortunately this is going to be one of the shortest, most boring developments in musical history: there is too little to say! I could describe multiple failed attempts. In particular, naïve attempts at dimension reduction, inspired by Johnson-Lindenstrauss or other standard techniques, or incremental “gradient-descent” type of progressive block diagonalization procedures, all seem doomed to fail.</p>
<p>Aside from Tsirelson’s result for real correlation matrices, the one case for which we were able to find a cute proof is the case of permutation correlation matrices, where each <img src="https://s0.wp.com/latex.php?latex=%7BU_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U_i}" class="latex" title="{U_i}" /> is assumed to be a permutation matrix. The fact that permutations are sparse seems to make it easier to operate on them by “shifting entries around”; unitaries have a more rigid structure. The proof uses a simple combinatorial argument, with the heaviest hammer being Hall’s theorem guaranteeing the existence of a perfect matching, which is used to simultaneously re-organize the “<img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />” entries in a subset of the permutation matrices while preserving all correlations. The upper bound on <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" /> we obtain is of order <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%2F%5Cvarepsilon%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n/\varepsilon^2}" class="latex" title="{2^n/\varepsilon^2}" />, which may be the right order.</p>
<p>More is known in terms of negative results, i.e. lower bounds on <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" />. Such bounds abound in the theory of nonlocal games, where they go by the name of “dimension witness”. The best known results I am aware of imply that <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'}" class="latex" title="{d'}" /> should grow at least like <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmin%282%5E%7B%5COmega%28%5Cepsilon%5E%7B-1%7D%29%7D%2C2%5En%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\min(2^{\Omega(\epsilon^{-1})},2^n)}" class="latex" title="{\min(2^{\Omega(\epsilon^{-1})},2^n)}" />, which is good for very small <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />, and also <img src="https://s0.wp.com/latex.php?latex=%7Bd%27%3D%5COmega%28n%5Ec%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d'=\Omega(n^c)}" class="latex" title="{d'=\Omega(n^c)}" />, which holds for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> smaller than a universal constant (the two bounds are obtained from different families of correlations; see <a href="https://arxiv.org/abs/1609.01652">here</a> for the former and <a href="https://arxiv.org/abs/1610.03574">here</a> for the latter). An interesting consequence of the (proof of) the second bound, which appears in joint work with Natarajan, is that even an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" />-approximation on average (over the entries of C) requires large dimension. This implies that no “oblivious” rounding technique, as in the Johnson-Lindenstrauss lemma, will work: such a technique would guarantee small approximation error on average independently of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />.</p>
<h2>Coda</h2>
<p>There has been a lot of progress recently on lower bounds, stimulated by works on quantum non-local games. This includes a beautiful framework of games for checking “non-commutative” analogues of linear equations over <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BF%7D_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{F}_2}" class="latex" title="{\mathbb{F}_2}" />, developed by <a href="https://arxiv.org/abs/1209.2729">Cleve and Mittal</a> and <a href="https://arxiv.org/abs/1310.3794">Ji</a>; extensions of the framework to testing finitely presented groups by <a href="https://arxiv.org/abs/1703.08618">Slofstra</a>; a development of approaches based on operator systems by <a href="https://arxiv.org/abs/1503.07207">Paulsen</a> and <a href="https://arxiv.org/abs/1612.02791">co-authors</a>, and many others. But no upper bounds! Get to work: things can’t remain this way.</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2017/04/20/unitary-correlation-matrices/"><span class="datestr">at April 20, 2017 09:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1146">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2017/01/16/quid-qpcp/">Quid qPCP?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This blog has already seen three posts on the quantum PCP conjecture: in <a href="https://mycqstate.wordpress.com/2013/02/24/a-quantum-pcp-theorem/">February 2013</a> to highlight several talks at the Simons Institute in Berkeley, in <a href="https://mycqstate.wordpress.com/2013/10/01/quantum-pcp-a-survey/">October 2013</a> to promote a <a href="https://arxiv.org/abs/1309.7495">survey</a> on the topic I wrote with Dorit Aharonov and Itai Arad, and in <a href="https://mycqstate.wordpress.com/2014/10/31/quantum-pcp-conjectures/">October 2014</a> to introduce the two main variants “constraint satisfaction” (CSP) and “multiplayer games” (MIP), of the quantum QCP (qPCP) conjecture. Such a high rate of posting (compared to the average frequency of posts on this blog) might indicate a slight obsession. But you may also notice it’s been…two years! Has no result worthy of note been established since? Certainly not, and although the conjecture still stands strong, there have been a few interesting developments on both variants of the conjecture. In this post I’ll discuss a couple results on the CSP-qPCP. In a follow-up post I’ll describe progress on the MIP-qPCP.</p>
<p>When we wrote the survey three summers ago, the latest word on the CSP-qPCP (see Conjecture 1.3 <a href="https://arxiv.org/pdf/1309.7495v1.pdf">here</a> for a precise formulation) had been given in a <a href="https://arxiv.org/abs/1310.0017">paper</a> by Brandao and Harrow. BH showed, using information-theoretic arguments, that the constraint graphs associated with constant-gap QMA-hard instances of the local Hamiltonian problem had to satisfy “non-expansion” requirements seemingly at odds with the expansion properties of graphs associated with what are often considered the hardest instances of classical CSPs. Intuitively, their argument uses the monogamy of quantum correlations to argue that highly expanding constraint graphs place such strong demands on entanglement that there is always a product state whose energy is not far from the minimum. Although not strictly a no-go result, their theorem indicates that QMA-hard instances must be based on constraint graphs with markedly different spectral properties than those associated with the hardest instances of classical CSP.</p>
<p>For the time being it seems like any proof, or disproof, of the conjecture remains out of reach. Instead of focusing directly on qPCP, it may be more fruitful to develop the objects that are expected to play an important role in the proof, such as (quantum) low-density parity check codes (qLDPC) and (quantum) locally testable codes (qLTC). Two recent works make progress on this front.</p>
<h2><b>The NLETS conjecture</b></h2>
<p>The <a href="https://arxiv.org/abs/1301.1363">no low-energy trivial states (NLTS) conjecture</a> was proposed by Freedman and Hastings as a “complexity-free” analogue of CSP-qPCP. The NLTS conjecture states that there exist local Hamiltonians such that all low-energy (within an additive constant, times the norm of the Hamiltonian, from the minimum) states are “non-trivial”, in the sense that they cannot be generated by a constant-depth quantum circuit applied on a product state. Equivalently, all states that are the output of a constant-depth quantum circuit must have energy a constant above the minimum. NLTS Hamiltonian are good candidates for qPCP as they provide local Hamiltonian for which many obvious classical certificates for the minimal energy of the Hamiltonian (such as the description of a small circuit which generates a low-energy state) are essentially ruled out.</p>
<p>An <a href="https://arxiv.org/abs/1510.02082v2">earlier version</a> of the Eldar-Harrow manuscript claimed a construction of NLTS Hamiltonian, but the paper was recently updated, and the claim retracted. The <a href="https://arxiv.org/abs/1510.02082v3">current manuscript</a> establishes a moderately weaker (though strictly incomparable) result, that the authors call NLETS, for “no low-<em>error</em> trivial states”. The main result of EH is a relatively simple, explicit construction of a family of local Hamiltonians that have no non-trivial “ground state <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" />-impostor”. An <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" />-impostor is a state that has the same reduced density matrix as a ground state on a fraction <img src="https://s0.wp.com/latex.php?latex=%7B%281-%5Cvarepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1-\varepsilon)}" class="latex" title="{(1-\varepsilon)}" /> of the qubits, but may differ arbitrarily on the remaining <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" /> fraction. Using that the Hamiltonian is local, impostors necessarily have low energy, but the converse is not true, so that NLETS rules out non-triviality for a more restricted class of states than NLTS. For that restricted class of states, however, the non-triviality established by EH is sronger than required by NLTS: they show that no <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" />-impostor can even be well-approximated (within inverse-polynomial trace distance) by logarithmic-depth, instead of just constant-depth, quantum circuits.</p>
<p>Let’s see if I can give some basic intuition on their construction; for anything substantial see the <a href="https://arxiv.org/abs/1510.02082">paper</a>, which gives many angles on the result. Consider first first a classical repetition code encoding <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> bit into <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> bits. This can be made into a locally testable code by enforcing pairwise equality of bits along the edges of a constant-degree expanding graph on vertex set <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cldots%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{1,\ldots,n\}}" class="latex" title="{\{1,\ldots,n\}}" />. Now allow me a little leap of faith: imagine there existed a magic quantum analogue of this classical repetition code, where equality between pairs of qubits is enforced not only in the <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> (computational) basis, but also in the <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> (Hadamard) basis. Of course such a thing does not exist: the constraints would force <em>any</em> pair of qubits (linked by the expander) to form an EPR pair, a requirement that strongly violates monogamy. But let’s <em>imagine</em>. Then I claim that we would essentially be done. Why? We need two more observations.</p>
<p>The first key observation made by EH is that any ground state of this imaginary code would have the following property: if you measure all qubits of the state in the same basis, either <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" />, then for at least one of the two possible choices the measurement outcomes will be distributed according to a distribution on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-bit strings that places a large (constant) weight on at least two well-isolated (separated by at least the minimum distance) subsets of the Hamming cube. Note that this does not hold of the classical repetition code: the distribution which all-<img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> codeword is, well, concentrated. But if we were to measure the associated quantum state <img src="https://s0.wp.com/latex.php?latex=%7B%7C0%5Ccdots+0+%5Crangle+%5Csimeq+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28+%7C%2B%5Ccdots%2B%5Crangle%2B%7C-%5Ccdots-%5Crangle%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|0\cdots 0 \rangle \simeq \frac{1}{\sqrt{2}}( |+\cdots+\rangle+|-\cdots-\rangle)}" class="latex" title="{|0\cdots 0 \rangle \simeq \frac{1}{\sqrt{2}}( |+\cdots+\rangle+|-\cdots-\rangle)}" /> in the Hadamard basis, we would get a very spread distribution, with constant mass on two sets that are at distance <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> apart (I realize the equation I wrote is not quite correct! Don’t think too hard about it; obviously my “magical quantum repetition code” does not exist). The reason the distribution obtained in at least one of the two bases must be spread out is due to the uncertainty principle: if the distribution is localized in the <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> basis it must be delocalized in the <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> basis, and vice-versa. And the reason it should be concentrated on isolated clumps is that we are measuring a codeword, which, for our magic example, can only lead to outcomes that are supported on the set <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%7C0%5Crangle%5E%7B%5Cotimes+n%7D%2C%7C1%5Crangle%5E%7B%5Cotimes+n%7D%2C%7C%2B%5Crangle%5E%7B%5Cotimes+n%7D%2C%7C-%5Crangle%5E%7B%5Cotimes+n%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{|0\rangle^{\otimes n},|1\rangle^{\otimes n},|+\rangle^{\otimes n},|-\rangle^{\otimes n}\}}" class="latex" title="{\{|0\rangle^{\otimes n},|1\rangle^{\otimes n},|+\rangle^{\otimes n},|-\rangle^{\otimes n}\}}" />.</p>
<p>To conclude we need the second observation, which is that trivial states do <em>not</em> have this property: measuring a trivial state in any product basis will always lead to a highly expanding distribution, which in particular cannot have large mass on well-isolated subsets. This is obviously true for product states, and requires a bit of work to be carried through logarithmically many layers of a quantum circuit; indeed this is where the main technical work of the paper lies.</p>
<p> </p>
<p>So the argument is complete…except for the fact that the required magic quantum repetition code does not exist! Instead, HE find a good make-do by employing a beautiful construction of quantum LDPC codes due to <a href="https://arxiv.org/abs/0903.0566">Tillich and Zemor</a>, the “hypergraph product”. The hypergraph product takes as input any pair of classical linear codes and returns a quantum “product” CSS code whose locality, distance and rate properties can be related to those of the original codes. The toric code can be case as an example of a hypergraph product code; see Section 3 in the <a href="https://arxiv.org/abs/0903.0566">paper</a> for explanations. Unfortunately, the way the distance of the product code scales with other parameters prevents TZ from obtaining good enough qLDPC for the CSP-QPCP; they can “only” obtain codes with constant weight and constant rate, but distance <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt{n})}" class="latex" title="{O(\sqrt{n})}" />.</p>
<p>In the context of NL(E)TS, and even more so qPCP, however, distance may not be the most relevant parameter. EH’s main construction is obtained as the hypergraph product of two expander-based repetition codes, which as a code only has logarithmic distance; nevertheless they are able to show that the robustness derived from the repetition code, together with the logarithmic distance, are enough to separate <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" />-impostors from logarithmic-depth trivial states.</p>
<h2><b>Quantum LDPC &amp; LTC</b></h2>
<p>Quantum low-density parity-check codes (qLDPC) already made a showing in the previous sections. These families of codes are of much broader interest than their possible role in a forthcoming proof of qPCP, and constructions are being actively pursued. For classical codes the situation is largely satisfactory, and there are constructions that simultaneously achieve constant rate and linear distance with constant-weight parity checks. For quantum codes less is known. If we insist on constant-weight stabilizers then the best distance is <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28%5Csqrt%7Bn%7D%5Clog%5E%7B1%2F4%7D+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(\sqrt{n}\log^{1/4} n)}" class="latex" title="{\Omega(\sqrt{n}\log^{1/4} n)}" /> (e.g. <a href="http://www.dtic.mil/dtic/tr/fulltext/u2/a414975.pdf">Freedman et al.</a>), a notch above the TZ construction mentioned earlier. The most local construction that achieves linear distance requires stabilizers of weight <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt{n})}" class="latex" title="{O(\sqrt{n})}" /> (e.g. <a href="https://arxiv.org/abs/1311.0885">Bravyi and Hastings</a>).</p>
<p>A recent <a href="https://arxiv.org/abs/1608.05089">paper</a> by Hastings makes progress on constructions of qLDPC – assuming a geometrical conjecture on the volume of certain surfaces defined from lattices in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^n}" class="latex" title="{{\mathbb R}^n}" />. Assuming the conjecture, Hastings shows the existence of qLDPC with <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E%7B1-%5Cvarepsilon%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^{1-\varepsilon}}" class="latex" title="{n^{1-\varepsilon}}" /> distance and logarithmic-weight stabilizers, a marked improvement over the state of the art. Although as discussed earlier even linear-distance, constant-weight, qLDPC would not imply the CSP-qPCP nor NLTS (the resulting Hamiltonian may still have low-energy eigenstates that are not at a small distance from codewords), by analogy with the classical case (and basic intuition!), constructions of such objects should certainly facilitate any attempt at a proof of the conjectures. Moreover, qLDPC suffice for the weaker NLETS introduced by EH, as the latter only makes a statement about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\varepsilon}" class="latex" title="{\varepsilon}" />-impostors, i.e. states that are at a constant distance from codewords. To obtain the stronger implication to NLTS, the proper notion is that of local testability: errors should be detected by a fraction of parity checks proportional to the distance of the error from the closest codeword (and not just <em>some</em> parity check).</p>
<p>Hastings’ construction follows the topological approach to quantum error correcting codes pioneered by Freedman and Kitaev. Although the latter introduced codes whose properties depend on the surface they are embedded in, at best I could tell the formal connection between homology and error correction is made in a comprehensive <a href="https://arxiv.org/abs/quant-ph/0605094">paper</a> by Bombin and Martin-Delgado. The advantage of this approach is that properties of the code, including rate and distance, can be tied to geometric properties of the underlying homology, reducing the construction of good codes to that of manifolds with the right properties.</p>
<p> </p>
<p>In addition to the (conjectural) construction of good qLDPC, almost as an afterthought Hastings provides an unconditional construction of a quantum locally testable code (qLTC), albeit one which encodes two qubits only. Let’s try to visualize this, starting from the helpful warm-up provided by Hastings, a high-dimensional, entangled, locally-testable code…which encodes zero qubit (the code space is one-dimensional). Of course this is trivial, but it’s a warm-up!</p>
<p>The simplest instance to visualize has six physical qubits. To follow the forthcoming paragraphs, take a piece of paper and draw a large tetrahedron. If you didn’t mess up your tetrahedron should have six edges: these are your qubits. Now the parity checks are as follows. Each of the four faces specifies an <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />-stabilizer which acts <img src="https://i0.wp.com/i-want-to-study-engineering.org/figs/tetrahedron_volume.png" alt="Image result for tetrahedron" class=" alignright" />on the three edges forming the face. Each of the four vertices specifies a <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" />-stabilizer which acts on the three edges that touch the vertex. The resulting eight operators pairwise commute, and they specify a unique (entangled) state in the <img src="https://s0.wp.com/latex.php?latex=%7B2%5E6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^6}" class="latex" title="{2^6}" />-dimensional physical space.</p>
<p>Next we’d like to understand “local” testability. This means that if we fix a set <img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O}" class="latex" title="{O}" /> of edges, and act on each of them using an <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> error, then the resulting operator should violate (anti-commute) with a fraction of <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" />-stabilizers that is proportional to the <em>reduced</em> weight of the error, i.e. its distance to the closest operator which commutes with all <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" />-stabilizers. To see which stabilizers “detect” the error <img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O}" class="latex" title="{O}" />, we recall that <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> which overlap at an even number of locations commute. Therefore a <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> stabilizer will detect <img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O}" class="latex" title="{O}" /> if and only if it lies in its <em>boundary</em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpartial+O%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\partial O}" class="latex" title="{\partial O}" />: the set of vertices which touch an odd number of edges in <img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O}" class="latex" title="{O}" />. This is our syndrome; it has a certain cardinality. To conclude we need to argue that <img src="https://s0.wp.com/latex.php?latex=%7BO%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O}" class="latex" title="{O}" /> can be modified into a set <img src="https://s0.wp.com/latex.php?latex=%7BO%2BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O+P}" class="latex" title="{O+P}" /> with no boundary, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpartial%28O%2BP%29%3D%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\partial(O+P)=\emptyset}" class="latex" title="{\partial(O+P)=\emptyset}" />, and such that <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> is as small as possible – ideally, it should involve at most as many edges as the size of the boundary <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cpartial+O%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\partial O|}" class="latex" title="{|\partial O|}" />. Here is how Hastings does it: for each vertex in the boundary, introduce an edge that links it to some fixed vertex – say the top-most one in your tetrahedron. Let <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> be the resulting set of edges. Then you can check (on the picture!) that <img src="https://s0.wp.com/latex.php?latex=%7BO%2BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O+P}" class="latex" title="{O+P}" /> is boundary-less. Since we added at most as many edges as vertices in the boundary (if the top-most vertex was part of the boundary it doesn’t contribute any edge), we have proven local testability with respect to <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> errors; <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" /> errors are similar.</p>
<p>This was all in three dimensions. The wonderful thing is that the construction generalizes in a “straightforward” way to <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> dimensions. Consider an <img src="https://s0.wp.com/latex.php?latex=%7B%28n%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n+1)}" class="latex" title="{(n+1)}" />-element universe <img src="https://s0.wp.com/latex.php?latex=%7BU%3D%5C%7B1%2C%5Cldots%2Cn%2B1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U=\{1,\ldots,n+1\}}" class="latex" title="{U=\{1,\ldots,n+1\}}" />. Qubits are all subsets of <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> of size <img src="https://s0.wp.com/latex.php?latex=%7Bq%3D%28n%2B1%29%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q=(n+1)/2}" class="latex" title="{q=(n+1)/2}" />; there are exponentially many of these. <img src="https://s0.wp.com/latex.php?latex=%7BZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z}" class="latex" title="{Z}" />-stabilizers are defined for each <img src="https://s0.wp.com/latex.php?latex=%7B%28q-1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(q-1)}" class="latex" title="{(q-1)}" />-element subset; each acts on all <img src="https://s0.wp.com/latex.php?latex=%7B%28q%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(q+1)}" class="latex" title="{(q+1)}" /> of its <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" />-element supersets. Symmetrically, <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />-stabilizers are defined for each <img src="https://s0.wp.com/latex.php?latex=%7B%28q%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(q+1)}" class="latex" title="{(q+1)}" />-element set; each acts on all <img src="https://s0.wp.com/latex.php?latex=%7B%28q%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(q+1)}" class="latex" title="{(q+1)}" /> of its <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" />-element subsets. Thus the code is local: each stabilizer has weight <img src="https://s0.wp.com/latex.php?latex=%7B%28q%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(q+1)}" class="latex" title="{(q+1)}" />, which is logarithmic in the number of qubits. It remains to check local testability; this follows using precisely the same argument as above (minus the picture…).</p>
<p>This first construction encodes zero qubits. How about getting a couple? Hastings gives a construction achieving this, and remains (poly-logarithmically) locally testable. The idea, very roughly, is to make a toric code by combining together two copies of the code described above. The number of encoded qubits will become non-trivial and local testability will remain. Unfortunately, just as for the toric code, the distance of the result code only scales as <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{n}}" class="latex" title="{\sqrt{n}}" />. To construct his code Hastings uses a slightly different cellulation than the above-described one. I am not sure precisely why the change is needed, and I defer to the paper for more details. (<a href="https://arxiv.org/abs/1504.00822">Leverrier, Tillich and Zemor</a> had earlier provided a construction, based on the TZ hypergraph product, with linear rate, square root distance, and local testability up to the minimal distance, i.e. for all errors of reduced weight at most <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt%7Bn%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt{n})}" class="latex" title="{O(\sqrt{n})}" />.)</p>
<p> </p>
<p>Although the geometric picture takes some effort to grasp, I find these constructions fascinating. Given the Brandao-Harrow objections to using the most “straighforward” expander constructions to achieve CSP-qPCP, or even NLTS, it seems logical to start looking for combinatorial structures that have more subtle properties and lie at the delicate boundary where both robustness (in terms of testability) and entanglement (non-triviality of ground states) can co-exist without challenging monogamy.</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2017/01/16/quid-qpcp/"><span class="datestr">at January 16, 2017 12:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=885">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2016/12/30/qcryptox-post-mortem/">QCryptoX: post-mortem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Our <a href="https://www.edx.org/course/quantum-cryptography-caltechx-delftx-qucryptox">EdX/Delft/Caltech course on quantum cryptography</a> officially ended on Dec. 20th, and is now archived (all material should remain available in the foreseeable future; we will also prepare a self-contained version of the lecture notes). At Caltech, the “flipped classroom” ended a couple weeks earlier; by now all grades are in and the students may even be beginning to recover. <strong>How did it go?</strong></p>
<h2>1. In the classroom</h2>
<p>Fifteen Caltech students, with a roughly equal mix of physics/CS/EE backgrounds, followed the course till the end (we started at ~20). We had a great time, but integration with the online course proved more challenging than I anticipated. Let me say why, in the hope that my experience could be useful to others (including myself, if I repeat the course).</p>
<p>The EdX content was released in 10 weekly updates, on Tuesdays. Since on-campus classes took place Tuesdays and Thursdays, I asked Caltech students to review the material (videos+lecture notes+quizzes) made available online on a given Tuesday by the following Tuesday’s class. I would then be able to structure the class under the assumption that the students had at least some minimal familiarity with the weeks’ concepts. This would allow for a more relaxed, “conversational” mode: I would be able to react to difficulties encountered by the students, and engage them in the exploration of more advanced topics. That was the theory. Some of it worked out, but not quite as well as I had hoped, and this for a variety of reasons:</p>
<ol>
<li><strong>There was a large discrepancy in the students’ level of preparation</strong>. Some had gone through lecture notes in detail, watched all videos, and completed all quizzes. Although some aspects of the week’s material might still puzzle them, they had a good understanding of the basics. But other students had barely pulled up the website, so that they didn’t even really know what topics were covered in a given week. This meant that, if I worked under the assumption that students already had a reasonable grasp of the material, I would loose half the class; whereas if I assumed they had not seen it at all I would put half the class to sleep. As an attempted remedy I enforced some minimal familiarity with the online content by requiring that weekly EdX quizzes be turned in each Tuesday before class. But these quizzes were not hard, and the students could (and did) get away with a very quick scan through the material.</li>
<li>As all students, but, I hear, even more so here, <strong>Caltech undergraduates generally (i) do not show up in class, and (ii) if per chance they happen to land in the right classroom, they certainly won’t participate</strong>. In an attempt to <em>encourage </em>attendance  I made homeworks due right before the Tuesday 10:30am class, the idea being that students would probably turn in homeworks at the last minute, but then they would at least be ready for class. Bad idea: as a result, students ended up spending the night on the homework, dropping it off at 10:29:59… only to skip class so as to catch up on sleep!Slightly over half of the registered students attended any given class, a small group of 8-10 on average. This made it harder to keep participation up. On the whole it still went pretty well, and with a little patience, and insistence, I think I eventually managed to instore a reasonably relaxed atmosphere, where students would naturally raise questions, submit suggestions, etc. But we did not reach the stage of all-out participation I had envisioned.</li>
<li><strong>The material was not easy</strong>. This is partially a result of my inexperience in teaching quantum information; as all bad teachers do I had under-estimated the effort it takes to learn the basis of kets, bras and other “elementary” manipulations, especially when one has but an introductory course in undergraduate linear algebra as background. Given this, I am truly amazed that the 15 students actually survived the class; they had to put in <em>a lot</em> of work. Lucky for me there are bright undergraduates around!We ended the course with projects, on which the students did amazingly well. In groups of 2-3 they read one or more papers in quantum cryptography, all on fairly advanced topics we had not covered in class (such as <a href="https://arxiv.org/abs/quant-ph/9810068">relativistic bit commitment</a>, <a href="https://arxiv.org/abs/1603.09717">quantum homomorphic encryption</a>, <a href="https://arxiv.org/abs/1604.01383">quantum bitcoin</a>, and more!), wrote up a short survey paper outlining some criticisms and ideas they had about what they had read, and gave an invariably excellent course presentation. From my perspective, this was certainly a highlight of the course.</li>
</ol>
<p>Given these observations on what went wrong (or at least sub-optimally), here are a few thoughts on how the course could be improved, mostly for my own benefit (I hope to put some of these to good practice in a year or two!). This should be obvious, but: <strong>the main hurdle in designing a “flipped classroom” is to figure out how to work with the online content</strong>:</p>
<ul>
<li>First there is a scheduling difficulty. Some students complained that by having to go through the weekly videos and lecture notes <em>prior</em> to the discussion of the material in class they simultaneously had to face two weeks’ worth of content at any given time. Scheduling of online material was decided based on other constraints, and turned out to be highly sub-optimal: each week was released on a Tuesday, which was also the first day of class, so that it was unreasonable to ask the students to review the material before that week’s classes….pushing it to the next week, and resulting in the aforementioned overlap. A much better schedule would have been to e.g. release material online on Friday, and then have class on Tuesdays and Thursdays. This would have led to a larger overlap and less schizophrenia.</li>
<li>Then comes the problem of “complementarity”. What can be done in class that does not replicate, but instead enriches, then online material? This is made all the more difficult by the inevitable heterogeneity in the student’s preparation. An effort has to be made to limit this by finding ways to enforce the student’s learning of the material. For instance, each class could be kick-started by a small presentation by one of the students, based on one of the online problems, or even by re-explaining (or, explaining better!) one of the week’s more challenging videos. This should be made in a way that the students find it valuable, both for the presenter and the listeners; I don’t want the outcome to be that no one shows up for class.</li>
<li>Student-led discussions usually work best. They love to expose their ideas to each other, and improve upon them. This forces them to be active, and creative. The best moments in the class where when the discussion really picked up and the students bounced suggestions off each other. The existence of the online material should facilitate this, by giving a common basis on which to base the discussion. My approach this time wasn’t optimal, but based on the experience I think it is possible to do something truly engaging. But it won’t work by itself; one really has to design incentive-based schemes to get the process going.</li>
</ul>
<h2>2. Online</h2>
<p>Success of the online course is rather hard to judge. At the end of the course there were about 8000 officially registered students. Of these, EdX identified ~500 as “active learners” over the last few weeks (dropping from ~1500 over the first few weeks, as is to be expected). I think an active learner is roughly someone who has at least watched some parts of a video, answered a quizz or problem, participated in a forum, etc.<br />
About 100 students pursued an official certificate, which means that they paid ~50$ to have their success in the course officially registered. I couldn’t figure out how many students have actually “passed” the class, but I expect the number to be around 200: most of the certified students plus a few others who didn’t want to pay for the certificate but still turned in most homeworks. This is a fair number for a challenging specialized course, I am pretty happy with it. The high initial enrollment numbers, together with anecdotal evidence from people who got in touch directly, indicate that there certainly is demand for the topic.  The most active students in the course definitely “wanted in”, and we had lots of good questions on the forum. And, many, many typos were fixed!</p>
<p>How satisfied were the students with the course? We ran an “exit survey”, but I don’t have the results yet; I can write about them later (hoping that a significant enough number of students bother to fill in the survey). We also had  pre- and mid-course survey. Some of the more interesting questions had to do with how students learn. In my opinion this is the main challenge in designing a MOOC: how to make it <em>useful</em>? Will the students learn anything by watching videos? Anecdotal evidence (but also serious research, I hear) suggests not. Reading the lecture notes? Maybe, but that requires time and dedication – basically, to be an assiduous learner already. Just as “in-the-classroom” learning, it is the problem-solving that students are brought to engage in that can make a difference. Students like to be challenged; they need to be given an active role. In the mid-course survey many of the positive comments had to do with “Julia lab” assignments that were part of the course, and for which the students had to do some simple coding that let them  experiment with properties of qubits, incompatible measurements, etc. In the pre-course survey students also indicated a marked preference for learning via solving problems rather than by watching videos.</p>
<p>So<strong> a good online MOOC should be one that actively engages the student’s problem-solving skills</strong>. But this is not easy! Much harder than recording a video in front of a tablet &amp; webcam. Even though I was repeatedly told about it before-hand, I learned the lesson the hard way: homework questions have to be vetted <em>very thoroughly.</em> There is no end to a student’s creativity in misinterpreting a statement – let alone 1000 students’. Multiple-choice questions may sound straightforward, but they’re not: one has to be very careful that there is exactly one straight correct answer, while at the same time not making it too obvious which is that answer; when one has a solution in mind it is easy not to realize that other proposed supposedly wrong solutions could in fact be interpreted as correct. The topic of cryptography makes this particularly tricky: we want the students to reason, be creative, devise attacks, but the multiple-choice limits us in this ability. Luckily we had a very dedicated, and creative, team of TAs, both in Delft and In Caltech, and by working together they compiled quite a nice set of problems; I hope they get used and re-used.</p>
<h2>3. Conclusions</h2>
<p>It’s too early (or too late) for conclusions. This was a first, and I hope there’ll be a second. The medium is a challenge, but it’s worth reaching out: we teach elite topics to elite students at elite institutions, but so many more have the drive, interest, and ability to learn the material that it would be irresponsible to leave them out. MOOCs may not be the best way to expand the reach of our work, but it is one way…to be improved!</p>
<p>It was certainly a lot of fun. I owe <strong>a huge thank you to all the students</strong>, in the classroom and online, who suffered through the course. I hope you learned a lot! Second in line were <strong>the TAs</strong>, at Caltech as well as Delft, who did impressive work, coping simultaneously with the heavy online and offline duties. They came up with a great set of resources. Last but not least, behind the scenes, the <strong>video production</strong> and <strong>online learning teams</strong>, from Delt and Caltech, without whose support none of this would have been made possible. Thanks!</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2016/12/30/qcryptox-post-mortem/"><span class="datestr">at December 30, 2016 03:06 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=782">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2016/10/24/two-weeks-in/">Two weeks in</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Our <a href="https://www.edx.org/course/quantum-cryptography-caltechx-delftx-qucryptox">course on quantum cryptography</a> will soon enter its third week of instruction (out of ten weeks planned). My parallel “in-class” course at Caltech has already gone through four weeks of lectures. How is it going so far?</p>
<p>There are many possible measures against which to evaluate the experience. An easy one is raw numbers. Online there are a bit over 7,200 students enrolled. But how many are “active”? The statistics tools provided by EdX report 1995 “active” students last week – under what definition of “active”? EdX also reports that 1003 students “watched a video”, and 861 “tried a problem”. What is an active student who neither watched a video nor tried a problem – they clicked on a link? In any case, the proportion seems high; from what I heard a typical experience is that about 2-5% of registered students will complete any given online course. Out of 7,000, this would bring the number of active students by the end of the course at at a couple hundred, a number I would certainly consider a marked success, given the specialized topic and technically challenging material.</p>
<p>At Caltech there are 20 students enrolled in CS/Phys 120. Given the size of our undergraduate population I also consider this to be a rather high number (but the hard drop deadline has not passed yet!). It’s always a pleasure to see our undergraduate’s eagerness to dive into any exciting topic of research that is brought to their attention. I don’t know the enrollment for TU Delft, but they have a large program in quantum information so the numbers are probably at least twice as high.</p>
<p>Numbers are numbers. How about enthusiasm? You saw the word cloud we collected in Week 0. Here is one from Week 2 (“What does “entanglement” evoke in you right now?”; spot the “love” and “love story”; unfortunately only 1% of responses for either!). <img width="440" alt="word2" src="https://mycqstate.files.wordpress.com/2016/10/word2.jpg?w=440&amp;h=455" class="  wp-image-882 alignright" height="455" />Some of the students speak up when prompted for simple feedback such as this, but the vast majority remain otherwise silent, so that involvement is hard to measure. We do have a few rather active participants in the discussion forums, and it’s been a pleasure to read and try to answer their creative questions each day – dear online learners, if you read this, thanks for your extremely valuable comments and feedback, which help make the course better for everyone! It’s amazing how even as we were learning qubits some rather insightful questions, and objections, were raised. It’s clear that people are coming to the course from a huge range of backgrounds, prompting the most unexpected reactions.</p>
<p>A similar challenge arises in the classroom. Students range from the freshmen with no background in quantum information (obviously), nor in quantum mechanics or computer science, to more advanced seniors (who form the bulk of the class) to graduate students in Caltech’s Institute for Quantum Information and Matter (IQIM). How to capture everyone’s attention, interest, imagination? The topic of cryptography helps -there is so much to be fascinated with. I started the course by discussing the problem of <a href="https://en.wikipedia.org/wiki/Quantum_money">quantum money</a>, which has the advantage of easily capturing one’s imagination, and for which there is a simple quantum scheme with a clear advantage over classical (cherry on top, the scheme is based on the famous “BB84 states” that will play a major role in the class via their use for quantum key distribution). So newcomers to quantum information could learn about qubits, kets and bras, while others could fend off their impatience by imagining new schemes for public-coin quantum money.</p>
<p>This is not an easy line to thread however, and given the composition of the class I eventually decided to err on the side of caution. Don’t repeat it, but this is my first time even teaching a full class on quantum information, and the basic concepts, not to mention the formalism, can be quite tricky to pick up. So we’re going to take it slow, and we’ll see how far we get. My hope is that the “flipped classroom” format should help needy but motivated students keep afloat by making all the online material available before it is discussed in class. Since the online course has only been going on for a couple weeks I can’t yet report on how well this will work out; my initial impression is that it is not given that the in-class students actually do spend enough time with the online material. I am yet to find the proper way to incentivize this: quizzes? rewards? The best reward should be that they manage to follow the course <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" style="height: 1em;" class="wp-smiley" alt="😉" /></p>
<p>In the coming weeks we’ll start making our way towards quantum key distribution and its analysis. Entanglement, measuring uncertainty, privacy amplification, BB84 and Eckert, and device independence. Quite a program, and it’s certainly nice to attempt it in such pleasant company!</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2016/10/24/two-weeks-in/"><span class="datestr">at October 24, 2016 04:48 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
