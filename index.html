<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at June 25, 2020 02:22 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13911">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13911">Acyclic coloring of special digraphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gurski:Frank.html">Frank Gurski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Komander:Dominique.html">Dominique Komander</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rehs:Carolin.html">Carolin Rehs</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13911">PDF</a><br /><b>Abstract: </b>An acyclic r-coloring of a directed graph G=(V,E) is a partition of the
vertex set V into r acyclic sets. The dichromatic number of a directed graph G
is the smallest r such that G allows an acyclic r-coloring. For symmetric
digraphs the dichromatic number equals the well-known chromatic number of the
underlying undirected graph. This allows us to carry over the W[1]-hardness and
lower bounds for running times of the chromatic number problem parameterized by
clique-width to the dichromatic number problem parameterized by directed
clique-width. We introduce the first polynomial-time algorithm for the acyclic
coloring problem on digraphs of constant directed clique-width. From a
parameterized point of view our algorithm shows that the Dichromatic Number
problem is in XP when parameterized by directed clique-width and extends the
only known structural parameterization by directed modular width for this
problem. For directed co-graphs, which is a class of digraphs of directed
clique-width 2, and several generalizations we even show linear time solutions
for computing the dichromatic number. Furthermore, we conclude that directed
co-graphs and the considered generalizations lead to subclasses of perfect
digraphs. For directed cactus forests, which is a set of digraphs of directed
tree-width 1, we conclude an upper bound of 2 for the dichromatic number and we
show that an optimal acyclic coloring can be computed in linear time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13911"><span class="datestr">at June 25, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13754">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13754">A Parameterized Family of Meta-Submodular Functions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghadiri:Mehrdad.html">Mehrdad Ghadiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santiago:Richard.html">Richard Santiago</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shepherd:Bruce.html">Bruce Shepherd</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13754">PDF</a><br /><b>Abstract: </b>Submodular function maximization has found a wealth of new applications in
machine learning models during the past years. The related supermodular
maximization models (submodular minimization) also offer an abundance of
applications, but they appeared to be highly intractable even under simple
cardinality constraints. Hence, while there are well-developed tools for
maximizing a submodular function subject to a matroid constraint, there is much
less work on the corresponding supermodular maximization problems.
</p>
<p>We give a broad parameterized family of monotone functions which includes
submodular functions and a class of supermodular functions containing diversity
functions. Functions in this parameterized family are called
\emph{$\gamma$-meta-submodular}. We develop local search algorithms with
approximation factors that depend only on the parameter $\gamma$. We show that
the $\gamma$-meta-submodular families include well-known classes of functions
such as meta-submodular functions ($\gamma=0$), metric diversity functions and
proportionally submodular functions (both with $\gamma=1$), diversity functions
based on negative-type distances or Jensen-Shannon divergence (both with
$\gamma=2$), and $\sigma$-semi metric diversity functions ($\gamma = \sigma$).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13754"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13738">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13738">The Power of Connection: Leveraging Network Analysis to Advance Receivable Financing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bordino:Ilaria.html">Ilaria Bordino</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gullo:Francesco.html">Francesco Gullo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Legnaro:Giacomo.html">Giacomo Legnaro</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13738">PDF</a><br /><b>Abstract: </b>Receivable financing is the process whereby cash is advanced to firms against
receivables their customers have yet to pay: a receivable can be sold to a
funder, which immediately gives the firm cash in return for a small percentage
of the receivable amount as a fee. Receivable financing has been traditionally
handled in a centralized way, where every request is processed by the funder
individually and independently of one another. In this work we propose a novel,
network-based approach to receivable financing, which enables customers of the
same funder to autonomously pay each other as much as possible, and gives
benefits to both the funder (reduced cash anticipation and exposure risk) and
its customers (smaller fees and lightweight service establishment). Our main
contributions consist in providing a principled formulation of the
network-based receivable-settlement strategy, and showing how to achieve all
algorithmic challenges posed by the design of this strategy. We formulate
network-based receivable financing as a novel combinatorial-optimization
problem on a multigraph of receivables. We show that the problem is NP-hard,
and devise an exact branch-and-bound algorithm, as well as algorithms to
efficiently find effective approximate solutions. Our more efficient algorithms
are based on cycle enumeration and selection, and exploit a theoretical
characterization in terms of a knapsack problem, as well as a refining strategy
that properly adds paths between cycles. We also investigate the real-world
issue of avoiding temporary violations of the problem constraints, and design
methods for handling it. An extensive experimental evaluation is performed on
real receivable data. Results attest the good performance of our methods.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13738"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13712">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13712">Disjointness through the Lens of Vapnik-Chervonenkis Dimension: Sparsity and Beyond</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhattacharya:Anup.html">Anup Bhattacharya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Sourav.html">Sourav Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosh:Arijit.html">Arijit Ghosh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mishra:Gopinath.html">Gopinath Mishra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paraashar:Manaswi.html">Manaswi Paraashar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13712">PDF</a><br /><b>Abstract: </b>The disjointness problem - where Alice and Bob are given two subsets of $\{1,
\dots, n\}$ and they have to check if their sets intersect - is a central
problem in the world of communication complexity. While both deterministic and
randomized communication complexities for this problem are known to be
$\Theta(n)$, it is also known that if the sets are assumed to be drawn from
some restricted set systems then the communication complexity can be much
lower. In this work, we explore how communication complexity measures change
with respect to the complexity of the underlying set system. The complexity
measure for the set system that we use in this work is the Vapnik-Chervonenkis
(VC) dimension. More precisely, on any set system with VC dimension bounded by
$d$, we analyze how large can the deterministic and randomized communication
complexities be, as a function of $d$ and $n$.
</p>
<p>In this paper, we construct two natural set systems of VC dimension $d$,
motivated from geometry. Using these set systems we show that the deterministic
and randomized communication complexity can be $\widetilde{\Theta}\left(d\log
\left( n/d \right)\right)$ for set systems of VC dimension $d$ and this matches
the deterministic upper bound for all set systems of VC dimension $d$. We also
study the deterministic and randomized communication complexities of the set
intersection problem when sets belong to a set system of bounded VC dimension.
We show that there exists set systems of VC dimension $d$ such that both
deterministic and randomized (one-way and multi-round) complexity for the set
intersection problem can be as high as $\Theta\left( d\log \left( n/d \right)
\right)$, and this is tight among all set systems of VC dimension $d$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13712"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13684">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13684">Kernelization of Whitney Switches</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovach:Petr_A=.html">Petr A. Golovach</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13684">PDF</a><br /><b>Abstract: </b>A fundamental theorem of Whitney from 1933 asserts that 2-connected graphs G
and H are 2-isomorphic, or equivalently, their cycle matroids are isomorphic,
if and only if G can be transformed into H by a series of operations called
Whitney switches. In this paper we consider the quantitative question arising
from Whitney's theorem: Given two 2-isomorphic graphs, can we transform one
into another by applying at most k Whitney switches? This problem is already
NP-complete for cycles, and we investigate its parameterized complexity. We
show that the problem admits a kernel of size O(k), and thus, is
fixed-parameter tractable when parameterized by k.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13684"><span class="datestr">at June 25, 2020 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13679">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13679">Approximation of the Diagonal of a Laplacian's Pseudoinverse for Complex Network Analysis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angriman:Eugenio.html">Eugenio Angriman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Predari:Maria.html">Maria Predari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grinten:Alexander_van_der.html">Alexander van der Grinten</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meyerhenke:Henning.html">Henning Meyerhenke</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13679">PDF</a><br /><b>Abstract: </b>The ubiquity of massive graph data sets in numerous applications requires
fast algorithms for extracting knowledge from these data. We are motivated here
by three electrical measures for the analysis of large small-world graphs $G =
(V, E)$ -- i.e., graphs with diameter in $O(\log |V|)$, which are abundant in
complex network analysis. From a computational point of view, the three
measures have in common that their crucial component is the diagonal of the
graph Laplacian's pseudoinverse, $L^\dagger$. Computing diag$(L^\dagger)$
exactly by pseudoinversion, however, is as expensive as dense matrix
multiplication -- and the standard tools in practice even require cubic time.
Moreover, the pseudoinverse requires quadratic space -- hardly feasible for
large graphs. Resorting to approximation by, e.g., using the
Johnson-Lindenstrauss transform, requires the solution of $O(\log |V| /
\epsilon^2)$ Laplacian linear systems to guarantee a relative error, which is
still very expensive for large inputs.
</p>
<p>In this paper, we present a novel approximation algorithm that requires the
solution of only one Laplacian linear system. The remaining parts are purely
combinatorial -- mainly sampling uniform spanning trees, which we relate to
diag$(L^\dagger)$ via effective resistances. For small-world networks, our
algorithm obtains a $\pm \epsilon$-approximation with high probability, in a
time that is nearly-linear in $|E|$ and quadratic in $1 / \epsilon$. Another
positive aspect of our algorithm is its parallel nature due to independent
sampling. We thus provide two parallel implementations of our algorithm: one
using OpenMP, one MPI + OpenMP. In our experiments against the state of the
art, our algorithm (i) yields more accurate results, (ii) is much faster and
more memory-efficient, and (iii) obtains good parallel speedups, in particular
in the distributed setting.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13679"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13673">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13673">Improved Circular $k$-Mismatch Sketches</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golan:Shay.html">Shay Golan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kociumaka:Tomasz.html">Tomasz Kociumaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kopelowitz:Tsvi.html">Tsvi Kopelowitz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porat:Ely.html">Ely Porat</a>, Przemysław Uznański <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13673">PDF</a><br /><b>Abstract: </b>The shift distance $\mathsf{sh}(S_1,S_2)$ between two strings $S_1$ and $S_2$
of the same length is defined as the minimum Hamming distance between $S_1$ and
any rotation (cyclic shift) of $S_2$. We study the problem of sketching the
shift distance, which is the following communication complexity problem:
Strings $S_1$ and $S_2$ of length $n$ are given to two identical players
(encoders), who independently compute sketches (summaries) $\mathtt{sk}(S_1)$
and $\mathtt{sk}(S_2)$, respectively, so that upon receiving the two sketches,
a third player (decoder) is able to compute (or approximate)
$\mathsf{sh}(S_1,S_2)$ with high probability.
</p>
<p>This paper primarily focuses on the more general $k$-mismatch version of the
problem, where the decoder is allowed to declare a failure if
$\mathsf{sh}(S_1,S_2)&gt;k$, where $k$ is a parameter known to all parties. Andoni
et al. (STOC'13) introduced exact circular $k$-mismatch sketches of size
$\widetilde{O}(k+D(n))$, where $D(n)$ is the number of divisors of $n$. Andoni
et al. also showed that their sketch size is optimal in the class of linear
homomorphic sketches.
</p>
<p>We circumvent this lower bound by designing a (non-linear) exact circular
$k$-mismatch sketch of size $\widetilde{O}(k)$; this size matches
communication-complexity lower bounds. We also design $(1\pm
\varepsilon)$-approximate circular $k$-mismatch sketch of size
$\widetilde{O}(\min(\varepsilon^{-2}\sqrt{k}, \varepsilon^{-1.5}\sqrt{n}))$,
which improves upon an $\widetilde{O}(\varepsilon^{-2}\sqrt{n})$-size sketch of
Crouch and McGregor (APPROX'11).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13673"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13642">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13642">Online Dense Subgraph Discovery via Blurred-Graph Feedback</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuroki:Yuko.html">Yuko Kuroki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miyauchi:Atsushi.html">Atsushi Miyauchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Honda:Junya.html">Junya Honda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sugiyama:Masashi.html">Masashi Sugiyama</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13642">PDF</a><br /><b>Abstract: </b>Dense subgraph discovery aims to find a dense component in edge-weighted
graphs. This is a fundamental graph-mining task with a variety of applications
and thus has received much attention recently. Although most existing methods
assume that each individual edge weight is easily obtained, such an assumption
is not necessarily valid in practice. In this paper, we introduce a novel
learning problem for dense subgraph discovery in which a learner queries edge
subsets rather than only single edges and observes a noisy sum of edge weights
in a queried subset. For this problem, we first propose a polynomial-time
algorithm that obtains a nearly-optimal solution with high probability.
Moreover, to deal with large-sized graphs, we design a more scalable algorithm
with a theoretical guarantee. Computational experiments using real-world graphs
demonstrate the effectiveness of our algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13642"><span class="datestr">at June 25, 2020 01:43 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13483">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13483">Provably and Efficiently Approximating Near-cliques using the Tur\'an Shadow: PEANUTS</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Shweta.html">Shweta Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seshadhri:C=.html">C. Seshadhri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13483">PDF</a><br /><b>Abstract: </b>Clique and near-clique counts are important graph properties with
applications in graph generation, graph modeling, graph analytics, community
detection among others. They are the archetypal examples of dense subgraphs.
While there are several different definitions of near-cliques, most of them
share the attribute that they are cliques that are missing a small number of
edges. Clique counting is itself considered a challenging problem. Counting
near-cliques is significantly harder more so since the search space for
near-cliques is orders of magnitude larger than that of cliques.
</p>
<p>We give a formulation of a near-clique as a clique that is missing a constant
number of edges. We exploit the fact that a near-clique contains a smaller
clique, and use techniques for clique sampling to count near-cliques. This
method allows us to count near-cliques with 1 or 2 missing edges, in graphs
with tens of millions of edges. To the best of our knowledge, there was no
known efficient method for this problem, and we obtain a 10x - 100x speedup
over existing algorithms for counting near-cliques.
</p>
<p>Our main technique is a space-efficient adaptation of the Tur\'an Shadow
sampling approach, recently introduced by Jain and Seshadhri (WWW 2017). This
approach constructs a large recursion tree (called the Tur\'an Shadow) that
represents cliques in a graph. We design a novel algorithm that builds an
estimator for near-cliques, using an online, compact construction of the
Tur\'an Shadow.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13483"><span class="datestr">at June 25, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13449">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13449">Hardness of Approximation of (Multi-)LCS over Small Alphabet</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhangale:Amey.html">Amey Bhangale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Diptarka.html">Diptarka Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Rajendra.html">Rajendra Kumar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13449">PDF</a><br /><b>Abstract: </b>The problem of finding longest common subsequence (LCS) is one of the
fundamental problems in computer science, which finds application in fields
such as computational biology, text processing, information retrieval, data
compression etc. It is well known that (decision version of) the problem of
finding the length of a LCS of an arbitrary number of input sequences (which we
refer to as Multi-LCS problem) is NP-complete. Jiang and Li [SICOMP'95] showed
that if Max-Clique is hard to approximate within a factor of $s$ then Multi-LCS
is also hard to approximate within a factor of $\Theta(s)$. By the NP-hardness
of the problem of approximating Max-Clique by Zuckerman [ToC'07], for any
constant $\delta&gt;0$, the length of a LCS of arbitrary number of input sequences
of length $n$ each, cannot be approximated within an $n^{1-\delta}$-factor in
polynomial time unless {\tt{P}}$=${\NP}. However, the reduction of Jiang and Li
assumes the alphabet size to be $\Omega(n)$. So far no hardness result is known
for the problem of approximating Multi-LCS over sub-linear sized alphabet. On
the other hand, it is easy to get $1/|\Sigma|$-factor approximation for strings
of alphabet $\Sigma$.
</p>
<p>In this paper, we make a significant progress towards proving hardness of
approximation over small alphabet by showing a polynomial-time reduction from
the well-studied \emph{densest $k$-subgraph} problem with {\em perfect
completeness} to approximating Multi-LCS over alphabet of size $poly(n/k)$. As
a consequence, from the known hardness result of densest $k$-subgraph problem
(e.g. [Manurangsi, STOC'17]) we get that no polynomial-time algorithm can give
an $n^{-o(1)}$-factor approximation of Multi-LCS over an alphabet of size
$n^{o(1)}$, unless the Exponential Time Hypothesis is false.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13449"><span class="datestr">at June 25, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13430">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13430">Approximation algorithms for the MAXSPACE advertisement problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>M. R. C. da Silva, L. L. C. Pedrosa, R. C. S. Schouery <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13430">PDF</a><br /><b>Abstract: </b>In the MAXSPACE problem, given a set of ads A, one wants to schedule a subset
A' of A into K slots B_1, ..., B_K of size L. Each ad A_i in A has a size s_i
and a frequency w_i. A schedule is feasible if the total size of ads in any
slot is at most L, and each ad A_i in A' appears in exactly w_i slots. The goal
is to find a feasible schedule that maximizes the sum of the space occupied by
all slots. We introduce a generalization called MAXSPACE-R in which each ad A_i
also has a release date r_i &gt;= 1, and may only appear in a slot B_j with j &gt;=
r_i. We also introduce a generalization of MAXSPACE-R called MAXSPACE-RD in
which each ad A_i also has a deadline d_i &lt;= K, and may only appear in a slot
B_j with r_i &lt;= j &lt;= d_i. These parameters model situations where a subset of
ads corresponds to a commercial campaign with an announcement date that may
expire after some defined period. We present a 1/9-approximation algorithm for
MAXSPACE-R and a polynomial-time approximation scheme for MAXSPACE-RD when K is
bounded by a constant. This is the best factor one can expect, since MAXSPACE
is NP-hard, even if K = 2.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13430"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13412">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13412">Lower Bounds on Rate of Convergence of Matrix Products in All Pairs Shortest Path of Social Network</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Dezhou Shen <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13412">PDF</a><br /><b>Abstract: </b>With the rapid development of social network applications, social network has
become an important medium for people to interact. For the minimum distance
computation of all pairs in networks, Alon N[4] proposed an algorithm with
matrix multiplication, combining with distance product association law and
block matrix multiplication, all pairs shortest path length algorithm on
networks has time bound O((2n^3)/B logn). In practical applications,
considering the scale-free characteristics of social networks and the precision
limitations of floating-point operations on computer hardware, I found that the
shortest path algorithm has an improved time bound O((14n^3)/B). Based on the
above theory, I propose an all pairs shortest path algorithm that combines
sparseness judgment and convergence judgment, leveraging the distance product
algorithm with matrix multiplication, distance product association law, block
matrix multiplication, scale-free characteristics of social networks, and
limitation of floating-point operations on hardware. Testing on a social
network dataset with 8508 actors, compared to Alon N algorithm, proposed
algorithm has a performance improvement of 39% to 36.2 times on CPU and GPU.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13412"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13312">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13312">Robust Gaussian Covariance Estimation in Nearly-Matrix Multiplication Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a>, Guanghao Ye <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13312">PDF</a><br /><b>Abstract: </b>Robust covariance estimation is the following, well-studied problem in high
dimensional statistics: given $N$ samples from a $d$-dimensional Gaussian
$\mathcal{N}(\boldsymbol{0}, \Sigma)$, but where an $\varepsilon$-fraction of
the samples have been arbitrarily corrupted, output $\widehat{\Sigma}$
minimizing the total variation distance between $\mathcal{N}(\boldsymbol{0},
\Sigma)$ and $\mathcal{N}(\boldsymbol{0}, \widehat{\Sigma})$. This corresponds
to learning $\Sigma$ in a natural affine-invariant variant of the Frobenius
norm known as the \emph{Mahalanobis norm}. Previous work of Cheng et al
demonstrated an algorithm that, given $N = \Omega (d^2 / \varepsilon^2)$
samples, achieved a near-optimal error of $O(\varepsilon \log 1 /
\varepsilon)$, and moreover, their algorithm ran in time $\widetilde{O}(T(N, d)
\log \kappa / \mathrm{poly} (\varepsilon))$, where $T(N, d)$ is the time it
takes to multiply a $d \times N$ matrix by its transpose, and $\kappa$ is the
condition number of $\Sigma$. When $\varepsilon$ is relatively small, their
polynomial dependence on $1/\varepsilon$ in the runtime is prohibitively large.
In this paper, we demonstrate a novel algorithm that achieves the same
statistical guarantees, but which runs in time $\widetilde{O} (T(N, d) \log
\kappa)$. In particular, our runtime has no dependence on $\varepsilon$. When
$\Sigma$ is reasonably conditioned, our runtime matches that of the fastest
algorithm for covariance estimation without outliers, up to poly-logarithmic
factors, showing that we can get robustness essentially "for free."
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13312"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13266">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13266">OMiCroN -- Oblique Multipass Hierarchy Creation while Navigating</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Vin=iacute=cius_da.html">Vinícius da Silva</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Esperan=ccedil=a:Claudio.html">Claudio Esperança</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marroquim:Ricardo.html">Ricardo Marroquim</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13266">PDF</a><br /><b>Abstract: </b>Rendering large point clouds ordinarily requires building a hierarchical data
structure for accessing the points that best represent the object for a given
viewing frustum and level-of-detail. The building of such data structures
frequently represents a large portion of the cost of the rendering pipeline
both in terms of time and space complexity, especially when rendering is done
for inspection purposes only. This problem has been addressed in the past by
incremental construction approaches, but these either result in low quality
hierarchies or in longer construction times. In this work we present OMiCroN --
Oblique Multipass Hierarchy Creation while Navigating -- which is the first
algorithm capable of immediately displaying partial renders of the geometry,
provided the cloud is made available sorted in Morton order. OMiCroN is fast,
being capable of building the entire data structure in memory spending an
amount of time that is comparable to that of just reading the cloud from disk.
Thus, there is no need for storing an expensive hierarchy, nor for delaying the
rendering until the whole hierarchy is read from disk. In fact, a pipeline
coupling OMiCroN with an incremental sorting algorithm running in parallel can
start rendering as soon as the first sorted prefix is produced, making this
setup very convenient for streamed viewing.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13266"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13241">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13241">The Bike Sharing Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Czyzowicz:Jurek.html">Jurek Czyzowicz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Georgiou:Konstantinos.html">Konstantinos Georgiou</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Killick:Ryan.html">Ryan Killick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kranakis:Evangelos.html">Evangelos Kranakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krizanc:Danny.html">Danny Krizanc</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Lata.html">Lata Narayanan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Opatrny:Jaroslav.html">Jaroslav Opatrny</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pankratov:Denis.html">Denis Pankratov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13241">PDF</a><br /><b>Abstract: </b>Assume that $m \geq 1$ autonomous mobile agents and $0 \leq b \leq m$
single-agent transportation devices (called {\em bikes}) are initially placed
at the left endpoint $0$ of the unit interval $[0,1]$. The agents are identical
in capability and can move at speed one. The bikes cannot move on their own,
but any agent riding bike $i$ can move at speed $v_i &gt; 1$. An agent may ride at
most one bike at a time. The agents can cooperate by sharing the bikes; an
agent can ride a bike for a time, then drop it to be used by another agent, and
possibly switch to a different bike.
</p>
<p>We study two problems. In the \BS problem, we require all agents and bikes
starting at the left endpoint of the interval to reach the end of the interval
as soon as possible. In the \RBS problem, we aim to minimize the arrival time
of the agents; the bikes can be used to increase the average speed of the
agents, but are not required to reach the end of the interval.
</p>
<p>Our main result is the construction of a polynomial time algorithm for the
\BS problem that creates an arrival-time optimal schedule for travellers and
bikes to travel across the interval. For the \RBS problem, we give an algorithm
that gives an optimal solution for the case when at most one of the bikes can
be abandoned.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13241"><span class="datestr">at June 25, 2020 01:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12943">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12943">Learning Based Distributed Tracking</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Hao.html">Hao Wu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gan:Junhao.html">Junhao Gan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Rui.html">Rui Zhang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12943">PDF</a><br /><b>Abstract: </b>Inspired by the great success of machine learning in the past decade, people
have been thinking about the possibility of improving the theoretical results
by exploring data distribution. In this paper, we revisit a fundamental problem
called Distributed Tracking (DT) under an assumption that the data follows a
certain (known or unknown) distribution, and propose a number data-dependent
algorithms with improved theoretical bounds. Informally, in the DT problem,
there is a coordinator and k players, where the coordinator holds a threshold N
and each player has a counter. At each time stamp, at most one counter can be
increased by one. The job of the coordinator is to capture the exact moment
when the sum of all these k counters reaches N. The goal is to minimise the
communication cost. While our first type of algorithms assume the concrete data
distribution is known in advance, our second type of algorithms can learn the
distribution on the fly. Both of the algorithms achieve a communication cost
bounded byO(k log log N) with high probability, improving the state-of-the-art
data-independent bound O(k log N/k). We further propose a number of
implementation optimisation heuristics to improve both efficiency and
robustness of the algorithms. Finally, we conduct extensive experiments on
three real datasets and four synthetic datasets. The experimental results show
that the communication cost of our algorithms is as least as 20% of that of the
state-of-the-art algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12943"><span class="datestr">at June 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12929">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12929">Approximation algorithms for general cluster routing problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Xiaoyan.html">Xiaoyan Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Donglei.html">Donglei Du</a>, Gregory Gutin, Qiaoxia Ming, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Jian.html">Jian Sun</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12929">PDF</a><br /><b>Abstract: </b>Graph routing problems have been investigated extensively in operations
research, computer science and engineering due to their ubiquity and vast
applications. In this paper, we study constant approximation algorithms for
some variations of the general cluster routing problem. In this problem, we are
given an edge-weighted complete undirected graph $G=(V,E,c),$ whose vertex set
is partitioned into clusters $C_{1},\dots ,C_{k}.$ We are also given a subset
$V'$ of $V$ and a subset $E'$ of $E.$ The weight function $c$ satisfies the
triangle inequality. The goal is to find a minimum cost walk $T$ that visits
each vertex in $V'$ only once, traverses every edge in $E'$ at least once and
for every $i\in [k]$ all vertices of $C_i$ are traversed consecutively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12929"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12897">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12897">Polynomial Time Approximation Schemes for Clustering in Low Highway Dimension Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldmann:Andreas_Emil.html">Andreas Emil Feldmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saulpic:David.html">David Saulpic</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12897">PDF</a><br /><b>Abstract: </b>We study clustering problems such as k-Median, k-Means, and Facility Location
in graphs of low highway dimension, which is a graph parameter modeling
transportation networks. It was previously shown that approximation schemes for
these problems exist, which either run in quasi-polynomial time (assuming
constant highway dimension) [Feldmann et al. SICOMP 2018] or run in FPT time
(parameterized by the number of clusters $k$, the highway dimension, and the
approximation factor) [Becker et al. ESA~2018, Braverman et al. 2020]. In this
paper we show that a polynomial-time approximation scheme (PTAS) exists
(assuming constant highway dimension). We also show that the considered
problems are NP-hard on graphs of highway dimension 1.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12897"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12881">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12881">BETULA: Numerically Stable CF-Trees for BIRCH Clustering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lang:Andreas.html">Andreas Lang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schubert:Erich.html">Erich Schubert</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12881">PDF</a><br /><b>Abstract: </b>BIRCH clustering is a widely known approach for clustering, that has
influenced much subsequent research and commercial products. The key
contribution of BIRCH is the Clustering Feature tree (CF-Tree), which is a
compressed representation of the input data. As new data arrives, the tree is
eventually rebuilt to increase the compression. Afterward, the leaves of the
tree are used for clustering. Because of the data compression, this method is
very scalable. The idea has been adopted for example for k-means, data stream,
and density-based clustering.
</p>
<p>Clustering features used by BIRCH are simple summary statistics that can
easily be updated with new data: the number of points, the linear sums, and the
sum of squared values. Unfortunately, how the sum of squares is then used in
BIRCH is prone to catastrophic cancellation.
</p>
<p>We introduce a replacement cluster feature that does not have this numeric
problem, that is not much more expensive to maintain, and which makes many
computations simpler and hence more efficient. These cluster features can also
easily be used in other work derived from BIRCH, such as algorithms for
streaming data. In the experiments, we demonstrate the numerical problem and
compare the performance of the original algorithm compared to the improved
cluster features.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12881"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12772">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12772">Combinatorial Pure Exploration of Dueling Bandit</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Wei.html">Wei Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Yihan.html">Yihan Du</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Longbo.html">Longbo Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Haoyu.html">Haoyu Zhao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12772">PDF</a><br /><b>Abstract: </b>In this paper, we study combinatorial pure exploration for dueling bandits
(CPE-DB): we have multiple candidates for multiple positions as modeled by a
bipartite graph, and in each round we sample a duel of two candidates on one
position and observe who wins in the duel, with the goal of finding the best
candidate-position matching with high probability after multiple rounds of
samples. CPE-DB is an adaptation of the original combinatorial pure exploration
for multi-armed bandit (CPE-MAB) problem to the dueling bandit setting.
</p>
<p>We consider both the Borda winner and the Condorcet winner cases. For Borda
winner, we establish a reduction of the problem to the original CPE-MAB setting
and design PAC and exact algorithms that achieve both the sample complexity
similar to that in the CPE-MAB setting (which is nearly optimal for a subclass
of problems) and polynomial running time per round.
</p>
<p>For Condorcet winner, we first design a fully polynomial time approximation
scheme (FPTAS) for the offline problem of finding the Condorcet winner with
known winning probabilities, and then use the FPTAS as an oracle to design a
novel pure exploration algorithm ${\sf CAR}$-${\sf Cond}$ with sample
complexity analysis. ${\sf CAR}$-${\sf Cond}$ is the first algorithm with
polynomial running time per round for identifying the Condorcet winner in
CPE-DB.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12772"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12748">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12748">Approximation Algorithms for Sparse Principal Component Analysis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chowdhury:Agniva.html">Agniva Chowdhury</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Drineas:Petros.html">Petros Drineas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12748">PDF</a><br /><b>Abstract: </b>We present three provably accurate, polynomial time, approximation algorithms
for the Sparse Principal Component Analysis (SPCA) problem, without imposing
any restrictive assumptions on the input covariance matrix. The first algorithm
is based on randomized matrix multiplication; the second algorithm is based on
a novel deterministic thresholding scheme; and the third algorithm is based on
a semidefinite programming relaxation of SPCA. All algorithms come with
provable guarantees and run in low-degree polynomial time. Our empirical
evaluations confirm our theoretical findings.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12748"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12670">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12670">An Efficient PTAS for Stochastic Load Balancing with Poisson Jobs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/De:Anindya.html">Anindya De</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khanna:Sanjeev.html">Sanjeev Khanna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Huan.html">Huan Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nikpey:Hesam.html">Hesam Nikpey</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12670">PDF</a><br /><b>Abstract: </b>We give the first polynomial-time approximation scheme (PTAS) for the
stochastic load balancing problem when the job sizes follow Poisson
distributions. This improves upon the 2-approximation algorithm due to Goel and
Indyk (FOCS'99). Moreover, our approximation scheme is an efficient PTAS that
has a running time double exponential in $1/\epsilon$ but nearly-linear in $n$,
where $n$ is the number of jobs and $\epsilon$ is the target error. Previously,
a PTAS (not efficient) was only known for jobs that obey exponential
distributions (Goel and Indyk, FOCS'99).
</p>
<p>Our algorithm relies on several probabilistic ingredients including some
(seemingly) new results on scaling and the so-called "focusing effect" of
maximum of Poisson random variables which might be of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12670"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12608">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12608">Similarity Search with Tensor Core Units</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahle:Thomas_D=.html">Thomas D. Ahle</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silvestri:Francesco.html">Francesco Silvestri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12608">PDF</a><br /><b>Abstract: </b>Tensor Core Units (TCUs) are hardware accelerators developed for deep neural
networks, which efficiently support the multiplication of two dense
$\sqrt{m}\times \sqrt{m}$ matrices, where $m$ is a given hardware parameter. In
this paper, we show that TCUs can speed up similarity search problems as well.
We propose algorithms for the Johnson-Lindenstrauss dimensionality reduction
and for similarity join that, by leveraging TCUs, achieve a $\sqrt{m}$ speedup
up with respect to traditional approaches.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12608"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12589">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12589">Distributional Individual Fairness in Clustering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Nihesh Anderson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bera:Suman_K=.html">Suman K. Bera</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Syamantak.html">Syamantak Das</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yang.html">Yang Liu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12589">PDF</a><br /><b>Abstract: </b>In this paper, we initiate the study of fair clustering that ensures
distributional similarity among similar individuals. In response to improving
fairness in machine learning, recent papers have investigated fairness in
clustering algorithms and have focused on the paradigm of statistical
parity/group fairness. These efforts attempt to minimize bias against some
protected groups in the population. However, to the best of our knowledge, the
alternative viewpoint of individual fairness, introduced by Dwork et al. (ITCS
2012) in the context of classification, has not been considered for clustering
so far. Similar to Dwork et al., we adopt the individual fairness notion which
mandates that similar individuals should be treated similarly for clustering
problems. We use the notion of $f$-divergence as a measure of statistical
similarity that significantly generalizes the ones used by Dwork et al. We
introduce a framework for assigning individuals, embedded in a metric space, to
probability distributions over a bounded number of cluster centers. The
objective is to ensure (a) low cost of clustering in expectation and (b)
individuals that are close to each other in a given fairness space are mapped
to statistically similar distributions.
</p>
<p>We provide an algorithm for clustering with $p$-norm objective ($k$-center,
$k$-means are special cases) and individual fairness constraints with provable
approximation guarantee. We extend this framework to include both group
fairness and individual fairness inside the protected groups. Finally, we
observe conditions under which individual fairness implies group fairness. We
present extensive experimental evidence that justifies the effectiveness of our
approach.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12589"><span class="datestr">at June 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12561">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12561">Better approximation algorithms for maximum weight internal spanning trees in cubic graphs and claw-free graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biniaz:Ahmad.html">Ahmad Biniaz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12561">PDF</a><br /><b>Abstract: </b>Given a connected vertex-weighted graph $G$, the maximum weight internal
spanning tree (MaxwIST) problem asks for a spanning tree of $G$ that maximizes
the total weight of internal nodes. This problem is NP-hard and APX-hard, with
the currently best known approximation factor $1/2$ (Chen et al., Algorithmica
2019). For the case of claw-free graphs, Chen et al. present an involved
approximation algorithm with approximation factor $7/12$. They asked whether it
is possible to improve these ratios, in particular for claw-free graphs and
cubic graphs.
</p>
<p>We improve the approximation factors for the MaxwIST problem in cubic graphs
and claw-free graphs. For cubic graphs we present an algorithm that computes a
spanning tree whose total weight of internal vertices is at least
$\frac{3}{4}-\frac{3}{n}$ times the total weight of all vertices, where $n$ is
the number of vertices of $G$. This ratio is almost tight for large values of
$n$. For claw-free graphs of degree at least three, we present an algorithm
that computes a spanning tree whose total internal weight is at least
$\frac{3}{5}-\frac{1}{n}$ times the total vertex weight. The degree constraint
is necessary as this ratio may not be achievable if we allow vertices of degree
less than three.
</p>
<p>With the above ratios, we immediately obtain better approximation algorithms
with factors $\frac{3}{4}-\epsilon$ and $\frac{3}{5}-\epsilon$ for the MaxwIST
problem in cubic graphs and claw-free graphs of degree at least three, for any
$\epsilon&gt;0$. In addition to improving the approximation factors, the new
algorithms are relatively short compared to that of Chen et al.. The new
algorithms are fairly simple, and employ a variant of the depth-first search
algorithm that selects a relatively-large-weight vertex in every branching
step. Moreover, the new algorithms take linear time while previous algorithms
for similar problem instances are super-linear.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12561"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03781">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03781">Attribute-Efficient Learning of Halfspaces with Malicious Noise: Near-Optimal Label Complexity and Noise Tolerance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Jie.html">Jie Shen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Chicheng.html">Chicheng Zhang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03781">PDF</a><br /><b>Abstract: </b>This paper is concerned with computationally efficient learning of
homogeneous sparse halfspaces in $\Rd$ under noise. Though recent works have
established attribute-efficient learning algorithms under various types of
label noise (e.g. bounded noise), it remains an open question of when and how
$s$-sparse halfspaces can be efficiently learned under the challenging {\em
malicious noise} model, where an adversary may corrupt both the unlabeled data
distribution and the labels. We answer this question in the affirmative by
designing a computationally efficient algorithm with near-optimal label
complexity $\tilde{O}\big(s \log^3 d \cdot \log^4\frac{1}{\epsilon}\big)$ and
noise tolerance $\eta = \Omega(\epsilon)$, where $\epsilon \in (0, 1)$ is the
target error rate. Our main techniques include attribute-efficient paradigms
for instance reweighting and for empirical risk minimization, and a new
analysis of uniform concentration for unbounded data~--~all of them crucially
take the structure of the underlying halfspace into account. To the best of our
knowledge, this is the first near-optimal result in the setting. As a byproduct
of our analysis, we resolve a long-standing problem in statistics and machine
learning: we show that a global optimum of sparse principal component analysis
can be found in polynomial time without any statistical assumption on the data.
This result might be of independent interest to both communities.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03781"><span class="datestr">at June 25, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
June 29, 2020 Virtual https://www.ideal.northwestern.edu/events/workshop-computational-vs-statistical-tradeoffs-in-network-inference/ Network models have been used as a tool to understand the role of interconnections between entities in multiple research areas like sociology, biology, meteorology, economics, and computer science. Moreover emerging technological developments allow collecting data on increasingly larger networks. This leads to both computational and statistical challenges when inferring or … <a href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/" class="more-link">Continue reading <span class="screen-reader-text">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/"><span class="datestr">at June 24, 2020 11:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/096">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/096">TR20-096 |  On the asymptotic complexity of sorting | 

	Igor Sergeev</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We investigate the number of pairwise comparisons sufficient to sort $n$ elements chosen from a linearly ordered set. This number is shown to be $\log_2(n!) + o(n)$ thus improving over the previously known upper bounds of the form $\log_2(n!) + \Theta(n)$. The new bound is achieved by the proposed group insertion sorting algorithm.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/096"><span class="datestr">at June 24, 2020 05:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/095">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/095">TR20-095 |  On Basing Auxiliary-Input Cryptography on NP-hardness via Nonadaptive Black-Box Reductions | 

	Mikito Nanashima</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A black-box (BB) reduction is a central proof technique in theoretical computer science. However, the limitations on BB reductions have been revealed for several decades, and the series of previous work gives strong evidence that we should avoid a nonadaptive BB reduction to base cryptography on NP-hardness (e.g., Akavia et al., 2006). Then should we also give up such a familiar proof technique even for an intermediate step towards cryptography?

In this paper, we continue to explore the capability of nonadaptive BB reductions and extend our knowledge on such a central technique out of the current (worst-to-average) framework. In particular, we investigate the attempt to base weaker cryptographic notions allowed to take auxiliary-input via nonadaptive BB reductions. As a result, we prove the following theorems: (1) if we base an auxiliary-input pseudorandom generator (AIPRG) on NP-hardness via a nonadaptive BB reduction, then the polynomial hierarchy collapses; (2) if we base an auxiliary-input one-way function (AIOWF) or auxiliary-input hitting set generator (AIHSG) on NP-hardness via a nonadaptive BB reduction, then an (i.o.-)one-way function also exists based on NP-hardness (via an adaptive BB reduction).

The first result gives new evidence that nonadaptive BB reductions are insufficient to base AIPRG. The second result also yields a weaker but still surprising consequence of nonadaptive BB reductions, that is, a one-way function based on NP-hardness. In fact, the second result is interpreted as the following two opposite ways. Pessimistically, it shows that basing AIOWF or AIHSG via nonadaptive BB reductions is harder than constructing a one-way function based on NP-hardness, which can be regarded as a negative result. Note that AIHSG is a weak primitive implied even by the hardness of learning; thus, this pessimistic view gives conceptually stronger limitations than the currently known limitations on nonadaptive BB reductions. Optimistically, our result gives a new hope: a breakthrough construction of auxiliary-input primitives might also be useful to construct standard cryptographic primitives. This optimistic view enhances the significance of further investigation on constructing auxiliary-input or other intermediate cryptographic primitives instead of standard cryptographic primitives.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/095"><span class="datestr">at June 24, 2020 04:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2020/06/24/equilibrium-min-max/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2020/06/24/equilibrium-min-max/">An equilibrium in nonconvex-nonconcave min-max optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>While there has been incredible progress in convex and nonconvex minimization, a multitude of problems in ML today are in need of efficient algorithms to solve min-max optimization problems. 
 Unlike minimization, where algorithms can always be shown to converge to some local minimum, there is no notion of a local equilibrium in min-max optimization that exists for general nonconvex-nonconcave functions.
    In two recent papers, we give  two notions of local equilibria that are guaranteed to exist and efficient algorithms to compute them.
In this post we present the key ideas behind a second-order notion of local min-max equilibrium from <a href="https://arxiv.org/abs/2006.12363">this paper</a> and in the next we will talk about a different notion along with the algorithm and show its implications to GANs from <a href="https://arxiv.org/abs/2006.12376">this paper</a>.</p>

<h2 id="min-max-optimization">Min-max optimization</h2>

<p>Min-max optimization of an objective function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$</p>



<p>is a powerful framework in optimization, economics, and ML as it allows one to model learning in the presence of multiple agents with competing objectives.
In ML applications, such as <a href="https://arxiv.org/abs/1406.2661">GANs</a> and <a href="https://adversarial-ml-tutorial.org">adversarial robustness</a>, the min-max objective function may be nonconvex-nonconcave.
We know that min-max optimization is at least as hard as minimization, hence, we cannot hope to find a globally optimal solution to min-max problems for general functions.</p>

<h2 id="approximate-local-minima-for-minimization">Approximate local minima for minimization</h2>

<p>Let us first revisit the special case of minimization, where there is a natural notion of an approximate second-order local minimum.</p>

<blockquote>
  <p>$x$ is a second-order $\varepsilon$-local minimum of $\mathcal{L}:\mathbb{R}^d\rightarrow \mathbb{R}$ if
</p>
</blockquote>

<p>Now suppose we just wanted to minimize a function $\mathcal{L}$, and we start from any point which is <em>not</em> at an $\varepsilon$-local minimum of $\mathcal{L}$.
Then we can always find a direction to travel in along which either $\mathcal{L}$ decreases rapidly, or the second derivative of $\mathcal{L}$ is large.
 By searching in such a direction we can easily find a new point which has a smaller value of $\mathcal{L}$ using only local information about the gradient and Hessian of $\mathcal{L}$.
 This means that we can keep decreasing $\mathcal{L}$ until we reach an $\varepsilon$-local minimum (see <a href="https://www.researchgate.net/profile/Boris_Polyak2/publication/220589612_Cubic_regularization_of_Newton_method_and_its_global_performance/links/09e4150dd2f0320879000000/Cubic-regularization-of-Newton-method-and-its-global-performance.pdf">Nesterov and Polyak</a>,  <a href="https://dl.acm.org/doi/10.1145/3055399.3055464">here</a>,  <a href="http://proceedings.mlr.press/v40/Ge15.pdf">here</a>,  and also an earlier <a href="https://www.offconvex.org/2016/03/22/saddlepoints">blog post</a> for how to do this with only access to gradients of $\mathcal{L}$).
 If $\mathcal{L}$ is Lipschitz smooth and bounded, we will reach an $\varepsilon$-local minimum in polynomial time from any starting point.</p>

<blockquote>
  <p>Is there an analogous definition with similar properties for min-max optimization?</p>
</blockquote>

<h2 id="problems-with-current-local-optimality-notions">Problems with current local optimality notions</h2>
<p>There has been much recent work on extending theoretical results in nonconvex minimization to min-max optimization (see <a href="https://arxiv.org/abs/1906.00331">here</a>, <a href="https://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization">here</a>, <a href="https://arxiv.org/pdf/1807.02629.pdf">here</a>,  <a href="https://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods.pdf">here</a>, <a href="https://arxiv.org/abs/1910.07512">here</a>.
One way to extend the notion of local minimum to the min-max setting is to seek a solution point called a “local saddle”–a point $(x,y)$ where 1) $y$ is a local maximum for $f(x, \cdot)$ and 2) $x$ is a local minimum for $f(\cdot, y).$</p>

<p>For instance,
 this is used  <a href="https://arxiv.org/abs/1706.08500">here</a>, <a href="https://arxiv.org/pdf/1901.00838.pdf">here</a>, <a href="https://arxiv.org/pdf/1705.10461.pdf">here</a>, and <a href="http://proceedings.mlr.press/v89/adolphs19a.html">here</a>.
But, there are very simple examples of two-dimensional bounded functions where a local saddle does not exist.</p>

<blockquote>
  <p>For instance, consider $f(x,y) = sin(x+y)$ from <a href="https://arxiv.org/abs/1902.00618">here</a>. Check that none of the points on this function are simultaneously a local minimum for $x$ and local maximum for $y$.</p>
</blockquote>

<p>The fact that no local saddle exists may be surprising, since an $\varepsilon$-global solution to a min-max optimization problem <em>is</em> guaranteed to exist as long as the objective function is uniformly bounded.
Roughly, this is because, in a global min-max setting, the max-player is empowered to globally maximize the function $f(x,\cdot)$, and the min-player is empowered to minimize the “global max” function $\max_y(f(x, \cdot))$.</p>

<p>The ability to compute the global max  allows the min-player to  predict the max-player’s response.
If $x$ is a global minimum of $\max_y(f(x, \cdot))$, the min-player is aware of this fact and will have no incentive to update $x$.
On the other hand, if the min-player can only simulate the max-player’s updates locally (as in local saddle),
then the min-player may try to update her strategy even when it leads to a net increase in $f$.
This can happen because the min-player is not powerful enough to accurately simulate the max-player’s response. (See  a  <a href="https://arxiv.org/abs/1902.00618">related notion</a> of local optimality with similar issues due to vanishingly small updates.)</p>

<p>The fact that players who can only make local predictions are
unable to predict their opponents’ responses can lead to convergence problems in many popular algorithms such as<br />
gradient descent ascent (GDA). This non-convergence behavior can occur if the function has no local saddle point (e.g. the function $sin(x+y)$  mentioned above), and can even happen on some functions, like $f(x,y) = xy$ which do have a local saddle point.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/GDA_spiral_fast.gif" alt="" />
<br />
<b>Figure 1.</b> GDA spirals off to infinity from almost every starting point on the objective function $f(x,y) = xy$. 
</div>
<p><br /></p>

<h2 id="greedy-max-a-computationally-tractable-alternative-to-global-max">Greedy max: a computationally tractable alternative to global max</h2>

<p>To allow for a more stable min-player, and a more stable notion of local optimality, we would like to empower the min-player to more effectively simulate the max-player’s response. 
While the notion of global min-max does exactly this by having the min-player compute the global max function $\max_y(f(\cdot,y))$, computing the global maximum may be intractable.</p>

<p>Instead, we replace the global max function $\max_y (f(\cdot ,y))$ with a computationally tractable alternative. 
Towards this end, we restrict the max-player’s response, and the min-player’s simulation of this response, to updates which can be computed using any algorithm from a class of second-order optimization algorithms.
More specifically, we restrict the max-player to updating $y$ by traveling along continuous paths which start at the current value of $y$ and along which either $f$ is increasing or the second derivative of $f$ is positive.  We refer to such paths as greedy paths since they model a class of second-order “greedy” optimization algorithms.</p>

<blockquote>
  <p><strong>Greedy path:</strong> A unit-speed path $\varphi:[0,\tau] \rightarrow \mathbb{R}^d$ is greedy if $f$ is non-decreasing over this path, and for every $t\in[0,\tau]$
</p>
</blockquote>

<p>Roughly speaking, when restricted to updates obtained from greedy paths, the max-player will always be able to reach a point which is an approximate local maximum for $f(x,\cdot)$, although there may not be a greedy path which leads the max-player to a global maximum.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/greedy_region_omega_t.png" style="width: 400px;" alt="" /> <img src="http://www.offconvex.org/assets/global_max_path_no_axes_t.png" style="width: 400px;" alt="" /> 
<br />
 <b>Figure 2.</b> <i>Left:</i> The light-colored region $\Omega$ is reachable from the initial point $A$ by a greedy path; the dark region is not reachable. <i>Right:</i> There is always a greedy path from any point $A$ to a local maximum ($B$), but a global maximum ($C$) may not be reachable by any greedy path.
</div>
<p><br /></p>

<p>To define an alternative to $\max_y(f(\cdot,y))$, we consider the local maximum point with the largest value of $f(x,\cdot)$ attainable from a given starting point $y$ by any greedy path.
We refer to the value of $f$ at this point as the <em>greedy max function</em>, and denote this value by $g(x,y)$.</p>

<blockquote>
  <p><strong>Greedy max function:</strong> 
    $g(x,y) = \max_{z \in \Omega} f(x,z),$
where $\Omega$ is points reachable from $y$ by greedy path.</p>
</blockquote>

<h2 id="our-greedy-min-max-equilibrium">Our greedy min-max equilibrium</h2>
<p>We use the greedy max function to define a new second-order notion of local optimality for min-max optimization, which we refer to as a greedy min-max equilibrium.
Roughly speaking, we say that $(x,y)$ is a greedy min-max equilibrium if 
1) $y$ is a local maximum for $f(x,\cdot)$ (and hence the endpoint of a greedy path), and 
2) if $x$ is a local minimum of the greedy max function $g(\cdot,y)$.</p>

<p>In other words, $x$ is a local minimum of $\max_y f(\cdot, y)$ under the constraint that the maximum is computed only over the set of greedy paths starting at $y$.
Unfortunately, even if $f$ is smooth, the greedy max function may not be differentiable with respect to $x$ and may even be discontinuous.</p>

<div style="text-align: center;">
<img width="400" alt="" src="http://www.offconvex.org/assets/discontinuity2_grid_t.png" /> <img width="400" alt="" src="http://www.offconvex.org/assets/discontinuity2g_grid_t.png" /> 
<br />
 <b>Figure 3.</b> <i>Left:</i> If we change $x$ from one value $x$ to a very close value $\hat{x}$, the largest value of $f$ reachable by greedy path undergoes a discontinuous change.  <i>Right:</i>  This means the greedy max function $g(x,y)$ is discontinuous in $x$.</div>
<p><br /></p>

<p>This creates a problem, since the definition of $\varepsilon$-local minimum only applies to smooth functions.</p>

<p>To solve this problem we would ideally like to smooth $g$ by convolution with a Gaussian.
Unfortunately, convolution can cause the local minima of a function to “shift”– a point which is a local minimum for $g$ may no longer be a local minimum for the convolved version of $g$ (to see why, try convolving the function $f(x) = x - 3x I(x\leq 0) + I(x \leq 0)$ with a Gaussian $N(0,\sigma^2)$ for any $\sigma&gt;0$).
To avoid this, we instead consider a “truncated” version of $g$, and then convolve this function in the $x$ variable with a Gaussian to obtain our smoothed version of $g$.</p>

<p>This allows us to define a notion of greedy min-max equilibrium.  We say that a point $(x^\star, y^\star)$ is a greedy min-max equilibrium if $y^\star$ is an approximate local maximum of $f(x^\star, \cdot)$, and $x^\star$ is an $\varepsilon$-local minimum of this smoothed version of $g(\cdot, y^\star)$.</p>

<blockquote>
  <p><b>Greedy min-max equilibrium:</b>
$(x^{\star}, y^{\star})$ is a greedy min-max equilibrium if

 
where $S(x,y):= \mathrm{smooth}_x(\mathrm{truncate}(g(x, y))$.</p>
</blockquote>

<h2 id="greedy-min-max-equilibria-always-exist-and-can-be-found-efficiently">Greedy min-max equilibria always exist! (And can be found efficiently)</h2>
<p>In <a href="https://arxiv.org/abs/2006.12363">this paper</a> we show: A greedy min-max equilibrium is always guaranteed to exist provided that $f$ is uniformly bounded with Lipschitz Hessian. We do so by providing an algorithm which converges to a greedy min-max equilibrium, and, moreover, we show that it is able to do this in polynomial time from any initial point:</p>

<blockquote>
  <p><b>Main theorem:</b> Suppose that we are given access to a smooth function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$ and to its gradient and Hessian.  And suppose that $f$ is unformly bounded by $b&gt;0$ and has $L$-Lipschitz Hessian.
Then given any initial point, our algorithm returns an $\varepsilon$-greedy min-max equilibrium $(x^\star,y^\star)$ of $f$ in $\mathrm{poly}(b, L, d, \frac{1}{\varepsilon})$ time.</p>
</blockquote>

<p>There are a number of difficulties that our algorithm and proof must overcome:
One difficulty in designing an algorithm is that the greedy max function may be discontinuous. 
To find an approximate local minimum of a discontinuous function, our algorithm combines a Monte-Carlo hill climbing algorithm with a <a href="https://arxiv.org/abs/cs/0408007">zeroth-order optimization version</a> of stochastic gradient descent.
Another difficulty is that, while one can easily compute a greedy path from any starting point, there may be many different greedy paths which end up at different local maxima.
Searching for the greedy path which leads to the local maximum point with the largest value of $f$ may be infeasible.
In other words the greedy max function $g$ may be intractable to compute.</p>

<div style="text-align: center;">
<img width="400" alt="" src="http://www.offconvex.org/assets/greedy_paths_no_axes_t.png" /> 
<br />
 <b>Figure 4.</b>There are many different greedy paths that start at the same point $A$.  They can end up at different local maxima ($B$, $D$), with different values of $f$.  In many cases it may be intractable to search over all these paths to compute the greedy max function.
 </div>
<p><br /></p>

<p>To get around this problem, rather than computing the exact value of $g(x,y)$, we instead compute a lower bound $h(x,y)$ for the greedy max function. Since we are able to obtain this lower bound by computing only a <em>single</em> greedy path, it is much easier to compute than greedy max function.</p>

<p>In our paper, we prove that if 1) $x^\star$ is an approximate local minimum for the this lower bound $h(\cdot, y^\star)$, and  2) $y^\star$ is a an approximate local maximum for $f(x^\star, \cdot)$, then $x^\star$ is also an approximate local minimum for the greedy max $g(\cdot, y^\star)$.
This allows us to design an algorithm which obtains a greedy min-max point by minimizing the computationally tractable lower bound $h$, instead of the greedy max function which may be intractable to compute.</p>

<h2 id="to-conclude">To conclude</h2>

<p>In this post we have shown how to extend a notion of second-order equilibrium for minimization to min-max optimization which is guaranteed to exist for any function which is bounded and Lipschitz, with Lipschitz gradient and Hessian.
We have also shown that our algorithm is able to find this equilibrium in  polynomial time from any initial point.</p>

<blockquote>
  <p>Our results do not require any additional assumptions such as convexity, monotonicity, or sufficient bilinearity.</p>
</blockquote>

<p>In an upcoming blog post we will show how one can use some of the ideas from here to obtain a new min-max optimization algorithm with applications to stably training GANs.</p></div>







<p class="date">
<a href="http://offconvex.github.io/2020/06/24/equilibrium-min-max/"><span class="datestr">at June 24, 2020 10:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/094">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/094">TR20-094 |  Is it possible to improve Yao’s XOR lemma using reductions that exploit the efficiency of their oracle? | 

	Ronen Shaltiel</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Yao's XOR lemma states that for every function $f:\set{0,1}^k \ar \set{0,1}$, if $f$ has hardness $2/3$ for $P/poly$ (meaning that for every circuit $C$ in $P/poly$, $\Pr[C(X)=f(X)] \le 2/3$ on a uniform input $X$), then the task of computing $f(X_1) \oplus \ldots \oplus f(X_t)$ for sufficiently large $t$ has hardness $\half +\epsilon$ for $P/poly$.

Known proofs of this lemma cannot achieve $\epsilon=\frac{1}{k^{\omega(1)}}$, and even for $\epsilon=\frac{1}{k}$, we do not know how to replace
$P/poly$ by AC$^0[\textsc{parity}]$ (the class of constant depth circuits with the gates $\set{\textsc{and,or,not,parity}}$ of unbounded fan-in).

Recently, Grinberg, Shaltiel and Viola (FOCS 2018) (building on a sequence of earlier works) showed that these limitations cannot be circumvented by \emph{black-box reductions}. Namely, by reductions $\Red^{(\cdot)}$ that given oracle access to a function $D$ that violates the conclusion of Yao's XOR lemma, implement a circuit that violates the assumption of Yao's XOR lemma.

There are a few known reductions in the related literature on worst-case to average case reductions that are \emph{non-black box}. Specifically, the reductions of Gutfreund, Shaltiel and Ta Shma (Computational Complexity 2007) and  Hirahara (FOCS 2018)) are ``class reductions'' that are only guaranteed to succeed when given oracle access to an oracle $D$ from some efficient class of algorithms. These works seem to circumvent some black-box impossibility results.

In this paper we extend the previous limitations of Grinberg, Shaltiel and Viola to class reductions, giving evidence that class reductions cannot yield the desired improvements in Yao's XOR lemma.  To the best of our knowledge, this is the first limitation on reductions for hardness amplification that applies to class reductions.

Our technique imitates the previous lower bounds for black-box reductions, replacing the inefficient oracle used in that proof, with an efficient one that is based on limited independence, and developing tools to deal with the technical difficulties that arise following this replacement.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/094"><span class="datestr">at June 24, 2020 05:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.13073">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.13073">Reduction From Non-Unique Games To Boolean Unique Games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eldan:Ronen.html">Ronen Eldan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moshkovitz:Dana.html">Dana Moshkovitz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.13073">PDF</a><br /><b>Abstract: </b>We reduce the problem of proving a "Boolean Unique Games Conjecture" (with
gap 1-delta vs. 1-C*delta, for any C&gt; 1, and sufficiently small delta&gt;0) to the
problem of proving a PCP Theorem for a certain non-unique game. In a previous
work, Khot and Moshkovitz suggested an inefficient candidate reduction (i.e.,
without a proof of soundness). The current work is the first to provide an
efficient reduction along with a proof of soundness. The non-unique game we
reduce from is similar to non-unique games for which PCP theorems are known.
Our proof relies on a new concentration theorem for functions in Gaussian space
that are restricted to a random hyperplane. We bound the typical Euclidean
distance between the low degree part of the restriction of the function to the
hyperplane and the restriction to the hyperplane of the low degree part of the
function.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.13073"><span class="datestr">at June 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.12760">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.12760">Symmetries, graph properties, and quantum speedups</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=David:Shalev.html">Shalev Ben-David</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Childs:Andrew_M=.html">Andrew M. Childs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gily=eacute=n:Andr=aacute=s.html">András Gilyén</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretschmer:William.html">William Kretschmer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Podder:Supartha.html">Supartha Podder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Daochen.html">Daochen Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.12760">PDF</a><br /><b>Abstract: </b>Aaronson and Ambainis (2009) and Chailloux (2018) showed that fully symmetric
(partial) functions do not admit exponential quantum query speedups. This
raises a natural question: how symmetric must a function be before it cannot
exhibit a large quantum speedup?
</p>
<p>In this work, we prove that hypergraph symmetries in the adjacency matrix
model allow at most a polynomial separation between randomized and quantum
query complexities. We also show that, remarkably, permutation groups
constructed out of these symmetries are essentially the only permutation groups
that prevent super-polynomial quantum speedups. We prove this by fully
characterizing the primitive permutation groups that allow super-polynomial
quantum speedups.
</p>
<p>In contrast, in the adjacency list model for bounded-degree graphs (where
graph symmetry is manifested differently), we exhibit a property testing
problem that shows an exponential quantum speedup. These results resolve open
questions posed by Ambainis, Childs, and Liu (2010) and Montanaro and de Wolf
(2013).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.12760"><span class="datestr">at June 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4870">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4870">Pseudonymity as a trivial concession to genius</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong><span class="has-inline-color has-vivid-red-color">Update (6/24):</span></strong> For further thoughts and context about this unfolding saga, see <a href="https://unherd.com/2020/06/slate-star-codex-must-remain-anonymous/">this excellent piece by Tom Chivers</a> (author of <em>The AI Does Not Hate You</em>, so far the only book about the rationalist community, one that I <a href="https://www.scottaaronson.com/blog/?p=4361">reviewed here</a>).</p>



<p></p><hr /><p></p>



<p>This morning, like many others, I woke up to the terrible news that Scott Alexander—the man I call “the greatest Scott A. of the Internet”—has <a href="https://slatestarcodex.com/">deleted SlateStarCodex in its entirety</a>.  The reason, Scott explains, is that the <em>New York Times</em> was planning to run an article about SSC.  Even though the article was going to be <em>positive</em>, NYT decided that by policy, it would need to include Scott’s real surname (Alexander is his middle name).  Scott felt that revealing his name to the world would endanger himself and his psychiatry patients.  Taking down his entire blog was the only recourse that he saw.</p>



<p>The NYT writer, Cade Metz, was someone who I’d previously known and trusted from his reporting on Google’s quantum supremacy experiment.  So in recent weeks, I’d spent a couple hours on the phone with Cade, answering his questions about the rationality community, the history of my interactions with it, and why I thought SlateStarCodex spoke to so many readers.  Alas, when word got around the rationality community that Cade was writing a story, a huge panic arose that he was planning on some sort of <em>Gawker</em>-style hit piece or takedown.  Trying to tamp down the fire, I told Scott Alexander and others that I knew Cade, his intentions were good, he was only trying to understand the community, and everyone should help him by talking to him openly.</p>



<p>In a year of historic ironies, here’s another one: that it was the decent, reasonable, and well-meaning Cade Metz, rather than any of the SneerClubbers or Twitter-gangsters who despised Scott Alexander for sharing his honest thoughts on hot-button issues, who finally achieved the latter’s dark dream of exiling Scott from the public sphere.</p>



<p>The recent news had already been bad enough: Trump’s “temporary suspension” of J1 and H1B visas (which will deal a body blow to American universities this year, and to all the foreign scientists who planned to work at them), on top of the civil unrest, on top of the economic collapse, on top of the now-resurgent coronavirus.  But with no more SlateStarCodex, now I <em>really</em> feel like my world is coming to an end.</p>



<p>I’ve considered SSC to be the best blog on the Internet since not long after discovering it five years ago.  Of course my judgment is colored by one of the most notorious posts in SSC’s history (“Untitled”) being a ferocious defense of me, when thousands were attacking me and it felt like my life was finished.  But that’s merely what brought me there in the first place.  I stayed because of Scott’s insights about everything else, and because of the humor and humanity and craftsmanship of his prose.  Since then I had the privilege to become friends with Scott, not only virtually but in real life, and to meet dozens of others in the SSC community, in its Bay Area epicenter and elsewhere.</p>



<p>In my view, for SSC to be <em>permanently</em> deleted would be an intellectual loss on the scale of, let’s say, John Stuart Mill or Mark Twain burning their collected works.  That might sound like hyperbole, but not (I don’t think) to the tens of thousands who read Scott’s essays and fiction, particularly during their 2013-2016 heyday, and who went from casual enjoyment to growing admiration to the gradual recognition that they were experiencing, “live,” the works that future generations of teachers will assign their students when they cover the early twenty-first century.  The one thing that mitigates this tragedy is the hope that it will yet be reversed (and, of course, the fact that backups still exist in the bowels of the Internet).</p>



<p>When I discovered Scott Alexander in early 2015, the one issue that gave me pause was his strange insistence on maintaining pseudonymity, even as he was already then becoming more and more of a public figure.  In effect, Scott was trying to erect a firewall between his Internet persona and his personal and professional identities, and was <em>relying on the entire world’s goodwill</em> not to breach that firewall.  I thought to myself, “this can’t <em>possibly</em> last!  Scott simply writes too well to evade mainstream notice forever—and once he’s on the world’s radar, he’ll need to make a choice, about who he is and whether he’s ready to own his gifts to posterity under his real name.”  In retrospect, what astonishes me is that Scott has been able to maintain the “double life” for as long as he has!</p>



<p>In his takedown notice, Scott writes that it’s considered vitally important in psychiatry for patients to know almost nothing about their doctors, beyond their names and their areas of expertise.  That caused me to wonder: OK, but doesn’t the world already have enough psychiatrists who are ciphers to their patients?  Would it be so terrible to have one psychiatrist with a clear public persona—possibly even one who patients sought out <em>because</em> of his public persona, because his writings gave evidence that he’d have sympathy or insight about their conditions?  To become a psychiatrist, does one really need to take a lifelong vow of boringness—a vow never to do or say anything notable enough that one would be “outed” to one’s patients?  What would Freud, or Jung, or any of the other famous therapist-intellectuals of times past have thought about such a vow?</p>



<p>Scott also mentions that he’s gotten death threats, and harassing calls to his workplace, from people who hate him because of his blog (and who found his real name by sleuthing).  I wish I knew a solution to that.  For what it’s worth, my blogging has <em>also</em> earned me a death threat, and threats to sue me, and accusatory letters to the president of my university—although in my case, the worst threats came neither from Jew-hating neo-Nazis nor from nerd-bashing SJWs, but from crackpots enraged that I wouldn’t use my blog to credit their proof of P≠NP or their refutation of quantum mechanics.</p>



<p>When I started <em>Shtetl-Optimized</em> back in 2005, I remember thinking: this is it.  From now on, the only secrets I’ll have in life will be ephemeral and inconsequential ones.  From this day on, every student in my class, every prospective employer, every woman who I ask on a date (I wasn’t married yet), can know whatever they want to know about my political sympathies, my deepest fears and insecurities, any of it, with a five-second Google search.  Am I ready for that?  I decided that I was—partly just because I‘ve never had the mental space to maintain multiple partitioned identities <em>anyway</em>, to remember what each one is or isn’t allowed to know and say!  I won’t pretend that this is the right decision for everyone, but it was my decision, and I stuck with it, and it wasn’t always easy but I’m still here and so evidently are you.</p>



<p>I’d be <em>overjoyed</em> if Scott Alexander were someday to reach a place in his life where he felt comfortable deciding similarly.  That way, not only could he enjoy the full acclaim that he’s earned for what he’s given to the world, but (much more importantly) his tens of thousands of fans would be able to continue benefitting from his insights.</p>



<p>For now, though, the brute fact is that Scott is obviously <em>not</em> comfortable making that choice.  That being so, it seems to me that, if the NYT was able to respect the pseudonymity of Banksy and many others who it’s reported on in the past, when revealing their real names would serve no public interest, then it should also be able to respect Scott Alexander’s pseudonymity.  Especially now that Scott has sent the most credible signal imaginable of how much he values that pseudonymity, a signal that astonished even me.  The world does not exist only to serve its rare geniuses, but surely it can make such trivial concessions to them.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4870"><span class="datestr">at June 23, 2020 05:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/093">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/093">TR20-093 |  Reduction From Non-Unique Games To Boolean Unique Games | 

	Dana Moshkovitz, 

	Ronen Eldan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We reduce the problem of proving a "Boolean Unique Games Conjecture" (with gap $1-\delta$ vs. $1-C\delta$, for any $C&gt; 1$, and sufficiently small $\delta&gt;0$) to the problem of proving a PCP Theorem for a certain non-unique game.
In a previous work, Khot and Moshkovitz suggested an inefficient candidate reduction (i.e., without a proof of soundness). 
The current work is the first to provide an efficient reduction along with a proof of soundness. 
The non-unique game we reduce from is similar to non-unique games for which PCP theorems are known.
Our proof relies on a new concentration theorem for functions in Gaussian space that are restricted to a random hyperplane. We bound the typical Euclidean distance between the low degree part of the restriction of the function to the hyperplane and the restriction to the hyperplane of the low degree part of the function.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/093"><span class="datestr">at June 23, 2020 02:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/06/22/postdoc-at-technion-israel-institute-of-technology-apply-by-august-1-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/06/22/postdoc-at-technion-israel-institute-of-technology-apply-by-august-1-2020/">Postdoc at Technion Israel Institute of Technology (apply by August 1, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Looking for excellent CS theory graduates for a postdoctoral position at the Computer Science Faculty of Technion Israel Institute of Technology, in Prof. Nir Ailon’s group. Research topics include theory of learning, optimization, information theory and their intersection.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/">https://nailon.net.technion.ac.il/</a><br />
Email: mayasidis@cs.technion.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/06/22/postdoc-at-technion-israel-institute-of-technology-apply-by-august-1-2020/"><span class="datestr">at June 22, 2020 08:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5075242632528707140">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/06/winner-of-ramsey-meme-contest.html">Winner of Ramsey Meme Contest</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
My REU program had a Ramsey Meme Contest.<br />
<br />
The winner was Saadiq Shaik with this entry:<br />
<br />
<a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/idont.jpg">I Don't Always...</a><br />
<br />
I challenge my readers to come up with other Ramsey Memes! or Complexity Memes! or point me to some that are already out there.<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/06/winner-of-ramsey-meme-contest.html"><span class="datestr">at June 22, 2020 05:15 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1791">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/06/21/free-registeration-to-tcs-women-rising-star-talks/">(Free) Registeration to TCS Women Rising Star talks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>TCS Women Rising Star talks are happening as part of TCS Women STOC Spotlight Workshop. Seven Rising Star speakers are lined up, all of whom are planning to be <em><strong>on the job market this year</strong></em>. In addition, Shafi Goldwasser will give a longer talk. Everybody is invited, but (free) registration is required. (Attendees don’t even have to pay the STOC registration fee.) More information is on the website:<br /><a href="https://sigact.org/tcswomen/" target="_blank" rel="noreferrer noopener">https://sigact.org/tcswomen/</a>. </p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/06/21/free-registeration-to-tcs-women-rising-star-talks/"><span class="datestr">at June 22, 2020 04:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2020/06/22/virtual-conferences/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2020/06/22/virtual-conferences/">The Uncanny Valley of Virtual Conferences</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>We wrapped up two amazing days of <a href="http://www.l4dc.org/">L4DC 2020</a> last Friday. It’s pretty wild to watch this community grow so quickly: starting as a <a href="https://kgatsis.github.io/learning_for_control_workshop_CDC2018/">workshop</a> at <a href="https://kgatsis.github.io/learning_for_control_workshop_CDC2018/">CDC 2018</a>, the conference organizers put together an <a href="https://l4dc.mit.edu/">inaugural event at MIT</a> in only a few months and were overwhelmed by nearly 400 attendees. Based on a groundswell of support from the participants, we decided to add contributed talks and papers this year. We had passionate volunteers for our <a href="https://sites.google.com/berkeley.edu/l4dc/organizers-pc">70-person program committee</a>, and they did heroic work of reviewing 135 submissions for this year’s program.</p>

<p>Then, of course, the pandemic hit forcing us to cancel our in-person event. As most conferences in a similar situation as ours, we decided to move to a virtual setting. I think that had we not had contributed papers, we would have simply canceled this year (I’ll return to this later). But to respect the passion and hard-work of our contributors, we tried to come up with a reasonable plan for running this conference virtually.</p>

<p>When we started planning to go virtual, there were too many options to sort through: Zoom webinars and breakout rooms? Sli.do Q&amp;As? Google Hangouts? Slack channels? We had so many tools for virtual community building, each with their own pluses and minuses. Our main constraints were that we wanted to highlight the best contributed papers as talks in some way, to give visibility to the wonderful set of accepted papers without burdening the authors with more work, to be inclusive to the broader community of folks interested in learning and automation, and, importantly, to not charge registration fees.</p>

<p>We eventually settled on the following scheme:</p>
<ol>
  <li>We had a Zoom room for invited and contributed speakers and moderators.</li>
  <li>This Zoom was <a href="https://www.youtube.com/watch?v=b_sJb1k9dVY">live streamed to Youtube</a>.</li>
  <li>Questions were gathered by grad student moderators who scanned the YouTube live chat and then relayed inquiries back to the speakers.</li>
  <li>We tried to keep the live part under four hours per day and to provide ample breaks. We recognize how hard it is to sit in front of a live stream for much more than that.</li>
  <li>Further discussion was then done on <a href="https://openreview.net/group?id=L4DC.org/2020/Conference">OpenReview</a>, where we hosted all accepted papers of the conference.</li>
  <li>The proceedings of the conference were subsequently archived by <a href="http://proceedings.mlr.press/">Proceedings of Machine Learning Research</a>.</li>
</ol>

<p>Though it took a lot of work to tie all these pieces together, everything went super smoothly in the end. I was basically able to run the entire AV setup from my garage.</p>

<p class="center"><img width="250px" alt="where the magic happens" src="http://www.argmin.net/assets/command_station.jpg" /></p>

<p>The only thing that cost money here was the Zoom account (20 dollars/month, though subsidized by Berkeley) and my home internet connection. I know that Zoom and YouTube have well documented issues, and I think it’s imperative that they continue to strive to fix these problems, but I also think it’s easy to forget how empowering this technology is. This format opens up conferences to those who can’t travel for financial or logistical reasons, and lowers the energy to engage with cutting edge research. Being able to sit in my garage and run a virtual conference with speakers spanning 10 time zones and nearly 2000 viewers is a wonder of modern times.</p>

<h2 id="second-life-still-has-a-long-way-to-go">Second Life still has a long way to go.</h2>

<p>There are still many parts of the online conference that felt cheated and incomplete. I still don’t know how to run a virtual poster session effectively. Most of our papers have not yet received any comments on <a href="https://openreview.net/group?id=L4DC.org/2020/Conference">OpenReview</a>, though comments are still open and I’d encourage you to drop by and ask questions! Partially, I think this lack of engagement stems from the considerable amount of effort required to participate, especially when it is compared to somewhat aimlessly ambling through a poster session.</p>

<p>Indeed, many aspects of live conferences are simply not replicable with our current tools, whether they be chance encounters or meetings with friends from far away. On the other hand, maybe we shouldn’t try to replicate this experience! Maybe we need to think harder about what opportunities our technology has for building communities and how we can better support these facets of academic interaction. When I think back on the decades of conferences I’ve attended, I can think of only a few posters that really got me interested in reading a paper, and <a href="https://papers.nips.cc/paper/3323-the-tradeoffs-of-large-scale-learning.pdf">one later won a test of time award at NeurIPS</a>. Poster sessions always felt like an anachronistic means to justify a work travel expense rather than an effective means of academic knowledge dissemination. Is there a better way forward that uses our current technological constraints to amplify the voices of young scholars with cutting edge ideas? I don’t have great ideas for how to do this yet, but new interaction structures may emerge as we deal with at least one more year without meetings with hundreds of people.</p>

<h2 id="how-much-should-conferences-cost">How much should conferences cost?</h2>

<p>We were able to do L4DC, with the proceedings and all, for free. Obviously, the program committee put in tons of work in reviewing and organizing the logistics. But reviewing labor isn’t compensated by any conference. All peer reviewed conferences rely on the volunteer service labor of a dedicated program committee. The main line items we expected for L4DC were for renting physical space, paying an AV crew, and food. But in the virtual world, these expenses drop to near zero.</p>

<p>I’m supposed to give a plenary talk at the <a href="https://www.ifac2020.org/">Virtual IFAC Congress</a> in July. I have to say, I am troubled: IFAC is charging <a href="https://www.ifac2020.org/registration/">380 euros per person</a> for registration. What does one get for this sum? Access to video streams and the ability to publish papers. This seems exorbitantly expensive. Why would anyone watch a talk I give at IFAC when I promise to just release it on YouTube at the same time? What value is IFAC providing back to the academic community?</p>

<h2 id="decoupling-papers-from-talks">Decoupling papers from talks</h2>

<p>One of the main things the registration fee at many conferences provides is a stamp of academic approval. It is a de facto publication fee. Led by computer science, conferences in engineering are replacing journals as the archives where CV-building work is cataloged. Though this wasn’t the initial purpose of conferences in computer science, conferences do have many attractive features over journals for rapidly evolving fields: Conferences have speedy turn-around times and clearly delineated submission and decision dates. This archival aspect of conferences, however, has nothing to do with community building or scholarly dissemination. Why do we need to couple a talk to a publication? Can’t we separate these two as is done in every other academic field?</p>

<p>Our collective pandemic moment gives us an opportunity not only to rethink community-building but also our publication model. With 10000-person mega-conferences like <a href="http://icml.cc">AI Summer</a> and <a href="http://neurips.cc">AI Winter</a>, why can’t we keep all of the deadlines the same but remove all of the talks? We’d still have the same reviewing architecture, which has been wholly virtual for over a decade. And we could still publish all of the proceedings online for free, which has been done for multiple decades.</p>

<p>The decoupling proposal here would have effectively zero overhead on our communities: the deadlines, CMTs, program committees, and proceedings could all function exactly the same way (though, to be fair, these systems all have warts worth improving upon). New archival, fast-turnaround journals could easily start using the same tools. Indeed, I’ve always been enamored with the idea of an arxiv-overlay journal that simply is a table of contents that points towards particular versions of arxiv papers as “accepted.” And a really radical idea would be to solicit <em>talks</em>—not papers—for virtual conferences where potential speakers would submit slides or videos to demonstrate proficiency in the medium in which they’d present.</p>

<p>I tend to dismiss most of the bloviation about how coronavirus permanently changes everything about how we live our lives. But it does provide us an opportunity to pause and assess whether current systems are functioning well. I’d argue that the current conference system hasn’t been functioning well for a while, but this simple decoupling of papers and talks might clear up a lot of the issues currently facing the hard-charging computing world.</p>

<p><em>Many thanks to my dedicated, passionate L4DC Co-organizers: Alex Bayen, Ali Jadbababie, George Pappas, Pablo Parrilo, Claire Tomlin, and Melanie Zeilinger. I’d also like to thank Rediet Abebe, Jordan Ellenberg, Eric Jonas, Angjoo Kanazawa, Adam Klivans, Nik Matni, Chris Re, and Tom Ristenpart for their helpful feedback on this post.</em></p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2020/06/22/virtual-conferences/"><span class="datestr">at June 22, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/06/21/subpract">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/06/21/subpract.html">Subpract</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I’ve <a href="https://11011110.github.io/blog/2018/04/18/subtraction-games.html">written here before</a> about <a href="https://en.wikipedia.org/wiki/Subtraction_game">subtraction games</a>, two-player games in which the players remove tokens from a pile of tokens, the number of removed tokens is required to belong to a designated <em>subtraction set</em>, and the goal is to make the last move. For instance, <a href="https://en.wikipedia.org/wiki/Subtract_a_square">subtract a square</a>, a game <a href="https://doi.org/10.4230/LIPIcs.FUN.2018.20">I studied at FUN 2018</a>, is of this type, with the subtraction set being the square numbers.</p>

<p>At some point in studying these games I also briefly looked at the subtraction game whose subtraction set is the set of <a href="https://en.wikipedia.org/wiki/Practical_number">practical numbers</a>, the numbers whose sums of divisors include all values up to the given numbers. The sequence of these numbers begins</p>



<p>and it turns out to be important here that, after the first one, they’re all even. Let’s call the subtraction game with this subtraction set <em>subpract</em>.</p>

<p>For a subtraction game, or more generally any <a href="https://en.wikipedia.org/wiki/Impartial_game">impartial game</a>, the game states can be partitioned into -positions (where the player who played previously is winning with optimal play) and -positions (where the next player to move can force a win); the -positions tend to be rarer than the -positions, and it’s important to know where they are because the optimal strategy in the game is to move to a -position whenever possible.</p>

<p><a href="http://oeis.org/A275432">OEIS A275432</a> lists the -positions for subpract. They are:</p>



<p>For instance, it’s a winning move in subpract to move to a pile of ten tokens (if you can), because  whatever move your opponent makes from there lets you win. If your opponent takes an even number of tokens, you will be able to take all the remaining tokens and win immediately. And if your opponent takes one token, leaving a pile of nine tokens, you can win by taking six more and leaving a pile of three tokens. Then, regardless of how your opponent responds, you will be able to take all the tokens on your next move.</p>

<p>An obvious pattern jumps out from this list of -positions: they come in pairs, spaced three apart. More precisely, an even number  is a -position if and only if the odd number  is a -position. It’s not just a coincidence, true at the start of the sequence and then false later on: it carries on throughout the entire sequence of -positions. More strongly, this same three-apart pairing of  -positions holds for any subtraction game whose subtraction set contains <span style="white-space: nowrap;">, , and ,</span> and does not contain any other odd numbers.</p>

<h1 id="proof-of-the-pairing-property">Proof of the pairing property</h1>

<p>To prove this, I need to show that  is a -position if and only if  is a winning position. We can prove this by induction, where we assume that all the -positions below  and  are paired up in the same way, and use it to prove that the same pairing holds for  and . The basic idea of the proof is to assume that one of the two players has a winning strategy for the <span style="white-space: nowrap;">position ,</span> and to copy that strategy for , most of the time playing the same moves and responses that you would play for the smaller position. Whenever a sequence of moves is applicable to both  and  and preserves the parity of the starting position, the induction hypothesis shows that it has the same outcome for both starting positions. However, there are a few cases where you may be forced to deviate from this strategy:</p>

<ul>
  <li>
    <p>If  is an -position, but its winning move is to subtract one token leading to an odd -position , then copying that move from the starting position  would lead to the position  which may not be a -position. Instead you should subtract four tokens to get to the position  directly.</p>
  </li>
  <li>
    <p>If  is a -position, and you’re trying to copy its winning strategy in the position , your opponent may be able to subtract , a move that is not possible in , so you have no response to copy. But in this case the result is a pile of just one token, from which you can immediately win.</p>
  </li>
  <li>
    <p>Again, if you’re trying to copy the winning strategy for -position  in the position , your opponent may subtract only one token. In this case, the winning response when starting from  might be to subtract an even number, leading to an odd -position . If you copy this response, you will end up at  which may not be a -position. But instead of copying the -strategy, you can simply subtract two tokens, leading to the position  itself.</p>
  </li>
  <li>
    <p>Similarly, it may be the case that the winning response to an opponent’s even move from  is to take a single token, leading to odd -position . Copying this strategy from the starting position  would again lead to . But in this case you can subtract four tokens leading to  again.</p>
  </li>
</ul>

<p>It’s tempting to guess that, more strongly than pairing -positions and -positions in this way, subpract and similar subtraction games have a pairing of their <a href="https://en.wikipedia.org/wiki/Sprague%E2%80%93Grundy_theorem">nim-values</a>, where the nim-value of an odd position always equals the nim-value of the even position three units smaller. But it’s not true. For instance, in subpract, a pile of four tokens has nim-value 1 while a pile of seven tokens has nim-value 4.</p>

<h1 id="other-subtraction-sets">Other subtraction sets</h1>

<p>Probably the most obvious choice of another subtraction set that begins  and has no larger odd numbers would be the powers of two, but they don’t give rise to an interesting subtraction game: the -positions are just the multiples of three. The same thing happens whenever there are no multiples of three in the subtraction set, as happens for instance with the <a href="https://11011110.github.io/blog/2020/06/21/Telephone number (mathematics)">telephone numbers</a> and <a href="http://oeis.org/A003422">left factorials</a>.</p>

<p>Another natural subtraction set to which this theory applies is the sequence of <a href="http://oeis.org/A025487">Hardy–Ramanujan integers (A025487)</a>, the numbers whose prime factorization  has a non-increasing sequence of exponents . They are:</p>



<p>These are a subset of the practical numbers so one would expect their subtraction game to have more-dense -positions. My implementation found that these -positions are:</p>



<p>again obeying the offset-by-three pairing as it should, and otherwise having somewhat irregular intervals between its -positions.</p>

<p>The <a href="http://oeis.org/A000084">enumeration function of the series-parallel graphs and the cographs</a> is even after its first term because of series-parallel duality; it begins</p>



<p>These are not all practical; for instance, 10, 1532, and 43930 are not practical. The sequence of -positions for their subtraction game begins</p>



<p>mostly differing by three between consecutive values but with occasional glitches where the larger multiple-of-three subtraction set values kick in.</p>

<p>And finally, if we subtract numbers that are one less than a prime, we get the subtraction set</p>



<p>and the sequence of -positions</p>



<p>Its small values have many five-unit gaps but that pattern appears to die out after the quadruple of -positions .</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104384624632242432">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/06/21/subpract.html"><span class="datestr">at June 21, 2020 04:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
