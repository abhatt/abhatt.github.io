<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at June 09, 2020 11:22 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.04166">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.04166">Learning Restricted Boltzmann Machines with Few Latent Variables</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bresler:Guy.html">Guy Bresler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buhai:Rares=Darius.html">Rares-Darius Buhai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.04166">PDF</a><br /><b>Abstract: </b>Restricted Boltzmann Machines (RBMs) are a common family of undirected
graphical models with latent variables. An RBM is described by a bipartite
graph, with all observed variables in one layer and all latent variables in the
other. We consider the task of learning an RBM given samples generated
according to it. The best algorithms for this task currently have time
complexity $\tilde{O}(n^2)$ for ferromagnetic RBMs (i.e., with attractive
potentials) but $\tilde{O}(n^d)$ for general RBMs, where $n$ is the number of
observed variables and $d$ is the maximum degree of a latent variable. Let the
MRF neighborhood of an observed variable be its neighborhood in the Markov
Random Field of the marginal distribution of the observed variables. In this
paper, we give an algorithm for learning general RBMs with time complexity
$\tilde{O}(n^{2^s+1})$, where $s$ is the maximum number of latent variables
connected to the MRF neighborhood of an observed variable. This represents an
improvement when $s &lt; \log_2 (d-1)$, which is satisfied by many classes of RBMs
with "few latent variables''. Furthermore, we give a version of this learning
algorithm that recovers a model with small prediction error and whose sample
complexity is independent of the minimum potential in the Markov Random Field
of the observed variables. This is of interest because the sample complexity of
current algorithms scales with the inverse of the minimum potential, which
cannot be controlled in terms of natural properties of the RBM.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.04166"><span class="datestr">at June 09, 2020 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.04124">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.04124">On the Complexity of Branching Proofs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dadush:Daniel.html">Daniel Dadush</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tiwari:Samarth.html">Samarth Tiwari</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.04124">PDF</a><br /><b>Abstract: </b>We consider the task of proving integer infeasibility of a bounded convex $K$
in $\mathbb{R}^n$ using a general branching proof system. In a general
branching proof, one constructs a branching tree by adding an integer
disjunction $\mathbf{a} \mathbf{x} \leq b$ or $\mathbf{a} \mathbf{x} \geq b+1$,
$\mathbf{a} \in \mathbb{Z}^n$, $b \in \mathbb{Z}$, at each node, such that the
leaves of the tree correspond to empty sets (i.e., $K$ together with the
inequalities picked up from the root to leaf is empty). Recently, Beame et al
(ITCS 2018), asked whether the bit size of the coefficients in a branching
proof, which they named stabbing planes (SP) refutations, for the case of
polytopes derived from SAT formulas, can be assumed to be polynomial in $n$. We
resolve this question by showing that any branching proof can be recompiled so
that the integer disjunctions have coefficients of size at most $(n
R)^{O(n^2)}$, where $R \in \mathbb{N}$ such that $K \in R \mathbb{B}_1^n$,
while increasing the number of nodes in the branching tree by at most a factor
$O(n)$. As our second contribution, we show that Tseitin formulas, an important
class of infeasible SAT instances, have quasi-polynomial sized cutting plane
(CP) refutations, disproving the conjecture that Tseitin formulas are
(exponentially) hard for CP. As our final contribution, we give a simple family
of polytopes in $[0,1]^n$ requiring branching proofs of length $2^n/n$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.04124"><span class="datestr">at June 09, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.04094">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.04094">Average Sensitivity of Spectral Clustering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Pan.html">Pan Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshida:Yuichi.html">Yuichi Yoshida</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.04094">PDF</a><br /><b>Abstract: </b>Spectral clustering is one of the most popular clustering methods for finding
clusters in a graph, which has found many applications in data mining. However,
the input graph in those applications may have many missing edges due to error
in measurement, withholding for a privacy reason, or arbitrariness in data
conversion. To make reliable and efficient decisions based on spectral
clustering, we assess the stability of spectral clustering against edge
perturbations in the input graph using the notion of average sensitivity, which
is the expected size of the symmetric difference of the output clusters before
and after we randomly remove edges.
</p>
<p>We first prove that the average sensitivity of spectral clustering is
proportional to $\lambda_2/\lambda_3^2$, where $\lambda_i$ is the $i$-th
smallest eigenvalue of the (normalized) Laplacian. We also prove an analogous
bound for $k$-way spectral clustering, which partitions the graph into $k$
clusters. Then, we empirically confirm our theoretical bounds by conducting
experiments on synthetic and real networks. Our results suggest that spectral
clustering is stable against edge perturbations when there is a cluster
structure in the input graph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.04094"><span class="datestr">at June 09, 2020 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.04046">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.04046">On Suboptimality of Least Squares with Application to Estimation of Convex Bodies</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kur:Gil.html">Gil Kur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rakhlin:Alexander.html">Alexander Rakhlin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guntuboyina:Adityanand.html">Adityanand Guntuboyina</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.04046">PDF</a><br /><b>Abstract: </b>We develop a technique for establishing lower bounds on the sample complexity
of Least Squares (or, Empirical Risk Minimization) for large classes of
functions. As an application, we settle an open problem regarding optimality of
Least Squares in estimating a convex set from noisy support function
measurements in dimension $d\geq 6$. Specifically, we establish that Least
Squares is mimimax sub-optimal, and achieves a rate of
$\tilde{\Theta}_d(n^{-2/(d-1)})$ whereas the minimax rate is
$\Theta_d(n^{-4/(d+3)})$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.04046"><span class="datestr">at June 09, 2020 01:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03856">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03856">On the Maximum Cardinality Cut Problem in Proper Interval Graphs and Related Graph Classes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Arman Boyacı, Tınaz Ekim, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shalom:Mordechai.html">Mordechai Shalom</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03856">PDF</a><br /><b>Abstract: </b>Although it has been claimed in two different papers that the maximum
cardinality cut problem is polynomial-time solvable for proper interval graphs,
both of them turned out to be erroneous. In this paper, we give FPT algorithms
for the maximum cardinality cut problem in classes of graphs containing proper
interval graphs and mixed unit interval graphs when parameterized by some new
parameters that we introduce. These new parameters are related to a
generalization of the so-called bubble representations of proper interval
graphs and mixed unit interval graphs and to clique-width decompositions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03856"><span class="datestr">at June 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03840">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03840">Building a Heterogeneous, Large Scale Morphable Face Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferrari:Claudio.html">Claudio Ferrari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Berretti:Stefano.html">Stefano Berretti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pala:Pietro.html">Pietro Pala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bimbo:Alberto_Del.html">Alberto Del Bimbo</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03840">PDF</a><br /><b>Abstract: </b>3D Morphable Models (3DMMs) are powerful statistical tools for representing
and modeling 3D faces. To build a 3DMM, a training set of fully registered face
scans is required, and its modeling capabilities directly depend on the
variability contained in the training data. Thus, accurately establishing a
dense point-to-point correspondence across heterogeneous scans with sufficient
diversity in terms of identities, ethnicities, or expressions becomes
essential. In this manuscript, we present an approach that leverages a 3DMM to
transfer its dense semantic annotation across a large set of heterogeneous 3D
faces, establishing a dense correspondence between them. To this aim, we
propose a novel formulation to learn a set of sparse deformation components
with local support on the face that, together with an original non-rigid
deformation algorithm, allow precisely fitting the 3DMM to arbitrary faces and
transfer its semantic annotation. We experimented our approach on three large
and diverse datasets, showing it can effectively generalize to very different
samples and accurately establish a dense correspondence even in presence of
complex facial expressions or unseen deformations. As main outcome of this
work, we build a heterogeneous, large-scale 3DMM from more than 9,000 fully
registered scans obtained joining the three datasets together.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03840"><span class="datestr">at June 09, 2020 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03819">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03819">A generalized expression for filling congruent circles in a circle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Ajeet K. Srivastav <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03819">PDF</a><br /><b>Abstract: </b>The paper reports a generalized expression for filling the congruent circles
(of radius r) in a circle (of radius R). First, a generalized expression for
the biggest circle (r) inscribed in the nth part of the bigger circle (R) was
developed. Further, it was extended as n such circles (r) touching each other
and the bigger circle (R). To fill the bigger circle (R), the exercise was
further repeated by considering the bigger circle radius as R-2r, R-4r and so
on. In the process, a generalized expression was deduced for the total no. of
such circles (r) which could be inscribed in this way of filling the bigger
circle (R). The approach does not claim the closest packing always though it
could be helpful for practical purposes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03819"><span class="datestr">at June 09, 2020 01:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03746">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03746">Distributed Approximation on Power Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bar=Yehuda:Reuven.html">Reuven Bar-Yehuda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Censor=Hillel:Keren.html">Keren Censor-Hillel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maus:Yannic.html">Yannic Maus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pai:Shreyas.html">Shreyas Pai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pemmaraju:Sriram_V=.html">Sriram V. Pemmaraju</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03746">PDF</a><br /><b>Abstract: </b>We investigate graph problems in the following setting: we are given a graph
$G$ and we are required to solve a problem on $G^2$. While we focus mostly on
exploring this theme in the distributed CONGEST model, we show new results and
surprising connections to the centralized model of computation. In the CONGEST
model, it is natural to expect that problems on $G^2$ would be quite difficult
to solve efficiently on $G$, due to congestion. However, we show that the
picture is both more complicated and more interesting.
</p>
<p>Specifically, we encounter two phenomena acting in opposing directions: (i)
slowdown due to congestion and (ii) speedup due to structural properties of
$G^2$.
</p>
<p>We demonstrate these two phenomena via two fundamental graph problems,
namely, Minimum Vertex Cover (MVC) and Minimum Dominating Set (MDS). Among our
many contributions, the highlights are the following.
</p>
<p>- In the CONGEST model, we show an $O(n/\epsilon)$-round
$(1+\epsilon)$-approximation algorithm for MVC on $G^2$, while no
$o(n^2)$-round algorithm is known for any better-than-2 approximation for MVC
on $G$.
</p>
<p>- We show a centralized polynomial time $5/3$-approximation algorithm for MVC
on $G^2$, whereas a better-than-2 approximation is UGC-hard for $G$.
</p>
<p>- In contrast, for MDS, in the CONGEST model, we show an
$\tilde{\Omega}(n^2)$ lower bound for a constant approximation factor for MDS
on $G^2$, whereas an $\Omega(n^2)$ lower bound for MDS on $G$ is known only for
exact computation.
</p>
<p>In addition to these highlighted results, we prove a number of other results
in the distributed CONGEST model including an $\tilde{\Omega}(n^2)$ lower bound
for computing an exact solution to MVC on $G^2$, a conditional hardness result
for obtaining a $(1+\epsilon)$-approximation to MVC on $G^2$, and an $O(\log
\Delta)$-approximation to the MDS problem on $G^2$ in $\mbox{poly}\log n$
rounds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03746"><span class="datestr">at June 09, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03684">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03684">Differentially private partition selection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Desfontaines:Damien.html">Damien Desfontaines</a>, James Voss, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gipson:Bryant.html">Bryant Gipson</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03684">PDF</a><br /><b>Abstract: </b>Many data analysis operations can be expressed as a GROUP BY query on an
unbounded set of partitions, followed by a per-partition aggregation. To make
such a query differentially private, adding noise to each aggregation is not
enough: we also need to make sure that the set of partitions released is also
differentially private.
</p>
<p>This problem is not new, and it was recently formally introduced as
differentially private set union. In this work, we continue this area of study,
and focus on the common setting where each user is associated with a single
partition. In this setting, we propose a simple, optimal differentially private
mechanism that maximizes the number of released partitions. We discuss
implementation considerations, as well as the possible extension of this
approach to the setting where each user contributes to a fixed, small number of
partitions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03684"><span class="datestr">at June 09, 2020 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03666">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03666">VectorTSP: A Traveling Salesperson Problem with Racetrack-like acceleration constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Casteigts:Arnaud.html">Arnaud Casteigts</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raffinot:Mathieu.html">Mathieu Raffinot</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schoeters:Jason.html">Jason Schoeters</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03666">PDF</a><br /><b>Abstract: </b>We study a new version of the Euclidean TSP called VectorTSP (VTSP for short)
where a mobile entity is allowed to move according to a set of physical
constraints inspired from the pen-and-pencil game Racetrack (also known as
Vector Racer ). In contrast to other versions of TSP accounting for physical
constraints, such as Dubins TSP, the spirit of this model is that (1) no speed
limitations apply, and (2) inertia depends on the current velocity. As such,
this model is closer to typical models considered in path planning problems,
although applied here to the visit of n cities in a non-predetermined order. We
motivate and introduce the VectorTSP problem, discussing fundamental
differences with previous versions of TSP. In particular, an optimal visit
order for ETSP may not be optimal for VTSP. We show that VectorTSP is NP-hard,
and in the other direction, that VectorTSP reduces to GroupTSP in polynomial
time (although with a significant blow-up in size). On the algorithmic side, we
formulate the search for a solution as an interactive scheme between a
high-level algorithm and a trajectory oracle, the former being responsible for
computing the visit order and the latter for computing the cost (or the
trajectory) for a given visit order. We present algorithms for both, and we
demonstrate and quantify through experiments that this approach frequently
finds a better solution than the optimal trajectory realizing an optimal ETSP
tour, which legitimates the problem itself and (we hope) motivates further
algorithmic developments.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03666"><span class="datestr">at June 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/088">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/088">TR20-088 |  Eliminating Intermediate Measurements in Space-Bounded Quantum Computation | 

	Bill Fefferman, 

	Zachary Remscrim</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A foundational result in the theory of quantum computation known as the ``principle of safe storage'' shows that it is always possible to take a quantum circuit and produce an equivalent circuit that makes all measurements at the end of the computation.  While this procedure is time efficient, meaning that it does not introduce a large overhead in the number of gates, it uses extra ancillary qubits and so is not generally space efficient.  It is quite natural to ask whether it is possible to defer measurements to the end of a quantum computation without increasing the number of ancillary qubits.
		
		We give an affirmative answer to this question by exhibiting a procedure to eliminate all intermediate measurements that is simultaneously space-efficient and time-efficient. A key component of our approach, which may be of independent interest, involves showing that the well-conditioned versions of many standard linear-algebraic problems may be solved by a quantum computer in less space than seems possible by a classical computer.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/088"><span class="datestr">at June 08, 2020 09:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/087">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/087">TR20-087 |  Quantum Logspace Algorithm for Powering Matrices with Bounded Norm | 

	Uma Girish, 

	Ran Raz, 

	Wei Zhan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give a quantum logspace algorithm for powering contraction matrices, that is, matrices with spectral norm at most 1. The algorithm gets as an input an arbitrary $n\times n$ contraction matrix $A$, and a parameter $T \leq poly(n)$ and outputs the entries of $A^T$, up to (arbitrary) polynomially small additive error. The algorithm applies only unitary operators, without intermediate measurements. We show various implications and applications of this result:

First, we use this algorithm to show that the class of quantum logspace algorithms with only quantum memory and with intermediate measurements is equivalent to the class of quantum logspace algorithms with only quantum memory without intermediate measurements. This shows that the deferred-measurement principle, a fundamental principle of quantum computing, applies also for quantum logspace algorithms (without classical memory). More generally, we give a quantum algorithm with space $O(S + \log T)$ that takes as an input the description of a quantum algorithm with quantum space $S$ and time $T$, with intermediate measurements (without classical memory), and simulates it unitarily with polynomially small error, without intermediate measurements.

Since unitary transformations are reversible (while measurements are irreversible) an interesting aspect of this result is that it shows that any quantum logspace algorithm (without classical memory) can be simulated by a reversible quantum logspace algorithm. This proves a quantum analogue of the result of Lange, McKenzie and Tapp that deterministic logspace is equal to reversible logspace.

Finally, we use our results to show non-trivial classical simulations of quantum logspace learning algorithms.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/087"><span class="datestr">at June 08, 2020 06:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-9046421052819875987">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/06/the-committee-for-adv-of-tcs-workshop.html">The Committee for the Adv. of TCS- workshop coming up SOON!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"></span><br />
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"><span>(Posted by request from Jelani Nelson.)</span></span></div>
<span id="docs-internal-guid-06a8f4c9-7fff-916b-0154-0d4b08969907"><br /><div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>The Committee for the Advancement of Theoretical Computer Science (CATCS)</span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>is organizing a Visioning workshop.  The primary objective of the workshop</span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>is for TCS participants to brainstorm directions and talking points for TCS</span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>program managers at funding agencies to advocate for theory funding.</span></div>
<br /><div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>There was some question of whether or not it would run this summer, but</span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>YES, it is going to run.</span></div>
<br /><div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>If you are interested then reply (at the link below) by June 15.</span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>This is SOON so click that link SOON.</span></div>
<br /><div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>The time commitment is 4-5 hours during the week of July 20-July 24 for</span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>most participants, or roughly 10 hours for those who are willing to</span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>volunteer to be group leaders.</span></div>
<br /><div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span>The link to sign up is:</span></div>
<br /><div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<span><a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/</a></span></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<br /></div>
<div style="line-height: 1.38; margin-bottom: 0pt; margin-top: 0pt;" dir="ltr">
<br /></div>
</span></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/06/the-committee-for-adv-of-tcs-workshop.html"><span class="datestr">at June 08, 2020 03:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4392">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/06/08/visioning-workshop-call-for-participation/">“Visioning” workshop call for participation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In 2008, the <a href="https://thmatters.wordpress.com/catcs/">Committee for the Advancement of Theoretical Computer Science</a> convened a workshop to brainstorm directions and talking points for TCS<br />
program managers at funding agencies to advocate for theory funding. The event was quite productive and successful. </p>
<p>A second such workshop is going to be held, online, in the third week of July. Applications to participate are due on June 15, a week from today. Organizers expect that participants will have to devote about four hours of their time to the workshop, and those who volunteer to be team leads will have a time commitment of about ten hours.</p>
<p>More information <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">at this link</a></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/06/08/visioning-workshop-call-for-participation/"><span class="datestr">at June 08, 2020 09:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1343">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1343">Welcome Akash Kumar!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Let’s welcome our latest editor, Akash Kumar. Akash will be taking the place of Gautam Kamath, who has decided to pass the torch on. Let’s also thank Gautam for all the help with PTReview.</p></div>







<p class="date">
by Seshadhri <a href="https://ptreview.sublinear.info/?p=1343"><span class="datestr">at June 08, 2020 03:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03578">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03578">Clique-Width: Harnessing the Power of Atoms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dabrowski:Konrad_K=.html">Konrad K. Dabrowski</a>, Tomáš Masařík, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novotn=aacute=:Jana.html">Jana Novotná</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paulusma:Dani=euml=l.html">Daniël Paulusma</a>, Paweł Rzążewski <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03578">PDF</a><br /><b>Abstract: </b>Many NP-complete graph problems are polynomially solvable on graph classes of
bounded clique-width. Several of these problems are polynomially solvable on a
hereditary graph class G if they are so on the atoms (graphs with no clique
cut-set) of G. Hence, we initiate a systematic study into boundedness of
clique-width of atoms of hereditary graph classes. A graph G is H-free if H is
not an induced subgraph of G, and G is (H_1, H_2)-free if it is both H_1-free
and H_2-free. A class of H-free graphs has bounded clique-width if and only if
its atoms have this property. This is no longer true for (H_1, H_2)-free graphs
as evidenced by one known example. We prove the existence of another such pair
(H_1, H_2) and classify the boundedness of (H_1, H_2)-free atoms for all but 22
cases.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03578"><span class="datestr">at June 08, 2020 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03530">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03530">Eliminating Intermediate Measurements in Space-Bounded Quantum Computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fefferman:Bill.html">Bill Fefferman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Remscrim:Zachary.html">Zachary Remscrim</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03530">PDF</a><br /><b>Abstract: </b>A foundational result in the theory of quantum computation known as the
"principle of safe storage" shows that it is always possible to take a quantum
circuit and produce an equivalent circuit that makes all measurements at the
end of the computation. While this procedure is time efficient, meaning that it
does not introduce a large overhead in the number of gates, it uses extra
ancillary qubits and so is not generally space efficient. It is quite natural
to ask whether it is possible to defer measurements to the end of a quantum
computation without increasing the number of ancillary qubits.
</p>
<p>We give an affirmative answer to this question by exhibiting a procedure to
eliminate all intermediate measurements that is simultaneously space-efficient
and time-efficient. A key component of our approach, which may be of
independent interest, involves showing that the well-conditioned versions of
many standard linear-algebraic problems may be solved by a quantum computer in
less space than seems possible by a classical computer.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03530"><span class="datestr">at June 08, 2020 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03499">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03499">Detecting and Analyzing Mobility Hotspots using Surface Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Yujie.html">Yujie Hu</a>, Harvey J Miller, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Xiang.html">Xiang Li</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03499">PDF</a><br /><b>Abstract: </b>Capabilities for collecting and storing data on mobile objects have increased
dramatically over the past few decades. A persistent difficulty is summarizing
large collections of mobile objects. This paper develops methods for extracting
and analyzing hotspots or locations with relatively high levels of mobility
activity. We use kernel density estimation (KDE) to convert a large collection
of mobile objects into a smooth, continuous surface. We then develop a
topological algorithm to extract critical geometric features of the surface;
these include critical points (peaks, pits and passes) and critical lines
(ridgelines and course-lines). We connect the peaks and corresponding
ridgelines to produce a surface network that summarizes the topological
structure of the surface. We apply graph theoretic indices to analytically
characterize the surface and its changes over time. To illustrate our approach,
we apply the techniques to taxi cab data collected in Shanghai, China. We find
increases in the complexity of the hotspot spatial distribution during normal
activity hours in the late morning, afternoon and evening and a spike in the
connectivity of the hotspot spatial distribution in the morning as taxis
concentrate on servicing travel to work. These results match with scientific
and anecdotal knowledge about human activity patterns in the study area.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03499"><span class="datestr">at June 08, 2020 11:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03460">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03460">Optimal Sensor Placement in Power Grids: Power Domination, Set Covering, and the Neighborhoods of Zero Forcing Forts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smith:Logan_A=.html">Logan A. Smith</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hicks:Illya_V=.html">Illya V. Hicks</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03460">PDF</a><br /><b>Abstract: </b>To monitor electrical activity throughout the power grid and mitigate
outages, sensors known as phasor measurement units can installed. Due to
implementation costs, it is desirable to minimize the number of sensors
deployed while ensuring that the grid can be effectively monitored. This
optimization problem motivates the graph theoretic power dominating set
problem. In this paper, we propose a novel integer program for identifying
minimum power dominating sets by formulating a set cover problem. This
problem's constraints correspond to neighborhoods of zero forcing forts; we
study their structural properties and show they can be separated, allowing the
proposed model to be solved via row generation. The proposed and existing
methods are compared in several computational experiments in which the proposed
method consistently exhibits an order of magnitude improvement in runtime
performance.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03460"><span class="datestr">at June 08, 2020 11:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03440">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03440">Spread of Influence in Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehmakan:Ahad_N=.html">Ahad N. Zehmakan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03440">PDF</a><br /><b>Abstract: </b>Consider a graph $G$ and an initial configuration where each node is black or
white. Assume that in each round all nodes simultaneously update their color
based on a predefined rule. One can think of graph $G$ as a social network,
where each black/white node represents an individual who holds a
positive/negative opinion regarding a particular topic. In the $r$-threshold
(resp. $\alpha$-threshold) model, a node becomes black if at least $r$ of its
neighbors (resp. $\alpha$ fraction of its neighbors) are black, and white
otherwise. The $r$-monotone (resp. $\alpha$-monotone) model is the same as the
$r$-threshold (resp. $\alpha$-threshold) model, except that a black node
remains black forever.
</p>
<p>What is the number of rounds that the process needs to stabilize? How many
nodes must be black initially so that black color takes over or survives? Our
main goal in the present paper is to address these two questions
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03440"><span class="datestr">at June 08, 2020 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03399">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03399">Single-machine scheduling with an external resource</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Briskorn:Dirk.html">Dirk Briskorn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Davari:Morteza.html">Morteza Davari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matuschke:Jannik.html">Jannik Matuschke</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03399">PDF</a><br /><b>Abstract: </b>This paper studies the complexity of single-machine scheduling with an
external resource, which is rented for a non-interrupted period. Jobs that need
this external resource are executed only when the external resource is
available. There is a cost associated with the scheduling of jobs and a cost
associated with the duration of the renting period of the external resource. We
look at three classes of problems with an external resource: a class of
problems where the renting period is budgeted and the scheduling cost needs to
be minimized, a class of problems where the scheduling cost is budgeted and the
renting period needs to be minimized, and a class of two-objective problems
where both, the renting period and the scheduling cost, are to be minimized. We
provide a thorough complexity analysis (NP-hardness proofs and
pseudo-polynomial algorithms) for different members of these three classes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03399"><span class="datestr">at June 08, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03372">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03372">Scaling Up Distanced-generalized Core Decomposition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dai:Qiangqiang.html">Qiangqiang Dai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Rong=Hua.html">Rong-Hua Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Qin:Lu.html">Lu Qin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Guoren.html">Guoren Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Weihua.html">Weihua Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Zhiwei.html">Zhiwei Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuan:Ye.html">Ye Yuan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03372">PDF</a><br /><b>Abstract: </b>Core decomposition is a fundamental operator in network analysis. In this
paper, we study a problem of computing distance-generalized core decomposition
on a network. A distance-generalized core, also termed $(k, h)$-core, is a
maximal subgraph in which every vertex has at least $k$ other vertices at
distance no larger than $h$. The state-of-the-art algorithm for solving this
problem is based on a peeling technique which iteratively removes the vertex
(denoted by $v$) from the graph that has the smallest $h$-degree. The
$h$-degree of a vertex $v$ denotes the number of other vertices that are
reachable from $v$ within $h$ hops. Such a peeling algorithm, however, needs to
frequently recompute the $h$-degrees of $v$'s neighbors after deleting $v$,
which is typically very costly for a large $h$. To overcome this limitation, we
propose an efficient peeling algorithm based on a novel $h$-degree updating
technique. Instead of recomputing the $h$-degrees, our algorithm can
dynamically maintain the $h$-degrees for all vertices via exploring a very
small subgraph, after peeling a vertex. We show that such an $h$-degree
updating procedure can be efficiently implemented by an elegant bitmap
technique. In addition, we also propose a sampling-based algorithm and a
parallelization technique to further improve the efficiency. Finally, we
conduct extensive experiments on 12 real-world graphs to evaluate our
algorithms. The results show that, when $h\ge 3$, our exact and sampling-based
algorithms can achieve up to $10\times$ and $100\times$ speedup over the
state-of-the-art algorithm, respectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03372"><span class="datestr">at June 08, 2020 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03365">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03365">The Baggage Belt Assignment Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pisinger:David.html">David Pisinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scatamacchia:Rosario.html">Rosario Scatamacchia</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03365">PDF</a><br /><b>Abstract: </b>We consider the problem of assigning flights to baggage belts in the baggage
reclaim area of an airport. The problem is originated by a real-life
application in Copenhagen airport. The objective is to construct a robust
schedule taking passenger and airline preferences into account. We consider a
number of business and fairness constraints, avoiding congestions, and ensuring
a good passenger flow. Robustness of the solutions is achieved by matching the
delivery time with the expected arrival time of passengers, and by adding
buffer time between two flights scheduled on the same belt. We denote this
problem as the Baggage Belt Assignment Problem (BBAP). We first derive a
general Integer Linear Programming (ILP) formulation for the problem. Then, we
propose a Branch-and-Price (B&amp;P) algorithm based on a reformulation of the ILP
model tackled by Column Generation. Our approach relies on an effective dynamic
programming algorithm for handling the pricing problems. We tested the proposed
algorithm on a set of real-life data from Copenhagen airport as well as on a
set of instances inspired by the real data. Our B&amp;P scheme outperforms a
commercial solver launched on the ILP formulation of the problem and is
effective in delivering high quality solutions in limited computational times,
making it possible its use in daily operations in medium-sized and large
airports.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03365"><span class="datestr">at June 08, 2020 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03363">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03363">From Checking to Inference: Actual Causality Computations as Optimization Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ibrahim:Amjad.html">Amjad Ibrahim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pretschner:Alexander.html">Alexander Pretschner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03363">PDF</a><br /><b>Abstract: </b>Actual causality is increasingly well understood. Recent formal approaches,
proposed by Halpern and Pearl, have made this concept mature enough to be
amenable to automated reasoning. Actual causality is especially vital for
building accountable, explainable systems. Among other reasons, causality
reasoning is computationally hard due to the requirements of counterfactuality
and the minimality of causes. Previous approaches presented either inefficient
or restricted, and domain-specific, solutions to the problem of automating
causality reasoning. In this paper, we present a novel approach to formulate
different notions of causal reasoning, over binary acyclic models, as
optimization problems, based on quantifiable notions within counterfactual
computations. We contribute and compare two compact, non-trivial, and sound
integer linear programming (ILP) and Maximum Satisfiability (MaxSAT) encodings
to check causality. Given a candidate cause, both approaches identify what a
minimal cause is. Also, we present an ILP encoding to infer causality without
requiring a candidate cause. We show that both notions are efficiently
automated. Using models with more than $8000$ variables, checking is computed
in a matter of seconds, with MaxSAT outperforming ILP in many cases. In
contrast, inference is computed in a matter of minutes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03363"><span class="datestr">at June 08, 2020 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03213">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03213">Linear Programming and Community Detection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pia:Alberto_Del.html">Alberto Del Pia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khajavirad:Aida.html">Aida Khajavirad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kunisky:Dmitriy.html">Dmitriy Kunisky</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03213">PDF</a><br /><b>Abstract: </b>The problem of community detection with two equal-sized communities is
closely related to the minimum graph bisection problem over certain random
graph models. In the stochastic block model distribution over networks with
community structure, a well-known semidefinite programming (SDP) relaxation of
the minimum bisection problem recovers the underlying communities whenever
possible. Motivated by their superior scalability, we study the theoretical
performance of linear programming (LP) relaxations of the minimum bisection
problem for the same random models. We show that unlike the SDP relaxation that
undergoes a phase transition in the logarithmic average-degree regime, the LP
relaxation exhibits a transition from recovery to non-recovery in the linear
average-degree regime. We show that in the logarithmic average-degree regime,
the LP relaxation fails in recovering the planted bisection with high
probability.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03213"><span class="datestr">at June 08, 2020 11:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03198">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03198">Efficient Semi-External Depth-First Search</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wan:Xiaolong.html">Xiaolong Wan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Hongzhi.html">Hongzhi Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03198">PDF</a><br /><b>Abstract: </b>Computing Depth-First Search (DFS) results, i.e. depth-first order or
DFS-Tree, on the semi-external environment becomes a hot topic, because the
scales of the graphs grow rapidly which can hardly be hold in the main memory,
in the big data era. Existing semi-external DFS algorithms assume the main
memory could, at least, hold a spanning tree T of a graph G, and gradually
restructure T into a DFS-Tree, which is non-trivial. In this paper, we present
a comprehensive study of semi-external DFS problem, including the first
theoretical analysis of the main challenge of this problem, as far as we know.
Besides, we introduce a new semi-external DFS algorithm with an efficient edge
pruning principle, named EP-DFS. Unlike the traditional algorithms, we not only
focus on addressing such complex problem efficiently with less I/Os, but also
focus on that with simpler CPU calculation (Implementation-friendly) and less
random I/O access (key-to-efficiency). The former is based on our efficient
pruning principle; the latter is addressed by a lightweight index N+-index,
which is a compressed storage for a subset of the edges for G. The extensive
experimental evaluation on both synthetic and real graphs confirms that our
EP-DFS algorithm outperforms the existing techniques.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03198"><span class="datestr">at June 08, 2020 11:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03177">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03177">Hardness of Learning Neural Networks with Natural Weights</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Daniely:Amit.html">Amit Daniely</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Gal.html">Gal Vardi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03177">PDF</a><br /><b>Abstract: </b>Neural networks are nowadays highly successful despite strong hardness
results. The existing hardness results focus on the network architecture, and
assume that the network's weights are arbitrary. A natural approach to settle
the discrepancy is to assume that the network's weights are "well-behaved" and
posses some generic properties that may allow efficient learning. This approach
is supported by the intuition that the weights in real-world networks are not
arbitrary, but exhibit some "random-like" properties with respect to some
"natural" distributions. We prove negative results in this regard, and show
that for depth-$2$ networks, and many "natural" weights distributions such as
the normal and the uniform distribution, most networks are hard to learn.
Namely, there is no efficient learning algorithm that is provably successful
for most weights, and every input distribution. It implies that there is no
generic property that holds with high probability in such random networks and
allows efficient learning.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03177"><span class="datestr">at June 08, 2020 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03176">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03176">Partitioned Learned Bloom Filter</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaidya:Kapil.html">Kapil Vaidya</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Knorr:Eric.html">Eric Knorr</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kraska:Tim.html">Tim Kraska</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html">Michael Mitzenmacher</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03176">PDF</a><br /><b>Abstract: </b>Learned Bloom filters enhance standard Bloom filters by using a learned model
for the represented data set. However, a learned Bloom filter may under-utilize
the model by not taking full advantage of the output. The learned Bloom filter
uses the output score by simply applying a threshold, with elements above the
threshold being interpreted as positives, and elements below the threshold
subject to further analysis independent of the output score (using a smaller
backup Bloom filter to prevent false negatives). While recent work has
suggested additional heuristic approaches to take better advantage of the
score, the results are only heuristic. Here, we instead frame the problem of
optimal model utilization as an optimization problem. We show that the
optimization problem can be effectively solved efficiently, yielding an
improved {partitioned learned Bloom filter}, which partitions the score space
and utilizes separate backup Bloom filters for each region. Experimental
results from both simulated and real-world datasets show significant
performance improvements from our optimization approach over both the original
learned Bloom filter constructions and previously proposed heuristic
improvements.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03176"><span class="datestr">at June 08, 2020 11:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.03134">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.03134">Tensor Completion Made Practical</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Allen.html">Allen Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moitra:Ankur.html">Ankur Moitra</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.03134">PDF</a><br /><b>Abstract: </b>Tensor completion is a natural higher-order generalization of matrix
completion where the goal is to recover a low-rank tensor from sparse
observations of its entries. Existing algorithms are either heuristic without
provable guarantees, based on solving large semidefinite programs which are
impractical to run, or make strong assumptions such as requiring the factors to
be nearly orthogonal. In this paper we introduce a new variant of alternating
minimization, which in turn is inspired by understanding how the progress
measures that guide convergence of alternating minimization in the matrix
setting need to be adapted to the tensor setting. We show strong provable
guarantees, including showing that our algorithm converges linearly to the true
tensors even when the factors are highly correlated and can be implemented in
nearly linear time. Moreover our algorithm is also highly practical and we show
that we can complete third order tensors with a thousand dimensions from
observing a tiny fraction of its entries. In contrast, and somewhat
surprisingly, we show that the standard version of alternating minimization,
without our new twist, can converge at a drastically slower rate in practice.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.03134"><span class="datestr">at June 08, 2020 11:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1315">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1315">News for May 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Last month saw activity across a diverse collection of topics in sublinear algorithms. In particular, we had the following <s>five</s> six papers. <em>(Sorry, I missed one)</em> </p>



<p><strong>One-Sided Error Testing of Monomials and Affine Subspaces</strong> by Oded Goldreich and Dana Ron (<a href="https://eccc.weizmann.ac.il/report/2020/068/">ECCC</a>). This work focuses on one-sided testing of two kinds of problems (and their variants): <br /><span class="has-inline-color has-blue-color">1.</span> Testing Monomials: Suppose you are given a function \(f \colon \{0,1\}^n \to \{0,1\}\). Is \(f = \wedge_{i \in I} x_i\) (that is, is \(f\) a monotone monomial). <br /><span class="has-inline-color has-blue-color">2.</span> Testing Affine Subspaces: Consider the task of testing whether a \(f \colon \mathcal{F}^n \to \{0,1\}\) is the indicator of an \((n-k)\)-dimensional affine space for some \(k\) (where \(\mathcal{F}\) is a finite field).<br /></p>



<p>The paper shows that the general problem — the one in which the arity of the monomial (resp the co-dimension of the subspace) is not specified has one-sided query complexity \(\widetilde{O}(1/\varepsilon)\). The same holds for testing whether the arity of the monomial is at most \(k\) (resp the co-dimension of the subspace is at most \(k\)). Finally, the exact problem which seeks to test whether the arity of the monomial is exactly \(k\) (resp the co-dimension of the space is exactly \(k\)) has query complexity \(\Omega(\log n)\). For two sided testers however, size oblivious testers are known for this problem. Thus, like the authors remark, two-sided error is inherent in the case of the exact version of the problem.</p>



<p></p>



<p><strong>Sampling Arbitrary Subgraphs Exactly Uniformly in Sublinear Time</strong> by Hendrik Fichtenberger, Mingze Gao, Pan Peng (<a href="https://arxiv.org/abs/2005.01861v2">arXiv</a>). Readers of PT Review are no strangers to the problem of counting cliques in sublinear time (with a certain query model). Building on tools from [1], in [2], Eden-Ron-Seshadhri gave the first algorithms for counting number of copies \(K_r\) in a graph \(G\) to within a \((1 \pm \varepsilon)\) multiplicative factor. En route to this result, they also gave a procedure to sample cliques incident to some special set \(S \subseteq V(G)\). The query model in [2] allowed the following queries: a u.a.r vertex query, degree query, \(i^{th}\) neighbor query and a pair query which answers whether a pair \((u,v)\) forms an edge. The work under consideration shows a result which I personally find remarkable: given the additional ability to get a u.a.r edge sample, we can do the following. For any graph \(H\) we can obtain a uniformly random subgraph isomorphic to \(H\) in \(G\). Let that sink in: this work shows that you can sample \(H\) <em>exactly uniformly</em> from the graph \(G\).  </p>



<p><strong>Finding Planted Cliques in Sublinear Time</strong> by Jay Mardia, Hilal Asi, Kabir Aladin Chandrasekher (<a href="https://arxiv.org/abs/2004.12002">arXiv</a>). Planted Clique is a time honored problem in average case complexity. This classic problem asks the following: You are given a \(G \sim \mathcal{G}(n, 1/2)\). Suppose I select a subset of \(k\) vertices in this graph and put a clique on the subgraph they induce. In principle it is possible to recover the clique I planted if \(k &gt; (2 + \varepsilon) \log n\). But it seems you get polynomial time algorithms only when \(k \geq \Omega(\sqrt n)\) even after you throw SDPs at the problem. Moreover, so far, the algorithms which recover the planted \(k\)-clique were known to take \(\widetilde{O}(n^2)\) time. This work shows that you actually get algorithms which take time \(\widetilde{O}(n^{3/2})\) if \(k \geq \Omega(\sqrt{n \log n})\). The key idea is to first obtain a “core” part of the clique of size \(O(\log n)\) in time \(\widetilde{O}(n^2/k)\). This is followed up with a clique completion routine where you mark all vertices connected to the entire core as being potentially in the clique. The paper also shows a conditional lower bound result which shows that given query access to adjacency matrix of the graph, a natural family of non-adaptive algorithms cannot recover a planted \(k\) clique in time \(o\left(\frac{n}{k}\right)^3\) (for \(k \geq \widetilde{\Omega}(\sqrt n))\).</p>



<p><strong>A robust multi-dimensional sparse Fourier transform in the continuous setting</strong> by Yaonan Jin, Daogao Liu and Zhao Song (<a href="https://arxiv.org/abs/2005.06156">arXiv</a>).  Suppose you are given an unknown signal whose Fourier Spectrum is k-sparse (that is, there are at most k dominant Fourier Coefficients and all the others are zero or close to zero). Significant research effort has been devoted to learn these signals leading to works which study this problem for multi-dimensional discrete setting and in the one-dimensional continuous case. The \(d\)-dimensional continuous case \((d = \Theta(1))\) was largely unexplored. This work makes progress on this frontier by making some natural assumptions on the unknown signal. In particular, the paper assumes that the frequencies — which are vectors \(f_i’s \in R^d\) — are well separated and satisfy \(\|f_i – f_j\|_2 \leq \eta\) and that all \({f_i}_{i \in [k]} \subseteq [-F, F]^d\) sit inside a bounded box.<br />The authors assume sample access to the signal in the sense that at any desired timestep \(\tau\), the algorithm can sample the signal’s value. With this setup, the authors show that all the dominant frequencies can be recovered with a \(O_d(k \cdot \log(F/\eta))\) samples by considering a relatively small time horizon.</p>



<p><strong>Extrapolating the profile of a finite population</strong> by Soham Jana, Yury Polyanskiy, Yihong Wu (<a href="https://arxiv.org/abs/2005.10561">arXiv</a>). Consider the following setup. You are given a universe \(k\) balls. Ball come in up to \(k\) different colors. Say you \(\theta_j\) balls in color \(j\) for each \(j \in [k]\). One of the fundamental problems in statistics considers taking samples \(m\) balls from the universe and attempts estimating “population profile” (that is, the number of balls in each color). Historically, it is known that unless an overwhelming majority of the universe has been seen, one cannot estimate the empirical distribution of colors. This paper shows that in the sublinear regime, with \(m \geq \omega(k/\log k)\), it is possible to consistently estimate the population profile in total variation. And once you have a handle on the empirical distribution of the population, you can go ahead and learn lots of interesting label invariant properties of your universe (things like entropy, number of distinct elements etc). </p>



<p></p>



<p><em>(Edit added later)</em></p>



<p><strong>Testing Positive Semi-Definiteness via Random Submatrices</strong> by Ainesh Bakshi, Nadiia Chepurko, Rajesh Jayaram (<a href="https://arxiv.org/abs/2005.06441">arXiv</a>). Suppose I give you a PSD matrix \(A \in R^{n \times n}\). You know that all of its principle submatrices are also PSD. What if \(A\) was \(\varepsilon\)-far from the PSD cone (in a sense I will define soon)? What can you say about the eigenvalues of principle submatrices of \(A\) now? In this paper, the authors tackle precisely this question. The paper defines a matrix \(A\) to be \(\varepsilon\)-far in \(\ell_2^2\) distance from the PSD Cone if you have that \(\min_{B \geq 0: B \in R^{n \times n}}\|A – B\|_F^2 \geq \varepsilon n^2\). You are allowed to randomly sample a bunch of principle submatrices (of order roughly \(O(1/\varepsilon)\) by \(O(1/\varepsilon)\) and check if they are PSD. Armed with this setup, the paper gives a non-adaptive one sided tester for this problem which makes \(\widetilde{O}(1/\varepsilon^4)\) queries. The paper also supplements this result with a lower bound of \(\widetilde{\Omega}(1/\varepsilon^2)\) queries.</p>



<p>If I missed something, please let me know. This is my first post on PT Review and I might have botched up a few things.</p>



<p><strong>References</strong></p>



<p>[1] Talya Eden, Amit Levi, Dana Ron and C. Seshadhri. Approximately Counting Triangles in Sublinear Time. <em>56th Annual Symposium on Foundations of Computer Science, 2015</em></p>



<p>[2] Talya Eden, Dana Ron and C. Seshadhri. On approximating the number of k-cliques in sublinear time. Proceedings of the <em>50th Annual ACM SIGACT Symposium on Theory of Computing 2018</em>.</p></div>







<p class="date">
by akumar <a href="https://ptreview.sublinear.info/?p=1315"><span class="datestr">at June 07, 2020 10:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17136">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/06/07/the-doomsday-argument-in-chess/">The Doomsday Argument in Chess</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Framing a controversial conversation piece as a conservation law</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/07/the-doomsday-argument-in-chess/jrichardgottsnip/" rel="attachment wp-att-17138"><img width="173" alt="" src="https://rjlipton.files.wordpress.com/2020/06/jrichardgottsnip.jpg?w=173&amp;h=190" class="alignright wp-image-17138" height="190" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Snip from <em>Closer to Truth</em> <a href="https://www.youtube.com/watch?v=Qlrj4iE7FA4">video</a> on DA</font></td>
</tr>
</tbody>
</table>
<p>
John Gott III is an emeritus professor of astrophysical sciences at Princeton. He was one of several independent inventors of the controversial <a href="https://en.wikipedia.org/wiki/Doomsday_argument">Doomsday</a> <a href="http://www.anthropic-principle.com/?q=anthropic_principle/doomsday_argument">Argument</a> (DA). He may have been the first to think of it but the last to expound it in a <a href="https://www.nature.com/articles/363315a0.epdf">paper</a> or presentation.</p>
<p>
Today we expound DA as a defense against thought experiments that require unreasonable lengths of time.</p>
<p>
Gott thought of the argument when he saw the Berlin Wall as a 22-year-old touring Berlin in 1969. He reasoned that his visit was a uniformly random event in the lifetime <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> of the wall. That assumption gave him a 75% likelihood that he was not observing the wall in the first quarter of its lifetime. Since the wall was then 8 years old, that became a 75% likelihood that the wall would not last beyond 1993. It came down in late 1989.</p>
<p>
The “Doomsday” name comes when one’s birthdate <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is regarded as a uniformly random sample from the sequence of all human births. If you are my age, <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is probably <a href="https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=F7CF2C002ED22C17F221BE1788C43A6E?doi=10.1.1.49.5899&amp;rep=rep1&amp;type=pdf">closer</a> to ordinal 60 billion than 70 or 100 billion. We can then say we are 95% confident that we are not in the initial 5% of this sequence. That <em>entails</em> the sequence stopping before 1.2 trillion births. If our population levels off at 10 billion with 80 years’ life expectancy, that makes <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> extend no further than the year 12,000 AD. The upshot is that a longer <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> entails asserting that our random sample gave a point unusually <em>early</em> in the span. The purer form of DA also argues that <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is not unusually <em>late</em>, giving this picture:</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/07/the-doomsday-argument-in-chess/doom/" rel="attachment wp-att-17140"><img width="290" alt="" src="https://rjlipton.files.wordpress.com/2020/06/doom.png?w=290&amp;h=120" class="aligncenter wp-image-17140" height="120" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Modified from Michael Stock <a href="https://michielstock.github.io/doomsday/">source</a></font>
</td>
</tr>
</tbody></table>
<p>This doubles the span of <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> allowed with 95% confidence while giving reason—at the time <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> occurs—to believe that the end is not imminent: at least about 1.75 billion more births will come after <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. For <img src="https://s0.wp.com/latex.php?latex=%7Bx+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x =}" class="latex" title="{x =}" /> my birth, however, this is already a given.</p>
<p>
</p><p></p><h2> Debating DA </h2><p></p>
<p></p><p>
The dependence on which observer is taken as the reference point <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is one shiftable parameter of the DA. If you are a preteen reader, then your own birth may be closer to ordinal 70 billion in the sequence, which becomes <em>your</em> reference point. You can then tack on another 2,000 years to <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" />. The earliest human cave painters may have been among the first 3 billion <em>Homo sapiens</em>. With regard to their reference point, <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> has already gone past their 95% limit. </p>
<p>
A more fundamental rebuff to DA comes from the equal reasonableness of an alternate uniformity assumption: that you are a uniformly random element of the set <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> of all <em>possible</em> human beings. Only a subset <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> will ever be born. The longer <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> is, the higher was your prior probability of belonging to <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />. Thus the fact of your birth can be construed as weighting the odds toward longer <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> in a way that cancels out the short-<img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> reasoning of DA.</p>
<p>
Even when an instance of DA passes these objections, the inference remains controversial. We <a href="https://rjlipton.wordpress.com/2019/12/22/predicting-when-pnp-is-resolved/">wrote</a> about DA last year in connection with estimating the lifespan of open problems remaining open. A clear <em>non</em>-instance is trying to apply DA to estimate the lifespan of the Covid-19 pandemic. We have all been going through the span together and <em>now</em> is not a uniformly random sample. </p>
<p>
The DA assumptions would however hold if an alien tourist with no prior knowledge of events dropped in on Earth today. The delicacy of the assumptions makes it significant to seek scenarios where DA firmly applies—and better, where the inference may be deemed <em>necessary</em> to preserve the validity of established modes of inference against extreme skeptical hypotheses. This is what we will try argue in regard to inferences of cheating at chess. </p>
<p>
</p><p></p><h2> The 1-in-100,000 Question </h2><p></p>
<p></p><p>
We have <a href="https://rjlipton.wordpress.com/2014/06/18/the-problem-of-catching-chess-cheaters/">posted</a> <a href="https://rjlipton.wordpress.com/2013/09/17/littlewoods-law/">numerous</a> <a href="https://rjlipton.wordpress.com/2013/01/13/the-crown-game-affair/">times</a> <a href="https://rjlipton.wordpress.com/2013/07/27/thirteen-sigma/">about</a> my statistical <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">chess</a> <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">model</a>, its giving judgments of odds against null hypotheses of fair play in the form of <a href="https://en.wikipedia.org/wiki/Standard_score"><em>z</em>-scores</a>, and my <a href="https://rjlipton.wordpress.com/2011/10/12/empirical-humility/">means</a> of <a href="https://rjlipton.wordpress.com/2019/08/20/our-trip-to-monte-carlo/">validating</a> them. We will suppose for this argument that the modeling is true in the sense that the distribution of <em>z</em>-scores from testing honest players conforms to the standard normal distribution. </p>
<p>
Now let us talk about chess in the years B.C.—before Covid—when the game was played over-the-board (OTB) in-person across a table. Suppose I obtained a <em>z</em>-score of 4.265 from a test of one player in one tournament. I have chosen this number for all of the following reasons:</p>
<ul>
<li>
It corresponds to what I call “face-value odds” of 100,000-to-1 against the null hypothesis, as one can see from <a href="https://www.fourmilab.ch/rpkp/experiments/analysis/zCalc.html">this</a> or any similar calculator. <p></p>
</li><li>
It is close to my number from an actual case in the year 1 B.C., that is, last year. <p></p>
</li><li>
It is also typical of <em>z</em>-scores I have been obtaining these past three months since chess went online, at the point where certain online platforms have made their own decisions to impose sanctions. Here I must add that the platforms’ cheating detection systems avail much information about the manner of play that often furnishes much greater statistical evidence, whereas my minimalist model uses only the record of the moves played in the games.
</li></ul>
<p>
Suppose there were no other relevant information about the case. How would one assess the significance of the <em>z</em>-score of 4.265? Here are two different ways of reasoning that—in the case of OTB chess—arrive at similar answers:</p>
<ol>
<li>
The Bayesian prior probability of cheating in OTB chess has been estimated between 1-in-10,000 and 1-in-5,000. Suppose the former, and consider a thought experiment in which 100,000 players are tested. For simplicity, let’s suppose all true instances—that is, cheating players—give above 4.265. We expect there to be ten of them, plus one <em>natural</em> occurrence of 4.265 or more. Thus the odds that our score represents a true positive are only 10-in-11. This is well short of the odds range usually needed to meet the standard of <em>comfortable satisfaction</em> used for example by the Court of Arbitration for Sport. Thus the 4.265 datum alone should not be sufficient grounds for sanction. <p></p>
</li><li>
Suppose there were a policy of sanction above a threshold of 4.25. The sum of playing fields in events held under auspices of the International Chess Federation (FIDE) each year exceeds 100,000. Thus we would expect to find at least one <em>z</em>-score over 4.265 per year by natural chance, whose sanctioning would be a serious human-rights error. FIDE cannot afford a rate of one such error per year. Thus it is insufficient for sanction.
</li></ol>
<p>
A 5.0 standard, however, gives a natural frequency of just over 1-in-3.5 million. The resulting error rate of once in 20-to-30 years might be acceptable in prospect. And the Bayesian argument based on a 0.0001 prior leaves about 350-to-1 odds against the null hypothesis, which is comfortably within the comfortable-satisfaction range as it has been applied. </p>
<p>
FIDE nevertheless has maintained a policy that statistical evidence must be accompanied by some other kind of evidence. If a player is caught looking at a chess position in a bathroom, or found to have a buzzing device or wires on his-or-her person, or signaling behavior is observed, then in fact much lower <em>z</em>-scores (to a threshold of 2.50, about 160-to-1 odds, in current FIDE regulations) are deemed to lend strong support to such evidence. </p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/07/the-doomsday-argument-in-chess/cheat/" rel="attachment wp-att-17142"><img width="240" alt="" src="https://rjlipton.files.wordpress.com/2020/06/cheat.png?w=240&amp;h=180" class="aligncenter wp-image-17142" height="180" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">2015 Peter Doggers/Chess.com <a href="https://www.chess.com/news/view/amateur-player-caught-cheating-at-tournament-in-new-delhi-7004?page=5">source</a></font>
</td>
</tr>
</tbody></table>
<p>
I posted a similar <a href="https://cse.buffalo.edu/~regan/chess/fidelity/Golfers.html">rationale</a> on my own website in early 2012, where causal evidence is likened to the “black spot” in the novel <em>Treasure Island</em>.</p>
<p>
</p><p></p><h2> One More Datum </h2><p></p>
<p></p><p>
Now, however, suppose we have the 4.265 and one more piece of “evidence” that is pertinent but not as clearly causal. It could be:</p>
<ul>
<li>
The player wore a hat that covers the ears, or <p></p>
</li><li>
An unusually bulky sweater (worn on a hot day), or <p></p>
</li><li>
Unusual gestures or movements during the games.
</li></ul>
<p>
Say a search of the player turned up nothing, but this occurred after the sequence of games giving the 4.265, a day after the player had been put on notice of suspicion. So the extra information is not a black spot but instead a “grey spot.” What can we conclude now?</p>
<p>
The Bayesian argument seems to depend on judging how this information affects the prior probability of cheating. Does it make cheating a more likely hypothesis? We don’t actually know. Whereas the 1-in-10,000 global prior estimate was based on knowing dozens of <a href="https://en.wikipedia.org/wiki/Cheating_in_chess#Incidents">cases</a> over the past decade, only a handful conformed to this level of indication—short of more obvious things like making frequent visits to the restroom or being seen with an ear adornment. The most we can say is that the datum is not irrelevant. An example of an irrelevant datum would be if the player were wearing neon green sneakers—not bulky, no wires, just a weird green.</p>
<p>
I would like, however, to argue that the player’s membership in a smaller sample <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> that is <em>pertinent</em> enhances the significance of the <em>z</em>-score. <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> must be defined by criteria that are not only independent of my statistical analysis of the games but also pertinent so as to avoid selection bias. What is needed to quantify this enhancement is:</p>
<blockquote><p>
(a) to collect all (other) kinds of items on a par with the above—say ostentatious bracelets that could camouflage electronic indicators—and</p>
<p>(b) to establish that the frequency of players having <em>any</em> such accoutrement over the global mass of tournaments is at most, say, 1-in-100.<br />
</p></blockquote>
<p>
Now there are several equivalent ways to continue the reasoning. One is to say that since <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is “at worst” independent, the face-value odds are amplified by a factor of at least 100. The Bayesian mitigation then still leaves about 1,000-to-1 odds against the null hypothesis. Another is to say that in any given year, the natural chance of seeing the conjunction of <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> and the <em>z</em>-score is at most 1-in-100. Thus aside from the frequency of true positives, a policy of sanctioning in such cases would have a prospective error rate of once in 100 years. The conjoined error rate of that and sanctioning on 5.0 in isolation would be acceptable.</p>
<p>
A Bayesian defense attorney might still counter: Consider a thought experiment in which we test 100,000 such “bulky” players. We don’t have any new information on the prior rate of cheating by players in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />. For all we know, it is still 1-in-10,000. Thus the same terms as before will apply: our experiment will expect to have 10 cheaters in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> plus the one natural false positive, leaving the odds only 10-to-1 as before. Put another way: without knowing the import of specializing to <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> on the likelihood of cheating, you can’t reach any further conclusion.</p>
<p>
</p><p></p><h2> Doomsday to the Rescue </h2><p></p>
<p></p><p>
The nub of rejecting this counter-argument is that:</p>
<blockquote><p><b> </b> <em> Because there are only about 1,000 players in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> per year, the thought experiment of testing 100,000 players in <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> now takes 100 years. </em>
</p></blockquote>
<p>Moreover, the defense attorney is asserting that the mistaken false positive has occurred <em>unusually early</em> in this span. If this is the first year under consideration, then it is a uniformly random event in the first 1% of <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" />. By the same reasoning of DA, the odds of this are only 1-in-100. Compounded by the 10-1 odds against this particular score in the thought experiment being the false positive, we recover something near the 1,000-to-1 odds of the original reasoning.</p>
<p>
We might allow that we are not in the first year of “the cheating era” in chess. The thicket of high-profile cases with solid grounds for judgment goes back a little over 10 years. The factor from DA then goes down to 1-in-10. But this still leaves the overall odds about 100-to-1 against the null hypothesis, and that is commonly taken as an anchor point for the standard of comfortable satisfaction after all mitigating factors have been addressed. </p>
<p>
Thus I am casting the Doomsday interval argument as a defense against unreasonably long thought experiments. It restores a dimension of time that is ignored by the Bayesian objection. This dimension of time is correctly preserved in the analysis of the expected error rate from a policy of imposing sanctions under this <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />–<em>z</em> combination of circumstances.</p>
<p>
Is my line of reasoning valid? You can be the judge. If so, then it is a class of instances where DA is applied merely to <em>conserve</em> an inference of unlikelihood that was originally made by other means. This supports the validity of DA-type inference in general.</p>
<p>
</p><p></p><h2> Online Chess and the Time Warp </h2><p></p>
<p></p><p>
We are now in the third month of “the online era” in chess. Even though online platforms can process many more kinds of information than I can avail from OTB play, my work has proved highly relevant for global early indications, second opinions, and transparent explanations. Alas, the sanction rate at the new featured tournaments has been well in excess of 1%. We hope this will come down as the playing pool—which has been greatly democratized in massive online events—wises up to the reality of getting caught.</p>
<p>
What I want to discuss here is how this brave new world flips the Bayesian reasoning in a way that may come on too strong <em>for the prosecution</em>, again by its indifference to the element of time. </p>
<p>
Take the 4.265 <em>z</em>-score with a <img src="https://s0.wp.com/latex.php?latex=%7B1%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1\%}" class="latex" title="{1\%}" /> prior. The face-value odds from the <em>z</em>-score are now mitigated only to 1-in-1,000. This gives 99.9% confidence in imposing a sanction. However, the <em>rate of errors</em> would be <em>higher</em> than once-per-year because more players total have been involved per tournament. The tournaments are played at faster Rapid and Blitz paces allowing eight or more games per day, whereas classic OTB tournaments feature one game per day, sometimes two, over a span of a week to ten days. </p>
<p>
This is also set against a vastly higher global sample size. Whereas the entire historical record of OTB chess represented by the ChessBase <a href="https://shop.chessbase.com/en/products/mega_database_2020?ref=RF32-OET9DCF5AK&amp;gclid=EAIaIQobChMIu9P-4-_u6QIVGqSzCh0QQQsyEAAYASAAEgKcevD_BwE">Mega</a> database has yet to hit the 10 million games mark, the online platform <a href="https://lichess.org/">Lichess</a> has now hit 75 million games played <a href="https://database.lichess.org/">per month</a>. Adding in <a href="https://en.wikipedia.org/wiki/Internet_Chess_Club">ICC</a> and <a href="https://www.chess.com/home">chess.com</a> and ChessBase’s and FIDE’s own servers yields an equation that recalls <a href="https://biblehub.com/psalms/90-4.htm">Ps 90:4</a> and <a href="https://biblehub.com/2_peter/3-8.htm">2 Peter 3:8</a>:</p>
<blockquote><p><b> </b> <em> A thousand years of OTB are but a day that passes online. </em>
</p></blockquote>
<p>
For online platforms in isolation, absent anything to distinguish one player’s set of games from any other’s (such as their belonging to a highest-profile tournament), this means that even a 5.0 standard is inadequate for sure judgment. At their volume, online sites can see deviations of by natural chance more than once per day. Thus they either tolerate a higher rate of errors or adopt a standard so high as to let many more guilty <a href="https://en.bab.la/dictionary/french-english/partie-d-echecs">parties</a> through the sieve. </p>
<p>
Such volume means all the more that one should hold a score of 4.265 as insufficient for judgment. This is despite the vastly higher Bayesian likelihood that a sanction based on that score is correct. The greater frequency of actual cheating does mean that the rate of error per positive reading declines, but the rate per absolute time, with regard to the fixed population of honest players, may matter more. This has accompanied deliberations of whether sanctions for online cheating must be given less permanent consequences in order to allow setting thresholds so that a high percentage of actual cheaters are flagged and the error rate can be tolerated.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Does this analysis square with you? Does it help in understanding controversies over the original Doomsday Argument’s paradigm?</p>
<p>
For another pass over the argument, suppose I get a <em>z</em>-score of 4.265 in a narrowly-defined event such as one country’s championship league. Does that limit the sample size, so that the score is more dispositive? The kind of reasoning in point (b) above, where we had to gather all possible indicators that would lead us to constrain the sample, would however mandate widening it at least to include other countries’ leagues. This is an aspect of the “look elsewhere” <a href="https://en.wikipedia.org/wiki/Look-elsewhere_effect">effect</a> where the space of potential tests is widened even before actual tests are considered. Possibly it should be widened to include all tournaments with similar levels of players, in which case we are back to the “square 1” of the 1-in-100,000 section of this post. The point of the analysis of the extra datum about the player is that the sample expansion has an effective pre-defined limit.</p>
<p></p><p><br />
[Added note about online cheating detection to third bullet in section 3.  Clarified: “… the conjunction of these two factors” –&gt; “… the conjunction of B and the z-score” and changed the succeeding sentence.]</p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/06/07/the-doomsday-argument-in-chess/"><span class="datestr">at June 07, 2020 07:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/086">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/086">TR20-086 |  A Survey on Approximation in Parameterized Complexity: Hardness and Algorithms | 

	Andreas Feldmann, 

	Karthik  C. S., 

	Euiwoong Lee, 

	Pasin Manurangsi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Parameterization and approximation are two popular ways of coping with NP-hard problems. More recently, the two have also been combined to derive many interesting results. We survey developments in the area both from the algorithmic and hardness perspectives, with emphasis on new techniques and potential future research directions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/086"><span class="datestr">at June 07, 2020 01:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-6421565733839282178">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2020/06/catcs-visioning-workshop.html">CATCS Visioning Workshop</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><span class="im">Reposting an important call -- these events have had big impact in the past!</span></div><div><span class="im">The <a style="color: #3f9291;" href="https://thmatters.wordpress.com/catcs/">CATCS</a> will be hosting a virtual <strong>“Visioning Workshop”</strong> the <strong>week of </strong></span><strong>July 20</strong> in order to identify broad research themes within theoretical computer science (TCS) that have potential for a major impact in the future. The goals are similar to the <a style="color: #3f9291;" href="https://thmatters.wordpress.com/visioning-workshop/">workshop of the same name</a> in 2008: to package these themes in a way that can be consumed <span class="im">by the general public, which we would deliver primarily to the Computing Community Consortium and others (e.g. funding agencies) to help them advocate for TCS.</span></div><div>While participation in the workshop is primarily through invitation, we have a few slots available for the broader community. If you are interested in participating, please see details of the application process below. The workshop will be organized according to area-wise breakout groups. Each breakout group will have 1-2 leads. Breakout groups will meet for 4-5 hours spread across several days and will be tasked with brainstorming ideas and preparing materials related to their topic. Leads are further expected to participate in plenary sessions held on Monday July 20 and Friday July 24 (4-5 hrs of additional time) where these materials will be discussed.</div><div>If you are interested in participating in the workshop, please fill out <a style="color: #3f9291;" href="https://forms.gle/cdCTsLfUs56CDhKS9">this Google form</a> by <strong>Monday June 15</strong>. On this form, applicants are asked to contribute one or two <span class="im">major results in the last 10 years whose significance can be explained in layperson terms, and one or two major challenges for theory whose significance can be explained in layperson terms. These descriptions </span>can be very brief. We will just use them to select participants and create breakout groups.</div></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2020/06/catcs-visioning-workshop.html"><span class="datestr">at June 06, 2020 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4839">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4839">Jonathan Dowling (1955-2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<figure class="wp-block-image"><img src="http://phys.lsu.edu/~jdowling/index_files/Dowling.jpg" alt="" /></figure>



<p>Today I woke up to the sad and shocking news that Jon Dowling (<a href="http://phys.lsu.edu/~jdowling/">homepage</a> / <a href="https://twitter.com/jpdowling?lang=en">Twitter</a> / <a href="https://en.wikipedia.org/wiki/Jonathan_Dowling">Wikipedia</a>)—physics professor at Louisiana State, guy who got the US government to invest in quantum computing back in the 90s, author of the popular book <a href="https://www.amazon.com/Schr%C3%B6dingers-Killer-App-Jonathan-Dowling/dp/1439896739">Schrödinger’s Killer App: Race to Build the World’s First Quantum Computer</a>, investigator of BosonSampling among many other topics, owner of a “QUBIT” license plate, and one of my main competitors in the field of quantum computing humor—has passed away at age 65, apparently due to an aortic aneurysm.</p>



<p>Three months ago, right before covid shut down the world, the <em>last</em> travel I did was a seven-hour road trip from Austin to Baton Rouge, together with my postdoc <a href="https://twitter.com/a_rocchetto?lang=en">Andrea Rocchetto</a>, to deliver something called the <a href="https://calendar.lsu.edu/event/the_hearne_eminent_lecture_with_scott_aaronson#.Xtv1HDpKg2w">Hearne Lecture</a> at the Louisiana State physics department.  My topic (unsurprisingly) was Google’s quantum supremacy experiment.</p>



<p>I’d debated whether to cancel the trip, as flying already seemed too dangerous.  Dowling was the one who said “why not just drive here with one of your postdocs?”—which turned into a memorable experience for me and Andrea, complete with a personal tour of <a href="https://en.wikipedia.org/wiki/LIGO">LIGO</a> and a visit to an alligator hatchery.  I had no inkling that it was the last time I’d ever see Jon Dowling, but am now super-glad that we made the visit.</p>



<p>At the dinner after my talk, Dowling was exactly the same as every other time I’d seen him: loud, piss-drunk, obnoxious, and hilarious.  He dominated the conversation with stories and jokes, referring in every other sentence either to his Irishness or my Jewishness.  His efforts to banter with the waitress, to elicit her deepest opinions about each appetizer and bottle of wine, were so over-the-top that I, sitting next to him, blushed, as if to say, “hey, I’m just the visitor here!  I don’t necessarily <em>endorse</em> this routine!”</p>



<p>But Dowling got away with it because, no matter how many taboos he violated per sentence, there was never any hint of malice in it.  He was an equal-opportunity offender, with his favorite target being himself.  He loved to talk, for example, about my pathological obsession with airy-fairy abstractions, like some kind of “polynomial hierarchy” that hopefully wouldn’t “collapse”—with the punchline being that he, the hardheaded laser physicist, then needed to learn what that meant for his own research.</p>



<p>The quantum computing community of the southern US, not to mention of Twitter and Facebook, and indeed of the entire world, will be poorer without this inimitable, louder-than-life presence.</p>



<p>Feel free to share your own Dowling stories in the comments.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4839"><span class="datestr">at June 06, 2020 08:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=441">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/06/06/tcs-talk-wednesday-june-10-cliff-stein-columbia-university/">TCS+ talk: Wednesday, June 10 — Cliff Stein, Columbia University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><b>In solidarity with the current protests in the United States (<a href="https://www.shutdownstem.com/" rel="nofollow">https://www.shutdownstem.com/</a>), our speaker asked that the talk this coming Wednesday be postponed.</b></p>
<p><strong>Cliff’s talk has been rescheduled to <span style="color: #ff0000;">Thursday, June 18th</span>; we will keep you updated in case of any further change. We would also take this opportunity to <a href="https://sites.google.com/site/plustcs/suggest">call the TCS community for feedback, and for suggestions and comments</a>. As a small team organizing this virtual seminar, we are continuously trying to improve and welcome your input.</strong></p>
<p>The next TCS+ talk<em> (and the last of the season!)</em> will take place this coming Wednesday, June 10th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Cliff Stein</strong> from Columbia University will speak about “<em>Parallel Approximate Undirected Shortest Paths Via Low Hop Emulators</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our<br />
website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see &gt;the website.</p>
<blockquote><p>Abstract: Although sequential algorithms with (nearly) optimal running time for finding shortest paths in undirected graphs with non-negative edge weights have been known for several decades, near-optimal parallel algorithms have turned out to be a much tougher challenge. In this talk, we present a <img src="https://s0.wp.com/latex.php?latex=%281%2B%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="(1+\varepsilon)" class="latex" title="(1+\varepsilon)" />-approximate parallel algorithm for computing shortest paths in undirected graphs, achieving polylog depth and near-linear work. All prior <img src="https://s0.wp.com/latex.php?latex=%281%2B%5Cvarepsilon%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="(1+\varepsilon)" class="latex" title="(1+\varepsilon)" />-algorithms with polylog depth perform at least superlinear work. Improving this long-standing upper bound obtained by Cohen (STOC’94) has been open for 25 years.</p>
<p>Our algorithm uses several new tools. Prior work uses hopsets to introduce shortcuts in the graph. We introduce a new notion that we call low hop emulators. We also introduce compressible preconditioners, which we use in conjunction with Serman’s framework (SODA ’17) for the uncapacitated minimum cost flow problem.</p>
<p>Joint work with Alex Andoni and Peilin Zhong.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/06/06/tcs-talk-wednesday-june-10-cliff-stein-columbia-university/"><span class="datestr">at June 06, 2020 06:16 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7750">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/06/06/tcs-visioning-workshop/">TCS visioning workshop</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>[From Jelani Nelson and David Woodruff. This workshop can be very important to ensure TCS is represented in what is likely to be a difficult funding environment in coming years. –Boaz ]</em> </p>



<p>The <a href="https://thmatters.wordpress.com/catcs/">CATCS</a> will be hosting a virtual <strong>“Visioning Workshop”</strong> the <strong>week of </strong><strong>July 20</strong> in order to identify broad research themes within theoretical computer science (TCS) that have potential for a major impact in the future. The goals are similar to the <a href="https://thmatters.wordpress.com/visioning-workshop/">workshop of the same name</a> in 2008: to package these themes in a way that can be consumed by the general public, which we would deliver primarily to the Computing Community Consortium and others (e.g. funding agencies) to help them advocate for TCS.</p>



<p>While participation in the workshop is primarily through invitation, we have a few slots available for the broader community. If you are interested in participating, please see details of the application process below. The workshop will be organized according to area-wise breakout groups. Each breakout group will have 1-2 leads. Breakout groups will meet for 4-5 hours spread across several days and will be tasked with brainstorming ideas and preparing materials related to their topic. Leads are further expected to participate in plenary sessions held on Monday July 20 and Friday July 24 (4-5 hrs of additional time) where these materials will be discussed.</p>



<p>If you are interested in participating in the workshop, please fill out <a href="https://forms.gle/cdCTsLfUs56CDhKS9">this Google form</a> by <strong>Monday June 15</strong> ( <a href="https://forms.gle/cdCTsLfUs56CDhKS9">https://forms.gle/cdCTsLfUs56CDhKS9</a> ). On this form, applicants are asked to contribute one or two major results in the last 10 years whose significance can be explained in layperson terms, and one or two major challenges for theory whose significance can be explained in layperson terms. <em>[The results need not and generally will not be your own. They just should be easy-to-explain major results in your research area–Boaz] </em>These descriptions can be very brief. We will just use them to select participants and create breakout groups.</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/06/06/tcs-visioning-workshop/"><span class="datestr">at June 06, 2020 05:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-25562705.post-4113531432946112122">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/roth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://aaronsadventures.blogspot.com/2020/06/tcs-visioning-workshop-call-for.html">TCS Visioning Workshop — Call for Participation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Reposting from here: <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/</a><br /><br /><div><div style="line-height: 22px; padding: 0px 0px 20px;"><span class="im">The <a style="color: #3f9291;" href="https://thmatters.wordpress.com/catcs/">CATCS</a> will be hosting a virtual <strong>“Visioning Workshop”</strong> the <strong>week of </strong></span><strong>July 20</strong> in order to identify broad research themes within theoretical computer science (TCS) that have potential for a major impact in the future. The goals are similar to the <a style="color: #3f9291;" href="https://thmatters.wordpress.com/visioning-workshop/">workshop of the same name</a> in 2008: to package these themes in a way that can be consumed <span class="im">by the general public, which we would deliver primarily to the Computing Community Consortium and others (e.g. funding agencies) to help them advocate for TCS.</span></div><div style="line-height: 22px; padding: 0px 0px 20px;">While participation in the workshop is primarily through invitation, we have a few slots available for the broader community. If you are interested in participating, please see details of the application process below. The workshop will be organized according to area-wise breakout groups. Each breakout group will have 1-2 leads. Breakout groups will meet for 4-5 hours spread across several days and will be tasked with brainstorming ideas and preparing materials related to their topic. Leads are further expected to participate in plenary sessions held on Monday July 20 and Friday July 24 (4-5 hrs of additional time) where these materials will be discussed.</div><div style="line-height: 22px; padding: 0px 0px 20px;">If you are interested in participating in the workshop, please fill out <a style="color: #3f9291;" href="https://forms.gle/cdCTsLfUs56CDhKS9">this Google form</a> by <strong>Monday June 15</strong>. On this form, applicants are asked to contribute one or two <span class="im">major results in the last 10 years whose significance can be explained in layperson terms, and one or two major challenges for theory whose significance can be explained in layperson terms. These descriptions </span>can be very brief. We will just use them to select participants and create breakout groups.</div></div><div></div><div><br /></div></div>







<p class="date">
by Aaron (noreply@blogger.com) <a href="http://aaronsadventures.blogspot.com/2020/06/tcs-visioning-workshop-call-for.html"><span class="datestr">at June 05, 2020 10:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1312">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">TCS Visioning Workshop — Call for Participation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div>
<p><span class="im">The <a href="https://thmatters.wordpress.com/catcs/">CATCS</a> will be hosting a virtual <strong>“Visioning Workshop”</strong> the <strong>week of </strong></span><strong>July 20</strong> in order to identify broad research themes within theoretical computer science (TCS) that have potential for a major impact in the future. The goals are similar to the <a href="https://thmatters.wordpress.com/visioning-workshop/">workshop of the same name</a> in 2008: to package these themes in a way that can be consumed <span class="im">by the general public, which we would deliver primarily to the Computing Community Consortium and others (e.g. funding agencies) to help them advocate for TCS.</span></p>
<p>While participation in the workshop is primarily through invitation, we have a few slots available for the broader community. If you are interested in participating, please see details of the application process below. The workshop will be organized according to area-wise breakout groups. Each breakout group will have 1-2 leads. Breakout groups will meet for 4-5 hours spread across several days and will be tasked with brainstorming ideas and preparing materials related to their topic. Leads are further expected to participate in plenary sessions held on Monday July 20 and Friday July 24 (4-5 hrs of additional time) where these materials will be discussed.</p>
<p>If you are interested in participating in the workshop, please fill out <a href="https://forms.gle/cdCTsLfUs56CDhKS9">this Google form</a> by <strong>Monday June 15</strong>. On this form, applicants are asked to contribute one or two <span class="im">major results in the last 10 years whose significance can be explained in layperson terms, and one or two major challenges for theory whose significance can be explained in layperson terms. These descriptions </span>can be very brief. We will just use them to select participants and create breakout groups.</p>
</div>
<div></div>
<div>(If the embedded link doesn’t work, paste this URL in your browser: <a href="https://forms.gle/cdCTsLfUs56CDhKS9" rel="nofollow">https://forms.gle/cdCTsLfUs56CDhKS9</a>.)</div></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/"><span class="datestr">at June 05, 2020 06:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/085">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/085">TR20-085 |  Neural Networks with Small Weights and Depth-Separation Barriers | 

	Gal Vardi, 

	Ohad Shamir</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In studying the expressiveness of neural networks, an important question is whether there are functions which can only be approximated by sufficiently deep networks, assuming their size is bounded. However, for constant depths, existing results are limited to depths $2$ and $3$, and achieving results for higher depths has been an important open question. In this paper, we focus on feedforward ReLU networks, and prove fundamental barriers to proving such results beyond depth $4$, by reduction to open problems and natural-proof barriers in circuit complexity. To show this, we study a seemingly unrelated problem of independent interest: Namely, whether there are polynomially-bounded functions which require super-polynomial weights in order to approximate with constant-depth neural networks. We provide a negative and constructive answer to that question, by showing that if a function can be approximated by a polynomially-sized, constant depth $k$ network with arbitrarily large weights, it can also be approximated by a polynomially-sized, depth $3k+3$ network, whose weights are polynomially bounded.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/085"><span class="datestr">at June 05, 2020 12:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17119">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/06/04/the-truth/">The Truth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>What is the truth?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/04/the-truth/whead/" rel="attachment wp-att-17122"><img width="160" alt="" class="alignright wp-image-17122" src="https://rjlipton.files.wordpress.com/2020/06/whead.jpg?w=160" /></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Alfred Whitehead was a logician and philosopher, who had a student of some note. The student was Bertrand Russell and together they wrote the famous three-volume <a href="https://en.wikipedia.org/wiki/Principia_Mathematica">Principia Mathematica</a>. It took several hundred pages to get to the result that <img src="https://s0.wp.com/latex.php?latex=%7B1%2B1%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1+1=2}" class="latex" title="{1+1=2}" />.</p>
<p><a href="https://rjlipton.wordpress.com/2020/06/04/the-truth/pm/" rel="attachment wp-att-17124"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/06/pm.png?w=300&amp;h=125" class="aligncenter size-medium wp-image-17124" height="125" /></a></p>
<p>
Amazing. </p>
<p>
Today I thought that discussing truth might be an interesting topic.<br />
<span id="more-17119"></span></p>
<p>
Whitehead said: </p>
<blockquote><p><b> </b> <em> There are no whole truths; all truths are half-truths. It is trying to treat them as whole truths that plays the devil. </em>
</p></blockquote>
<p></p><p>
I like this quote. Whitehead was not the best lecturer, however. He gave the prestigious <a href="https://en.wikipedia.org/wiki/Gifford_lectures">Gifford lectures</a> a year after the astronomer Arthur Eddington. As Wikipedia <a href="https://en.wikipedia.org/wiki/Alfred_North_Whitehead">relates</a> quoting Victor Lowe: </p>
<blockquote><p><b> </b> <em> Eddington was a marvellous popular lecturer who had enthralled an audience of 600 for his entire course. The same audience turned up to Whitehead’s first lecture but it was completely unintelligible, not merely to the world at large but to the elect. My father remarked to me afterwards that if he had not known Whitehead well he would have suspected that it was an imposter making it up as he went along … The audience at subsequent lectures was only about half a dozen in all. </em>
</p></blockquote>
<p>Between the pandemic and the unrest in our cities there is debate about what is the “truth”. On cable news—CNN, MSNBC, FOX—one hears statements about the truth. You can also hear statements like “the experts know” or the “model” shows that this is true. Can math shed light on these discussions? What would Whitehead say?</p>
<p>
</p><p></p><h2> What is the Truth? </h2><p></p>
<p></p><p>
Mathematical truth is the one absolute we can count on—right? Math is precise in its own way, but does it yield truth? Not so clear.</p>
<p>
Whitehead’s proof that <img src="https://s0.wp.com/latex.php?latex=%7B1%2B1%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1+1=2}" class="latex" title="{1+1=2}" /> takes 100’s of pages; it may or may not increase your confidence. Here is a short “proof” that <img src="https://s0.wp.com/latex.php?latex=%7B2%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2=1}" class="latex" title="{2=1}" />:</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/04/the-truth/proof-5/" rel="attachment wp-att-17125"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/06/proof.png?w=300&amp;h=195" class="aligncenter size-medium wp-image-17125" height="195" /></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
Math proofs are only as safe as two elements that are unavoidably social: </p>
<ol>
<li>
The care we use in applying our reasoning; and <p></p>
</li><li>
The care we use in choosing our assumptions.
</li></ol>
<p>
In the above proof snippet, one step divided by <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> which is the source of the error that <img src="https://s0.wp.com/latex.php?latex=%7B2%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2=1}" class="latex" title="{2=1}" />. A more worrisome issue is reasoning from assumptions. Wrong assumptions are a problem.</p>
<p>
</p><p></p><h2> Who are the Experts? </h2><p></p>
<p></p><p>
One definition of <a href="https://en.wikipedia.org/wiki/Expert">expert</a> is: An expert is somebody who has a broad and deep competence in terms of knowledge, skill and experience through practice and education in a particular field. </p>
<p>
More amusing definitions are: </p>
<blockquote><p><b> </b> <em> Mark Twain defined an expert as “an ordinary fellow from another town.” Will Rogers described an expert as “A man fifty miles from home with a briefcase.” Danish scientist and Nobel laureate Niels Bohr defined an expert as “A person that has made every possible mistake within his or her field.” </em>
</p></blockquote>
<p></p><p>
I find the use of the term <i>expert</i> in regard to the pandemic at best puzzling. How can anyone be an expert when the current situation is unique? The last pandemic happened over a hundred years ago. Unfortunately Twain, Rogers, and Bohr are closer to being correct. The situation we find ourselves in today does not lend itself to being an expert. At least in my non-expert opinion.</p>
<p><a href="https://rjlipton.wordpress.com/2020/06/04/the-truth/not/" rel="attachment wp-att-17131"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/06/not.jpg?w=300&amp;h=102" class="aligncenter size-medium wp-image-17131" height="102" /></a></p>
<p></p><p>
Yes there are people, for example, who are experts on various viral agents. But there is more we do not know about this agent that we do know. </p>
<ul>
<li>
Can you get the virus twice? <p></p>
</li><li>
Can children get the virus? <p></p>
</li><li>
Will a vaccine be possible? <p></p>
</li><li>
Are there long-term affects even for those who survive? <p></p>
</li><li>
And so on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" />
</li></ul>
<p>
</p><p></p><h2> Where are the Models? </h2><p></p>
<p></p><p>
Models are created by experts, so you probably guess that I am not bullish on models. There are lots of models, for example, on the projection of how many will be infected, and how many will get seriously sick, and sadly how many will succumb. These models are based on various assumptions about how the virus works. Most of these assumptions are not proved in any sense. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
I plan on saying more about truth in the future. Take care.</p>
<p></p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/06/04/the-truth/"><span class="datestr">at June 04, 2020 04:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
