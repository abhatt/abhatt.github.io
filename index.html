<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="https://cstheory.stackexchange.com/feeds/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="http status 503">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="http status 503">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" class="message" title="internal server error">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A> &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at January 06, 2019 01:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42161">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete">Is this partition problem strongly NP-complete?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Some computational problems have variants that appear to be harder. For instance, Graph Automorphism (GA) problem has quasi-polynomial time algorithm ( by Babai's Graph Isomorphism result) while the fixed-point free GA problem is NP-complete. </p>

<p><a href="https://en.wikipedia.org/wiki/Partition_problem" rel="nofollow noreferrer">Partition problem</a> is weakly NP-complete problem since it has pseudo-polynomial time algorithm. I am interested in variants that are strongly NP-complete.</p>

<p>Here is a variant of partition problem:</p>

<p>Restricted partition problem</p>

<p><strong>Input</strong>: Set <span class="math-container">$S$</span> of <span class="math-container">$2N$</span> integers, and a collection <span class="math-container">$P$</span> of pairs from <span class="math-container">$S$</span>, <span class="math-container">$0 \lt |P| \lt N$</span> </p>

<p><strong>Query</strong>: Is there a partition of <span class="math-container">$S$</span> into two equal cardinality parts <span class="math-container">$A$</span> and <span class="math-container">$S-A$</span> such that both parts have the same sum and no pair in <span class="math-container">$P$</span> has both elements in one side of the partition?</p>

<blockquote>
  <p>Is this variant of partition problem NP-complete in the strong sense? </p>
</blockquote>

<p>This was posted first on <a href="https://mathoverflow.net/questions/306039/is-this-partition-problem-strongly-np-complete">Math overflow</a> (I believe the posted answer is incorrect since the proposed dynamic programming algorithm does not take into consideration the cardinality of <span class="math-container">$P$</span>).</p></div>







<p class="date">
by Mohammad Al-Turkistany <a href="https://cstheory.stackexchange.com/questions/42161/is-this-partition-problem-strongly-np-complete"><span class="datestr">at January 06, 2019 12:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42160">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph">maximize edges minus vertices in a weighted graph</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>for a given weighted vertices and edges graph, we want to find the maximum subgraph. the maximum subgraph is made of some vertices and some edges of the given graph which sum of the edges minus sum of the vertices is maximum. what is the algorithm for this problem? or any help with the code please.</p></div>







<p class="date">
by andrew <a href="https://cstheory.stackexchange.com/questions/42160/maximize-edges-minus-vertices-in-a-weighted-graph"><span class="datestr">at January 06, 2019 11:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/003">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/003">TR19-003 |  Near-Optimal Lower Bounds on the Threshold Degree and Sign-Rank of AC^0 | 

	Alexander A. Sherstov, 

	Pei Wu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The threshold degree of a Boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is the minimum degree of a real polynomial $p$ that represents $f$ in sign: $\mathrm{sgn}\; p(x)=(-1)^{f(x)}.$ A related notion is sign-rank, defined for a Boolean matrix $F=[F_{ij}]$ as the minimum rank of a real matrix $M$ with $\mathrm{sgn}\; M_{ij}=(-1)^{F_{ij}}$.  Determining the maximum threshold degree and sign-rank achievable by constant-depth circuits ($\text{AC}^{0}$) is a well-known and extensively studied open problem, with complexity-theoretic and algorithmic applications.

We give an essentially optimal solution to this problem. For any $\epsilon&gt;0,$ we construct an $\text{AC}^{0}$ circuit in $n$ variables that has threshold degree $\Omega(n^{1-\epsilon})$ and sign-rank $\exp(\Omega(n^{1-\epsilon})),$ improving on the previous best lower bounds of $\Omega(\sqrt{n})$ and $\exp(\tilde{\Omega}(\sqrt{n}))$, respectively. Our results subsume all previous lower bounds on the threshold degree and sign-rank of $\text{AC}^{0}$ circuits of any given depth, with a strict improvement starting at depth $4$. As a corollary, we also obtain near-optimal bounds on the discrepancy, threshold weight, and threshold density of $\text{AC}^{0}$, strictly subsuming previous work on these quantities.  Our work gives some of the strongest lower bounds to date on the communication complexity of $\text{AC}^{0}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/003"><span class="datestr">at January 06, 2019 08:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/002">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/002">TR19-002 |  Complexity of Linear Operators | 

	Alexander Kulikov, 

	Ivan Mikhailin, 

	Vladimir Podolskii, 

	Andrey Mokhov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Let $A \in \{0,1\}^{n \times n}$ be a matrix with $z$ zeroes and $u$ ones and $x$ be an $n$-dimensional vector of formal variables over a semigroup $(S, \circ)$. How many semigroup operations are required to compute the linear operator $Ax$?

As we observe in this paper, this problem contains as a special case the well-known range queries problem and has a rich variety of applications in such areas as graph algorithms, functional programming, circuit complexity, and others. It is easy to compute $Ax$ using $O(u)$ semigroup operations. The main question studied in this paper is: can $Ax$ be computed using $O(z)$ semigroup operations? We prove that in general this is not possible: there exists a matrix $A \in \{0,1\}^{n \times n}$ with exactly two zeroes in every row (hence $z=2n$) whose complexity is $\Theta(n\alpha(n))$ where $\alpha(n)$ is the inverse Ackermann function. However, for the case when the semigroup is commutative, we give a constructive proof of an $O(z)$ upper bound. This implies that in commutative settings, complements of sparse matrices can be processed as efficiently as sparse matrices (though the corresponding algorithms are more involved). Note that this covers the cases of Boolean and tropical semirings that have numerous applications, e.g., in graph theory. 

As a simple application of the presented linear-size construction, we show how to multiply two $n\times n$ matrices over an arbitrary semiring in $O(n^2)$ time if one of these matrices is a 0/1-matrix with $O(n)$ zeroes (i.e., a complement of a sparse matrix).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/002"><span class="datestr">at January 06, 2019 05:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42159">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often">NuSMV - How to indicate the execution should visit some states infinitely often?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have the following kripke structure:</p>

<p><a href="https://i.stack.imgur.com/3xDPG.png" rel="nofollow noreferrer"><img src="https://i.stack.imgur.com/3xDPG.png" alt="enter image description here" /></a></p>

<p>I need my model to follow the LTL constraint that state d will be visited infinitely often:</p>

<pre><code>LTLSPEC  G F (modelState=d)
</code></pre>

<p>This constraint fails due to existence of the loop .... b-&gt;c-&gt;b-&gt;c ......  </p>

<p>Question: What would be a solution to this problem? This may be related to fair traces, but I am not very familiar with that, or how to indicate d as a fair state in NuSMV. </p>

<p>I am learning model checking on my own and I appreciate your help very much.</p></div>







<p class="date">
by Fabiana <a href="https://cstheory.stackexchange.com/questions/42159/nusmv-how-to-indicate-the-execution-should-visit-some-states-infinitely-often"><span class="datestr">at January 06, 2019 05:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42158">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems">Best polynomial-time approximation factor for NP-optimization problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Let us say that a function <span class="math-container">$f(n)$</span> is the <strong>best approximation factor</strong> for an NP-optimization problem, if both of the following hold:</p>

<ol>
<li><p>There exist a polynomial-time algorithm <span class="math-container">$A,$</span> and an integer <span class="math-container">$n_0$</span>, such that <span class="math-container">$A$</span> provides an <span class="math-container">$f(n)$</span>-approximation for the NP-optimization problem for every instance with size <span class="math-container">$n\geq n_0$</span>. (Note: the role of <span class="math-container">$n_0$</span> is merely to treat potentially deviant small instances, which might make the function "ugly.")</p></li>
<li><p>There is no polynomial-time <span class="math-container">$(1-o(1))f(n)$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p></li>
</ol>

<p>A classic example where such a best approximation is known is the SET COVER problem (for a summary and references see its Wikipedia page): the Greedy Algorithm provides an <span class="math-container">$\ln n$</span> approximation, but there is no  <span class="math-container">$(1-o(1))\ln n$</span> approximation, unless <span class="math-container">$P=NP$</span>.</p>

<p><strong>Questions:</strong></p>

<ol>
<li><p>Which are some other interesting NP-optimization problems for which a best approximation factor, along with its realizing algorithm, are known?  </p></li>
<li><p>Are there any counterexamples, i.e., NP-optimization problems, for which such a best approximation cannot exist, unless <span class="math-container">$P=NP$</span>?</p></li>
</ol></div>







<p class="date">
by Andras Farago <a href="https://cstheory.stackexchange.com/questions/42158/best-polynomial-time-approximation-factor-for-np-optimization-problems"><span class="datestr">at January 05, 2019 04:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1075">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1075">News for December 2018</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Happy near year, and best wishes to those close and \(\varepsilon\)-far! December concluded the year with 4 new preprints, spanning quite a lot of the property testing landscape:</p>



<p><strong>Testing Stability Properties in Graphical Hedonic Games</strong>, by Hendrik Fichtenberger and Anja Rey (<a href="https://arxiv.org/abs/1812.09249">arXiv</a>). The authors of this paper consider the problem of deciding whether a given <em>hedonic game</em>  possesses some “coalition stability” in a property testing framework. Namely, recall that a hedonic game is a game where players (nodes) form coalitions (subsets of nodes) based on their individual preferences and local information about the considered coalition, thus resulting in a partition of the original graph. <br /> Several notions exist to evaluate how good such a partition is, based on how “stable” the given coalitions are. This work focuses on hedonic games corresponding to bounded-degree graphs, introducing and studying the property testing question of deciding <em>(for several such notions of stability)</em> whether a given game admits a stable coalition structure, or is far from admitting such a partition.</p>



<p><strong>Spectral methods for testing cluster structure of graphs</strong>, by Sandeep Silwal and Jonathan Tidor (<a href="https://arxiv.org/abs/1812.11564">arXiv</a>). Staying among bounded-degree graphs, we turn to testing clusterability of graphs, the focus of this paper. Given an \(n\)-node graph \(G\) of degree at most \(d\) and parameters \(k, \phi\), say that \(G\) is \((k, \phi)\)-clusterable if it can be partitioned in \(k\) parts of inner conductance at least \(\phi\).<br />Analyzing properties of a random walk on \(G\), this work gives a bicriterion guarantee (\((k, \phi)\)-clusterable vs. \(\varepsilon\)-far from \((k, \phi^\ast)\)-clusterable, where \(\phi^\ast \approx \varepsilon^2\phi^2\)) for the case \(k=2\), improving on previous work by Czumaj, Peng, and Sohler’15.</p>



<p>We then switch from graphs to probability distributions with our third paper:</p>



<p><strong>Inference under Information Constraints I: Lower Bounds from Chi-Square Contraction</strong>, by Jayadev Acharya, Clément Canonne, and Himanshy Tyagi (<a href="https://arxiv.org/abs/1812.11476">arXiv</a>). <em>(Disclaimer: I’m one of the authors.)</em> In this paper, the first of an announced series of three, the authors generalize the settings of two previous works we covered <a href="https://ptreview.sublinear.info/?m=201805">here</a> and <a href="https://ptreview.sublinear.info/?m=201809">there</a> to consider the general question of distribution testing and learning when the \(n\) i.i.d. samples are distributed among \(n\) players, which each can only communicate their sample to the central algorithm by respecting some pre-specified local information constraint <em>(e.g., privacy, or noise, or communication budget)</em>. This paper develops a general lower bound framework to study such questions, with a systematic focus on the power of public vs. private randomness between the \(n\) parties, and instantiate it to obtain tight bounds in the aforementioned locally private and communication-limited settings. (Spoiler: public randomness strictly helps, but not always.)</p>



<p>Finally, after games, graphs, and distributions, our fourth paper of the month concerns testing of functions:</p>



<p><strong>Partial Function Extension with Applications to Learning and Property Testing</strong>, by Umang Bhaskar and Gunjan Kumar (<a href="https://arxiv.org/abs/1812.05821">arXiv</a>). This work focuses on a problem quite related to property testing, that of partial function extension: given as input \(n\) pairs point/value from a purported function on a domain \(X\) of size \(|X| &gt; n\), one is tasked with deciding whether there does exist (resp., with finding) a function  \(f\) on \(X\) consistent with these \(n\) values which further satisfies a specific property, such as linearity or convexity. This is indeed very reminiscent of property testing, where one gets to query these \(n\) points and must decide (approximate) consistency with such a well-behaved function. Here, the authors study the computational hardness of this partial function extension problem, specifically for properties such as subadditivity and XOS (a sub-property of subadditivity); and as corollaries obtain new property testers for the classes of subadditive and XOS functions.</p>



<p>As usual, if you know of some work we missed from last December, let us know in the comments!</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1075"><span class="datestr">at January 05, 2019 02:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42155">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1">Why can't a left-recursive, non-deterministic, or ambiguous grammar be LL(1)?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I've learned from several sources that an LL(1) grammar is:</p>

<ol>
<li>unambiguous,</li>
<li>not left-recursive,</li>
<li>and, deterministic (left-factorized).</li>
</ol>

<p>What I can't fully understand is why the above is true for any LL(1) grammar. I know the LL(1) parsing table will have multiple entries at some cells, but what I really want to get is a formal and general (not with an example) proof to the following proposition(s):</p>

<p>A left-recursive (1), non-deterministic (2), or ambiguous (3) grammar is not LL(1).</p></div>







<p class="date">
by Mr Geek <a href="https://cstheory.stackexchange.com/questions/42155/why-cant-a-left-recursive-non-deterministic-or-ambiguous-grammar-be-ll1"><span class="datestr">at January 05, 2019 01:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/001">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/001">TR19-001 |  On OBDD-based algorithms and proof systems that dynamically change order of   variables | 

	Alexander Knop, 

	Dmitry Itsykson, 

	Dmitry Sokolov, 

	Andrei Romashchenko</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://example.com/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In 2004 Atserias, Kolaitis and Vardi proposed OBDD-based propositional proof systems that prove unsatisfiability of a CNF formula by deduction of identically false OBDD from OBDDs representing clauses of the initial formula. All OBDDs in such proofs have the same order of variables. We initiate the study of OBDD based proof systems that additionally contain a rule that allows changing the order in OBDDs. At first, we consider a proof system OBDD($\land$, reordering) that uses the conjunction (join) rule and the rule that allows changing the order. We exponentially separate this proof system from OBDD($\land$) proof system that uses only the conjunction rule. We prove two exponential lower bounds on the size of OBDD($\land$, reordering) refutations of Tseitin formulas and the pigeonhole principle. The first lower bound was previously unknown even for OBDD($\land$) proofs and the second one extends the result of Tveretina et al. from OBDD($\land$) to OBDD($\land$, reordering).

In 2004 Pan and Vardi proposed an approach to the propositional satisfiability problem based on OBDDs and symbolic quantifier elimination (we denote algorithms based on this approach as OBDD($\land$, $\exists$) algorithms). An instance of the propositional satisfiability problem is considered as an existential quantified propositional formula. The algorithm chooses an order on variables and creates an ordered binary decision diagram (OBDD) $D$ that initially represents the constant $1$ function. Then the algorithm downloads to $D$ clauses of the CNF one by one, and applies to $D$ the elimination of the existential quantifier for variable $x$ if all clauses that contain $x$ are already downloaded. We augment these algorithms with the operation of reordering of variables and call the new scheme OBDD($\land$, $\exists$, reordering) algorithms. We notice that there exists an OBDD($\land$, $\exists$) algorithm that solves satisfiable and unsatisfiable Tseitin formulas in polynomial time. In contrast, we show that there exist formulas representing systems of linear equations over $\mathbb{F}_2$ that are hard for OBDD($\land$, $\exists$, reordering)  algorithms. Our hard instances are satisfiable formulas representing systems of linear equations over $\mathbb{F}_2$ that
correspond to some checksum matrices of error correcting codes.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/001"><span class="datestr">at January 05, 2019 07:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00754">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00754">Sparsification of Binary CSPs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Silvia Butti, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zivny:Stanislav.html">Stanislav Zivny</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00754">PDF</a><br /><b>Abstract: </b>A cut $\varepsilon$-sparsifier of a weighted graph $G$ is a re-weighted
subgraph of $G$ of (quasi)linear size that preserves the size of all cuts up to
a multiplicative factor of $\varepsilon$. Since their introduction by Bencz\'ur
and Karger [STOC'96], cut sparsifiers have proved extremely influential and
found various applications. Going beyond cut sparsifiers, Filtser and
Krauthgamer [SIDMA'17] gave a precise classification of which binary Boolean
CSPs are sparsifiable. In this paper, we extend their result to binary CSPs on
arbitrary finite domains.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00754"><span class="datestr">at January 05, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00718">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00718">Mergeable Dictionaries With Shifts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, Mikko Berggren Etienne, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00718">PDF</a><br /><b>Abstract: </b>We revisit the mergeable dictionaries with shift problem, where the goal is
to maintain a family of sets subject to search, split, merge, make-set, and
shift operations. The search, split, and make-set operations are the usual
well-known textbook operations. The merge operation merges two sets and the
shift operation adds or subtracts an integer from all elements in a set. Note
that unlike the join operation on standard balanced search tree structures,
such as AVL trees or 2-4 trees, the merge operation has no restriction on the
key space of the input sets and supports merging arbitrarily interleaved sets.
This problem is a key component in searching Lempel-Ziv compressed texts, in
the mergeable trees problem, and in the union-split-find problem.
</p>
<p>We present the first solution achieving O(log U) amortized time for all
operations, where {1, 2, ..., U} is the universe of the sets. This bound is
optimal when the size of the universe is polynomially bounded by the sum of the
sizes of the sets. Our solution is simple and based on a novel extension of
biased search trees.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00718"><span class="datestr">at January 05, 2019 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00717">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00717">Almost Optimal Distribution-free Junta Testing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bshouty:Nader_H=.html">Nader H. Bshouty</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00717">PDF</a><br /><b>Abstract: </b>We consider the problem of testing whether an unknown $n$-variable Boolean
function is a $k$-junta in the distribution-free property testing model, where
the distance between function is measured with respect to an arbitrary and
unknown probability distribution over $\{0,1\}^n$. Chen, Liu, Servedio, Sheng
and Xie showed that the distribution-free $k$-junta testing can be performed,
with one-sided error, by an adaptive algorithm that makes $\tilde
O(k^2)/\epsilon$ queries. In this paper, we give a simple two-sided error
adaptive algorithm that makes $\tilde O(k/\epsilon)$ queries.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00717"><span class="datestr">at January 05, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00695">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00695">The Product Knapsack Problem: Approximation and Complexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pferschy:Ulrich.html">Ulrich Pferschy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schauer:Joachim.html">Joachim Schauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thielen:Clemens.html">Clemens Thielen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00695">PDF</a><br /><b>Abstract: </b>We consider the product knapsack problem, which is the variant of the
classical 0-1 knapsack problem where the objective consists of maximizing the
product of the profits of the selected items. These profits are allowed to be
positive or negative. We show that this recently introduced variant of the
knapsack problem is weakly NP-hard and present a fully polynomial-time
approximation scheme (FPTAS) for the problem. Moreover, we analyze the
approximation quality achieved by a natural extension of the classical greedy
procedure to the product knapsack problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00695"><span class="datestr">at January 05, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00650">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00650">A Fast Sketch Method for Mining User Similarities over Fully Dynamic Graph Streams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jia:Peng.html">Peng Jia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Pinghui.html">Pinghui Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Jing.html">Jing Tao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guan:Xiaohong.html">Xiaohong Guan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00650">PDF</a><br /><b>Abstract: </b>Many real-world networks such as Twitter and YouTube are given as fully
dynamic graph streams represented as sequences of edge insertions and
deletions. (e.g., users can subscribe and unsubscribe to channels on YouTube).
Existing similarity estimation methods such as MinHash and OPH are customized
to static graphs. We observe that they are indeed sampling methods and exhibit
a sampling bias when applied to fully dynamic graph streams, which results in
large estimation errors. To solve this challenge, we develop a fast and
accurate sketch method VOS. VOS processes each edge in the graph stream of
interest with small time complexity O(1) and uses small memory space to build a
compact sketch of the dynamic graph stream over time. Based on the sketch built
on-the-fly, we develop a method to estimate user similarities over time. We
conduct extensive experiments and the experimental results demonstrate the
efficiency and efficacy of our method.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00650"><span class="datestr">at January 05, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00626">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00626">A modified greedy algorithm to improve bounds for the vertex cover number</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>R. Dharmarajan, D. Ramachandran <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00626">PDF</a><br /><b>Abstract: </b>In any attempt at designing an efficient algorithm for the minimum vertex
cover problem, obtaining good upper and lower bounds for the vertex cover
number could be crucial. In this article we present a modified greedy algorithm
of worst-case time complexity O(n3) to obtain bounds for the vertex cover
number of an input graph of order n. Using simple facts, the proposed algorithm
computes a lower bound for the vertex cover number. Then using this lower bound
it outputs a minimal vertex cover and hence gives an upper bound. The algorithm
ensures the output vertex cover is always minimal, which feature is an
improvement upon the existing greedy algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00626"><span class="datestr">at January 05, 2019 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00622">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00622">Efficient Race Detection with Futures</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Utterback:Robert.html">Robert Utterback</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agrawal:Kunal.html">Kunal Agrawal</a>, Jeremy Fineman, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:I=Ting_Angelina.html">I-Ting Angelina Lee</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00622">PDF</a><br /><b>Abstract: </b>This paper addresses the problem of provably efficient and practically good
on-the-fly determinacy race detection in task parallel programs that use
futures. Prior works determinacy race detection have mostly focused on either
task parallel programs that follow a series-parallel dependence structure or
ones with unrestricted use of futures that generate arbitrary dependences. In
this work, we consider a restricted use of futures and show that it can be race
detected more efficiently than general use of futures.
</p>
<p>Specifically, we present two algorithms: MultiBags and MultiBags+. MultiBags
targets programs that use futures in a restricted fashion and runs in time
$O(T_1 \alpha(m,n))$, where $T_1$ is the sequential running time of the
program, $\alpha$ is the inverse Ackermann's function, $m$ is the total number
of memory accesses, $n$ is the dynamic count of places at which parallelism is
created. Since $\alpha$ is a very slowly growing function (upper bounded by $4$
for all practical purposes), it can be treated as a close-to-constant overhead.
MultiBags+ an extension of MultiBags that target programs with general use of
futures. It runs in time $O((T_1+k^2)\alpha(m,n))$ where $T_1$, $\alpha$, $m$
and $n$ are defined as before, and $k$ is the number of future operations in
the computation. We implemented both algorithms and empirically demonstrate
their efficiency.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00622"><span class="datestr">at January 05, 2019 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00532">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00532">Adversarial Robustness May Be at Odds With Simplicity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakkiran:Preetum.html">Preetum Nakkiran</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00532">PDF</a><br /><b>Abstract: </b>Current techniques in machine learning are so far are unable to learn
classifiers that are robust to adversarial perturbations. However, they are
able to learn non-robust classifiers with very high accuracy, even in the
presence of random perturbations. Towards explaining this gap, we highlight the
hypothesis that $\textit{robust classification may require more complex
classifiers (i.e. more capacity) than standard classification.}$
</p>
<p>In this note, we show that this hypothesis is indeed possible, by giving
several theoretical examples of classification tasks and sets of "simple"
classifiers for which: (1) There exists a simple classifier with high standard
accuracy, and also high accuracy under random $\ell_\infty$ noise. (2) Any
simple classifier is not robust: it must have high adversarial loss with
$\ell_\infty$ perturbations. (3) Robust classification is possible, but only
with more complex classifiers (exponentially more complex, in some examples).
</p>
<p>Moreover, $\textit{there is a quantitative trade-off between robustness and
standard accuracy among simple classifiers.}$ This suggests an alternate
explanation of this phenomenon, which appears in practice: the tradeoff may
occur not because the classification task inherently requires such a tradeoff
(as in [Tsipras-Santurkar-Engstrom-Turner-Madry `18]), but because the
structure of our current classifiers imposes such a tradeoff.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00532"><span class="datestr">at January 05, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.00512">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.00512">Real-Time EEG Classification via Coresets for BCI Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Eitan Netzer, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frid:Alex.html">Alex Frid</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Dan.html">Dan Feldman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.00512">PDF</a><br /><b>Abstract: </b>A brain-computer interface (BCI) based on the motor imagery (MI) paradigm
translates one's motor intention into a control signal by classifying the
Electroencephalogram (EEG) signal of different tasks. However, most existing
systems either (i) use a high-quality algorithm to train the data off-line and
run only classification in real-time, since the off-line algorithm is too slow,
or (ii) use low-quality heuristics that are sufficiently fast for real-time
training but introduces relatively large classification error. In this work, we
propose a novel processing pipeline that allows real-time and parallel learning
of EEG signals using high-quality but possibly inefficient algorithms. This is
done by forging a link between BCI and core-sets, a technique that originated
in computational geometry for handling streaming data via data summarization.
</p>
<p>We suggest an algorithm that maintains the representation such coreset
tailored to handle the EEG signal which enables: (i) real time and continuous
computation of the Common Spatial Pattern (CSP) feature extraction method on a
coreset representation of the signal (instead on the signal itself) , (ii)
improvement of the CSP algorithm efficiency with provable guarantees by
applying CSP algorithm on the coreset, and (iii) real time addition of the data
trials (EEG data windows) to the coreset.
</p>
<p>For simplicity, we focus on the CSP algorithm, which is a classic algorithm.
Nevertheless, we expect that our coreset will be extended to other algorithms
in future papers. In the experimental results we show that our system can
indeed learn EEG signals in real-time for example a 64 channels setup with
hundreds of time samples per second. Full open source is provided to reproduce
the experiment and in the hope that it will be used and extended to more
coresets and BCI applications in the future.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.00512"><span class="datestr">at January 05, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42150">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com">Prove that if A is NP-complete and B is coNP-complete, than AxB is NP-, coNP-complete</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>AxB means cartesian product of A and B.</p>

<p>May someone help me with this? I even have no idea how to prove that AxB belongs to NP or coNP</p></div>







<p class="date">
by guest <a href="https://cstheory.stackexchange.com/questions/42150/prove-that-if-a-is-np-complete-and-b-is-conp-complete-than-axb-is-np-conp-com"><span class="datestr">at January 04, 2019 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42148">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission">Feel dissatisfied after each submission</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am a third year graduate student at a "top-20" university who works on fine-grained complexity (lots of playing with 3-SUM, OV and the usual popular hardness conjectures). I have been fairly productive over the last year or so and have 3 accepted papers and two submitted papers. All of this to say that I am a fairly experienced graduate student and what I am about to describe is not anecdotal.</p>

<p>Every submission brings me more dissatisfaction than satisfaction. Just before I start working on a problem, me and my advisor identify a list of concrete questions that need to be answered. After lots of thinking, we have some very nice non-trivial results which gives me a lot of happiness and satisfaction. As we start to write down all of the results, inevitably, there are some more interesting variants that pop up but are much harder to make progress on. After the initial euphoria point, I feel everything seems to go downhill. There are so many variants that also need to be answered, are clearly in the purview of the problem at hand but I am not able to. By the time we submit the paper, I am so dismayed that results in the paper seem almost trivial. Perhaps this is simply tunnel vision, but I can't overcome the sadness about not being able to answer peripheral questions (although these make for a terrific conclusion section).</p>

<p>This has happened every single time and I am wondering if this is a common feeling. Do other people in theory community feel the same way? I am not sure if this is an academia wide feeling. My fellow graduate students from other areas are over the moon after every submission (but this is just anecdotal).</p>

<p>Edit - I see that there is another soft-question on the front page. I apologize for adding another one. Its holiday season and (only?) after a few drinks, one starts to ponder over these things!</p></div>







<p class="date">
by karmanaut <a href="https://cstheory.stackexchange.com/questions/42148/feel-dissatisfied-after-each-submission"><span class="datestr">at January 04, 2019 05:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1474">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/">On PAC Analysis and Deep Neural Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>Guest post by <a href="http://amitdaniely.com/">Amit Daniely</a> and <a href="https://cs.stanford.edu/~rfrostig/">Roy Frostig</a>.</em></p>
<p>For years now—especially since the landmark work of <a href="https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks">Krishevsky et. al.</a>—learning deep neural networks has been a method of choice in prediction and regression tasks, especially in perceptual domains found in computer vision and natural language processing. How effective might it be for solving <em>theoretical</em> tasks?</p>
<p>Specifically, focusing on supervised learning:</p>
<blockquote><p>Can a deep neural network, paired with a stochastic gradient method, be shown to <a href="https://en.wikipedia.org/wiki/Probably_approximately_correct_learning">PAC learn</a> any interesting concept class in polynomial time?</p></blockquote>
<p>Depending on assumptions, and on one’s definition of “interesting,” present-day learning theory gives answers ranging from “no, that would solve hard problems,” to, more recently:</p>
<blockquote><p><strong>Theorem:</strong> Networks with depth between 2 and <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />,<a href="https://theorydish.blog/feed/#fn1" class="footnoteRef" id="fnref1"><sup>1</sup></a> having standard activation functions,<a href="https://theorydish.blog/feed/#fn2" class="footnoteRef" id="fnref2"><sup>2</sup></a> with weights initialized at random and trained with stochastic gradient descent, learn, in polynomial time, constant degree large margin polynomial thresholds.</p></blockquote>
<p>Learning constant-degree polynomials can also be done simply <em>with a linear predictor</em> over a polynomial embedding, or, in other words, by learning a halfspace. That said, what a linear predictor can do is also <em>essentially the state of the art</em> in PAC learning, so this result pushes neural net learning at least as far as one might hope at first. We will return to this point later, and discuss some limitations of PAC analysis once they are more apparent. In this sense, this post will turn out to be as much an overview of some PAC learning theory as it is about neural networks.</p>
<p>Naturally, there is a wide variety of theoretical perspectives on neural network analysis, especially in the past couple of years. Our goal in this post is not to survey or cover any extensive body of work, but simply to summarize our own recent line (from two papers: <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">DFS’16</a> and <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">D’17</a>), and to highlight the interaction with PAC learning.</p>
<h2 id="neural-network-learning">Neural network learning</h2>
<p>First, let’s define a learning task. To keep things simple, we’ll focus on binary classification over the boolean cube, without noise. Formally:</p>
<blockquote><p><strong>(Binary classification.)</strong> Given examples of the form <img src="https://s0.wp.com/latex.php?latex=%28x%2Ch%5E%2A%28x%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(x,h^*(x))" class="latex" title="(x,h^*(x))" />, where <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> is sampled from some unknown distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" /> on <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" />, and <img src="https://s0.wp.com/latex.php?latex=h%5E%2A%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*:\{\pm 1\}^n\to\{\pm 1\}" class="latex" title="h^*:\{\pm 1\}^n\to\{\pm 1\}" /> is some unknown function (the one that we wish to learn), find a function <img src="https://s0.wp.com/latex.php?latex=h%3A%5C%7B%5Cpm+1%5C%7D%5En%5Cto%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h:\{\pm 1\}^n\to\{\pm 1\}" class="latex" title="h:\{\pm 1\}^n\to\{\pm 1\}" /> whose error, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h%29+%3D+%5Cmathrm%7BPr%7D_%7Bx%5Csim%5Cmathcal%7BD%7D%7D+%5Cleft%28h%28x%29+%5Cne+h%5E%2A%28x%29%5Cright%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" class="latex" title="\mathrm{Err}(h) = \mathrm{Pr}_{x\sim\mathcal{D}} \left(h(x) \ne h^*(x)\right)" />, is small.</p></blockquote>
<p>Second, define a neural network <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal N" class="latex" title="\mathcal N" /> formally as a directed acyclic graph <img src="https://s0.wp.com/latex.php?latex=%28V%2C+E%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(V, E)" class="latex" title="(V, E)" /> whose vertices <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="V" class="latex" title="V" /> are called neurons. Of them, <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> are input neurons, one is an output neuron, and the rest are called hidden neurons.<a href="https://theorydish.blog/feed/#fn3" class="footnoteRef" id="fnref3"><sup>3</sup></a> A network together with a weight vector <img src="https://s0.wp.com/latex.php?latex=w+%3D+%5C%7Bw_%7Buv%7D+%3A+uv+%5Cin+E%5C%7D+%5Ccup+%5C%7Bb_v+%3A+v+%5Cin+V+%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" class="latex" title="w = \{w_{uv} : uv \in E\} \cup \{b_v : v \in V \}" /> defines a predictor <img src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" class="latex" title="h_{\mathcal N, w} : \{\pm 1\}^n \to \{\pm 1\}" /> whose prediction is computed by propagating <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> forward through the network. Concretely:</p>
<ul>
<li>For an input neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" />, <img src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{v,w}(x)" class="latex" title="h_{v,w}(x)" /> is the corresponding coordinate in <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" />.</li>
<li>For a hidden neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" />, define<img src="https://s0.wp.com/latex.php?latex=h_%7Bv%2Cw%7D%28x%29+%3D+%5Csigma%5Cleft%28+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28v%29%7D+w_%7Buv%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_v+%5Cright%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." class="latex" title="h_{v,w}(x) = \sigma\left( \sum_{u \in \mathrm{IN}(v)} w_{uv} h_{u,w}(x) + b_v \right)." />The scalar weight <img src="https://s0.wp.com/latex.php?latex=b_v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b_v" class="latex" title="b_v" /> is called a “bias.” In this post, the function <img src="https://s0.wp.com/latex.php?latex=%5Csigma+%3A+%5Cmathbb%7BR%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sigma : \mathbb{R} \to \mathbb{R}" class="latex" title="\sigma : \mathbb{R} \to \mathbb{R}" /> is the ReLU activation <img src="https://s0.wp.com/latex.php?latex=%5Csigma%28t%29+%3D+%5Cmax%5C%7Bt%2C+0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sigma(t) = \max\{t, 0\}" class="latex" title="\sigma(t) = \max\{t, 0\}" />, though others are possible as well.</li>
<li>For the output neuron <img src="https://s0.wp.com/latex.php?latex=o&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="o" class="latex" title="o" />, we drop the activation: <img src="https://s0.wp.com/latex.php?latex=h_%7Bo%2Cw%7D%28x%29+%3D+%5Csum_%7Bu+%5Cin+%5Cmathrm%7BIN%7D%28o%29%7D+w_%7Buo%7D+h_%7Bu%2Cw%7D%28x%29+%2B+b_o&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" class="latex" title="h_{o,w}(x) = \sum_{u \in \mathrm{IN}(o)} w_{uo} h_{u,w}(x) + b_o" />.</li>
</ul>
<p>Finally, let <img src="https://s0.wp.com/latex.php?latex=h_%7B%5Cmathcal+N%2C+w%7D%28x%29+%3D+h_%7Bo%2C+w%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h_{\mathcal N, w}(x) = h_{o, w}(x)" class="latex" title="h_{\mathcal N, w}(x) = h_{o, w}(x)" />. This computes a real-valued function, so where we’d like to use it for classification, we do so by thresholding, and abuse the notation <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h_w)" class="latex" title="\mathrm{Err}(h_w)" /> to mean <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28%5Cmathrm%7Bsign%7D+%5Ccirc+h_w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(\mathrm{sign} \circ h_w)" class="latex" title="\mathrm{Err}(\mathrm{sign} \circ h_w)" />.</p>
<p>Some intuition for this definition would come from verifying that:</p>
<ul>
<li>Any function <img src="https://s0.wp.com/latex.php?latex=h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h : \{\pm 1\}^n \to \{\pm 1\}" class="latex" title="h : \{\pm 1\}^n \to \{\pm 1\}" /> can be computed by a network of depth two and <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="2^n" class="latex" title="2^n" /> hidden neurons.</li>
<li>The parity function <img src="https://s0.wp.com/latex.php?latex=h%28x%29+%3D+%5Cprod_%7Bi%3D1%7D%5En+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h(x) = \prod_{i=1}^n x_i" class="latex" title="h(x) = \prod_{i=1}^n x_i" /> can be computed by a network of depth two and <img src="https://s0.wp.com/latex.php?latex=4n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="4n" class="latex" title="4n" /> hidden neurons. (NB: this one is a bit more challenging.)</li>
</ul>
<p>In practice, the network architecture (this DAG) is designed based on some domain knowledge, and its design can impact the predictor that’s later selected by SGD. One default architecture, useful in the absence of domain knowledge, is the multi-layer perceptron, comprised of layers of complete bipartite graphs:</p>
<figure><img width="431" alt="full_con_net" src="https://theorydish.files.wordpress.com/2019/01/full_con_net.png?w=431&amp;h=426" class="  wp-image-1479 aligncenter" height="426" />A toy “fully-connected neural network”, a.k.a. a multi-layer perceptronAnother paradigmatic architecture is a <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional network</a>:<p></p>
</figure>
<figure><img width="490" alt="conv_net" src="https://theorydish.files.wordpress.com/2019/01/conv_net.png?w=490&amp;h=463" class="  wp-image-1478 aligncenter" height="463" />A toy convolutional neural network</figure>
<p>Convolutional nets capture the notion of spatial input locality in signals such as images and audio.<a href="https://theorydish.blog/feed/#fn4" class="footnoteRef" id="fnref4"><sup>4</sup></a> In the toy example drawn, each clustered triple of neurons is a so-called convolution filter applied to two components below it. In image domains, convolutions filters are two-dimensional and capture responses to spatial 2-D patches of the image or of an intermediate layer.</p>
<p>Training a neural net comprises (i) initialization, and (ii) iterative optimization run until <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bsign%7D%28h_w%28x%29%29+%3D+h%5E%2A%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{sign}(h_w(x)) = h^*(x)" class="latex" title="\mathrm{sign}(h_w(x)) = h^*(x)" /> for sufficiently many examples <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" />. The initialization step sets the starting values of the weights <img src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^0" class="latex" title="w^0" /> at random:</p>
<blockquote><p><strong>(Glorot initialization.)</strong> Draw weights <img src="https://s0.wp.com/latex.php?latex=%5C%7Bw%5E0_%7Buv%7D%5C%7D_%7Buv%5Cin+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{w^0_{uv}\}_{uv\in E}" class="latex" title="\{w^0_{uv}\}_{uv\in E}" /> from centered Gaussians with variance <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathrm%7BIN%7D%28v%29%7C%5E%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="|\mathrm{IN}(v)|^{-1}" class="latex" title="|\mathrm{IN}(v)|^{-1}" /> and biases <img src="https://s0.wp.com/latex.php?latex=%5C%7Bb%5E0_%7Bv%7D%5C%7D_%7Bv%5Cin+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{b^0_{v}\}_{v\in V}" class="latex" title="\{b^0_{v}\}_{v\in V}" /> from independent standard Gaussians.<a href="https://theorydish.blog/feed/#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p></blockquote>
<p>While other initialization schemes exists, this one is canonical, simple, and, as the reader can verify, satisfies <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7Bw%5E0%7D%5Cleft%5B%28h_%7Bv%2Cw%5E0%7D%28x%29%29%5E2%5Cright%5D+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" class="latex" title="\mathbb{E}_{w^0}\left[(h_{v,w^0}(x))^2\right] = 1" /> for every neuron <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="v" class="latex" title="v" /> and input <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \in \{\pm 1\}^n" class="latex" title="x \in \{\pm 1\}^n" />.</p>
<p>The optimization step is essentially a local search method from the initial point, using <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> (SGD) or a variant thereof.<a href="https://theorydish.blog/feed/#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a> To apply SGD, we need a function suitable for descent, and we’ll use the commonplace logistic loss <img src="https://s0.wp.com/latex.php?latex=%5Cell%28z%29+%3D+%5Clog_2%281%2Be%5E%7B-z%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\ell(z) = \log_2(1+e^{-z})" class="latex" title="\ell(z) = \log_2(1+e^{-z})" />, which bounds the zero-one loss <img src="https://s0.wp.com/latex.php?latex=%5Cell%5E%7B0-1%7D%28z%29+%3D+%5Cmathbf%7B1%7D%5Bz+%5Cle+0%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" class="latex" title="\ell^{0-1}(z) = \mathbf{1}[z \le 0]" /> from above:</p>
<figure><img width="329" alt="losses" src="https://theorydish.files.wordpress.com/2019/01/losses.png?w=329&amp;h=246" class="  wp-image-1480 aligncenter" height="246" />The logistic and zero-one losses</figure>
<p> </p>
<p>Define <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D%28w%29+%3D+%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathcal+D%7D%5Cleft%5B+%5Cell%28h_w%28x%29h%5E%2A%28x%29%29+%5Cright%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" class="latex" title="L_{\mathcal D}(w) = \mathbb{E}_{x\sim\mathcal D}\left[ \ell(h_w(x)h^*(x)) \right]" />. Note that <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BErr%7D%28h_w%29+%5Cle+L_%7B%5Cmathcal+D%7D%28w%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" class="latex" title="\mathrm{Err}(h_w) \le L_{\mathcal D}(w)" />, so finding weights <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w" class="latex" title="w" /> for which the upper bound <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}" class="latex" title="L_{\mathcal D}" /> is small enough implies low error in turn. Meanwhile, <img src="https://s0.wp.com/latex.php?latex=L_%7B%5Cmathcal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{\mathcal D}" class="latex" title="L_{\mathcal D}" /> is amenable to iterative gradient-based minimization.</p>
<p>Given samples from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />, stochastic gradient descent creates an unbiased estimate of the gradient at each step <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="t" class="latex" title="t" /> by drawing a batch of i.i.d. samples <img src="https://s0.wp.com/latex.php?latex=S_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_t" class="latex" title="S_t" /> from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />. The gradient <img src="https://s0.wp.com/latex.php?latex=%5Cnabla+L_%7BS_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\nabla L_{S_t}" class="latex" title="\nabla L_{S_t}" /> at a point <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w" class="latex" title="w" /> can be computed efficiently by the <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a> algorithm.</p>
<p>In more complete detail, our prototypical neural network training algorithm is as follows. On input a network <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal N" class="latex" title="\mathcal N" />, an iteration count <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" />, a batch size <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b" class="latex" title="b" />, and a step size <img src="https://s0.wp.com/latex.php?latex=%5Ceta+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\eta &gt; 0" class="latex" title="\eta &gt; 0" />:</p>
<p><strong>Algorithm: <em>SGDNN</em></strong></p>
<ol type="1">
<li>Let <img src="https://s0.wp.com/latex.php?latex=w%5E0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^0" class="latex" title="w^0" /> be random weights sampled per Glorot initialization</li>
<li>For <img src="https://s0.wp.com/latex.php?latex=t+%3D+1%2C+%5Cldots%2C+T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="t = 1, \ldots, T" class="latex" title="t = 1, \ldots, T" />:
<ol type="1">
<li>Sample a batch <img src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D+%3D+%5C%7B%28x%5Et_1%2C+h%5E%2A%28x%5Et_1%29%29%2C+%5Cldots%2C+%28x%5Et_b%2C+h%5E%2A%28x%5Et_b%29%29%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" class="latex" title="S_{t} = \{(x^t_1, h^*(x^t_1)), \ldots, (x^t_b, h^*(x^t_b))\}" />, where <img src="https://s0.wp.com/latex.php?latex=x%5Et_1%2C+%5Cldots%2C+x%5Et_b&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x^t_1, \ldots, x^t_b" class="latex" title="x^t_1, \ldots, x^t_b" /> are i.i.d. samples from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />.</li>
<li>Update <img src="https://s0.wp.com/latex.php?latex=w%5Et+%5Cgets+w%5E%7Bt-1%7D+-+%5Ceta+%5Cnabla+L_%7BS_t%7D%28w%5E%7Bt-1%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" class="latex" title="w^t \gets w^{t-1} - \eta \nabla L_{S_t}(w^{t-1})" />, where<img src="https://s0.wp.com/latex.php?latex=L_%7BS_t%7D%28w%5E%7Bt-1%7D%29+%3D+b%5E%7B-1%7D+%5Csum_%7Bi%3D1%7D%5Eb+%5Cell%28h_%7Bw%7D%28x%5Et_i%29+h%5E%2A%28x%5Et_i%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" class="latex" title="L_{S_t}(w^{t-1}) = b^{-1} \sum_{i=1}^b \ell(h_{w}(x^t_i) h^*(x^t_i))" />.</li>
</ol>
</li>
<li>Output <img src="https://s0.wp.com/latex.php?latex=w%5ET&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w^T" class="latex" title="w^T" /></li>
</ol>
<h2 id="pac-learning">PAC learning</h2>
<p>Learning a predictor from example data is a general task, and a hard one in the worst case. We cannot efficiently (i.e. in <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{poly}(n)" class="latex" title="\mathrm{poly}(n)" /> time) compute, let alone learn, general functions from <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}^n" class="latex" title="\{\pm 1\}^n" /> to <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Cpm+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{\pm 1\}" class="latex" title="\{\pm 1\}" />. In fact, any learning algorithm that is guaranteed to succeed in general (i.e. with any target predictor <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> over any data distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />) runs, in the worst case, in time exponential in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" />. This is true even for rather weak definitions of “success,” such as finding a predictor with error less than <img src="https://s0.wp.com/latex.php?latex=1%2F2+-+2%5E%7B-n%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1/2 - 2^{-n/2}" class="latex" title="1/2 - 2^{-n/2}" />, i.e. one that slightly outperforms a random guess.</p>
<p>While it is impossible to efficiently learn general functions under general distributions, it might still be possible to learn efficiently under some assumptions on the target <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> or the distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />. Charting out such assumptions is the realm of learning theorists: by now, they’ve built up a broad catalog of function classes, and have studied the complexity of learning when the target function is in each such class. Although their primary aim has been to develop theory, the potential guidance for practice is easy to imagine: if one’s application domain happens to be modeled well by one of these easily-learnable function classes, there’s a corresponding learning algorithm to consider as well.</p>
<p>The vanilla PAC model makes no assumptions on the data distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal D" class="latex" title="\mathcal D" />, but it does assume the target <img src="https://s0.wp.com/latex.php?latex=h%5E%2A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^*" class="latex" title="h^*" /> belongs to some simple, predefined class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H" class="latex" title="\mathcal H" />. Formally, a <em>PAC learning problem</em> is defined by a function class<a href="https://theorydish.blog/feed/#fn7" class="footnoteRef" id="fnref7"><sup>7</sup></a> <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H+%5Csubset+%5C%7B%5Cpm+1%5C%7D%5E%7B%5C%7B%5Cpm+1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" class="latex" title="\mathcal H \subset \{\pm 1\}^{\{\pm 1\}^n}" />. A learning algorithm <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal A" class="latex" title="\mathcal A" /> <em>learns</em> the class <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H" class="latex" title="\mathcal H" /> if, whenever <img src="https://s0.wp.com/latex.php?latex=h%5E%2A+%5Cin+%5Cmathcal+H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h^* \in \mathcal H" class="latex" title="h^* \in \mathcal H" />, and provided <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\epsilon &gt; 0" class="latex" title="\epsilon &gt; 0" />, it runs in time <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bpoly%7D%281%2F%5Cepsilon%2C+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathrm{poly}(1/\epsilon, n)" class="latex" title="\mathrm{poly}(1/\epsilon, n)" />, and returns a function of error at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, with probability at least 0.9. Note that:</p>
<ol type="1">
<li>The learning algorithm need not return a function from the learnt class.</li>
<li>The polynomial-time requirement means in particular that the learning algorithm cannot output a complete truth table, as its size would be exponential. Instead, it must output a short description of a hypothesis that can be evaluated in polynomial time.</li>
</ol>
<p>For a taste of the computational learning theory literature, here are some of the function classes studied by theorists over the years:</p>
<ol type="1">
<li><em>Linear thresholds (halfspaces):</em> functions that map a halfspace to 1 and its complement to -1. Formally, functions of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Ctheta%28%5Clangle+w%2C+x+%5Crangle%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \theta(\langle w, x \rangle)" class="latex" title="x \mapsto \theta(\langle w, x \rangle)" /> for some <img src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5Cmathbb%7BR%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w \in \mathbb{R}^n" class="latex" title="w \in \mathbb{R}^n" />, where <img src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\theta(z) = 1" class="latex" title="\theta(z) = 1" /> when <img src="https://s0.wp.com/latex.php?latex=z+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="z &gt; 0" class="latex" title="z &gt; 0" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctheta%28z%29+%3D+-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\theta(z) = -1" class="latex" title="\theta(z) = -1" /> when <img src="https://s0.wp.com/latex.php?latex=z+%5Cle+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="z \le 0" class="latex" title="z \le 0" />.</li>
<li><em>Large-margin linear thresholds:</em> for<img src="https://s0.wp.com/latex.php?latex=%5Crho%28z%29+%3D+%5Cbegin%7Bcases%7D+1+%26+z+%5Cge+1+%5C%5C+%2A+%26+-1+%5Cle+z+%5Cle+1+%5C%5C+-1+%26+z+%5Cle+-1+%5Cend%7Bcases%7D%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," class="latex" title="\rho(z) = \begin{cases} 1 &amp; z \ge 1 \\ * &amp; -1 \le z \le 1 \\ -1 &amp; z \le -1 \end{cases}," />the class<img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%28%5Clangle+w%2Cx+%5Crangle%29+%5Ctext%7B+with+%7D+%5C%7Cw%5C%7C_2%5E2+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." class="latex" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho(\langle w,x \rangle) \text{ with } \|w\|_2^2 \le \mathrm{poly}(n) \right\}." /></li>
<li><em>Intersections of halfspaces:</em> functions that map an intersection of polynomially many halfspaces to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1" class="latex" title="1" /> and its complement to <img src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="-1" class="latex" title="-1" />.</li>
<li><em>Polynomial threshold functions:</em> thresholds of constant-degree polynomials.</li>
<li><em>Large-margin polynomial threshold functions:</em> the class</li>
</ol>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cleft%5C%7B+h+%3A+%5C%7B%5Cpm+1%5C%7D%5En+%5Cto+%5C%7B%5Cpm+1%5C%7D+%5Cmid+h%28x%29+%3D+%5Crho%5Cleft%28+%5Csum_%7BA+%5Csubset+%5Bn%5D%2C+%7CA%7C+%5Cle+O%281%29%7D+%5Calpha_A+%5Cprod_%7Bi+%5Cin+A%7D+x_i+%5Cright%29+%5C%3B%5Ctext%7B+with+%7D%5C%3B+%5Csum_%7BA%7D+%5Calpha%5E2_A+%5Cle+%5Cmathrm%7Bpoly%7D%28n%29+%5Cright%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." class="latex" title="\left\{ h : \{\pm 1\}^n \to \{\pm 1\} \mid h(x) = \rho\left( \sum_{A \subset [n], |A| \le O(1)} \alpha_A \prod_{i \in A} x_i \right) \;\text{ with }\; \sum_{A} \alpha^2_A \le \mathrm{poly}(n) \right\}." /></p>
<ol type="1">
<li><em>Decision trees</em>, <em>deterministic automata</em>, and <em><a href="https://en.wikipedia.org/wiki/Disjunctive_normal_form">DNF</a> formulas</em> of polynomial size.</li>
<li><em>Monotone conjunctions:</em> functions that, for some <img src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A \subset [n]" class="latex" title="A \subset [n]" /> map <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x" class="latex" title="x" /> to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1" class="latex" title="1" /> if <img src="https://s0.wp.com/latex.php?latex=x_i+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_i = 1" class="latex" title="x_i = 1" /> for all <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+A&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i \in A" class="latex" title="i \in A" />, and to <img src="https://s0.wp.com/latex.php?latex=-1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="-1" class="latex" title="-1" /> otherwise.</li>
<li><em>Parities:</em> functions of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cprod_%7Bi+%5Cin+A%7D+x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \prod_{i \in A} x_i" class="latex" title="x \mapsto \prod_{i \in A} x_i" /> for some <img src="https://s0.wp.com/latex.php?latex=A+%5Csubset+%5Bn%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A \subset [n]" class="latex" title="A \subset [n]" />.</li>
<li><em>Juntas:</em> functions that depend on at most <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" /> variables.</li>
</ol>
<p>Learning theorists look at these function classes and work to distinguish those that are efficiently learnable from those that are <em>hard</em> to learn. They establish hardness results by reduction from other computational problems that are conjectured to be hard, such as random XOR-SAT (though none today are conditioned outright on NP hardness); see for example <a href="https://arxiv.org/abs/1404.3378">these</a> <a href="https://arxiv.org/abs/1505.05800">two</a> results. Meanwhile, halfspaces are learnable by linear programming. Parities, or more generally, <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />-linear functions for a field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />, are learnable by Gaussian elimination. In turn, via reductions, many other classes are efficiently learnable. This includes polynomial thresholds, decision lists, and more. To give an idea of what’s known in the literature, here is an artist’s depiction of some of what’s currently known:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/classes.png?w=620" alt="classes" class=" size-full wp-image-1477 aligncenter" />Learnable and conjectured hard-to-learn function classes</figure>
<p> </p>
<p>At a high-level, the upshot from all of this—and if you take away just one thing from this quick tour of PAC—is that:</p>
<blockquote><p>Barring a small handful of exceptions, all known efficiently learnable classes can be reduced to halfspaces or <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}" class="latex" title="\mathbb{F}" />-linear functions.</p></blockquote>
<p>Or, to put it more bluntly, <strong>the state of the art in PAC-learnability is essentially linear prediction</strong>.</p>
<h2 id="pac-analyzing-neural-nets">PAC analyzing neural nets</h2>
<p>Research in algorithms and complexity often follows these steps:</p>
<ol type="1">
<li>define a computational problem,</li>
<li>design an algorithm that solves it, and then</li>
<li>establish bounds on the resource requirements of that algorithm.</li>
</ol>
<p>A bound on the algorithm’s performance forms, in turn, a bound on the <em>computational problem’s</em> inherent complexity.</p>
<p>By contrast, we have already decided on our SGDNN algorithm, and we’d like to attain some grasp on its capabilities. So we’d like to do things in a different order:</p>
<ol type="1">
<li>define an <em>algorithm</em> (done),</li>
<li>design a computational problem to which the algorithm can be applied, and then</li>
<li>establish bounds on the resource requirements of the algorithm in solving the problem.</li>
</ol>
<p>Our computational problem will be a PAC learning problem, corresponding to a function class. For SGDNN, an ambitious function class we might consider is the class of all functions realizable by the network. But if we were to follow this approach, we would run up against the same hardness results mentioned before.</p>
<p>So instead, we’ve established the theorem stated at the top of this post. That is, that SGDNN, over a range of network configurations, learns a class that we <em>already know</em> to be learnable: large margin polynomial thresholds. Restated:</p>
<blockquote><p><strong>Theorem, again:</strong> There is a choice of SGDNN step size <img src="https://s0.wp.com/latex.php?latex=%5Ceta&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\eta" class="latex" title="\eta" /> and number of steps <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" />, as well as a with parameter <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="r" class="latex" title="r" />, where <img src="https://s0.wp.com/latex.php?latex=T%2C+r+%5Cle+%5Cmathrm%7Bpoly%7D%28n%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T, r \le \mathrm{poly}(n/\epsilon)" class="latex" title="T, r \le \mathrm{poly}(n/\epsilon)" />, such that SGDNN on a multi-layer perceptron of depth between 2 and <img src="https://s0.wp.com/latex.php?latex=%5Clog%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\log(n)" class="latex" title="\log(n)" />, and of width<a href="https://theorydish.blog/feed/#fn8" class="footnoteRef" id="fnref8"><sup>8</sup></a> <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="r" class="latex" title="r" />, learns large magin polynomials.</p></blockquote>
<p>How rich are large margin polynomials? They contain disjunctions, conjunctions, DNF and <a href="https://en.wikipedia.org/wiki/Conjunctive_normal_form">CNF</a> formulas with a constant many terms, DNF and CNF formulas with a constant many literals in each term. By corollary, SGDNN can PAC learn these classes as well. And at this point, we’ve covered a considerable fraction of the function classes known to be poly-time PAC learnable by <em>any</em> method.</p>
<p>Exceptions include constant-degree polynomial thresholds with no restriction on the coefficients, decision lists, and parities. It is well known that SGDNN cannot learn parities, and in ongoing work with Vitaly Feldman, we show that SGDNN cannot learn decision lists nor constant-degree polynomial thresholds with unrestricted coefficients. So the picture becomes more clear:</p>
<figure><img src="https://theorydish.files.wordpress.com/2019/01/classes_nn.png?w=620" alt="classes_nn" class=" size-full wp-image-1476 aligncenter" />Conjectured hard-to-learn classes, known learnable classes, and those known to be learnable by SGDNN.</figure>
<p> </p>
<p>The theorem above runs SGDNN with a multi-layer perceptron. What happens if we change the network architecture? It can be shown then that SGDNN learns a qualitatively different function class. For instance, with convolutional networks, the learnable functions include certain polynomials of <em>super-constant</em> degree.</p>
<h3 id="a-word-on-the-proof">A word on the proof</h3>
<p>The path to the theorem traverses two papers. There’s a corresponding outline for the proof.</p>
<p>The first step is to show that, with high probability, the Glorot random initialization renders the network in a state where the final hidden layer (just before the output node) is rich enough to approximate all large-margin polynomial threshold functions (LMPTs). Namely, every LMPT can be approximated by the network up to some setting of the weights that enter the output neuron (all remaining weights random). The tools for this part of the proof include (i) the connection between kernels and random features, (ii) a characterization of symmetric kernels of the sphere, and (iii) a variety of properties of Hermite polynomials. It’s described in our <a href="https://papers.nips.cc/paper/6427-toward-deeper-understanding-of-neural-networks-the-power-of-initialization-and-a-dual-view-on-expressivity">2016 paper</a>.</p>
<p>An upshot of this correspondence is that if we run SGD <em>only on the top layer</em> of a network, leaving the remaining weights as they were randomly initialized, we learn LMPTs. (Remember when we said that we won’t beat what a linear predictor can do? There it is again.) The second step of the proof, then, is to show that the correspondence continues to hold even if we train all the weights. In the assumed setting (e.g. provided at most logarithmic depth, sufficient width, and so forth), what’s represented in the final hidden layer changes sufficiently slowly that, over the course of SGDNN’s iterations, it <em>remains</em> rich enough to approximate all LMPTs. The final layer does the remaining work of picking out the right LMPT. The argument is in Amit’s <a href="https://papers.nips.cc/paper/6836-sgd-learns-the-conjugate-kernel-class-of-the-network">2017 paper</a>.</p>
<h2 id="pacing-up">PACing up</h2>
<p>To what extent should we be satisfied, knowing that our algorithm of interest (SGDNN) can solve a (computationally) easy problem?</p>
<p>On the positive side, we’ve managed to say something at all about neural network training in the PAC framework. Roughly speaking, some class of non-trivially layered neural networks, trained as they typically are, learns any known learnable function class that isn’t “too sensitive.” It’s also appealing that the function classes vary across different architectures.</p>
<p>On the pessimistic side, we’re confronted to a major limitation on the “function class” perspective, prevalent in PAC analysis and elsewhere in learning theory. All of the classes that SGDNN learns, <em>under the assumptions</em> touched on in this post, are so-called large-margin classes. Large-margin classes are essentially linear predictors over a <em>fixed and data-independent</em> embedding of input examples, as alluded to before. These are inherently “shallow models.”</p>
<p>That seems rather problematic in pursuing any kind of theory for learning layered networks, where the entire working premise is that a deep network uses its hidden layers to learn a representation adapted to the example domain. Our analysis—both its goal and its proof—clash with this intuition: it works out that a “shallow model” can be learned when assumptions imply that “not too much” change takes place in hidden layers. It seems that the representation learning phenomenon is what’s interesting, yet the typical PAC approach, as well as the analysis touched on in this post, all avoid capturing it.</p>
<section class="footnotes">
<hr />
<ol>
<li id="fn1">Here <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> is the dimension of the instance space.<a href="https://theorydish.blog/feed/#fnref1"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn2">For instance, ReLU activations, of the form <img src="https://s0.wp.com/latex.php?latex=x+%5Cmapsto+%5Cmax%5C%7Bx%2C0%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x \mapsto \max\{x,0\}" class="latex" title="x \mapsto \max\{x,0\}" />.<a href="https://theorydish.blog/feed/#fnref2"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn3">Recurrent networks allow for cycles, but in this post we stick to DAGs.<a href="https://theorydish.blog/feed/#fnref3"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn4">Convolutional networks often also constrain subsets of their weights to be equal; that turns out not to bear much on this post.<a href="https://theorydish.blog/feed/#fnref4"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn5">Although not essential to the results described, it also simplifies this post to zero the weights on edges incident to the output node as part of the initialization.<a href="https://theorydish.blog/feed/#fnref5"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn6"><a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Extensions_and_variants">Variants of SGD</a> are used in practice, including algorithms used elsewhere in optimization (e.g. <a href="https://distill.pub/2017/momentum/">SGD with momentum</a>, <a href="http://www.jmlr.org/papers/v12/duchi11a.html">AdaGrad</a>) or techniques developed more specifically for neural nets (e.g. RMSprop, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="https://arxiv.org/abs/1502.03167">batch norm</a>). We’ll stick to plain SGD.<a href="https://theorydish.blog/feed/#fnref6"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn7">More accurately, a sequence of function classes <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+H_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathcal H_n" class="latex" title="\mathcal H_n" /> for <img src="https://s0.wp.com/latex.php?latex=n+%3D+1%2C+2%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n = 1, 2, \ldots" class="latex" title="n = 1, 2, \ldots" />.<a href="https://theorydish.blog/feed/#fnref7"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
<li id="fn8">The width of a multi-layer perceptron is the number of neurons in each hidden layer.<a href="https://theorydish.blog/feed/#fnref8"><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/21a9.png" alt="↩" style="height: 1em;" class="wp-smiley" /></a></li>
</ol>
</section></div>







<p class="date">
by amitdanielymailhujiacil <a href="https://theorydish.blog/2019/01/04/on-pac-analysis-and-deep-neural-networks/"><span class="datestr">at January 04, 2019 03:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42145">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications">Grid-Minor Theorem of Robertson and Seymour and its Algorithmic Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Graph-Minor Theorem of Robertson and Seymour [<a href="https://www.sciencedirect.com/science/article/pii/S0095895684710732" rel="nofollow noreferrer">1</a>] states that if graph G has large treewidth, then it contains a large grid as minor. Most approximation results on general classes of graphs with excluded minors make heavy use of Robertson and Seymour’s structure theory for graphs with excluded minors, especially when the treewidth is large (small treewidth usually makes problem to be easily solved by dynamic programming) [<a href="http://chekuri.cs.illinois.edu/talks/NIPS-Tutorial.pdf" rel="nofollow noreferrer">2</a>]. </p>

<p>However, there are some results are trying to avoid using the grid minor theorem. For example, Chekuri and Chuzhoy [<a href="https://arxiv.org/abs/1304.1577" rel="nofollow noreferrer">3</a>] show a framework for using theorems to bypass the well-known Grid-Minor Theorem of Robertson and Seymour in some applications. In particular, this leads to substantially improved parameters in some Erdos-Posa-type results, and faster running times for algorithms for some fi�xed parameter tractable problems.</p>

<p>Do you know any other examples of problems with large treewidth avoid using the grid minor theorem? </p></div>







<p class="date">
by Rupei Xu <a href="https://cstheory.stackexchange.com/questions/42145/grid-minor-theorem-of-robertson-and-seymour-and-its-algorithmic-applications"><span class="datestr">at January 04, 2019 09:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42144">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42144/maximum-weight-independent-set-on-a-changing-graph">Maximum Weight Independent Set on a Changing Graph?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Suppose I have an optimal solution to the maximum weight independent/stable set problem on an arbitrary graph. If I were to induce a clique among a subset of its vertices (and perhaps add in some additional nodes that are only adjacent to the nodes of the induced clique), does there exist an efficient way in which I use the original optimal solution (i.e. its structure as a starting solution) to find the new optimal maximum weight independent set in the modified graph??</p></div>







<p class="date">
by Student <a href="https://cstheory.stackexchange.com/questions/42144/maximum-weight-independent-set-on-a-changing-graph"><span class="datestr">at January 04, 2019 07:48 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7217">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/01/03/quantum-games/">Quantum Games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Nilin Abrahamsen <font face="courier new">nilin@mit.edu</font>
</p><p>Daniel Alabi <font face="courier new">alabid@g.harvard.edu</font>
</p><p>Mitali Bafna <font face="courier new">mitalibafna@g.harvard.edu</font>
</p><p>Emil Khabiboulline <font face="courier new">ekhabiboulline@g.harvard.edu</font>
</p><p>Juspreet Sandhu <font face="courier new">jus065@g.harvard.edu</font>

<br />
<br />
Two-prover one-round (2P-1R) games have been the subject of intensive study in classical complexity theory and quantum information theory. In a 2P-1R game, a <em>verifier</em> sends questions privately to each of two collaborating <em>provers</em> , who then aim to respond with a compatible pair of answers without communicating with each other. Sharing quantum entanglement allows the provers to improve their strategy without any communication, illustrating an apparent paradox of the quantum postulates. These notes aim to give an introduction to the role of entanglement in nonlocal games, as they are called in the quantum literature. We see how nonlocal games have rich connections within computer science and quantum physics, giving rise to theorems ranging from hardness of approximation to the resource theory of entanglement.
</p><h2>Introduction</h2>
In these notes we discuss 2-prover 1-round games and the classical complexity of approximating the value of such games in the setting where the provers can share entanglement. That is, given the description of a game, we ask how hard it is to estimate the winning probability of the best winning strategy of the entangled provers. Let us first formally define games and its relation to the label cover problem. We write <img src="https://s0.wp.com/latex.php?latex=%7B+%5Bn%5D%3D%5C%7B1%2C%5Cldots%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ [n]=\{1,\ldots,n\}}" class="latex" title="{ [n]=\{1,\ldots,n\}}" />.
<h4>Definition (Label cover)</h4>
<em> A label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%3D%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I=(S,T,\Sigma,\Pi)}" class="latex" title="{ I=(S,T,\Sigma,\Pi)}" /> consists of variable sets <img src="https://s0.wp.com/latex.php?latex=%7B+S%3D%5C%7Bs_i%5C%7D_%7Bi%5Cin%5Bn%5D%7D%2CT%3D%5C%7Bt_j%5C%7D_%7Bj%5Cin%5Bn%5D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" class="latex" title="{ S=\{s_i\}_{i\in[n]},T=\{t_j\}_{j\in[n]}}" />, alphabet set <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma}" class="latex" title="{ \Sigma}" />, and a collection <img src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Pi}" class="latex" title="{ \Pi}" /> of constraints of the form <img src="https://s0.wp.com/latex.php?latex=%7B+t_j%3Df_%7Bi%2Cj%7D%28s_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_j=f_{i,j}(s_i)}" class="latex" title="{ t_j=f_{i,j}(s_i)}" />. Given an assignment (or coloring) <img src="https://s0.wp.com/latex.php?latex=%7B+c+%3A+S%5Ccup+T+%5Crightarrow+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c : S\cup T \rightarrow \Sigma}" class="latex" title="{ c : S\cup T \rightarrow \Sigma}" /> we define its value to be <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28c%29%3D%5Cmathbb+P_%7Bf_%7Bij%7D%5Csim%5CPi%7D%5Cbig%28c%28t_j%29%3Df_%7Bij%7D%28c%28s_i%29%29%5Cbig%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" class="latex" title="{ \omega(c)=\mathbb P_{f_{ij}\sim\Pi}\big(c(t_j)=f_{ij}(c(s_i))\big)}" />. Define the value of <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" /> to be the maximum over all possible assignments, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29+%3D+%5Cmax_%7Bc%7D+%5Comega%28c%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(I) = \max_{c} \omega(c)}" class="latex" title="{ \omega(I) = \max_{c} \omega(c)}" />. </em>



Many familiar computational problems can be formulated as a label cover, such as <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3SAT%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{3SAT}}" class="latex" title="{ \textsc{3SAT}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7B3Lin%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{3Lin}}" class="latex" title="{ \textsc{3Lin}}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctextsc%7BMaxCut%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \textsc{MaxCut}}" class="latex" title="{ \textsc{MaxCut}}" />.
<figure style="width: 11em; margin: auto;">

<a href="https://windowsontheory.org/?attachment_id=7236"><img width="110" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/labelcover.png?w=110&amp;h=150" class="attachment-thumbnail size-thumbnail" height="150" /></a>
Label cover graph</figure>
<h4>Definition (2-prover 1-round game)</h4>
<em> Let <img src="https://s0.wp.com/latex.php?latex=%7B+I+%3D+%28S%2CT%2C%5CSigma%2C%5CPi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I = (S,T,\Sigma,\Pi)}" class="latex" title="{ I = (S,T,\Sigma,\Pi)}" /> be a label cover instance. We can then associate the following two-prover one-round game <img src="https://s0.wp.com/latex.php?latex=%7B+G%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G(I)}" class="latex" title="{ G(I)}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B+P_1%2CP_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_1,P_2}" class="latex" title="{ P_1,P_2}" /> be two provers who cannot communicate, and let <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" /> be the verifier. Given the label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" />, the verifier uniformly samples a constraint <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bi%2Cj%7D+%5Cin+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{i,j} \in \Pi}" class="latex" title="{ f_{i,j} \in \Pi}" /> and sends <img src="https://s0.wp.com/latex.php?latex=%7B+s_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s_i}" class="latex" title="{ s_i}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+P_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_1}" class="latex" title="{ P_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_j}" class="latex" title="{ t_j}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+P_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P_2}" class="latex" title="{ P_2}" />. The provers then reply with <img src="https://s0.wp.com/latex.php?latex=%7B+a+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a \in \Sigma}" class="latex" title="{ a \in \Sigma}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%5Cin%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b\in\Sigma}" class="latex" title="{ b\in\Sigma}" /> respectively to <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" />. Finally, <img src="https://s0.wp.com/latex.php?latex=%7B+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V}" class="latex" title="{ V}" /> outputs <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%7B+b+%3D+f_%7Bi%2Cj%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b = f_{i,j}(a)}" class="latex" title="{ b = f_{i,j}(a)}" />. </em>


<figure style="width: 25em; margin: auto;">
 
<a href="https://windowsontheory.org/?attachment_id=7235"><img width="150" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/game.png?w=150&amp;h=104" class="attachment-thumbnail size-thumbnail" height="104" /></a>


The game view of label cover</figure>
Any coloring of the label cover instance corresponds to a deterministic strategy for the corresponding game. Therefore, with an optimal strategy the provers win the game associated to label cover instance <img src="https://s0.wp.com/latex.php?latex=%7B+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I}" class="latex" title="{ I}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(I)}" class="latex" title="{ \omega(I)}" />. That is, the value of the game equals that of the label cover instance. However, this is with the assumption that provers can only use deterministic strategies or convex combinations of these (that is, using shared randomness). If the provers share an entangled quantum state, then the provers (who still cannot communicate) can enjoy correlations that allow them to win with a higher probability than classically. In the quantum literature, these 2P-1R games are known as nonlocal games referring to the fact that the correlations arise without signaling between the provers. We are concerned with the complexity of approximating the winning probability of this strategy.

We refer to the optimal winning probability within some class (classical or entangled) of strategies as the classical and quantum value of the game, respectively, and we use the terms quantum strategy and entangled strategy interchangeably.

Fixing different constraint families in the label cover game changes the complexity of finding the (classical and entangled) values of the game. We will show that approximating the entangled value of XOR games, or more generally <em>unique games</em> (to be defined later on), is possible in polynomial time. This is remarkable because a famous conjecture known as the <a href="https://en.wikipedia.org/wiki/Unique_games_conjecture"> <em>unique games conjecture</em> </a> says that approximating the classical value of unique games is NP-hard. In contrast, we will see that for unrestricted edge constraints, it is NP-hard to approximate the entangled value of a nonlocal game. Thus, hardness of approximation of the game’s value, established by the celebrated <em>PCP theorem</em> , still applies in the presence of entanglement. In the quantum world, we have new complexity classes such as QMA (which can be regarded as “quantum NP”), so one may conjecture whether approximating the entangled value of a general game is QMA-hard (the games formulation of the <em>quantum PCP conjecture</em> ). We will indicate progress in this direction but will explicitly demonstrate the NP-hardness result.

Entanglement is often regarded as an expensive resource in quantum information because it is difficult to produce and maintain. Hence, even if sharing entanglement can improve the success probability of winning a game, the resource consumption may be costly. We will conclude by discussing lower bounds on the number of shared entangled bits required to achieve the optimal value of a game.
<h2>Notation and quantum postulates</h2>
Let us first establish notation and define what is meant by an entangled strategy. In keeping with physics notation we write a column vector as <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v}\rangle \in\mathbb C^d}" class="latex" title="{ |{v}\rangle \in\mathbb C^d}" /> and its conjugate-transpose (a row vector) as <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{v}| }" class="latex" title="{ \langle{v}| }" /> . More generally the conjugate-transpose (Hermitian conjugate) of a matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is written <img src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^\dag}" class="latex" title="{ A^\dag}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7Bv%7D%7C+w%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{v}| w\rangle}" class="latex" title="{ \langle{v}| w\rangle}" /> is the inner product of two vectors (a scalar) and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%7D%5Crangle+%5Clangle%7Bw%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v}\rangle \langle{w}| }" class="latex" title="{ |{v}\rangle \langle{w}| }" /> the outer product (a rank-1 matrix). A matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is said to be <em>Hermitian</em> if <img src="https://s0.wp.com/latex.php?latex=%7B+A%5E%5Cdag%3DA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^\dag=A}" class="latex" title="{ A^\dag=A}" />. A matrix <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> is <em>positive semidefinite</em> , written <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Csucceq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A\succeq 0}" class="latex" title="{ A\succeq 0}" />, if <img src="https://s0.wp.com/latex.php?latex=%7B+A%3DB%5E%5Cdag+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A=B^\dag B}" class="latex" title="{ A=B^\dag B}" /> for some matrix <img src="https://s0.wp.com/latex.php?latex=%7B+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B}" class="latex" title="{ B}" />. We write the identity matrix as <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathbb{I}}}" class="latex" title="{ {\mathbb{I}}}" />, denote by <img src="https://s0.wp.com/latex.php?latex=%7B+Herm%28%5Cmathbb%7BC%7D%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ Herm(\mathbb{C}^d)}" class="latex" title="{ Herm(\mathbb{C}^d)}" /> the set of <img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" /> Hermitian matrices.
<h3> Observables, states, and entanglement</h3>
In a quantum theory the <em>observables</em> are Hermitian operators <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Cin+Herm%28%5Cmathbb+C%5Ed%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A\in Herm(\mathbb C^d)}" class="latex" title="{ A\in Herm(\mathbb C^d)}" /> on a vector space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" />. It then makes sense to say that a <em>state</em> is a functional <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varphi}" class="latex" title="{ \varphi}" /> on the set of observables. That is, to specify the state of a physical system means giving a (expected) value for each observable. It turns out states are <em>linear</em> functionals of the observables, and such functionals can be written <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarphi%28A%29%3D%5Clangle+A%2C%5Crho%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varphi(A)=\langle A,\rho\rangle}" class="latex" title="{ \varphi(A)=\langle A,\rho\rangle}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d}" class="latex" title="{ d}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" />. We call <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> the density matrix and require moreover that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> is positive semidefinite and has trace <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" />. Every density matrix is a convex combination of rank-one projections <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Clangle%5Cpsi%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\langle\psi|}" class="latex" title="{ |\psi\rangle\langle\psi|}" /> known as pure states. The unit vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" title="{ |\psi\rangle\in\mathbb C^d}" /> are also themselves known as pure states.

If the state of one particle is described by a vector in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> (referring here to pure states), then two particles are described by a vector in the tensor product <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ \mathbb C^d\otimes\mathbb C^d}" />. The two particles are entangled if their state is not in the form of a pure tensor <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cotimes%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle\otimes|\psi\rangle}" class="latex" title="{ |\phi\rangle\otimes|\psi\rangle}" />. We also write product states as <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle|\psi\rangle}" class="latex" title="{ |\phi\rangle|\psi\rangle}" />, omitting the tensor symbol.
<h3> Quantum measurements</h3>
A quantum measurement can be described in terms of a <em>projection-valued measure</em> (PVM).
<b>Definition 1 (PVM)</b> <em><a name="measurement"></a> A projection-valued measure on vector space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> (where the quantum states live) is a list of projection matrices <img src="https://s0.wp.com/latex.php?latex=%7B+A_1%2C%5Cldots%2CA_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_1,\ldots,A_k}" class="latex" title="{ A_1,\ldots,A_k}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B+A_iA_j%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_iA_j=0}" class="latex" title="{ A_iA_j=0}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\neq j}" class="latex" title="{ i\neq j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_i+A_i%3D%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_i A_i={\mathbb{I}}}" class="latex" title="{ \sum_i A_i={\mathbb{I}}}" />. The PVM describes a measurement which, on state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%5Cin%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle\in\mathbb C^d}" class="latex" title="{ |\psi\rangle\in\mathbb C^d}" /> outputs measurement outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cpsi%7C+A_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\psi| A_i|\psi\rangle}" class="latex" title="{ \langle\psi| A_i|\psi\rangle}" />. The quantum state after obtaining outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%5C%7CA_i%7C%5Cpsi%5Crangle%5C%7C%7DA_i%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" class="latex" title="{ \frac1{\|A_i|\psi\rangle\|}A_i|\psi\rangle}" />. </em>
When the projections are rank-one projections <img src="https://s0.wp.com/latex.php?latex=%7B+A_i%3D+%7C%7B%5Cbeta_i%7D%5Crangle+%5Clangle%7B%5Cbeta_i%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" class="latex" title="{ A_i= |{\beta_i}\rangle \langle{\beta_i}| }" /> we say that we measure in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_i%7D%5Crangle+%5C%7D_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_i}\rangle \}_i}" class="latex" title="{ \{ |{\beta_i}\rangle \}_i}" />. In this case the probability of outcome <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> in state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cpsi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\psi\rangle}" class="latex" title="{ |\psi\rangle}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_i+%7C%7B%5Cpsi%7D%5Crangle+%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\langle\beta_i |{\psi}\rangle |^2}" class="latex" title="{ |\langle\beta_i |{\psi}\rangle |^2}" />, and the post-measurement state is simply <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_i%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_i}\rangle}" class="latex" title="{ |{\beta_i}\rangle}" /> .

Applying the measurement <img src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%29_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A_i)_i}" class="latex" title="{ (A_i)_i}" /> on the left half of a two-particle state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5CPsi%7D%5Crangle+%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |{\Psi}\rangle \in\mathbb C^d\otimes\mathbb C^d}" /> means applying the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+%28A_i%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A_i\otimes {\mathbb{I}})_{i}}" class="latex" title="{ (A_i\otimes {\mathbb{I}})_{i}}" /> on the two-particle state.
<h3> Quantum strategies for nonlocal games</h3>
We now introduce the notion of a quantum strategy for a nonlocal game. Each prover holds a particle, say with state space <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^d}" class="latex" title="{ \mathbb C^d}" />, and Alices particle may be entangled with Bob’s. The global state is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |{\phi}\rangle _{AB}\in\mathbb C^d\otimes\mathbb C^d}" />. Each player receives a question from the verifier and then chooses a measurement (a PVM) depending on the question. The player applies the measurement to their own particle and responds to the verifier with their measurement outcome. Hence for Alice we specify <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cin+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\in S}" class="latex" title="{ s\in S}" /> is a question, and each PVM is a list <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_%7Ba%3D1%7D%2C%5Cldots%2CA%5Es_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_{a=1},\ldots,A^s_k}" class="latex" title="{ A^s_{a=1},\ldots,A^s_k}" />. By definition <a href="https://windowsontheory.org/feed/#measurement">1</a>, given questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t}" class="latex" title="{ s,t}" /> the probability that Alice outputs <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and Bob outputs <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> is <a name="Qstrategy"></a>

<a name="Qstrategy">
</a><a name="Qstrategy"></a>
<p align="center"><a name="Qstrategy"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++P%28a%2Cb%7Cs%2Ct%29%3D%5C%7C%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b%29%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5C%7C%5E2%3D+%5Clangle%7B%5Cphi%7D%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%2C+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" class="latex" title="\displaystyle  P(a,b|s,t)=\|({\mathbb{I}}\otimes B^t_b)(A^s_a\otimes {\mathbb{I}}) |{\phi}\rangle _{AB}\|^2= \langle{\phi}| A^s_a\otimes B^t_b|\phi\rangle, \ \ \ \ \ (1)" /></a></p>
<a name="Qstrategy">
</a><a name="Qstrategy"></a> where we have used that squaring a projection leaves it unchanged.
<h2>Quantum strategies beat classical ones</h2>
For any 2P-1R game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" />, let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" /> be the maximum probability — over the players’ classical strategies — that the verifier accepts and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> the maximum probability that the verifier accepts when the provers use qubits such that player 1’s qubits are entangled with those of player 2.

The game of Clauser, Horne, Shimony, and Holt (CHSH) has the property that the provers can increase their chance of winning by sharing an entangled pair of qubits, even when no messages are exchanged between the players. We show that there’s a characterization of the CHSH game’s value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29+%3D+%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" class="latex" title="{ \omega^*(G)=\cos^2(\frac{\pi}{8}) = \frac{1}{2}+\frac{\sqrt{2}}{4}\approx 0.85}" /> which is better than the classical value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%5Cleq+%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)\leq \frac{3}{4}}" class="latex" title="{ \omega(G)\leq \frac{3}{4}}" />. Let us first define XOR games, of which the CHSH game is a special case.
<h4>Definition (XOR game)</h4>
<em> An XOR game is a 2-player classical game (the questions and answers are classical bits) where: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> Questions <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%5Cin%5C%7B0%2C+1%2C+%5Cldots%2C+n-1%5C%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" class="latex" title="{ (s, t)\in\{0, 1, \ldots, n-1\}^2}" /> are asked according to some distribution <img src="https://s0.wp.com/latex.php?latex=%7B+%5CPi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Pi}" class="latex" title="{ \Pi}" /> (e.g. uniform).</li>
 	<li> Answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a, b\in\{0, 1\}}" class="latex" title="{ a, b\in\{0, 1\}}" /> are provided by players (call them Alice and Bob).</li>
 	<li> The verifier computes a predicate <img src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b%7Cs%2C+t%29+%3D+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" class="latex" title="{ V(a, b|s, t) = f_{s, t}(a\oplus b)}" /> used to decide acceptance/rejection.</li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>


<h4>Definition (CHSH Game)</h4>
<em> An XOR game with <img src="https://s0.wp.com/latex.php?latex=%7B+n%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n=2}" class="latex" title="{ n=2}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in\{0, 1\}}" class="latex" title="{ s, t\in\{0, 1\}}" /> are independent random bits and <img src="https://s0.wp.com/latex.php?latex=%7B+V%28a%2C+b+%7C+s%2C+t%29%3D1+%5CLongleftrightarrow+a%5Coplus+b+%3D+s%5Cwedge+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" class="latex" title="{ V(a, b | s, t)=1 \Longleftrightarrow a\oplus b = s\wedge t}" />. </em>



To win the CHSH game, Alice and Bob need to output bits <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> (from Alice) and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> (from Bob) that disagree if <img src="https://s0.wp.com/latex.php?latex=%7B+s%3Dt%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=t=1}" class="latex" title="{ s=t=1}" /> and agree otherwise.

If Alice and Bob are classical then they can do no better than by always outputting <img src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0}" class="latex" title="{ 0}" />, say, in which case they win in the three out of four cases when one of the questions is <img src="https://s0.wp.com/latex.php?latex=%7B+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0}" class="latex" title="{ 0}" />. Equivalently, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%3D%5Cfrac34%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)=\frac34}" class="latex" title="{ \omega(G)=\frac34}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> is the CHSH game. This is the content of <em>Bell’s inequality</em> :
<h4>Lemma (Bell’s Inequality)</h4>
<em> For any two functions <img src="https://s0.wp.com/latex.php?latex=%7B+g%2C+h%3A+%5C%7B0%2C+1%5C%7D%5Crightarrow%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" class="latex" title="{ g, h: \{0, 1\}\rightarrow\{0, 1\}}" />, we have </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D+%5Cleq+%5Cfrac%7B3%7D%7B4%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" class="latex" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right] \leq \frac{3}{4} }" /></em>

<em>
</em><em></em><em> where <img src="https://s0.wp.com/latex.php?latex=%7B+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x}" class="latex" title="{ x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ y}" class="latex" title="{ y}" /> are independent uniformly random bits. </em>



<em><br /><b>Proof.</b></em> The probability of any event is a multiple of <img src="https://s0.wp.com/latex.php?latex=%7B+1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1/4}" class="latex" title="{ 1/4}" /> so it suffices to show that <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D_%7Bx%2C+y%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%5Bg%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%5Cright%5D%5Cneq1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" class="latex" title="{ {\mathop{\mathbb{P}}}_{x, y\in\{0, 1\}}\left[g(x)\oplus h(y) = x\wedge y\right]\neq1}" />. So assume for contradiction that <img src="https://s0.wp.com/latex.php?latex=%7B+g%28x%29%5Coplus+h%28y%29+%3D+x%5Cwedge+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(x)\oplus h(y) = x\wedge y}" class="latex" title="{ g(x)\oplus h(y) = x\wedge y}" /> for all pairs <img src="https://s0.wp.com/latex.php?latex=%7B+x%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x,y}" class="latex" title="{ x,y}" />. Then we have that <img src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%280%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(0)\oplus h(0) = 0}" class="latex" title="{ g(0)\oplus h(0) = 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+g%280%29%5Coplus+h%281%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ g(0)\oplus h(1) = 0}" class="latex" title="{ g(0)\oplus h(1) = 0}" /> which implies that <img src="https://s0.wp.com/latex.php?latex=%7B+h%280%29%3Dh%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ h(0)=h(1)}" class="latex" title="{ h(0)=h(1)}" />. But then <img src="https://s0.wp.com/latex.php?latex=%7B+0%3Dg%281%29%5Coplus+h%280%29+%3Dg%281%29%5Coplus+h%281%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" class="latex" title="{ 0=g(1)\oplus h(0) =g(1)\oplus h(1) = 1}" /> which is a contraction. 
<div align="right">□</div>
<h3> The strategy</h3>
The entangled strategy for the CHSH game requires that Alice and Bob each hold a qubit, so that their two qubits together are described by a vector in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E2%5Cotimes%5Cmathbb+C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^2\otimes\mathbb C^2}" class="latex" title="{ \mathbb C^2\otimes\mathbb C^2}" />. The two qubits together are in the state

<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cleft%28+%7C%7B0%7D%5Crangle+_A+%7C%7B0%7D%5Crangle+_B+%2B+%7C%7B1%7D%5Crangle+_A+%7C%7B1%7D%5Crangle+_B%5Cright%29%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" class="latex" title="{ |{\phi}\rangle = \frac{1}{\sqrt{2}}\left( |{0}\rangle _A |{0}\rangle _B + |{1}\rangle _A |{1}\rangle _B\right), }" />

forming what is known as an EPR (Einstein-Podolsky-Rosen) pair. Now for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctheta%5Cin%5B-%5Cpi%2C+%5Cpi%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \theta\in[-\pi, \pi]}" class="latex" title="{ \theta\in[-\pi, \pi]}" /> define <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Ctheta%29%7D%5Crangle+%3D+%5Ccos%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Csin%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" class="latex" title="{ |{\beta_0(\theta)}\rangle = \cos\theta |{0}\rangle + \sin\theta |{1}\rangle }" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Ctheta%29%7D%5Crangle+%3D+-%5Csin%5Ctheta+%7C%7B0%7D%5Crangle+%2B+%5Ccos%5Ctheta+%7C%7B1%7D%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" class="latex" title="{ |{\beta_1(\theta)}\rangle = -\sin\theta |{0}\rangle + \cos\theta |{1}\rangle }" /> .

Now we describe a (quantum) strategy with winning probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\frac{\pi}{8})}" class="latex" title="{ \cos^2(\frac{\pi}{8})}" />. In each case Alice and Bob respond with their measurement outcome, where subscripts of the measurement basis vectors correspond to the answer to be sent back to the verifier.
<ul>
 	<li> If <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=0}" class="latex" title="{ s=0}" />, Alice measures in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%280%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%280%29%7D%5Crangle+%5C%7D+%3D+%5C%7B+%7C%7B0%7D%5Crangle+%2C+%7C%7B1%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" class="latex" title="{ \{ |{\beta_0(0)}\rangle , |{\beta_1(0)}\rangle \} = \{ |{0}\rangle , |{1}\rangle \}}" />. If <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=1}" class="latex" title="{ s=1}" />, Alice measures in <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B4%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" class="latex" title="{ \{ |{\beta_0(\frac{\pi}{4})}\rangle , |{\beta_1(\frac{\pi}{4})}\rangle \}}" />. Alice answers bit <img src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a = 0}" class="latex" title="{ a = 0}" /> if outcome is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cbeta_0%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \beta_0(\cdot)}" class="latex" title="{ \beta_0(\cdot)}" /> and answers <img src="https://s0.wp.com/latex.php?latex=%7B+a+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a = 1}" class="latex" title="{ a = 1}" /> otherwise.</li>
 	<li> If <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=0}" class="latex" title="{ t=0}" />, Bob measures in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" class="latex" title="{ \{ |{\beta_0(\frac{\pi}{8})}\rangle , |{\beta_1(\frac{\pi}{8})}\rangle\}}" />. If <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=1}" class="latex" title="{ t=1}" />, Bob measures in <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_0%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%2C+%7C%7B%5Cbeta_1%28-%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D%5Crangle+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" class="latex" title="{ \{ |{\beta_0(-\frac{\pi}{8})}\rangle , |{\beta_1(-\frac{\pi}{8})}\rangle \}}" />.</li>
 	<li> Each player responds with their respective measurement outcome.</li>
</ul>
<b>Lemma 2</b> <em><a name="goodstrategy"></a> Alice and Bob win the CHSH game with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\frac{\pi}{8})}" class="latex" title="{ \cos^2(\frac{\pi}{8})}" />. </em>
<em><br /><b></b>Proof.</em> We will show that for each pair of questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t}" class="latex" title="{ s,t}" /> the pair of answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> is correct with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\pi/8)}" class="latex" title="{ \cos^2(\pi/8)}" />. We can split the pairs of questions into the two cases <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=0}" class="latex" title="{ s\wedge t=0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=1}" class="latex" title="{ s\wedge t=1}" />:
<ul>
 	<li> (<img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=0}" class="latex" title="{ s\wedge t=0}" />) The three cases <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%3D%280%2C0%29%2C%280%2C1%29%2C%281%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,t)=(0,0),(0,1),(1,0)}" class="latex" title="{ (s,t)=(0,0),(0,1),(1,0)}" /> are all analogous: in each case Alice an Bob must output the same answer, and in each case Bob’s measurement basis is almost the same as Alice’s except rotated by a small angle <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpm%5Cpi%2F8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \pm\pi/8}" class="latex" title="{ \pm\pi/8}" />.
Of the three above cases we consider the one where <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ct%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,t=0}" class="latex" title="{ s,t=0}" /> and check that indeed the two measurement outcomes agree with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccos%5E2%28%5Cpi%2F8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cos^2(\pi/8)}" class="latex" title="{ \cos^2(\pi/8)}" />: When Alice measures her qubit and obtains some bit <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" />, the shared pair <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta}\rangle}" class="latex" title="{ |{\beta}\rangle}" /> collapses to <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{a}\rangle _A |{a}\rangle _B}" class="latex" title="{ |{a}\rangle _A |{a}\rangle _B}" />. Indeed, since the question was <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=0}" class="latex" title="{ s=0}" />, Alice measures her qubit in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{|0\rangle,|1\rangle\}}" class="latex" title="{ \{|0\rangle,|1\rangle\}}" />. This means that Alice applies the measurement <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7C0%5Crangle%5Clangle+0%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%2C%7C1%5Crangle%5Clangle+1%7C%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" class="latex" title="{ \{|0\rangle\langle 0|\otimes {\mathbb{I}},|1\rangle\langle 1|\otimes {\mathbb{I}}\}}" /> on the global state. The post-measurement state is the normalization of

<img src="https://s0.wp.com/latex.php?latex=%7B+%28+%7C%7Ba%7D%5Crangle+%5Clangle%7Ba%7D%7C+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%3D%5Cfrac%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B0%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C0%7D%7D%5Cotimes+%7C+0%5Crangle+%2B+%7C%7Ba%7D%5Crangle+%5Coverbrace%7B%5Clangle+a+%7C%7B1%7D%5Crangle+%7D%5E%7B%5Cdelta_%7Ba%2C1%7D%7D%5Cotimes+%7C%7B1%7D%5Crangle+%3D%5Cfrac+%7B1%7D%7B%5Csqrt2%7D+%7C%7Ba%7D%5Crangle+_A+%7C%7Ba%7D%5Crangle+_B+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" class="latex" title="{ ( |{a}\rangle \langle{a}| \otimes {\mathbb{I}}) |{\phi}\rangle _{AB}=\frac{1}{\sqrt2} |{a}\rangle \overbrace{\langle a |{0}\rangle }^{\delta_{a,0}}\otimes | 0\rangle + |{a}\rangle \overbrace{\langle a |{1}\rangle }^{\delta_{a,1}}\otimes |{1}\rangle =\frac {1}{\sqrt2} |{a}\rangle _A |{a}\rangle _B }" />

because <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle+a+%7C%7Ba%27%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle a |{a'}\rangle}" class="latex" title="{ \langle a |{a'}\rangle}" /> can be viewed as a Kronecker delta of <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+a%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a'}" class="latex" title="{ a'}" />. In particular, Bob is now in the pure state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Ba%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{a}\rangle}" class="latex" title="{ |{a}\rangle}" /> .

Because Bob received question <img src="https://s0.wp.com/latex.php?latex=%7B+t%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t=0}" class="latex" title="{ t=0}" /> he measures in the basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_b%28%5Cpi%2F8%29%7D%5Crangle+%5C%7D_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" class="latex" title="{ \{ |{\beta_b(\pi/8)}\rangle \}_b}" /> Therefore his probability of correctly outputting <img src="https://s0.wp.com/latex.php?latex=%7B+b%3Da%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b=a}" class="latex" title="{ b=a}" /> is

<img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathop%7B%5Cmathbb%7BP%7D%7D%7D%5B%5Ctext%7BBob+gets+outcome+%7Da%5D+%3D+%7C%5Clangle%5Cbeta_a%28%5Ctfrac%7B%5Cpi%7D%7B8%7D%29+%7C%7Ba%7D%5Crangle+%7C%5E2+%3D+%5Ccos%5E2%5Cleft%28%5Cfrac%7B%5Cpi%7D%7B8%7D%5Cright%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" class="latex" title="{ {\mathop{\mathbb{P}}}[\text{Bob gets outcome }a] = |\langle\beta_a(\tfrac{\pi}{8}) |{a}\rangle |^2 = \cos^2\left(\frac{\pi}{8}\right) }" />

</li>
 	<li> (<img src="https://s0.wp.com/latex.php?latex=%7B+s%5Cwedge+t%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s\wedge t=1}" class="latex" title="{ s\wedge t=1}" />)
Now consider the case <img src="https://s0.wp.com/latex.php?latex=%7B+s%3D1%2Ct%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s=1,t=1}" class="latex" title="{ s=1,t=1}" /> where Alice and Bob are supposed to give different answers. Alice measures in basis consisting of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_0%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" class="latex" title="{ |{\beta_0(\pi/4)}\rangle =\frac{|0\rangle+|1\rangle}{\sqrt2}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_1%28%5Cpi%2F4%29%7D%5Crangle+%3D%5Cfrac%7B-%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" class="latex" title="{ |{\beta_1(\pi/4)}\rangle =\frac{-|0\rangle+|1\rangle}{\sqrt2}}" />. If Alice gets outcome <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> then the post-measurement global state is <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle+%7C%7B%5Cbeta_a%28%5Cfrac%5Cpi4%29%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" class="latex" title="{ |{\beta_a(\frac\pi4)}\rangle |{\beta_a(\frac\pi4)}\rangle}" /> . Therefore when Bob applies the measurement in basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%5C%7D_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" class="latex" title="{ \{ |{\beta_a(-\frac\pi8)}\rangle \}_a}" /> he mistakenly outputs <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> only with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Clangle%5Cbeta_a%28%5Cfrac%5Cpi4%29+%7C%7B%5Cbeta_a%28-%5Cfrac%5Cpi8%29%7D%5Crangle+%7C%5E2%3D%5Csin%5E2%28%5Cfrac%5Cpi8%29%3D1-%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" class="latex" title="{ |\langle\beta_a(\frac\pi4) |{\beta_a(-\frac\pi8)}\rangle |^2=\sin^2(\frac\pi8)=1-\cos^2(\frac\pi8)}" />.</li>
</ul>

<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#goodstrategy">2</a> implies a lower bound on the value of the CHSH game.
<h4>Corollary</h4>
<em> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%5Cge%5Ccos%5E2%28%5Cfrac%5Cpi8%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" class="latex" title="{ \omega^*(G)\ge\cos^2(\frac\pi8)}" /> </em>

 
<br />It turns out that this lower bound is sharp, that is, the strategy just described is optimal.

<h4>Lemma</h4><em> The value of the CHSH game using a quantum strategy is at most <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+%3D+%5Ccos%5E2%5Cfrac%7B%5Cpi%7D%7B8%7D%5Capprox+0.85%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" class="latex" title="{ \frac{1}{2} + \frac{\sqrt{2}}{4} = \cos^2\frac{\pi}{8}\approx 0.85}" />. </em>



<em><b>Proof.</b></em>

We can describe the quantum strategy of Alice and Bob in an XOR game by (i) a shared quantum state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cphi%7D%5Crangle+_%7BAB%7D%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" title="{ |{\phi}\rangle _{AB}\in\mathbb{C}^d\otimes\mathbb{C}^d}" /> (note that for the CHSH game, <img src="https://s0.wp.com/latex.php?latex=%7B+d%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d=2}" class="latex" title="{ d=2}" />); (ii) measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA%5E0_s%2C+A%5E1_s%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A^0_s, A^1_s\}}" class="latex" title="{ \{A^0_s, A^1_s\}}" /> for every question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> sent to Alice; (iii) measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB%5E0_t%2C+B%5E1_t%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B^0_t, B^1_t\}}" class="latex" title="{ \{B^0_t, B^1_t\}}" /> for every question <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> sent to Bob.

The probability of answering <img src="https://s0.wp.com/latex.php?latex=%7B+%28a%2C+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a, b)}" class="latex" title="{ (a, b)}" /> given questions <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2C+t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s, t)}" class="latex" title="{ (s, t)}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" class="latex" title="{ \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle}" /> . Now let us write <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%3DA%5E0_s+-+A%5E1_s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s=A^0_s - A^1_s}" class="latex" title="{ A_s=A^0_s - A^1_s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_t%3DB%5E0_t+-+B%5E1_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_t=B^0_t - B^1_t}" class="latex" title="{ B_t=B^0_t - B^1_t}" /> so that for any <img src="https://s0.wp.com/latex.php?latex=%7B+a%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a, b\in\{0, 1\}}" class="latex" title="{ a, b\in\{0, 1\}}" />, we can write

<img src="https://s0.wp.com/latex.php?latex=%7B+A_s%5Ea+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%2C+B_t%5Eb+%3D+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" class="latex" title="{ A_s^a = \frac{{\mathbb{I}} + (-1)^aA_s}{2}, B_t^b = \frac{{\mathbb{I}} + (-1)^bB_t}{2} }" />

Note that since the possible outcomes here are finite, <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s, B_t}" class="latex" title="{ A_s, B_t}" /> are Hermitian and we may assume have bounded norm of 1. Furthermore, we assume that <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%2C+B_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s, B_t}" class="latex" title="{ A_s, B_t}" /> are <em>observables</em> so that <img src="https://s0.wp.com/latex.php?latex=%7B+A_s%5E2+%3D+B_t%5E2+%3D+%7B%5Cmathbb%7BI%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_s^2 = B_t^2 = {\mathbb{I}}}" class="latex" title="{ A_s^2 = B_t^2 = {\mathbb{I}}}" /> .

Now denoting <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{s, t}(a\oplus b)}" class="latex" title="{ f_{s, t}(a\oplus b)}" /> as the XOR predicate to be computed, we can write the quantum game value as

<img src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5Ea%5C%7D%2C+%5C%7BB_t%5Eb%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+A%5Ea_s%5Cotimes+B%5Eb_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7Df_%7Bs%2C+t%7D%28a%5Coplus+b%29+%5Clangle%7B%5Cphi%7D%7C+%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EaA_s%7D%7B2%7D%5Cotimes++%5Cfrac%7B%7B%5Cmathbb%7BI%7D%7D+%2B+%28-1%29%5EbB_t%7D%7B2%7D+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%28-1%29%5E%7Bab%7D%7D%7B4%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+%3D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Csum_%7Ba%2C+b%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%28a%5Coplus+b%29%7D%7B4%7D+%2B+%5Csup_%7B+%7C%7B%5Cphi%7D%5Crangle+%2C+%5C%7BA_s%5C%7D%2C+%5C%7BB_t%5C%7D%7D+%7B%5Cmathop%7B%5Cmathbb%7BE%7D%7D%7D_%7B%28s%2C+t%29%5Csim%5CPi%7D%5Cfrac%7Bf_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29%7D%7B2%7D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle++%5C%5C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " class="latex" title="\omega^*(G) = \sup_{ |{\phi}\rangle , \{A_s^a\}, \{B_t^b\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| A^a_s\otimes B^b_t |{\phi}\rangle  \\ = \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}f_{s, t}(a\oplus b) \langle{\phi}| \frac{{\mathbb{I}} + (-1)^aA_s}{2}\otimes  \frac{{\mathbb{I}} + (-1)^bB_t}{2} |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)(-1)^{ab}}{4} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ = {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\sum_{a, b}\frac{f_{s, t}(a\oplus b)}{4} + \sup_{ |{\phi}\rangle , \{A_s\}, \{B_t\}} {\mathop{\mathbb{E}}}_{(s, t)\sim\Pi}\frac{f_{s, t}(0) - f_{s,t}(1)}{2} \langle{\phi}| A_s\otimes B_t |{\phi}\rangle  \\ " />

where the summation <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Ba%2C+b%5Cin%5C%7B0%2C+1%5C%7D%7D%5Cleft%28%5Ccdot%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" class="latex" title="{ \sum_{a, b\in\{0, 1\}}\left(\cdot\right)}" /> has been evaluated in the last line.

Now note that the first term is independent of the quantum strategy and as a result equals the value of the uniformly random strategy which is 1/2. So we proceed to focus on the second term. Note that for CHSH <img src="https://s0.wp.com/latex.php?latex=%7B+f_%7Bs%2C+t%7D%280%29+-+f_%7Bs%2Ct%7D%281%29+%3D+%28-1%29%5E%7Bst%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" class="latex" title="{ f_{s, t}(0) - f_{s,t}(1) = (-1)^{st}}" /> simplifying the second term to

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac%7B1%7D%7B8%7D%28+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_0+%7C%7B%5Cphi%7D%5Crangle+%2B+%5Clangle%7B%5Cphi%7D%7C+A_0%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+-+%5Clangle%7B%5Cphi%7D%7C+A_1%5Cotimes+B_1+%7C%7B%5Cphi%7D%5Crangle+%29.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" class="latex" title="{ \frac{1}{8}( \langle{\phi}| A_0\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_1\otimes B_0 |{\phi}\rangle + \langle{\phi}| A_0\otimes B_1 |{\phi}\rangle - \langle{\phi}| A_1\otimes B_1 |{\phi}\rangle ). }" />

Next, we invoke Tsirelson’s Theorem (See Theorem <a href="https://windowsontheory.org/feed/#thmtsirelson">3</a>) to bound this second term as

<img src="https://s0.wp.com/latex.php?latex=%3D+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7Bx%7D%7D_0%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1+%2B+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7Bx%7D%7D_1%5Ccdot+%7B%5Ctextbf%7By%7D%7D_1%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B1%7D%7B8%7D%28%5C%7C%7B%5Ctextbf%7Bx%7D%7D_0%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+%2B+%7B%5Ctextbf%7By%7D%7D_1%5C%7C+%2B+%5C%7C%7B%5Ctextbf%7Bx%7D%7D_1%5C%7C%5C%7C%7B%5Ctextbf%7By%7D%7D_0+-+%7B%5Ctextbf%7By%7D%7D_1%5C%7C%29+%5C%5C+%5Cleq+%5Csup_%7B%7B%5Ctextbf%7Bx%7D%7D_s%2C+%7B%5Ctextbf%7By%7D%7D_t%7D%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B8%7D%5Csqrt%7B2%5C%7C%7B%5Ctextbf%7By%7D%7D_0%5C%7C%5E2+%2B+2%5C%7C%7B%5Ctextbf%7By%7D%7D_1%5C%7C%5E2%7D+%5Cleq+%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " class="latex" title="= \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}({\textbf{x}}_0\cdot {\textbf{y}}_0 + {\textbf{x}}_0\cdot {\textbf{y}}_1 + {\textbf{x}}_1\cdot {\textbf{y}}_0 - {\textbf{x}}_1\cdot {\textbf{y}}_1) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{1}{8}(\|{\textbf{x}}_0\|\|{\textbf{y}}_0 + {\textbf{y}}_1\| + \|{\textbf{x}}_1\|\|{\textbf{y}}_0 - {\textbf{y}}_1\|) \\ \leq \sup_{{\textbf{x}}_s, {\textbf{y}}_t}\frac{\sqrt{2}}{8}\sqrt{2\|{\textbf{y}}_0\|^2 + 2\|{\textbf{y}}_1\|^2} \leq \frac{\sqrt{2}}{4} " />

where we have used Cauchy-Schwartz and the concavity of the <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csqrt%7B%5Ccdot%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sqrt{\cdot}}" class="latex" title="{ \sqrt{\cdot}}" /> function.

This completes our proof showing the exact characterization of the value (<img src="https://s0.wp.com/latex.php?latex=%7B+%3D%5Ccos%5E2%28%5Cfrac%7B%5Cpi%7D%7B8%7D%29%3D%5Cfrac%7B1%7D%7B2%7D%2B%5Cfrac%7B%5Csqrt%7B2%7D%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" class="latex" title="{ =\cos^2(\frac{\pi}{8})=\frac{1}{2}+\frac{\sqrt{2}}{4}}" />) of the CHSH game using a quantum strategy. This proof is an adaptation of the one in [12]. 
<div align="right">□</div>
<b>Theorem 3 (Tsirelson’s Theorem [1])</b> <em><a name="thmtsirelson"></a> For any <img src="https://s0.wp.com/latex.php?latex=%7B+n%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n\times n}" class="latex" title="{ n\times n}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+C+%3D+%28C_%7Bs%2C+t%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C = (C_{s, t})}" class="latex" title="{ C = (C_{s, t})}" />, the following are equivalent: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> There exist <img src="https://s0.wp.com/latex.php?latex=%7B+d%5Cin%5Cmathbb%7BN%7D%2C+%7C%7B%5Cphi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5E%7Bd%7D%5Cotimes%5Cmathbb%7BC%7D%5E%7Bd%7D%2C+A_s%2C+B_t%5Cin%5Ctext%7BHerm%7D%28%5Cmathbb%7BC%7D%5Ed%29%2C+A_s%5E2+%3D+B_t%5E2+%3D+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" class="latex" title="{ d\in\mathbb{N}, |{\phi}\rangle \in\mathbb{C}^{d}\otimes\mathbb{C}^{d}, A_s, B_t\in\text{Herm}(\mathbb{C}^d), A_s^2 = B_t^2 = I}" /> such that for any <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in[n]}" class="latex" title="{ s, t\in[n]}" /> <img src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%5Clangle%7B%5Cphi%7D%7C+A_s%5Cotimes+B_t+%7C%7B%5Cphi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" class="latex" title="{ C_{s, t} = \langle{\phi}| A_s\otimes B_t |{\phi}\rangle}" /> . Further this would imply that <img src="https://s0.wp.com/latex.php?latex=%7B+d%5Cleq+2%5E%7B%5Clceil%5Cfrac%7Bn%2B2%7D%7B2%7D%5Crceil%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" class="latex" title="{ d\leq 2^{\lceil\frac{n+2}{2}\rceil}}" />;</li>
 	<li> There exist real unit vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%2C+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%5Cin%7B%5Cmathbb%7BR%7D%7D%5E%7Bn%2B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" class="latex" title="{ { {\textbf{x}}}_s, { {\textbf{y}}}_t\in{\mathbb{R}}^{n+2}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B+s%2C+t%5Cin+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s, t\in [n]}" class="latex" title="{ s, t\in [n]}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B+C_%7Bs%2C+t%7D+%3D+%7B%09%7B%5Ctextbf%7Bx%7D%7D%7D_s%5Ccdot+%7B%09%7B%5Ctextbf%7By%7D%7D%7D_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" class="latex" title="{ C_{s, t} = { {\textbf{x}}}_s\cdot { {\textbf{y}}}_t}" />;</li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>
<h2>Entangled unique games are easy</h2>
The CHSH game provides the first example that the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> of a nonlocal game can exceed the classical value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" />. XOR-games like the CHSH game are the special case corresponding to alphabet size <img src="https://s0.wp.com/latex.php?latex=%7B+k%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k=2}" class="latex" title="{ k=2}" /> of the class of <em>unique games</em> :
<h4>Definition (Unique Games)</h4>
<em> A 2-prover 1-round game is called a <em>unique game</em> if its constraints are of the form <img src="https://s0.wp.com/latex.php?latex=%7B+b%3D%5Cpi_%7Bij%7D%28a%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b=\pi_{ij}(a)}" class="latex" title="{ b=\pi_{ij}(a)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpi_%7Bij%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \pi_{ij}}" class="latex" title="{ \pi_{ij}}" /> is a permutation of the alphabet <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma}" class="latex" title="{ \Sigma}" /> for each edge <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Csim+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\sim j}" class="latex" title="{ i\sim j}" />. </em>

 The famous <em>unique games conjecture</em> (UGC) by Khot says that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G)}" class="latex" title="{ \omega(G)}" /> is NP-hard to approximate for unique games. Surprisingly, Kempe et al. showed that a natural semidefinite relaxation for unique games yields an approximation to the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> which can be computed in polynomial time. In other words the UGC is false for entangled provers, in contrast to the classical case where the conjecture is open.
<br />Theorem 4 <em><a name="efficientUGC"></a> There is an efficient (classical) algorithm which takes a description of a nonlocal game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> as its input and outputs <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)}" class="latex" title="{ \hat\omega(G)}" /> such that </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+1-6%281-%5Chat%5Comega%28G%29%29%5Cle%5Comega%5E%2A%28G%29%5Cle%5Chat%5Comega%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" class="latex" title="{ 1-6(1-\hat\omega(G))\le\omega^*(G)\le\hat\omega(G) }" /></em>

<em>Put differently, if <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%3D1-%5Cvarepsilon%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)=1-\varepsilon^*}" class="latex" title="{ \omega^*(G)=1-\varepsilon^*}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D1-%5Chat%5Cvarepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=1-\hat\varepsilon}" class="latex" title="{ \hat\omega(G)=1-\hat\varepsilon}" />, then</em>

<em><img src="https://s0.wp.com/latex.php?latex=%7B+%5Cvarepsilon%5E%2A%5Cin%5B%5Chat%5Cvarepsilon%2C6%5Chat%5Cvarepsilon%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" class="latex" title="{ \varepsilon^*\in[\hat\varepsilon,6\hat\varepsilon] }" /></em>

<em>
</em><em></em><em></em><em></em><em> </em>
<br />The algorithm of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> proceeds by relaxing the set of quantum strategies to a larger convex set <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> of <em>pseudo-strategies</em> and maximizing over <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> instead of actual strategies, a much easier task. In approximation theory one often encounters a collection of hypothetical moments not arising from a distribution, known as a pseudo-distribution. In contrast, our pseudo-strategies are actual conditional probability distributions on answers (conditional on the questions). What makes <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> a set of “pseudo”-strategies rather than actual strategies is that they may enjoy correlations which cannot be achieved without communication.
<h3> Convex relaxation of quantum strategies</h3>
We will define <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> to be a class of conditional probability distributions <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> on answers given questions. We will require that the pseudo-strategies satisfy a positive semidefinite constraint when arranged in matrix form. In particular this matrix has to be symmetric, so we symmetrize the conditional probability <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> by allowing each of <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> to be either a question for Alice or for Bob. That is, we extend the domain of definition for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(a,b|s,t)}" class="latex" title="{ \tilde{P}(a,b|s,t)}" /> from <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma^2\times S\times T}" class="latex" title="{ \Sigma^2\times S\times T}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \Sigma^2\times (S\cup T)^2}" class="latex" title="{ \Sigma^2\times (S\cup T)^2}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S}" class="latex" title="{ S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ T}" class="latex" title="{ T}" /> are the question sets. So each question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> and answer <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> can be either for Alice or Bob — we indicate this by changing notation from <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ct%29%5Cin+S%5Ctimes+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,t)\in S\times T}" class="latex" title="{ (s,t)\in S\times T}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'\in S\cup T}" class="latex" title="{ q,q'\in S\cup T}" /> and for the answers replacing <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> by <img src="https://s0.wp.com/latex.php?latex=%7B+c%2Cc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c,c'}" class="latex" title="{ c,c'}" />.

<br />Definition 5 (Block-matrix form) <em><a name="to_matrix"></a> Given a function <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" class="latex" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot)}" /> defined on <img src="https://s0.wp.com/latex.php?latex=%7B+%28S%5Ccup+T%29%5E2%5Ctimes+%5CSigma%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (S\cup T)^2\times \Sigma^2}" class="latex" title="{ (S\cup T)^2\times \Sigma^2}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+%7CS%7C%3D%7CT%7C%3Dn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |S|=|T|=n}" class="latex" title="{ |S|=|T|=n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5CSigma%7C%3Dk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\Sigma|=k}" class="latex" title="{ |\Sigma|=k}" />, define a <img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> whose rows are indexed by pairs <img src="https://s0.wp.com/latex.php?latex=%7B+%28q%2Cc%29%5Cin%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (q,c)\in(S\cup T)\times\Sigma}" class="latex" title="{ (q,c)\in(S\cup T)\times\Sigma}" /> and columns by pairs <img src="https://s0.wp.com/latex.php?latex=%7B+%28q%27%2Cc%27%29%5Cin+%28S%5Ccup+T%29%5Ctimes%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (q',c')\in (S\cup T)\times\Sigma}" class="latex" title="{ (q',c')\in (S\cup T)\times\Sigma}" />, and whose entries are </em>

<em>
<img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28q%2Cc%29%2C%28q%27%2Cc%27%29%7D%3D%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" class="latex" title="{ M^{\tilde{P}}_{(q,c),(q',c')}=\tilde{P}(c,c'|q,q') }" /></em>

<em>
</em><em></em><em> In other words <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> consists of <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> blocks where the block <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" title="{ M^{\tilde{P}}_{q,q'}}" /> at position <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'}" class="latex" title="{ q,q'}" /> contains the entries <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7Cq%2Cq%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}(\cdot\cdot|q,q')}" class="latex" title="{ \tilde{P}(\cdot\cdot|q,q')}" />. </em><br />
Definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a> is simply a convenient change of notation and we identify <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" />, using either notation depending on the context.
<br />Definition 6 (Pseudo-strategies) <em><a name="Sdef"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7B+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ S}" class="latex" title="{ S}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ T}" class="latex" title="{ T}" /> be the question sets for Alice and Bob, respectively. We say that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%3D%5Ctilde%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes+%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" class="latex" title="{ \tilde{P}=\tilde{P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times (S\cup T)^2\rightarrow[0,1]}" /> (or its matrix form <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" />) is a pseudo-strategy if: </em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em></em>

<em>
<ol>
 	<li> <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> is positive semidefinite.<a name="positive"></a></li>
 	<li> For any pair of questions <img src="https://s0.wp.com/latex.php?latex=%7B+q%2Cq%27%5Cin+S%5Ccup+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ q,q'\in S\cup T}" class="latex" title="{ q,q'\in S\cup T}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Csum_%7Bc%2Cc%27%3D1%7D%5Ek+%5Ctilde%7BP%7D%28c%2Cc%27%7Cq%2Cq%27%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" class="latex" title="{ \sum_{c,c'=1}^k \tilde{P}(c,c'|q,q')=1}" />.<a name="sum1"></a></li>
 	<li> The blocks <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{q,q'}}" class="latex" title="{ M^{\tilde{P}}_{q,q'}}" /> on the diagonal are themselves diagonal <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> matrices.<a name="diagonal"></a></li>
</ol>
</em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em></em><em> </em>
Define the winning probability or value of a pseudo-strategy as:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29%3D%5Cmathbb+E_%7B%28s%2Ct%29%5Csim+%5CPi%7D+%5Csum_%7Ba%2Cb%7D+%5Ctilde%7BP%7D%28a%2Cb%7Cs%2Ct%29V%28a%2Cb%7Cs%2Ct%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" class="latex" title="{ \omega^{\tilde{P}}(G)=\mathbb E_{(s,t)\sim \Pi} \sum_{a,b} \tilde{P}(a,b|s,t)V(a,b|s,t) }" />

The algorithm outputs the maximum winning probability:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D%5Comega%5E%7B%5Ctilde%7BP%7D%7D%28G%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" class="latex" title="{ \hat\omega(G)=\max_{\tilde{P}\in\mathcal S}\omega^{\tilde{P}}(G) }" />

over pseudo-strategies <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}\in \mathcal S}" class="latex" title="{ \tilde{P}\in \mathcal S}" />. This maximum is efficiently computable using standard semidefinite programming algorithms. As we will see, actual quantum strategies are in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> which immediately implies <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%5Cge%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)\ge\omega^*(G)}" class="latex" title="{ \hat\omega(G)\ge\omega^*(G)}" />. It then remains to show that the optimal pseudo-strategy can be approximated by an actual entangled strategy, thus bounding the gap from <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)}" class="latex" title="{ \hat\omega(G)}" />.
<h3> Quantum strategies are in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /></h3>
Let us establish that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal S}" class="latex" title="{ \mathcal S}" /> is indeed a relaxation of the class of quantum strategies, that is, it contains the quantum strategies. So suppose we are given a quantum strategy. By equation <a href="https://windowsontheory.org/feed/#Qstrategy">1</a> the probability of answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a}" class="latex" title="{ a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" /> given questions <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> is of the form

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%3D%5Clangle%5Cphi%7C%28A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29%28%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_b+%29%7C%5Cphi%5Crangle+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" class="latex" title="{ \langle\phi|A^s_a\otimes B^t_b |\phi\rangle=\langle\phi|(A^s_a\otimes {\mathbb{I}})({\mathbb{I}}\otimes B^t_b )|\phi\rangle }" />

for some PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> and some <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%5Cin%5Cmathbb+C%5Ed%5Cotimes%5Cmathbb+C%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" class="latex" title="{ |\phi\rangle\in\mathbb C^d\otimes\mathbb C^d}" />. This conditional probability distibution is not immediately in the form of a pseudo-strategy because we cannot evaluate it on pairs of Alice-questions or pairs of Bob-questions. We therefore have to extend it, as follows: Place all the column vectors <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" class="latex" title="{ A^s_a\otimes {\mathbb{I}}|\phi\rangle}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%28s%2Ca%29%5Cin+S%5Ctimes+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (s,a)\in S\times \Sigma}" class="latex" title="{ (s,a)\in S\times \Sigma}" /> side by side, and then append the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+I%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ I\otimes B^t_b|\phi\rangle}" class="latex" title="{ I\otimes B^t_b|\phi\rangle}" />, resulting in a <img src="https://s0.wp.com/latex.php?latex=%7B+d%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d^2}" class="latex" title="{ d^2}" />-by-<img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R}" class="latex" title="{ R}" />. We then define <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%28%5Ccdot%5Ccdot%7C%5Ccdot%5Ccdot%29%3A%5CSigma%5E2%5Ctimes%28S%5Ccup+T%29%5E2%5Crightarrow%5B0%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" class="latex" title="{ {P}(\cdot\cdot|\cdot\cdot):\Sigma^2\times(S\cup T)^2\rightarrow[0,1]}" /> through its matrix form (see the comment below definition <a href="https://windowsontheory.org/feed/#to_matrix">5</a>): <a name="eqMp"></a>
<p align="center"><a name="eqMp"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++M%5E%7BP%7D%3A%3DR%5E%5Cdag+R%3D%5Cbegin%7Bpmatrix%7D+%28%5Clangle%5Cphi%7CA%5Es_a+A%5E%7Bs%27%7D_%7Ba%27%7D%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28s%27%2Ca%27%29%7D+%28%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b+%7C%5Cphi%5Crangle%29_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D+%5C%5C%5C%5C+%28%5Clangle%5Cphi%7CB%5Et_b%5Cotimes+A%5Es_a+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28s%2Ca%29%7D+%28%5Clangle%5Cphi%7C%7B%5Cmathbb%7BI%7D%7D%5Cotimes+B%5Et_bB%5E%7Bt%27%7D_%7Bb%27%7D+%7C%5Cphi%5Crangle%29_%7B%28t%2Cb%29%2C%28t%27%2Cb%27%29%7D+%5Cend%7Bpmatrix%7D+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" class="latex" title="\displaystyle  M^{P}:=R^\dag R=\begin{pmatrix} (\langle\phi|A^s_a A^{s'}_{a'}\otimes {\mathbb{I}} |\phi\rangle)_{(s,a),(s',a')} (\langle\phi|A^s_a\otimes B^t_b |\phi\rangle)_{(s,a),(t,b)} \\\\ (\langle\phi|B^t_b\otimes A^s_a |\phi\rangle)_{(t,b),(s,a)} (\langle\phi|{\mathbb{I}}\otimes B^t_bB^{t'}_{b'} |\phi\rangle)_{(t,b),(t',b')} \end{pmatrix} \ \ \ \ \ (2)" /></a></p>
<a name="eqMp">
</a><a name="eqMp"></a>
<b>Lemma 7</b> <em><a name="relaxation"></a> <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}}" class="latex" title="{ M^{P}}" /> defined in <a href="https://windowsontheory.org/feed/#eqMp">2</a> is a pseudo-strategy, that is, <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}\in\mathcal S}" class="latex" title="{ M^{P}\in\mathcal S}" />. </em>
<em><br />Proof.</em> We verify the conditions in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a>. Condition <a href="https://windowsontheory.org/feed/#positive">1</a> (<img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D%5Csucceq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}\succeq0}" class="latex" title="{ M^{P}\succeq0}" />) holds because it is of the form <img src="https://s0.wp.com/latex.php?latex=%7B+R%5E%5Cdag+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R^\dag R}" class="latex" title="{ R^\dag R}" />. Condition <a href="https://windowsontheory.org/feed/#sum1">2</a> (Each block <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7BP%7D_%7Bq%2Cq%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{P}_{q,q'}}" class="latex" title="{ M^{P}_{q,q'}}" /> sums to <img src="https://s0.wp.com/latex.php?latex=%7B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1}" class="latex" title="{ 1}" />) holds because PVM’s sum to the identity. Condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> (Diagonal blocks <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DM%5E%7BP%7D_%7Bqq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde M=M^{P}_{qq}}" class="latex" title="{ \tilde M=M^{P}_{qq}}" /> are diagonal) holds because the projections in the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Eq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^q}" class="latex" title="{ A^q}" /> are mutually orthogonal, hence <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%7B%5Cphi%7D%7C+A%5Eq_cA%5Eq_%7Bc%27%7D+%7C%7B%5Cphi%7D%5Crangle+%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" class="latex" title="{ \langle{\phi}| A^q_cA^q_{c'} |{\phi}\rangle =0}" /> if <img src="https://s0.wp.com/latex.php?latex=%7B+c%5Cneq+c%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c\neq c'}" class="latex" title="{ c\neq c'}" />. 
<div align="right">□</div>
Lemma <a href="https://windowsontheory.org/feed/#relaxation">7</a> means <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%28G%29%3D%5Cmax_%7B%7BP%7D%5Cin+%5Cmathcal+S%7D%5Comega%5E%7BP%7D%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" class="latex" title="{ \hat\omega(G)=\max_{{P}\in \mathcal S}\omega^{P}(G)}" /> is an (efficiently computable) upper bound for <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G)}" class="latex" title="{ \omega^*(G)}" />:
<h4>Corollary</h4><em> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat%5Comega%5Cge+%5Comega%5E%2A%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat\omega\ge \omega^*(G)}" class="latex" title="{ \hat\omega\ge \omega^*(G)}" />. </em>



<br />To finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a> we need to show that any pseudo-strategy <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" /> can be <em>rounded</em> to an actual quantum strategy with answer probabilities <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> such that <a name="roundingobjective"></a>
<p align="center"><a name="roundingobjective"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1-%5Comega%5E%7BP%7D%5Cle+6%281-%5Comega%5E%7B%5Ctilde+P%7D%29+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" class="latex" title="\displaystyle  1-\omega^{P}\le 6(1-\omega^{\tilde P}) \ \ \ \ \ (3)" /></a></p>
<a name="roundingobjective">
</a><a name="roundingobjective"></a> Applying this rounding to the optimal pseudo-strategy implies that

<img src="https://s0.wp.com/latex.php?latex=%7B+1-%5Comega%5E%2A%5Cle+6%281-%5Chat%5Comega%29+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 1-\omega^*\le 6(1-\hat\omega) }" class="latex" title="{ 1-\omega^*\le 6(1-\hat\omega) }" />

or <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%5Cge+1-6%281-%5Chat%5Comega%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*\ge 1-6(1-\hat\omega)}" class="latex" title="{ \omega^*\ge 1-6(1-\hat\omega)}" />, which will finish the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.

<em><br /><b>Proof.</b></em>[Proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>] Let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%5Cin%5Cmathcal+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}\in\mathcal S}" class="latex" title="{ \tilde{P}\in\mathcal S}" /> be a pseudo-strategy. We construct a quantum strategy <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> approximating <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{P}}" class="latex" title="{ \tilde{P}}" />. Since <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}}" class="latex" title="{ M^{\tilde{P}}}" /> is positive semidefinite we can write

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde+M%3DR%5E%5Cdag+R+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde M=R^\dag R }" class="latex" title="{ \tilde M=R^\dag R }" />

for <em>some</em> matrix <img src="https://s0.wp.com/latex.php?latex=%7B+R%5Cin+%5Cmathbb+C%5E%7Br%5Ctimes+2nk%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ R\in \mathbb C^{r\times 2nk}}" class="latex" title="{ R\in \mathbb C^{r\times 2nk}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+r%5Cleq+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ r\leq 2nk}" class="latex" title="{ r\leq 2nk}" />. Now let us define <img src="https://s0.wp.com/latex.php?latex=%7B+2nk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 2nk}" class="latex" title="{ 2nk}" /> vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+u%5Es_a%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\tilde u^s_a\rangle}" class="latex" title="{ |\tilde u^s_a\rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Ctilde+v%5Et_b%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\tilde v^t_b\rangle}" class="latex" title="{ |\tilde v^t_b\rangle}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathbb+C%5E%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathbb C^{r}}" class="latex" title="{ \mathbb C^{r}}" />, and let <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_a%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{u^s_a}\rangle}" class="latex" title="{ |{u^s_a}\rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bv%5Et_b%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{v^t_b}\rangle}" class="latex" title="{ |{v^t_b}\rangle}" /> be the same vectors normalized. The strategy is constructed as follows. Alice and Bob share the maximally entangled state

<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle%3D%5Cfrac1%7B%5Csqrt+r%7D%5Csum_%7Bi%3D1%7D%5Er%7Ci%5Crangle%7Ci%5Crangle%5Cin%5Cmathbb+C%5Er%5Cotimes%5Cmathbb+C%5Er+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" class="latex" title="{ |\phi\rangle=\frac1{\sqrt r}\sum_{i=1}^r|i\rangle|i\rangle\in\mathbb C^r\otimes\mathbb C^r }" />

Before deciding on Alice and Bob’s PVM’s <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s}" class="latex" title="{ A^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> let us see what this choice of shared state means for the conditional distribution on answers (see equation <a href="https://windowsontheory.org/feed/#Qstrategy">(1)</a>).
<p align="center"> <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cphi%7C+A%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle+%3D%5Cfrac1r%5Csum_%7Bi%2Cj%3D1%7D%5Er%5Clangle+i+%7C+A%5Es_a%7C+j%5Crangle%5Clangle+i+%7C+B%5Et_b%7C+j%5Crangle+%3D%5Cfrac1r+A%5Es_a%5Ccdot+B%5Et_b%3D%5Cfrac1r%5Clangle+A%5Es_a%2C%5Coverline%7BB%5Et_b%7D%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" class="latex" title="\langle\phi| A^s_a\otimes B^t_b|\phi\rangle =\frac1r\sum_{i,j=1}^r\langle i | A^s_a| j\rangle\langle i | B^t_b| j\rangle =\frac1r A^s_a\cdot B^t_b=\frac1r\langle A^s_a,\overline{B^t_b}\rangle" />, (*)</p>
where the bar represents entrywise complex conjugation, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ccdot%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \cdot}" class="latex" title="{ \cdot}" /> is the entrywise dot product of matrices, and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5C%3A%2C%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\:,\rangle}" class="latex" title="{ \langle\:,\rangle}" /> the entrywise complex inner product (Hilbert-Schmidt inner product).

We now choose the measurements. Given question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" />, Alice measures in the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es%3D%28A%5Es_a%29_%7Ba%3D0%7D%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s=(A^s_a)_{a=0}^k}" class="latex" title="{ A^s=(A^s_a)_{a=0}^k}" /> with

<img src="https://s0.wp.com/latex.php?latex=%7B+A%5Es_a%3D+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%5Ctext%7B+for+%7Da%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DA%5Es_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7Bu%5Es_a%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" class="latex" title="{ A^s_a= |{u^s_a}\rangle \langle{u^s_a}| \text{ for }a=1,\ldots,k\text{, and }A^s_0={\mathbb{I}}-\sum_{i=1}^k |{u^s_a}\rangle \langle{u^s_a}| }" />

Similarly, Bob on question <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> applies the PVM <img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t}" class="latex" title="{ B^t}" /> with

<img src="https://s0.wp.com/latex.php?latex=%7B+B%5Et_b%3D+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%5Ctext%7B+for+%7Db%3D1%2C%5Cldots%2Ck%5Ctext%7B%2C+and+%7DB%5Et_0%3D%7B%5Cmathbb%7BI%7D%7D-%5Csum_%7Bi%3D1%7D%5Ek+%7C%7Bv%5Et_b%7D%5Crangle+%5Clangle%7Bv%5Et_b%7D%7C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" class="latex" title="{ B^t_b= |{v^t_b}\rangle \langle{v^t_b}| \text{ for }b=1,\ldots,k\text{, and }B^t_0={\mathbb{I}}-\sum_{i=1}^k |{v^t_b}\rangle \langle{v^t_b}| }" />

The condition <a href="https://windowsontheory.org/feed/#diagonal">3</a> in definition <a href="https://windowsontheory.org/feed/#Sdef">6</a> ensures that for any question <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" />, the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7Bu%5Es_1%7D%5Crangle+%2C%5Cldots%2C+%7C%7Bu%5Es_1%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" class="latex" title="{ |{u^s_1}\rangle ,\ldots, |{u^s_1}\rangle}" /> are orthogonal so that this is a valid PVM.

The measurement outcome “<img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />” is interpreted as “fail”, and upon getting this outcome the player attempts the measurement again on their share of a fresh copy of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle_{AB}}" class="latex" title="{ |\phi\rangle_{AB}}" />. This means that the strategy requires many copies of the entangled state to be shared before the game starts. It also leads to the complication of ensuring that with high probability the players measure the same number of times before outputting their measurement, so that the outputs come from measuring the same entangled state.

By (*), at a given round of measurements the conditional distribution of answers is given by

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Clangle%5Cphi%7CA%5Es_a%5Cotimes+B%5Et_b%7C%5Cphi%5Crangle%3D%5Cfrac1r%5CBig%5Clangle+%7C%7Bu%5Es_a%7D%5Crangle+%5Clangle%7B+u%5Es_a%7D%7C+%5C%3A%2C%5C%3A+%7C%7B%7Bv%5Et_b%7D%5Crangle+%7D+%5Clangle%7B+%7Bv%5Et_b%7D%7C+%7D%5CBig%5Crangle%3D%5Cfrac1r%7C%5Clangle+%7Bu%5Es_a%7D%7Cv%5Et_b%5Crangle%7C%5E2%3D%5Cfrac1%7Br%7C%5Ctilde+u%5Es_a%7C%5E2%7C%5Ctilde+v%5Et_b%7C%5E2%7D%5CBig%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29%5E2%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" class="latex" title="{ \langle\phi|A^s_a\otimes B^t_b|\phi\rangle=\frac1r\Big\langle |{u^s_a}\rangle \langle{ u^s_a}| \:,\: |{{v^t_b}\rangle } \langle{ {v^t_b}| }\Big\rangle=\frac1r|\langle {u^s_a}|v^t_b\rangle|^2=\frac1{r|\tilde u^s_a|^2|\tilde v^t_b|^2}\Big(M^{\tilde{P}}_{(s,a),(t,b)}\Big)^2, }" />

We wish to relate the LHS to <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(s,a),(t,b)}}" class="latex" title="{ M^{\tilde{P}}_{(s,a),(t,b)}}" />, so to handle the factor <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1r}" class="latex" title="{ \frac1r}" /> each prover performs repeated measurements, each time on a fresh copy of <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%5Cphi%5Crangle_%7BAB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |\phi\rangle_{AB}}" class="latex" title="{ |\phi\rangle_{AB}}" />, until getting an outcome <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cneq0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \neq0}" class="latex" title="{ \neq0}" />. Moreover, to handle the factor <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cfrac1%7B%7Cu%5Es_a%7C%5E2%7Cv%5Et_b%7C%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \frac1{|u^s_a|^2|v^t_b|^2}}" class="latex" title="{ \frac1{|u^s_a|^2|v^t_b|^2}}" />, each prover consults public randomness and accepts the answer <img src="https://s0.wp.com/latex.php?latex=%7B+a%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a\in[k]}" class="latex" title="{ a\in[k]}" /> with probability <img src="https://s0.wp.com/latex.php?latex=%7B+%7Cu%5Ea_s%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |u^a_s|^2}" class="latex" title="{ |u^a_s|^2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%7Cv%5Eb_t%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |v^b_t|^2}" class="latex" title="{ |v^b_t|^2}" /> respectively, or rejects and start over depending on the public randomness. Under a few simplifying conditions (more precisely, assuming that the game is <em>uniform</em> meaning that an optimal strategy exists where the marginal distribution on each prover’s answers is uniform), we can let <img src="https://s0.wp.com/latex.php?latex=%7B+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cle+1%2Fk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" class="latex" title="{ M^{\tilde{P}}_{(s,a),(t,b)}\le 1/k}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7B+s%2Ca%2Ct%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s,a,t,b}" class="latex" title="{ s,a,t,b}" />, and one can ensure that the conditional probabilities <img src="https://s0.wp.com/latex.php?latex=%7B+%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {P}}" class="latex" title="{ {P}}" /> of the final answers satisfy
<p align="center">
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+1%2Fk-P%28a%2Cb%7Cs%2Ct%29%5Cle+3%5Cbig%281%2Fk-k%28M%5E%7B%5Ctilde+P%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2%5Cbig%29%2C%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" class="latex" title="\displaystyle 1/k-P(a,b|s,t)\le 3\big(1/k-k(M^{\tilde P}_{(s,a),(t,b)})^2\big),\ \ \ \ \ (4)" />
<a name="PM"></a>

At this stage it is important that we are dealing with a <em>unique game</em> . Indeed, by <a href="https://windowsontheory.org/feed/#PM">(4)</a> we have for every <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" />,

<img src="https://s0.wp.com/latex.php?latex=1-%5Csum_%7Ba%3D1%7D%5Ek+P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29%3D%5Csum_a+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-P%28a%2C%5Cpi_%7Bst%7D%28a%29%7Cs%2Ct%29+%5CBig%29+%5C%5C+%5Cleq+3%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+%5CBig%28%5Cfrac%7B1%7D%7Bk%7D-k%28M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%29%5E2+%5CBig%29+%5C%5C+%5Cleq+6%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D%5Cbig%28%5Cfrac%7B1%7D%7Bk%7D-M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5Cbig%29%3D6%5CBig%281-%5Csum_%7Bb%3D%5Cpi_%7Bst%7D%28a%29%7D+M%5E%7B%5Ctilde%7BP%7D%7D_%7B%28s%2Ca%29%2C%28t%2Cb%29%7D%5CBig%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " class="latex" title="1-\sum_{a=1}^k P(a,\pi_{st}(a)|s,t)=\sum_a \Big(\frac{1}{k}-P(a,\pi_{st}(a)|s,t) \Big) \\ \leq 3\sum_{b=\pi_{st}(a)} \Big(\frac{1}{k}-k(M^{\tilde{P}}_{(s,a),(t,b)})^2 \Big) \\ \leq 6\sum_{b=\pi_{st}(a)}\big(\frac{1}{k}-M^{\tilde{P}}_{(s,a),(t,b)}\big)=6\Big(1-\sum_{b=\pi_{st}(a)} M^{\tilde{P}}_{(s,a),(t,b)}\Big) " />

where the last inequality follows from concavity. Taking the expectation over <img src="https://s0.wp.com/latex.php?latex=%7B+s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ s}" class="latex" title="{ s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t}" class="latex" title="{ t}" /> implies the bound <a href="https://windowsontheory.org/feed/#roundingobjective">(3)</a>, thus concluding the proof of theorem <a href="https://windowsontheory.org/feed/#efficientUGC">4</a>.
</p><div align="right">□</div>
<h2>General games are hard</h2>
We just saw that a specific class of games becomes easy in the presence of shared entanglement, in that semidefinite programming allows the entangled value <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*}" class="latex" title="{ \omega^*}" /> to be approximated to within exponential precision in polynomial time. Does this phenomenon hold more generally, so that the value of entangled games can always be efficiently approximated? We answer in the negative, by constructing a game where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*}" class="latex" title="{ \omega^*}" /> is NP-hard to approximate to within inverse-polynomial factors. The complexity for 2P-1R entangled games can be strengthened to constant-factor NP-hardness, putting it on par with the classical PCP theorem. This result is used to prove (with some conditions) the games formulation of the quantum PCP theorem, which states that the entangled value of general games is QMA-hard to approximate within a constant factor.
<h3> Formulation of game</h3>
Given any instance <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" /> of a <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP (constraint satisfaction problem, where <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> is the number of literals), we can define a clause-vs-variable game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> (see clause-vs-variable figure):
<ol>
 	<li> The referee (verifier) randomly sends a clause to Alice (first prover) and a variable to Bob (second prover).</li>
 	<li> Alice and Bob reply with assignments.</li>
 	<li> The referee accepts if Alice’s assignment satisfies the clause and Bob’s answer is consistent with Alice’s.</li>
</ol>
To show hardness of approximation, we need to go beyond the usual 2-player construction. In particular, in our game [3] one of the players receives an extra dummy question (see subfigure (a)). Mathematically, the result is very similar to introducing another player and having the referee play the 2-player game with two players chosen randomly [4] (see subfigure (b)). In either variation, the quantum phenomenon of <em>monogamy of entanglement</em> , imposing that only two parties can be maximally entangled to one another, is key to establishing hardness. The players do not know where to use their entanglement, which prevents them from coordinating as well as they could in the standard game.
<figure style="width: 25em; margin: auto;">  
<a href="https://windowsontheory.org/?attachment_id=7233"><img width="107" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/2player.png?w=107&amp;h=150" class="attachment-thumbnail size-thumbnail" height="150" /></a>
<a href="https://windowsontheory.org/?attachment_id=7234"><img width="107" alt="" src="https://windowsontheory.files.wordpress.com/2019/01/3player.png?w=107&amp;h=150" class="attachment-thumbnail size-thumbnail" height="150" /></a>


Two variations of a 2-player clause-vs-variable game; new features are in red and shared entanglement is denoted in blue. In the standard game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" />, given <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%3D%28C_1%2C%5Cldots%2CC_m%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi=(C_1,\ldots,C_m)}" class="latex" title="{ \phi=(C_1,\ldots,C_m)}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> variables <img src="https://s0.wp.com/latex.php?latex=%7B+x_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ x_i}" class="latex" title="{ x_i}" />, (1) the referee R randomly sends a clause <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> to Alice A and a literal index <img src="https://s0.wp.com/latex.php?latex=%7B+t%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t\in[k]}" class="latex" title="{ t\in[k]}" /> to Bob B, (2) A replies with an assignment <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)}" class="latex" title="{ (a_1,\ldots,a_k)}" /> and B replies with assignment <img src="https://s0.wp.com/latex.php?latex=%7B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b}" class="latex" title="{ b}" />, (3) R accepts iff <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)}" class="latex" title="{ (a_1,\ldots,a_k)}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+a_t%3Db%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_t=b}" class="latex" title="{ a_t=b}" />. In variation (a), R sends an additional dummy index <img src="https://s0.wp.com/latex.php?latex=%7B+l%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ l\in[k]}" class="latex" title="{ l\in[k]}" />, so that B replies with an additional assignment <img src="https://s0.wp.com/latex.php?latex=%7B+b%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b'}" class="latex" title="{ b'}" />, but he does not know which is the right variable. Equivalently, in (b) a third player Charlie C is introduced, but <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> is played with two randomly chosen players. Since only parties can be maximally entangled and the players do not know who is playing the game, they cannot coordinate perfectly. </figure>
<h3> NP-hardness of approximating the entangled value</h3>
To prove hardness, we rely on several results from classical complexity theory.
<br />Theorem 8 ([6]) <em> Given an instance of 1-in-3 3SAT (a CSP), it is NP-hard to distinguish whether it is satisfiable or no assignments satisfy more than a constant fraction of clauses. <a name="thmCSP"></a> </em>
<br />Theorem 9 ([2]) <em> For a PCP game <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> (emulating the CSP) and its oracularization <img src="https://s0.wp.com/latex.php?latex=%7BG%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G'}" class="latex" title="{G'}" /> (transformation to a 2P-1R game), </em>

<p align="center"><em><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%28G%29%5Cleq+%5Comega%28G%27%29%5Cleq+1-%5Cfrac%7B1-%5Comega%28G%29%7D%7B3%7D%5C%2C.+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" class="latex" title="\displaystyle  \omega(G)\leq \omega(G')\leq 1-\frac{1-\omega(G)}{3}\,. \ \ \ \ \ (5)" /></em></p>
<em>
</em><em> <a name="thmMIP"></a> </em>
Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a> establishes the CSP variant of the classical PCP theorem: distinguishing between <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)=1}" class="latex" title="{ \omega(\phi)=1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq 1/2}" class="latex" title="{ \omega(\phi)\leq 1/2}" /> is NP-hard for some <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" />-CSP. Here, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)}" class="latex" title="{ \omega(\phi)}" /> denotes the maximum fraction of clauses that are simultaneously satisfiable. Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> relates the general game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" /> obtained from the CSP to a two-player one-round game <img src="https://s0.wp.com/latex.php?latex=%7B+G%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G'}" class="latex" title="{ G'}" />, in terms of the value (probability of winning) the game. The first inequality, equivalently saying <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq \omega(G_\phi)}" class="latex" title="{ \omega(\phi)\leq \omega(G_\phi)}" />, is achieved since the players can answer the questions in the game <img src="https://s0.wp.com/latex.php?latex=%7B+G_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G_\phi}" class="latex" title="{ G_\phi}" /> to satisfy the clauses in <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" />. These theorems together imply that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(G_\phi)}" class="latex" title="{ \omega(G_\phi)}" /> is NP-hard to approximate to within constant factors.

Allowing the two players to share entanglement can increase the game value to <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%5Cgeq+%5Comega%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" class="latex" title="{ \omega^*(G_\phi)\geq \omega(G_\phi)}" />. Classical results do not necessarily carry over, but exploiting monogamy of entanglement allows us to limit the power of entangled strategies. One can show the following lemma, which is weaker than what we have classically.
<br /><b>Lemma 10 ([3])</b> <em> There exists a constant <img src="https://s0.wp.com/latex.php?latex=%7Bc%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c&gt;0}" class="latex" title="{c&gt;0}" /> such that for a CSP <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" />, </em>
<p align="center"><em><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C%2C+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" class="latex" title="\displaystyle  \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,, \ \ \ \ \ (6)" /></em></p>
<em>
</em><em> where <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is the number of variables. <a name="lemmaIto"></a> </em>
Combining Theorem <a href="https://windowsontheory.org/feed/#thmMIP">9</a> and Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a>, we have

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%28%5Cphi%29%5Cleq+%5Comega%5E%2A%28G_%5Cphi%29%5Cleq+1+-+%5Cfrac%7Bc%281-%5Comega%28%5Cphi%29%29%5E2%7D%7Bn%5E2%7D%5C%2C.+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" class="latex" title="{ \omega(\phi)\leq \omega^*(G_\phi)\leq 1 - \frac{c(1-\omega(\phi))^2}{n^2}\,. }" />

Using Theorem <a href="https://windowsontheory.org/feed/#thmCSP">8</a>, approximating <img src="https://s0.wp.com/latex.php?latex=%7B+%5Comega%5E%2A%28G_%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \omega^*(G_\phi)}" class="latex" title="{ \omega^*(G_\phi)}" /> is NP-hard to within inverse polynomial factors. Proving Lemma <a href="https://windowsontheory.org/feed/#lemmaIto">10</a> takes some work in keeping track of approximations. For simplicity, we will show a less quantitative statement and indicate where the approximations come in.
<br />Proposition 11 (adapted from [13]) <em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> is satisfiable iff <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%5E%2A%28G_%5Cphi%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\omega^*(G_\phi)=1}" class="latex" title="{\omega^*(G_\phi)=1}" />. <a name="proposition"></a> </em>
<h3> Proof of Proposition <a href="https://windowsontheory.org/feed/#proposition">11</a></h3>
The forward direction is straightforward: If <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \phi}" class="latex" title="{ \phi}" /> is satisfiable, then there exists a perfect winning strategy where the questions are answered according to the satisfying assignment.

For the reverse direction, suppose there exists a strategy that succeeds with probability 1, specified by a shared entangled state <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%5Cin%5Cmathbb%7BC%7D%5Ed%5Cotimes%5Cmathbb%7BC%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" class="latex" title="{ |{\psi}\rangle \in\mathbb{C}^d\otimes\mathbb{C}^d}" /> and measurements <img src="https://s0.wp.com/latex.php?latex=%7B+%28A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%29_%7Ba_1%2C%5Cldots%2Ca_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" class="latex" title="{ (A^j_{a_1,\ldots,a_k})_{a_1,\ldots,a_k}}" /> for Alice and <img src="https://s0.wp.com/latex.php?latex=%7B+%28B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%29_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (B^{t,l}_{b,b'})_{b,b'}}" class="latex" title="{ (B^{t,l}_{b,b'})_{b,b'}}" /> for Bob, where the questions <img src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ j\in[m]}" class="latex" title="{ j\in[m]}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+t%2Cl%5Cin%5Bk%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t,l\in[k]}" class="latex" title="{ t,l\in[k]}" /> and the answers <img src="https://s0.wp.com/latex.php?latex=%7B+a%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a,b}" class="latex" title="{ a,b}" /> are from the CSP’s alphabet. Since one of the questions/answers for Bob corresponds to a dummy variable that is irrelevant to the game, trace over the dummy variable to define a new measurement operator <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5Et_b%3D%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl%2Cb%27%7D+B%5E%7Bt%2Cl%7D_%7Bb%2Cb%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" class="latex" title="{ \tilde{B}^t_b=\frac{1}{n}\sum_{l,b'} B^{t,l}_{b,b'}}" />. We can introduce a distribution on assignments to the <img src="https://s0.wp.com/latex.php?latex=%7B+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ n}" class="latex" title="{ n}" /> relevant variables,

<a name="eqpB"></a>
<p align="center"><a name="eqpB"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D%5Ccdots%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C.++%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" class="latex" title="\displaystyle  p(a_1,\ldots,a_n)=\lVert \mathbb{I} \otimes \tilde{B}^1_{a_1}\cdots\tilde{B}^n_{a_n} |\psi\rangle \rVert^2\,.  \ \ \ \ \ (7)" /></a></p>
<a name="eqpB">
</a><a name="eqpB"></a> If we show that the distribution for assignments <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_{i_1},\ldots,a_{i_k}}" class="latex" title="{a_{i_1},\ldots,a_{i_k}}" /> on variables <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi_1%7D%2C%5Cldots%2Cx_%7Bi_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i_1},\ldots,x_{i_k}}" class="latex" title="{x_{i_1},\ldots,x_{i_k}}" /> in any clause <img src="https://s0.wp.com/latex.php?latex=%7BC_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_j}" class="latex" title="{C_j}" /> is <a name="eqpA"></a>
<p align="center"><a name="eqpA"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%5CrVert%5E2%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%288%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" class="latex" title="\displaystyle  p(a_{i_1},\ldots,a_{i_k})= \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes \mathbb{I} |\psi\rangle \rVert^2\,,  \ \ \ \ \ (8)" /></a></p>
<a name="eqpA">
</a><a name="eqpA"></a> then, since the players win with certainty, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> has a satisfying assignment. To transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a>, we need a relation between the <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{B}}" class="latex" title="{\tilde{B}}" /> measurement operators and a way to commute the <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{B}}" class="latex" title="{\tilde{B}}" /> operators.

The success probability of the players’ strategy is expressed as

<img src="https://s0.wp.com/latex.php?latex=%7B+P%3D%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bj%5Cin%5Bm%5D%7D%5Cfrac%7B1%7D%7Bk%7D%5Csum_%7Bi%5Cin+C_j%7D+%5Csum_%7B%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D+%5Clangle%7B%5Cpsi%7D%7C+A%5Ej_%7Ba_1%2C%5Cldots%2Ca_k%7D%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%2C%2C+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" class="latex" title="{ P=\frac{1}{m}\sum_{j\in[m]}\frac{1}{k}\sum_{i\in C_j} \sum_{(a_1,\ldots,a_k)\vdash C_j} \langle{\psi}| A^j_{a_1,\ldots,a_k}\otimes \tilde{B}^i_{a_i} |{\psi}\rangle \,, }" />

where <img src="https://s0.wp.com/latex.php?latex=%7B+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i}" class="latex" title="{ i}" /> is the index of one of the <img src="https://s0.wp.com/latex.php?latex=%7B+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ k}" class="latex" title="{ k}" /> variables on which <img src="https://s0.wp.com/latex.php?latex=%7B+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ C_j}" class="latex" title="{ C_j}" /> acts, and <img src="https://s0.wp.com/latex.php?latex=%7B+%28a_1%2C%5Cldots%2Ca_k%29%5Cvdash+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (a_1,\ldots,a_k)\vdash C_j}" class="latex" title="{ (a_1,\ldots,a_k)\vdash C_j}" /> indicates that the assignment satisfies the clause. By positivity and summation to identity of the measurement operators <img src="https://s0.wp.com/latex.php?latex=%7B+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A}" class="latex" title="{ A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}}" class="latex" title="{ \tilde{B}}" />, each term is at most 1; for our hypothesis <img src="https://s0.wp.com/latex.php?latex=%7B+P%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=1}" class="latex" title="{ P=1}" />, each has to be 1. Hence, using orthogonality of the vectors <img src="https://s0.wp.com/latex.php?latex=%7B+%7B%5Cmathbb%7BI%7D%7D%5Cotimes%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" class="latex" title="{ {\mathbb{I}}\otimes\tilde{B}^i_{a_i} |{\psi}\rangle}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+a_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_i}" class="latex" title="{ a_i}" />, we have <a name="eqrelation"></a>
<p align="center"><a name="eqrelation"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7B%5Csubstack%7B%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5Cvdash+C_j+%5C%5C+a_i%3Db%7D%7D+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D%5Cotimes+%5Cmathbb%7BI%7D+%7C%5Cpsi%5Crangle+%3D+%5Cmathbb%7BI%7D+%5Cotimes+%5Ctilde%7BB%7D%5Ei_%7Ba_i%7D%7C%5Cpsi%5Crangle%5C%2C%2C++%5C+%5C+%5C+%5C+%5C+%289%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" class="latex" title="\displaystyle  \sum_{\substack{(a_{i_1},\ldots,a_{i_k})\vdash C_j \\ a_i=b}} A^j_{a_{i_1},\ldots,a_{i_k}}\otimes \mathbb{I} |\psi\rangle = \mathbb{I} \otimes \tilde{B}^i_{a_i}|\psi\rangle\,,  \ \ \ \ \ (9)" /></a></p>
<a name="eqrelation">
</a><a name="eqrelation"></a> for any <img src="https://s0.wp.com/latex.php?latex=%7B+j%5Cin%5Bm%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ j\in[m]}" class="latex" title="{ j\in[m]}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+i%5Cin+C_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ i\in C_j}" class="latex" title="{ i\in C_j}" />.

We now demonstrate that two different <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^{t_1}_{b_1}}" class="latex" title="{ \tilde{B}^{t_1}_{b_1}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \tilde{B}^{t_2}_{b_2}}" class="latex" title="{ \tilde{B}^{t_2}_{b_2}}" /> commute, so that Bob can match any satisfied clause/variable.

<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%3D++%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_1%2Cb_1%27%7D+B%5E%7Bt_1%2Cl_1%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bl_2%2Cb_2%27%7D+B%5E%7Bt_2%2Cl_2%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_2%2Cb_1%27%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_1%27%7D%29+%28%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bt_1%2Cb_2%27%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_2%27%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Ct_2%7D+B%5E%7Bt_2%2Ct_1%7D_%7Bb_2%2Cb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+%5C%5C+%3D+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%7C%7B%5Cpsi%7D%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " class="latex" title="{\mathbb{I}} \otimes \tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} |{\psi}\rangle =  {\mathbb{I}} \otimes (\frac{1}{n}\sum_{l_1,b_1'} B^{t_1,l_1}_{b_1,b_1'}) (\frac{1}{n}\sum_{l_2,b_2'} B^{t_2,l_2}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes (\frac{1}{n}\sum_{t_2,b_1'} B^{t_1,t_2}_{b_1,b_1'}) (\frac{1}{n}\sum_{t_1,b_2'} B^{t_2,t_1}_{b_2,b_2'}) |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_1,t_2}_{b_1,b_2} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \frac{1}{n^2}\sum_{t_1,t_2} B^{t_2,t_1}_{b_2,b_1} |{\psi}\rangle \\ = {\mathbb{I}} \otimes \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1} |{\psi}\rangle " />

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate the measurements. The third line follows by the orthogonality of <img src="https://s0.wp.com/latex.php?latex=%7B+B%5E%7Bt_1%2Ct_2%7D_%7Bb_1%2Cb_2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B^{t_1,t_2}_{b_1,b_2}}" class="latex" title="{ B^{t_1,t_2}_{b_1,b_2}}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+b_1%2Cb_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ b_1,b_2}" class="latex" title="{ b_1,b_2}" />. For the fourth equation, we simply swap <img src="https://s0.wp.com/latex.php?latex=%7B+t_1%2Ct_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ t_1,t_2}" class="latex" title="{ t_1,t_2}" /> since the questions are indistinguishable to Bob. Thus, we can see how the dummy variable comes into play. If we had assumed <img src="https://s0.wp.com/latex.php?latex=%7B+P%3D1-%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P=1-\epsilon}" class="latex" title="{ P=1-\epsilon}" /> and kept track of approximations, we would find <a name="eqcommutation"></a>
<p align="center"><a name="eqcommutation"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bt_1%2Cb_1%7D%5Csum_%7Bt_2%2Cb_2%7D%5ClVert+%5Cmathbb%7BI%7D+%5Cotimes+%28%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+-+%5Ctilde%7BB%7D%5E%7Bt_2%7D_%7Bb_2%7D+%5Ctilde%7BB%7D%5E%7Bt_1%7D_%7Bb_1%7D%29+%7C%5Cpsi%5Crangle+%5CrVert%5E2+%3D+O%28%5Cepsilon%29%5C%2C.++%5C+%5C+%5C+%5C+%5C+%2810%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" class="latex" title="\displaystyle  \frac{1}{n^2}\sum_{t_1,b_1}\sum_{t_2,b_2}\lVert \mathbb{I} \otimes (\tilde{B}^{t_1}_{b_1} \tilde{B}^{t_2}_{b_2} - \tilde{B}^{t_2}_{b_2} \tilde{B}^{t_1}_{b_1}) |\psi\rangle \rVert^2 = O(\epsilon)\,.  \ \ \ \ \ (10)" /></a></p>
<a name="eqcommutation">
</a><a name="eqcommutation"></a> This approximate commutativity results in the hardness of approximation holding only to within inverse poly<img src="https://s0.wp.com/latex.php?latex=%7B+%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (n)}" class="latex" title="{ (n)}" /> factors.

Now we are ready to transform Eq. <a href="https://windowsontheory.org/feed/#eqpB">7</a> to Eq. <a href="https://windowsontheory.org/feed/#eqpA">8</a> to conclude the proof.

<img src="https://s0.wp.com/latex.php?latex=p%28a_1%2C%5Cldots%2Ca_n%29%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E1_%7Ba_1%7D+%5Cldots+%5Ctilde%7BB%7D%5En_%7Ba_n%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D%5ClVert+%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+%5Ctilde%7BB%7D%5E%7Bi_1%7D_%7Ba_%7Bi_1%7D%7D+%5Cldots+%5Ctilde%7BB%7D%5E%7Bi_k%7D_%7Ba_%7Bi_k%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3D+%5ClVert+A%5Ej_%7Ba_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%7D+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D+%7C%7B%5Cpsi%7D%5Crangle+%5CrVert%5E2+%5C%5C+%3Dp%28a_%7Bi_1%7D%2C%5Cldots%2Ca_%7Bi_k%7D%29%5C%2C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " class="latex" title="p(a_1,\ldots,a_n)=\lVert {\mathbb{I}} \otimes \tilde{B}^1_{a_1} \ldots \tilde{B}^n_{a_n} |{\psi}\rangle \rVert^2 \\ =\lVert {\mathbb{I}} \otimes \tilde{B}^{i_1}_{a_{i_1}} \ldots \tilde{B}^{i_k}_{a_{i_k}} |{\psi}\rangle \rVert^2 \\ = \lVert A^j_{a_{i_1},\ldots,a_{i_k}} \otimes {\mathbb{I}} |{\psi}\rangle \rVert^2 \\ =p(a_{i_1},\ldots,a_{i_k})\,. " />

In the second line, we used (<a href="https://windowsontheory.org/feed/#eqcommutation">10</a>) to commute the measurement operators, along with their properties of orthogonality and summation to identity. For the third equality, we used (<a href="https://windowsontheory.org/feed/#eqrelation">9</a>) to relate Bob’s measurements to Alice’s, along with orthogonality of <img src="https://s0.wp.com/latex.php?latex=%7B+A%5Ej_%7Ba_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A^j_{a_{i_1,\ldots,i_k}}}" class="latex" title="{ A^j_{a_{i_1,\ldots,i_k}}}" /> for different <img src="https://s0.wp.com/latex.php?latex=%7B+a_%7Bi_1%2C%5Cldots%2Ci_k%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ a_{i_1,\ldots,i_k}}" class="latex" title="{ a_{i_1,\ldots,i_k}}" />. 
<div align="right">□</div>
<h3> Constant-factor NP-hardness</h3>
The weakness in the above two-player game carries over from the original three-player variant. Thus, to achieve constant-factor NP-hardness of approximation, we could start with a different multiplayer game. Vidick [11] establishes the soundness of the “plane-vs-point” low-degree test (checking that the restriction of a low-degree polynomial to a plane matches its value at some point) in the presence of shared entanglement. <em> Soundness </em>, in the eponymous probabilistically checkable proof (PCP) formulation of the PCP theorem, refers to the verifier accepting a wrong proof with some bounded probability; bounding with a constant maps to constant-factor hardness of approximation. Here, soundness comes from a strong bound on error accumulation, similar to our approximate commutativity, but relies on the players’ Hilbert space being decomposable into three parts (i.e., there being three players). The particular game is constructed by combining the low-degree test with the 3-SAT test (encoding satisfying assignments in a low-degree polynomial), which can be reduced to the three-player QUADEQ test (testing satisfiability of a system of quadratic equations in binary variables, which is NP-complete). By the strong soundness result, the entangled value is NP-hard to approximate to within constant factors. Natarajan et al. [7] show that soundness holds even for two players, using a semidefinite program. They then construct a two-player game in a way similar to what we demonstrated.
<h3> Constant-factor QMA-hardness</h3>
The above can be thought of as the games formulation of the classical PCP theorem holding under shared entanglement. A true quantum PCP theorem states that the entangled value of general games is QMA-hard to approximate to within constant factors. Natarajan et al. [8] establish such a theorem, but under randomized reductions. This requirement stems from the lack of a sufficiently strong QMA-hardness result for local Hamiltonians (the quantum analog of CSPs). The soundness of the two-player low-degree test above is one instrumental component in the proof.
<h2>How much entanglement is needed?</h2>
We now focus on the question of quantifying exactly how much entanglement is needed to play XOR games optimally. As we shall see, the answer depends on the size of the question sets posed to Alice &amp; Bob in the game. The previous bound given by Tsirelson [10] (see table below) is tight for certain families of games, but is not tight for other families of games (such as a generalization of the CHSH game). The reason for this discrepancy is closely tied in with the the properties of the representation of the Observables that form the Optimal Strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />). Slofstra [9] shows that if the Observables constitute a Clifford Algebra (that is, the solutions are pair-wise anti-commutative), then the strategy is minimally entangled (uses the least number of entangled bits) iff the strategy is a unique solution to the SDP rounding problem. As a trivial corollary, if the SDP rounding problem does not have a unique solution (and a correspondingly unique strategy), then there exists a Non-Clifford optimal strategy that uses (atleast) <img src="https://s0.wp.com/latex.php?latex=%7B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |T|}" class="latex" title="{ |T|}" /> bits of entanglement less than the Clifford strategy. Slofstra further states that minimally entangled <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon}" class="latex" title="{ \epsilon}" />-optimal strategies may be constructed for XOR games where the optimal strategies have ‘stable’ representations. For the purposes of this post, we will analyze the exact result and merely state the approximate result.
<h3> Main Results</h3>
<h4><u>EXACT</u></h4>
For the exact realm, the table below summarizes Slofstra and Tsirelson’s main results.
<table border="1px">
<tbody>
<tr>
<th>Person</th>
<th> Strategy</th>
<th> Bound(entangled bits)</th>
</tr>
<tr>
<td> Slofstra</td>
<td> (Possibly) Non-Clifford</td>
<td> <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \log_{2}(N)}" class="latex" title="{ \log_{2}(N)}" /></td>
</tr>
<tr>
<td> Tsirelson</td>
<td>Clifford</td>
<td><img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" /></td>
</tr>
</tbody>
</table>
Here, <img src="https://s0.wp.com/latex.php?latex=%7B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ r}" class="latex" title="{ r}" /> is the largest integer such that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cbinom%7Br+%2B+1%7D%7B2%7D+%3C+%7CS%7C+%2B+%7CT%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \binom{r + 1}{2} &lt; |S| + |T|}" class="latex" title="{ \binom{r + 1}{2} &lt; |S| + |T|}" /> and corresponds to the maximum-rank of an extremal point in the quantum correlation matrix corresponding to an optimal strategy.
<img src="https://s0.wp.com/latex.php?latex=%7B+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ N}" class="latex" title="{ N}" /> is the minimum dimension of the representations of the Operators (<img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" />).
<h4><u>APPROXIMATE</u></h4>
In the approximate realm, the minimum entanglement dimension of the representation of the Operators from an <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon}" class="latex" title="{ \epsilon}" />-Optimal Strategy is: min(<img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BO%7D%28%5Cepsilon%5E%7B%5Cfrac%7B-1%7D%7B12%7D%7D%29%2C+2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" title="{ \mathcal{O}(\epsilon^{\frac{-1}{12}}), 2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" />).

As we shall see, Slofstra’s theorem allows us to recover Tsirelson’s bound easily by using a fact from Representation Theory about the irreducible representations of Clifford Algebras, but stands as a more general lower bound for solutions that aren’t Clifford.
<h3> Marginals and Solution Algebras</h3>
We’ll begin by introducing 3 key ideas:
i) Degeneracy <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleftrightarrow%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \leftrightarrow}" class="latex" title="{ \leftrightarrow}" /> Non-Degeneracy
ii) Existence of Marginals
iii) Solution Algebra

Once these ideas are defined and their notions made clear, we will be in a position to state the main result and sketch a proof for it.
<h4>Definition (Marginal Strategy)</h4>
<em> Given an Optimal Quantum Strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />), a marginal constitutes <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}_{j \in T}}" class="latex" title="{ \{B_{j}\}_{j \in T}}" />, and the partial trace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \psi}" class="latex" title="{ \psi}" /> with respect to <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{A}}" class="latex" title="{ H_{A}}" /> (<img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho_{B}}" class="latex" title="{ \rho_{B}}" />). </em>

 It is also possible to dualize the definition for obtaining <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}_{i \in S}}" class="latex" title="{ \{A_{i}\}_{i \in S}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho_{A}}" class="latex" title="{ \rho_{A}}" />.
We now define the notion of degeneracy, which is critical when proving the main theorem. The main point to drive home is that a degenerate optimal quantum strategy can be reduced to a unique, non-degenerate optimal quantum strategy.
<h4>Definition (Degenerate Quantum Strategy)</h4>
<em> A quantum strategy (<img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" class="latex" title="{ |{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}}" />) is said to be degenerate if <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cexists+%28P+%5Cin+H_A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \exists (P \in H_A)}" class="latex" title="{ \exists (P \in H_A)}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%28Q+%5Cin+H_B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (Q \in H_B)}" class="latex" title="{ (Q \in H_B)}" /> such that:
i) <img src="https://s0.wp.com/latex.php?latex=%7B+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ P}" class="latex" title="{ P}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+A_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_i}" class="latex" title="{ A_i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%28P+%5Cotimes+%7B%5Cmathbb%7BI%7D%7D%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" class="latex" title="{ (P \otimes {\mathbb{I}}) |{\psi}\rangle = |{\psi}\rangle}" />
ii) <img src="https://s0.wp.com/latex.php?latex=%7B+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ Q}" class="latex" title="{ Q}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+B_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_j}" class="latex" title="{ B_j}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%28%7B%5Cmathbb%7BI%7D%7D+%5Cotimes+Q%29+%7C%7B%5Cpsi%7D%5Crangle+%3D+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" class="latex" title="{ ({\mathbb{I}} \otimes Q) |{\psi}\rangle = |{\psi}\rangle}" /> </em>

 Since we can efficiently construct for any degenerate Optimal Quantum Strategy a unique, non-degenerate Optimal Quantum Strategy, we will now assume WLOG that every Optimal Quantum Strategy is non-degenerate (and unique).

We now define the (unique) existence of marginal biases, which correspond to constants for the rows of the quantum correlation matrix (which is a generalization of the classical pay-off). An equivalent statement can be made for columns (<img src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d_{j}}" class="latex" title="{ d_{j}}" />) by dualizing the existence of row marginals. These constants can be thought of as representing the (expected) optimum-payoff possible for a set of operator choices by one player, given that the other player’s choice is fixed. Intuitively, this can be seen as “collapsing” the quantum correlation matrix into a column, by summing over the rows (or collapsing into a row, by summing over the columns).
<br /><b>Lemma 12 (Existence of Marginals)</b> <em> For all <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR games G, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cexists+%5C%7Bc_%7Bi%7D+%5Cgeq+0+%5Chspace%7B1mm%7D+%7C+%5Chspace%7B1mm%7D+i+%5Cin+%7CS%7C%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" class="latex" title="{\exists \{c_{i} \geq 0 \hspace{1mm} | \hspace{1mm} i \in |S|\}}" />, such that, if <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bu_%7Bi%7D%5C%7D_%7Bi+%5Cin+%7CS%7C%7D%2C+%5C%7Bv_%7Bj%7D%5C%7D_%7Bj+%5Cin+%7CT%7C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" class="latex" title="{\{u_{i}\}_{i \in |S|}, \{v_{j}\}_{j \in |T|}}" /> form an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-optimal vector strategy where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%5Cleq+%5Cfrac%7B1%7D%7B4%28m%2Bn%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon \leq \frac{1}{4(m+n)}}" class="latex" title="{\epsilon \leq \frac{1}{4(m+n)}}" />,
<a name="eqmarginale"></a></em>
<p align="center"><em><a name="eqmarginale"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+-+c_%7Bi%7Du_%7Bi%7D%5C%7C+%5Cleq+%5Csqrt%7B10%7D%28m+%2B+n%29%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%5Cepsilon%5E%7B%5Cfrac%7B1%7D%7B4%7D%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2811%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" class="latex" title="\displaystyle  \|\sum_{j\in|T|}G_{ij}v_{j} - c_{i}u_{i}\| \leq \sqrt{10}(m + n)^{\frac{1}{4}}\epsilon^{\frac{1}{4}}, \forall i  \ \ \ \ \ (11)" /></a></em></p>
<em><a name="eqmarginale">
</a></em><em><a name="eqmarginale"></a> <a name="lemma"></a> </em>
If <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon = 0}" class="latex" title="{ \epsilon = 0}" /> and our strategy is perfectly optimal, we recover an exact estimation of the marginal biases: <a name="eqmarginal"></a>
<p align="center"><a name="eqmarginal"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bj%5Cin%7CT%7C%7DG_%7Bij%7Dv_%7Bj%7D+%3D+c_%7Bi%7Du_%7Bi%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2812%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" class="latex" title="\displaystyle  \sum_{j\in|T|}G_{ij}v_{j} = c_{i}u_{i}, \forall i  \ \ \ \ \ (12)" /></a></p>
<a name="eqmarginal">
</a><a name="eqmarginal"></a> The proof for the above lemma provided by Slofstra relies on using techniques to analyze the structure of the SDP program that pertains to quantum marginals. In particular, conducting trace analysis on SDP matrices that correspond to using the game matrix as off-diagonal elements leads us to the construction of the desired marginal biases.
It is also critical to note that a dual statement allows us to recover the column biases <img src="https://s0.wp.com/latex.php?latex=%7B+d_%7Bj%7D+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ d_{j} \geq 0}" class="latex" title="{ d_{j} \geq 0}" />: <a name="eqmarginalc"></a>
<p align="center"><a name="eqmarginalc"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bi%5Cin%5B%7CS%7C%5D%7DG_%7Bij%7Du_%7Bi%7D+%3D+d_%7Bj%7Dv_%7Bj%7D%2C+%5Cforall+j++%5C+%5C+%5C+%5C+%5C+%2813%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" class="latex" title="\displaystyle  \sum_{i\in[|S|]}G_{ij}u_{i} = d_{j}v_{j}, \forall j  \ \ \ \ \ (13)" /></a></p>
<a name="eqmarginalc">
</a><a name="eqmarginalc"></a> We now move on to defining the notion of a solution algebra.
<br />Definition 13 (Solution Algebra) <em> A solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> consists of self-adjoint (Hermitian) operators <img src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{j}}" class="latex" title="{X_{j}}" /> that satisfy the following predicates:  <a name="eqhermit"></a></em>
<p align="center"><em><a name="eqhermit"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X_%7Bj%7D%5E%7B2%7D+%3D+%5Cmathbb%7BI%7D%2C+%5Cforall+1+%5Cleq+j+%5Cleq+n++%5C+%5C+%5C+%5C+%5C+%2814%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" class="latex" title="\displaystyle  X_{j}^{2} = \mathbb{I}, \forall 1 \leq j \leq n  \ \ \ \ \ (14)" /></a></em></p>
<em><a name="eqhermit">
</a><a name="eqhermit"></a> <a name="eqbiasespay"></a>
</em>
<p align="center"><em><a name="eqbiasespay"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Csum_%7Bj%5Cin%5B%7CT%7C%5D%7DG_%7Bij%7DX_%7Bj%7D%29%5E%7B2%7D+%3D+%28c_%7Bi%7D%29%5E%7B2%7D%5Ccdot%5Cmathbb%7BI%7D%2C+%5Cforall+i++%5C+%5C+%5C+%5C+%5C+%2815%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" class="latex" title="\displaystyle  (\sum_{j\in[|T|]}G_{ij}X_{j})^{2} = (c_{i})^{2}\cdot\mathbb{I}, \forall i  \ \ \ \ \ (15)" /></a></em></p>
<em>
</em><em><a name="eqbiasespay">
</a></em><em><a name="eqbiasespay"></a> </em>
The definition above merely enforces the property that our unknown marginal operators be Hermitian <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a> and that they respect the optimal marginal biases (or payoffs) <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> we saw in <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a>, so that they correspond to being constructed from an optimal vector strategy. These unknown operators will be mapped to operators that are the marginal strategy corresponding to the optimal quantum strategy. This is at the heart of the main theorem we will now state:
<b>Theorem 14 (Slofstra, 2010)</b> <em> Given a <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR game G (with no zero rows or columns) and a solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" />, a collection of Linear Operators <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{B_{j}\}}" class="latex" title="{\{B_{j}\}}" /> and density matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> are the marginal of an optimal strategy iff the map <img src="https://s0.wp.com/latex.php?latex=%7BX_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{j} \rightarrow B_{j}}" class="latex" title="{X_{j} \rightarrow B_{j}}" /> induces a density-matrix representation of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho}" class="latex" title="{\rho}" /> commutes with <img src="https://s0.wp.com/latex.php?latex=%7Bim%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{im(\mathcal{A})}" class="latex" title="{im(\mathcal{A})}" />. <a name="th20"></a> </em>
Put simply, the theorem states that our unknown self-adjoint operators map to an optimal marginal strategy iff the density matrix (traced from the joint Hilbert-Space) commutes with all the mapped operators (<img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" />). The result we desire on the lower bound for the number of entangled bits, given a mapping from these indeterminate operators to the marginal of an optimal strategy, comes from a corollary to <a href="https://windowsontheory.org/feed/#th20">(14)</a>.
<br />Corollary 15 <em> Given a <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times n}" class="latex" title="{m \times n}" /> XOR game G (with no zero rows or columns) and a solution algebra <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{A}}" class="latex" title="{\mathcal{A}}" /> with minimum dimension <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> among non-zero representations, the strategy for minimum entanglement uses <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog_%7B2%7D%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log_{2}(N)}" class="latex" title="{\log_{2}(N)}" /> entangled bits. <a name="co21"></a> </em>
The proof for this corollary follows from the eigenspace decomposition of the joint Hilbert Space <img src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H}" class="latex" title="{ H}" /> in terms of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" />, which is preserved by the action of <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\mathcal{A})}" class="latex" title="{ im(\mathcal{A})}" />. As a result, each eigenspace decomposes into a finite sum of irreducible representations of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" />. The minimum entanglement is realized when there is exactly one invariant subspace (with one irreducible representation). The entanglement used by such a representation is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clog_%7B2%7D%28%5Ctext%7Bdim%7D%5C%2CH%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \log_{2}(\text{dim}\,H)}" class="latex" title="{ \log_{2}(\text{dim}\,H)}" />.
<h3> Proof of Theorem 20</h3>
The rest of the section is dedicated to sketching a brief (but formal) proof for Theorem <a href="https://windowsontheory.org/feed/#th20">(14)</a>, and then using a simple fact about the representations of a Clifford Algebra to show how Slofstra’s result subsumes Tsirelson’s bound.

For this section, <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle}" class="latex" title="{ |{\psi}\rangle}" /> refers to an arbitrary state in <img src="https://s0.wp.com/latex.php?latex=%7B+H+%3D+H_%7BA%7D+%5Cotimes+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H = H_{A} \otimes H_{B}}" class="latex" title="{ H = H_{A} \otimes H_{B}}" /> (the joint Hilbert space). We can write <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle+%3D+%5Csum_%7Bi%7D+%7C%7Bi%7D%5Crangle+%5Clambda+%7C%7Bi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" class="latex" title="{ |{\psi}\rangle = \sum_{i} |{i}\rangle \lambda |{i}\rangle}" /> over some basis <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7B%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{{i}\}}" class="latex" title="{ \{{i}\}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda}" class="latex" title="{ \lambda}" /> is a linear map. Then, the partial trace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \psi}" class="latex" title="{ \psi}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{A}}" class="latex" title="{ H_{A}}" /> is given by <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho+%3D+%5Clambda%5Clambda%5E%7B%2A%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho = \lambda\lambda^{*}}" class="latex" title="{ \rho = \lambda\lambda^{*}}" />.
Let <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BB%7D_%7BA%7D%2C+%5Cmathcal%7BB%7D_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" class="latex" title="{ \mathcal{B}_{A}, \mathcal{B}_{B}}" /> denote the algebra generated by <img src="https://s0.wp.com/latex.php?latex=%7B+A_%7B1%7D%2C..%2CA_%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_{1},..,A_{m}}" class="latex" title="{ A_{1},..,A_{m}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7B1%7D%2C..%2CB_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{1},..,B_{n}}" class="latex" title="{ B_{1},..,B_{n}}" />. Here, the generating elements are the observables of an optimal quantum strategy.

To arrive at a proof for the theorem, we will rely on 2 additional lemmas which we will not prove but state.
<br />Lemma 16 <em> Given Hermitian operators <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, <img src="https://s0.wp.com/latex.php?latex=%7BB+%5Cin+H_%7BA%7D%2C+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B \in H_{A}, H_{B}}" class="latex" title="{B \in H_{A}, H_{B}}" />,
<a name="eqfrob"></a></em>
<p align="center"><em><a name="eqfrob"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5C%7C%5Clambda%5Coverline%7BA%7D+-+B%5Clambda%5C%7C_%7BF%7D++%5C+%5C+%5C+%5C+%5C+%2816%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" class="latex" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \|\lambda\overline{A} - B\lambda\|_{F}  \ \ \ \ \ (16)" /></a></em></p>
<em><a name="eqfrob">
</a><a name="eqfrob"></a> This allows us to conclude that,
<a name="eqcomm"></a>
</em>
<p align="center"><em><a name="eqcomm"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5C%7C%28A+%5Cotimes+%5Cmathbb%7BI%7D+-+%5Cmathbb%7BI%7D+%5Cotimes+B%29%7C%5Cpsi%5Crangle%5C%7C+%5Cleq+%5Cepsilon+%5Cimplies+%5C%7C%5Crho%28B%29+-+B%5Crho%5C%7C_%7BF%7D+%5Cleq+2%5Cepsilon++%5C+%5C+%5C+%5C+%5C+%2817%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" class="latex" title="\displaystyle  \|(A \otimes \mathbb{I} - \mathbb{I} \otimes B)|\psi\rangle\| \leq \epsilon \implies \|\rho(B) - B\rho\|_{F} \leq 2\epsilon  \ \ \ \ \ (17)" /></a></em></p>
<em>
</em><em><a name="eqcomm">
</a></em><em><a name="eqcomm"></a> <a name="lecomm"></a> </em>
<b>Lemma 17</b> <em> The optimal strategy in question is non-degenerate iff <a name="eqcl1"></a></em>
<p align="center"><em><a name="eqcl1"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+closure%28%5Cmathcal%7BB%7D_%7BA%7D%5Clambda%5E%7B%2A%7DH_%7BB%7D%29.+%5C%5C++%5C+%5C+%5C+%5C+%5C+%2818%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" class="latex" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = closure(\mathcal{B}_{A}\lambda^{*}H_{B}). \\  \ \ \ \ \ (18)" /></a></em></p>
<em><a name="eqcl1">
</a><a name="eqcl1"></a> As a special case:
<a name="eqcl2"></a>
</em>
<p align="center"><em><a name="eqcl2"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++closure%28%5Cmathcal%7BB%7D_%7BB%7D%5Clambda+H_%7BA%7D%29+%3D+H_%7BB%7D+%5Cleftrightarrow+closure%28%5Crho+H_%7BB%7D%29+%3D+H_%7BB%7D++%5C+%5C+%5C+%5C+%5C+%2819%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" class="latex" title="\displaystyle  closure(\mathcal{B}_{B}\lambda H_{A}) = H_{B} \leftrightarrow closure(\rho H_{B}) = H_{B}  \ \ \ \ \ (19)" /></a></em></p>
<em>
</em><em><a name="eqcl2">
</a></em><em><a name="eqcl2"></a> <a name="lecl"></a> </em>
<b> Forward direction </b>:
We use the first lemma to prove commutativity of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho" class="latex" title="\rho" /> with all <img src="https://s0.wp.com/latex.php?latex=B_%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="B_{j}" class="latex" title="B_{j}" />, and we use the second lemma to show that the closure of <img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\rho" class="latex" title="\rho" /> is <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{B}}" class="latex" title="{ H_{B}}" />.
We first show the forward direction:
Suppose we are given an optimal quantum strategy (<img src="https://s0.wp.com/latex.php?latex=%7C%7B%5Cpsi%7D%5Crangle+%2C+%5C%7BA_%7Bi%7D%5C%7D_%7Bi+%5Cin+S%7D%2C+%5C%7BB_%7Bj%7D%5C%7D_%7Bj+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" class="latex" title="|{\psi}\rangle , \{A_{i}\}_{i \in S}, \{B_{j}\}_{j \in T}" />) for a game <img src="https://s0.wp.com/latex.php?latex=%7B+G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ G}" class="latex" title="{ G}" />. Then, we fix our optimal vector strategy as:
<a name="eqrs"></a>
<p align="center"><b><a name="eqrs"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u_%7Bi%7D+%3D+%28A_%7Bi%7D+%5Cotimes+%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2820%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" class="latex" title="\displaystyle  u_{i} = (A_{i} \otimes \mathbb{I})|\psi\rangle  \ \ \ \ \ (20)" /></a></b></p>
<b><a name="eqrs">
</a><a name="eqrs"></a> <a name="eqcs"></a>
</b>
<p align="center"><b><a name="eqcs"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++v_%7Bj%7D+%3D+%28%5Cmathbb%7BI%7D+%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2821%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" class="latex" title="\displaystyle  v_{j} = (\mathbb{I} \otimes B_{j})|\psi\rangle  \ \ \ \ \ (21)" /></a></b></p>
<a name="eqcs">
</a><a name="eqcs"></a>

We can now use Equations <a href="https://windowsontheory.org/feed/#eqmarginale">(11)</a> and <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> to establish our optimal marginal biases to write a relationship between them and <img src="https://s0.wp.com/latex.php?latex=%7B+%7C%7B%5Cpsi%7D%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ |{\psi}\rangle}" class="latex" title="{ |{\psi}\rangle}" /> , and apply Lemma <a href="https://windowsontheory.org/feed/#lecomm">(16)</a> to show commutativity and Lemma <a href="https://windowsontheory.org/feed/#lecl">(17)</a> to show that <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Cmathcal%7BA%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\mathcal{A})}" class="latex" title="{ im(\mathcal{A})}" /> = cyclic(<img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}, \rho}" class="latex" title="{ B_{j}, \rho}" />).
Using <a href="https://windowsontheory.org/feed/#eqmarginalc">(13)</a> with <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a>, we have:
<a name="eqqs1"></a>
<p align="center"><a name="eqqs1"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d_%7Bj%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bi%7DG_%7Bij%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle++%5C+%5C+%5C+%5C+%5C+%2822%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" class="latex" title="\displaystyle  d_{j}(\mathbb{I}\otimes B_{j})|\psi\rangle = \sum_{i}G_{ij}(A_{i}\otimes\mathbb{I})|\psi\rangle  \ \ \ \ \ (22)" /></a></p>
<a name="eqqs1">
</a><a name="eqqs1"></a> We can now use <a href="https://windowsontheory.org/feed/#eqcomm">(17)</a> with <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cepsilon+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \epsilon = 0}" class="latex" title="{ \epsilon = 0}" /> on <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> to see that <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> commutes with every <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />.
Additionally, as the terms in <a href="https://windowsontheory.org/feed/#eqqs1">(22)</a> constitute linear combinations of <img src="https://s0.wp.com/latex.php?latex=%7B+A_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ A_{i}}" class="latex" title="{ A_{i}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />, we can compute the closure of their actions on <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H_%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda H_{A}}" class="latex" title="{ \lambda H_{A}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda%5E%7B%2A%7D+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda^{*} H_{B}}" class="latex" title="{ \lambda^{*} H_{B}}" />, which will be equivalent. Therefore, <img src="https://s0.wp.com/latex.php?latex=%7B+im%28%5Crho%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ im(\rho)}" class="latex" title="{ im(\rho)}" /> = <img src="https://s0.wp.com/latex.php?latex=%7B+H_%7BB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H_{B}}" class="latex" title="{ H_{B}}" />, which follows from the special case of <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a>.
For the dual case, we substitute <a href="https://windowsontheory.org/feed/#eqrs">(20)</a> and <a href="https://windowsontheory.org/feed/#eqcs">(21)</a> into <a href="https://windowsontheory.org/feed/#eqmarginal">(12)</a>:
<a name="eqdn"></a>
<p align="center"><a name="eqdn"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c_%7Bi%7D%28A_%7Bi%7D%5Cotimes%5Cmathbb%7BI%7D%29%7C%5Cpsi%5Crangle+%3D+%5Csum_%7Bj%7DG_%7Bij%7D%28%5Cmathbb%7BI%7D%5Cotimes+B_%7Bj%7D%29%7C%5Cpsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" class="latex" title="\displaystyle  c_{i}(A_{i}\otimes\mathbb{I})|\psi\rangle = \sum_{j}G_{ij}(\mathbb{I}\otimes B_{j})|\psi\rangle" /> </a></p>
<a name="eqdn"></a>

<a name="eqdn">
</a><a name="eqdn"></a><a name="eqdn"></a> On taking the norm of the above on both sides and using a little algebra, we finally obtain the fact that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> satisfy predicate <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> making them the representations of <img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{j}}" class="latex" title="{ X_{j}}" />:

<img src="https://s0.wp.com/latex.php?latex=%7B+%28%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%29%5E%7B2%7D+%3D+c_%7Bi%7D%5E%7B2%7D%7B%5Cmathbb%7BI%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" class="latex" title="{ (\sum_{j}G_{ij}B_{j})^{2} = c_{i}^{2}{\mathbb{I}} }" />

This shows that the map from <img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bj%7D+%5Crightarrow+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{j} \rightarrow B_{j}}" class="latex" title="{ X_{j} \rightarrow B_{j}}" /> computes a density matrix representation of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> commutes with all <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />.

<br /><b> Backward Direction </b>:
The proof for the backward direction is much less involved:
If we knew that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%2C+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}, \rho}" class="latex" title="{ \{B_{j}\}, \rho}" /> constituted the cyclic representation of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cmathcal%7BA%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \mathcal{A}}" class="latex" title="{ \mathcal{A}}" /> with commutativity (with <img src="https://s0.wp.com/latex.php?latex=%7B+B_%7Bj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ B_{j}}" class="latex" title="{ B_{j}}" />), then we can use Lemma <a href="https://windowsontheory.org/feed/#eqcl2">(19)</a> to conclude that the image of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Crho%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \rho}" class="latex" title="{ \rho}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ H}" class="latex" title="{ H}" /> would form a subspace of <img src="https://s0.wp.com/latex.php?latex=%7B+%5Clambda+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \lambda H}" class="latex" title="{ \lambda H}" />. We define:

<img src="https://s0.wp.com/latex.php?latex=%7B+%5Coverline%7BA%7D_%7Bi%7D+%3D+%5Cfrac%7B%5Csum_%7Bj%7DG_%7Bij%7DB_%7Bj%7D%7D%7Bc_%7Bi%7D%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" class="latex" title="{ \overline{A}_{i} = \frac{\sum_{j}G_{ij}B_{j}}{c_{i}} }" />

allowing us to recover our original marginal biases <img src="https://s0.wp.com/latex.php?latex=%7B+c_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ c_{i}}" class="latex" title="{ c_{i}}" /> that satisfy <a href="https://windowsontheory.org/feed/#eqdn">(23)</a> and therefore correspond to the optimal strategy. This shows us that <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}}" class="latex" title="{ \{A_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> would constitute an optimal quantum strategy. 
<div align="right">□</div>
Having proved this theorem, we now obtain Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, which is the main desired result. To see how it subsumes Tsirelson’s result as a special case, we use a simple fact from Representation Theory:
<br /><b>Lemma 18</b> <em> For a Clifford Algebra generated by <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1%7D%2C..%2CX_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1},..,X_{r}}" class="latex" title="{X_{1},..,X_{r}}" />, there exist one or two irreducible representations of dimension <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" class="latex" title="{2^{\left \lfloor{\frac{r}{2}}\right \rfloor}}" /> <a name="lecr"></a> </em>
Plugging Lemma <a href="https://windowsontheory.org/feed/#lecr">18</a> into Corollary <a href="https://windowsontheory.org/feed/#co21">15</a>, we simply recover the fact that the number of entangled bits of a solution algebra that is Clifford is <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cleft+%5Clfloor%7B%5Cfrac%7Br%7D%7B2%7D%7D%5Cright+%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" class="latex" title="{ \left \lfloor{\frac{r}{2}}\right \rfloor}" />. However, note that being Clifford means an extra constraint:
<img src="https://s0.wp.com/latex.php?latex=%7B+X_%7Bi%7DX_%7Bj%7D+%3D+-X_%7Bj%7DX_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ X_{i}X_{j} = -X_{j}X_{i}}" class="latex" title="{ X_{i}X_{j} = -X_{j}X_{i}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5Cforall+i%2C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \forall i, j}" class="latex" title="{ \forall i, j}" />

The constraints on the Solution Algebra <a href="https://windowsontheory.org/feed/#eqhermit">(14)</a>, <a href="https://windowsontheory.org/feed/#eqbiasespay">(15)</a> given by Slofstra do \textit{not} necessarily mean that the solution is Clifford. In fact, when an optimal quantum strategy with minimal entanglement is Clifford, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BA_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{A_{i}\}}" class="latex" title="{ \{A_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BB_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{B_{j}\}}" class="latex" title="{ \{B_{j}\}}" /> are constructed from a unique set of <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bu_%7Bi%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{u_{i}\}}" class="latex" title="{ \{u_{i}\}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7Bv_%7Bj%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{v_{j}\}}" class="latex" title="{ \{v_{j}\}}" />.
To end, we write down a lemma that shows there exist XOR games where the optimal strategy is not unique and for minimal entanglement, a solution generated by a Non-Clifford algebra must be used:
<h4>Lemma (Existence of XOR games with Non-Clifford optimal strategies)</h4>
<em> There exist a family of <img src="https://s0.wp.com/latex.php?latex=%7B+m+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ m \times n}" class="latex" title="{ m \times n}" /> XOR games <img src="https://s0.wp.com/latex.php?latex=%7B+%5C%7BG%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \{G\}}" class="latex" title="{ \{G\}}" /> that correspond to generalizations of the CHSH games (<img src="https://s0.wp.com/latex.php?latex=%7BCL_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{CL_{n}}" class="latex" title="{CL_{n}}" />), such that, the optimal strategy of minimal entanglement is Non-Clifford. </em>


<h2>References</h2>
<p>[1] David Avis, Sonoko Moriyama, and Masaki Owari. From bell inequalities to tsirelson’s theorem. IEICE Transactions, 92-A(5):1254–1267, 2009.

</p><p>[2] Lance Fortnow, John Rompel, and Michael Sipser. On the power of multi-prover interactive protocols. Theoretical Computer Science, 134(2):545 – 557, 1994.

</p><p>[3] T. Ito, H. Kobayashi, and K. Matsumoto. Oracularization and Two-Prover One-Round Interactive Proofs against Nonlocal Strategies. ArXiv e-prints, October 2008.

</p><p>[4] J. Kempe, H. Kobayashi, K. Matsumoto, B. Toner, and T. Vidick. Entangled games are hard to approximate. ArXiv e-prints, April 2007.

</p><p>[5] Julia Kempe, Oded Regev, and Ben Toner. Unique games with entangled provers are easy. SIAM Journal on Computing, 39(7):3207– 3229, 2010.

</p><p>[6] S. Khanna, M. Sudan, L. Trevisan, and D. Williamson. The approximability of constraint satisfaction problems. SIAM Journal on Computing, 30(6):1863–1920, 2001.

</p><p>[7] Anand Natarajan and Thomas Vidick. Two-player entangled games are NP-hard. arXiv e-prints, page arXiv:1710.03062, October 2017.

</p><p>[8] Anand Natarajan and Thomas Vidick. Low-degree testing for quantum states, and a quantum entangled games PCP for QMA. arXiv e-prints, page arXiv:1801.03821, January 2018.

</p><p>[9] William Slofstra. Lower bounds on the entanglement needed to play xor non-local games. CoRR, abs/1007.2248, 2010.

</p><p>[10] B.S. Tsirelson. Quantum analogues of the bell inequalities. the case of two spatially separated domains. Journal of Soviet Mathematics, 36(4):557–570, 1987.

</p><p>[11] Thomas Vidick. Three-player entangled XOR games are NP-hard to approximate. arXiv e-prints, page arXiv:1302.1242, February 2013.

</p><p>[12] Thomas Vidick. Cs286.2 lecture 15: Tsirelson’s characterization of xor games. Online, December 2014. Lecture Notes.

</p><p>[13] Thomas Vidick. Cs286.2 lecture 17: Np-hardness of computing <img src="https://s0.wp.com/latex.php?latex=%5Comega%5E%2A%28G%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\omega^*(G)" class="latex" title="\omega^*(G)" />. Online, December 2014. Lecture Notes.



</p><p></p></div>







<p class="date">
by mitalibafna <a href="https://windowsontheory.org/2019/01/03/quantum-games/"><span class="datestr">at January 04, 2019 04:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42140">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42140/explanation-of-monadic-second-order-logic">Explanation of Monadic Second Order Logic [on hold]</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am reading Wolfgang's Book <a href="https://drona.csa.iisc.ac.in/~deepakd/atc-common/wolfgang-aat.pdf" rel="nofollow noreferrer">Applied Automata Theory </a>, wherein, I came across what Monadic Second Order Logic means. </p>

<blockquote>
  <p>MSO stands for “monadic second-order”:
  Second-order because it allows quantification not only over (first-order) position
  variables but also over (second-order) set variables.
  Monadic because quantification is allowed at most over unary (monadic) relations,
  namely sets.</p>
</blockquote>

<p>I have a fundamental question , how do position variables become first order variables, and how are set variables second order? I am not able to go further, since I cannot wrap my head around this. </p></div>







<p class="date">
by GermanShepherd <a href="https://cstheory.stackexchange.com/questions/42140/explanation-of-monadic-second-order-logic"><span class="datestr">at January 03, 2019 01:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3027987398928428578">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/01/today-is-thirdsday-enjoy-it-while-you.html">Today is Thirdsday!  Enjoy it while you can!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Fellow Blogger James Propp has come up with a new Math holiday:<br />
<br />
<b>Thirsdsday!</b><br />
<br />
The day is Jan 3 (1-3 in America, though 3-1 in ... Everywhere else?) but only when Jan 3 is a Thursday.<br />
<br />
It is a day where we celebrate the magic of the number 1/3.<br />
<br />
0) For other math days to celebrate see <a href="https://stemjobs.com/math-holidays/">here</a><br />
<br />
1/3) James Propp's blog about Thirdsday on Monday Dec 31. Really ???   : <a href="https://mathenchant.wordpress.com/2018/12/31/introducing-thirdsday/#more-2632">here</a><br />
<br />
2/3) Evelyn Lamb blogged about Thirdsday on Tuesday Jan 1. Really ??? : <a href="https://blogs.scientificamerican.com/roots-of-unity/how-to-celebrate-thirdsday/">here</a><br />
<br />
3/3) Ben Orlin blogged about Thirsdsday on Wedensday Jan 2. Really??? <a href="https://mathwithbaddrawings.com/2019/01/02/thirdsday-the-holiday-thats-33-33-better-than-any-other/">here</a><br />
<br />
(Added ON Thirdsday: Matt Foreman has a video about Thirdsday: <a href="https://www.youtube.com/watch?v=NinrTW1Bx2Y&amp;feature=youtu.be">here</a> and a blog post <a href="https://www.think-maths.co.uk/celebrating-thirdsday">here</a>)<br />
<br />
 How come I'm the only one blogged  about Thirdsday on Thursday Jan 3 ??? (Added later- not quite true anymore, Matt Foreman also waited until Thirdsday to post on Thirdsday).<br />
I asked Jim Propp about this. He said that he want to help prepare teachers and other eduators for the excitment of Thirdsday! If they already know the wonders of 1/3 they can prepare and lecture on it! Kudos to him! I assume that Evelyn and Ben are similar! Kudos to them! And Ben blogged ON Thirdsday so Kudos to him!<br />
<br />
2) Darling asked me `<i>is it a real day like Pi-Day?'</i>  Is Pi-Day real? Is any Holiday real? All holidays are made up until they are accepted and become real. The distinction between <i>real holidays</i> and  <i>made up holidays</i>  is ... nonexistent.  One can talk of <i>accepted </i>and <i>not-accepted</i> holidays.  How long did Pi-day take to be accepted? This is prob not a well defined question.<br />
<br />
3) James Propp's and Evelyn Lamb's  blog has many math properties of 1/3.  One educational property: I think it is the first number that students see that is an infinite decimal. My favorite unbiased use of 1/3: The Cantor Set: Uncountable subset of [0,1] that has measure 0. Really!!! My favorite biased use: its important in Muffin Math. If m&gt;s and you want to divide and distribute m muffins to s students, there is always a way to do this with smallest piece at least 1/3. (Usually you can do better but this is sometimes the best you can do.)<br />
<br />
4) When will the next Thirdsday come?<br />
<br />
2019: Jan 3 is a Thursday, so YES<br />
<br />
2020: Jan 3 is a Friday, so NO<br />
<br />
2021: Jan 3 is a Sunday (why no Saturday? Leap year. Great- it will come sooner!)  so NO<br />
<br />
2022: Jan 3 is a Monday, so NO<br />
<br />
2023: Jan 3 is a Tuesday  so NO<br />
<br />
2024: Jan 3 is a Wednesday  so NO<br />
<br />
2025: Jan 3 is a Friday. WHAT! Why no Thirdsday?  Darn leap year! So NO.<br />
<br />
2026: Jan 3 is a Saturday, so NO<br />
<br />
2027: Jan 3 is a Sunday so NO<br />
<br />
2028: Jan 3 is a Monday so NO<br />
<br />
2029: Jan 3 is a Wedensday (Why no Tuesday? Leap year), so NO<br />
<br />
2030: Jan 3 is a Thursday (Leap Year helped!), so YES FINALLY!<br />
<br />
(Exercise: find a formula: if 2019 was the first Thirdsday, find the year for TD(i), the ith Thirdsday.)<br />
<br />
So enjoy Thirdsday in 2019 when spellcheck still flags it.<br />
<br />
In 2030 it will be an accepted holiday and spellcheck will think it's fine.<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/01/today-is-thirdsday-enjoy-it-while-you.html"><span class="datestr">at January 03, 2019 05:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42138">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42138/the-definition-of-weakest-precondition-for-a-non-deterministic-language">The definition of weakest precondition for a non-deterministic language</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the classical IMP language, the definition of weakest precondition is:</p>

<pre><code>definition "wp c Q s ≡ ∃t. (c,s) ⇒ t ∧ Q t"
</code></pre>

<p>This is stating that from state s, after executing c we get to a state satisfying Q. My question comes when handling the selection construct in the language of guarded commands (see selection command in <a href="https://en.wikipedia.org/wiki/Predicate_transformer_semantics" rel="nofollow noreferrer">Wikipedia</a>). My guess is that in this case one needs to define:</p>

<pre><code>definition "wp c Q s ≡ ∃t. (c,s) ⇒ t ∧ (∀ t'. (c,s) ⇒ t' ⟶ Q t)"
</code></pre>

<p>I wonder if this is correct. Currently, I'm having problems proving the weakest precondition definition for the sequential composition of commands:</p>

<pre><code>"wp (c1;;c2) Q s = wp c1 (wp c2 Q) s" 
</code></pre>

<p>So, I'm beginning to think my definition is wrong.</p>

<p>Does anybody see what am I doing wrong?</p></div>







<p class="date">
by Javier <a href="https://cstheory.stackexchange.com/questions/42138/the-definition-of-weakest-precondition-for-a-non-deterministic-language"><span class="datestr">at January 02, 2019 09:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/01/02/faculty-position-in-theoretical-cs-at-imperial-college-london-apply-by-january-7-2019-2/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/01/02/faculty-position-in-theoretical-cs-at-imperial-college-london-apply-by-january-7-2019-2/">Faculty Position in Theoretical CS at Imperial College London (apply by January 7, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Multiple faculty openings (at Assistant Professor level) including a dedicaed position in CS theory. Department of Computing at Imperial College London has ambitious plans of expansion in all areas, including theory. Academics in the department enjoy a mild teaching load, which is currently up to 1.5 one-term courses per year. Each term amounts to about 10 weeks of teaching. Deadline is strict.</p>
<p>Website: <a href="https://www.imperial.ac.uk/jobs/description/ENG00581/six-lectureships-assistant-professor-senior-lectureships-associate-professor-computer-science/">https://www.imperial.ac.uk/jobs/description/ENG00581/six-lectureships-assistant-professor-senior-lectureships-associate-professor-computer-science/</a><br />
Email: margaret.hall@imperial.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/01/02/faculty-position-in-theoretical-cs-at-imperial-college-london-apply-by-january-7-2019-2/"><span class="datestr">at January 02, 2019 08:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16724">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/01/02/jean/">Jean</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2018/12/Jean-Joram.png?w=640&amp;h=500" class="alignnone size-full wp-image-16725" height="500" /></a></p>
<p><span style="color: #ff0000;">Jean Bourgain and Joram Lindenstrauss.</span></p>
<p>I was very sad to hear that Jean Bourgain, among the greatest mathematicians of our time, and a dear friend, passed away.  I first met Jean about forty years ago and later we have become friends and collaborators.  In the 80s and 90s Jean used to visit Israel quite often and had close collaboration with the Banach space Israeli community, and with the Ergodic theory community,  and with the Harmonic analysis community, and the PDE community, and later also with the combinatorics, probability,  algebra, number theory,  and theoretical computer science communities.  I always admired his immense mathematical powers and his deep devotion to mathematics.</p>
<p>You can read about Jean Bourgain in Terry Tao’s <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/">beautiful obituary post</a>.  I was also moved by Svetlana Jitomirskaya’s beautiful <a href="https://www.facebook.com/photo.php?fbid=10106557607678501&amp;set=a.10102850768938051&amp;type=3&amp;theater">facebook post</a>. Some of Jean’s contributions to combinatorics (which formed a small portion of his interests) are mentioned in <a href="https://gilkalai.wordpress.com/tag/jean-bourgain/">several posts </a>over my blog (and my lecture below). I will try to come back to these mathematical topics at a later post and here I post a few pictures of Jean over the years. Here is the moving <a href="https://www.ias.edu/news/2018/bourgain-obituary-notice">IAS obituary notice</a>. See also Ryan O’Donnell’s <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/#comment-509792">moving comment</a>. And here is a MathOverflow question <a href="https://mathoverflow.net/questions/319893/jean-bourgains-relatively-lesser-known-significant-contributions">Jean Bourgains relatively lesser known significant contributions</a>.</p>
<p> </p>
<p></p>
<p><span style="color: #ff0000;"><strong>My 2016 lecture “Questions for Jean Bourgain” about questions that I (and some colleagues) asked Jean Bourgain over the years, mainly in the areas of combinatorics and combinatorial aspects of convexity.</strong></span></p>
<p><span id="more-16724"></span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/SvetlanaonJean.png"><img src="https://gilkalai.files.wordpress.com/2019/01/SvetlanaonJean.png?w=640" alt="" class="alignnone size-full wp-image-16740" /></a></p>
<p class="_14f3 _14f5 _5pbw _5vra" id="js_6s"><span style="color: #0000ff;"><strong><span class="fwn fcg"><span class="fwb fcg">Svetlana Jitomirskaya:</span></span></strong></span></p>
<p>Вечности заложник<br />
У времени в плену</p>
<p>Eternity’s ambassador<br />
held captive by the time…</p>
<p>He was truly a gift from God to humanity and yet unparalleled in his kindness, humbleness, and generosity.</p>
<p>It is an enormous loss</p>
<p>February 28, 1954 – December 22, 2018</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/KFBT.jpg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/01/KFBT.jpg?w=640&amp;h=439" class="alignnone size-full wp-image-16742" height="439" /></a></p>
<p>Hermann K<em>ö</em>nig,Tadeusz Figiel, Jean Bourgain, and Lior Tzafriri  (<a href="http://www.math.kent.edu/~mtackett/mathweb/pictures/banach.html">Banach Center Photo Archive</a>)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/JeanRussell.jpg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/01/JeanRussell.jpg?w=640&amp;h=454" class="alignnone size-full wp-image-16747" height="454" /></a></p>
<p>With <span dir="ltr">Russell Impagliazzo </span>(picture taken from the IAS obituary)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/JB.jpg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/01/JB.jpg?w=640&amp;h=489" class="alignnone size-full wp-image-16743" height="489" /></a></p>
<p>An early picture near the blackboard</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/AlexJeanPeter.png"><img src="https://gilkalai.files.wordpress.com/2019/01/AlexJeanPeter.png?w=640" alt="" class="alignnone size-full wp-image-16755" /></a></p>
<p>Alex Gamburd, Jean Bourgain, and Peter Sarnak.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/crafoord-day.jpg"><img src="https://gilkalai.files.wordpress.com/2019/01/crafoord-day.jpg?w=640" alt="" class="alignnone size-full wp-image-16744" /></a></p>
<p>Crafoord day, Lund 2012 Carlos Kenig, Ben Green, Jean, Terry Tao, me, and Michael Christ.</p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/jeangil88.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/01/jeangil88.png?w=640&amp;h=470" class="alignnone size-full wp-image-16741" height="470" /></a></p>
<p>At IHES, 1989</p>
<h3>Pictures of early version of our first joint work (around 1990) with Izzy Katznelson, Jeff Kahn and Nati Linial.</h3>
<p>The initial approach had a 22 page long proof and my copy has a dense (Hebrew) handwritten explanation all the way to page 15.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/BKKKL2.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/01/BKKKL2.png?w=640&amp;h=325" class="alignnone size-full wp-image-16738" height="325" /></a></p>
<p> </p>
<p style="text-align: center;"><span style="color: #ff0000;">Part of Page 6</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/01/BKKK3.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/01/BKKK3.png?w=640&amp;h=399" class="alignnone size-full wp-image-16739" height="399" /></a></p>
<p style="text-align: center;"><span style="color: #ff0000;">Part of page 19</span></p>
<p>At the end we found a shortcut to the problem itself, but both Jean and I have felt over the years that the deeper methods developed initially by Jean may have further important use.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/01/02/jean/"><span class="datestr">at January 02, 2019 07:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42135">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42135/strong-seeded-randomness-extractors-with-low-entropy-loss">Strong seeded randomness extractors with low entropy loss</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I would like to implement a strong seeded randomness extractor for flat sources as a part of my project. </p>

<p>Most of the literature on seeded extractors is concentrated on minimizing seed length. However, low entropy loss is crucial for my construction. What are the known extractors with minimal entropy loss? How efficient is the extractor in practice? </p>

<p>Is there a lower bound on the entropy loss for strong seeded extractors? </p>

<p>Are there any implementations of extractors that I can use off the shelf?</p></div>







<p class="date">
by satya <a href="https://cstheory.stackexchange.com/questions/42135/strong-seeded-randomness-extractors-with-low-entropy-loss"><span class="datestr">at January 02, 2019 04:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42133">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42133/what-is-a-good-route-for-a-math-student-to-self-study-computer-science-systemati">What is a good route for a math student to self study computer science systematically and efficiently?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I decided to ask this question after being attracted by how much one can do with the knowledge in computer science, including iOS application development, game(or mods) development, website creating, etc., but having trouble with matching what I learned with what I really understood. </p>

<p>Realizing the lack of knowledge in programming, I once decided to learn programming in a specific language, like Objective-C and Swift. After I tried every single textbook on OC programming, I found myself wasting time in the "explanation" part and getting lost with the real "theoretical" part. It seems to me that those textbooks prefer a long and loose explanation in describing a concept without telling me what exactly it is(Like the notion of "Object" and "Pointer") and skip the real important "thinking" before the implementation of the code. Although after many times of reading I could create a very simple application(like a simple calculator), I was still very lost in how it really works.</p>

<p>That reminds me how I began to learn mathematics. In middle school "function" is just "<span class="math-container">$y=f(x)$</span>", where <span class="math-container">$f(x)$</span> can be <span class="math-container">$x^2$</span>, <span class="math-container">$\sin(x)$</span>, and other operations about <span class="math-container">$x$</span>. However, now for me <span class="math-container">$f$</span> is a set of tuples satisfying the unique mapping property, or an arrow with domain and codomain. More generally, I can give a affirmative response to every question like "what is (the definition of) this?(in a math sentence.)" So I asked myself, "what is most basic among all subjects in computer science"? </p>

<p>Based on the belief that computer system and programming can be completely theoretical, I decided to learn from the very basic. That's when I began to have trouble because of the lack of knowledge in the computer science world. Where is the code for my programming environment?(For me, Xcode) and how can I understand it? What is a computer made of (up to the transistors), and how do them work together? 
But then I found out that there is no book with the name similar to "how a computer works" that reach my satisfaction, which I thought is my vocabulary problem. </p>

<p>I hope that in the book I'm looking for, every keyword is rigorously defined, and without any waste of time in explaining what a notion "means" or how it is developed stage by stage historically. I expect that it gives only the goals(like the adding machine) and how to build it from the given definitions(a graph with the nodes of value "0" or "1"). Every textbooks in mathematics(like the GTM series) reach this goal, and for me, that is MUCH easier to read and understand. I think most of the math student like me will prefer this style of learning.</p>

<p>What is a good (book) route for a math student to self study computer science from the basic? I wish there are some theoretical textbooks that build the whole operation system, compiler, or some of this kind, that is readable to math students. Any answer would be much appreciated. Thank you. </p></div>







<p class="date">
by William Sun <a href="https://cstheory.stackexchange.com/questions/42133/what-is-a-good-route-for-a-math-student-to-self-study-computer-science-systemati"><span class="datestr">at January 01, 2019 11:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42132">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42132/separating-words-and-graph-isomorphism">Separating words and graph isomorphism</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I wonder if there are any known implications of Babai's recent quasi-polynomial time algorithm for Graph Isomorphism to <a href="https://cstheory.stackexchange.com/a/22494/419">separating words by DFA's</a>.
In both cases the ultimate goal is to differentiate some object, though the conditions are quite different.
I would like to know what people more familiar with Babai's proof think about whether some of the ideas there are applicable to word separation or not.</p></div>







<p class="date">
by domotorp <a href="https://cstheory.stackexchange.com/questions/42132/separating-words-and-graph-isomorphism"><span class="datestr">at January 01, 2019 09:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42130">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42130/busy-beaver-equivalent-for-the-untyped-lambda-calculus">Busy Beaver Equivalent for the Untyped Lambda Calculus</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the same way that the Busy Beaver function is defined for Turing Machines, we could define a similar function for the untyped lambda calculus:</p>

<p>Over all terms in the ULC composed of <code>n</code> abstractions, variables and applications, which has the longest normal form?</p>

<p>This could be defined in a couple ways: we could consider only strongly normalizing ULC terms, or we could look for the longest normal form over all replacements.</p>

<p>Clearly, this function is not computable for arbitrarily large <code>n</code>, for the same reason as for the standard Busy Beaver function. However, I am interested in whether anything is known about this function for small values of <code>n</code>. What values is it known for? What bounds exists for higher <code>n</code>? For what <code>n</code> is the value known to be independent of ZFC?</p></div>







<p class="date">
by isaacg <a href="https://cstheory.stackexchange.com/questions/42130/busy-beaver-equivalent-for-the-untyped-lambda-calculus"><span class="datestr">at January 01, 2019 01:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42129">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42129/how-to-prove-that-models-of-indirect-and-direct-ram-machines-are-equivalent">How to prove that models of indirect and direct RAM machines are equivalent?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>as in the title, I am looking for a formal proof how to show that models of indirect and direct RAM (random-access) machines are equivalent. I would really appreciate your help.</p></div>







<p class="date">
by Tomek <a href="https://cstheory.stackexchange.com/questions/42129/how-to-prove-that-models-of-indirect-and-direct-ram-machines-are-equivalent"><span class="datestr">at January 01, 2019 10:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42126">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42126/hamiltonian-cycle-vs-co-np">Hamiltonian cycle vs co-NP [on hold]</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am trying to understand co-NP and its implications properly.</p>

<p>The French Wikipedia <a href="https://fr.wikipedia.org/wiki/Co-NP" rel="nofollow noreferrer">page</a> describing co-NP provides the "complementary" version of the Hamiltonian cycle in co-NP as follows:</p>

<pre><code>Considering a graph G, is it true that it does not have an Hamiltonian cycle?
</code></pre>

<p>Is this correct?</p>

<p>If so, then how is this complementary version a different class of complexity than the original Hamiltonian cycle problem? The decision question is the same. To put it differently, what is the difference between NP and co-NP here?</p>

<p>Otherwise, if this complementary version is false, what would be the correct version (if any exists)?</p></div>







<p class="date">
by Jérôme Verstrynge <a href="https://cstheory.stackexchange.com/questions/42126/hamiltonian-cycle-vs-co-np"><span class="datestr">at December 31, 2018 10:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2018/12/31/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2018/12/31/linkage.html">Linkage for the end of the year</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://twitter.com/trannosaurusma/status/959423514485841925?s=21">LaTeX, the game</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101252368314388741"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/BAwHG7Tnc2N">G+</a>, <a href="https://mathstodon.xyz/@ejk/101201955004129570">via</a>). It should be an even higher level to get the commutative diagram to format in Wikipedia’s lobotomized version of LaTeX.</p>
  </li>
  <li>
    <p><a href="http://aperiodical.com/2018/12/byrnes-euclid-recreated-for-the-web/">Byrne’s Euclid recreated for the web</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101259384727886209"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/4Z1pWdmcWui">G+</a>, <a href="https://plus.google.com/+Aperiodical/posts/KdfBH9YMFMV">via</a>, <a href="https://www.metafilter.com/178260/Byrnes-Euclid">also via</a>. Beautiful three-color figures, hard-to-read old-faſhioned orthography, and all. I have the Taſchen reprint in my office, but I prefer the Dover Heath edition for actually uſing the books rather than looking pretty.</p>
  </li>
  <li>
    <p><a href="https://www.theengineer.co.uk/electric-eel-hydrogel-battery/">Electric eel inspires biocompatible hydrogel battery</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101264841241151850"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/EioURA7NEmH">G+</a>, <a href="https://www.nature.com/articles/nature24670">original paper</a>, <a href="https://news.umich.edu/electricity-eel-style-soft-power-cells-could-run-tomorrow-s-implantables/">see also</a>). The part that caught my attention is that they’re using a Miura fold to simultaneously align and press together many pairs of droplets of four types (salty, fresh water, or two kinds of charge-selective hydrogel), creating an origami-activated electrical discharge.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/in-the-universe-of-equations-virtually-all-are-prime-20181210/">In the universe of equations, virtually all are prime</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101270526352782325"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/d7hvGtho5FJ">G+</a>, <a href="https://plus.google.com/+QuantamagazineOrgNews/posts/9e2bRyNfyeF">via</a>, <a href="https://arxiv.org/abs/1810.13360">original paper</a>). Choose a polynomial’s coefficients randomly and independently from your favorite nontrivial distribution. Then it should be irreducible with high probability for polynomials of high enough degree. This was previously conjectured for the uniform distribution on  by Odlyzko and Poonen; now Breuillard and Varjú have proven that it follows from a form of the Riemann hypothesis.</p>
  </li>
  <li>
    <p>A tricky Sudoku (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101277538292220348"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/NDeATkTyEKT">G+</a>):</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2018/sudoku.svg" alt="A sudoku puzzle" /></p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/In-Talks-With-Elsevier-UCLA/245311">UCLA suggests that its faculty refrain from publishing with or reviewing for Elsevier while negotiations are ongoing</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101281900329465390"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/E4KAhwXct6y">G+</a>). For those willing to take a longer-term stand, there’s always <a href="http://thecostofknowledge.com/">thecostofknowledge.com</a>.</p>
  </li>
  <li>
    <p><a href="https://suomela.github.io/snowflake/">A161330 Snowflake</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101293131395532694"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/N1gsDwSmjrX">G+</a>, <a href="https://plus.google.com/+JukkaSuomela/posts/b7rngpsTaVc">via</a>). An animated holiday greeting from <a href="https://twitter.com/JukkaSuomela">Jukka Suomela</a> based on <a href="https://oeis.org/A161330">integer sequence A161330</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@unknown/101273978649098365">Festive two-to-one star dissection</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101298812633911915"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Bf3kWzhc9Yh">G+</a>). A Christmas greeting from <a href="https://mathstodon.xyz/@unknown/">@unknown@mathstodon.xyz</a>.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=uNJ7riiPHOY">Journeys of women in mathematics</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101311027456154189"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/5CXnPF36FMz">G+</a>, <a href="https://blogs.scientificamerican.com/roots-of-unity/women-mathematicians-in-their-own-words/">via</a>). A 20-minute documentary profiling three women mathematicians from developing countries: Neela Nataraj of IIT Bombay in India, Aminatou Pecha Nijahouo from Cameroon, and Carolina Araujo at IMPA in Brazil, with brief quotes from many more.</p>
  </li>
  <li>
    <p><a href="https://wikiedu.org/blog/2018/12/20/three-things-i-learned-as-a-wiki-scholar/">Three things i learned as a Wiki scholar</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101314727270253883"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/hmWXq3eDTqf">G+</a>, <a href="https://en.wikipedia.org/wiki/Wikipedia_talk:WikiProject_Women_in_Red">via</a>). Historian Rachel Boyle on some cultural differences between academia and Wikipedia.</p>
  </li>
  <li>
    <p><a href="https://commons.wikimedia.org/wiki/File:Mendocino_Beacon_Building.jpg">Mendocino Beacon Building</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101320263516053157"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/ik4GHTux6wN">G+</a>). It feels like I haven’t been taking and posting enough photos. So here’s a cell phone shot that I took to illustrate the Wikipedia article on the <em><a href="https://en.wikipedia.org/wiki/Mendocino_Beacon">Mendocino Beacon</a></em>. The <em>Beacon</em> hasn’t actually lived there for nearly 20 years, but their old sign still hangs on the building.</p>
  </li>
  <li>
    <p><em><a href="http://algorithms.wtf/">Algorithms</a></em> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101327166193790839"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/Vsin2Hxwpaj">G+</a>, <a href="https://3dpancakes.typepad.com/ernie/2018/12/steal-this-book-1.html">via</a>). Jeff Erickson’s open-licensed algorithms text is finally more-or-less complete and available in prepublication form.</p>
  </li>
  <li>
    <p><a href="https://wyss.harvard.edu/studying-aliens-of-the-deep/">Using unfolded polyhedra to catch and later release deep-sea creatures without harming them</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101332999043783606"></a>,</span> <a href="https://plus.google.com/100003628603413742554/posts/j42xnNxs7nW">G+</a>, <a href="https://news.ycombinator.com/item?id=18769435">via</a>).</p>
  </li>
  <li>
    <p><a href="https://plus.google.com/100003628603413742554/posts/WSizeQTqrZH">In which I say goodbye to Google+</a> (<span style="white-space: nowrap;"><a href="https://mathstodon.xyz/@11011110/101338372532836995"></a>).</span></p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2018/12/31/linkage.html"><span class="datestr">at December 31, 2018 04:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2187908441651073696">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html">Complexity Year in Review 2018</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Result of the year goes to<br />
<blockquote style="text-align: center;" class="tr_bq">
<a href="https://eccc.weizmann.ac.il/report/2018/107/">Oracle Separation of BQP and PH</a> by Ran Raz and Avishay Tal</blockquote>
<div style="text-align: left;">
which we <a href="https://blog.computationalcomplexity.org/2018/06/bqp-not-in-polynomial-time-hierarchy-in.html">wrote about in June</a>. This work solves one of the original open questions in quantum complexity using tools from both quantum and classical circuit complexity. How often do we see oracle results with popular articles in <a href="https://www.quantamagazine.org/finally-a-problem-that-only-quantum-computers-will-ever-be-able-to-solve-20180621/">Quanta</a> (ignore the hyperbolic title), <a href="https://www.thehindu.com/sci-tech/science/quantum-computers-have-an-edge-over-classical-ones-says-the-oracle/article24420375.ece">The Hindu</a> and <a href="https://cacm.acm.org/magazines/2019/1/233514-quantum-leap/fulltext">CACM</a>?</div>
<div style="text-align: left;">
<br /></div>
<div style="text-align: left;">
Runner up goes to the <a href="https://eccc.weizmann.ac.il/report/2018/006/">solution</a> of the 2-to-2 Games Conjecture by Subhash Khot, Dor Minzer and Muli Safra early in 2018. Boaz Barak gave a nice <a href="https://windowsontheory.org/2018/01/10/unique-games-conjecture-halfway-there/">two</a> <a href="https://windowsontheory.org/2018/02/26/on-the-recent-proof-of-the-2-to-2-conjecture/">post</a> overview.</div>
<div style="text-align: left;">
<br /></div>
<div style="text-align: left;">
In last year's <a href="https://blog.computationalcomplexity.org/2017/12/complexity-year-in-review-2017.html">review</a> we talked about the magical breakthroughs of machine learning. This year we seemed to have moved beyond the magic to where machine learning has become a thing. We see the immense value of data and continue to struggle with the ethical challenges of collecting and acting on data, dominance of the big tech companies, training all these students who want to gain expertise in the area and trying to understand why ML works as well as it does. </div>
<div style="text-align: left;">
<br />
The big X-factor is <a href="https://blog.computationalcomplexity.org/2018/10/a-new-cold-war.html">China</a>. Will competition with China spur science literacy and funding in the US like the cold war with the Soviets did? Or will isolation with China limit scientific collaboration like the cold war with the Soviets did? </div>
<div style="text-align: left;">
<br />
The big tech surprise was the rise of electric scooters. Georgia Tech has embraced them and it is a quick way to get around campus.<br />
<br />
Some of the other questions I asked last year didn't have interesting answers: What will the Internet look like post-net neutrality? (too early to tell) How will the new tax code play out? (too early to tell) Where will Amazon put HQ2? (New York and DC--only surprise was picking two cities) What can quantum computers with 50 qbits accomplish? (still a good question) Will bitcoin move to $300K or 30 cents? (it dropped but still has real value)<br />
<br />
Thanks to our guest posters <a href="https://blog.computationalcomplexity.org/2018/10/a-new-aco-center-guest-post-by-vijay.html">Vijay Vazirani</a>, <a href="https://blog.computationalcomplexity.org/2018/12/guest-post-join-sigact.html">Samir Khuller and Robert Kleinberg</a>, and <a href="https://blog.computationalcomplexity.org/2018/09/the-tenure-system-is-broken-but-not-in.html">anonymous</a>.</div>
<div style="text-align: left;">
<br /></div>
<div style="text-align: left;">
We remember <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/">Jean Bourgain</a>, <a href="https://blog.computationalcomplexity.org/2018/12/remembering-george-h-w-bush.html">George H. W. Bush</a>, <a href="https://www.tehrantimes.com/news/431247/Iranian-scientist-Babak-Farzad-dies-of-terminal-cancer">Babak Farzad</a>, <a href="https://blog.computationalcomplexity.org/2018/03/stephen-hawking-1942-2018.html">Stephen Hawking</a>, <a href="https://blog.computationalcomplexity.org/2018/12/ker-i-ko-1950-2018.html">Ker-I Ko</a> and Stan Lee.</div>
<div style="text-align: left;">
<br /></div>
<div style="text-align: left;">
We end the year with craziness, the stock market is going through wild gyrations, we have a partial government shutdown including all of NSF and an uncertain political landscape with different parties leading the two houses of congress. We're still in the midst of a technological revolution and governments around the world try to figure how to regulate it. I find it hard to predict 2019 but it will not be quiet.</div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2018/12/complexity-year-in-review-2018.html"><span class="datestr">at December 31, 2018 12:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42122">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42122/what-to-do-as-a-theoretical-computer-science-phd-student-in-a-free-time">What to do as a Theoretical computer science PhD student in a free time?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am a mid-stage theoretical computer science student. Although I have a busy schedule, I still have a one or one a half hour in a day which I devote to reading and solving the question given Jeff Erickson's lecture note etc. I am doing this thing from many months and wondering. Is this a right thing for me to do in free time as now I am a Ph.D. student not an undergraduate student. Now why I do this to become more strong in an algorithm, discrete maths etc part. Another thing which seems more valuable to me is to read more and more research paper of my research domain as my goal after my Ph.D. is to publish more quality research papers in the field related to my current field. I am wondering which one is better or suggest anything else which may be more valuable to me keeping my future perspective in mind.</p>

<p><strong>Question:</strong> What to do as a Theoretical computer science PhD student in free time? I am wondering what star experienced researchers do in their time ( assuming they have a free time ).</p>

<p>Some of my free time I also spent on watching video lecture of workshops related to my field.</p>

<p>After looking at all the comments and answers, I have to edit my question. I think, I have not been able to convey what I was trying to ask. My question was how to sharp my technical skills in the free time for a better future. It has nothing to do with my personal life or some one's personal space. I was here for the various possibilities and opinions of users, who have experience in theoretical computer science. Let me clarify my question further, I was to trying to ask in the free time what is more significant to do " continue to think about the research problem at hand or do the problems related to maths or algorithms " and so on. Looking at the comments have made me realise that definitely I need to improve my writing skills also. </p></div>







<p class="date">
by A_Theory <a href="https://cstheory.stackexchange.com/questions/42122/what-to-do-as-a-theoretical-computer-science-phd-student-in-a-free-time"><span class="datestr">at December 31, 2018 12:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://cstheory.stackexchange.com/q/42120">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://cstheory.stackexchange.com/questions/42120/is-a-binary-sequence-computable-iff-the-kolmogorov-complexity-of-its-initial-seg">Is a binary sequence computable iff the Kolmogorov complexity of its initial segments is bounded?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory.stackexchange.com/questions" title="Recent Questions - Theoretical Computer Science Stack Exchange">CS Theory StackExchange (Q&A)</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><strong>Disclaimer:</strong> I am mostly unfamiliar with theoretical computer science, making it hard for me to navigate literature in the field. I ask the following out of curiosity.</p>

<p><strong>Background/Motivation:</strong> Coming from information theory, I recently learned about a connection of entropy and Kolmogorov complexity: Loosely speaking, entropy of a random variable is the expected rate at which the Kolmogorov complexity of a long sample sequence increases per sample. <a href="http://www.cs-114.org/wp-content/uploads/2015/01/Elements_of_Information_Theory_Elements.pdf" rel="nofollow noreferrer">[Elements of Information Theory, p. 154]</a> Kolmogorov complexity can therefore capture the notion of entropy, but it is more general than that. Hereby, and in the following, whenever I write complexity, I implicitly refer to the complexity given the length of the output.</p>

<p>For non-zero entropy, the Kolmogorov complexity of initial segments of an infinite sequence of samples from a random variable is therefore unbounded. I was wondering whether this is equivalent to the fact that an infinite sequence of samples is uncomputable. This led me to the hypothesis in the title: Is a binary sequence computable if and only if the Kolmogorov complexity of its initial segments is bounded?</p>

<p>If the hypothesis was true, then computability could be understood as an indicator that the "amount of information" in a sequence is finite. In some sense, the initial segment complexities would allow a more finely graded characterization of infinite sequences than just "computable" and "uncomputable". We could get a notion of "information content" and "information rate" of infinite sequences by analyzing the size of the bound or, in the unbounded case, the rate/type of growth, as in the entropy case above. My question boils down to whether "computable" and "uncomputable" are regions on this scale.</p>

<p>If the hypothesis is true, I'd be interested in whether this perspective is useful for TCS research. If yes, are there references elaborating this idea? If not, why not?</p>

<p><strong>What I found in literature:</strong> It is shown that a sequence is Martin-Löf random iff there is a constant <span class="math-container">$c$</span> so that there are infinitely many initial segments with complexity greater than <span class="math-container">$n - c$</span> where <span class="math-container">$n$</span> is the segment length. <a href="https://arxiv.org/pdf/math/0110086.pdf" rel="nofollow noreferrer">[Randomness, p. 18]</a></p>

<p>This means that random sequences have unbounded initial segment complexity. Since they are not computable, the hypothesis is true at least for this case. If I am not mistaken, a similar argument could even be made for a weaker form of randomness, since Mises-Wald-Church random sequences cannot have initial segment complexity of O(log n). <a href="https://www.math.uni-heidelberg.de/logic/merkle/ps/JCSS-stoch.pdf" rel="nofollow noreferrer">[The complexity of stochastic sequences]</a></p>

<p><strong>What's missing for a proof:</strong></p>

<p><span class="math-container">$\Leftarrow$</span>:
Assume a sequence is computable. We know that a program <code>generate_bit(n)</code> exists that generates any bit of the sequence. Now, we can build a program <code>generate_initial_segment(n) = concat(map(1..n, generate_bit))</code> that, given the segment length <span class="math-container">$n$</span>, generates the initial segment up to position n by invoking <code>generate_bit</code> <span class="math-container">$n$</span> times and concatenating the results. The Kolmogorov complexity of this task is therefore bounded by the length of this program. ☐</p>

<p><span class="math-container">$\Rightarrow$</span>: I struggle to prove/disprove this direction, namely: If initial segment complexity is bounded, is a sequence always computable?</p>

<p>Update: The last two pages of <a href="https://www.sciencedirect.com/science/article/pii/S0019995869905385/pdf?md5=5ff60459e171a92caef1156280e1ce2c&amp;pid=1-s2.0-S0019995869905385-main.pdf" rel="nofollow noreferrer">A variant of the Kolmogorov concept of complexity</a> prove this direction.</p></div>







<p class="date">
by Julius Kunze <a href="https://cstheory.stackexchange.com/questions/42120/is-a-binary-sequence-computable-iff-the-kolmogorov-complexity-of-its-initial-seg"><span class="datestr">at December 31, 2018 09:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4045">Incompleteness ex machina</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I have a treat with which to impress your friends at New Year’s Eve parties tomorrow night: a <a href="https://www.scottaaronson.com/incompleteness.pdf">rollicking essay</a> graciously contributed by a reader named Sebastian Oberhoff, about a unified and simplified way to prove all of Gödel’s Incompleteness Theorems, as well as Rosser’s Theorem, directly in terms of computer programs.  In particular, this improves over my treatments in <em>Quantum Computing Since Democritus</em> and my <a href="https://www.scottaaronson.com/blog/?p=710">Rosser’s Theorem via Turing machines</a> post.  While there won’t be anything new here for the experts, I loved the style—indeed, it brings back wistful memories of how <em>I</em> used to write, before I accumulated too many imaginary (and non-imaginary) readers tut-tutting at crass jokes over my shoulder.  May 2019 bring us all the time and the courage to express ourselves authentically, even in ways that might be sneered at as incomplete, inconsistent, or unsound.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4045"><span class="datestr">at December 31, 2018 02:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
