<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at May 05, 2020 10:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/073">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/073">TR20-073 |  Lower Bounds on OBDD Proofs with Several Orders | 

	Dmitry Itsykson, 

	Sam Buss, 

	Dmitry Sokolov, 

	Alexander Knop, 

	Artur Riazanov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
This paper is motivated by seeking lower bounds on OBDD($\land$, weakening, reordering) refutations, namely OBDD refutations that allow weakening and arbitrary reorderings. We first work with 1-NBP($\land$) refutations based on read-once nondeterministic branching programs. These generalize OBDD($\land$, reordering) refutations. There are polynomial size 1-NBP($\land$) refutations of the pigeonhole principle, hence 1-NBP($\land$) is strictly stronger than OBDD($\land$, reordering). There are also formulas that have polynomial size tree-like resolution refutations but require exponential size 1-NBP($\land$) refutations. As a corollary, OBDD($\land$, reordering) does not simulate tree-like resolution, answering a previously open question.

The system 1-NBP($\land$, $\exists$) uses projection inferences instead of weakening. 1-NBP($\land$, $\exists_k$) is the system restricted to projection on at most $k$ distinct variables. We construct explicit constant degree graphs $G_n$ on $n$ vertices and an $\epsilon &gt; 0$, such that 1-NBP($\land$, $\exists_{\epsilon n}$) refutations of the Tseitin formula for $G_n$ require exponential size.

Second, we study the proof system OBDD($\land$, weakening, reordering$_\ell$) which allows $\ell$ different variable orders in a refutation. We prove an exponential lower bound on the complexity of tree-like OBDD($\land$, weakening, reordering$_\ell$) refutations for $\ell = \epsilon \log n$, where $n$ is the number of variables and $\epsilon &gt; 0$ is a constant. The lower bound is based on multiparty communication complexity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/073"><span class="datestr">at May 05, 2020 06:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5609460581142399437">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html">Why is there no (d,n) grid for Hilbert's Tenth Problem?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
Hilbert's 10th problem, in modern language is:<br />
<br />
Find an algorithm that will, given a poly over Z in many variables, determine if it has a solution in Z.<br />
<br />
This problem was proven undecidable through the work of Davis, Putnam, Robinson and then<br />
Matiyasevich supplied the last crucial part of the proof.<br />
<br />
Let H10(d,n) be the problem with degree d and n variables.<br />
<br />
I had assumed that somewhere on the web would be a grid where the dth row, nth col has<br />
<br />
U if  H10(d,n) is undecidable<br />
<br />
D if H10(d,n) is decidable<br />
<br />
? if the status of H10(d,n) was unknown.<br />
<br />
I found no grid. I then collected up all the results I could find <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/h10.pdf">here</a><br />
<br />
This lead to the (non-math) question: Why is there no grid out there? Here are my speculations.<br />
<br />
1) Logicians worked on proving particular (d,n) are undecidable. They sought solutions in N. By contrast number theorists worked on proving particular (d,n) decidable. They sought solutions in Z.. Hence a grid would need to reconcile these two related problems.<br />
<br />
<div>
<div>
2) Logicians and number theorists didn't talk to each other. Websites and books on Hilbert's Tenth problem do not mention any solvable cases of it.</div>
</div>
<div>
<br /></div>
<div>
<div>
3) There is a real dearth of positive results, so a grid would not be that interesting. Note that we do not even know if the following is decidable: given k in Z does there exists x,y,z in Z such that</div>
<div>
<br /></div>
<div>
x^3 +y^3+ z^3 = k. I blogged about that <a href="https://blog.computationalcomplexity.org/2019/04/x-3-y-3-z-3-33-has-solution-in-z-and.html">here</a></div>
</div>
<div>
<br /></div>
<div>
4) For an undecidable result for (d,n) if you make n small then all of the results make d very large.</div>
<div>
<br /></div>
<div>
For example</div>
<div>
<br /></div>
<div>
n=9, d= 1.6 x 10^{45}  is undecidable. The status of n=9, d=1.6 x 10^{45} -1 is unknown.</div>
<div>
<br /></div>
<div>
Hence the grid would be hard to draw.</div>
<div>
<br /></div>
<div>
Frankly I don't really want a grid. I really want a sense of what open problems might be solved. I think progress has gone in other directions- H10 over other domains. Oh well, I want to know about</div>
<div>
<br /></div>
<div>
n=9 and d=1.6 x 10^{45}-1. (parenthesis ambiguous but either way would be an advance.)</div>
<div>
<br /></div>
<div>
<br /></div>
<div>
<br /></div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html"><span class="datestr">at May 05, 2020 04:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=48">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/">Friday, May 15 — Amin Karbasi from Yale University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Amin Karbasi </strong>from Yale University will speak about “<em>User-Friendly Submodular Maximization</em>”.</p>



<p class="has-text-align-left"><strong>Abstract</strong>: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they have been rediscovered in many fields such as information theory, operations research, statistical physics, economics, and machine learning. They also enjoy computational tractability as they can be minimized exactly or maximized approximately.</p>



<p>The goal of this talk is simple. We see how a little bit of randomness, a little bit of greediness, and the right combination can lead to pretty good methods for offline, streaming, and distributed solutions. I do not assume any background on submodularity and try to explain all the required details during the talk.</p>



<p><a href="https://sites.google.com/view/dstheory" target="_blank" rel="noreferrer noopener">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/"><span class="datestr">at May 05, 2020 01:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/072">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/072">TR20-072 |  Locally testable codes via high-dimensional expanders | 

	Irit Dinur, 

	Prahladh Harsha, 

	Yotam Dikstein, 

	Noga Ron-Zewi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Locally testable codes (LTC) are error-correcting codes that have a local tester which can distinguish valid codewords from words that are far from all codewords, by probing a given word only at a very small (sublinear, typically constant) number of locations. Such codes form the combinatorial backbone of PCPs. A major open problem is whether there exist LTCs with positive rate, constant relative distance and testable with a constant number of queries. 

In this paper, we present a new approach towards constructing such LTCs using the machinery of high-dimensional expanders. 
To this end, we consider the Tanner representation of a code, which is specified by a graph and a base code. Informally, our result states that if this graph is part of an {\em agreement expander} then the local testability of the code follows from the local testability of the base code. Agreement expanders allow one to stitch together many mostly-consistent local functions into a single global function. High-dimensional expanders are known to yield agreement expanders with constant degree. 

This work unifies and generalizes the known results on testability of the Hadamard, Reed-Muller and lifted codes, all of which are proved via a single round of local self-correction: the corrected value at a vertex v depends on the values of all vertices that share a constraint with v. In the above codes this set includes all of the vertices. In contrast, in our setting the degree of a vertex might be a constant, so we cannot hope for one-round self-correction. We overcome this technical hurdle by performing iterative self correction with logarithmically many rounds and tightly controlling the error in each iteration using properties of the agreement expander.

Given this result, the missing ingredient towards constructing a constant-query LTC with positive rate and constant relative distance is an instantiation of a base code and a constant-degree agreement expander that interact well with each other.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/072"><span class="datestr">at May 05, 2020 12:09 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01242">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01242">Probabilistic Analysis of RRT Trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Konrad Anand, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Devroye:Luc.html">Luc Devroye</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01242">PDF</a><br /><b>Abstract: </b>This thesis presents analysis of the properties and run-time of the
Rapidly-exploring Random Tree (RRT) algorithm. It is shown that the time for
the RRT with stepsize $\epsilon$ to grow close to every point in the
$d$-dimensional unit cube is $\Theta\left(\frac1{\epsilon^d} \log
\left(\frac1\epsilon\right)\right)$. Also, the time it takes for the tree to
reach a region of positive probability is $O\left(\epsilon^{-\frac32}\right)$.
Finally, a relationship is shown to the Nearest Neighbour Tree (NNT). This
relationship shows that the total Euclidean path length after $n$ steps is
$O(\sqrt n)$ and the expected height of the tree is bounded above by $(e +
o(1)) \log n$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01242"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01182">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01182">A Study of Performance of Optimal Transport</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Yihe.html">Yihe Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Yu.html">Yu Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Richard.html">Richard Peng</a>, Ilya Razenshteyn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sawlani:Saurabh.html">Saurabh Sawlani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01182">PDF</a><br /><b>Abstract: </b>We investigate the problem of efficiently computing optimal transport (OT)
distances, which is equivalent to the node-capacitated minimum cost maximum
flow problem in a bipartite graph. We compare runtimes in computing OT
distances on data from several domains, such as synthetic data of geometric
shapes, embeddings of tokens in documents, and pixels in images. We show that
in practice, combinatorial methods such as network simplex and augmenting path
based algorithms can consistently outperform numerical matrix-scaling based
methods such as Sinkhorn [Cuturi'13] and Greenkhorn [Altschuler et al'17], even
in low accuracy regimes, with up to orders of magnitude speedups. Lastly, we
present a new combinatorial algorithm that improves upon the classical
Kuhn-Munkres algorithm.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01182"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01112">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01112">Efficiently Testing Simon's Congruence</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gawrychowski:Pawel.html">Pawel Gawrychowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kosche:Maria.html">Maria Kosche</a>, Tore Koss, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manea:Florin.html">Florin Manea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Siemer:Stefan.html">Stefan Siemer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01112">PDF</a><br /><b>Abstract: </b>Simon's congruence $\sim_k$ is defined as follows: two words are
$\sim_k$-equivalent if they have the same set of subsequences of length at most
$k$. We propose an algorithm which computes, given two words $s$ and $t$, the
largest $k$ for which $s\sim_k t$. Our algorithm runs in linear time
$O(|s|+|t|)$ when the input words are over the integer alphabet
$\{1,\ldots,|s|+|t|\}$ (or other alphabets which can be sorted in linear time).
This approach leads to an optimal algorithm in the case of general alphabets as
well. Our results are based on a novel combinatorial approach and a series of
efficient data structures.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01112"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01098">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01098">A Dynamic Space-Efficient Filter with Constant Time Operations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bercea:Ioana_Oriana.html">Ioana Oriana Bercea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Even:Guy.html">Guy Even</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01098">PDF</a><br /><b>Abstract: </b>A dynamic dictionary is a data structure that maintains sets of cardinality
at most $n$ from a given universe and supports insertions, deletions, and
membership queries. A filter approximates membership queries with a one-sided
error that occurs with probability at most $\epsilon$. The goal is to obtain
dynamic filters that are space-efficient (the space is $1+o(1)$ times the
information-theoretic lower bound) and support all operations in constant time
with high probability. One approach to designing filters is to reduce to the
retrieval problem. When the size of the universe is polynomial in $n$, this
approach yields a space-efficient dynamic filter as long as the error parameter
$\epsilon$ satisfies $\log(1/\epsilon) = \omega(\log\log n)$.
</p>
<p>For the case that $\log(1/\epsilon) = O(\log\log n)$, we present the first
space-efficient dynamic filter with constant time operations in the worst case
(whp). In contrast, the space-efficient dynamic filter of Pagh, Pagh, Rao (SODA
2005) supports insertions and deletions in amortized expected constant time.
Our approach employs the classic reduction of Carter et al. (STOC 1978) on a
new type of dictionary construction that supports random multisets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01098"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01076">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01076">The complexity of approximating the complex-valued Potts model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Herrera=Poyatos:Andr=eacute=s.html">Andrés Herrera-Poyatos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01076">PDF</a><br /><b>Abstract: </b>We study the complexity of approximating the partition function of the
$q$-state Potts model and the closely related Tutte polynomial for complex
values of the underlying parameters. Apart from the classical connections with
quantum computing and phase transitions in statistical physics, recent work in
approximate counting has shown that the behaviour in the complex plane, and
more precisely the location of zeros, is strongly connected with the complexity
of the approximation problem, even for positive real-valued parameters.
Previous work in the complex plane by Goldberg and Guo focused on $q=2$, which
corresponds to the case of the Ising model; for $q&gt;2$, the behaviour in the
complex plane is not as well understood and most work applies only to the
real-valued Tutte plane.
</p>
<p>Our main result is a complete classification of the complexity of the
approximation problems for all non-real values of the parameters, by
establishing \#P-hardness results that apply even when restricted to planar
graphs. Our techniques apply to all $q\geq 2$ and further complement/refine
previous results both for the Ising model and the Tutte plane, answering in
particular a question raised by Bordewich, Freedman, Lov\'{a}sz and Welsh in
the context of quantum computations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01076"><span class="datestr">at May 05, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01045">Locally testable codes via high-dimensional expanders</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dikstein:Yotam.html">Yotam Dikstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dinur:Irit.html">Irit Dinur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harsha:Prahladh.html">Prahladh Harsha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ron=Zewi:Noga.html">Noga Ron-Zewi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01045">PDF</a><br /><b>Abstract: </b>Locally testable codes (LTC) are error-correcting codes that have a local
tester which can distinguish valid codewords from words that are "far" from all
codewords by probing a given word only at a very few (sublinear, typically
constant) number of locations. Such codes form the combinatorial backbone of
PCPs. A major open problem is whether there exist LTCs with positive rate,
constant relative distance and testable with a constant number of queries.
</p>
<p>In this paper, we present a new approach towards constructing such LTCs using
the machinery of high-dimensional expanders. To this end, we consider the
Tanner representation of a code, which is specified by a graph and a base code.
Informally, our result states that if this graph is part of a high-dimensional
expander then the local testability of the code follows from the local
testability of the base code.
</p>
<p>This work unifies and generalizes the known results on testability of the
Hadamard, Reed-Muller and lifted codes on the Subspace Complex, all of which
are proved via local self correction. However, unlike previous results,
constant rounds of self correction do not suffice as the diameter of the
underlying test graph can be logarithmically large in a high-dimensional
expander and not constant as in all known earlier results. We overcome this
technical hurdle by performing iterative self correction with logarithmically
many rounds and tightly controlling the error in each iteration using
properties of the high-dimensional expander.
</p>
<p>Given this result, the missing ingredient towards constructing a
constant-query LTC with positive rate and constant relative distance is an
instantiation of a base code that interacts well with a constant-degree
high-dimensional expander.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01045"><span class="datestr">at May 05, 2020 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01003">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01003">Variational Shape Approximation of Point Set Surfaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skrodzki:Martin.html">Martin Skrodzki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zimmermann:Eric.html">Eric Zimmermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Polthier:Konrad.html">Konrad Polthier</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01003">PDF</a><br /><b>Abstract: </b>In this work, we present a translation of the complete pipeline for
variational shape approximation (VSA) to the setting of point sets. First, we
describe an explicit example for the theoretically known non-convergence of the
currently available VSA approaches. The example motivates us to introduce an
alternate version of VSA based on a switch operation for which we prove
convergence. Second, we discuss how two operations - split and merge - can be
included in a fully automatic pipeline that is in turn independent of the
placement and number of initial seeds. Third and finally, we present two
approaches how to obtain a simplified mesh from the output of the VSA
procedure. This simplification is either based on simple plane intersection or
based on a variational optimization problem. Several qualitative and
quantitative results prove the relevance of our approach.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01003"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00947">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00947">Online Learning and Optimization for Revenue Management Problems with Add-on Discounts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simchi=Levi:David.html">David Simchi-Levi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Rui.html">Rui Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Huanan.html">Huanan Zhang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00947">PDF</a><br /><b>Abstract: </b>We study in this paper a revenue management problem with add-on discounts.
The problem is motivated by the practice in the video game industry, where a
retailer offers discounts on selected supportive products (e.g. video games) to
customers who have also purchased the core products (e.g. video game consoles).
We formulate this problem as an optimization problem to determine the prices of
different products and the selection of products with add-on discounts. To
overcome the computational challenge of this optimization problem, we propose
an efficient FPTAS algorithm that can solve the problem approximately to any
desired accuracy. Moreover, we consider the revenue management problem in the
setting where the retailer has no prior knowledge of the demand functions of
different products. To resolve this problem, we propose a UCB-based learning
algorithm that uses the FPTAS optimization algorithm as a subroutine. We show
that our learning algorithm can converge to the optimal algorithm that has
access to the true demand functions, and we prove that the convergence rate is
tight up to a certain logarithmic term. In addition, we conduct numerical
experiments with the real-world transaction data we collect from a popular
video gaming brand's online store on Tmall.com. The experiment results
illustrate our learning algorithm's robust performance and fast convergence in
various scenarios. We also compare our algorithm with the optimal policy that
does not use any add-on discount, and the results show the advantages of using
the add-on discount strategy in practice.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00947"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00937">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00937">Simultaneous Visibility Representations of Undirected Pairs of Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chugg:Ben.html">Ben Chugg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Evans:William_S=.html">William S. Evans</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wong:Kelvin.html">Kelvin Wong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00937">PDF</a><br /><b>Abstract: </b>We consider the problem of determining if a pair of undirected graphs
$\langle G_\mathsf{V}, G_\mathsf{H} \rangle$, which share the same vertex set,
has a representation using opaque geometric shapes for vertices, and
vertical/horizontal visibility between shapes to determine the edges of
$G_\mathsf{V}$/$G_\mathsf{H}$. While such a simultaneous visibility
representation of two graphs can be determined efficiently if the direction of
the required visibility for each edge is provided (and the vertex shapes are
sufficiently simple), it was unclear if edge direction is critical for
efficiency. We show that the problem is $\mathsf{NP}$-complete without that
information, even for graphs that are only slightly more complex than paths. In
addition, we characterize which pairs of paths have simultaneous visibility
representations using fixed orientation L-shapes. This narrows the range of
possible graph families for which determining simultaneous visibility
representation is non-trivial yet not $\mathsf{NP}$-hard.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00937"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00880">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00880">Almost Universal Anonymous Rendezvous in the Plane</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bouchard:S=eacute=bastien.html">Sébastien Bouchard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dieudonn=eacute=:Yoann.html">Yoann Dieudonné</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pelc:Andrzej.html">Andrzej Pelc</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petit:Franck.html">Franck Petit</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00880">PDF</a><br /><b>Abstract: </b>Two mobile agents represented by points freely moving in the plane and
starting at two distinct positions, have to meet. The meeting, called
rendezvous, occurs when agents are at distance at most $r$ of each other and
never move after this time, where $r$ is a positive real unknown to them,
called the visibility radius. Agents are anonymous and execute the same
deterministic algorithm. Each agent has a set of private attributes, some or
all of which can differ between agents. These attributes are: the initial
position of the agent, its system of coordinates (orientation and chirality),
the rate of its clock, its speed when it moves, and the time of its wake-up. If
all attributes (except the initial positions) are identical and agents start at
distance larger than $r$ then they can never meet. However, differences between
attributes make it sometimes possible to break the symmetry and accomplish
rendezvous. Such instances of the rendezvous problem (formalized as lists of
attributes), are called feasible.
</p>
<p>Our contribution is three-fold. We first give an exact characterization of
feasible instances. Thus it is natural to ask whether there exists a single
algorithm that guarantees rendezvous for all these instances. We give a strong
negative answer to this question: we show two sets $S_1$ and $S_2$ of feasible
instances such that none of them admits a single rendezvous algorithm valid for
all instances of the set. On the other hand, we construct a single algorithm
that guarantees rendezvous for all feasible instances outside of sets $S_1$ and
$S_2$. We observe that these exception sets $S_1$ and $S_2$ are geometrically
very small, compared to the set of all feasible instances: they are included in
low-dimension subspaces of the latter. Thus, our rendezvous algorithm handling
all feasible instances other than these small sets of exceptions can be justly
called almost universal.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00880"><span class="datestr">at May 05, 2020 01:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00875">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00875">Deterministic Treasure Hunt in the Plane with Angular Hints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bouchard:S=eacute=bastien.html">Sébastien Bouchard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dieudonn=eacute=:Yoann.html">Yoann Dieudonné</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pelc:Andrzej.html">Andrzej Pelc</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petit:Franck.html">Franck Petit</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00875">PDF</a><br /><b>Abstract: </b>A mobile agent equipped with a compass and a measure of length has to find an
inert treasure in the Euclidean plane. Both the agent and the treasure are
modeled as points. In the beginning, the agent is at a distance at most $D&gt;0$
from the treasure, but knows neither the distance nor any bound on it. Finding
the treasure means getting at distance at most 1 from it. The agent makes a
series of moves. Each of them consists in moving straight in a chosen direction
at a chosen distance. In the beginning and after each move the agent gets a
hint consisting of a positive angle smaller than $2\pi$ whose vertex is at the
current position of the agent and within which the treasure is contained. We
investigate the problem of how these hints permit the agent to lower the cost
of finding the treasure, using a deterministic algorithm, where the cost is the
worst-case total length of the agent's trajectory. It is well known that
without any hint the optimal (worst case) cost is $\Theta(D^2)$. We show that
if all angles given as hints are at most $\pi$, then the cost can be lowered to
$O(D)$, which is optimal. If all angles are at most $\beta$, where $\beta&lt;2\pi$
is a constant unknown to the agent, then the cost is at most
$O(D^{2-\epsilon})$, for some $\epsilon&gt;0$. For both these positive results we
present deterministic algorithms achieving the above costs. Finally, if angles
given as hints can be arbitrary, smaller than $2\pi$, then we show that cost
$\Theta(D^2)$ cannot be beaten.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00875"><span class="datestr">at May 05, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00858">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00858">Minimum Cuts in Geometric Intersection Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cabello:Sergio.html">Sergio Cabello</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00858">PDF</a><br /><b>Abstract: </b>Let $\mathcal{D}$ be a set of $n$ disks in the plane. The \emph{disk graph}
$G_\mathcal{D}$ for $\mathcal{D}$ is the undirected graph with vertex set
$\mathcal{D}$ in which two disks are joined by an edge if and only if they
intersect. The \emph{directed transmission graph} $G^{\rightarrow}_\mathcal{D}$
for $\mathcal{D}$ is the directed graph with vertex set $\mathcal{D}$ in which
there is an edge from a disk $D_1 \in \mathcal{D}$ to a disk $D_2 \in
\mathcal{D}$ if and only if $D_1$ contains the center of $D_2$.
</p>
<p>Given $\mathcal{D}$ and two non-intersecting disks $s, t \in \mathcal{D}$, we
show that a minimum $s$-$t$ vertex cut in $G_\mathcal{D}$ or in
$G^{\rightarrow}_\mathcal{D}$ can be found in $O(n^{3/2}\operatorname{polylog}
n)$ expected time. To obtain our result, we combine an algorithm for the
maximum flow problem in general graphs with dynamic geometric data structures
to manipulate the disks.
</p>
<p>As an application, we consider the \emph{barrier resilience problem} in a
rectangular domain. In this problem, we have a vertical strip $S$ bounded by
two vertical lines, $L_\ell$ and $L_r$, and a collection $\mathcal{D}$ of
disks. Let $a$ be a point in $S$ above all disks of \mathcal{D}, and let $b$ a
point in $S$ below all disks of $\mathcal{D}$. The task is to find a curve from
$a$ to $b$ that lies in $S$ and that intersects as few disks of $\mathcal{D}$
as possible. Using our improved algorithm for minimum cuts in disk graphs, we
can solve the barrier resilience problem in $O(n^{3/2}\operatorname{polylog}
n)$ expected time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00858"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00853">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00853">Lower Bounds for Non-Elitist Evolutionary Algorithms Via Negative Multiplicative Drift</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doerr:Benjamin.html">Benjamin Doerr</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00853">PDF</a><br /><b>Abstract: </b>A decent number of lower bounds for non-elitist population-based evolutionary
algorithms has been shown by now. Most of them are technically demanding due to
the (hard to avoid) use of negative drift theorems -- general results which
translate an expected progress away from the target into a high hitting time.
</p>
<p>We propose a simple negative drift theorem for multiplicative drift scenarios
and show that it simplifies many existing results. We discuss in more detail
Lehre's (PPSN 2010) \emph{negative drift in populations} method, one of the
most general tools to prove lower bounds on the runtime of non-elitist
evolutionary algorithms. Together with other arguments, we obtain an
alternative and simpler proof, which also strengthens and simplifies this
method. In particular, now only three of the five technical conditions of the
previous result have to be verified. The lower bounds we obtain are explicit
instead of only asymptotic. This allows to compute concrete lower bounds for
concrete algorithms, but also enables us to show that super-polynomial runtimes
appear already when the reproduction rate is only a $(1 - \omega(n^{-1/2}))$
factor below the threshold. As one particular result, we apply this method, for
the first time, to an algorithm using fitness-proportionate selection.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00853"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00809">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00809">More on NP Versus P</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gordeev:Lev.html">Lev Gordeev</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00809">PDF</a><br /><b>Abstract: </b>We generalize a well-known result that P = NP fails for monotone polynomial
circuits - more precisely, that the clique problem CLIQUE(k^4,k) is not
solvable by Boolean (AND,OR)-circuits of the size polynomial in k. In the other
words, there is no (AND,OR)-formula F with 1/2(k^4-1)k^4 Boolean variables
expressing that a given graph with k^4 vertices contains a clique of k
elements, provided that the circuit length of F, cl(F), is polynomial in k. In
fact, for any solution F in question, cl(F) must be exponential in k. Moreover
this holds also for DeMorgan normal (abbr.: DMN) (AND,OR)-formulas F that allow
negated variables. Based on the latter observation we consider an arbitrary
(AND,OR,NOT)-formula F and recall that standard NOT-conversions to DMN at most
double its circuit length. Hence for any Boolean solution F of CLIQUE(k^4,k),
cl(F) is exponential in k. We conclude that CLIQUE(k^4,k) is not solvable by
polynomial-size Boolean circuits, and hence P is not NP. The entire proof is
formalizable by standard methods in the exponential function arithmetic EFA.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00809"><span class="datestr">at May 05, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00690">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00690">Independent Set on P$_k$-Free Graphs in Quasi-Polynomial Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Peter Gartland, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00690">PDF</a><br /><b>Abstract: </b>We present an algorithm that takes as input a graph $G$ with weights on the
vertices, and computes a maximum weight independent set $S$ of $G$. If the
input graph $G$ excludes a path $P_k$ on $k$ vertices as an induced subgraph,
the algorithm runs in time $n^{O(k^2 \log^3 n)}$. Hence, for every fixed $k$
our algorithm runs in quasi-polynomial time. This resolves in the affirmative
an open problem of [Thomass\'{e}, SODA'20 invited presentation]. Previous to
this work, polynomial time algorithms were only known for $P_4$-free graphs
[Corneil et al., DAM'81], $P_5$-free graphs [Lokshtanov et al., SODA'14], and
$P_6$-free graphs [Grzesik et al., SODA'19]. For larger values of $t$, only
$2^{O(\sqrt{kn\log n})}$ time algorithms [Basc\'{o} et al., Algorithmica'19]
and quasi-polynomial time approximation schemes [Chudnovsky et al., SODA'20]
were known. Thus, our work is the first to offer conclusive evidence that
Independent Set on $P_k$-free graphs is not NP-complete for any integer $k$.
</p>
<p>Additionally we show that for every graph $H$, if there exists a
quasi-polynomial time algorithm for Independent Set on $C$-free graphs for
every connected component $C$ of $H$, then there also exists a quasi-polynomial
time algorithm for {\sc Independent Set} on $H$-free graphs. This lifts our
quasi-polynomial time algorithm to $T_k$-free graphs, where $T_k$ has one
component that is a $P_k$, and $k-1$ components isomorphic to a fork (the
unique $5$-vertex tree with a degree $3$ vertex).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00690"><span class="datestr">at May 05, 2020 01:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00681">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00681">Pointer-Machine Algorithms for Fully-Online Construction of Suffix Trees and DAWGs on Multiple Strings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00681">PDF</a><br /><b>Abstract: </b>We deal with the problem of maintaining the suffix tree indexing structure
for a fully-online collection of multiple strings, where a new character can be
prepended to any string in the collection at any time. The only previously
known algorithm for the problem, recently proposed by Takagi et al.
[Algorithmica 82(5): 1346-1377 (2020)], runs in $O(N \log \sigma)$ time and
$O(N)$ space on the word RAM model, where $N$ denotes the total length of the
strings and $\sigma$ denotes the alphabet size. Their algorithm makes heavy use
of the nearest marked ancestor (NMA) data structure on semi-dynamic trees, that
can answer queries and supports insertion of nodes in $O(1)$ amortized time on
the word RAM model. In this paper, we present a simpler fully-online
right-to-left algorithm that builds the suffix tree for a given string
collection in $O(N (\log \sigma + \log d))$ time and $O(N)$ space, where $d$ is
the maximum number of in-coming Weiner links to a node of the suffix tree. We
note that $d$ is bounded by the height of the suffix tree, which is further
bounded by the length of the longest string in the collection. The advantage of
this new algorithm is that it works on the pointer machine model, namely, it
does not use the complicated NMA data structures that involve table look-ups.
As a byproduct, we also obtain a pointer-machine algorithm for building the
directed acyclic word graph (DAWG) for a fully-online left-to-right collection
of multiple strings, which runs in $O(N (\log \sigma + \log d))$ time and
$O(N)$ space again without the aid of the NMA data structures.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00681"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00593">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00593">Strong subalgebras and the Constraint Satisfaction Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhuk:Dmitriy.html">Dmitriy Zhuk</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00593">PDF</a><br /><b>Abstract: </b>In 2007 it was conjectured that the Constraint Satisfaction Problem (CSP)
over a constraint language $\Gamma$ is tractable if and only if $\Gamma$ is
preserved by a weak near-unanimity (WNU) operation. After many efforts and
partial results, this conjecture was independently proved by Andrei Bulatov and
the author in 2017. In this paper we consider one of two main ingredients of my
proof, that is, strong subalgebras that allow us to reduce domains of the
variables iteratively. To explain how this idea works we show the algebraic
properties of strong subalgebras and provide self-contained proof of two
important facts about the complexity of the CSP. First, we prove that if a
constraint language is not preserved by a WNU operation then the corresponding
CSP is NP-hard. Second, we characterize all constraint languages that can be
solved by local consistency checking. Additionally, we characterize all
idempotent algebras not having a WNU term of a concrete arity $n$, not having a
WNU term, having WNU terms of all arities greater than 2. Most of the results
presented in the paper are not new, but I believe this paper can help to
understand my approach to CSP and the new self-contained proof of known facts
will be also useful.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00593"><span class="datestr">at May 05, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00575">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00575">Approximating maximum integral multiflows on bounded genus graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Chien-chung Huang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mari:Mathieu.html">Mathieu Mari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mathieu:Claire.html">Claire Mathieu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vygen:Jens.html">Jens Vygen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00575">PDF</a><br /><b>Abstract: </b>We devise the first constant-factor approximation algorithm for finding an
integral multi-commodity flow of maximum total value for instances where the
supply graph together with the demand edges can be embedded on an orientable
surface of bounded genus. This extends recent results for planar instances.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00575"><span class="datestr">at May 05, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/">postdoc position at University of Alberta (apply by December 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Theory Group in the Dept. of Computing Science at U. of Alberta invites applications for TWO postdoc positions. The successful applicants are expected to work closely with Zachary Friggstad and Mohammad Salavatipour in the areas of: approx algorithms, hardness of approximation, combinatorial optimization. For details see <a href="https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf">https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf</a><br />
Email: mrs@ualberta.ca</p>
<p>Website: <a href="http://www.cs.ualberta.ca">http://www.cs.ualberta.ca</a><br />
Email: mrs@ualberta.ca</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/"><span class="datestr">at May 04, 2020 06:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/071">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/071">TR20-071 |  A Tight Lower Bound on Adaptively Secure Full-Information Coin Flip | 

	Iftach Haitner, 

	Yonatan Karidi-Heller</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a distributed coin-flipping protocol, Blum [ACM Transactions on Computer Systems '83],
the parties try to output a common (close to) uniform bit, even when some adversarially chosen parties try to bias the common output. In an adaptively secure full-information coin flip, Ben-Or and Linial [FOCS '85], the parties communicate over a broadcast channel and a computationally unbounded adversary can choose which parties to corrupt during the protocol execution. Ben-Or and Linial proved that the $n$-party majority protocol is resilient to $o(\sqrt{n})$ corruptions (ignoring log factors), and conjectured this is a tight upper bound for any $n$-party protocol (of any round complexity). Their conjecture was proved to be correct for single-turn (each party sends a single message) single-bit (a message is one bit) protocols, Lichtenstein, Linial, and Saks [Combinatorica '89], symmetric protocols Goldwasser, Kalai, and Park [ICALP '15], and recently for (arbitrary message length) single-turn protocols Tauman Kalai, Komargodski, and Raz [DISC '18]. Yet, the question for many-turn (even single-bit) protocols was left completely open.

In this work we close the above gap, proving that no $n$-party protocol (of any round complexity) is resilient to $O(\sqrt{n})$ (adaptive) corruptions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/071"><span class="datestr">at May 04, 2020 02:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/070">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/070">TR20-070 |  On the list recoverability of randomly punctured codes | 

	Ben Lund, 

	Aditya Potukuchi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that a random puncturing of a code with good distance is list recoverable beyond the Johnson bound.
In particular, this implies that there are Reed-Solomon codes that are list recoverable beyond the Johnson bound.
It was previously known that there are Reed-Solomon codes that do not have this property. 
As an immediate corollary to our main theorem, we obtain better degree bounds on unbalanced expanders that come from Reed-Solomon codes.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/070"><span class="datestr">at May 04, 2020 09:06 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1297">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1297">News for April 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>April is now behind us, and we hope you and your families are all staying safe and healthy. We saw <s>six</s> seven property papers appear online last month, so at least there is some reading ahead of us! A mixture of privacy, quantum, high-dimensional distributions, and juntas (juntæ?). A lot of distribution testing, overall.</p>



<p><strong>Connecting Robust Shuffle Privacy and Pan-Privacy</strong>, by Victor Balcer, Albert Cheu, Matthew Joseph, and Jieming Mao (<a href="https://arxiv.org/abs/2004.09481">arXiv</a>). This paper considers a recent notion of differential privacy called<em> shuffle privacy</em>, where users have sensitive data, a central untrusted server wants to do something with that data (for instance, say… testing its distribution), and a trusted middle-man/entity shuffles the users’ messages u.a.r. to bring in a bit more anonymity. As it turns out, testing uniformity (or identity) of distributions in the shuffle privacy model is (i) much harder than without privacy constraints; (ii) much harder than with ‘usual’ (weaker) differential privacy (iii) much easier than with local privacy; (iv) related to the sample complexity under another privacy notion, <em>pan-privacy</em>. It’s a brand exciting new world out there!</p>



<p><em>(Note: for the reader interested in keeping track of identity/uniformity testing of probability distributions under various privacy models, I wrote a very short summary of the current results <a href="https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/private-goodness-of-fit.pdf">here</a>.)</em></p>



<p><strong>Entanglement is Necessary for Optimal Quantum Property Testing, </strong>by Sebastien Bubeck, Sitan Chen, and Jerry Li (<a href="https://arxiv.org/abs/2004.07869">arXiv</a>). The analogue of uniformity testing, in the quantum world, is testing whether a quantum state is equal (or far from) the maximally mixed state. It’s known that this task  has “quantum sample complexity” (number of measurements) \(\Theta(d/\varepsilon^2)\) (i.e., square root dependence on  the dimension of the state, \(d^2\)). But this requires <em>entangled</em> measurements, which may be tricky to get (or, in my case, understand): what happens if the measurements can be adaptive, but not entangled? In this work, the authors show that, under this weaker access model \(\Omega(d^{4/3}/\varepsilon^2)\) measurements are necessary: adaptivity alone won’t cut it. It may still help though: without either entanglement <em>nor</em> adaptivity, the authors also show a \(\Omega(d^{3/2}/\varepsilon^2)\) measurements lower bound.</p>



<p><strong>Testing Data Binnings</strong>, by Clément Canonne and Karl Wimmer (<a href="https://eccc.weizmann.ac.il/report/2020/062/">ECCC</a>). More identity testing! Not private and not quantum for this one, but… not <em>quite</em> identity testing either. To paraphrase the abstract: this paper introduces (and gives near matching bounds for)  the related question of <em>identity up to binning</em>, where the reference distribution \(q\) is over \(k \ll n\) elements: the question is then whether there exists a suitable binning of the domain \([n]\) into \(k\) intervals such that, <em>once binned</em>, \(p\) is equal to \(q\).” </p>



<p><strong>Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models</strong>, by Antonio Blanca, Zongchen Chen, Daniel Štefankovič, and Eric Vigoda (<a href="https://arxiv.org/abs/2004.10805">arXiv</a>). Back to identity testing of distributions, but for high-dimensional structured ones this one. Specifically, this paper focuses on the undirected graphical models known as <em>restricted Boltzmann machines, </em>and provides efficient algorithms for identity testing and conditional hardness lower bounds depending on the type of correlations allowed in the graphical models.</p>



<p><strong>Robust testing of low-dimensional functions</strong>, by Anindya De, Elchanan Mossel, and Joe Neeman (<a href="https://arxiv.org/abs/2004.11642">arXiv</a>). Junta testing is a classical, central problem in property testing, with motivations and applications in machine learning and complexity. The related (and equally well-motivated) question of junta testing of functions on \(\mathbb{R}^d\) (instead of the Boolean hypercube) was recently studied by the same authors; and the related (and, again, equally well-motivated) question of <em>tolerant</em> junta testing on the Boolean hypercube was also recently studied (among other works) by the same authors. Well, this paper does it all, and tackles the challenging (and, for a change, equally well-motivated!) question of <em>tolerant</em> testing of juntas  on \(\mathbb{R}^d\).</p>



<p><strong>Differentially Private Assouad, Fano, and Le Cam</strong>, by Jayadev Acharya, Ziteng Sun, and Huanyu Zhang (<a href="https://arxiv.org/abs/2004.06830">arXiv</a>). Back to probability distributions and privacy. This paper provides differentially private analogues of the classical eponymous statistical inference results (Assouad’s lemma, Fano’s inequality, and Le Cam’s method). In particular, it gives ready-to-use, blackbox tools to prove testing and learning lower bounds for distributions in the differentially private setting, and shows how to use them to easily derive, and rederive, several lower bounds.</p>



<p><strong>Edit: </strong>We missed one!</p>



<p><strong>Learning and Testing Junta Distributions with Subcube Conditioning</strong>, by Xi Chen, Rajesh Jayaram, Amit Levi, Erik Waingarten (<a href="https://arxiv.org/abs/2004.12496">arXiv</a>). This paper focuses on the <em>subcube conditioning</em> model of (high-dimensional) distribution testing, where the algorithm can fix some variables to values of its choosing and get samples conditioned on those variables. Extending and refining techniques from <a href="https://ptreview.sublinear.info/?p=1227">a previous work by a (sub+super)set of the authors</a>, the paper shows how to optimally learn and test <a href="http://proceedings.mlr.press/v49/aliakbarpour16.html">junta distributions</a> in this framework—with exponential savings with respect to the usual i.i.d. sampling model.</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1297"><span class="datestr">at May 04, 2020 01:52 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blog.simons.berkeley.edu/?p=164">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/simons.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/">Fine-grained hardness of lattice problems: Open questions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<h1>1 Introduction</h1>
<h2>1.1 Lattices and lattice-based cryptography</h2>
<p>Lattices are classically-studied geometric objects that in the past few decades have found a multitude of applications in computer science. The most important application area is <em>lattice-based cryptography</em>, the design of cryptosystems whose security is based on the apparent intractability of computational problems on lattices, even for quantum computers. Indeed, lattice-based cryptography has revolutionized the field because of its apparent quantum resistance and its other attractive security, functionality, and efficiency properties.</p>
<p>Intuitively, a lattice is a regular ordering of points in some (typically high-dimensional) space. More precisely, a <em>lattice</em> \( {{\cal{L}}}\) of rank \( {n}\) is the set of all integer linear combinations of some linearly independent vectors \( {\mathbf{b}_1, \ldots, \mathbf{b}_n}\), which are called a <em>basis</em> of \( {{\cal{L}}}\). We will be primarily interested in analyzing the running times of lattice algorithms as functions of the lattice’s rank \( {n}\).</p>
<h2>1.2. Computational lattice problems</h2>
<p>The two most important computational problems on lattices are the Shortest Vector Problem (SVP) and the Closest Vector Problem (CVP). SVP asks, given a basis of a lattice \( {{\cal{L}}}\) as input, to find a shortest non-zero vector in \( {{\cal{L}}}\). CVP, which can be viewed as an inhomogeneous version of SVP, asks, given a basis of a lattice \( {{\cal{L}}}\) and a target point \( {\mathbf{t}}\) as input, to find a closest vector in \( {{\cal{L}}}\) to \( {\mathbf{t}}\).</p>
<p>Algorithms for solving SVP form the core of the best known attacks on lattice-based cryptography both in theory and in practice. Accordingly, it is critical to understand the precise complexity of SVP as well as possible. The best provably correct algorithms for both SVP and CVP run in \( {2^{n + o(n)}}\)-time [<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>, <a href="https://arxiv.org/abs/1504.01995">ADS15</a>, <a href="https://arxiv.org/abs/1709.01535">AS18a</a>]. The best heuristic algorithms for SVP run in \( {2^{cn + o(n)}}\)-time for \( {c = 0.292}\) classically [<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] and \( {c = 0.265}\) using quantum speedups [<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] (see also [<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>]), and most real-world lattice-based cryptosystems assume that these algorithms are close to optimal. Indeed, many of these cryptosystems assume what Albrecht et al. [<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>] call a “paranoid” worst-case estimate of \( {c = 0.2075}\) (based on the kissing number and assuming that sieving algorithms are optimal) as the fastest hypothetical running time for SVP algorithms when choosing parameters. Accordingly, the difference in being able to solve SVP in \( {2^{0.2075n}}\) versus \( {2^{n/20}}\) versus \( {2^{\sqrt{n}}}\) time may mean the difference between lattice-based cryptosystems being secure, insecure with current parameters, or effectively broken in practice.</p>
<p>There is a rank-preserving reduction from SVP to CVP [<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>], so any algorithm for CVP immediately gives an essentially equally fast algorithm for SVP. In other words, CVP is at least as hard as SVP (and probably a bit harder). Indeed, historically, almost all lower bounds for SVP are proven via reduction from CVP (and nearly all algorithmic progress on CVP uses ideas originally developed for SVP).</p>
<h2>1.3. Fine-grained hardness</h2>
<p>The field of fine-grained complexity works to give strong, quantitative lower bounds on computational problems assuming standard complexity-theoretic assumptions. Proving such a (conditional) lower bound for an \( {{\mathsf{NP}}}\)-hard problem generally works by (1) assuming a stronger hardness assumption than \( {{\mathsf{P}} \neq {\mathsf{NP}}}\) about the complexity of \( {k}\)-SAT (such as ETH or SETH, defined below), and (2) giving a highly efficient reduction from \( {k}\)-SAT to the problem. The most important hardness assumptions for giving lower bounds on \( {{\mathsf{NP}}}\)-hard problems are the Exponential Time Hypothesis (ETH) and the Strong Exponential Time Hypothesis (SETH) of Impagliazzo and Paturi [<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>]. ETH asserts that there is no \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT, and SETH asserts that for every \( {\epsilon &gt; 0}\) there exists \( {k \in {\mathbb Z}^+}\) such that there is no \( {2^{(1 – \epsilon)n}}\)-time algorithm for \( {k}\)-SAT, where \( {n}\) denotes the number of variables in the SAT instance.</p>
<p>Here by “highly efficient” reductions we mean linear ones, i.e., reductions that map a \( {3}\)-SAT or \( {k}\)-SAT formula on \( {n}\) variables to an SVP or CVP instance of rank \( {C n + o(n)}\) for some absolute constant \( {C &gt; 0}\). Indeed, by giving a reduction from \( {3}\)-SAT (respectively, \( {k}\)-SAT for any \( {k \in {\mathbb Z}^+}\)) instances on \( {n}\) variables to SVP or CVP instances of rank \( {C n + o(n)}\), we can conclude that there is no \( {2^{o(n)}}\)-time (resp., \( {2^{(1-\epsilon)n/C}}\)-time for any \( {\epsilon &gt; 0}\)) algorithm for the corresponding problem assuming ETH (resp., SETH). Note that the smaller the value of \( {C}\) for which one can show such a reduction, the stronger the conclusion. In particular, a reduction mapping \( {k}\)-SAT instances on \( {n}\) variables to SVP or CVP instances of rank \( {n + o(n)}\) would imply an essentially tight lower bound on the corresponding problem assuming SETH — as mentioned above, the best provably correct algorithms for both SVP and CVP run in time \( {2^{n + o(n)}}\).</p>
<h2>1.4. Fine-grained hardness of CVP (and SVP)</h2>
<p>It is relatively easy to show that CVP is “ETH-hard,” i.e., to show that a \( {2^{o(n)}}\)-time algorithm for CVP would imply a \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT instances with \( {n}\) variables. This would falsify ETH. (It’s a nice exercise to show that the Subset Sum problem on a set of size \( {n}\) reduces to CVP on a lattice of rank \( {n}\), which implies the result.)</p>
<p>With some work, Divesh Aggarwal and Noah extended this to SVP [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>]. In particular, we showed a reduction from CVP to SVP that only increases the rank of the lattice by some constant multiplicative factor. (Formally, the reduction only works with certain minor constraints on the CVP instance. The reduction originally relied on a geometric conjecture, which was open for decades. But, Serge Vlăduţ proved the conjecture [<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] shortly after we published!)</p>
<p>So, unless ETH is false, there is no \( {2^{o(n)}}\)-time algorithm for CVP or SVP. But, for cryptographic applications, even, say, a \( {2^{n/20}}\)-time algorithm would be completely devastating. If such an algorithm were found, cryptographic schemes that we currently think are secure against absurdly powerful attackers straight out of science fiction (say, one with a computer the size of the sun running until the heat death of the universe) would turn out to be easily broken (e.g., in seconds on our laptops).</p>
<p>In [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we <em>almost</em> showed that CVP is “SETH-hard,” i.e., that a \( {2^{(1-\epsilon)n}}\)-time algorithm for CVP would imply such an algorithm for \( {k}\)-SAT for <em>any</em> constant \( {k}\). This would falsify SETH. So, we <em>almost</em> showed that the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm is optimal. The “almost” is because our proof works with \( {\ell_p}\) norms, that is, we show hardness for the version of CVP in which the distance from the target to a lattice vector is defined in terms of the \( {\ell_p}\) norm,</p>
<p align="center">\( \displaystyle \|\mathbf{x}\|_p := (|x_1|^p + \cdots + |x_d|^p)^{1/p} \; . \)</p>
<p>We call the corresponding problem \( {{\mathrm{CVP}}_p}\). In fact, our proof works for all \( {\ell_p}\) norms <em>except</em> when \( {p}\) is an even integer. (To see why this might happen, notice \( {\|\mathbf{x}\|_p^p}\) is a polynomial in the \( {x_i}\) if and only if \( {p}\) is an even integer. In fact, there’s some sense in which “\( {\ell_2}\) is the easiest norm,” because for any \( {p}\), there is a linear map \( {A \in {\mathbb R}^{d \times m}}\) such that \( {m}\) is not too large and \( {\|\mathbf{x}\|_2 \approx \|A \mathbf{x}\|_p}\).) Of course, we are most interested in the case \( {p= 2}\) (the only case for which the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm works), which is an even integer! Indeed, for all \( {p \neq 2}\), the fastest known algorithm for CVP is still Ravi Kannan’s \( {n^{O(n)}}\)-time algorithm from 1987 [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>]. (For SVP and for constant-factor approximate CVP, \(2^{O(n)}\)-time algorithms are known [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>].)</p>
<p>In fact, we showed that for \( {p = 2}\), no “natural” reduction can rule out a \( {2^{3n/4}}\)-time algorithm for CVP under SETH. A “natural” reduction is one with a fixed bijection between witnesses. In particular, any “natural” reduction from \( {3}\)-SAT to CVP must reduce to a lattice with rank at least roughly \( {4n/3}\). So, new ideas will be needed to prove stronger hardness of CVP in the \( {\ell_2}\) norm.</p>
<h1>2. Open problems</h1>
<p>We now discuss some of the problems that we left open in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]. For simplicity, we ask for specific results (e.g., “prove that problem \( {A}\) is \( {T}\)-hard under hypothesis \( {B}\)“), but of course any similar results would be very interesting (e.g., “\( {A}\) is \( {T’}\)-hard under hypothesis \( {B’}\)“).</p>
<h2>2.1. Hardness in the \(\ell_2\) norm</h2>
<p>The most obvious question that we left open is, of course, to prove similar \( {2^n}\)-time hardness results for \( {{\mathrm{CVP}}_2}\) (and more generally for \( {{\mathrm{CVP}}_p}\) for even integers \( {p}\)).</p>
<blockquote>
<p><b>Open problem 1.</b> Show that there is no \( {2^{0.99 n}}\)-time algorithm for \( {{\mathrm{CVP}}_2}\) assuming SETH.</p>
</blockquote>
<p>Remember that we showed that any proof of such a strong result would have to use an “unnatural” reduction. So, a fundamentally different approach is needed. One potentially promising direction would be to find a Cook reduction, as our limitations only apply to Karp reductions.</p>
<p>Alternatively, one might try for a different result that gets around this “natural” reduction limitations. E.g., even the following much weaker result would be very interesting.</p>
<blockquote>
<p><b>Open problem 2.</b> Show an efficient reduction from \( {3}\)-SAT on \( {n}\) variables to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {\approx 10n}\).</p>
</blockquote>
<p>Such a reduction to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {Cn}\) for some large constant \( {C}\) is known by applying the Sparsification Lemma [<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] to \( {3}\)-SAT, but showing such a reduction for any reasonably small \( {C}\) or even any explicit \( {C}\) using a different proof technique would be interesting.</p>
<p>Also, our limitations only apply to reductions that map satisfying assignments to <em>exact</em> closest vectors. So, one might try to get around our limitation by working directly with approximate versions of \( {3}\)-SAT and \( {{\mathrm{CVP}}_2}\). (In [<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we show such reductions from Gap-\( {k}\)-SAT to constant-factor approximate \( {{\mathrm{CVP}}_p}\) for all \( {p \notin 2{\mathbb Z}}\) as well as all \( {k \leq p}\). We also show reductions from Gap-\( {k}\)-Parity that achieve relatively large approximation factors.)</p>
<blockquote>
<p><b>Open problem 3.</b> Show an efficient reduction from Gap-\( {3}\)-SAT on \( {n}\) variables to approximate \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {n}\).</p>
</blockquote>
<h2>2.2. Hardness in \(\ell_p\) norms</h2>
<p>Intuitively, one reason that we are able to prove such strong results for \( {\ell_p}\) norms for \( {p \neq 2}\) is because we can use lattices with large ambient dimension \( {d}\) but low rank \( {n}\). In other words, while our reductions produce lattices \( {{\cal{L}}}\) that live in some \( {n}\)-dimensional subspace of \( {\ell_p}\)-space, the ambient space itself has large dimension \( {d}\) relative to \( {n}\). Of course, any subspace of the \( {\ell_2}\) norm is an \( {\ell_2}\) subspace (i.e., every slice of a ball is a lower-dimensional ball), so in the \( {\ell_2}\) norm, one can assume without loss of generality that \( {d = n}\). In particular, if we were able to prove \( {2^n}\)-hardness for the \( {\ell_2}\) norm, then we would actually prove \( {2^d}\)-hardness for free. However, a potentially easier problem would be to improve the \( {2^n}\)-hardness of \( {{\mathrm{CVP}}_p}\) shown in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]  to \( {2^d}\)-hardness for some \( p \neq 2 \).</p>
<blockquote>
<p><b>Open problem 4.</b> Show that there is no \( {2^{0.99 d}}\)-time algorithm for \( {{\mathrm{CVP}}_p}\) (for some \( {p}\)) assuming SETH.</p>
</blockquote>
<p>More generally, it would be very interesting to settle the fine-grained complexity of \( {{\mathrm{CVP}}_p}\) for some \( {p \neq 2}\) (either in terms of rank \( {n} \) or dimension \( {d} \)). This could take the form either of showing improved algorithms (currently the fastest algorithms for \( {{\mathrm{CVP}}_p}\) for general \( {p}\) run in \( {n^{O(n)}}\)-time [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>], and \( {2^{O(n)}}\)-time for a constant approximation factor [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>]), or showing super-\( {2^n}\) hardness, or both.</p>
<blockquote>
<p><b>Open problem 5.</b> Show matching upper bounds and lower bounds (under SETH) for \( {{\mathrm{CVP}}_p}\) for some \( {p}\) (possibly with a constant approximation factor).</p>
</blockquote>
<p>The case where \( {p = \infty}\) is especially interesting. Indeed, because the kissing number in the \( {\ell_\infty}\) norm is \( {3^n-1}\), one might guess that the fastest algorithms for \( {{\mathrm{CVP}}_\infty}\) and \( {{\mathrm{SVP}}_\infty}\) actually run in time \( {3^{n + o(n)}}\) or perhaps \( {3^{d + o(d)}}\). (See [<a href="https://arxiv.org/pdf/1801.02358">AM18</a>], which essentially achieves this.) We therefore ask whether stronger lower bounds can be proven in this special case.</p>
<blockquote>
<p><b>Open problem 6.</b> Show that \( {{\mathrm{CVP}}_\infty}\) cannot be solved in time \( {3^{0.99n}}\) (under SETH).</p>
</blockquote>
<h2>2.3. Hardness closer to crypto</h2>
<p>The most relevant problem to cryptography is approximate \( {{\mathrm{SVP}}_2}\) with an approximation factor that is polynomial in the rank \( {n}\). Our fastest algorithms to solve this problem work via a reduction to exact (or near exact) \( {{\mathrm{SVP}}_2}\) with some lower rank \( {n’ = \Theta(n)}\), so that even for these polynomial approximation factors, our fastest algorithms run in time \( {2^{\Omega(n)}}\) (where the hidden constant depends on the polynomial; see <a href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/">Michael’s post</a> for more on this topic). And, hardness results for exact SVP rule out attacks on cryptography that use such reductions. We currently only know how to rule out \( {2^{o(n)}}\)-time algorithms for \( {{\mathrm{SVP}}_2}\) (under the Gap-ETH assumption). We ask whether we can do better. (In [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>], we proved the stronger result below for \( {\ell_p}\) norms for large enough \( {p \notin 2{\mathbb Z}}\).)</p>
<blockquote>
<p><b>Open problem 7.</b> Prove that there is no \( {2^{n/10}}\)-time algorithm for \( {{\mathrm{SVP}}_2}\) (under SETH).</p>
</blockquote>
<p>Of course, we would ideally like to directly rule out faster algorithms for approximate \( {{\mathrm{SVP}}_2}\) with the approximation factors that are most directly relevant to cryptography. There are serious complexity-theoretic barriers to overcome to get all the way there (e.g., \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) are known to be in \( {{\mathsf{NP}}} \cap {{\mathsf{coNP}}}\) for large enough polynomial approximation factors. But, we can still hope to get as close as possible, by proving stronger hardness results for approximate \( {{\mathrm{CVP}}_p}\) and approximate \( {{\mathrm{SVP}}_p}\). Indeed, a beautiful sequence of works showed hardness for approximation factors up to \( {n^{c/\log \log n}}\) (so “nearly polynomial) [<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>, <a href="https://arxiv.org/abs/1806.04087">HR12</a>], but these results are not fine grained.</p>
<p>The best <em>fine-grained</em> hardness of approximation results known rule out algorithms for small constant-factor approximations for \( {{\mathrm{CVP}}_p}\) with \( {p \notin 2{\mathbb Z}}\) in time \( {2^{0.99n}}\) for \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) for any \( {p}\) in time \( {2^{o(n)}}\). We ask whether we can do better.</p>
<blockquote>
<p><b>Open problem 8.</b> Prove that there is no \( {2^{0.99 n}}\)-time algorithm for \( {2}\)-approximate \( {{\mathrm{CVP}}_p}\) (under some form of Gap-SETH, see below).</p>
</blockquote>
<blockquote>
<p><b>Open problem 9.</b> Prove that there is no \( {2^{o(n)}}\)-time algorithm for \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for superconstant \( {\gamma = \omega(1)}\) (under Gap-ETH).</p>
</blockquote>
<h2>2.4. Gap-SETH?</h2>
<p>One issue that arose in our attempts to prove fine-grained hardness of approximation results is that we don’t even know the “right” complexity-theoretic assumption about approximate CSPs to use as a starting point. For fine-grained hardness of exact problems, ETH and SETH are very well established hypotheses, and they are in some sense “the weakest possible” assumptions of their form. E.g., it is easy to see that \( {k}\)-SAT is \( {2^{Cn}}\) hard if any \( {k}\)-CSP is. But, for hardness of approximation, the situation is less clear.</p>
<p>The analogue of ETH in the regime of hardness of approximation is the beautiful Gap-ETH assumption, which was defined independently by Irit Dinur [<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] and Pasin Manurangsi and Prasad Raghavendra [<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>]. This assumption says that there exists some constant approximation factor \( {\delta \neq 1}\) such that \( {\delta}\)-Gap-\( {3}\)-SAT cannot be solved in time \( {2^{o(n)}}\). (Formally, both Dinur and Manurangsi and Raghavendra say that there is no \( {2^{o(n)}}\)-time algorithm that distinguishes a satisfiable formula from a formula for which no assignment satisfies more than a \( {(1-\epsilon)}\) fraction of the clauses, but we ignore this requirement of perfect completeness here.) It is easy to see that this hypothesis is equivalent to a similar hypothesis about any \( {3}\)-CSP (or, indeed, any \( {k}\)-CSP for any constant\( {k}\)).</p>
<p>However, to prove hardness of approximation with the finest of grains, we need some “gap” analogue of SETH, i.e., we would like to assume that for large enough \( {k}\), some Gap-\( {k}\)-CSP is hard to approximate up to some constant factor \( {\delta \neq 1}\) in better than \( {2^{0.99n}}\)-time. (Formally, we should add an additional variable \( {\epsilon &gt; 0}\) and have such a hypothesis for every running time \( {2^{(1-\epsilon)n}}\), but we set \( {\epsilon = 0.01}\) here to keep things relatively simple.)</p>
<p>An issue arises here concerning the dependence of the approximation factor \( {\delta}\) on the arity \( {k}\). In particular, recall that \( {k}\)-SAT can be trivially approximated up to a factor of \( {1-2^{-k}}\) (since a random assignment satisfies a \( {1-2^{-k}}\) fraction of the clauses in expectation). So, if we define Gap-SETH in terms of Gap-\( {k}\)-SAT, then we must choose \( {\delta = \delta(k) \geq 1-2^{-k}}\) that converges to one as \(k\) increases. Manurangsi proposed such a version of Gap-SETH in his thesis [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>, Conjecture 12.1], specifically that for every large enough constant \( {k}\) there exists a constant \( {\delta = \delta(k) \neq 1}\) such that Gap-\( {k}\)-SAT cannot be approximated up to a factor of \( {\delta}\) in time \( {2^{0.99n}}\). (Again, we are leaving out an additional variable, \( {\epsilon}\).)</p>
<p>If we rely on this version of Gap-SETH, then our current techniques seem to get stuck at proving hardness of approximation for, say, \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for some non-explicit constant \( {\gamma_p &gt; 1}\) (and, if one works out the numbers, one can see immediately that \( {\gamma_p}\) must be really quite close to one). However, other Gap-\(k\)-CSPs are known to be (\(\mathsf{NP}\)-)hard to approximate up to much better approximation factors. E.g., for any \( {k}\), Gap-\(k\)-Parity is \( {{\mathsf{NP}}}\)-hard to approximate up to any constant approximation factor \( {1/2 &lt; \delta \leq 1}\) [<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>], and Gap-\( {k}\)-AND is \( {{\mathsf{NP}}}\)-hard to approximate for any constant approximation factor \( {\Omega(k/2^k) \leq \delta \leq 1}\) [<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>]. Indeed, Gap-\( {k}\)-AND is a quite natural problem to consider in this context since there is a fine-grained, approximation-factor preserving reduction from any Gap-\( {k}\)-CSP to Gap-\( {k}\)-AND. This generality motivates understanding the precise complexity of Gap-\( {k}\)-AND.</p>
<blockquote>
<p><b>Open problem 10.</b> What is the fine-grained complexity of the \( {\delta}\)-Gap-\( {k}\)-AND problem in terms of \( {n}\), \( {k}\), and \( {\delta}\)? In particular, if</p>
<p align="center">\( \displaystyle C_{k,\delta} := \inf \{ C &gt; 0 \ : \ \text{there is a $2^{C_{k,\delta}}$-time algorithm for algorithm for $\delta$-Gap-$k$-AND}\}\)</p>
<p>then what is the behavior of \( {C_{k,\delta}}\) as \( {k \rightarrow \infty}\) (for various functions \( {\delta = \delta(k)}\) of \( {k}\))?</p>
</blockquote>
<p>In particular, if one were to hypothesize sufficiently strong hardness of \( {\delta}\)-Gap-\( {k}\)-AND — i.e., to define an appropriate variant of Gap-SETH based on Gap-\( {k}\)-AND — then one might be able to use this hypothesis to prove very strong fine-grained hardness of approximation results. There is a fine-grained (but non-approximation preserving) reduction from Gap-\( {k}\)-AND to Gap-\( {k}\)-SAT, and so Manurangsi’s Gap-SETH is equivalent to the conjecture that there exists some non-explicit \( {\delta(k)}\) such that \( {\lim_{k \rightarrow \infty} C_{k,\delta} = 1}\).</p>


<ul><li>[<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>] Aggarwal, Bennett, Golovnev, Stephens-Davidowitz. Fine-grained hardness of CVP(P)— Everything that we can prove (and nothing else)</li><li>[<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>] Albrecht, Curtis, Deo, Davidson, Player, Postlethwaite, Virdia, Wunderer. Estimate all the {LWE, NTRU} schemes! <em>SCN</em>, 2019.</li><li>[<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>] Aggarwal, Dadush, Regev, Stephens-Davidowitz. Solving the Shortest Vector Problem in \(2^n\) time via discrete Gaussian sampling. <em>STOC</em>, 2015.</li><li>[<a href="https://arxiv.org/abs/1504.01995">ADS15</a>]  Aggarwal, Dadush, Stephens-Davidowitz. Solving the Closest Vector Problem in \(2^n\) time–The discrete Gaussian strikes again! <em>FOCS</em>, 2015.</li><li>[<a href="https://arxiv.org/pdf/1801.02358">AM18</a>] Aggarwal, Mukhopadhyay. Faster algorithms for SVP and CVP in the \(\ell_\infty\) norm. <em>ISAAC</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1709.01535">AS18a</a>] Aggarwal, Stephens-Davidowitz. Just take the average! An embarrassingly simple \(2^n\)-time algorithm for SVP (and CVP). <em>SOSA</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1712.00942">AS18b</a>] Aggarwal, Stephens-Davidowitz. (Gap/S)ETH hardness of SVP. In <em>STOC</em>, 2018.</li><li>[<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] Becker, Ducas, Gama, Laarhoven. New directions in nearest neighbor searching with applications to lattice sieving. <em>SODA</em>, 2016.</li><li>[<a href="https://arxiv.org/abs/1704.03928">BGS17</a>] Bennett, Golovnev, Stephens-Davidowitz. On the quantitative hardness of CVP. <em>FOCS</em>, 2017.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>] Chan. Approximation resistance from pairwise-independent subgroups. <em>J. ACM</em>, 2016.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] Dinur. Mildly exponential reduction from gap 3SAT to polynomial-gap label-cover.</li><li>[<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>] Dinur, Kindler, Raz, Safra. Approximating CVP to within almost-polynomial factors is NP-hard. <em>Combinatorica</em>, 2003.</li><li>[<a href="https://arxiv.org/abs/1011.5666">DPV11</a>] Dadush, Peikert, Vempala. Enumerative lattice algorithms in any norm via \(M\)-ellipsoid coverings. <em>FOCS</em>, 2011.</li><li>[<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>] Goldreich, Micciancio, Safra, Seifert. Approximating shortest lattice vectors is not harder than approximating closest lattice vectors. <em>IPL</em>, 1999.</li><li>[<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>] Håstad. Some optimal inapproximability results. <em>J. ACM</em>, 2001.</li><li>[<a href="https://arxiv.org/abs/1806.04087">HR12</a>] Haviv, Regev. Tensor-based hardness of the Shortest Vector Problem to within almost polynomial factors. <em>TOC</em>, 2012.</li><li>[<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>] Impagliazzo, Paturi. On the complexity of \(k\)-SAT. <em>JCSS</em>, 2001.</li><li>[<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] Impagliazzo, Paturi, Zane. Which problems have strongly exponential complexity? <em>JCSS</em>, 2001.</li><li>[<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] Laarhoven. Search problems in cryptography. Ph.D thesis, 2015.</li><li>[<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>] Kannan. Minkowski’s convex body theorem and Integer Programming. <em>MOR</em>, 1987.</li><li>[<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>] Kirshanova, Mårtensson, Postlethwaite, Roy Moulik. Quantum algorithms for the approximate \(k\)-list problem and their application to lattice sieving. <em>Asiacrypt</em>, 2019.</li><li>[<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>] Manurangsi. Approximation and Hardness: Beyond P and NP.</li><li>[<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>] Manurangsi, Raghavendra. A Birthday Repetition Theorem and Complexity of Approximating Dense CSPs. <em>ICALP</em>, 17.</li><li>[<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] Vlăduţ. Lattices with exponentially large kissing numbers. <em>Moscow J. of Combinatorics and Number Theory</em>, 2019<em>.</em></li></ul></div>







<p class="date">
by Huck Bennett <a href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/"><span class="datestr">at May 04, 2020 01:07 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00515">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00515">The Hypervolume Indicator: Problems and Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guerreiro:Andreia_P=.html">Andreia P. Guerreiro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fonseca:Carlos_M=.html">Carlos M. Fonseca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paquete:Lu=iacute=s.html">Luís Paquete</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00515">PDF</a><br /><b>Abstract: </b>The hypervolume indicator is one of the most used set-quality indicators for
the assessment of stochastic multiobjective optimizers, as well as for
selection in evolutionary multiobjective optimization algorithms. Its
theoretical properties justify its wide acceptance, particularly the strict
monotonicity with respect to set dominance which is still unique of
hypervolume-based indicators. This paper discusses the computation of
hypervolume-related problems, highlighting the relations between them,
providing an overview of the paradigms and techniques used, a description of
the main algorithms for each problem, and a rundown of the fastest algorithms
regarding asymptotic complexity and runtime. By providing a complete overview
of the computational problems associated to the hypervolume indicator, this
paper serves as the starting point for the development of new algorithms, and
supports users in the identification of the most appropriate implementations
available for each problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00515"><span class="datestr">at May 04, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00198">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00198">Multi-dimensional Arrays with Levels</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Artjoms {Š}inkarovs <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00198">PDF</a><br /><b>Abstract: </b>We explore a data structure that generalises rectangular multi-dimensional
arrays. The shape of an n-dimensional array is typically given by a tuple of n
natural numbers. Each element in that tuple defines the length of the
corresponding axis. If we treat this tuple as an array, the shape of that array
is described by the single natural number n. A natural number itself can be
also treated as an array with the shape described by the natural number 1 (or
the element of any singleton set). This observation gives rise to the hierarchy
of array types where the shape of an array of level l+1 is a level-l array of
natural numbers. Such a hierarchy occurs naturally when treating arrays as
containers, which makes it possible to define both rank- and level-polymorphic
operations. The former can be found in most array languages, whereas the latter
gives rise to partial selections on a large set of hyperplanes, which is often
useful in practice. In this paper we present an Agda formalisation of arrays
with levels. We show that the proposed formalism supports standard
rank-polymorphic array operations, while type system gives static guarantees
that indexing is within bounds. We generalise the notion of ranked operator so
that it becomes applicable on arrays of arbitrary levels and we show why this
may be useful in practice.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00198"><span class="datestr">at May 04, 2020 10:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00168">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00168">Cutting Bamboo Down to Size</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bil=ograve=:Davide.html">Davide Bilò</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gual=agrave=:Luciano.html">Luciano Gualà</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leucci:Stefano.html">Stefano Leucci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Proietti:Guido.html">Guido Proietti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Scornavacca:Giacomo.html">Giacomo Scornavacca</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00168">PDF</a><br /><b>Abstract: </b>This paper studies the problem of programming a robotic panda gardener to
keep a bamboo garden from obstructing the view of the lake by your house.
</p>
<p>The garden consists of $n$ bamboo stalks with known daily growth rates and
the gardener can cut at most one bamboo per day. As a computer scientist, you
found out that this problem has already been formalized in [G\k{a}sieniec et
al., SOFSEM'17] as the Bamboo Garden Trimming (BGT) problem, where the goal is
that of computing a perpetual schedule (i.e., the sequence of bamboos to cut)
for the robotic gardener to follow in order to minimize the makespan, i.e., the
maximum height ever reached by a bamboo.
</p>
<p>Two natural strategies are Reduce-Max and Reduce-Fastest(x). Reduce-Max trims
the tallest bamboo of the day, while Reduce-Fastest(x) trims the fastest
growing bamboo among the ones that are taller than $x$. It is known that
Reduce-Max and Reduce-Fastest(x) achieve a makespan of $O(\log n)$ and $4$ for
the best choice of $x=2$, respectively. We prove the first constant upper bound
of $9$ for Reduce-Max and improve the one for Reduce-Fastest(x) to
$\frac{3+\sqrt{5}}{2} &lt; 2.62$ for $x=1+\frac{1}{\sqrt{5}}$.
</p>
<p>Another critical aspect stems from the fact that your robotic gardener has a
limited amount of processing power and memory. It is then important for the
algorithm to be able to quickly determine the next bamboo to cut while
requiring at most linear space. We formalize this aspect as the problem of
designing a Trimming Oracle data structure, and we provide three efficient
Trimming Oracles implementing different perpetual schedules, including those
produced by Reduce-Max and Reduce-Fastest(x).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00168"><span class="datestr">at May 04, 2020 10:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00010">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00010">A Primer on Private Statistics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kamath:Gautam.html">Gautam Kamath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Ullman:Jonathan.html">Jonathan Ullman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00010">PDF</a><br /><b>Abstract: </b>Differentially private statistical estimation has seen a flurry of
developments over the last several years. Study has been divided into two
schools of thought, focusing on empirical statistics versus population
statistics. We suggest that these two lines of work are more similar than
different by giving examples of methods that were initially framed for
empirical statistics, but can be applied just as well to population statistics.
We also provide a thorough coverage of recent work in this area.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00010"><span class="datestr">at May 04, 2020 10:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/05/03/hanoi-vs-sierpinski">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/05/03/hanoi-vs-sierpinski.html">Hanoi vs Sierpiński</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The Hanoi graphs and Sierpiński graphs both look like the <a href="https://en.wikipedia.org/wiki/Sierpi%C5%84ski_triangle">Sierpiński triangle</a>, and have a very similar recursive construction from triples of smaller graphs of the same type, but they are not quite the same graphs as each other. The Sierpiński graphs (left, below) are the graphs of the vertices and boundary edges of partially-constructed Sierpiński triangles; they can also be formed from three smaller Sierpiński graphs by identifying pairs of extreme vertices (the vertices of degree two at the three corners of the triangular layout). The <a href="https://en.wikipedia.org/wiki/Hanoi_graph">Hanoi graphs</a> (right, below) are the state spaces of the tower of Hanoi puzzle, in which rings of different size are moved one at a time between three pegs, only allowing moves that keep the rings sorted on each peg. They also have a construction from three smaller Hanoi graphs, but where the pairs of extreme vertices are connected by an edge rather than identified.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/hanoi-vs-sierpinski.svg" alt="Hanoi graphs and Sierpiński graphs" /></p>

<p>The difference between them comes out much more strongly when you generalize them to higher dimensions. The Sierpiński triangle generalizes to tetrahedra (a popular shape for kites) and higher-dimensional simplices; <a href="https://commons.wikimedia.org/wiki/File:Alexander_Graham_Bell_facing_his_wife,_Mabel_Hubbard_Gardiner_Bell,_who_is_standing_in_a_tetrahedral_kite,_Baddeck,_Nova_Scotia.tif">the photo below</a> shows <a href="https://en.wikipedia.org/wiki/Mabel_Gardiner_Hubbard">Mabel Bell</a> and <a href="https://en.wikipedia.org/wiki/Alexander_Graham_Bell">Alexander Graham Bell</a>, seemingly about to kiss, in a three-dimensional Sierpiński graph, the framework for a kite.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/bell-kite-kiss.jpg" alt="Mabel Bell and Alexander Graham Bell kissing in a Sierpiński tetrahedron kite frame, from https://commons.wikimedia.org/wiki/File:Alexander_Graham_Bell_facing_his_wife,_Mabel_Hubbard_Gardiner_Bell,_who_is_standing_in_a_tetrahedral_kite,_Baddeck,_Nova_Scotia.tif" /></p>

<p>Again, the -dimensional Sierpiński graph has a recursive construction from  smaller graphs of the same type, identified at extreme vertices (the vertices of degree  at the  corners of the layout). Because the number of vertices separating the subgraphs at each level of the recursion is so small, these graphs have bounded <a href="https://en.wikipedia.org/wiki/Treewidth">treewidth</a>, and a few years ago on the TCS stackexchange <a href="https://cstheory.stackexchange.com/q/36542">I calculated the treewidth of the Sierpiński triangle graphs explicitly as being four</a>. The same bound transfers easily enough to the three-peg Hanoi graphs.</p>

<p>The analogue of higher dimensions for the Hanoi graphs is to use more pegs. The Hanoi graph with  pegs and  rings has  states, more or less the same as the Sierpiński graph for -dimensional Sierpiński fractals with  levels of recursion. Here’s the one with two rings; each state is described by a pair of letters, using a capital letter for the peg holding the larger ring and a lowercase letter for the peg holding the smaller ring.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/Hanoi-4-2.svg" alt="Hanoi graph for two rings on four pegs" /></p>

<p>The recursive construction for these graphs combines  copies of a smaller graph of the same type: one copy for each position where the largest ring can be placed, and a smaller graph describing the placements of the smaller rings once the largest ring has been placed. These copies of the smaller graph are connected together by edges describing the movements of the largest ring. But I’ve only drawn an example for two rings because these graphs get messy and hard to draw very quickly. The reason is not the exponential number of total vertices, but the large number of connections from one recursive subgraph to another. Two recursive subgraphs are connected whenever the largest ring can move from its peg in one subgraph to its peg in the other, and this is allowed whenever these two pegs have no smaller rings on them. So in a Hanoi graph with  pegs,  rings, and  vertices, each pair of recursive subgraphs has  edges between them, one for each placement of the smaller rings on the  remaining pegs.</p>

<p>The recursive subdivision with  edges between subgraphs leads to a tree-decomposition with treewidth , and this naturally raises the question of whether this is tight or whether some other less-intuitive recursive decomposition has smaller cuts between its recursive subgraphs. This is the question studied in my newest preprint, “On the treewidth of Hanoi graphs” (<a href="https://arxiv.org/abs/2005.00179">arXiv:2005.00179</a>), with UCI student Daniel Frishberg and Oregon State student Will Maxwell, to appear at <a href="https://sites.google.com/view/fun2020/home">FUN 2020</a> (supposedly to be held in person in September in Italy after being rescheduled from June, but I’m not holding my breath). We don’t get a precise answer, but we succeed in proving bounds on the treewidth of the form <span style="white-space: nowrap;">.</span> This is nearly tight for fixed  and variable : we get the same exponential function of  as the upper bound, and are smaller than the upper bound by only a much lower-order polynomial factor. But the exact treewidth remains elusive.</p>

<p>To put it in a possibly more familiar form, when one of these graphs (for a fixed number of pegs and variable number of rings) has  vertices, it has separators of size , where . For the four-peg Hanoi graphs, this means separators of size , more or less the same as for planar graphs (although these graphs seem far from planar). But that nice exponent is just a coincidence caused by the fact that  is a power of . For other choices of , that doesn’t happen and we get a transcendental exponent . So these graphs don’t even act like -dimensional graphs, for which a reasonable separator exponent might be the rational number . And they certainly don’t act like the Sierpiński graphs, for which the exponent is zero.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104108481482094736">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/05/03/hanoi-vs-sierpinski.html"><span class="datestr">at May 03, 2020 10:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/069">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/069">TR20-069 |  Optimal Error Pseudodistributions for Read-Once Branching Programs | 

	Eshan Chattopadhyay, 

	Jyun-Jie Liao</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a seminal work, Nisan (Combinatorica'92) constructed a pseudorandom generator for length $n$ and width $w$ read-once branching programs  with seed length $O(\log n\cdot \log(nw)+\log n\cdot\log(1/\varepsilon))$ and  error $\varepsilon$. It remains a central question  to reduce the seed length to $O(\log (nw/\varepsilon))$, which would prove that $\mathbf{BPL}=\mathbf{L}$. However, there has been no improvement on Nisan's construction for the case $n=w$, which is most relevant to space-bounded derandomization.




Recently, in a beautiful work, Braverman, Cohen and Garg (STOC'18) introduced the notion of a \emph{pseudorandom pseudo-distribution} (PRPD) and gave an explicit construction of a PRPD with seed length $\tilde{O}(\log n\cdot \log(nw)+\log(1/\varepsilon))$. A PRPD is a relaxation of a pseudorandom generator, which suffices for derandomizing $\mathbf{BPL}$ and also implies a hitting set. Unfortunately, their construction is quite involved and complicated. Hoza and Zuckerman (FOCS'18) later constructed a much simpler hitting set generator with seed length $O(\log n\cdot \log(nw)+\log(1/\varepsilon))$, but their techniques are restricted to hitting sets.

In this work, we construct a PRPD with seed length 
$$O(\log n\cdot \log (nw)\cdot \log\log(nw)+\log(1/\varepsilon)).$$
This improves upon the construction in \cite{BCG18} by a $O(\log\log(1/\varepsilon))$ factor, and is optimal in the small error regime. In addition, we believe our construction and analysis to be   simpler than the work of Braverman, Cohen and Garg.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/069"><span class="datestr">at May 03, 2020 10:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/068">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/068">TR20-068 |  One-Sided Error Testing of Monomials and Affine Subspaces | 

	Oded Goldreich, 

	Dana Ron</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We consider the query complexity of three versions of the problem of testing monomials and affine (and linear) subspaces with one-sided error, and obtain the following results: 
\begin{itemize}
\item The general problem, in which the arity of the monomial (resp., co-dimension of the subspace) is not specified, has query complexity ${\widetilde{O}}(1/\epsilon)$, where $\epsilon$ denotes the proximity parameter. 
\item The bounded problem, in which the arity of the monomial (resp., co-dimension of the subspace) is upper bounded by a fixed parameter, has query complexity ${\widetilde{O}}(1/\epsilon)$.
\item The exact problem, in which the arity of the monomial (resp., co-dimension of the subspace) is required to equal a fixed parameter (e.g., equals~2), has query complexity ${\widetilde{\Omega}}(\log n)$, where $n$ denotes the length of the argument for the tested function.  
\end{itemize}
The running time of the testers in the positive results is linear in their query complexity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/068"><span class="datestr">at May 03, 2020 08:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4379">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/05/03/talagrands-generic-chaining/">Talagrand’s Generic Chaining</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
 Welcome to phase two of <em>in theory</em>, in which we again talk about math. I spent last Fall teaching two courses and getting settled, I mostly traveled in January and February, and I have spent the last two months on my sofa catching up on TV series. Hence I will reach back to last Spring, when I learned about Talagrand’s machinery of generic chaining and majorizing measures from Nikhil Bansal, in the context of our work with Ola Svensson on <a href="https://arxiv.org/abs/1905.01495">graph and hypergraph sparsification</a>. Here I would like to record what I understood about the machinery, and in a follow-up post I plan to explain the application to hypergraph sparsification.</p>
<p>
<span id="more-4379"></span></p>
<p>
</p><p><b>1. A Concrete Setting </b></p>
<p></p><p>
Starting from a very concrete setting, suppose that we have a subset <img src="https://s0.wp.com/latex.php?latex=%7BT+%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T \subseteq {\mathbb R}^n}" class="latex" title="{T \subseteq {\mathbb R}^n}" />, we pick a random Gaussian vector <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> from <img src="https://s0.wp.com/latex.php?latex=%7BN%28%7B%5Cbf+0%7D%2C+I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N({\bf 0}, I)}" class="latex" title="{N({\bf 0}, I)}" />, and we are interested in the random variable</p>
<p>
<a name="eqg"></a></p><a name="eqg">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+%5Crangle+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \ \ \ \ \ (1)" class="latex" title="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \ \ \ \ \ (1)" /></p>
</a><p><a name="eqg"></a> In theoretical computer science, for example, a random variable like <a href="https://lucatrevisan.wordpress.com/feed/#eqg">(1)</a> comes up often in the study of rounding algorithms for semidefinite programming, but this is a problem of much broader interest. </p>
<p>
A first observation is that each <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+g%2Ct+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle g,t \rangle}" class="latex" title="{\langle g,t \rangle}" /> is Gaussian with mean zero and variance <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+t%7C%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|| t||^2}" class="latex" title="{|| t||^2}" />. If <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is finite, we can use a union bound to estimate the tail of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t%2Cg+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sup_{t\in T} \langle t,g \rangle}" class="latex" title="{\sup_{t\in T} \langle t,g \rangle}" />, and we can compute the upper bound <a name="equb"></a></p><a name="equb">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+%5Crangle+%5Cleq+O%5Cleft%28%5Csqrt%7B%5Clog+%7CT%7C%7D+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%7C%7C+t%7C%7C+%5Cright%29+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \leq O\left(\sqrt{\log |T|} \cdot \sup_{t\in T} || t|| \right) \ \ \ \ \ (2)" class="latex" title="\displaystyle  \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle \leq O\left(\sqrt{\log |T|} \cdot \sup_{t\in T} || t|| \right) \ \ \ \ \ (2)" /></p>
</a><p><a name="equb"></a> The above bound can be tight, but it is poor if the points of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> are densely clustered, and it is useless if <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is infinite. </p>
<p>
It is useful to note that, if we fix, arbitrarily, an element <img src="https://s0.wp.com/latex.php?latex=%7Bt_0+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_0 \in T}" class="latex" title="{t_0 \in T}" />, then we have <a name="eqgtzero"></a></p><a name="eqgtzero">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+++%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+%5Crangle+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2C+I%29%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D%5C+%5Clangle+g%2C+t+-+t_0+%5Crangle+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle = \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t - t_0 \rangle \ \ \ \ \ (3)" class="latex" title="\displaystyle   \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t \rangle = \mathop{\mathbb E}_{g\sim N({\bf 0}, I)} \ \ \sup_{t\in T}\ \langle g, t - t_0 \rangle \ \ \ \ \ (3)" /></p>
</a><p><a name="eqgtzero"></a> because <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Clangle+g%2C+t_0+%5Crangle+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E} \langle g, t_0 \rangle = 0}" class="latex" title="{\mathop{\mathbb E} \langle g, t_0 \rangle = 0}" />. The latter expression is nicer to work with because it makes it more explicit that what we are trying to compute is invariant under shifts of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />, and only depends on pairwise distances of the elements of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />, rather than their norm. </p>
<p>
In the cases in which <a href="https://lucatrevisan.wordpress.com/feed/#equb">(2)</a> gives a poor bound, a natural approach is to reason about an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-net <img src="https://s0.wp.com/latex.php?latex=%7BT%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T'}" class="latex" title="{T'}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />, that is, a subset <img src="https://s0.wp.com/latex.php?latex=%7BT%27%5Csubseteq+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T'\subseteq T}" class="latex" title="{T'\subseteq T}" /> such that for every <img src="https://s0.wp.com/latex.php?latex=%7Bt%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t\in T}" class="latex" title="{t\in T}" /> there is an element <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28t%29+%5Cin+T%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi(t) \in T'}" class="latex" title="{\pi(t) \in T'}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7Ct+-+%5Cpi%28t%29+%7C%7C%5Cleq+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{||t - \pi(t) ||\leq \epsilon}" class="latex" title="{||t - \pi(t) ||\leq \epsilon}" />. Then we can say that</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_t+%5Clangle+t+-+t_0%2C+g+%5Crangle+%3D+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t+-+%5Cpi%28t%29+%2C+g+%5Crangle+%2B+%5Clangle+%5Cpi%28t%29+-t_0%2C+g+%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_t \langle t - t_0, g \rangle = \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle + \langle \pi(t) -t_0, g \rangle " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_t \langle t - t_0, g \rangle = \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle + \langle \pi(t) -t_0, g \rangle " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+%5Cleft%28+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t+-+%5Cpi%28t%29+%2C+g+%5Crangle+%5Cright%29+%2B+%5Cleft%28+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D%5Clangle+%5Cpi%28t%29+-t_0%2C+g+%5Crangle+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq \left( \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle \right) + \left( \mathop{\mathbb E} \sup_{t\in T}\langle \pi(t) -t_0, g \rangle \right) " class="latex" title="\displaystyle  \leq \left( \mathop{\mathbb E} \sup_{t\in T} \langle t - \pi(t) , g \rangle \right) + \left( \mathop{\mathbb E} \sup_{t\in T}\langle \pi(t) -t_0, g \rangle \right) " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+O%28+%5Csqrt%7B%5Clog+%7CT%7C%7D+%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%7C%7Ct-%5Cpi%28t%29+%7C%7C+%2B+%5Cleft%28+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%27%5Cin+T%27%7D%5Clangle+t%27+-t_0%2C+g+%5Crangle+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq O( \sqrt{\log |T|} ) \cdot \sup_{t\in T} ||t-\pi(t) || + \left( \mathop{\mathbb E} \sup_{t'\in T'}\langle t' -t_0, g \rangle \right) " class="latex" title="\displaystyle  \leq O( \sqrt{\log |T|} ) \cdot \sup_{t\in T} ||t-\pi(t) || + \left( \mathop{\mathbb E} \sup_{t'\in T'}\langle t' -t_0, g \rangle \right) " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleq+O%5Cleft%28+%5Csqrt%7B%5Clog+%7CT%7C%7D+%5Ccdot+%5Cepsilon+%2B+%5Csqrt+%7B%5Clog+%7CT%27%7C%7D+%5Ccdot+%5Csup_%7Bt%27%5Cin+T%27%7D+%7C%7C+t%27+-+t_0%7C%7C+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \leq O\left( \sqrt{\log |T|} \cdot \epsilon + \sqrt {\log |T'|} \cdot \sup_{t'\in T'} || t' - t_0|| \right) " class="latex" title="\displaystyle  \leq O\left( \sqrt{\log |T|} \cdot \epsilon + \sqrt {\log |T'|} \cdot \sup_{t'\in T'} || t' - t_0|| \right) " /></p>
<p>
which can be a much tighter bound. Notice that we used <a href="https://lucatrevisan.wordpress.com/feed/#equb">(2)</a> to bound </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%27%7D+%5Clangle+t%27+-+t_0+%2C+g%5Crangle+%5C+%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T'} \langle t' - t_0 , g\rangle \ , " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T'} \langle t' - t_0 , g\rangle \ , " /></p>
<p> but it might actually be better to find an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon'}" class="latex" title="{\epsilon'}" />-net <img src="https://s0.wp.com/latex.php?latex=%7BT%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T''}" class="latex" title="{T''}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BT%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T'}" class="latex" title="{T'}" />, and so on. In general, a tighter analysis would be to choose a sequence of nested sets <img src="https://s0.wp.com/latex.php?latex=%7BT_0+%5Csubseteq+T_1+%5Csubseteq+%5Ccdots+%5Csubseteq+T_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_0 \subseteq T_1 \subseteq \cdots \subseteq T_k}" class="latex" title="{T_0 \subseteq T_1 \subseteq \cdots \subseteq T_k}" />, where <img src="https://s0.wp.com/latex.php?latex=%7BT_0+%3D+%5C%7B+t_0+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_0 = \{ t_0 \}}" class="latex" title="{T_0 = \{ t_0 \}}" />, <img src="https://s0.wp.com/latex.php?latex=%7BT_k+%3D+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k = T}" class="latex" title="{T_k = T}" />, and we have that <img src="https://s0.wp.com/latex.php?latex=%7BT_%7Bi-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{i-1}}" class="latex" title="{T_{i-1}}" /> is an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon_i}" class="latex" title="{\epsilon_i}" />-net of <img src="https://s0.wp.com/latex.php?latex=%7BT_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{i}}" class="latex" title="{T_{i}}" />, that is, for every element <img src="https://s0.wp.com/latex.php?latex=%7Bt_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_{i}}" class="latex" title="{t_{i}}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BT_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_i}" class="latex" title="{T_i}" /> there is an element <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_i+%28t_i%29+%5Cin+T_%7Bi-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi_i (t_i) \in T_{i-1}}" class="latex" title="{\pi_i (t_i) \in T_{i-1}}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+t_i+-+%5Cpi_i+%28t_i%29+%7C%7C+%5Cleq+%5Cepsilon_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|| t_i - \pi_i (t_i) || \leq \epsilon_i}" class="latex" title="{|| t_i - \pi_i (t_i) || \leq \epsilon_i}" />. Then, by generalizing the above reasoning, we get </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t-t_0%2Cg+%5Crangle+%5Cleq+O%281%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5Ek+%5Csqrt%7B%5Clog+%7CT_i+%7C+%7D+%5Ccdot+%5Csup_%7Bt_i+%5Cin+T_i%7D+%7C%7C+t_i+-+%5Cpi_i%28t_i%29+%7C%7C+%5Cleq+O%281%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5En+%5Cepsilon_i+%5Csqrt%7B%5Clog+%7CT_i+%7C+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sum_{i=1}^k \sqrt{\log |T_i | } \cdot \sup_{t_i \in T_i} || t_i - \pi_i(t_i) || \leq O(1) \cdot \sum_{i=1}^n \epsilon_i \sqrt{\log |T_i | } " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sum_{i=1}^k \sqrt{\log |T_i | } \cdot \sup_{t_i \in T_i} || t_i - \pi_i(t_i) || \leq O(1) \cdot \sum_{i=1}^n \epsilon_i \sqrt{\log |T_i | } " /></p>
<p>
Finally, if the cardinality of the <img src="https://s0.wp.com/latex.php?latex=%7BT_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_i}" class="latex" title="{T_i}" /> grows sufficiently fast, namely, if we have <img src="https://s0.wp.com/latex.php?latex=%7B%7CT_i%7C+%3E+%7CT_%7Bi-1%7D%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|T_i| &gt; |T_{i-1}|^2}" class="latex" title="{|T_i| &gt; |T_{i-1}|^2}" />, it is possible to refine the estimate to </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t-t_0%2Cg+%5Crangle+%5Cleq+O%281%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%5Csum_%7Bi%3D1%7D%5Ek+%5Csqrt%7B%5Clog+%7CT_i+%7C+%7D+%5Ccdot+%7C%7C+t+-+%5Cpi_i+%28t%29+%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{i=1}^k \sqrt{\log |T_i | } \cdot || t - \pi_i (t) || " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t-t_0,g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{i=1}^k \sqrt{\log |T_i | } \cdot || t - \pi_i (t) || " /></p>
<p> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_i%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi_i(t)}" class="latex" title="{\pi_i(t)}" /> is the closest element to <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BT_%7Bi-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{i-1}}" class="latex" title="{T_{i-1}}" />. This is done by avoiding to write the expectation of the sup of a sum as a sum of expectations of sups and then using <a href="https://lucatrevisan.wordpress.com/feed/#equb">(2)</a>, but by bounding the tail of the sup of the sum directly.</p>
<p>
At this point, we do not even need to assume that <img src="https://s0.wp.com/latex.php?latex=%7BT_k%3D+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k= T}" class="latex" title="{T_k= T}" />, that <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is finite, or that the sequence of sets is finite, and we have the following result.</p>
<blockquote><p><b>Theorem 1 (Talagrand’s generic chaining inequality)</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BT+%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T \subseteq {\mathbb R}^n}" class="latex" title="{T \subseteq {\mathbb R}^n}" /> be an arbitrary set, let <img src="https://s0.wp.com/latex.php?latex=%7BT_0+%5Csubseteq+T_1+%5Csubseteq+%5Ccdots+T_k+%5Csubseteq+%5Ccdots+%5Csubseteq+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}" class="latex" title="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}" /> be a countable sequence of finite subsets of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%7CT_0%7C+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|T_0| = 1}" class="latex" title="{|T_0| = 1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7CT_k%7C+%5Cleq+2%5E%7B2%5Ek%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|T_k| \leq 2^{2^k}}" class="latex" title="{|T_k| \leq 2^{2^k}}" />. Then </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Clangle+t%2C+g+%5Crangle+%5Cleq+O%281%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+2%5E%7Bk%2F2%7D+%7C%7C+t+-+%5Cpi_k%28t%29%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t, g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} || t - \pi_k(t)|| " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \langle t, g \rangle \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} || t - \pi_k(t)|| " /></p>
</em><p><em> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_k%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi_k(t)}" class="latex" title="{\pi_k(t)}" /> is the element of <img src="https://s0.wp.com/latex.php?latex=%7BT_%7Bk-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{k-1}}" class="latex" title="{T_{k-1}}" /> closest to <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />. </em></p></blockquote>
<p></p><p>
A short complete proof is in these <a href="https://tcsmath.wordpress.com/2010/06/15/the-generic-chaining/">notes by James Lee</a>.</p>
<p>
While the above Theorem has a very simple proof, the amazing thing, which is rather harder to prove, is that it is <em>tight</em>, in the sense that for every <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> there is a sequence of sets such that the bound of the above theorem has a matching lower bound, up to an absolute constant. This is why it is called <em>generic chaining</em>. <em>Chaining</em> because the projection <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+t-t_0%2Cg%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle t-t_0,g\rangle}" class="latex" title="{\langle t-t_0,g\rangle}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bt-t_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t-t_0}" class="latex" title="{t-t_0}" /> on <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> is estimated based on the “chain” </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_k+%5Clangle+%5Cpi_%7Bk%2B1%7D+%28t%29+-+%5Cpi_k%28t%29+%2C+g+%5Crangle&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_k \langle \pi_{k+1} (t) - \pi_k(t) , g \rangle" class="latex" title="\displaystyle  \sum_k \langle \pi_{k+1} (t) - \pi_k(t) , g \rangle" /></p>
<p> of projections of the intermediate steps of a path that goes from <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bt_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_0}" class="latex" title="{t_0}" /> passing through the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_k%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi_k(t)}" class="latex" title="{\pi_k(t)}" />. <em>Generic</em> because this upper bound technique works as well as any other possible upper bound, up to an absolute constant.</p>
<p>
</p><p><b>2. An Abstract Setting </b></p>
<p></p><p>
Let now <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> be a completely arbitrary set, and suppose that we have a distribution <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal D}" class="latex" title="{\cal D}" /> over functions <img src="https://s0.wp.com/latex.php?latex=%7Bf%3A+T+%5Crightarrow+%7B%5Cmathbb+R%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f: T \rightarrow {\mathbb R}}" class="latex" title="{f: T \rightarrow {\mathbb R}}" /> and we want to upper bound </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D_%7BF+%5Csim+%7B%5Ccal+D%7D%7D+%5C+%5C+%5Csup_%7Bt%5Cin+T%7D+%5C+F%28t%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E}_{F \sim {\cal D}} \ \ \sup_{t\in T} \ F(t) " class="latex" title="\displaystyle  \mathop{\mathbb E}_{F \sim {\cal D}} \ \ \sup_{t\in T} \ F(t) " /></p>
<p> That is, we have a random optimization problem with a fixed feasible set <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />, and we want to know the typical value of the optimum. For example, <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> could be the set of cuts of a vertex set <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal D}" class="latex" title="{\cal D}" /> describe a distribution of random graphs <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t)}" class="latex" title="{F(t)}" /> is the number of edges cut in a random graph by the cut <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />. Then the above problem is to estimate the average value of the max cut in the random graphs of the distribution. Or <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> could be the unit sphere <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+x+%5Cin+%7B%5Cmathbb+R%7D%5EN+%3A+%7C%7Cx%7C%7C+%3D+1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ x \in {\mathbb R}^N : ||x|| = 1 \}}" class="latex" title="{\{ x \in {\mathbb R}^N : ||x|| = 1 \}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal D}" class="latex" title="{\cal D}" /> describe a distribution of random Hermitian matrices such that <img src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t)}" class="latex" title="{F(t)}" /> is the quadratic form of a random matrix evaluated at <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />. In this case, the above problem is to estimate the average value of the largest eigenvalue of such a random matrix.</p>
<p>
We will call the collection of random variables <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> a <em>random process</em>, where <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is a random variable distributed according to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal D}" class="latex" title="{\cal D}" />.</p>
<p>
If every <img src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t)}" class="latex" title="{F(t)}" />, and every finite linear combination <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7Bi%3D1%7D%5Ek+%5Calpha_i+F%28t_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_{i=1}^k \alpha_i F(t_i)}" class="latex" title="{\sum_{i=1}^k \alpha_i F(t_i)}" />, has a Gaussian distribution, then we say that <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> is a <em>Gaussian process</em>, and if, in addition, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+F%28t%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E} F(t) = 0}" class="latex" title="{\mathop{\mathbb E} F(t) = 0}" /> for every <img src="https://s0.wp.com/latex.php?latex=%7Bt%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t\in T}" class="latex" title="{t\in T}" /> then we say that it is a <em>centered Gaussian process</em>.</p>
<p>
If <img src="https://s0.wp.com/latex.php?latex=%7BT%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T\subseteq {\mathbb R}^n}" class="latex" title="{T\subseteq {\mathbb R}^n}" />, and we define <img src="https://s0.wp.com/latex.php?latex=%7BF%28t%29+%3D+%5Clangle+t%2Cg%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t) = \langle t,g\rangle}" class="latex" title="{F(t) = \langle t,g\rangle}" /> for a random standard Gaussian <img src="https://s0.wp.com/latex.php?latex=%7Bg%5Csim+N%28%7B%5Cbf+0%7D%2CI%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g\sim N({\bf 0},I)}" class="latex" title="{g\sim N({\bf 0},I)}" />, then <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> is a centered Gaussian process and, in this case, upper bounding <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+F%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E} \sup F(t)}" class="latex" title="{\mathop{\mathbb E} \sup F(t)}" /> is precisely the problem we studied before. </p>
<p>
If <img src="https://s0.wp.com/latex.php?latex=%7BT%5Csubseteq+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T\subseteq {\mathbb R}^n}" class="latex" title="{T\subseteq {\mathbb R}^n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BF%28t%29+%3D+%5Clangle+t%2Cg+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t) = \langle t,g \rangle}" class="latex" title="{F(t) = \langle t,g \rangle}" /> for a random standard Gaussian <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" />, then, for every <img src="https://s0.wp.com/latex.php?latex=%7Bt_1%2Ct_2+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_1,t_2 \in T}" class="latex" title="{t_1,t_2 \in T}" />, we have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft%28F%28t_1%29+-+F%28t_2%29%5Cright%29%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7Bg+%5Csim+N%28%7B%5Cbf+0%7D%2CI%29%7D+%5C+%5C+%5Clangle+t_1-t_2%2Cg+%5Crangle%5E2+%3D+%7C%7Ct_1+-+t_2+%7C%7C%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \left(F(t_1) - F(t_2)\right)^2 = \mathop{\mathbb E}_{g \sim N({\bf 0},I)} \ \ \langle t_1-t_2,g \rangle^2 = ||t_1 - t_2 ||^2 " class="latex" title="\displaystyle  \mathop{\mathbb E} \left(F(t_1) - F(t_2)\right)^2 = \mathop{\mathbb E}_{g \sim N({\bf 0},I)} \ \ \langle t_1-t_2,g \rangle^2 = ||t_1 - t_2 ||^2 " /></p>
<p> and, by analogy, if <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> is a centered Gaussian process, we will define the following distance function on <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28t_1%2Ct_2+%29+%3A%3D+%5Csqrt%7B+%5Cmathop%7B%5Cmathbb+E%7D+%28F%28t_1%29+-+F%28t_2%29%5E2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  d(t_1,t_2 ) := \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2)^2} " class="latex" title="\displaystyle  d(t_1,t_2 ) := \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2)^2} " /></p>
<p> If <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> is a centered Gaussian process then one can prove that the above distance function is a semi-metric on <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />.</p>
<p>
We will not need this fact, but if <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> is a centered Gaussian process and <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> is finite, then there is an embedding <img src="https://s0.wp.com/latex.php?latex=%7Bh%3A+T+%5Crightarrow+%7B%5Cmathbb+R%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h: T \rightarrow {\mathbb R}^n}" class="latex" title="{h: T \rightarrow {\mathbb R}^n}" />, for some <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, such that the process can be equivalently defined as picking <img src="https://s0.wp.com/latex.php?latex=%7Bg%5Csim+N%28%7B%5Cbf+0%7D+%2C+I%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g\sim N({\bf 0} , I)}" class="latex" title="{g\sim N({\bf 0} , I)}" /> and setting <img src="https://s0.wp.com/latex.php?latex=%7BF%28t%29+%3A%3D+%5Clangle+h%28t%29%2C+g+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t) := \langle h(t), g \rangle}" class="latex" title="{F(t) := \langle h(t), g \rangle}" />, so that <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> is also an isometric embedding of the above distance function into <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2}" class="latex" title="{\ell_2}" />.</p>
<p>
The arguments of the previous section apply to centered Gaussian processes without change, and so we have.</p>
<blockquote><p><b>Theorem 2</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> be an arbitrary set, and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> be a centered Gaussian process. Let <img src="https://s0.wp.com/latex.php?latex=%7BT_0+%5Csubseteq+T_1+%5Csubseteq+%5Ccdots+T_k+%5Csubseteq+%5Ccdots+%5Csubseteq+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}" class="latex" title="{T_0 \subseteq T_1 \subseteq \cdots T_k \subseteq \cdots \subseteq T}" /> be a countable sequence of finite subsets of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%7CT_0%7C+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|T_0| = 1}" class="latex" title="{|T_0| = 1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%7CT_k%7C+%5Cleq+2%5E%7B2%5Ek%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|T_k| \leq 2^{2^k}}" class="latex" title="{|T_k| \leq 2^{2^k}}" />. Then </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+F%28t%29+%5Cleq+O%281%29+%5Ccdot+%5Csup_%7Bt%5Cin+T%7D+%5Csum_%7Bk%3D1%7D%5E%5Cinfty+2%5E%7Bk%2F2%7D+d+%28t+%2C+%5Cpi_k%28t%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} F(t) \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} d (t , \pi_k(t)) " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} F(t) \leq O(1) \cdot \sup_{t\in T} \sum_{k=1}^\infty 2^{k/2} d (t , \pi_k(t)) " /></p>
</em><p><em> where <img src="https://s0.wp.com/latex.php?latex=%7Bd%28%5Ccdot%2C%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(\cdot,\cdot)}" class="latex" title="{d(\cdot,\cdot)}" /> is the distance function <img src="https://s0.wp.com/latex.php?latex=%7Bd%28t_1+%2C+t_2%29+%3D+%5Csqrt%7B+%5Cmathop%7B%5Cmathbb+E%7D+%28F%28t_1%29+-+F%28t_2%29%29%5E2+%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(t_1 , t_2) = \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2))^2 }}" class="latex" title="{d(t_1 , t_2) = \sqrt{ \mathop{\mathbb E} (F(t_1) - F(t_2))^2 }}" />and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi_k%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi_k(t)}" class="latex" title="{\pi_k(t)}" /> is the element of <img src="https://s0.wp.com/latex.php?latex=%7BT_%7Bk-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_{k-1}}" class="latex" title="{T_{k-1}}" /> closest to <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> according to <img src="https://s0.wp.com/latex.php?latex=%7Bd%28%5Ccdot%2C%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(\cdot,\cdot)}" class="latex" title="{d(\cdot,\cdot)}" />. </em></p></blockquote>
<p>
</p><p><b>3. Sub-Gaussian Random Processes </b></p>
<p></p><p>
This theory does not seem to apply to problems such as bounding the max cut of a <img src="https://s0.wp.com/latex.php?latex=%7BG_%7Bn%2Cp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G_{n,p}}" class="latex" title="{G_{n,p}}" /> unweighted graph, or bounding the largest eigenvalue of a random symmetric matrix with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpm+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pm 1}" class="latex" title="{\pm 1}" /> entries, because such problems have a finite sample space and so cannot be modeled as Gaussian processes.</p>
<p>
Fortunately, there is a notion of a <em>sub-Gaussian</em> process, which applies to such problems and which reduces their analysis to the analysis of a related Gaussian process. </p>
<p>
First, recall that a centered real-valued random variable <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is <em>sub-Gaussian</em> if there is a centered Gaussian random variable whose tail dominates the tail of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, that is, if we have two constants <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> such that, for all <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPr+%5B+X+%5Cgeq+t+%5D+%5Cleq+k+%5Ccdot+e%5E%7B-t%5E2+%2Fv+%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \Pr [ X \geq t ] \leq k \cdot e^{-t^2 /v } " class="latex" title="\displaystyle  \Pr [ X \geq t ] \leq k \cdot e^{-t^2 /v } " /></p>
<p>
An equivalent condition is that there is a <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> such that</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+e%5E%7BX%5E2+%2F+v%7D+%3D+O%281%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} e^{X^2 / v} = O(1) " class="latex" title="\displaystyle  \mathop{\mathbb E} e^{X^2 / v} = O(1) " /></p>
<p>
In that case, we can define a norm, called the <img src="https://s0.wp.com/latex.php?latex=%7B%5CPsi_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Psi_2}" class="latex" title="{\Psi_2}" /> norm as</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+X+%7C%7C_%7B%5CPsi_2%7D+%3A%3D+%5C%7B+%5Cinf+%5Csigma+%3A+%5Cmathop%7B%5Cmathbb+E%7D%5E%7BX%5E2+%2F+%5Csigma%5E2%7D+%5Cleq+2+%5C%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || X ||_{\Psi_2} := \{ \inf \sigma : \mathop{\mathbb E}^{X^2 / \sigma^2} \leq 2 \} " class="latex" title="\displaystyle  || X ||_{\Psi_2} := \{ \inf \sigma : \mathop{\mathbb E}^{X^2 / \sigma^2} \leq 2 \} " /></p>
<p>
which is, roughly, the standard deviation of a centered Gaussian that dominates <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />.</p>
<blockquote><p><b>Example 1</b> <em> All bounded random variables are sub-Gaussian. </em></p></blockquote>
<p>
</p><blockquote><p><b>Example 2</b> <em> If </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%3D+%5Csum_i+X_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  X = \sum_i X_i " class="latex" title="\displaystyle  X = \sum_i X_i " /></p>
</em><p><em> where the <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> are independent Rademacher random variables, that is, if each <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> is equally likely to be +1 or -1, then <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is sub-Gaussian with <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+X%7C%7C_%7B%5CPsi_2%7D+%3D+O%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|| X||_{\Psi_2} = O(\sqrt n)}" class="latex" title="{|| X||_{\Psi_2} = O(\sqrt n)}" />, which is within a constant factor of its actual standard deviation. </em></p></blockquote>
<p>
</p><blockquote><p><b>Example 3</b> <em> If </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%3D+%5Csum_i+X_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  X = \sum_i X_i " class="latex" title="\displaystyle  X = \sum_i X_i " /></p>
</em><p><em> where the <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> are independent and each <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> has probability <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> of being equal to <img src="https://s0.wp.com/latex.php?latex=%7B1-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-p}" class="latex" title="{1-p}" /> and probability <img src="https://s0.wp.com/latex.php?latex=%7B1-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-p}" class="latex" title="{1-p}" /> of being equal to <img src="https://s0.wp.com/latex.php?latex=%7B-p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-p}" class="latex" title="{-p}" /> (that is, each <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> is a centered Bernoulli random variable), then <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+X%7C%7C_%7B%5CPsi_2%7D+%3D+%5COmega+%5Cleft%28+%5Csqrt+%7B%5Cfrac+%7Bn%7D+%7B%5Clog+1%2Fp+%7D+%7D+%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|| X||_{\Psi_2} = \Omega \left( \sqrt {\frac {n} {\log 1/p } } \right)}" class="latex" title="{|| X||_{\Psi_2} = \Omega \left( \sqrt {\frac {n} {\log 1/p } } \right)}" />, which is much more than the standard deviation of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> when <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> is small. </em></p></blockquote>
<p>
</p><blockquote><p><b>Example 4</b> <em> If </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++X+%3D+%5Csum_i+a_i+X_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  X = \sum_i a_i X_i " class="latex" title="\displaystyle  X = \sum_i a_i X_i " /></p>
</em><p><em> where the <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> are independent Rademacher random variables, and the <img src="https://s0.wp.com/latex.php?latex=%7Ba_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_i}" class="latex" title="{a_i}" /> are arbitrary real scalars, then <img src="https://s0.wp.com/latex.php?latex=%7B%7C%7C+X+%7C%7C_%7B%5CPsi_2%7D+%3D+O%28%5Csqrt+%7B%5Csum_i+a_i%5E2+%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|| X ||_{\Psi_2} = O(\sqrt {\sum_i a_i^2 })}" class="latex" title="{|| X ||_{\Psi_2} = O(\sqrt {\sum_i a_i^2 })}" />, which is within a constant factor of the standard deviation that we would get by replacing each <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> with a standard Gaussian. </em></p></blockquote>
<p></p><p>
Let now <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> be a centered random process. We will say that a Gaussian process <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+%5Chat+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ \hat F(t) \}_{t\in T} }" class="latex" title="{\{ \hat F(t) \}_{t\in T} }" /> <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />-dominates <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> if, for every <img src="https://s0.wp.com/latex.php?latex=%7Bt_1%2Ct_2+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_1,t_2 \in T}" class="latex" title="{t_1,t_2 \in T}" /> we have</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+F%28t_1%29+-+F%28t_2%29+%7C%7C_%7B%5CPsi_2%7D+%5Cleq+K+%5Ccdot+%5Csqrt%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft+%28%5Chat+F%28t_1%29+-+%5Chat+F%28t_2%29+%5Cright%29%5E2+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || F(t_1) - F(t_2) ||_{\Psi_2} \leq K \cdot \sqrt{\mathop{\mathbb E} \left (\hat F(t_1) - \hat F(t_2) \right)^2 }" class="latex" title="\displaystyle  || F(t_1) - F(t_2) ||_{\Psi_2} \leq K \cdot \sqrt{\mathop{\mathbb E} \left (\hat F(t_1) - \hat F(t_2) \right)^2 }" /></p>
<p>
That is, every random variable of the form <img src="https://s0.wp.com/latex.php?latex=%7BF%28t_1%29+-+F%28t_2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t_1) - F(t_2)}" class="latex" title="{F(t_1) - F(t_2)}" /> is sub-Gaussian, and its tail is dominated by the tail of the Gaussian distribution <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%28t_1%29+-+%5Chat+F%28t_2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat F(t_1) - \hat F(t_2)}" class="latex" title="{\hat F(t_1) - \hat F(t_2)}" /></p>
<blockquote><p><b>Theorem 3 (Talagrand’s comparison inequality)</b> <em> There is an absolute constant <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> such that if <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> is a centered random process that is <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />-dominated by a centered Gaussian random process <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+%5Chat+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ \hat F(t) \}_{t\in T} }" class="latex" title="{\{ \hat F(t) \}_{t\in T} }" />, then </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5C+F%28t%29+%5Cleq+CK+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Chat+F%28t%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \ F(t) \leq CK \mathop{\mathbb E} \sup_{t\in T} \hat F(t) " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup_{t\in T} \ F(t) \leq CK \mathop{\mathbb E} \sup_{t\in T} \hat F(t) " /></p>
<p> Furthermore, for every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cgeq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell \geq 0}" class="latex" title="{\ell \geq 0}" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CPr+%5Cleft%5B+%5Csup_%7Bt_1%2Ct_2+%5Cin+T%7D+F%28t_1%29+-+F%28t_2%29+%5Cgeq+CK+%5C+%5Cleft%28+%5Cell+%5Ccdot+diam%28T%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D+%5Csup_%7Bt%5Cin+T%7D+%5Chat+F%28t%29+%5Cright%29+%5Cright%5D+%5Cleq+2+e%5E%7B-%5Cell%5E2%7D+%5C+%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \Pr \left[ \sup_{t_1,t_2 \in T} F(t_1) - F(t_2) \geq CK \ \left( \ell \cdot diam(T) + \mathop{\mathbb E} \sup_{t\in T} \hat F(t) \right) \right] \leq 2 e^{-\ell^2} \ , " class="latex" title="\displaystyle  \Pr \left[ \sup_{t_1,t_2 \in T} F(t_1) - F(t_2) \geq CK \ \left( \ell \cdot diam(T) + \mathop{\mathbb E} \sup_{t\in T} \hat F(t) \right) \right] \leq 2 e^{-\ell^2} \ , " /></p>
</em><p><em> where <img src="https://s0.wp.com/latex.php?latex=%7Bdiam%28T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{diam(T)}" class="latex" title="{diam(T)}" /> is the diameter of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> with respect to the distance function <img src="https://s0.wp.com/latex.php?latex=%7Bd%28s%2Ct%29+%3A%3D+%5Csqrt%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Cleft+%28%5Chat+F%28s%29+-+%5Chat+F%28t%29+%5Cright%29%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(s,t) := \sqrt{\mathop{\mathbb E} \left (\hat F(s) - \hat F(t) \right)^2}}" class="latex" title="{d(s,t) := \sqrt{\mathop{\mathbb E} \left (\hat F(s) - \hat F(t) \right)^2}}" />. </em></p></blockquote>
<p></p><p>
The way to apply this theory is the following. </p>
<p>
Suppose that we want estimate, on average or with high probability, the optimum of an optimization problem with feasible set <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> over the randomness of the choice of a random instance. We model this problem like a centered random process <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ F(t) \}_{t\in T}}" class="latex" title="{\{ F(t) \}_{t\in T}}" /> in which <img src="https://s0.wp.com/latex.php?latex=%7BF%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(t)}" class="latex" title="{F(t)}" /> is the difference between the cost of solution <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> in a random instance minus the average cost of <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />.</p>
<p>
Then we think about a related random experiment, in which the random choices involved in constructing our instance are replaced by Gaussian choices (for example, instead of a <img src="https://s0.wp.com/latex.php?latex=%7BG_%7Bn%2C1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G_{n,1/2}}" class="latex" title="{G_{n,1/2}}" /> random graph we may think of a complete graph with Gaussian weights on the edges chosen with expectation 1/2 and constant variance) and we let <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B+%5Chat+F%28t%29+%5C%7D_%7Bt%5Cin+T%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{ \hat F(t) \}_{t\in T}}" class="latex" title="{\{ \hat F(t) \}_{t\in T}}" /> be the analogous process in this Gaussian model.</p>
<p>
If we can argue that <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat F}" class="latex" title="{\hat F}" /> dominates <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />, then it remains to estimate <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E} \sup \hat F}" class="latex" title="{\mathop{\mathbb E} \sup \hat F}" />, which we can do either by the generic chaining theorem or by other methods.</p>
<p>
</p><p><b>4. An Example </b></p>
<p></p><p>
We will now use this machinery to show that the largest eigenvalue of a random symmetric <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\times n}" class="latex" title="{n\times n}" /> matrix with Rademacher entries is <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\sqrt n)}" class="latex" title="{O(\sqrt n)}" />. This is certainly not the simplest way of proving such a result, but it will give a sense of how these techniques can be applied.</p>
<p>
We let <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5C%7B+x%5Cin+%7B%5Cmathbb+R%7D%5En+%3A+%7C%7Cx+%7C%7C%3D1+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = \{ x\in {\mathbb R}^n : ||x ||=1 \}}" class="latex" title="{T = \{ x\in {\mathbb R}^n : ||x ||=1 \}}" /> be the unit sphere. </p>
<p>
Our Gaussian process will be to pick standard Gaussians <img src="https://s0.wp.com/latex.php?latex=%7Bg_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_{i,j}}" class="latex" title="{g_{i,j}}" />, for each <img src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+i+%5Cleq+j+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 \leq i \leq j \leq n}" class="latex" title="{1 \leq i \leq j \leq n}" />, define the matrix <img src="https://s0.wp.com/latex.php?latex=%7B+%5Chat+M_%7Bi%2Cj%7D+%3D+%5Chat+M_%7Bj%2Ci%7D+%3D+g_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ \hat M_{i,j} = \hat M_{j,i} = g_{i,j}}" class="latex" title="{ \hat M_{i,j} = \hat M_{j,i} = g_{i,j}}" /> and let</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Chat+F%28x%29+%3D+x%5ET+%5Chat+M+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \hat F(x) = x^T \hat M x " class="latex" title="\displaystyle  \hat F(x) = x^T \hat M x " /></p>
<p> for every <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in T}" class="latex" title="{x\in T}" />.</p>
<p>
Our “sub-Gaussian” random process is to pick Rademacher random variables <img src="https://s0.wp.com/latex.php?latex=%7Br_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_{i,j}}" class="latex" title="{r_{i,j}}" />, for each <img src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+i+%5Cleq+j+%5Cleq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 \leq i \leq j \leq n}" class="latex" title="{1 \leq i \leq j \leq n}" />, define the matrix <img src="https://s0.wp.com/latex.php?latex=%7B+M_%7Bi%2Cj%7D+%3D+M_%7Bj%2Ci%7D+%3D+r_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ M_{i,j} = M_{j,i} = r_{i,j}}" class="latex" title="{ M_{i,j} = M_{j,i} = r_{i,j}}" /> and let</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28x%29+%3D+x%5ET+M+x+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F(x) = x^T M x " class="latex" title="\displaystyle  F(x) = x^T M x " /></p>
<p> for every <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in T}" class="latex" title="{x\in T}" />.</p>
<p>
We will argue that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" />-dominated by <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat F}" class="latex" title="{\hat F}" /> and that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+%5Chat+F+%3D+O%28%5Csqrt+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E} \sup \hat F = O(\sqrt n)}" class="latex" title="{\mathop{\mathbb E} \sup \hat F = O(\sqrt n)}" />.</p>
<p>
For the first claim, we see that for every <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y \in T}" class="latex" title="{x,y \in T}" />, we can write <img src="https://s0.wp.com/latex.php?latex=%7BF%28x%29-F%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(x)-F(y)}" class="latex" title="{F(x)-F(y)}" /> as</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%28x%29+-+F%28y%29+%3D+%5Csum_%7Bi%2Cj%7D+M_%7Bi%2Cj%7D+%28x_ix_j+-+y_iy_j%29+%3D+2+%5Csum_%7Bi%3Cj%7D+r_%7Bi%2Cj%7D+%28x_ix_j+-+y_iy_j%29+%2B+%5Csum_i+r_%7Bi%2Ci%7D+%28x_i%5E2+-+y_i%5E2%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F(x) - F(y) = \sum_{i,j} M_{i,j} (x_ix_j - y_iy_j) = 2 \sum_{i&lt;j} r_{i,j} (x_ix_j - y_iy_j) + \sum_i r_{i,i} (x_i^2 - y_i^2) " class="latex" title="\displaystyle  F(x) - F(y) = \sum_{i,j} M_{i,j} (x_ix_j - y_iy_j) = 2 \sum_{i&lt;j} r_{i,j} (x_ix_j - y_iy_j) + \sum_i r_{i,i} (x_i^2 - y_i^2) " /></p>
<p>
So, as noted in one of our examples above, we can say that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+F%28x%29+-+F%28y%29+%7C%7C%5E2_%7B%5CPsi_2%7D+%5Cleq+O+%5Cleft%28+4+%5Csum_%7Bi%3Cj%7D+%28x_ix_j+-+y_iy_j%29+%5E2+%2B+%5Csum_i+%28x_i%5E2+-+y_i%5E2%29%5E2+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || F(x) - F(y) ||^2_{\Psi_2} \leq O \left( 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 \right) " class="latex" title="\displaystyle  || F(x) - F(y) ||^2_{\Psi_2} \leq O \left( 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 \right) " /></p>
<p> and we see that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28d%28x%2Cy%29%29%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D+%28+%5Chat+F%28x%29+-+%5Chat+F%28y%29+%29%5E2+%3D+4+%5Csum_%7Bi%3Cj%7D+%28x_ix_j+-+y_iy_j%29+%5E2+%2B+%5Csum_i+%28x_i%5E2+-+y_i%5E2%29%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} ( \hat F(x) - \hat F(y) )^2 = 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 " class="latex" title="\displaystyle  (d(x,y))^2 = \mathop{\mathbb E} ( \hat F(x) - \hat F(y) )^2 = 4 \sum_{i&lt;j} (x_ix_j - y_iy_j) ^2 + \sum_i (x_i^2 - y_i^2)^2 " /></p>
<p> so that, indeed, <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" />-dominated by <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat+F%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat F}" class="latex" title="{\hat F}" />.</p>
<p>
Now we need to apply generic chaining to <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />. It is very helpful to note that the distance function defined on <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> by the Gaussian process is dominated by Euclidean distance between the vectors <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, because</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28d%28x%2Cy%29%29%5E2+%5Cleq+2+%7C%7C+xx%5ET+-+yy%5ET+%7C%7C%5E2_F+%5Cleq+2+%5Ccdot+%28%7C%7Cx%7C%7C+%2B+%7C%7Cy%7C%7C%29%5E2+%5Ccdot+%7C%7Cx-y%7C%7C%5E2+%3D+8+%7C%7Cx-y%7C%7C%5E2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (d(x,y))^2 \leq 2 || xx^T - yy^T ||^2_F \leq 2 \cdot (||x|| + ||y||)^2 \cdot ||x-y||^2 = 8 ||x-y||^2 " class="latex" title="\displaystyle  (d(x,y))^2 \leq 2 || xx^T - yy^T ||^2_F \leq 2 \cdot (||x|| + ||y||)^2 \cdot ||x-y||^2 = 8 ||x-y||^2 " /></p>
<p> where we used the inequality </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%7C+xx%5ET+-+yy%5ET+%7C%7C_F+%5Cleq+%28+%7C%7Cx+%7C%7C+%2B+%7C%7Cy%7C%7C%29+%5Ccdot+%7C%7Cx-y%7C%7C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  || xx^T - yy^T ||_F \leq ( ||x || + ||y||) \cdot ||x-y|| " class="latex" title="\displaystyle  || xx^T - yy^T ||_F \leq ( ||x || + ||y||) \cdot ||x-y|| " /></p>
<p>
We can conclude that an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-net over the unit Euclidean sphere is also a <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt+%7B8%7D%5Ccdot+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt {8}\cdot \epsilon}" class="latex" title="{\sqrt {8}\cdot \epsilon}" />-net for the metric space <img src="https://s0.wp.com/latex.php?latex=%7B%28T%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(T,d)}" class="latex" title="{(T,d)}" />. For the unit Euclidean sphere there is an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-net of size at most <img src="https://s0.wp.com/latex.php?latex=%7B%283%2F%5Cepsilon%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(3/\epsilon)^n}" class="latex" title="{(3/\epsilon)^n}" />. To apply generic chaining, let <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> be an arbitrary subset of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> of cardinality <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7B2%5Ek%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{2^k}}" class="latex" title="{2^{2^k}}" /> if <img src="https://s0.wp.com/latex.php?latex=%7B2%5Ek+%3C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^k &lt; n}" class="latex" title="{2^k &lt; n}" />, and an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" />-net with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3D+3%5Ccdot+2%5E%7B-2%5Ek+%2F+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon = 3\cdot 2^{-2^k / n}}" class="latex" title="{\epsilon = 3\cdot 2^{-2^k / n}}" /> otherwise. Applying the generic chaining inequality,</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathop%7B%5Cmathbb+E%7D+%5Csup+%5C+%5Chat+F+%5Cleq+O%281%29+%5Ccdot+%5Csum_k+2%5E%7Bk%2F2%7D+%5Ccdot+%5Csqrt%7B8%7D+%5Ccdot+%5Cmin+%5Cleft%5C%7B+2%2C+3%5Ccdot+2%5E%7B-2%5Ek+%2F+n%7D+%5Cright%5C%7D+%3D+O%28%5Csqrt+n%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathop{\mathbb E} \sup \ \hat F \leq O(1) \cdot \sum_k 2^{k/2} \cdot \sqrt{8} \cdot \min \left\{ 2, 3\cdot 2^{-2^k / n} \right\} = O(\sqrt n) " class="latex" title="\displaystyle  \mathop{\mathbb E} \sup \ \hat F \leq O(1) \cdot \sum_k 2^{k/2} \cdot \sqrt{8} \cdot \min \left\{ 2, 3\cdot 2^{-2^k / n} \right\} = O(\sqrt n) " /></p>
<p></p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/05/03/talagrands-generic-chaining/"><span class="datestr">at May 03, 2020 05:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/067">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/067">TR20-067 |  Computational and proof complexity of partial string avoidability | 

	Dmitry Itsykson, 

	Alexander Okhotin, 

	Vsevolod Oparin</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The partial string avoidability problem is stated as follows: given a finite set of strings with possible ``holes'' (wildcard symbols), determine whether there exists a two-sided infinite string containing no substrings from this set, assuming that a hole matches every symbol. The problem is known to be NP-hard and in PSPACE, and this paper establishes its PSPACE-completeness. Next, string avoidability over the binary alphabet is interpreted as a version of conjunctive normal form satisfiability problem (SAT), where each clause has infinitely many shifted variants. Non-satisfiability of these formulas can be proved using variants of classical propositional proof systems, augmented with derivation rules for shifting proof lines
(such as clauses, inequalities, polynomials, etc). First, it is proved that there is a particular formula that has a short refutation in Resolution with a shift rule, but requires classical proofs of exponential size At the same time, it is shown that exponential lower bounds for classical proof systems can be translated for their shifted versions. Finally, it is shown that superpolynomial lower bounds on the size of shifted proofs would separate NP from PSPACE; a connection to lower bounds on circuit complexity is also established.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/067"><span class="datestr">at May 03, 2020 11:07 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/066">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/066">TR20-066 |  Quantum Implications of Huang&amp;#39;s Sensitivity Theorem | 

	Scott Aaronson, 

	Shalev Ben-David, 

	Robin Kothari, 

	Avishay Tal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Based on the recent breakthrough of Huang (2019), we show that for any total Boolean function $f$, the deterministic query complexity, $D(f)$, is at most quartic in the quantum query complexity, $Q(f)$: $D(f) = O(Q(f)^4)$. This matches the known separation (up to log factors) due to Ambainis, Balodis, Belovs, Lee, Santha, and Smotrovs (2017). We also use the result to resolve the quantum analogue of the Aanderaa-Karp-Rosenberg conjecture. We show that if $f$ is a nontrivial monotone graph property of an $n$-vertex graph specified by its adjacency matrix, then $Q(f) = \Omega(n)$, which is also optimal.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/066"><span class="datestr">at May 03, 2020 11:01 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5494">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2020/05/03/math-summer-programs/">Math Summer Programs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The virus is causing some math summer programs to cancel. Surprisingly, this led to something wonderful. Unusually strong undergrads are starting to run their own online summer math programs for high school students. 1. The MORPH program is run by the Harvard math club. It offers a variety of mathematical topics at different levels of […]</div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2020/05/03/math-summer-programs/"><span class="datestr">at May 03, 2020 01:11 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/065">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/065">TR20-065 |  Sharp Threshold Results for Computational Complexity | 

	Lijie Chen, 

	Ce Jin, 

	Ryan Williams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We establish several ``sharp threshold'' results for computational complexity. For certain tasks, we can prove a resource lower bound of $n^c$ for $c \geq 1$ (or obtain an efficient circuit-analysis algorithm for $n^c$ size), there is strong intuition that a similar result can be proved for larger functions of $n$, yet we can also prove that replacing ``$n^c$'' with ``$n^{c+\varepsilon}$'' in our results, for any $\varepsilon &gt; 0$, would imply a breakthrough $n^{\omega(1)}$ lower bound.  
	  
We first establish such a result for Hardness Magnification. We prove (among other results) that for some $c$, the Minimum Circuit Size Problem for $(\log n)^c$-size circuits on length-$n$ truth tables (${MCSP}[(\log n)^c]$) does not have $n^{2-o(1)}$-size probabilistic formulas. We also prove that an $n^{2+\varepsilon}$ lower bound for ${MCSP}[(\log n)^c]$ (for any $\varepsilon &gt; 0$ and $c \geq 1$) would imply major lower bound results, such as ${NP}$ does not have $n^k$-size formulas for all $k$, and $\#{SAT}$ does not have log-depth circuits.  
Similar results hold for time-bounded Kolmogorov complexity. Note that cubic size lower bounds are known for probabilistic De Morgan formulas (for other functions).  
	  
Next we show a sharp threshold for Quantified Derandomization (QD) of probabilistic formulas.  
(1) For all $\alpha, \varepsilon &gt; 0$, there is a deterministic polynomial-time algorithm that finds satisfying assignments to every probabilistic formula of $n^{2-2\alpha-\varepsilon}$ size with at most $2^{n^{\alpha}}$ falsifying assignments.  
(2) If for some $\alpha, \varepsilon &gt; 0$, there is such an algorithm for probabilistic formulas of $n^{2-\alpha+\varepsilon}$-size and $2^{n^{\alpha}}$ unsatisfying assignments, then a full derandomization of ${NC}^1$ follows: a deterministic poly-time algorithm additively approximating the acceptance probability of any polynomial-size formula. Consequently, ${NP}$ does not have $n^k$-size formulas, for all $k$.  

	  
Finally we show a sharp threshold result for Explicit Obstructions, inspired by Mulmuley's notion of explicit obstructions from GCT. An explicit obstruction against $S(n)$-size formulas is a poly-time algorithm $A$ such that $A(1^n)$ outputs a list $\{(x_i,f(x_i))\}_{i \in [\mathrm{poly}(n)]} \subseteq \{0,1\}^n \times \{0,1\}$, and every $S(n)$-size formula $F$ is inconsistent with the (partially defined) function $f$. We prove that for all $\varepsilon &gt; 0$, there is an explicit obstruction against $n^{2-\varepsilon}$-size formulas, and prove that there is an explicit obstruction against $n^{2+\varepsilon}$-size formulas for some $\varepsilon &gt; 0$ if and only if there is an explicit obstruction against all polynomial-size formulas. This in turn is equivalent to the statement that ${E}$ does not have $2^{o(n)}$-size formulas, a breakthrough in circuit complexity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/065"><span class="datestr">at May 02, 2020 11:43 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/064">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/064">TR20-064 |  Automating Algebraic Proof Systems is NP-Hard | 

	Mika Göös, 

	Susanna de Rezende, 

	Jakob Nordström, 

	Toniann Pitassi, 

	Robert Robere, 

	Dmitry Sokolov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that algebraic proofs are hard to find: Given an unsatisfiable CNF formula $F$, it is NP-hard to find a refutation of $F$ in the Nullstellensatz, Polynomial Calculus, or Sherali--Adams proof systems in time polynomial in the size of the shortest such refutation. Our work extends, and gives a simplified proof of, the recent breakthrough of Atserias and Muller (FOCS 2019) that established an analogous result for Resolution.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/064"><span class="datestr">at May 02, 2020 11:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
