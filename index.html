<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at July 15, 2020 10:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/106">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/106">TR20-106 |  Explicit Extremal Designs and Applications to Extractors | 

	Eshan Chattopadhyay, 

	Jesse Goodman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
An $(n,r,s)$-design, or $(n,r,s)$-partial Steiner system, is an $r$-uniform hypergraph over $n$ vertices with pairwise hyperedge intersections of size $0$, we extract from $(N,K,n,k)$-adversarial sources of locality $0$, where $K\geq N^\delta$ and $k\geq\text{polylog }n$. The previous best result (Chattopadhyay et al., STOC 2020) required $K\geq N^{1/2+o(1)}$. As a result, we get extractors for small-space sources over $n$ bits with entropy requirement $k\geq n^{1/2+\delta}$, whereas the previous best result (Chattopadhyay et al., STOC 2020) required $k\geq n^{2/3+\delta}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/106"><span class="datestr">at July 15, 2020 04:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2020-07-15-asynchronous-fault-tolerant-computation-with-optimal-resilience/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2020-07-15-asynchronous-fault-tolerant-computation-with-optimal-resilience/">Asynchronous Fault Tolerant Computation with Optimal Resilience</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A basic question of distributed computing: Is there a fundamental limit to fault tolerant computation in the Asynchronous model? The celebrated FLP theorem says that any protocol that solves Agreement in the asynchronous model that is resilient to at least one crash failure must have a non-terminating execution. This means...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2020-07-15-asynchronous-fault-tolerant-computation-with-optimal-resilience/"><span class="datestr">at July 15, 2020 08:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07161">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07161">Graph Sparsification by Universal Greedy Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lai:Ming=Jun.html">Ming-Jun Lai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xie:Jiaxin.html">Jiaxin Xie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Zhiqiang.html">Zhiqiang Xu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07161">PDF</a><br /><b>Abstract: </b>Graph sparsification is to approximate an arbitrary graph by a sparse graph
and is useful in many applications, such as simplification of social networks,
least squares problems, numerical solution of symmetric positive definite
linear systems and etc. In this paper, inspired by the well-known sparse signal
recovery algorithm called orthogonal matching pursuit (OMP), we introduce a
deterministic, greedy edge selection algorithm called universal greedy
algorithm(UGA) for graph sparsification. The UGA algorithm can output a
$\frac{(1+\epsilon)^2}{(1-\epsilon)^2}$-spectral sparsifier with
$\lceil\frac{n}{\epsilon^2}\rceil$ edges in $O(m+n^2/\epsilon^2)$ time with $m$
edges and $n$ vertices for a general random graph satisfying a mild sufficient
condition. This is a linear time algorithm in terms of the number of edges that
the community of graph sparsification is looking for. The best result in the
literature to the knowledge of the authors is the existence of a deterministic
algorithm which is almost linear, i.e. $O(m^{1+o(1)})$ for some
$o(1)=O(\frac{(\log\log(m))^{2/3}}{\log^{1/3}(m)})$. We shall point out that
several random graphs satisfy the sufficient condition and hence, can be
sparsified in linear time. For a general spectral sparsification problem, e.g.,
positive subset selection problem, a nonnegative UGA algorithm is proposed
which needs $O(mn^2+ n^3/\epsilon^2)$ time and the convergence is established.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07161"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07049">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07049">Quantum exploration algorithms for multi-armed bandits</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Daochen.html">Daochen Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/You:Xuchen.html">Xuchen You</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Tongyang.html">Tongyang Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Childs:Andrew_M=.html">Andrew M. Childs</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07049">PDF</a><br /><b>Abstract: </b>Identifying the best arm of a multi-armed bandit is a central problem in
bandit optimization. We study a quantum computational version of this problem
with coherent oracle access to states encoding the reward probabilities of each
arm as quantum amplitudes. Specifically, we show that we can find the best arm
with fixed confidence using
$\tilde{O}\bigl(\sqrt{\sum_{i=2}^n\Delta^{\smash{-2}}_i}\bigr)$ quantum
queries, where $\Delta_{i}$ represents the difference between the mean reward
of the best arm and the $i^\text{th}$-best arm. This algorithm, based on
variable-time amplitude amplification and estimation, gives a quadratic speedup
compared to the best possible classical result. We also prove a matching
quantum lower bound (up to poly-logarithmic factors).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07049"><span class="datestr">at July 15, 2020 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07040">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07040">Hybrid divide-and-conquer approach for tree search algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rennela:Mathys.html">Mathys Rennela</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Laarman:Alfons.html">Alfons Laarman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dunjko:Vedran.html">Vedran Dunjko</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07040">PDF</a><br /><b>Abstract: </b>As we are entering the era of real-world small quantum computers, finding
applications for these limited devices is a key challenge. In this vein, it was
recently shown that a hybrid classical-quantum method can help provide
polynomial speed-ups to classical divide-and-conquer algorithms, even when only
given access to a quantum computer much smaller than the problem itself. In
this work we study the hybrid divide-and-conquer method in the context of tree
search algorithms, and extend it by including quantum backtracking, which
allows better results than previous Grover-based methods. Further, we provide
general criteria for polynomial speed-ups in the tree search context, and
provide a number of examples where polynomial speed ups, using arbitrarily
smaller quantum computers, can still be obtained. This study possible speed-ups
for the well known algorithm of DPLL and prove threshold-free speed-ups for the
tree search subroutines of the so-called PPSZ algorithm - which is the core of
the fastest exact Boolean satisfiability solver - for certain classes of
formulas. We also provide a simple example where speed-ups can be obtained in
an algorithm-independent fashion, under certain well-studied
complexity-theoretical assumptions. Finally, we briefly discuss the fundamental
limitations of hybrid methods in providing speed-ups for larger problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07040"><span class="datestr">at July 15, 2020 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.07025">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.07025">A Nearly Optimal Deterministic Online Algorithm for Non-Metric Facility Location</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bienkowski:Marcin.html">Marcin Bienkowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldkord:Bj=ouml=rn.html">Björn Feldkord</a>, Paweł Schmidt <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.07025">PDF</a><br /><b>Abstract: </b>In the online non-metric variant of the facility location problem, there is a
given graph consisting of set $F$ of facilities (each with a certain opening
cost), set $C$ of potential clients, and weighted connections between them. The
online part of the input is a sequence of clients from $C$, and in response to
any requested client, an online algorithm may open an additional subset of
facilities and must connect the given client to an open facility.
</p>
<p>We give the first online, polynomial-time deterministic algorithm for this
problem, with competitive ratio of $O(\log |F| \cdot (\log |C| + \log \log
|F|))$. The result is optimal up to loglog factors. Previously, the only known
solution for this problem with a sub-linear competitive ratio was randomized
[Alon et al., TALG 2006]. Our approach is based on solving a different
fractional relaxation than that of Alon et al., where we combine dual fitting
and multiplicative weight updates approaches. By maintaining certain
monotonicity properties of the created fractional solution, we are able to
handle the dependencies between facilities and connections in a rounding
routine.
</p>
<p>Our result, combined with the algorithm by Naor et al. [FOCS 2011] implies
the first deterministic algorithm for the online node-weighted Steiner tree
problem. The resulting competitive ratio is $O(\log k \cdot \log^2 \ell)$ on
graphs of $\ell$ nodes and $k$ terminals.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.07025"><span class="datestr">at July 15, 2020 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06979">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06979">The Collatz process embeds a base conversion algorithm</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/St=eacute=rin:Tristan.html">Tristan Stérin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woods:Damien.html">Damien Woods</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06979">PDF</a><br /><b>Abstract: </b>The Collatz process is defined on natural numbers by iterating the map $T(x)
= T_0(x) = x/2$ when $x\in\mathbb{N}$ is even and $T(x)=T_1(x) =(3x+1)/2$ when
$x$ is odd. In an effort to understand its dynamics, and since Generalised
Collatz Maps are known to simulate Turing Machines [Conway, 1972], it seems
natural to ask what kinds of algorithmic behaviours it embeds. We define a
quasi-cellular automaton that exactly simulates the Collatz process on the
square grid: on input $x\in\mathbb{N}$, written horizontally in base 2,
successive rows give the Collatz sequence of $x$ in base 2. We show that
vertical columns simultaneously iterate the map in base 3. This leads to our
main result: the Collatz process embeds an algorithm that converts any natural
number from base 3 to base 2. We also find that the evolution of our automaton
computes the parity of the number of 1s in any ternary input. It follows that
predicting about half of the bits of the iterates $T^i(x)$, for $i = O(\log
x)$, is in the complexity class NC$^1$ but outside AC$^0$. Finally, we show
that in the extension of the Collatz process to numbers with infinite binary
expansions ($2$-adic integers) [Lagarias, 1985], our automaton constructs
Collatz cycles and encodes the cyclic Collatz conjecture as a natural
reachability problem. These results show that the Collatz process is capable of
some simple, but non-trivial, computation in bases 2 and 3, suggesting an
algorithmic approach to thinking about existence, prediction and structure of
cycles in the Collatz process.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06979"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06920">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06920">A Practical Algorithm with Performance Guarantees for the Art~Gallery Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Simon Hengeveld, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miltzow:Tillmann.html">Tillmann Miltzow</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06920">PDF</a><br /><b>Abstract: </b>Given a closed simple polygon $P$, we say two points $p,q$ see each other if
the segment $pq$ is fully contained in $P$. The art gallery problem seeks a
minimum size set $G\subset P$ of guards that sees $P$ completely. The only
currently correct algorithm to solve the art gallery problem exactly uses
algebraic methods and is attributed to Sharir. As the art gallery problem is
ER-complete, it seems unlikely to avoid algebraic methods, without additional
assumptions. In this paper, we introduce the notion of vision stability. In
order to describe vision stability consider an enhanced guard that can see
``around the corner'' by an angle of $\delta$ or a diminished guard whose
vision is by an angle of $\delta$ ``blocked'' by reflex vertices. A polygon $P$
has vision stability $\delta$ if the optimal number of enhanced guards to guard
$P$ is the same as the optimal number of diminished guards to guard $P$. We
will argue that most relevant polygons are vision stable. We describe a
one-shot vision stable algorithm that computes an optimal guard set for
visionstable polygons using polynomial time and solving one integer program. It
guarantees to find the optimal solution for every vision stable polygon. We
implemented an iterative visionstable algorithm and show its practical
performance is slower, but comparable with other state of the art algorithms.
Our iterative algorithm is inspired and follows closely the one-shot algorithm.
It delays several steps and only computes them when deemed necessary. Given a
chord $c$ of a polygon, we denote by $n(c)$ the number of vertices visible from
$c$. The chord-width of a polygon is the maximum $n(c)$ over all possible
chords $c$. The set of vision stable polygons admits an FPT algorithm when
parametrized by the chord-width. Furthermore, the one-shot algorithm runs in
FPT time, when parameterized by the number of reflex vertices.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06920"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06896">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06896">Component Order Connectivity in Directed Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>J. Bang-Jensen, E. Eiben, G. Gutin, M. Wahlstrom, A. Yeo <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06896">PDF</a><br /><b>Abstract: </b>A directed graph $D$ is semicomplete if for every pair $x,y$ of vertices of
$D,$ there is at least one arc between $x$ and $y.$ \viol{Thus, a tournament is
a semicomplete digraph.} In the Directed Component Order Connectivity (DCOC)
problem, given a digraph $D=(V,A)$ and a pair of natural numbers $k$ and
$\ell$, we are to decide whether there is a subset $X$ of $V$ of size $k$ such
that the largest strong connectivity component in $D-X$ has at most $\ell$
vertices. Note that DCOC reduces to the Directed Feedback Vertex Set problem
for $\ell=1.$ We study parametered complexity of DCOC for general and
semicomplete digraphs with the following parameters: $k, \ell,\ell+k$ and
$n-\ell$. In particular, we prove that DCOC with parameter $k$ on semicomplete
digraphs can be solved in time $O^*(2^{16k})$ but not in time $O^*(2^{o(k)})$
unless the Exponential Time Hypothesis (ETH) fails. \gutin{The upper bound
$O^*(2^{16k})$ implies the upper bound $O^*(2^{16(n-\ell)})$ for the parameter
$n-\ell.$ We complement the latter by showing that there is no algorithm of
time complexity $O^*(2^{o({n-\ell})})$ unless ETH fails.} Finally, we improve
\viol{(in dependency on $\ell$)} the upper bound of G{\"{o}}ke, Marx and Mnich
(2019) for the time complexity of DCOC with parameter $\ell+k$ on general
digraphs from $O^*(2^{O(k\ell\log (k\ell))})$ to $O^*(2^{O(k\log (k\ell))}).$
Note that Drange, Dregi and van 't Hof (2016) proved that even for the
undirected version of DCOC on split graphs there is no algorithm of running
time $O^*(2^{o(k\log \ell)})$ unless ETH fails and it is a long-standing
problem to decide whether Directed Feedback Vertex Set admits an algorithm of
time complexity $O^*(2^{o(k\log k)}).$
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06896"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06869">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06869">Robust Identifiability in Linear Structural Equation Models of Causal Inference</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankararaman:Karthik_Abinav.html">Karthik Abinav Sankararaman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Louis:Anand.html">Anand Louis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goyal:Navin.html">Navin Goyal</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06869">PDF</a><br /><b>Abstract: </b>In this work, we consider the problem of robust parameter estimation from
observational data in the context of linear structural equation models (LSEMs).
LSEMs are a popular and well-studied class of models for inferring causality in
the natural and social sciences. One of the main problems related to LSEMs is
to recover the model parameters from the observational data. Under various
conditions on LSEMs and the model parameters the prior work provides efficient
algorithms to recover the parameters. However, these results are often about
generic identifiability. In practice, generic identifiability is not sufficient
and we need robust identifiability: small changes in the observational data
should not affect the parameters by a huge amount. Robust identifiability has
received far less attention and remains poorly understood. Sankararaman et al.
(2019) recently provided a set of sufficient conditions on parameters under
which robust identifiability is feasible. However, a limitation of their work
is that their results only apply to a small sub-class of LSEMs, called
``bow-free paths.'' In this work, we significantly extend their work along
multiple dimensions. First, for a large and well-studied class of LSEMs, namely
``bow free'' models, we provide a sufficient condition on model parameters
under which robust identifiability holds, thereby removing the restriction of
paths required by prior work. We then show that this sufficient condition holds
with high probability which implies that for a large set of parameters robust
identifiability holds and that for such parameters, existing algorithms already
achieve robust identifiability. Finally, we validate our results on both
simulated and real-world datasets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06869"><span class="datestr">at July 15, 2020 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06828">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06828">Network Flow Methods for the Minimum Covariates Imbalance Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hochbaum:Dorit_S=.html">Dorit S. Hochbaum</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rao:Xu.html">Xu Rao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06828">PDF</a><br /><b>Abstract: </b>The problem of balancing covariates arises in observational studies where one
is given a group of control samples and another group, disjoint from the
control group, of treatment samples. Each sample, in either group, has several
observed nominal covariates. The values, or categories, of each covariate
partition the treatment and control samples to a number of subsets referred to
as \textit{levels} where the samples at every level share the same covariate
value. We address here a problem of selecting a subset of the control group so
as to balance, to the best extent possible, the sizes of the levels between the
treatment group and the selected subset of control group, the min-imbalance
problem.
</p>
<p>It is proved here that the min-imbalance problem, on two covariates, is
solved efficiently with network flow techniques. We present an integer
programming formulation of the problem where the constraint matrix is totally
unimodular, implying that the linear programming relaxation to the problem has
all basic solutions, and in particular the optimal solution, integral. This
integer programming formulation is linked to a minimum cost network flow
problem which is solvable in $O(n\cdot (n' + n\log n))$ steps, for $n$ the size
of the treatment group and $n'$ the size of the control group. A more efficient
algorithm is further devised based on an alternative, maximum flow, formulation
of the two-covariate min-imbalance problem, that runs in $O(n'^{3/2}\log^2n)$
steps.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06828"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06819">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06819">Lower Bounds of Algebraic Branching Programs and Layerization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Engels:Christian.html">Christian Engels</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06819">PDF</a><br /><b>Abstract: </b>In this paper we improve the lower bound of Chatterjee et al.\ (ECCC 2019) to
an $\Omega(n^2)$ lower bound for unlayered Algebraic Branching Programs. We
also
</p>
<p>study the impact layerization has on Algebraic Branching Programs. We exhibit
a polynomial that has an unlayered ABP of size $O(n)$ but any layered ABP has
size at least $\Omega(n\sqrt{n})$.
</p>
<p>We exhibit a similar dichotomy in the non-commutative setting where the
unlayered ABP has size $O(n)$ and any layered ABP has size at least
$\Omega(n\log n -\log^2 n)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06819"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06754">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06754">Consensus Halving for Sets of Items</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Paul_W=.html">Paul W. Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hollender:Alexandros.html">Alexandros Hollender</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Igarashi:Ayumi.html">Ayumi Igarashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suksompong:Warut.html">Warut Suksompong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06754">PDF</a><br /><b>Abstract: </b>Consensus halving refers to the problem of dividing a resource into two parts
so that every agent values both parts equally. Prior work has shown that when
the resource is represented by an interval, a consensus halving with at most
$n$ cuts always exists, but is hard to compute even for agents with simple
valuation functions. In this paper, we study consensus halving in a natural
setting where the resource consists of a set of items without a linear
ordering. When agents have additive utilities, we present a polynomial-time
algorithm that computes a consensus halving with at most $n$ cuts, and show
that $n$ cuts are almost surely necessary when the agents' utilities are drawn
from probabilistic distributions. On the other hand, we show that for a simple
class of monotonic utilities, the problem already becomes PPAD-hard.
Furthermore, we compare and contrast consensus halving with the more general
problem of consensus $k$-splitting, where we wish to divide the resource into
$k$ parts in possibly unequal ratios, and provide some consequences of our
results on the problem of computing small agreeable sets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06754"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06744">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06744">WOR and $p$'s: Sketches for $\ell_p$-Sampling Without Replacement</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Edith.html">Edith Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagh:Rasmus.html">Rasmus Pagh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06744">PDF</a><br /><b>Abstract: </b>Weighted sampling is a fundamental tool in data analysis and machine learning
pipelines. Samples are used for efficient estimation of statistics or as sparse
representations of the data. When weight distributions are skewed, as is often
the case in practice, without-replacement (WOR) sampling is much more effective
than with-replacement (WR) sampling: it provides a broader representation and
higher accuracy for the same number of samples. We design novel composable
sketches for WOR $\ell_p$ sampling, weighted sampling of keys according to a
power $p\in[0,2]$ of their frequency (or for signed data, sum of updates). Our
sketches have size that grows only linearly with the sample size. Our design is
simple and practical, despite intricate analysis, and based on off-the-shelf
use of widely implemented heavy hitters sketches such as CountSketch. Our
method is the first to provide WOR sampling in the important regime of $p&gt;1$
and the first to handle signed updates for $p&gt;0$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06744"><span class="datestr">at July 15, 2020 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06693">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06693">The Invisible Hand Heuristic for Origin-Destination Integer Multicommodity Network Flows</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barr:Richard_S=.html">Richard S. Barr</a>, Thomas McLoud <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06693">PDF</a><br /><b>Abstract: </b>Origin-destination integer multicommodity flow problems differ from classic
multicommodity models in that each commodity has one source and one sink, and
each commodity must be routed along a single path. A new invisible-hand
heuristic that mimics economic markets' behavior is presented and tested on
large-scale telecommunications networks, with solution times two orders of
magnitude faster than Cplex's LP relaxation, more dramatic MIP ratios, and
small solution value differences.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06693"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06658">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06658">Predicates of the 3D Apollonius Diagram</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Manos Kamarianakis <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06658">PDF</a><br /><b>Abstract: </b>In this thesis we study one of the fundamental predicates required for the
construction of the 3D Apollonius diagram (also known as the 3D Additively
Weighted Voronoi diagram), namely the EDGECONFLICT predicate: given five sites
$S_i, S_j,S_k,S_l,S_m$ that define an edge $e_{ijklm}$ in the 3D Apollonius
diagram, and a sixth query site $S_q$, the predicate determines the portion of
$e_{ijklm}$ that will disappear in the Apollonius diagram of the six sites due
to the insertion of $S_q$. Our focus is on the algorithmic analysis of the
predicate with the aim to minimize its algebraic degree. We decompose the main
predicate into sub-predicates, which are then evaluated with the aid of
additional primitive operations. We show that the maximum algebraic degree
required to answer any of the sub-predicates and primitives, and, thus, our
main predicate is 10 in non-degenerate configurations when the trisector is of
Hausdorff dimension 1. We also prove that all subpredicates developed can be
evaluated using 10 or 8-degree demanding operations for degenerate input for
these trisector types, depending on whether they require the evaluation of an
intermediate INSPHERE predicate or not. Among the tools we use is the 3D
inversion transformation and the so-called qualitative symbolic perturbation
scheme. Most of our analysis is carried out in the inverted space, which is
where our geometric observations and analysis is captured in algebraic terms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06658"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06604">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06604">Update Query Time Trade-off for dynamic Suffix Arrays</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amir:Amihood.html">Amihood Amir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boneh:Itai.html">Itai Boneh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06604">PDF</a><br /><b>Abstract: </b>The Suffix Array SA(S) of a string S[1 ... n] is an array containing all the
suffixes of S sorted by lexicographic order. The suffix array is one of the
most well known indexing data structures, and it functions as a key tool in
many string algorithms. In this paper, we present a data structure for
maintaining the Suffix Array of a dynamic string. For every $0 \leq \varepsilon
\leq 1$, our data structure reports SA[i] in $\tilde{O}(n^{\varepsilon})$ time
and handles text modification in $\tilde{O}(n^{1-\varepsilon})$ time.
Additionally, our data structure enables the same query time for reporting
iSA[i], with iSA being the Inverse Suffix Array of S[1 ... n]. Our data
structure can be used to construct sub-linear dynamic variants of static
strings algorithms or data structures that are based on the Suffix Array and
the Inverse Suffix Array.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06604"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06569">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06569">Conformal mapping in linear time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bishop:Christopher_J=.html">Christopher J. Bishop</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06569">PDF</a><br /><b>Abstract: </b>Given any $\epsilon &gt;0$ and any planar region $\Omega$ bounded by a simple
n-gon $P$ we construct a ($1 + \epsilon)$-quasiconformal map between $\Omega$
and the unit disk in time $C(\epsilon)n$. One can take $ C(\epsilon) = C + C
\log (1/\epsilon) \log \log (1/\epsilon)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06569"><span class="datestr">at July 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/105">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/105">TR20-105 |  Automating Regular or Ordered Resolution is NP-Hard | 

	Zoë Bell</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that is hard to find regular or even ordered (also known as Davis-Putnam) Resolution proofs, extending the breakthrough result for general Resolution from Atserias and Müller to these restricted forms. Namely, regular and ordered Resolution are automatable if and only if P = NP. Specifically, for a CNF formula $F$ the problem of distinguishing between the existence of a polynomial-size ordered Resolution refutation of $F$ and an at least exponential-size general Resolution proof being required to refute $F$ is NP-complete.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/105"><span class="datestr">at July 14, 2020 01:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2020/07/14/there-are-none/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2020/07/14/there-are-none/">There are none</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the <a href="http://www.argmin.net/2020/07/08/gain-margin/">last post</a>, we showed that continuous-time LQR has “natural robustness” insofar as the optimal solution is robust to a variety of model-mismatch conditions. LQR makes the assumption that the state of the system is fully, perfectly observed. In many situations, we don’t have access to such perfect state information. What changes?</p>

<p>The generalization of LQR to the case with imperfect state observation is called “Linear Quadratic Gaussian” control (LQG). This is the simplest, special case of a Partially Observed Markov Decision Process (POMDP). We again assume linear dynamics:</p>



<p>where the state is now corrupted by zero-mean Gaussian noise, $w_t$. Instead of measuring the state $x_t$ directly, we instead  measure a signal $y_t$ of the form</p>



<p>Here, $v_t$ is also zero-mean Gaussian noise. Suppose we’d still like to minimize a quadratic cost function</p>



<p>This problem is very similar to our LQR problem except for the fact that we get an indirect measurement of the state and need to apply some sort of <em>filtering</em> of the $y_t$ signal to estimate $x_t$.</p>

<p>The optimal solution for LQG is strikingly elegant. Since the observation of $x_t$ is through a Gaussian process, the maximum likelihood estimation algorithm has a clean, closed form solution, even in continuous time. Our best estimate for $x_t$, denoted $\hat{x}_t$, given all of the data observed up to time $t$ obeys a differential equation</p>



<p>The matrix $L$ that can be found by solving an algebraic Riccati equation that depends on the variance of $v_t$ and $w_t$ and on the matrices $A$ and $C$. In particular, it’s the CARE with data $(A^\top,C^\top,\Sigma_w,\Sigma_v)$. This solution is called a <em>Kalman Filter</em> and is a continuous limit of the discrete time Kalman Filter one might see in a course on graphical models.</p>

<p>The optimal LQG solution takes the estimate of the Kalman Filter, $\hat{x}_t$, and sets the control signal to be</p>



<p>Here, $K$ is gain matrix that would be used to solve the LQR problem with data $(A,B,Q,R)$. That is, LQG performs optimal filtering to compute the best state estimate, and then computes a feedback policy as if this estimate was a noiseless measurement of the state. That this turns out to be optimal is one of the more amazing results in control theory. It decouples the process of designing an optimal filter from designing an optimal controller, enabling simplicity and modularity in control design. This decoupling where we treat the output of our state estimator as the true state is an example of <em>certainty equivalence</em>, the umbrella term for using point estimates of stochastic quantities as if they were the correct value. Though certainty equivalent control may be suboptimal in general, it remains ubiquitous for all of the benefits it brings as a design paradigm. Unfortunately, not only is this decoupled design of filters and controllers often suboptimal, it has many hidden fragilities. LQG highlights a particular scenario where certainty equivalent control leads to misplaced optimism about robustness.</p>

<p>We saw in the previous post that LQR had this amazing robustness property: even if you optimize with the wrong model, you’ll still probably be OK. Is the same true about LQG? What are the guaranteed stability margins for LQG regulators? The answer was succinctly summed up in the <a href="https://ieeexplore.ieee.org/document/1101812">abstract of a 1978 paper by John Doyle</a>: “There are none.”</p>

<p class="center"><img width="400px" alt="There Are None" src="http://www.argmin.net/assets/there_are_none.png" /></p>

<p>What goes wrong? Doyle came up with a simple counterexample, that I’m going to simplify even further for the purpose of contextualizing in our modern discussion. Before presenting the example, let’s first dive into <em>why</em> LQG is likely less robust than LQR. Let’s assume that the true dynamics obeys the ODE:</p>



<p>though we computed the optimal controller with the matrix $B$. Define an error signal, $e_t = x_t - \hat{x}_t$, that measures the current deviation between the actual state and the estimate. Then, using the fact that $u_t = -K \hat{x}_t$, we get the closed loop dynamics</p>



<p>When $B=B_\star$, the bottom left block is equal to zero. The system is then stable provided $A-BK$ and $A-LC$ are both stable matrices (i.e., have eigenvalues in the left half plane). However, small perturbations in the off-diagonal block can make the matrix unstable. For intuition, consider the matrix</p>



<p>The eigenvalues of this matrix are $-1$ and $-2$, so the matrix is clearly stable. But the matrix</p>



<p>has an eigenvalue greater than zero if $t&gt;0.01$. So a tiny perturbation significantly shifts the eigenvalues and makes the matrix unstable.</p>

<p>Similar things happen in LQG. In Doyle’s example he uses the problem instance:</p>







<p>The open loop system here is unstable, having two eigenvalues at $1$. We can stabilize the system only by modifying the second state. The state disturbance is aligned along the $[1;1]$ direction, and the state cost only penalizes states aligned with this disturbance. So the goal is simply to remove as much signal as possible in the $[1;1]$ direction without using too much control authority. We only are able to measure the first component of the state, and this measurement is corrupted by Gaussian noise.</p>

<p>What does the optimal policy look like? Perhaps unsurprisingly, it focuses all of its energy on ensuring that there is little state signal along the disturbance direction. The optimal $K$ and $L$ matrices are</p>



<p>Now what happens when we have model mismatch? If we set $B_\star=tB$ and use the formula for the closed loop above, we see that closed loop state transition matrix is</p>



<p>It’s straight forward to check that when $t=1$ (i.e., no model mismatch), the eigenvalues of  $A-BK$ and $A-LC$ all have negative real parts. For the full closed loop matrix, analytically computing the eigenvalues themselves is a pain, but we can prove instability by looking at the characteristic polynomial. For a matrix to have all of its eigenvalues in the left half plane, its characteristic polynomial necessarily must have all positive coefficients. If we look at the linear term in the polynomial, we see that we must have</p>



<p>if we’d like any hope of having a stable system. Hence, we can guarantee that this closed loop system is unstable if $t\geq 1+\sigma$. This is a very conservative condition, and we could get a tighter bound if we’d like, but it’s good enough to reveal some paradoxical properties of LQG. The most striking is that if we build a sensor that gives us a better and better measurement, our system becomes more and more fragile to perturbation and model mismatch. For machine learning scientists, this seems to go against all of our training. How can a system become <em>less</em> robust if we improve our sensing and estimation?</p>

<p>Let’s look at the example in more detail to get some intuition for what’s happening. When the sensor noise gets small, the optimal Kalman Filter is more aggressive. If the model is true, then the disturbance has equal value in both states, so, when $\sigma$ is small, the filter can effectively just set the value of the second state to be equal to whatever is in the first state. The filter is effectively deciding that the first state should equal the observation $y_t$, and the second state should be equal to the first state. In other words, it rapidly damps any errors in the disturbance direction $[1;1]$ and, as $d$ increases, it damps the $[0;1]$ direction less. When $t \neq 1$, we are effectively introducing a disturbance that makes the two states unequal. That is, $B-B_\star$ is aligned in the $[0;1]$ and can be treated as a disturbance signal. This undamped component of the error is fed errors from the state estimate $\hat{x}$, and these errors compound each other. Since we spend so much time focusing on our control along the direction of the injected state noise, we become highly susceptible to errors in a different direction and these are the exact errors that occur when there is a gain mismatch between the model and reality.</p>

<p>The fragility of LQG has many takeaways. It highlights that noiseless state measurement can be a dangerous modeling assumption, because it is then optimal to trust our model too much. Though we apparently got a freebie with LQR, for LQG, model mismatch must be explicitly accounted for when designing the controller.</p>

<p>This should be a cautionary tale for modern AI systems. Most of the papers I read in reinforcement learning consider MDPs where we get perfect state measurement. Building an entire field around optimal actions with perfect state observation builds too much optimism. Any realistic scenario is going to have partial state observation, and such problems are much thornier.</p>

<p>A second lesson is that it is not enough to just improve the prediction components in feedback systems that are powered by machine learning. I have spoken with many applied machine learning engineers who have told me that they have seen performance degrade in production systems when they improve their prediction model. They might spend months building some state of the art LSTM mumbo jumbo that is orders of magnitude more accurate in prediction, but in production yields worse performance than the legacy system with a boring ARMA model. It is quite possible that these performance drops are due to the Doyle effect: the improved prediction system is increasing sensitivity to a modeling flaw in some other part of the engineering pipeline.</p>

<p>The story turns out to be even worse than what I have described thus far. The supposed robustness guarantees we derived for LQR assume not just full noiseless state measurement, but that the sensors and actuators have infinite bandwidth. That is, they assume you can build controllers $K$ with arbitrarily large entries and that react instantaneously, without delay, to changes in the state. In the next post, I’ll show how realistic sampled data controllers for LQR, even with noiseless state measurement, also have no guarantees.</p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2020/07/14/there-are-none/"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06242">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06242">Settling the Price of Fairness for Indivisible Goods</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barman:Siddharth.html">Siddharth Barman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhaskar:Umang.html">Umang Bhaskar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shah:Nisarg.html">Nisarg Shah</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06242">PDF</a><br /><b>Abstract: </b>In the allocation of resources to a set of agents, how do fairness guarantees
impact the social welfare? A quantitative measure of this impact is the price
of fairness, which measures the worst-case loss of social welfare due to
fairness constraints. While initially studied for divisible goods, recent work
on the price of fairness also studies the setting of indivisible goods.
</p>
<p>In this paper, we resolve the price of two well-studied fairness notions for
the allocation of indivisible goods: envy-freeness up to one good (EF1), and
approximate maximin share (MMS). For both EF1 and 1/2-MMS guarantees, we show,
via different techniques, that the price of fairness is $O(\sqrt{n})$, where
$n$ is the number of agents. From previous work, it follows that our bounds are
tight. Our bounds are obtained via efficient algorithms. For 1/2-MMS, our bound
holds for additive valuations, whereas for EF1, our bound holds for the more
general class of subadditive valuations. This resolves an open problem posed by
Bei et al. (2019).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06242"><span class="datestr">at July 14, 2020 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06167">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06167">Local Editing in LZ-End Compressed Data</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Daniel Roodt, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Speidel:Ulrich.html">Ulrich Speidel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Vimal.html">Vimal Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Ko:Ryan_K=_L=.html">Ryan K. L. Ko</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06167">PDF</a><br /><b>Abstract: </b>This paper presents an algorithm for the modification of data compressed
using LZ-End, a derivate of LZ77, without prior decompression. The performance
of the algorithm and the impact of the modifications on the compression ratio
is evaluated. Finally, we discuss the importance of this work as a first step
towards local editing in Lempel-Ziv compressed data.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06167"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06110">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06110">Streaming Algorithms for Online Selection Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Correa:Jos=eacute=.html">José Correa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=uuml=tting:Paul.html">Paul Dütting</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Felix.html">Felix Fischer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schewior:Kevin.html">Kevin Schewior</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Ziliotto:Bruno.html">Bruno Ziliotto</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06110">PDF</a><br /><b>Abstract: </b>The model of streaming algorithms is motivated by the increasingly common
situation in which the sheer amount of available data limits the ways in which
the data can be accessed. Streaming algorithms are typically allowed a single
pass over the data and can only store a sublinear fraction of the data at any
time. We initiate the study of classic online selection problems in a streaming
model where the data stream consists of two parts: historical data points that
an algorithm can use to learn something about the input; and data points from
which a selection can be made. Both types of data points are i.i.d. draws from
an unknown distribution. We consider the two canonical objectives for online
selection---maximizing the probability of selecting the maximum and maximizing
the expected value of the selection---and provide the first performance
guarantees for both these objectives in the streaming model.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06110"><span class="datestr">at July 14, 2020 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06105">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06105">Efficient Labeling for Reachability in Digraphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Maciej Dulęba, Paweł Gawrychowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Janczewski:Wojciech.html">Wojciech Janczewski</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06105">PDF</a><br /><b>Abstract: </b>We consider labeling nodes of a directed graph for reachability queries. A
reachability labeling scheme for such a graph assigns a binary string, called a
label, to each node. Then, given the labels of nodes $u$ and $v$ and no other
information about the underlying graph, it should be possible to determine
whether there exists a directed path from $u$ to $v$. By a simple information
theoretical argument and invoking the bound on the number of partial orders, in
any scheme some labels need to consist of at least $n/4$ bits, where $n$ is the
number of nodes. On the other hand, it is not hard to design a scheme with
labels consisting of $n/2+O(\log n)$ bits. In the classical centralised
setting, Munro and Nicholson designed a data structure for reachability queries
consisting of $n^2/4+o(n^2)$ bits (which is optimal, up to the lower order
term). We extend their approach to obtain a scheme with labels consisting of
$n/3+o(n)$ bits.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06105"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06098">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06098">Graph Connectivity and Single Element Recovery via Linear and OR Queries</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Assadi:Sepehr.html">Sepehr Assadi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarty:Deeparnab.html">Deeparnab Chakrabarty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khanna:Sanjeev.html">Sanjeev Khanna</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06098">PDF</a><br /><b>Abstract: </b>We study the problem of finding a spanning forest in an undirected,
$n$-vertex multi-graph under two basic query models. One is the Linear query
model which are linear measurements on the incidence vector induced by the
edges; the other is the weaker OR query model which only reveals whether a
given subset of plausible edges is empty or not. At the heart of our study lies
a fundamental problem which we call the {\em single element recovery} problem:
given a non-negative real vector $x$ in $N$ dimension, return a single element
$x_j &gt; 0$ from the support. Queries can be made in rounds, and our goals is to
understand the trade-offs between the query complexity and the rounds of
adaptivity needed to solve these problems, for both deterministic and
randomized algorithms. These questions have connections and ramifications to
multiple areas such as sketching, streaming, graph reconstruction, and
compressed sensing. Our main results are:
</p>
<p>* For the single element recovery problem, it is easy to obtain a
deterministic, $r$-round algorithm which makes $(N^{1/r}-1)$-queries per-round.
We prove that this is tight: any $r$-round deterministic algorithm must make
$\geq (N^{1/r} - 1)$ linear queries in some round. In contrast, a $1$-round
$O(\log^2 N)$-query randomized algorithm which succeeds 99% of the time is
known to exist.
</p>
<p>* We design a deterministic $O(r)$-round, $\tilde{O}(n^{1+1/r})$-OR query
algorithm for graph connectivity. We complement this with an
$\tilde{\Omega}(n^{1 + 1/r})$-lower bound for any $r$-round deterministic
algorithm in the OR-model.
</p>
<p>* We design a randomized, $2$-round algorithm for the graph connectivity
problem which makes $\tilde{O}(n)$-OR queries. In contrast, we prove that any
$1$-round algorithm (possibly randomized) requires $\tilde{\Omega}(n^2)$-OR
queries.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06098"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06060">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06060">Recognizing $k$-Clique Extendible Orderings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Francis:Mathew.html">Mathew Francis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neogi:Rian.html">Rian Neogi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raman:Venkatesh.html">Venkatesh Raman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06060">PDF</a><br /><b>Abstract: </b>A graph is $k$-clique-extendible if there is an ordering of the vertices such
that whenever two $k$-sized overlapping cliques $A$ and $B$ have $k-1$ common
vertices, and these common vertices appear between the two vertices $a,b\in
(A\setminus B)\cup (B\setminus A)$ in the ordering, there is an edge between
$a$ and $b$, implying that $A\cup B$ is a $(k+1)$-sized clique. Such an
ordering is said to be a $k$-C-E ordering. These graphs arise in applications
related to modelling preference relations. Recently, it has been shown that a
maximum sized clique in such a graph can be found in $n^{O(k)}$ time when the
ordering is given. When $k$ is $2$, such graphs are precisely the well-known
class of comparability graphs and when $k$ is $3$ they are called
triangle-extendible graphs. It has been shown that triangle-extendible graphs
appear as induced subgraphs of visibility graphs of simple polygons, and the
complexity of recognizing them has been mentioned as an open problem in the
literature.
</p>
<p>While comparability graphs (i.e. $2$-C-E graphs) can be recognized in
polynomial time, we show that recognizing $k$-C-E graphs is NP-hard for any
fixed $k \geq 3$ and co-NP-hard when $k$ is part of the input. While our
NP-hardness reduction for $k \geq 4$ is from the betweenness problem, for
$k=3$, our reduction is an intricate one from the $3$-colouring problem. We
also show that the problems of determining whether a given ordering of the
vertices of a graph is a $k$-C-E ordering, and that of finding an $\ell$-sized
(or maximum sized) clique in a $k$-C-E graph, given a $k$-C-E ordering, are
complete for the parameterized complexity classes co-W[1] and W[1]
respectively, when parameterized by $k$. However we show that the former is
fixed-parameter tractable when parameterized by the treewidth of the graph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06060"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.06052">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.06052">City Guarding with Limited Field of View</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Daescu:Ovidiu.html">Ovidiu Daescu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Malik:Hemant.html">Hemant Malik</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.06052">PDF</a><br /><b>Abstract: </b>Drones and other small unmanned aerial vehicles are starting to get
permission to fly within city limits. While video cameras are easily available
in most cities, their purpose is to guard the streets at ground level. Guarding
the aerial space of a city with video cameras is a problem that so far has been
largely ignored.
</p>
<p>In this paper, we present bounds on the number of cameras needed to guard the
city's aerial space (roofs, walls, and ground) using cameras with 180-degree
range of vision (the region in front of the guard), which is common for most
commercial cameras. We assume all buildings are vertical and have a rectangular
base. Each camera is placed at a top corner of a building.
</p>
<p>We considered the following two versions: (i) buildings have an axis-aligned
ground base and, (ii) buildings have an arbitrary orientation. We give
necessary and sufficient results for (i), necessary results for (ii), and
conjecture sufficiency results for (ii). Specifically, for (i) we prove a
sufficiency bound of 2k + k/4 +4 on the number of vertex guards, while for (ii)
we show that 3k + 1 vertex guards are sometimes necessary, where k is the total
number of buildings in the city.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.06052"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05912">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05912">Robust Learning of Mixtures of Gaussians</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kane:Daniel_M=.html">Daniel M. Kane</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05912">PDF</a><br /><b>Abstract: </b>We resolve one of the major outstanding problems in robust statistics. In
particular, if $X$ is an evenly weighted mixture of two arbitrary
$d$-dimensional Gaussians, we devise a polynomial time algorithm that given
access to samples from $X$ an $\eps$-fraction of which have been adversarially
corrupted, learns $X$ to error $\poly(\eps)$ in total variation distance.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05912"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05870">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05870">A subquadratic algorithm for the simultaneous conjugacy problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brodnik:Andrej.html">Andrej Brodnik</a>, Aleksander Malnič, Rok Požar <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05870">PDF</a><br /><b>Abstract: </b>The $d$-Simultaneous Conjugacy problem in the symmetric group $S_n$ asks
whether there exists a permutation $\tau \in S_n$ such that $b_j = \tau^{-1}a_j
\tau$ holds for all $j = 1,2,\ldots, d$, where $a_1, a_2,\ldots , a_d$ and
$b_1, b_2,\ldots , b_d$ are given sequences of permutations in $S_n$. The time
complexity of existing algorithms for solving the problem is $O(dn^2)$. We show
that for a given positive integer $d$ the $d$-Simultaneous Conjugacy problem in
$S_n$ can be solved in $o(n^2)$ time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05870"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05852">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05852">Submodular Meta-Learning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Adibi:Arman.html">Arman Adibi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mokhtari:Aryan.html">Aryan Mokhtari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hassani:Hamed.html">Hamed Hassani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05852">PDF</a><br /><b>Abstract: </b>In this paper, we introduce a discrete variant of the meta-learning
framework. Meta-learning aims at exploiting prior experience and data to
improve performance on future tasks. By now, there exist numerous formulations
for meta-learning in the continuous domain. Notably, the Model-Agnostic
Meta-Learning (MAML) formulation views each task as a continuous optimization
problem and based on prior data learns a suitable initialization that can be
adapted to new, unseen tasks after a few simple gradient updates. Motivated by
this terminology, we propose a novel meta-learning framework in the discrete
domain where each task is equivalent to maximizing a set function under a
cardinality constraint. Our approach aims at using prior data, i.e., previously
visited tasks, to train a proper initial solution set that can be quickly
adapted to a new task at a relatively low computational cost. This approach
leads to (i) a personalized solution for each individual task, and (ii)
significantly reduced computational cost at test time compared to the case
where the solution is fully optimized once the new task is revealed. The
training procedure is performed by solving a challenging discrete optimization
problem for which we present deterministic and randomized algorithms. In the
case where the tasks are monotone and submodular, we show strong theoretical
guarantees for our proposed methods even though the training objective may not
be submodular. We also demonstrate the effectiveness of our framework on two
real-world problem instances where we observe that our methods lead to a
significant reduction in computational complexity in solving the new tasks
while incurring a small performance loss compared to when the tasks are fully
optimized.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05852"><span class="datestr">at July 14, 2020 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05647">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05647">Finding Equilibrium in Multi-Agent Games with Payoff Uncertainty</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Wenshuo.html">Wenshuo Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Curmei:Mihaela.html">Mihaela Curmei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Serena.html">Serena Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Recht:Benjamin.html">Benjamin Recht</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jordan:Michael_I=.html">Michael I. Jordan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05647">PDF</a><br /><b>Abstract: </b>We study the problem of finding equilibrium strategies in multi-agent games
with incomplete payoff information, where the payoff matrices are only known to
the players up to some bounded uncertainty sets. In such games, an ex-post
equilibrium characterizes equilibrium strategies that are robust to the payoff
uncertainty. When the game is one-shot, we show that in zero-sum polymatrix
games, an ex-post equilibrium can be computed efficiently using linear
programming. We further extend the notion of ex-post equilibrium to stochastic
games, where the game is played repeatedly in a sequence of stages and the
transition dynamics are governed by an Markov decision process (MDP). We
provide sufficient condition for the existence of an ex-post Markov perfect
equilibrium (MPE). We show that under bounded payoff uncertainty, the value of
any two-player zero-sum stochastic game can be computed up to a tight value
interval using dynamic programming.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05647"><span class="datestr">at July 14, 2020 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05637">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05637">Dynamic Graph Streaming Algorithm for Digital Contact Tracing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mahapatra:Gautam.html">Gautam Mahapatra</a>, Priodyuti~Pradhan, Ranjan Chattaraj, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Soumya.html">Soumya Banerjee</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05637">PDF</a><br /><b>Abstract: </b>Digital contact tracing of an infected person, testing the possible infection
for the contacted persons, and isolation play a crucial role in alleviating the
outbreak. Here, we design a dynamic graph streaming algorithm that can trace
the contacts under the control of the Public Health Authorities (PHA). The
algorithm can work as the augmented part of the PHA for the crisis period. Our
algorithm receives proximity data from the mobile devices as contact data
streams and uses a sliding window model to construct a dynamic contact graph
sketch. Prominently, we introduce the edge label of the contact graph as a
contact vector, which acts like a sliding window and holds the latest D days of
social interactions. Importantly, the algorithm prepares the direct and
indirect (multilevel) contact list from the contact graph sketch for a given
set of infected persons. The algorithm also uses a disjoint set data structure
to construct the infectious trees for the trace list. The present study offers
the design of algorithms with underlying data structures for digital contact
trace relevant to the proximity data produced by Bluetooth enabled mobile
devices. Our analysis reveals that for COVID-19 close contact parameters, the
storage space requires maintaining the contact graph of ten million users
having 14 days close contact data in PHA server takes 55 Gigabytes of memory
and preparation of the contact list for a given set of the infected person
depends on the size of the infected list.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05637"><span class="datestr">at July 14, 2020 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05634">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05634">Vector Balancing in Lebesgue Spaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reis:Victor.html">Victor Reis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rothvoss:Thomas.html">Thomas Rothvoss</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05634">PDF</a><br /><b>Abstract: </b>A tantalizing conjecture in discrete mathematics is the one of Koml\'os,
suggesting that for any vectors $\mathbf{a}_1,\ldots,\mathbf{a}_n \in B_2^m$
there exist signs $x_1, \dots, x_n \in \{ -1,1\}$ so that $\|\sum_{i=1}^n
x_i\mathbf{a}_i\|_\infty \le O(1)$. It is a natural extension to ask what
$\ell_q$-norm bound to expect for $\mathbf{a}_1,\ldots,\mathbf{a}_n \in B_p^m$.
We prove that, for $2 \le p \le q \le \infty$, such vectors admit fractional
colorings $x_1, \dots, x_n \in [-1,1]$ with a linear number of $\pm 1$
coordinates so that $\|\sum_{i=1}^n x_i\mathbf{a}_i\|_q \leq
O(\sqrt{\min(p,\log(2m/n))}) \cdot n^{1/2-1/p+ 1/q}$, and that one can obtain a
full coloring at the expense of another factor of $\frac{1}{1/2 - 1/p + 1/q}$.
In particular, for $p \in (2,3]$ we can indeed find signs $\mathbf{x} \in \{
-1,1\}^n$ with $\|\sum_{i=1}^n x_i\mathbf{a}_i\|_\infty \le O(n^{1/2-1/p} \cdot
\frac{1}{p-2})$. Our result generalizes Spencer's theorem, for which $p = q =
\infty$, and is tight for $m = n$.
</p>
<p>Additionally, we prove that for any fixed constant $\delta&gt;0$, in a centrally
symmetric body $K \subseteq \mathbb{R}^n$ with measure at least $e^{-\delta n}$
one can find such a fractional coloring in polynomial time. Previously this was
known only for a small enough constant -- indeed in this regime classical
nonconstructive arguments do not apply and partial colorings of the form
$\mathbf{x} \in \{ -1,0,1\}^n$ do not necessarily exist.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05634"><span class="datestr">at July 14, 2020 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05580">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05580">A Strong XOR Lemma for Randomized Query Complexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brody:Joshua.html">Joshua Brody</a>, Jae Tak Kim, Peem Lerdputtipongporn, Hari Srinivasulu <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05580">PDF</a><br /><b>Abstract: </b>We give a strong direct sum theorem for computing $xor \circ g$.
Specifically, we show that for every function g and every $k\geq 2$, the
randomized query complexity of computing the xor of k instances of g satisfies
$\overline{R}_\eps(xor\circ g) = \Theta(k \overline{R}_{\eps/k}(g))$. This
matches the naive success amplification upper bound and answers a conjecture of
Blais and Brody (CCC19).
</p>
<p>As a consequence of our strong direct sum theorem, we give a total function g
for which $R(xor \circ g) = \Theta(k \log(k)\cdot R(g))$, answering an open
question from Ben-David et al.(arxiv:<a href="http://export.arxiv.org/abs/2006.10957">2006.10957v1</a>).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05580"><span class="datestr">at July 14, 2020 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.05557">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.05557">Learning Entangled Single-Sample Gaussians in the Subset-of-Signals Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liang:Yingyu.html">Yingyu Liang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuan:Hui.html">Hui Yuan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.05557">PDF</a><br /><b>Abstract: </b>In the setting of entangled single-sample distributions, the goal is to
estimate some common parameter shared by a family of $n$ distributions, given
one single sample from each distribution. This paper studies mean estimation
for entangled single-sample Gaussians that have a common mean but different
unknown variances. We propose the subset-of-signals model where an unknown
subset of $m$ variances are bounded by 1 while there are no assumptions on the
other variances. In this model, we analyze a simple and natural method based on
iteratively averaging the truncated samples, and show that the method achieves
error $O \left(\frac{\sqrt{n\ln n}}{m}\right)$ with high probability when
$m=\Omega(\sqrt{n\ln n})$, matching existing bounds for this range of $m$. We
further prove lower bounds, showing that the error is
$\Omega\left(\left(\frac{n}{m^4}\right)^{1/2}\right)$ when $m$ is between
$\Omega(\ln n)$ and $O(n^{1/4})$, and the error is
$\Omega\left(\left(\frac{n}{m^4}\right)^{1/6}\right)$ when $m$ is between
$\Omega(n^{1/4})$ and $O(n^{1 - \epsilon})$ for an arbitrarily small
$\epsilon&gt;0$, improving existing lower bounds and extending to a wider range of
$m$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.05557"><span class="datestr">at July 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=3843">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/">Gradient descent for wide two-layer neural networks – II: Generalization and implicit bias</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">In this blog post, we continue our investigation of gradient flows for wide two-layer “relu” neural networks. In the <a href="https://francisbach.com/gradient-descent-neural-networks-global-convergence/">previous post</a>, Francis explained that under suitable assumptions these dynamics converge to global minimizers of the training objective. Today, we build on this to understand qualitative aspects of the predictor learnt by such neural networks. The content is mostly based on our recent joint work [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</p>



<h2>1. Generalization with weight decay regularization</h2>



<p class="justify-text">Let us start our journey with the comfortable case where the training objective includes an explicit <em>weight decay</em> regularization (i.e. \(\ell_2\)-regularization on the parameters). Using the notations of the previous post, this consists in the following objective function on the space of probability measures on \(\mathbb{R}^{d+1}\):  $$ \underbrace{R\Big(\int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w)\Big)}_{\text{Data fitting term}} + \underbrace{\frac{\lambda}{2} \int_{\mathbb{R}^{d+1}} \Vert w \Vert^2_2d\mu(w)}_{\text{Regularization}} \tag{1}$$ where \(R\) is the loss and \(\lambda&gt;0\) is the regularization strength. Remember that a  neural network of finite width with \(m\) neurons is recovered with an empirical measure \(\mu = \frac1m \sum_{j=1}^m\delta_{w_j}\), in which case this regularization is proportional to the sum of the squares of all the parameters \(\frac{\lambda}{2m}\sum_{j=1}^m \Vert w_j\Vert^2_2\).</p>



<p class="justify-text"><strong>Variation norm.</strong> In the previous post, we have seen that the Wasserstein gradient flow of this objective function — an idealization of the gradient descent training dynamics in the large width limit — converges to a global minimizer \(\mu^*\) when initialized properly. An example of an admissible initialization is the hidden weights \(b_j\) distributed according to the uniform distribution \(\tau\) on the unit sphere \(\mathbb{S}^{d-1}\subset \mathbb{R}^d\) and the output weights \(a_j\) uniform in \(\{-1,1\}\). What does this minimizer look like in predictor space when the objective function is as in Eq. (1) ? </p>



<p class="justify-text">To answer this question, we define for a predictor \(h:\mathbb{R}^d\to \mathbb{R}\), the quantity $$ \Vert h \Vert_{\mathcal{F}_1} := \min_{\mu \in \mathcal{P}(\mathbb{R}^{d+1})} \frac{1}{2} \int_{\mathbb{R}^{d+1}} \Vert w\Vert^2_2 d\mu(w) \quad \text{s.t.}\quad h = \int_{\mathbb{R}^{d+1}} \Phi(w)d\mu(w).\tag{2} $$ As the notation suggests, \(\Vert \cdot \Vert_{\mathcal{F}_1}\) is a norm in the space of predictors. It is known as the <em>variation norm</em> [<a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">2</a>, <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">3</a>]. We call \(\mathcal{F}_1\) the space of functions with finite norm, which is a Banach space. By construction, the learnt predictor \(h^* = \int \Phi(w)d\mu^*(w)\) is a minimizer of the \(\mathcal{F}_1\)-regularized regression: $$ \min_{h:\mathbb{R}^d\to \mathbb{R}} R(h) + \lambda \Vert h \Vert_{\mathcal{F}_1} \tag{3}.$$ This \(\mathcal{F}_1\)-norm regularization shares similarity with \(\ell_1\) regularization [<a href="https://arxiv.org/pdf/1412.6614.pdf">4</a>]. To see this, observe that the “magnitude” \(\vert a\vert \Vert b\Vert_2\) of a relu function \(x\mapsto a(b^\top x)_+\) with parameter \(w=(a,b)\) equals \(\Vert w\Vert^2_2/2\) if \(\vert a\vert = \Vert b\Vert_2\) and is smaller otherwise. Thus parameterizing the relus by their direction \(\theta = b/\Vert b\Vert_2\) and optimizing over their signed magnitude \(r(\theta) = a\Vert b\Vert_2\)  we have $$ \Vert h \Vert_{\mathcal{F}_1} = \inf_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).\tag{4}$$</p>



<p class="justify-text"><strong>Conjugate RKHS norm.</strong> The regression in the space \(\mathcal{F}_1\) is best understood when compared with the regression obtained by only training the output weights. We consider the same training dynamics with weight decay except that we fix the hidden weights to their initial value, where they are distributed according to the uniform distribution \(\tau\) on the sphere. In that case, the Wasserstein gradient flow also converges to the solution of a regularized regression as in Eq. (3) — this is in fact a convex problem —  but the regularizing norm is different and now defined as $$ \Vert h \Vert_{\mathcal{F}_2}^2 := \min_{r:\mathbb{S}^{d-1}\to \mathbb{R}} \int_{\mathbb{S}^{d-1}} \vert r(\theta)\vert^2 d\tau(\theta) \quad \text{s.t.}\quad h(x) = \int _{\mathbb{S}^{d-1}} r(\theta) (\theta^\top x)_+ d\tau(\theta).$$ We call \(\mathcal{F}_2\) the set of functions with finite norm. It can be shown to be a <a href="https://en.wikipedia.org/wiki/Reproducing_kernel_Hilbert_space">Reproducing Kernel Hilbert Space</a> (RKHS), with kernel  $$ K(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+ d\tau(\theta),$$ which has a closed form expression [<a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">5</a>]. In this context, taking a finite width neural network corresponds to a random feature approximation of the kernel [<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf">6</a>, <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines">7</a>].</p>



<p class="justify-text">Let us informally compare the properties of these spaces \(\mathcal{F}_1\) and \(\mathcal{F}_2\) (see [<a href="https://arxiv.org/abs/1412.8690">2</a>] for details):</p>



<ul class="justify-text"><li><strong>Approximation power.</strong> In high dimension, only very smooth functions have small \(\mathcal{F}_2\)-norm (in rough terms, the \(\lceil (d+3)/2\rceil\) first derivatives should be small). In contrast, there exists non-smooth functions with small \(\mathcal{F}_1\)-norm, an example being the relu function \(x\mapsto (\theta^\top x)_+\). Remarkably, if we define \(f(x)=g(Ux)\) where \(U\) is an orthogonal projection then \(\Vert f\Vert_{\mathcal{F}_1} \leq  \Vert g\Vert_{\mathcal{F}_2}\). This shows in particular that \(\mathcal{F}_1\) contains \(\mathcal{F}_2\) and that \(\mathcal{F}_1\) is <em>adaptive</em> to lower dimensional structures.</li><li><strong>Statistical complexity.</strong> It could be feared that the good approximation properties of \(\mathcal{F}_1\) come at the price of being “too large” as a hypothesis space, making it difficult to estimate a predictor in \(\mathcal{F}_1\) from few samples. But, as measured by their Rademacher complexities, the unit ball of \(\mathcal{F}_1\) is only \(O(\sqrt{d})\) larger than that of \(\mathcal{F}_2\). By going from \(\mathcal{F}_2\) to \(\mathcal{F}_1\), we thus add some nicely structured predictors to our hypothesis space, but not too much garbage that could fit unstructured noise.</li><li><strong>Generalization guarantees.</strong> By combining the two previous points, it is possible to prove that supervised learning in \(\mathcal{F}_1\) breaks the curse of dimensionality when the output depends on a lower dimensional projection of the input: the required number of training samples only depends mildly on the dimension \(d\).</li><li><strong>Optimization guarantees.</strong> However \(\mathcal{F}_1\) has a strong drawback : there is no known algorithm that solves the problem of Eq. (3) in polynomial time. On practical problems, gradient descent seems to behave well, but in general only qualitative results such as presented in the previous post are known. In contrast, various provably efficient algorithms can solve regression in \(\mathcal{F}_2\), which is a classical kernel ridge regression problem [Chap. 14.4.3, <a href="https://doc.lagout.org/science/Artificial%20Intelligence/Machine%20learning/Machine%20Learning_%20A%20Probabilistic%20Perspective%20%5BMurphy%202012-08-24%5D.pdf">8</a>].</li></ul>



<p class="justify-text">In the plot below, we compare the predictor learnt by gradient descent for a 2-D regression with the square loss and weight decay, after training (a) both layers — which is regression in \(\mathcal{F}_1\) — or (b) just the output layer — which is regression in \(\mathcal{F}_2\). This already illustrates some distinctive features of both spaces, although the differences become more stringent in higher dimensions. In particular, observe that in (a) the predictor is the combination of few relu functions, which illustrates  the sparsifying effect of the \(L^1\)-norm in Eq. (4). To simplify notations, we do not include a bias/intercept in the formulas but our numerical experiments include it, so in this plot the input is of the form \(x=(x_1,x_2,1)\) and \(d=3\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="564" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/regularized-2.png" class="wp-image-4231" height="293" />Predictor learnt by the gradient flow on the square loss with weight decay, when training (a) both layers (b) only the output layer. The markers indicate the location of the training samples  \((x_i)_{i=1}^n\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_weightdecay.jl">[code]</a></figure></div>



<p class="justify-text">The qualitative picture is quite clear so far, but something is a bit unsettling: weight decay is often not needed to obtain a good performance in practice. Our line of reasoning however completely falls apart without such a regularization: if the objective function depends on the predictor only via its values on the training set, being a minimizer does not guarantee anything about generalization outside of the training set (remember that wide relu neural networks are <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximators</a>). Why does it still work in the unregularized case? There must be something in the algorithm…</p>



<h2>2. Implicit bias: linear classification</h2>



<p class="justify-text">This something is called the <em>implicit bias</em> : when there are several minimizers, the optimization algorithm makes a specific choice. In the unregularized case, the “quality” of this choice is a crucial property of an algorithm; much more crucial than, say, its convergence speed on the training objective. To gradually build our intuition of the implicit bias of gradient flows, let us put neural networks aside for a moment and consider, following Soudry, Hoffer, Nacson, Gunasekar and Srebro [<a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">9</a>], a linear classification task.</p>



<p class="justify-text"><strong>Gradient flow of the smooth-margin.</strong> Let \((x_i,y_i)_{i=1}^n\) be a training set of \(n\) pairs of inputs \(x_i\in \mathbb{R}^d\) and outputs \(y_i\in \{-1,1\}\) and let us choose the exponential loss. The analysis that follows also apply to the logistic loss (which is the same as the cross-entropy loss after a sigmoid non-linearity) because only the “tail” of the loss matters, but it is more straightforward with the exponential loss. In order to give a natural “scale” to the problem, we  renormalize the empirical risk by taking minus its logarithm and consider the concave objective $$ F_\beta(a) = -\frac{1}{\beta}\log\Big( \frac1n \sum_{i=1}^n \exp(-\beta y_i \ x_i^\top a) \Big).\tag{5}$$ </p>



<p class="justify-text">Here \(\beta&gt;0\) is a parameter that will be useful in a moment. For now, we take \(\beta=1\) and we note \(F(a)=F_1(a)\).  In this context, the <em>margin</em> of a vector \(a\in \mathbb{R}^d\) is the quantity \(\min_{i} y_i\ x_i^\top a\) which quantifies how far this linear predictor is from making a wrong prediction on the training set.  </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="453" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/max_margin-4.png" class="wp-image-4274" height="386" />The margin of the linear predictor \(x \mapsto a^\top x\) with parameters \(a \in \mathbb{S}^{d-1}\) is the smallest distance of a training point to the decision boundary. We show here the max-margin predictor.</figure></div>



<p class="justify-text">Obtained via simple manipulations, the inequalities  $$ \min_i y_i\ x_i^\top a \leq F_\beta(a) \leq \min_i y_i\ x_i^\top a +\frac{\log(n)}{\beta}, \tag{6}$$ suggest to call \(F_\beta\) the <em>smooth-margin</em> because, well, it is smooth and converges to the margin \(F_\infty(a) := \min_i y_i x_i^\top a\) as \(\beta\to \infty\). Let us look at the gradient flow in the ascent direction that maximizes the smooth-margin: $$ a'(t) = \nabla F(a(t))$$ initialized with \(a(0)=0\) (here the initialization does not matter so much). The path followed by this gradient flow is exactly the same as the gradient flow on the empirical risk: taking the logarithm only changes the time parameterization or, in practice, the step-size.</p>



<p class="justify-text"><strong>Convergence to the max-margin.</strong> Assume that the data set is linearly separable, which means that the \(\ell_2\)-max-margin $$ \gamma := \max_{\Vert a\Vert_2 \leq 1} \min_i y_i x_i^\top a$$ is positive. In this case \(F\) is unbounded (indeed \(\lim_{\alpha \to \infty} F(\alpha a) =\infty\) whenever \(a\)  has a positive margin) and thus \(a(t)\) diverges. This is not an issue as such, since for classification, only the sign of the prediction matters.  This just means that the relevant question is not “where does \(a(t)\) converge?” but rather “towards which direction does it diverge?”. In other words, we are interested in the limit of \(\bar a(t):= a(t)/\Vert a(t)\Vert_2\) (in convex analysis, this is called the <em>cosmic limit</em> of \(a(t)\) [Chap. 3, <a href="https://www.springer.com/gp/book/9783540627722">10</a>], isn’t it beautiful ?).</p>



<p class="justify-text">The argument that follows is adapted from [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>] and can be traced back to [<a href="http://proceedings.mlr.press/v28/telgarsky13-supp.pdf">13</a>] for coordinate ascent. It can be shown by looking at the structure of the gradient (see the end of the blog post) that \(\Vert \nabla F(a)\Vert_2\geq \gamma\) for all \(a\in \mathbb{R}^d\). By the inequality of Eq. (6) and the gradient flow property \(\frac{d}{dt}F(a(t))=\Vert \nabla F(a(t))\Vert_2^2\), it follows $$\begin{aligned}\min_i y_i x_i^\top a(t) \geq F(a(t)) \  – \log(n) \geq \gamma \int_0^t \Vert \nabla F(a(s))\Vert_2ds -\log (n).\end{aligned}$$  For \(t&gt; \log(n)/\gamma^2\), this lower bound is positive. We can then divide the left-hand side by \(\Vert a(t)\Vert_2\) and the right-hand side by the larger quantity \(\int_0^t \Vert\nabla F(a(s))\Vert_2ds\), and we get $$\min_i y_i x_i^\top \bar a(t) \geq \gamma -\frac{\log(n)}{\int_0^t \Vert\nabla F(a(s))\Vert_2ds} \geq \gamma -\frac{\log(n)}{\gamma t}.$$ This shows that the margin of \(\bar a(t) := a(t)/\Vert a(t)\Vert_2\) converges to the \(\ell_2\)-max-margin at a rate \(\log(n)/\gamma t\). That’s it, the implicit bias of this gradient flow is exposed!</p>



<p class="justify-text"><strong>Stability to step-size choice.</strong> To translate this argument to discrete time, we need decreasing step-sizes of order \(1/\sqrt{t}\) which deteriorates the convergence rate to \(\tilde O(1/\sqrt{t})\), see [<a href="https://arxiv.org/pdf/1802.08246.pdf">11</a>, <a href="https://arxiv.org/pdf/1803.07300.pdf">12</a>]. In [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>], we proposed a different proof strategy (based on an online optimization interpretation of \(\bar a(t)\), as below) which recovers the same convergence rate \(O(1/\sqrt{t})\) with <em>exponentially larger</em> step-sizes. This suggests that these diverging trajectories are extremely robust to the choice of step-size.</p>



<p class="justify-text"><strong>Illustration. </strong>In the figure below, we plot on the left the evolution of the parameter \(a(t)\) and on the right the predictor \(x\mapsto (x,1)^\top a(t)\) with \(x\in \mathbb{R}^2\). In parameter space, we apply the hyperbolic tangent to the radial component which allows to easily visualize diverging trajectories. This way, the unit sphere represents the <em>horizon</em> of \(\mathbb{R}^d\), i.e., the set of directions at infinity [Chap. 3 in <a href="https://www.springer.com/gp/book/9783540627722">9</a>]. We will use the same convention in the other plots below.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="586" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/linear.gif" class="wp-image-4106" height="288" />Implicit bias of gradient descent for a linear classification task with the exponential loss: (left) parameter space, (right) predictor space.</figure></div>



<h2>3. Implicit bias:  training only the output layer</h2>



<p class="justify-text">Despite its apparently restrictive setting, the previous result already tells us something about wide neural networks. Consider the situation touched upon earlier where we only train the output weights \(a_j\) and the hidden weights \(b_j\) are picked uniformly at random on the sphere. This corresponds to learning a linear classifier on top of the random feature \([(b_j^\top x)_+]_{j=1}^m\). </p>



<p class="justify-text">As we have just shown, if the training set is separable, the normalized gradient flow of the unregularized exponential loss (or logistic loss) converges to a solution to  $$ \max_{\Vert a\Vert_2 \leq 1}\min_i y_i \sum_{j=1}^m  a_j (b_j^\top x_i)_+.$$ </p>



<p class="justify-text">This is a random feature approximation for the unregularized kernel support vector machine problem in the RKHS \(\mathcal{F}_2\), which is recovered in the large width limit \(m\to \infty\):  $$\max_{\Vert h\Vert_{\mathcal{F}_2}\leq 1} \min_i y_i h(x_i).$$ Notice that if \(m\) is large enough, the linear separability assumption is not even needed anymore, because any training set is separable in \(\mathcal{F}_2\) (at least if all \(x_i\)s are distinct and if we do not forget to include the bias/intercept).</p>



<p class="justify-text"><strong>Illustration.</strong> In the animation below, we plot on the left the evolution of the parameters and on the right the predictor for a 2-D classification task. In parameter space, each particle represents a neuron: their direction is fixed, their distance to \(0\) is their absolute weight and the color is red (+) or blue (-) depending on the sign of the weight. As above, the unit sphere is at infinity and the particles diverge. In predictor space, the markers represent the training samples of both classes, the color shows the predictor and the black line is the decision boundary. The fact that the predictor has a smooth decision boundary is in accordance with the properties of \(\mathcal{F}_2\) given above. </p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://francisbach.com/wp-content/uploads/2020/07/film_output_comp-1.gif" alt="" class="wp-image-4275" />Gradient descent on the output layer of a two-layer relu neural network with the exponential loss: (left) parameter space, (right) predictor space. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_output.jl">[code]</a></figure></div>



<h2>4. Implicit bias: 2-homogeneous linear classifiers</h2>



<p class="justify-text">Although the analyses where neural networks behave like kernel methods are pleasant for us theoreticians because we are in conquered territory, they miss essential aspects of neural networks such as their adaptivity and their ability to learn a representation. Let us see if we can characterize the implicit bias of the gradient flow of the unregularized exponential loss when training <em>both</em> layers of the neural network.</p>



<p class="justify-text"><strong>A 2-homogeneous linear model.</strong> From an optimization point of view, an important property of two layer relu neural networks is that \(\Phi(\alpha w)= \alpha^2 \Phi(w)\) for all \(\alpha&gt;0\), i.e., they are positively 2-homogeneous in the training parameters. In contrast, a linear model is 1-homogeneous in the parameters. This seemingly little difference leads to drastic changes in the gradient flow dynamics. </p>



<p class="justify-text">Let us again build our intuition with a simplified model that captures key aspects of the dynamics, namely the linear classification setting of above. This time, we take any initialization \(r(0)\in \mathbb{R}^d\) with positive entries and the gradient flow in the ascent direction of the function \( F(r\odot r)\) where \(\odot\) is the pointwise product between two vectors and \(F\) is defined in Eq. (5). This is just a trick to obtain a 2-homogeneous parameterization of a linear model. This gradient flow satisfies $$ r'(t) = 2 r(t)\odot \nabla F(r(t)\odot r(t)).$$ </p>



<p class="justify-text"><strong>Normalized dynamics.</strong> Let us define \(\bar a(t):=(r(t)\odot r(t))/\Vert r(t)\Vert_2^2\) the normalized predictor associated to our dynamics which, by definition, belongs to the simplex \(\Delta_d\), i.e., the set of nonnegative vectors in \(\mathbb{R}^d\) that sum to one. Using the fact that \(\nabla F(\beta a) = \nabla F_\beta (a)\) for all \(\beta&gt;0\), we obtain $$\begin{aligned} \bar a'(t) &amp;= 2\frac{r(t)\odot r'(t)}{\Vert r(t)\Vert_2^2} -2 (r(t)^\top r'(t))\frac{r(t)\odot r(t)}{\Vert r(t)\Vert_2^4}\\ &amp;=4\bar a(t) \odot \nabla F_{\Vert r(t)\Vert_2^2}(\bar a(t))\ – \alpha(t) \bar a(t)\end{aligned}$$ where \(\alpha(t)\) is the scalar such that \(\sum_{i=1}^d a’_i(t) =0\). Online optimization experts might have recognized that this is (continuous time) <em>online mirror ascent in the simplex</em> for the sequence of smooth-margin functions \(F_{\Vert r(t)\Vert_2^2}\). Notice in particular the multiplicative updates: they correspond to the entropy mirror function, and they are particularly well suited for optimization in the high dimensional simplex [Chap.4, <a href="https://arxiv.org/pdf/1405.4980.pdf">14</a>].</p>



<p>What do we learn from this reformulation? </p>



<ul class="justify-text"><li>We can prove (by similar means) that if the data set is linearly separable then \(\Vert r(t)\Vert_2^2\) diverges. So the sequence of functions \(F_{\Vert r\Vert_2^2}\) converges to the margin \(F_\infty\) which means that \(\bar a(t)\) just ends up optimizing the function \(F_\infty\). As a consequence, we have $$\lim_{t\to \infty} y_i x_i^\top \bar a(t) = \max_{a\in \Delta_d} \min_{i} y_i x_i^\top a.$$ This exposes another implicit bias of gradient flow. Notice the key difference with the implicit bias obtained with a linear parameterization: we obtain here the \(\ell_1\)-max-margin (over classifiers with non-negative entries) instead of the \(\ell_2\)-max-margin.  </li><li>Beyond exposing the implicit bias, this reformulation shows that \(\bar a(t)\) implicitly optimizes a sequence of smooth objectives which converge to the margin \(F_\infty\). Unknowingly, we have recovered the well-principled optimization method that consists in approximating a non-smooth objective with smooth functions [<a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">15</a>].</li><li>While the conclusion above was only formal, this point of view leads to rigorous proofs of convergence and convergence rates in discrete time in \(\tilde O(1/\sqrt{t})\) with a step-size in \(O(1/\sqrt{t})\), by  exploiting tools from online optimization, see [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>].</li></ul>



<h2>5. Implicit bias: fully trained 2-layer neural networks</h2>



<p class="justify-text">Once again this argument about linear predictors applies to neural networks: if we train both layers but only the magnitude of the hidden weights and not their direction, then this is equivalent to learning a 2-homogeneous linear model on top of the random feature \([  a_j(0) (x_i^\top b_j(0))_+]_{j=1}^m\). If each feature appears twice with opposite signs — which is essentially the case in the large width limit — then the simplex constraint can be equivalently replaced by an \(\ell_1\)-norm constraint on the weights. Recalling the definition of the \(\mathcal{F}_1\)-norm from Eq. (4), we thus obtain that, in the infinite-width limit, the normalized predictor converges to a solution to $$ \max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">This result is correct, but it is not relevant. In contrast to functions in \(\mathcal{F}_2\), functions in \(\mathcal{F}_1\) <em>can not</em> in general be approximated with few <em>random</em> features in high dimension. In fact, lower bounds that are exponential in the dimension exist in certain settings [Sec. X, <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">16</a>]. They can be approximated with a small number of features but those need to be data-dependent: in that sense, it is necessary to learn a representation – here,  a distribution over the hidden weights — in order to learn in \(\mathcal{F}_1\). </p>



<p class="justify-text">This raises the following question: do we obtain the same implicit bias when training both layers of the neural network, without fixing the direction of the input weights? In the following result, which is the main theorem of our paper [<a href="https://arxiv.org/abs/2002.04486">1</a>], we answer by the affirmative.</p>



<p class="justify-text"><strong>Theorem</strong> (C. and Bach [<a href="https://arxiv.org/abs/2002.04486">1</a>], informal). Assume that for some \(\sigma&gt;0\), the hidden weights \(b_j\) are initialized uniformly on the sphere of radius \(\sigma\) and the output weights \(a_j\) are uniform in \(\{-\sigma,\sigma\}\). Let \(\mu_t\) be the Wasserstein gradient flow for the unregularized exponential loss and \(h_t = \int \Phi(w)d\mu_t(w)\) be the corresponding dynamics in predictor space. Under some technical assumptions, the normalized predictor \(h_t/\Vert h_t\Vert_{\mathcal{F}_1}\) converges to a solution to the \(\mathcal{F}_1\)-max-margin problem: $$\max_{\Vert h\Vert_{\mathcal{F}_1} \leq 1} \min_i y_i h(x_i).$$</p>



<p class="justify-text">Giving an idea of proof would be a bit too technical for this blog post, but let us make some remarks:</p>



<ul class="justify-text"><li>The strength of this result is that although this dynamics could get trapped towards limit directions which are not optimal, this choice of initialization allows to avoid them all and to only converge to <em>global</em> minimizers of this max-margin problem. The principle behind this is similar to the global convergence result in the previous blog post. </li><li>The fact that optimizing on the direction of the hidden weights is compatible with the global optimality conditions of the \(\mathcal{F}_1\)-max-margin problem is very specific to the structure of positively 2-homogeneous problems, and should not be taken for granted for other architectures of neural networks.</li><li>Although at a formal level this result works for any initialization that is diverse enough (such as the standard Gaussian initialization), the initialization proposed here yields dynamics with a better behavior for relu networks: by initializing the hidden and output weights with equal norms – a property preserved by the dynamics – we avoid some instabilities in the gradient. Also notice that this result applies to any scale \(\sigma&gt;0\) of the initialization (we’ll see an intriguing consequence of this in the next section).</li></ul>



<p class="justify-text"><strong>Illustration.</strong> In the figure below, we plot the training dynamics when both layers are trained. In parameter space (left), each particle represents a neuron: its position is \(\vert a_j\vert b_j\) and its color depends on the sign of \(a_j\).  Here again the unit sphere is at infinity. The inactive neurons at the bottom correspond to those with a bias that is “too negative” at initialization. We observe that all the other neurons gather into few clusters: this is the sparsifying effect of the \(L^1\)-norm in Eq. (4). In predictor space, we obtain a polygonal classifier, as expected for a \(\mathcal{F}_1\)-max-margin classifier. See the paper [<a href="https://arxiv.org/pdf/2002.04486.pdf">1</a>] for experiments that illustrate the strengths of this classifier in terms of generalization.</p>



<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://francisbach.com/wp-content/uploads/2020/07/film_both_comp.gif" alt="" class="wp-image-4194" />Training both layers of a wide relu neural network with the exponential loss: (left) space of parameters, (right) space of predictors. <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_bothlayers.jl">[code]</a></figure></div>



<h2>6. Lazy regime and the neural tangent kernel</h2>



<p class="justify-text">This blog post would not be complete without mentioning the <em>lazy regime</em>. This is yet another kind of implicit bias which, in our context, takes place when at initialization the weights have a large magnitude and the step-size is small. It was first exhibited in [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] for deep neural networks.</p>



<p class="justify-text"><strong>Lazy training via scaling.</strong> This phenomenon is in fact very general so let us present it with a generic parametric predictor \(h(W)\) with differential \(Dh(W)\). We introduce a scaling factor \(\alpha&gt;0\) and look at the gradient flow of \(F(W) := R(\alpha h(W))\) with a step-size \(1/\alpha^2\), that is $$ W'(t) = \ – \frac{1}{\alpha}Dh(W(t))^\top \nabla R(\alpha h(W(t))),$$ with initialization \(W(0)\). In terms of the predictor \(\alpha h(W)\), this yields the dynamics $$\frac{d}{dt} \alpha h(W(t)) = \ – Dh(W(t))Dh(W(t))^\top \nabla R(\alpha h(W(t)).$$ </p>



<p class="justify-text">Lazy training [<a href="https://arxiv.org/pdf/1812.07956.pdf">18</a>] happens when we take \(\alpha\) large while making sure that \(\alpha h(W(0))\) stays bounded. In this case, we see that the parameters change at a rate \(O(1/\alpha)\), while the predictor changes at a rate independent of \(\alpha\). On any bounded time interval, in the limit of  a large \(\alpha\), the parameters only move infinitesimally, while the predictor still makes significant progress, hence the name <em>lazy training</em>.</p>



<p class="justify-text"><strong>Equivalent linear model.</strong> Since the parameters hardly move, if we assume that \(Dh(W(0))\neq 0\) then we can replace the map \(h\) by its linearization \(W \mapsto h(W(0))+Dh(W(0))(W-W(0))\). This means that the training dynamics essentially follows the gradient flow of the  objective $$ R\big ( \alpha h(W(0)) + \alpha Dh(W(0))(W-W(0)) \big)$$ which is a convex function of \(W\) as soon as \(R\) is convex.</p>



<p class="justify-text">If this objective admits a minimizer that is not too far away from \(W(0)\), then \(W(t)\) converges to this minimizer. If in contrast all  the minimizers are too far away (think of the exponential loss where they are at infinity), then the parameters will eventually move significantly and the lazy regime is just a transient regime in the early phase of training.  Of course, all these behaviors can be quantified and made more precise, because this phenomenon brings us back to the realm of linear models. </p>



<p class="justify-text">What all of this has to do with two-layer neural networks? As it happens, this scale factor appears implicit in various situations for these models; let us detail two of them. </p>



<p class="justify-text"><strong>Neural networks with \(1/\sqrt{m}\) scaling.</strong> For two-layer neural networks, lazy training occurs if we define \(h = \frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j)\) instead of \(h=\frac{1}{m} \sum_{j=1}^m \Phi(w_j)\) before taking the infinite width limit. Indeed:</p>



<ul class="justify-text"><li>This induces a scaling factor \(\alpha = \sqrt{m} \to \infty\) compared to \(1/m\) which, as we have already seen, is the “correct” scaling that leads to a non-degenerate dynamics in parameter space as \(m\) increases. </li><li>Moreover, by the central limit theorem,  \(\frac{1}{\sqrt{m}} \sum_{j=1}^m \Phi(w_j(0)) = O(1)\) for typical random initializations of the parameters. So the initial predictor stays bounded.</li></ul>



<p class="justify-text">To take the Wasserstein gradient flow limit, the step-size has to be of order \(m\) (see previous blog post). So here we should take a step-size of order \(m/\alpha^2 = 1\). With such a step-size, all the conditions for lazy training are gathered when \(m\) is large. Intuitively, each neuron only moves infinitesimally, but they collectively produce a significant movement in predictor space.</p>



<p class="justify-text"><strong>Neural networks with large initialization.</strong> Coming back to our scaling in \(1/m\) and our Wasserstein gradient flow that is obtained in the large width limit, there is another way to enter the lazy regime: by increasing the variance of the initialization. </p>



<p class="justify-text">To see this, assume that \(h\) is a positively \(p\)-homogeneous parametric predictor, which means that \(h(\sigma W)=\sigma^p h(W)\) for all \(\sigma&gt;0\) and some \(p&gt;1\) (remember that this is true with \(p=2\) for our two-layer relu neural network). Take an initialization of the form \(W(0) = \sigma \bar W_0\) where \(\sigma&gt;0\) and \(h(\bar W_0)=0\) (which is also satisfied for our infinite width neural networks with the initialization considered previously). Consider the gradient flow of \(R(h(W))\) with step-size \(\sigma^{2-2p}\).   By defining \(\bar W(t) = W(t)/\sigma\) and using the fact that the differential of a p-homogeneous function <a href="https://en.wikipedia.org/wiki/Homogeneous_function#Positive_homogeneity">is (p-1)-homogeneous</a>, we have, on the one hand $$ \bar W'(t) = -\sigma^{-p} Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))), $$ and on the other hand $$\frac{d}{dt} \sigma^p h(\bar W(t)) =\  – Dh(\bar W(t))Dh(\bar W(t))^\top \nabla R(\sigma^p h(\bar W(t))).$$ So in terms of the dynamics \(\bar W(t)\), the situation is exactly equivalent to having a scaling factor \(\alpha=\sigma^p\). This implies that as the magnitude \(\sigma\) of the initialization increases, we enter the lazy regime, provided the step-size is of order \(\sigma^{2-2p}\).</p>



<p class="justify-text"><strong>Neural tangent kernel. </strong>What does the lazy regime tell us about the learnt predictor for two-layer neural networks? Assuming for simplicity that the predictor at initialization is \(0\), this regime amounts to learning a linear model on top of the feature \([(b_j^\top x)_+]_{j=1}^m\) — the derivative with respect to the output weights — concatenated with the feature \([x a_j 1_{b_j^\top x &gt; 0} ]_{j=1}^m\)  — the derivative with respect to the input weights. Compared to training only the output layer, this thus simply adds some features. </p>



<p class="justify-text">Assume for concreteness, that at initialization the hidden weights \(b_j\) are uniform on a sphere of large radius \(\sigma&gt;0\) and the output weights are uniform on \(\{-\kappa\sigma, \kappa\sigma\}\) where \(\kappa\geq 0\). For a large width and a large \(\sigma\), we enter the lazy regime which amounts to learning in a RKHS — let us call it \(\mathcal{F}_{2,\kappa}\) — that is slightly different from \(\mathcal{F}_2 = \mathcal{F}_{2,0}\), since its kernel \(K_\kappa\) contains another term: $$ K_\kappa(x,x’) = \int_{\mathbb{S}^{d-1}} (\theta^\top x)_+ (\theta^\top x’)_+d\tau(\theta) + \kappa^2 \int_{\mathbb{S}^{d-1}} (x^\top x’) 1_{\theta^\top x &gt; 0}1_{\theta^\top x’ &gt; 0}d\tau(\theta). $$</p>



<p class="justify-text">This kernel is called the Neural Tangent Kernel [<a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">17</a>] and the properties of the associated RKHS have been studied in [<a href="https://arxiv.org/pdf/1904.12191.pdf">19</a>, <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels.pdf">20</a>], where it is shown to include functions that are slightly less smooth than those of \(\mathcal{F}_2\) when \(\kappa\) increases. This is illustrated in the plot below, obtained by training a wide neural network with \(\sigma\) large (to reach the lazy regime) on the square loss, and various values of \(\kappa\).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="574" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/interp-4.png" class="wp-image-4213" height="287" />1-D regression with a wide two-layer relu neural network (gradient descent on square loss, in the lazy regime) with 4 training samples (black dots). At initialization, output weights have \(\kappa\) times the (large) magnitude of the hidden weights. This implicitly solves kernel ridgeless regression for a kernel that depends on \(\kappa\). <a href="https://github.com/lchizat/2020_implicitbias_blog/blob/master/exp_NTK.jl">[code]</a></figure></div>



<p class="justify-text"><strong>Two implicit biases in one shot.</strong> The attentive reader might have noticed that for large initialization scale \(\sigma\gg 1\), when training both layers on the unregularized exponential loss, two of our analyses apply:  lazy training — that leads to a max-margin predictor in \(\mathcal{F}_{2,\kappa}\) — and the asymptotic implicit bias — that leads to a max-margin predictor in \(\mathcal{F}_{1}\).  So, where is the catch? </p>



<p class="justify-text">There is none! Since the minimizers of this loss are at infinity, the lazy regime is just a transient phase and we will observe both implicit biases along the training dynamics! Take a look at the video below: we observe that in early phases of training, the neurons do not move while learning a smooth classifier — this is the lazy regime and the classifier approaches the \(\mathcal{F}_{2,\kappa}\)-max-margin classifier. In later stages of training, the neurons start moving and the predictor converges to a \(\mathcal{F}_1\)-max-margin classifier as stated by the main theorem. The predictor jitters a little bit during training because I have chosen rather aggressive step-sizes.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large"><img src="https://francisbach.com/wp-content/uploads/2020/07/film_lazy2sparse_ns_comp-1.gif" alt="" class="wp-image-4219" />Training both layers with gradient descent for the unregularized exponential loss. The only difference with the previous video is that at initialization the variance \(\sigma^2\) is larger and the step-size smaller \(\approx \sigma^{-2}\). First the network learns a classifier in the lazy regime (a kernel max-margin classifier) and eventually converges to the \(\mathcal{F}_1\)-max-margin classifier.</figure></div>



<h2>Discussion</h2>



<p class="justify-text">In this blog post, I described how analyses of the training dynamics can help us understand the properties of the predictor learnt by neural networks even in the absence of an explicit regularization. Already for the simplest algorithm one can think of — gradient descent — we have found a variety of behaviors depending on the loss, the initialization or the step-size. </p>



<p class="justify-text">To achieve this description, the infinite width limit is of great help. It allows to obtain synthetic and precise characterizations of the learnt predictor, that can be used to derive generalization bounds. Yet, there are many interesting non-asymptotic effects caused by having a finite width.  In that sense, we were only concerned with the end of the curve of double descent [<a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">21</a>].</p>



<h2>References</h2>



<p class="justify-text">[1] Lénaïc Chizat, Francis Bach. <a href="https://arxiv.org/pdf/2002.04486.pdf">Implicit Bias of Gradient Descent for Wide Two-layer Neural Networks Trained with the Logistic Loss.</a> <em>To appear in Conference On Learning Theory</em>, 2020.<br />[2] Francis Bach. <a href="http://jmlr.org/papers/volume18/14-546/14-546.pdf">Breaking the curse of dimensionality with convex neural networks.</a> <em>The Journal of Machine Learning Research</em>, <em>18</em>(1), 629-681, 2017.<br />[3]  Vera Kurková, Marcello Sanguineti. <a href="https://www.cs.cas.cz/~vera/publications/journals/I3Edin.pdf">Bounds on rates of variable-basis and neural-network approximation.</a> <em>IEEE Transactions on Information Theory</em>, 47(6):2659-2665, 2001.  <br />[4] Behnam Neyshabur, Ryota Tomioka, Nathan Srebro. <a href="https://arxiv.org/pdf/1412.6614.pdf">In Search of the Real Inductive Bias: On the Role of Implicit Regularization in Deep Learning.</a> <em>ICLR (Workshop)</em>. 2015.<br />[5] Youngmin Cho, Lawrence K. SAUL.  <a href="https://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf">Kernel methods for deep learning.</a> <em>Advances in neural information processing systems</em>. 342-350, 2009.<br />[6] Radford M. Neal. <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf"><em>Bayesian learning for neural networks</em>.</a> Springer Science &amp; Business Media, 2012.<br />[7] Ali Rahimi, Benjamin Recht. <a href="https://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf">Random features for large-scale kernel machines.</a> <em>Advances in neural information processing systems</em>. 1177-1184, 2008.<br />[8] Kevin P. Murphy. Machine Learning: A Probabilistic Perspective. <em>The MIT Press</em>, 2012<br />[9] Daniel Soudry, Elad Hoffer, Mor Shpigel Nacson, Suriya Gunasekar, Nathan Srebro. <a href="http://www.jmlr.org/papers/volume19/18-188/18-188.pdf">The Implicit Bias of Gradient Descent on Separable Data.</a><em> The Journal of Machine Learning Research</em>, <em>19</em>(1), 2822-2878, 2018.<br />[10] R. Tyrrell Rockafellar, Roger J-B. Wets. <a href="https://www.springer.com/gp/book/9783540627722"><em>Variational analysis</em>.</a> Springer Science &amp; Business Media, 2009.<br />[11] Suriya Gunasekar,  Jason D. Lee, Daniel Soudry, Nathan Srebro.  <a href="https://par.nsf.gov/servlets/purl/10107856">Characterizing implicit bias in terms of optimization geometry.</a> <em>International Conference on Machine Learning</em>, 2018.<br />[12] Ziwei Ji, Matus Telgarsky. <a href="https://arxiv.org/pdf/1803.07300.pdf">Risk and parameter convergence of logistic regression.</a> 2018.<br />[13] Matus Telgarsky. <a href="https://arxiv.org/abs/1303.4172">Margins, Shrinkage, and Boosting.</a> <em>International Conference on Machine Learning</em>, 307-315, 2013.<br />[14] Sébastien Bubeck. <a href="https://arxiv.org/pdf/1405.4980.pdf">Convex Optimization: Algorithms and Complexity.</a> Foundations and Trends in Machine Learning, 8(3-4):231-357, 2015.<br />[15] Yuri Nesterov. <a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">Smooth minimization of non-smooth functions.</a> <em>Mathematical programming</em>, 103(1):127-152, 2005.<br />[16] Anrew R. Barron. <a href="http://www.stat.yale.edu/~arb4/publications_files/UniversalApproximationBoundsForSuperpositionsOfASigmoidalFunction.pdf">Universal approximation bounds for superpositions of a sigmoidal function.</a> <em>IEEE Transactions on Information theory. </em>39(3), 930-945, 1993.<br />[17] Jacot, Arthur, Franck Gabriel, Clément Hongler. <a href="https://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf">Neural tangent kernel: Convergence and generalization in neural networks.</a> <em>Advances in neural information processing systems.</em> 8571-8580, 2018.<br />[18] Lénaïc Chizat, Édouard Oyallon, Francis Bach. <a href="https://papers.nips.cc/paper/8559-on-lazy-training-in-differentiable-programming.pdf">On lazy training in differentiable programming.</a> <em>Advances in Neural Information Processing Systems.</em> 2937-2947, 2019.<br />[19] Behrooz Ghorbani, Song Mei, Theodor Misiakiewicz, Andrea Montanari. <a href="https://arxiv.org/pdf/1904.12191.pdf">Linearized two-layers neural networks in high dimension.</a> To appear in <em>Annals of Statistics</em>. 2019.<br />[20] Alberto Bietti, Julien Mairal. <a href="http://papers.nips.cc/paper/9449-on-the-inductive-bias-of-neural-tangent-kernels">On the Inductive Bias of Neural Tangent Kernels</a>. <em>Advances in Neural Information Processing Systems.</em> p. 12893-12904, 2019.<br />[21] Mikhail Belkin, Daniel Hsu, Siyuan Ma, Soumik Mandal. <a href="https://www.pnas.org/content/pnas/116/32/15849.full.pdf">Reconciling modern machine-learning practice and the classical bias–variance trade-off.</a> <em>Proceedings of the National Academy of Sciences.</em> <em>116</em>(32), 15849-15854, 2019.</p>



<h3>Lower bound on the gradient norm for linear classification with the exponential loss</h3>



<p class="justify-text">In the context of Section 2, we want to prove that \(\Vert \nabla F(a)\Vert_2\geq \gamma\). For this, let \(Z\in \mathbb{R}^{n\times d}\) be the matrix with rows \(y_i x_i\) and let \(\Delta_n\) be the simplex in \(\mathbb{R}^n\). We have by duality $$ \gamma = \max_{\Vert a\Vert_2\leq 1}\min_{p\in \Delta_n} p^\top Z a =   \min_{p\in \Delta_n} \max_{\Vert a\Vert_2\leq 1} a^\top Z^\top p = \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 .$$  Also, notice that \(\nabla F(a) = Z^\top p\) with \(p_i = \frac{e^{-y_ix_i^\top a}}{\sum_{j=1}^n e^{-y_{j}x_{j}^\top a}}\). Since \(p \in \Delta_n\), we conclude that \(\Vert \nabla F(a)\Vert_2\geq \min_{p\in \Delta_n} \Vert Z^\top p\Vert_2 = \gamma\).</p></div>







<p class="date">
by Lénaïc Chizat <a href="https://francisbach.com/gradient-descent-for-wide-two-layer-neural-networks-implicit-bias/"><span class="datestr">at July 13, 2020 07:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7770">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/07/13/simons-institute-lectures-on-analysis-of-boolean-functions/">Simons institute lectures on analysis of Boolean functions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>(Does it still make sense to blog such announcements or is these days <a href="https://twitter.com/boazbaraktcs/status/1282443765224017920">Twitter</a> the only way to go about this? Asking for a friend <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /> )</em></p>



<p>Prasad Raghavendra and Avishay Tal have organized a sequence of 6 lectures on some of the exciting recent advances in analysis of Boolean functions. </p>



<p><a href="https://simons.berkeley.edu/events/boolean" target="_blank" rel="noreferrer noopener">Lecture Series: Advances in Boolean Function Analysis</a><br /></p>



<p>The Simons Institute is organizing a series of lectures on Advances in Boolean Function Analysis, that will highlight a few major developments in the area. The series will feature weekly two-hour lectures from July 15th to Aug 18th.  The lectures aim to address both the broad context of the results and their technical details. Though closely related in theme, each lecture will be self-contained.  The schedule is attached below (more info at <a href="https://simons.berkeley.edu/events/boolean" target="_blank" rel="noreferrer noopener">link</a>). </p>



<p>Talks take place on Wednesdays at 10am Pacific time (1pm Eastern). If you can’t catch them live, they will be redcorded.</p>



<p><strong>Zoom Link: </strong><a href="https://berkeley.zoom.us/j/93086371156" target="_blank" rel="noreferrer noopener">https://berkeley.zoom.us/j/93086371156</a><br /></p>



<p><strong><u>Talk Schedule:</u></strong></p>



<p>July 15, Wednesday  10:00am PDT (1pm EDT) <em>Dor Minzer (Institute of Advanced Study)<a href="https://simons.berkeley.edu/events/boolean-1" target="_blank" rel="noreferrer noopener">On the Fourier-Entropy Influence Conjecture</a></em></p>



<p><br />July 22, Wednesday, 10:00am PDT (1pm EDT) <em>Hao Huang (Emory University) &amp; Avishay Tal (UC Berkeley)<a href="https://simons.berkeley.edu/events/boolean-3" target="_blank" rel="noreferrer noopener">Sensitivity Conjecture and Its Applications</a></em></p>



<p><br />August 3rd, Monday, 10:00am PDT (1pm EDT)<em>  Shachar Lovett (UC San Diego)<a href="https://simons.berkeley.edu/events/boolean-2" target="_blank" rel="noreferrer noopener">Improved Bounds for the Sunflower Lemma</a></em></p>



<p><br />August 5, Wednesday, 10:00am PDT (1pm EDT) <em>Ronen Eldan (Weizmann Institute)</em><a href="https://simons.berkeley.edu/events/boolean-4" target="_blank" rel="noreferrer noopener"><em>Concentration on the Boolean Hypercube via Pathwise Stochastic Analysis</em></a></p>



<p><br />August 12, Wednesday, 10:00am <em>Esty Kelman (Tel Aviv University) <a href="https://simons.berkeley.edu/events/boolean-5" target="_blank" rel="noreferrer noopener">KKL via Random Restrictions</a></em></p>



<p><br />August 18, Tuesday, 10:00am <em>Pooya Hatami (Ohio State University)<a href="https://simons.berkeley.edu/events/boolean-6" target="_blank" rel="noreferrer noopener">Pseudorandom Generators from Polarizing Random Walks</a></em></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/07/13/simons-institute-lectures-on-analysis-of-boolean-functions/"><span class="datestr">at July 13, 2020 04:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3507">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2020/07/13/adfocs-2020-market-design-and-computational-fair-division/">ADFOCS 2020 (Market Design and Computational Fair Division)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Via Pieter Kleer:</p>
<hr />
<p>21st Max Planck Summer School:<br />
Advanced Course on the Foundations of Computer Science (ADFOCS 2020)</p>
<p>August 24 – 28, 2020</p>
<p>Saarbruecken, Germany</p>
<p>THIS IS A VIRTUAL EVENT<a href="http://www.mpi-inf.mpg.de/conference/adfocs" target="_blank" rel="noopener noreferrer"></a></p><a href="http://www.mpi-inf.mpg.de/conference/adfocs" target="_blank" rel="noopener noreferrer">
</a><p><a href="http://www.mpi-inf.mpg.de/conference/adfocs" target="_blank" rel="noopener noreferrer">http://www.mpi-inf.mpg.de/conference/adfocs</a><br />
—————————————————————————————————</p>
<p><b>About ADFOCS</b><br />
ADFOCS is an international summer school that has been held annually for the last twenty years at the Max Planck Institute for Informatics (MPII) in Saarbruecken, Germany. It is organized as part of the activities of the MPII, in particular the International Max Planck Research School (IMPRS), MPII’s graduate program. The purpose of this summer school is to introduce young researchers to topics which are the focus of current research in theoretical computer science. We bring together leading researchers in the field and international participants at the graduate level and above. This year’s focus is on:</p>
<p><b>*** Market Design and Computational Fair Division ***</b><br />
<b>Program</b><br />
Our invited speakers give five 60-min lectures with subsequent exercise and discussion sessions. These sessions will take place daily from 14:30 to 18:30 UTC+2 (CEST) in the week of August 24-28. On some days there will be a social event after the regular schedule. This year’s speakers are:</p>
<p>* Nicole Immorlica, Microsoft Research Lab, New York City, USA<br />
* Jugal Garg and Ruta Mehta, University of Illinois at Urbana-Champaign, USA<br />
<b>Registration</b><br />
This year registration is free as the event takes place virtually. Nevertheless, registration is MANDATORY and can be done through the website (at the latest August 10)</p>
<p><b>Contact</b><br />
The homepage of ADFOCS, including forms for registration, can be found at <a href="http://www.mpi-inf.mpg.de/conference/adfocs" target="_blank" rel="noopener noreferrer">http://www.mpi-inf.mpg.de/conference/adfocs</a></p>
<p>If you have further questions, please do not hesitate to contact the ADFOCS team by sending an email to <a href="mailto:adfocs@mpi-inf.mpg.de" target="_blank" rel="noopener">adfocs@mpi-inf.mpg.de</a></p>
<p>Organizers: Cosmina Croitoru, Sandor Kisfaludi-Bak and Pieter Kleer</p></div>







<p class="date">
by timroughgarden <a href="https://agtb.wordpress.com/2020/07/13/adfocs-2020-market-design-and-computational-fair-division/"><span class="datestr">at July 13, 2020 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-127536327837647663">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/07/ronald-graham-summary-of-blog-posts-we.html">Ronald Graham: A summary of blog Posts We had about his work</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
To Honor Ronald Graham I summarize the blog posts we had about his work.<br />
<br />
1) Blog post <a href="https://blog.computationalcomplexity.org/2016/05/new-ramsey-result-that-will-be-hard-to.html">New Ramsey Result that will be hard to verify but Ronald Graham thinks its right which is good enough for me</a>.<br />
<br />
Wikipedia (see <a href="https://en.wikipedia.org/wiki/Boolean_Pythagorean_triples_problem">here</a>) says that in the early 1980's (can't Wikipedia be more precise than that?) Ronald Graham conjectured the following:<br />
<br />
For all 2-colorings of N, there exists x,y,z all the same color such that (x,y,z) form a Pythagorean triple.<br />
<br />
I cannot imagine he did not also conjecture this to be true for all finite colorings.<br />
<br />
I suspect that when he conjectured it, the outcomes thought to be likely were:<br />
<br />
a) A purely combinatorial (my spell check says that combinatorial  is not a word. Really? It gets 14,000,000 hits) proof. Perhaps a difficult one. (I think Szemeredi's proof of his density theorem is a rather difficult but purely combinatorial proof).<br />
<br />
b) A proof that uses advanced mathematics, like Roth's proof of the k=3 case of Sz-density, or Furstenberg's proof of Sz theorem.<br />
<br />
c) The question stays open though with some progress over the years, like R(5).<br />
<br />
What actually happened was<br />
<br />
d) A SAT Solver solves it AND gets exact bounds:<br />
<br />
For all 2-colorings of {1,...,7285} there is a mono Pythag triple.<br />
<br />
There exists a 2-coloring of {1,...,7284} with no mono Pythag triple.<br />
<br />
I wonder if this would have been guessed as the outcome back in the early 1980's.<br />
<br />
-------------------------------------------------------------------------------<br />
2) Blog Post <a href="https://blog.computationalcomplexity.org/2019/05/ronald-grahams-other-large-number-well.html">Ronald Graham's Other Large Number- well it was large in 1964 anyway</a><br />
<br />
Let<br />
<br />
a(n) = a(n-1) + a(n-2)<br />
<br />
I have not given a(0) and a(1). Does there exists rel prime values of a(0) and a(1) such that for all n, a(n) is composite.<br />
<br />
In 1964 Ronald Graham showed yes, though the numbers he found (with the help of 1964-style computing) were<br />
<br />
a(0) = 1786772701928802632268715130455793<br />
<br />
a(1) = 2059683225053915111058164141686995<br />
<br />
I suspect it is open to get smaller numbers, though I do not know.<br />
<br />
<br />
------------------------------------------------------------------------------<br />
3) Blog Post <a href="https://blog.computationalcomplexity.org/2011/12/solution-to-reciprocals-problem.html">Solution to the reciprocals problem</a><br />
<br />
Prove or disprove that there exists 10 natural numbers a,...,j such that<br />
<br />
2011= a+ ... + j<br />
1 = 1/a + ... + 1/j<br />
<br />
I had pondered putting this on a HS math competition in 2011; however, the committee thought it was too hard. I blogged on the problem asking for solutions, seeing if there was one that a HS student could have gotten. The following post (this one) gave those solutions. My conclusion is that it could have been put on the competition, but its a close call.<br />
<br />
All of the answers submitted had some number repeated.<br />
<br />
So I wondered if there was a way to do this with distinct a,...,j.<br />
<br />
 I was told about Ronald Grahams result:<br />
<br />
For all n at least 78, n can be written as the sum of DISTINCT naturals, where the sum of<br />
the reciprocals is 1.<br />
<br />
This is tight: 77 cannot be so written.<br />
<br />
Comment on that blog DID include solutions  to my original problem with all distinct numbers<br />
<br />
----------------------------------------------------------------------<br />
4) Blog Post <a href="https://blog.computationalcomplexity.org/2013/04/a-nice-case-of-interdisciplinary.html">A nice case of interdisplanary research</a> tells the story of how the study of history lead to R(5) being determined (see <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/ramseykings.pdf">here</a> for the actual paper on the subject). One of the main players in the story is the mathematician<br />
<br />
Alma Grand-Rho.<br />
<br />
Note that this is an anagram of<br />
<br />
Ronald Graham.<br />
<br />
What is the probability that two mathematicians have names that are anagrams. I suspect very small. However, see <a href="https://blog.computationalcomplexity.org/2013/04/post-mortem-on-april-fools-day-joke.html">this</a> blog post to see why the probability is not as small as it might be.<br />
<br />
-----------------------------------------------------------------------<br />
5) Blog Post <a href="https://blog.computationalcomplexity.org/search?q=Meme">Winner of Ramsey Meme Contest</a> This post didn't mention Ronald Graham; however I think he would have liked it.<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/07/ronald-graham-summary-of-blog-posts-we.html"><span class="datestr">at July 12, 2020 08:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/07/12/graham-pollak-partitions">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/07/12/graham-pollak-partitions.html">Graham–Pollak partitions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>As you’ve probably already seen, Ron Graham recently died. I first met him many years ago at Xerox PARC; what I remember from that meeting is this old guy easily beating me at ping-pong, and I was startled to learn (while working to beef up <a href="https://en.wikipedia.org/wiki/Ronald_Graham">his Wikipedia article</a> after his death) that that was exactly Graham’s first impression of Paul Erdős. We’ve chatted about research, most recently in <a href="https://www.ics.uci.edu/~eppstein/pix/bellairs18/index.html">2018 in Barbados</a>, but somehow never published anything together; on the other hand, Graham’s work in computational geometry, Ramsey theory, and approximation algorithms has certainly had a strong influence on me. Anyway, as part of the project of improving his Wikipedia article, I put together a separate new article on <a href="https://en.wikipedia.org/wiki/Graham%E2%80%93Pollak_theorem">the Graham–Pollak theorem</a>, the theorem that partitioning the edges of an -vertex complete graph into complete bipartite subgraphs requires at least  subgraphs. And while doing that, I started to wonder about what the optimal partitions look like, and how many there are.</p>

<p>In <em>Proofs from THE BOOK</em>, Aigner and Ziegler describe a simple construction for an -subgraph partition: just order the vertices of the complete graph, and make a star connecting each vertex (except the last) to its later neighbors.
But there are a lot more partitions than that. For instance, you can take any rooted binary tree whose leaves are the vertices of the complete graph, and form a partition in which each complete bipartite subgraph connects the left and right descendants of one of the interior nodes of the tree. The ordered star partition is the special case of this where each internal node has one leaf child.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/graham-pollak-hierarchy.svg" alt="Graham–Pollak partitions from binary trees" /></p>

<p>Even these are not the only possibilities. For instance, a four-vertex complete graph can be partitioned into  subgraphs in this triskelion pattern:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/graham-pollak-triskelion.svg" alt="Graham–Pollak partitions from binary trees" /></p>

<p>More generally, whenever one has a partition of , one can form a partition of a larger complete graph by partitioning its vertices into  subsets, applying the partition of  to the edges that go from one subset to another, and then recursively partitioning the edges within each subset. This is already enough to show that there is a rapidly growing number of these partitions, but not enough to count them more precisely.</p>

<p>This still leaves many questions. How many Graham–Pollak partitions does  have, as a function of ? How complicated can they be? If we define a state space whose states are Graham–Pollak partitions, and whose state transitions correspond to re-partitioning the subgraph formed by two of the complete bipartite graphs, is it connected? Can a graph traversal of this state space list all the Graham–Pollak partitions faster than a brute force search? What does a random partition look like?</p>

<p>It’s too bad Ron’s no longer around to help answer some of them.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104503441875881282">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/07/12/graham-pollak-partitions.html"><span class="datestr">at July 12, 2020 03:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
