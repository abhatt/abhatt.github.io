<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="http://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at August 11, 2021 06:22 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/08/10/relandscaping">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/08/10/relandscaping.html">Relandscaping</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>We recently redid our front yard, after spending too long with a boring flat weedy mostly-unused and water-thirsty lawn and after our neighbor took out the only part of it that we actually cared for, a liquidambar tree between our yards. This week’s WADS/CCCG conference, with its four-hour time difference from Pacific, gave me an excuse to catch it in the early morning light:</p>

<p style="text-align: center;"><img src="https://www.ics.uci.edu/~eppstein/pix/frontyard/frontyard-m.jpg" style="border-style: solid; border-color: black;" alt="My house with its old front lawn" /></p>

<p>I don’t have a photo of the old front, so for comparison here’s a similar angle snagged from Google Street View.</p>

<p style="text-align: center;"><img width="80%" style="border-style: solid; border-color: black;" alt="My house with its old front lawn" src="https://www.ics.uci.edu/~eppstein/pix/frontyard/lawn.jpg" /></p>

<p>More for my own later benefit than because I imagine anyone else cares:</p>

<p>The frontmost tree is a <a href="https://en.wikipedia.org/wiki/Parkinsonia_florida">palo verde</a>; a neighbor across the street has a much bigger one, a little messy but quite pretty, especially when covered with its yellow flowers. The tree in the back corner with the blue bistro table under it is some kind of mesquite, I think maybe a black mesquite; the flagstone path makes a loop around it. The two tallest bushes, forming a quadrilateral with the two trees, are <a href="https://en.wikipedia.org/wiki/Feijoa_sellowiana">pineapple guavas / feijoas</a>.</p>

<p>Behind the palo verde and against the house are some <a href="https://en.wikipedia.org/wiki/Kangaroo_paw">kangaroo paws</a>. The closest medium-sized bush on the bottom right (and elsewhere) is <a href="https://en.wikipedia.org/wiki/Salvia_yangii">Russian sage</a>. There are also some <a href="https://en.wikipedia.org/wiki/Buddleja_davidii">butterfly bushes</a>, and several other low bushes and flowers whose names I already lost track of or didn’t get. I think the tall bunchgrass may be a <a href="https://en.wikipedia.org/wiki/Lomandra">lomandra</a>, and the low blue ones <a href="https://en.wikipedia.org/wiki/Festuca_glauca">blue fescue</a>.</p>

<p>Lining the path to the door is <a href="https://en.wikipedia.org/wiki/Curio_repens">senecio / blue chalksticks</a>, and there’s more of it around the base of the mesquite. The groundcover in front is <a href="https://en.wikipedia.org/wiki/Dymondia">dymondia / silver carpet</a> (well, and some crabgrass and spurge, but let’s not count that), with some <a href="https://11011110.github.io/blog/2021/08/10/Myoporum parvifolium">myoporum parvifolium</a> behind it (the low spreading groundcover with white flowers); there’s more myoporum barely visible near the porch bench.</p>

<p>The neighbor ended up replacing the liquidambar (at the far left of the Street View shot) with a <a href="https://11011110.github.io/blog/2021/08/10/Podocarpus henkelii">podocarpus henkelii</a> and some bottlebrushes.</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/08/10/relandscaping.html"><span class="datestr">at August 10, 2021 09:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19041">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/08/10/p-vs-np-proof-claims/">P vs NP Proof Claims</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><font color="#0044cc"><br />
Ken Ribet once was sent a freebie book that he looked at and decided he didn’t want, so took it to a second hand bookstore on his lunch break, sold it, and bought lunch with the proceeds. On the way back to the math department he realized he’d turned theorems into coffee.<br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p></p><p>
</p><p></p>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/08/10/p-vs-np-proof-claims/dijkgraafias/" rel="attachment wp-att-19043"><img width="120" alt="" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/08/DijkgraafIAS.jpg?resize=120%2C144&amp;ssl=1" class="alignright size-full wp-image-19043" height="144" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">IAS <a href="https://www.ias.edu/scholars/dijkgraaf">page</a></font></td>
</tr>
</tbody>
</table>
<p>
Robbert Dijkgraaf is a mathematical physicist and the current Director of the Institute for Advanced Study in Princeton. He is also a down-to-earth communicator of mathematics and a <a href="https://www.ias.edu/news/dijkgraaf-blackhole-mural">spacy</a> surrealist artist. He wrote a guest <a href="https://www.quantamagazine.org/the-subtle-art-of-the-mathematical-conjecture-20190507/">column</a> for <em>Quanta</em> two years ago titled, “The Subtle Art of the Mathematical Conjecture.”</p>
<p>
Today I talk again about what I feel is a meta-error in all the claims to resolve our favorite conjecture, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P &lt; NP}}" class="latex" />. Or <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P = NP}}" class="latex" /> if you are so inclined.</p>
<p>
I have an issue with them that goes beyond well-noted <a href="https://www.scottaaronson.com/blog/?p=458">advice</a> by Scott Aaronson on how to tell claimed proofs of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P &lt; NP}}" class="latex" /> are wrong. It is not about whether they are incorrect. They all are incorrect. And I believe that they will continue to be so into the future.</p>
<p>
My problem with these claims is: they are always all or nothing. </p>
<p>
The claims never improve what we know about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P}}" class="latex" /> versus <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" />. They always resolve the entire question. There is no partial result, no improvement of what we know. They always solve the conjecture and are ready to get the $1,000,000 dollars. Of course the prize money is not in any jeopardy. </p>
<p>
</p><p></p><h2> Climbing a Mountain </h2><p></p>
<p></p><p>
This is where Dijkgraaf’s article comes in. He talks first about mountain climbing (as we have <a href="https://rjlipton.wpcomstaging.com/2010/02/02/climbing-mountains-and-proving-theorems/">also</a> <a href="https://rjlipton.wpcomstaging.com/2012/12/08/mounting-or-solving-open-problems/">done</a>) rather than art:</p>
<blockquote><p><b> </b> <em> Mountain climbing is a beloved metaphor for mathematical research. … [T]he role of these highest peaks is played by the great conjectures—sharply formulated statements that are most likely true but for which no conclusive proof has yet been found.</em></p><em>
</em><p><em>
The highest summits are not conquered in a single effort. Climbing expeditions carefully lay out base camps and fixed ropes, then slowly work their way to the peak. Similarly, in mathematics one often needs to erect elaborate structures to attack a major problem. A direct assault is seen as foolish and naive. These auxiliary mathematical constructions can sometimes take centuries to build and in the end often prove to be more valuable than the conquered theorem itself. The scaffold then becomes a permanent addition to the architecture of mathematics. </em>
</p></blockquote>
<p></p><p>
What strikes me and Ken about the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P}}" class="latex" /> versus <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" /> claims we see so often is that they try to reach the summit in one bound. There is no scaffolding, no rope, no new handhold. The reader learns little.</p>
<p>
The term that most needs expounding is <em>base camp</em>. A base camp is not at the bottom. The main <a href="https://en.wikipedia.org/wiki/Everest_base_camps">base camps</a> for Mount Everest are halfway up to the summit. Getting to a base camp takes substantial work by itself. <em>Building</em> a base camp certainly does. But getting to one is essential. This is what is missing for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P}}" class="latex" /> versus <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" />.</p>
<p>
</p><p></p><h2> P&lt;NP Base Camps </h2><p></p>
<p></p><p>
Let’s look at <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P &lt; NP}}" class="latex" />. Suppose you claim that you can show that CLIQUE requires super polynomial time. This is what you need to do to prove <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P &lt; NP}}" class="latex" />. This is way beyond anything we can imagine proving. </p>
<p>
Suppose rather you claimed that CLIQUE requires <img src="https://s0.wp.com/latex.php?latex=%7Bm%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{m^2}" class="latex" /> deterministic time where <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{m}" class="latex" /> is the number of edges. This would be the best result ever on the difficulty of CLIQUE. It would easily be the best paper in complexity theory in decades. Would win prizes of all kinds. </p>
<p>
It is even worse. If one could prove that CLIQUE is not in deterministic time 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m%5Clog%5Clog%5Clog+m+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  m\log\log\log m " class="latex" /></p>
<p>that would also be a major result. Forget about proving a lower bound of 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m%5E%7B1000%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  m^{1000} " class="latex" /></p>
<p>and more that is needed to solve <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P &lt; NP}}" class="latex" />. Just the above would be major.</p>
<p>
If we skirt around some technical issues with time on Turing machines, we can pitch our camp right at going beyond linear time. Or certainly linear size circuits. Nobody knows a language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" /> that does not have linear size circuits. Proving one would bring enough renown for anyone.</p>
<p>
</p><p></p><h2> P=NP Base Camps </h2><p></p>
<p></p><p>
Let’s look at <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P = NP}}" class="latex" />. Most regard this as the far side of the mountain but please bear with us to the end. Suppose you claim that CLIQUE is in polynomial time. </p>
<p>
The usual paper of this type claims it is doable by some straightforward polynomial time algorithm. The method might use linear programming in some standard manner. This might lead to a <em>practical</em> algorithm, but none of those has ever been observed in the wild. Even worse, any proof that CLIQUE can be resolved in time 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n%5E%7BC%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  n^{C} " class="latex" /></p>
<p>would be also the best result ever on this problem. This applies even if <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{C}" class="latex" /> is an unknown constant, or is equal to some astronomically large value. Think <a href="https://en.wikipedia.org/wiki/Graham%27s_number">Graham’s number</a> or the <a href="https://en.wikipedia.org/wiki/Skewes%27s_number">Skewes</a> number: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+10%5E%7B10%5E%7B10%5E%7B502%7D%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle 10^{10^{10^{502}}} " class="latex" /></p>
<p>Nor do we need <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{C}" class="latex" /> to be constant. Say it is <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{O(\log n)}" class="latex" /> or some polynomial in <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\log n}" class="latex" />. This would be a <em>quasi-polynomial</em> time algorithm. Here a really big campsite was built by László Babai, who <a href="https://www.quantamagazine.org/graph-isomorphism-vanquished-again-20170114/">proved</a> that Graph Isomorphism is in quasi-polynomial time. His <a href="http://people.cs.uchicago.edu/~laci/17groups/version2.1.pdf">paper</a> has a wealth of ideas that might be extended.</p>
<p>
But what really might be attractive about this side is that you can make progress without “shaking the Earth.” These results would be in the direction of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3D+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P = NP}}" class="latex" /> but not opposed by as many factors:</p>
<ul>
<li>
<em>Refute the Strong Exponential Time Hypothesis</em> (SETH). That is, find an algorithm in time <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7BO%28cn%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2^{O(cn)}}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c &lt; 1}" class="latex" /> for CNF-SAT. We have written about SETH <a href="https://rjlipton.wpcomstaging.com/2015/06/01/puzzling-evidence/">here</a>. <p></p>
</li><li>
<em>Refute the Unique Games Conjecture</em> (UGC). Unlike SETH, this technically does not imply <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P &lt; NP}.}" class="latex" /> But refuting it does reduce the reach of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" />-hardness. A large special case of UGC was, however, <a href="https://ieeexplore.ieee.org/document/8555140">proved</a> three years ago.
</li></ul>
<p>
Or prove that they cannot both be true simultaneously. My old <a href="https://rjlipton.wpcomstaging.com/2010/05/05/unique-games-a-three-act-play/">post</a> on UGC covered a sense in which there is no “SETH for UGC.” </p>
<p>
</p><p></p><h2> But … </h2><p></p>
<p></p><p>
The trouble with our insight is that in the past, sometimes a full conjecture has been solved. That is, partial progress did not happen first—the mountain was scaled in one go. Or at least a lot of it, from a relatively low base camp. For <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{P &lt; NP}}" class="latex" /> there is an essence of “polynomial” versus “exponential” that is sharply defined in other ways, for instance Mikhail Gromov’s theorem about growth rates in groups, which we wrote about <a href="https://rjlipton.wpcomstaging.com/2013/06/20/three-theorems-about-growth/">here</a>.</p>
<p>
Ken and I have differed on how long and steep and sudden the final ascent was for the <a href="https://en.wikipedia.org/wiki/Four_color_theorem">Four Color Theorem</a> and <a href="https://en.wikipedia.org/wiki/Fermat%27s_Last_Theorem">Fermat’s Last Theorem</a> (FLT). The proof of the former by Kenneth Appel and Wolfgang Haken was a watershed for its use of computers, but drew on ideas that had gone through the non-computer proofs-and-refutations process. Andrew Wiles’s announcement of FLT was a shock even with a three-day buildup of his lectures at a conference in 1993 having hinted it to several attendees. But he drew on partial progress that had been ramped up by Ribet and others since the mid-1980s.</p>
<p>
Maybe if Évariste Galois had beaten Niels Abel to showing the unsolvability of the quintic, his invention of group theory for the proof used today would have been a single bound. But Abel got a big lift from Paolo Ruffini’s 500 pages of work in 1799. (Évariste is the same name as <a href="https://appellationmountain.net/baby-name-of-the-day-everest/">Everest</a>, go figure.)</p>
<p>
The proof of the Boolean Sensitivity Conjecture two years ago by Hao Huang was short and sudden. But along lines remarked also in Dijkgraaf’s article, perhaps it was “more of a foothill.” Or maybe a base camp for harder problems, such as improving the upper bound from quartic to cubic or quadratic, as we discussed <a href="https://rjlipton.wpcomstaging.com/2019/07/12/tools-and-sensitivity/">here</a> and <a href="https://rjlipton.wpcomstaging.com/2019/07/25/discrepancy-games-and-sensitivity/">here</a>.</p>
<p>
This leads Ken into a historical daydream, taking over from here.</p>
<p>
</p><p></p><h2> A Fermat Fantasy </h2><p></p>
<p></p><p>
Pierre de Fermat famously <a href="https://www.maths-et-tiques.fr/index.php/detentes/la-conjecture-de-fermat">wrote</a> the following in French in the margin of his copy of the famous book on arithmetic by Diophantus:</p>
<blockquote><p><b> </b> <em> Un cube n’est jamais la somme de deux cubes, une puissance quatrième n’est jamais la somme de deux puissances quatriémes et plus généralement aucune puissance supérieure à 2 n’est la somme de deux puissances analogues. J’ai trouvé une merveilleuse démonstration de cette proposition, mais la marge est trop étroite pour la contenir. </em>
</p></blockquote>
<p></p><p>
I (Ken) think he could just as easily have written the following—and in place of the margin being too narrow, he could have given a more reasonable excuse, one I know all too well:</p>
<blockquote><p><b> </b> <em> Un cube n’est jamais la somme de moins que trois cubes, une puissance quatrième n’est jamais la somme de moins que quatre puissances quatriémes, et plus généralement aucune puissance n’est la somme de un moindre nombre de puissances analogues. J’ai trouvé une merveilleuse démonstration de cette proposition, que je rédigerai après avoir traité onze nouveaux cas de triche aux échecs en ligne. </em>
</p></blockquote>
<p></p><p>
The stronger statement here is that no cube can be a nontrivial sum of fewer than three cubes (such as <img src="https://s0.wp.com/latex.php?latex=%7B6%5E3+%3D+3%5E3+%2B+4%5E3+%2B+5%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{6^3 = 3^3 + 4^3 + 5^3}" class="latex" />), no fourth power a sum of fewer than four other like powers, and so on. This also was a hallowed conjecture that stood for centuries, <a href="https://en.wikipedia.org/wiki/Euler's_sum_of_powers_conjecture">named for</a> the giant Leonhard Euler no less. Well, if Pierre had just changed a few of his words, then <em>this</em> is what we would have known as FLT. Call it EFLT. It could have been just as worthy. That there were reservations known to Euler, even as he lent his name to it, might have made it all the more Olympian. </p>
<p>
Then what we actually know as FLT would have been a hard-work base camp for EFLT. Would we have seen the vast number of unsuccessful FLT proofs directed at EFLT instead? By people claiming to climb this peak in one bound—without first trying to prove that a sum of <b>just two</b> <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />-th powers cannot be a higher <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />-th power, for all <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n \geq 3}" class="latex" />? Well, there would have been a problem with that, one we <a href="https://rjlipton.wpcomstaging.com/2015/09/03/open-problems-that-might-be-easy/">discussed</a> in connection with solutions that might be easy after all:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++144%5E5+%26%3D%26+27%5E5+%2B+84%5E5+%2B+110%5E5+%2B+133%5E5.%5C%5C+20615673%5E4+%26%3D%26+2682440%5E4+%2B+15365639%5E4+%2B+18796760%5E4.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  \begin{array}{rcl}  144^5 &amp;=&amp; 27^5 + 84^5 + 110^5 + 133^5.\\ 20615673^4 &amp;=&amp; 2682440^4 + 15365639^4 + 18796760^4. \end{array} " class="latex" /></p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Do you have your own issues with these claimed proofs? Or, do you see other cases of people having suddenly scaled a mountain in one stride?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/08/10/p-vs-np-proof-claims/"><span class="datestr">at August 10, 2021 07:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5706">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5706">Yet more mistakes in papers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>In my <a href="https://www.scottaaronson.com/blog/?p=5675">last post</a>, I came down pretty hard on the blankfaces: people who relish their power to persist in easily-correctable errors, to the detriment of those subject to their authority.  The sad truth, though, is that <em>I</em> don’t obviously do better than your average blankface in my ability to resist falsehoods on early encounter with them.  As one of many examples that readers of this blog might know, I didn’t think covid seemed like a big deal in early February 2020—although by mid-to-late February 2020, I’d repented of my doofosity.  If I have <em>any</em> tool with which to unblank my face, then it’s only my extreme self-consciousness when confronted with evidence of my own stupidities—the way I’ve trained myself over decades in science to see error-correction as a or even <em>the</em> fundamental virtue.</p>



<p>Which brings me to today’s post.  Continuing what’s become a <em>Shtetl-Optimized</em> tradition—see <a href="https://www.scottaaronson.com/blog/?p=2072">here from 2014</a>, <a href="https://www.scottaaronson.com/blog/?p=2854">here from 2016</a>, <a href="https://www.scottaaronson.com/blog/?p=3256">here from 2017</a>—I’m going to fess up to two serious mistakes in research papers on which I was a coauthor.</p>



<hr class="wp-block-separator" />



<p>In 2015, Andris Ambainis and I had a STOC paper entitled <a href="https://arxiv.org/abs/1411.5729">Forrelation: A Problem that Optimally Separates Quantum from Classical Computing</a>.  We gave two main results there:</p>



<ol><li>A lower bound on the randomized query complexity of my “Forrelation” problem, which was known to be solvable with only a single quantum query.</li><li>A proposed way to take any k-query quantum algorithm that queries an N-bit string, and simulate it using only O(N<sup>1-1/2k</sup>) classical randomized queries.</li></ol>



<p>Later, <a href="https://arxiv.org/abs/2008.07003">Bansal and Sinha</a> and independently <a href="https://arxiv.org/abs/2008.10223">Sherstov, Storozhenko, and Wu</a> showed that a k-query generalization of Forrelation, which I’d also defined, requires Ω(N<sup>1-1/2k</sup>) classical randomized queries, in line with my and Andris’s conjecture that k-fold Forrelation <em>optimally</em> separates quantum and classical query complexities.</p>



<p>A couple months ago, alas, my former grad school officemate <a href="https://www.cse.cuhk.edu.hk/~andrejb/">Andrej Bogdanov</a>, along with Tsun Ming Cheung and Krishnamoorthy Dinesh, emailed me and Andris to say that they’d discovered an error in result 2 of our paper (result 1, along with the Bansal-Sinha and Sherstov-Storozhenko-Wu extensions of it, remained fine).  So, adding our own names, we’ve now posted a <a href="https://eccc.weizmann.ac.il/report/2021/115/">preprint on ECCC</a> that explains the error, while also showing how to recover our result for the special case k=1: that is, any 1-query quantum algorithm really can be simulated using O(√N) classical randomized queries.</p>



<p>Read the preprint if you really want to know the details of the error, but to summarize it in my words: Andris and I used a trick that we called “variable-splitting” to handle variables that have way more influence than average on the algorithm’s acceptance probability.  Alas, variable-splitting fails to take care of a situation where there are a bunch of variables that are non-influential individually, but that on some unusual input string, can “conspire” in such a way that their signs all line up and their contribution overwhelms those from the other variables.  A single mistaken inequality fooled us into thinking such cases were handled, but an explicit counterexample makes the issue obvious.</p>



<p>I <em>still</em> conjecture that my original guess was right: that is, I conjecture that any problem solvable with k quantum queries is solvable with O(N<sup>1-1/2k</sup>) classical randomized queries, so that k-fold Forrelation is the extremal example, and so that no problem has constant quantum query complexity but linear randomized query complexity.  More strongly, I reiterate the conjecture that any bounded degree-d real polynomial, p:{0,1}<sup>N</sup>→[0,1], can be approximated by querying O(N<sup>1-1/d</sup>) input bits drawn from some suitable distribution.  But proving these conjectures, if they’re true, will require a new algorithmic idea.</p>



<hr class="wp-block-separator" />



<p>Now for the second <em>mea culpa</em>.  Earlier this year, my student Sabee Grewal and I posted a short preprint on the arXiv entitled <a href="https://arxiv.org/abs/2102.10458">Efficient Learning of Non-Interacting Fermion Distributions</a>.  In it, we claimed to give a classical algorithm for reconstructing any “free fermionic state” |ψ⟩—that is, a state of n identical fermionic particles, like electrons, each occupying one of m&gt;n possible modes, that can be produced using only “fermionic beamsplitters” and no interaction terms—and for doing so in polynomial time and using a polynomial number of samples (i.e., measurements of where all the fermions are, given a copy of |ψ⟩).  Alas, after trying to reply to confused comments from readers and reviewers (albeit, none of them <em>exactly</em> putting their finger on the problem), Sabee and I were able to figure out that we’d done no such thing.</p>



<p>Let me explain the error, since it’s actually really interesting.  In our underlying problem, we’re trying to find a collection of unit vectors, call them |v<sub>1</sub>⟩,…,|v<sub>m</sub>⟩, in C<sup>n</sup>.  Here, again, n is the number of fermions and m&gt;n is the number of modes.  By measuring the “2-mode correlations” (i.e., the probability of finding a fermion in both mode i and mode j), we can figure out the approximate value of |⟨v<sub>i</sub>|v<sub>j</sub>⟩|—i.e., the absolute value of the inner product—for any i≠j.  From that information, we want to recover |v<sub>1</sub>⟩,…,|v<sub>m</sub>⟩ themselves—or rather, their relative configuration in n-dimensional space, isometries being irrelevant.</p>



<p>It seemed to me and Sabee that, if we knew ⟨v<sub>i</sub>|v<sub>j</sub>⟩ for all i≠j, then we’d get linear equations that iteratively constrained each |v<sub>j</sub>⟩ in terms of ⟨v<sub>i</sub>|v<sub>j</sub>⟩ for j&lt;i, so all we’d need to do is solve those linear systems, and then (crucially, and this was the main work we did) show that the solution would be <em>robust</em> with respect to small errors in our estimates of each ⟨v<sub>i</sub>|v<sub>j</sub>⟩.  It seemed further to us that, while it was true that the measurements only revealed |⟨v<sub>i</sub>|v<sub>j</sub>⟩| rather than ⟨v<sub>i</sub>|v<sub>j</sub>⟩ itself, the “phase information” in ⟨v<sub>i</sub>|v<sub>j</sub>⟩ was manifestly irrelevant, as it in any case depended on the irrelevant global phases of |v<sub>i</sub>⟩ and |v<sub>j</sub>⟩ themselves.</p>



<p>Alas, it turns out that the phase information <em>does</em> matter.  As an example, suppose I told you only the following about three unit vectors |u⟩,|v⟩,|w⟩ in R<sup>3</sup>:</p>



<p>|⟨u|v⟩| = |⟨u|w⟩| = |⟨v|w⟩| = 1/2.</p>



<p>Have I thereby determined these vectors up to isometry?  Nope!  In one class of solution, all three vectors belong to the same plane, like so:</p>



<p>|u⟩=(1,0,0),<br />|v⟩=(1/2,(√3)/2,0),<br />|w⟩=(-1/2,(√3)/2,0).</p>



<p>In a completely different class of solution, the three vectors <em>don’t</em> belong to the same plane, and instead look like three edges of a tetrahedron meeting at a vertex:</p>



<p>|u⟩=(1,0,0),<br />|v⟩=(1/2,(√3)/2,0),<br />|w⟩=(1/2,1/(2√3),√(2/3)).</p>



<p>These solutions correspond to different sign choices for |⟨u|v⟩|, |⟨u|w⟩|, and |⟨v|w⟩|—choices that <em>collectively</em> matter, even though each of them is individually irrelevant.</p>



<p>It follows that, even in the special case where the vectors are all real, the 2-mode correlations are <em>not </em>enough information to determine the vectors’ relative positions.  (Well, it takes some more work to convert this to a counterexample that could actually arise in the fermion problem, but that work can be done.)  And alas, the situation gets even gnarlier when, as for us, the vectors can be complex.</p>



<p>Any possible algorithm for our problem will have to solve a system of <em>non</em>linear equations (albeit, a massively overconstrained system that’s guaranteed to have a solution), and it will have to use <em>3-mode</em> correlations (i.e., statistics of <em>triples</em> of fermions), and quite possibly 4-mode correlations and above.</p>



<p>But now comes the good news!  Googling revealed that, for reasons having nothing to do with fermions or quantum physics, problems <em>extremely</em> close to ours had already been studied in classical machine learning.  The key term here is <a href="https://en.wikipedia.org/wiki/Determinantal_point_process">“Determinantal Point Processes”</a> (DPPs).  A DPP is a model where you specify an m×m matrix A (typically symmetric or Hermitian), and then the probabilities of various events are given by the determinants of various principal minors of A.  Which is <em>precisely</em> what happens with fermions!  In terms of the vectors |v<sub>1</sub>⟩,…,|v<sub>m</sub>⟩ that I was talking about before, to make this connection we simply let A be the m×m <em>covariance matrix</em>, whose (i,j) entry equals ⟨v<sub>i</sub>|v<sub>j</sub>⟩.</p>



<p>I first learned of this remarkable correspondence between fermions and DPPs a decade ago, from a talk on DPPs that <a href="https://www.cs.washington.edu/people/faculty/taskar">Ben Taskar</a> gave at MIT.  Immediately after the talk, I made a mental note that Taskar was a rising star in theoretical machine learning, and that his work would probably be relevant to me in the future.  While researching this summer, I was devastated to learn that Taskar died of heart failure in 2013, in his mid-30s and only a couple of years after I’d heard him speak.</p>



<p>The most relevant paper for me and Sabee was called <a href="https://www.alexkulesza.com/pubs/spmap_laa14.pdf">An Efficient Algorithm for the Symmetric Principal Minor Assignment Problem</a>, by Rising, Kulesza, and Taskar.  Using a combinatorial algorithm based on minimum spanning trees and chordless cycles, this paper <em>nearly</em> solves our problem, except for two minor details:</p>



<ol><li>It doesn’t do an error analysis, and</li><li>It considers complex <em>symmetric</em> matrices, whereas our matrix A is <a href="https://en.wikipedia.org/wiki/Hermitian_matrix">Hermitian</a> (i.e., it equals its <em>conjugate</em> transpose, not its transpose).</li></ol>



<p>So I decided to email <a href="https://www.alexkulesza.com/">Alex Kulezsa</a>, one of Taskar’s surviving collaborators who’s now a research scientist at Google NYC, to ask his thoughts about the Hermitian case.  Alex kindly replied that they’d been meaning to study that case—a reviewer had even asked about it!—but they’d ran into difficulties and didn’t know what it was good for.  I asked Alex whether he’d like to join forces with me and Sabee in tackling the Hermitian case, which (I told him) was enormously relevant in quantum physics.  To my surprise and delight, Alex agreed.</p>



<p>So we’ve been working on the problem together, making progress, and I’m optimistic that we’ll have <em>some</em> nice result.  By using the 3-mode correlations, at least “generically” we can recover the entries of the matrix A <em>up to complex conjugation</em>, but further ideas will be needed to resolve the complex conjugation ambiguity, to whatever extent it actually matters.</p>



<p>In short: on the negative side, there’s much more to the problem of learning a fermionic state than we’d realized.  But on the positive side, there’s much more to the problem than we’d realized!  As with the simulation of k-query quantum algorithms, my coauthors and I would welcome any ideas.  And I apologize to anyone who was misled by our premature (and hereby retracted) claims.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5706"><span class="datestr">at August 10, 2021 07:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/116">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/116">TR21-116 |  Quantum Meets the Minimum Circuit Size Problem | 

	Nai-Hui Chia, 

	Chi-Ning  Chou, 

	Jiayu Zhang, 

	Ruizhe Zhang</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work, we initiate the study of the Minimum Circuit Size Problem (MCSP) in the quantum setting. MCSP is a problem to compute the circuit complexity of Boolean functions. It is a fascinating problem in complexity theory---its hardness is mysterious, and a better understanding of its hardness can have surprising implications to many fields in computer science.

We first define and investigate the basic complexity-theoretic properties of minimum quantum circuit size problems for three natural objects: Boolean functions, unitaries, and quantum states. We show that these problems are not trivially in NP but in QCMA (or have QCMA protocols). Next, we explore the relations between the three quantum MCSPs and their variants. We discover that some reductions that are not known for classical MCSP exist for quantum MCSPs for unitaries and states, e.g., search-to-decision reduction and self-reduction. Finally, we systematically generalize results known for classical MCSP to the quantum setting (including quantum cryptography, quantum learning theory, quantum circuit lower bounds, and quantum fine-grained complexity) and also find new connections to tomography and quantum gravity. Due to the fundamental differences between classical and quantum circuits, most of our results require extra care and reveal properties and phenomena unique to the quantum setting. Our findings could be of interest for future studies, and we post several open problems for further exploration along this direction.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/116"><span class="datestr">at August 10, 2021 06:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.04071">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.04071">EPTAS for load balancing problem on parallel machines with a non-renewable resource</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>G. Jaykrishnan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:Asaf.html">Asaf Levin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.04071">PDF</a><br /><b>Abstract: </b>The problem considered is the non-preemptive scheduling of independent jobs
that consume a resource (which is non-renewable and replenished regularly) on
parallel uniformly related machines. The input defines the speed of machines,
size of jobs, the quantity of resource required by the jobs, the replenished
quantities, and replenishment dates of the resource. Every job can start
processing only after the required quantity of the resource is allocated to the
job. The objective function is the minimization of the convex combination of
the makespan and an objective that is equivalent to the $l_p$-norm of the
vector of loads of the machines. We present an EPTAS for this problem. Prior to
our work only a PTAS was known in this non-renewable resource settings and this
PTAS was only for the special case of our problem of makespan minimization on
identical machines.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.04071"><span class="datestr">at August 10, 2021 10:58 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.04007">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.04007">Topological Art in Simple Galleries</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bertschinger:Daniel.html">Daniel Bertschinger</a>, Nicolas El Maalouly, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miltzow:Tillmann.html">Tillmann Miltzow</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schnider:Patrick.html">Patrick Schnider</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weber:Simon.html">Simon Weber</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.04007">PDF</a><br /><b>Abstract: </b>Let $P$ be a simple polygon, then the art gallery problem is looking for a
minimum set of points (guards) that can see every point in $P$. We say two
points $a,b\in P$ can see each other if the line segment $seg(a,b)$ is
contained in $P$. We denote by $V(P)$ the family of all minimum guard
placements. The Hausdorff distance makes $V(P)$ a metric space and thus a
topological space. We show homotopy-universality, that is for every
semi-algebraic set $S$ there is a polygon $P$ such that $V(P)$ is homotopy
equivalent to $S$.
</p>
<p>Furthermore, for various concrete topological spaces $T$, we describe
instances $I$ of the art gallery problem such that $V(I)$ is homeomorphic to
$T$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.04007"><span class="datestr">at August 10, 2021 11:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.04000">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.04000">Efficient algorithms for collecting the statistics of large-scale IP address data</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Jie.html">Jie Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mao:Hua.html">Hua Mao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.04000">PDF</a><br /><b>Abstract: </b>Compiling the statistics of large-scale IP address data is an essential task
in network traffic measurement. The statistical results are used to evaluate
the potential impact of user behaviors on network traffic. This requires
algorithms that are capable of storing and retrieving a high volume of IP
addresses within time and memory constraints. In this paper, we present two
efficient algorithms for collecting the statistics of large-scale IP addresses
that balance time efficiency and memory consumption. The proposed solutions
take into account the sparse nature of the statistics of IP addresses while
building the hash function and maintain a dynamic balance among layered memory
blocks. There are two layers in the first proposed method, each of which
contains a limited number of memory blocks. Each memory block contains 256
elements of size $256 \times 8$ bytes for a 64-bit system. In contrast to
built-in hash mapping functions, the proposed solution completely avoids
expensive hash collisions while retaining the linear time complexity of
hash-based solutions. Moreover, the mechanism dynamically determines the hash
index length according to the range of IP addresses, and can balance the time
and memory constraints. In addition, we propose an efficient parallel scheme to
speed up the collection of statistics. The experimental results on several
synthetic datasets show that the proposed method substantially outperforms the
baselines with respect to time and memory space efficiency.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.04000"><span class="datestr">at August 10, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03882">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03882">Two-Class (r,k)-Coloring: Coloring with Service Guarantees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Papp:P=aacute=l_Andr=aacute=s.html">Pál András Papp</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmid:Roland.html">Roland Schmid</a>, Valentin Stoppiello, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wattenhofer:Roger.html">Roger Wattenhofer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03882">PDF</a><br /><b>Abstract: </b>This paper introduces the Two-Class ($r$,$k$)-Coloring problem: Given a fixed
number of $k$ colors, such that only $r$ of these $k$ colors allow conflicts,
what is the minimal number of conflicts incurred by an optimal coloring of the
graph?
</p>
<p>We establish that the family of Two-Class ($r$,$k$)-Coloring problems is
NP-complete for any $k \geq 2$ when $(r, k) \neq (0,2)$. Furthermore, we show
that Two-Class ($r$,$k$)-Coloring for $k \geq 2$ colors with one ($r = 1$)
relaxed color cannot be approximated to any constant factor ($\notin$ APX).
Finally, we show that Two-Class ($r$,$k$)-Coloring with $k \geq r \geq 2$
colors is APX-complete.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03882"><span class="datestr">at August 10, 2021 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03877">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03877">A Polynomial Time Algorithm for a NPC Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Xinwen.html">Xinwen Jiang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03877">PDF</a><br /><b>Abstract: </b>It is introduced a so called 'Multi-stage graph Simple Path' problem (MSP for
short) and proved that SAT problem can be polynomial reducible to MSP problem
in this small paper. To solve MSP problem, we propose a polynomial time
algorithm. Our result implies NP=P.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03877"><span class="datestr">at August 10, 2021 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03868">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03868">Euclidean 3D Stable Roommates is NP-hard</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Jiehua Chen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roy:Sanjukta.html">Sanjukta Roy</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03868">PDF</a><br /><b>Abstract: </b>We establish NP-completeness for the Euclidean 3D Stable Roommates problem,
which asks whether a given set $V$ of $3n$ points from the Euclidean space can
be partitioned into $n$ disjoint (unordered) triples $\Pi=\{V_1,\dots,V_n\}$
such that $\Pi$ is stable. Here, stability means that no three points $x,y,z\in
V$ are blocking $\Pi$, and $x,y,z\in V$ are said to be blocking $\Pi$ if the
following is satisfied:
</p>
<p>-- $\delta(x,y)+\delta(x,z) &lt; \delta(x,x_1)+\delta(x,x_2)$,
</p>
<p>-- $\delta(y,x)+\delta(y,z) &lt; \delta(y,y_1)+\delta(y, y_2)$, and
</p>
<p>-- $\delta(z,x)+\delta(z,y) &lt; \delta(z,z_1)+\delta(z,z_2)$, where
$\{x,x_1,x_2\}, \{y,y_1,y_2\}, \{z,z_1,z_2\}\in \Pi$, and $\delta(a,b)$ denotes
the Euclidean distance between $a$ and $b$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03868"><span class="datestr">at August 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03867">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03867">Benchmarking Multi-Task Learning for Sentiment Analysis and Offensive Language Identification in Under-Resourced Dravidian Languages</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hande:Adeep.html">Adeep Hande</a>, Siddhanth U Hegde, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Priyadharshini:Ruba.html">Ruba Priyadharshini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Ponnusamy:Rahul.html">Rahul Ponnusamy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumaresan:Prasanna_Kumar.html">Prasanna Kumar Kumaresan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thavareesan:Sajeetha.html">Sajeetha Thavareesan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakravarthi:Bharathi_Raja.html">Bharathi Raja Chakravarthi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03867">PDF</a><br /><b>Abstract: </b>To obtain extensive annotated data for under-resourced languages is
challenging, so in this research, we have investigated whether it is beneficial
to train models using multi-task learning. Sentiment analysis and offensive
language identification share similar discourse properties. The selection of
these tasks is motivated by the lack of large labelled data for user-generated
code-mixed datasets. This paper works on code-mixed YouTube comments for Tamil,
Malayalam, and Kannada languages. Our framework is applicable to other sequence
classification problems irrespective of the size of the datasets. Experiments
show that our multi-task learning model can achieve high results compared with
single-task learning while reducing the time and space constraints required to
train the models on individual tasks. Analysis of fine-tuned models indicates
the preference of multi-task learning over single-task learning resulting in a
higher weighted F1-score on all three languages. We apply two multi-task
learning approaches to three Dravidian languages: Kannada, Malayalam, and
Tamil. Maximum scores on Kannada and Malayalam were achieved by mBERT subjected
to cross-entropy loss and with an approach of hard parameter sharing. Best
scores on Tamil was achieved by DistilBERT subjected to cross-entropy loss with
soft parameter sharing as the architecture type. For the tasks of sentiment
analysis and offensive language identification, the best-performing model
scored a weighted F1-score of (66.8\% and 90.5\%), (59\% and 70\%), and (62.1\%
and 75.3\%) for Kannada, Malayalam, and Tamil on sentiment analysis and
offensive language identification, respectively. The data and approaches
discussed in this paper are published in
Github\footnote{\href{https://github.com/SiddhanthHegde/Dravidian-MTL-Benchmarking}{Dravidian-MTL-Benchmarking}}.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03867"><span class="datestr">at August 10, 2021 10:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03837">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03837">Online Multiobjective Minimax Optimization and Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Noarov:Georgy.html">Georgy Noarov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pai:Mallesh.html">Mallesh Pai</a>, Aaron Roth <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03837">PDF</a><br /><b>Abstract: </b>We introduce a simple but general online learning framework, in which at
every round, an adaptive adversary introduces a new game, consisting of an
action space for the learner, an action space for the adversary, and a vector
valued objective function that is convex-concave in every coordinate. The
learner and the adversary then play in this game. The learner's goal is to play
so as to minimize the maximum coordinate of the cumulative vector-valued loss.
The resulting one-shot game is not convex-concave, and so the minimax theorem
does not apply. Nevertheless, we give a simple algorithm that can compete with
the setting in which the adversary must announce their action first, with
optimally diminishing regret.
</p>
<p>We demonstrate the power of our simple framework by using it to derive
optimal bounds and algorithms across a variety of domains. This includes no
regret learning: we can recover optimal algorithms and bounds for minimizing
external regret, internal regret, adaptive regret, multigroup regret,
subsequence regret, and a notion of regret in the sleeping experts setting.
Next, we use it to derive a variant of Blackwell's Approachability Theorem,
which we term "Fast Polytope Approachability". Finally, we are able to recover
recently derived algorithms and bounds for online adversarial multicalibration
and related notions (mean-conditioned moment multicalibration, and prediction
interval multivalidity).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03837"><span class="datestr">at August 10, 2021 10:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03757">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03757">Scalable adaptive PDE solvers in arbitrary domains</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Kumar.html">Kumar Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ishii:Masado.html">Masado Ishii</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fernando:Milinda.html">Milinda Fernando</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Boshun.html">Boshun Gao</a>, Kendrick Tan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hsu:Ming=Chen.html">Ming-Chen Hsu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krishnamurthy:Adarsh.html">Adarsh Krishnamurthy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sundar:Hari.html">Hari Sundar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganapathysubramanian:Baskar.html">Baskar Ganapathysubramanian</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03757">PDF</a><br /><b>Abstract: </b>Efficiently and accurately simulating partial differential equations (PDEs)
in and around arbitrarily defined geometries, especially with high levels of
adaptivity, has significant implications for different application domains. A
key bottleneck in the above process is the fast construction of a `good'
adaptively-refined mesh. In this work, we present an efficient novel
octree-based adaptive discretization approach capable of carving out
arbitrarily shaped void regions from the parent domain: an essential
requirement for fluid simulations around complex objects. Carving out objects
produces an $\textit{incomplete}$ octree. We develop efficient top-down and
bottom-up traversal methods to perform finite element computations on
$\textit{incomplete}$ octrees. We validate the framework by (a) showing
appropriate convergence analysis and (b) computing the drag coefficient for
flow past a sphere for a wide range of Reynolds numbers ($\mathcal{O}(1-10^6)$)
encompassing the drag crisis regime. Finally, we deploy the framework on a
realistic geometry on a current project to evaluate COVID-19 transmission risk
in classrooms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03757"><span class="datestr">at August 10, 2021 10:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03697">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03697">Alignment of Tractography Streamlines using Deformation Transfer via Parallel Transport</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lizarraga:Andrew.html">Andrew Lizarraga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:David.html">David Lee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kubicki:Antoni.html">Antoni Kubicki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sahib:Ashish.html">Ashish Sahib</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nunez:Elvis.html">Elvis Nunez</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narr:Katherine.html">Katherine Narr</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Joshi:Shantanu_H=.html">Shantanu H. Joshi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03697">PDF</a><br /><b>Abstract: </b>We present a geometric framework for aligning white matter fiber tracts. By
registering fiber tracts between brains, one expects to see overlap of
anatomical structures that often provide meaningful comparisons across
subjects. However, the geometry of white matter tracts is highly heterogeneous,
and finding direct tract-correspondence across multiple individuals remains a
challenging problem. We present a novel deformation metric between tracts that
allows one to compare tracts while simultaneously obtaining a registration. To
accomplish this, fiber tracts are represented by an intrinsic mean along with
the deformation fields represented by tangent vectors from the mean. In this
setting, one can determine a parallel transport between tracts and then
register corresponding tangent vectors. We present the results of bundle
alignment on a population of 43 healthy adult subjects.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03697"><span class="datestr">at August 10, 2021 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03621">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03621">Fairest Neighbors: Tradeoffs Between Metric Queries</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hetland:Magnus_Lie.html">Magnus Lie Hetland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hummel:Halvard.html">Halvard Hummel</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03621">PDF</a><br /><b>Abstract: </b>Metric search commonly involves finding objects similar to a given sample
object. We explore a generalization, where the desired result is a fair
tradeoff between multiple query objects. This builds on previous results on
complex queries, such as linear combinations. We instead use measures of
inequality, like ordered weighted averages, and query existing index structures
to find objects that minimize these. We compare our method empirically to
linear scan and a post hoc combination of individual queries, and demonstrate a
considerable speedup.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03621"><span class="datestr">at August 10, 2021 11:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03616">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03616">Circuit imbalance measures and linear programming</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Farbod Ekbatani, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natura:Bento.html">Bento Natura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/V=eacute=gh:L=aacute=szl=oacute=_A=.html">László A. Végh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03616">PDF</a><br /><b>Abstract: </b>We study properties and applications of various circuit imbalance measures
associated with linear spaces. These measures describe possible ratios between
nonzero entries of support-minimal nonzero vectors of the space. The fractional
circuit imbalance measure turns out to be a crucial parameter in the context of
linear programming, and two integer variants can be used to describe
integrality properties of associated polyhedra.
</p>
<p>We give an overview of the properties of these measures, and survey classical
and recent applications, in particular, for linear programming algorithms with
running time dependence on the constraint matrix only, and for circuit
augmentation algorithms. We also present new bounds on the diameter and circuit
diameter of polyhedra in terms of the fractional circuit imbalance measure.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03616"><span class="datestr">at August 10, 2021 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03529">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03529">SpEuler: Semantics-preserving Euler Diagrams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kehlbeck:Rebecca.html">Rebecca Kehlbeck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=ouml=rtler:Jochen.html">Jochen Görtler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yunhai.html">Yunhai Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deussen:Oliver.html">Oliver Deussen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03529">PDF</a><br /><b>Abstract: </b>Creating comprehensible visualizations of highly overlapping set-typed data
is a challenging task due to its complexity. To facilitate insights into set
connectivity and to leverage semantic relations between intersections, we
propose a fast two-step layout technique for Euler diagrams that are both
well-matched and well-formed. Our method conforms to established form
guidelines for Euler diagrams regarding semantics, aesthetics, and readability.
First, we establish an initial ordering of the data, which we then use to
incrementally create a planar, connected, and monotone dual graph
representation. In the next step, the graph is transformed into a circular
layout that maintains the semantics and yields simple Euler diagrams with
smooth curves. When the data cannot be represented by simple diagrams, our
algorithm always falls back to a solution that is not well-formed but still
well-matched, whereas previous methods often fail to produce expected results.
We show the usefulness of our method for visualizing set-typed data using
examples from text analysis and infographics. Furthermore, we discuss the
characteristics of our approach and evaluate our method against
state-of-the-art methods.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03529"><span class="datestr">at August 10, 2021 11:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03517">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03517">Online Resource Allocation with Time-Flexible Customers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golrezaei:Negin.html">Negin Golrezaei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yao:Evan.html">Evan Yao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03517">PDF</a><br /><b>Abstract: </b>In classic online resource allocation problems, a decision-maker tries to
maximize her reward through making immediate and irrevocable choices regarding
arriving demand points (agents). However, in many settings, some arriving
agents may be patient and willing to wait a short amount of time for the
resource. Motivated by this, we study the online resource allocation problem in
the presence of time-flexible agents under an adversarial online arrival model.
We present a setting with flexible and inflexible agents who seek a resource or
service that replenishes periodically. Inflexible agents demand the resource
immediately upon arrival while flexible agents are willing to wait a short
period of time. Our work presents a class of POLYtope-based Resource Allocation
(POLYRA) algorithms that achieve optimal or near-optimal competitive ratios
under an adversarial arrival process. Such POLYRA algorithms work by consulting
a particular polytope and only making decisions that guarantee the algorithm's
state remains feasible in this polytope. When the number of agent types is
either two or three, POLYRA algorithms can obtain the optimal competitive
ratio. We design these polytopes by constructing an upper bound on the
competitive ratio of any algorithm, which is characterized via a linear program
(LP) that considers a collection of overlapping worst-case input sequences. Our
designed POLYRA algorithms then mimic the optimal solution of this upper bound
LP via its polytope's definition, obtaining the optimal competitive ratio. When
there are more than three types, we show that our overlapping worst-case input
sequences do not result in an attainable competitive ratio, adding an
additional challenge to the problem. Considering this, we present a
near-optimal nested POLYRA algorithm which achieves at least 80% of the optimal
competitive ratio while having a simple and interpretable structure.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03517"><span class="datestr">at August 10, 2021 10:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03462">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03462">On the Computational Complexity of Determining Value</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Tiasa Mondol <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03462">PDF</a><br /><b>Abstract: </b>We look at an algorithmic information theory based definition of value of a
creative artifact and discuss the computational difficulty associated with the
creation or determination of value. We look at the computational resources
required to create a valuable product and discuss how likely an observer is to
verify a claim that an object required significant effort on the creator's
part.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03462"><span class="datestr">at August 10, 2021 10:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03455">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03455">An output-sensitive algorithm for all-pairs shortest paths in directed acyclic graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lingas:Andrzej.html">Andrzej Lingas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Persson:Mia.html">Mia Persson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sledneu:Dzmitry.html">Dzmitry Sledneu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03455">PDF</a><br /><b>Abstract: </b>A straightforward dynamic programming method for the single-source shortest
paths problem (SSSP) in an edge-weighted directed acyclic graph (DAG) processes
the vertices in a topologically sorted order.
</p>
<p>First, we similarly iterate this method alternatively in a breadth-first
search sorted order and the reverse order on an input directed graph with both
positive and negative real edge weights, $n$ vertices and $m$ edges. For a
positive integer $t,$ after $O(t)$ iterations in $O(tm)$ time, we obtain for
each vertex $v$ a path distance from the source to $v$ not exceeding that
yielded by the shortest path from the source to $v$ among the so called {\em$
t+$light paths}. A directed path between two vertices is $t+$light if it
contains at most $t$ more edges than the minimum edge-cardinality directed path
between these vertices. After $O(n)$ iterations, we obtain an $O(nm)$-time
solution to SSSP in directed graphs with real edge weights matching that of
Bellman and Ford.
</p>
<p>Our main result is an output-sensitive algorithm for the all-pairs shortest
paths problem (APSP) in DAGs with positive and negative real edge weights. It
runs in time $O(\min \{n^{\omega}, nm+n^2\log n\}+\sum_{v\in
V}\text{indeg}(v)|\text{leaf}(T_v)|),$ where $n$ is the number of vertices, $m$
is the number of edges, $\omega$ is the exponent of fast matrix multiplication,
$\text{indeg}(v)$ stands for the indegree of $v,$ $T_v$ is a tree of
lexicographically-first shortest directed paths from all ancestors of $v$ to
$v$, and $\text{leaf}(T_v)$ is the set of leaves in $T_v.$
</p>
<p>Finally, we discuss an extension of hypothetical improved upper time-bounds
for APSP in non-negatively edge-weighted DAGs to include directed graphs with a
polynomial number of large directed cycles.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03455"><span class="datestr">at August 10, 2021 11:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2108.03335">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2108.03335">On the complexity of the generalized Q2R automaton</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Eric Goles, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montalva=Medel:Marco.html">Marco Montalva-Medel</a>, Pedro Montealegre, Martín Ríos-Wilson <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2108.03335">PDF</a><br /><b>Abstract: </b>We study the dynamic and complexity of the generalized Q2R automaton. We show
the existence of non-polynomial cycles as well as its capability to simulate
with the synchronous update the classical version of the automaton updated
under a block sequential update scheme. Furthermore, we show that the decision
problem consisting in determine if a given node in the network changes its
state is \textbf{P}-Hard.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2108.03335"><span class="datestr">at August 10, 2021 10:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-480455417739937086">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2021/08/queues-with-small-advice.html">Queues with Small Advice</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I have had papers rejected, with comments of the form that the results seem too easy, and are at the level of a homework assignment.  Generally, I think these reviewers miss the point.  The fact that the results seem easy may be because the point isn't the derivation but the conception and framing of the problem.  I actually think that generally it's an interesting subclass of good papers that can be and are turned into homework assignments.</p><p>A new-ish paper of mine, Queues with Small Advice, was recently accepted to the very new SIAM Conference on Applied and Computational Discrete Algorithms (<a href="https://www.siam.org/conferences/cm/conference/acda21">ACDA21</a>), which took place July 19-21.  This conference focuses on algorithms with a close tie to applications.  Some people unfamiliar with theory conferences might think that algorithms work would naturally be tied to applications, but I've generally found that algorithmic work tied to applications is more negatively reviewed in theory conferences.  Indeed, that type of work is much more likely to receive comments of the form that the results seem too easy, and are at the level of a homework assignment.  So perhaps this new conference will fill an important role and hole in the current slate of theory conferences. </p><p>In any case, I actually do think this paper is in some ways easy (in that the analysis is readily approachable with standard tools), and parts of it would, I believe, make a great homework assignment.  The goal was to show the potential power of using even very simple advice, such as from machine-learning algorithms, in queueing systems.  This seems to me to be a very understudied topic, and fits into the recently growing theme of <a href="https://arxiv.org/abs/2006.09123">Algorithms with Predictions</a>.  (The paper was rejected previously from a conference, where the most negative review said "Very accessible and well written paper, which certainly provides motivation to consider problems of this type." but also said "The mathematical analysis in this paper is fairly standard, and in that sense not novel... the paper is interesting, but not advancing sufficiently the state of the art.")  </p><p>The paper focuses on the case of 1 bit of advice -- essentially, is the job "short" or "long".  I think this type is advice is a good approach to look at for queueing -- it corresponds naturally to putting a job at the front of the queue, or the back.  And it may be easier for machine-learning algorithms to generate accurately.  Simple is often good in practice.  </p><p>Rather than describe the paper further, I'll go ahead and turn it directly into a collection of homework problems.  Feel free to use them or variations you come up with;  hopefully, the students won't find the paper for answers. I personally would be thrilled if one outcome of this paper was that prediction-based problems of this form made their way into problem sets.  (Although, serious question:  who still teaches queueing theory any more?)  </p><p><b>Section 1:  One-Bit Advice (Single Queue)</b></p><p>a)  Consider the standard M/M/1 queue, with Poisson arrivals at rate λ, and exponentially distributed service times of mean 1;  the expected time a job spends in the queue in equilibrium is 1/(1-λ).  Now suppose each job comes with one bit advice;  if the job has service time greater than T, the bit is 1, and if it is smaller than T, the bit is 0.  A "big" job goes to the end of the queue, a "small" job goes to the front.  (Assume the queue is non-preemptive.)  Find the expected time for a job in this queue in equilibrium, as a function of T and λ.</p><p>b)  What is the optimal value for T (as a function of λ)? </p><p>c)  Repeat parts a and b, but this time with a preemptive queue.  Does preemption help or hurt performance?</p><p>Harder variation:  The above questions, but with an M/G/1 queue (that is, for a general, given service distribution);  derive a formula for the expected time in the system, where the formula may involve terms based on the service distribution.</p><p>Easier variation:  Write a simulation, experimentally determine the best threshold, and the improvements from one bit of advice.  Different service time distributions can be tried.  </p><p><b>Section 2:  One-Bit Advice with Predictions (Single Queue)</b></p><p>Where would possibly get a bit of advice in real life?  Perhaps from a machine learning predictor.  But in that case, the advice might turn out to be wrong.  What if our bit of advice is just right most of the time?</p><p>a)  Consider the (non-preemptive) M/M/1 queue variation from Section 1 part a above, but now the advice is correct with some probability p.  Find the expected time for a job in this queue in equilibrium, as a function of p, T, and λ.</p><p>b)  Repeat part a with a preemptive queue.</p><p>Harder variations:  The above questions, but have the probability the advice is correct depend on the size of the job.  A particularly fun example is when the "predicted service time" for a job with true time x is exponentially distributed with mean x, and the prediction bit is 1 if the predicted time is larger than T, and 0 otherwise.  Also, one can again consider general service times.  </p><p>Easier variation:  Again, write a simulation and derive experimental results/insights.  </p><p><b>Section 3:  One-Bit Advice with Prediction (Power of 2 Choices)</b>  <i>[harder, grad student level;  needs to know fluid limit models;  I'd stick with sections 1 and 2!]</i></p><p>a)  Derive fluid limit equations for a collection of N queues, where there are two types of jobs:  "large" jobs arrive as a Poisson stream of rate λ₁N and have exponentially distributed service times with mean μ₁ and "small" jobs arrive as a Poisson stream of rate λ₂N and have exponentially distributed service times of mean μ₂.  Each job comes with a bit of advice determining whether it is large or small, but large jobs are mislabelled with probability p₁ and small jobs are mislabelled with probability p₂.  An incoming job selects a queue using "the power of two choices" -- it is up to you to describe how a job determines what is the better of the two choices (there are multiple possibilities) and how jobs are processed within a queue (non-preemptive is suggested).   </p><p>[Hint:  the queue state can be represented by the number of jobs that are labelled short that are waiting, the number of jobs that are labelled long that are waiting, and the type of the job currently being serviced.]  </p><p>b)  Compare fluid limit results to simulations for 1000 queues to see if your equations seem accurate.  </p><p><br /></p></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2021/08/queues-with-small-advice.html"><span class="datestr">at August 09, 2021 08:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/one-shot-top-k/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/one-shot-top-k/">One-shot DP Top-k mechanisms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the last <a href="https://differentialprivacy.org/exponential-mechanism-bounded-range/"><em>blog post</em></a>, we showed that the exponential mechanism enjoys improved composition bounds over general pure DP mechanisms due to a property called <strong>bounded range</strong>.  For this post, we will present another useful, and somewhat surprising, property of the exponential mechanism in its application of top-\(k\) selection.</p>

<h2 id="differentially-private-top-k-selection">Differentially Private Top-\(k\) Selection</h2>

<p>We will focus on datasets that are a vector of counts \(h = (h_1, \cdots, h_d) \in \mathbb{N}^d\), which consist of counts \(h_i\) for elements from a universe \(\mathcal{U}\) where \(|\mathcal{U}| = d\).  Let’s assume that a user’s data can modify each count by at most 1, yet can change all \(d\) counts, i.e. the \(\ell_\infty\)-sensitivity is 1 and the \(\ell_0\)-sensitivity is \(d\).  The task here is to return the top-\(k\) elements from the input counts in a differentially private way.</p>

<p>For top-\(1\), this is simply returning the element with the max count, and this is precisely the problem that the exponential mechanism is set up to solve.  Let’s write out the exponential mechanism \(M^{(1)}: \mathbb{N}^d \to [d]\) for this instance:
\[
\mathbb{P}[M^{(1)}(h) = i] = \frac{e^{ \varepsilon h_i }}{\sum_{j \in [d] } e^{ \varepsilon h_j } }, \qquad \forall i \in [d].
\]
For those wondering why this formula omits the factor of \(1/2\) in the exponent, we are using the <a href="https://dongjs.github.io/2020/02/10/ExpMech.html">stronger result</a> of the exponential mechanism which replaces global sensitivity with the range of the loss function \(\ell(i,h) = - h_i\), which is \(1\) in this case.  Recall from the last blog post that the exponential mechanism is \(\varepsilon^2/8\)-CDP.</p>

<p>Hence, to generalize this to top-\(k\) selection, we can simply iteratively apply this exponential mechanism by removing the <em>discovered</em> element from each previous round.  That is, we write \(M^{(k)}: \mathbb{N}^d \to [d]^k\) as the following for any outcome \( (i_1, i_2, \cdots, i_k) \in [d]^k\),</p>

<p>\[
\mathbb{P}[M^{(k)}(h) = (i_1, i_2, \cdots, i_k)] \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad 
\]
<a name="eq:peelingEM"></a>
\[\qquad = \frac{e^{ \varepsilon h_{i_1} }}{\sum_{j \in [d] } e^{ \varepsilon h_j } } \cdot  \frac{ e^{\varepsilon h_{i_2} } }{\sum_{j\in [d]\setminus \{ i_1\}} e^{\varepsilon h_j } } \cdot \cdots \cdot \frac{ e^{ \varepsilon h_{i_2} } }{\sum_{j\in [d]\setminus \{ i_1, \cdots, i_{k-1}\}} e^{ \varepsilon h_j } }. 
\tag{1}
\]</p>

<p>We can then apply composition to conclude that \(M^{(k)}\) is \(k \varepsilon^2/8\)-CDP.</p>

<h2 id="gumbel-noise-and-the-exponential-mechanism">Gumbel Noise and the Exponential Mechanism</h2>

<p>As we discussed in our last post, we can implement the exponential mechanism by adding <a href="https://en.wikipedia.org/wiki/Gumbel_distribution">Gumbel</a> noise to each count and reporting the noisy max element.  A Gumbel random variable \(X \sim \text{Gumbel}(\beta) \), parameterized by scale parameter \(\beta&gt;0\), has the following density function
<a name="eq:GumbelDensity"></a>
\[
p(x;\beta) = \frac{1}{\beta} \exp\left( - x/\beta - e^{-x/\beta} \right), \qquad \forall x \in \mathbb{R}.
\tag{2}
\]</p>

<p>Hence, we can write the exponential mechanism in the following way
\[
M^{(1)}(h) = \arg\max \{ h_i + X_i : i \in [d] \}, \qquad \{X_i \} \stackrel{i.i.d.}{\sim} \text{Gumbel}(1/\varepsilon).
\]</p>

<p>We can then extend this to top-\(k\) by repeatedly adding independent Gumbel noise to each count and removing the discovered element for the next round.  However, something that would significantly improve run time would be to add Gumbel noise to each count <em>once</em> and then take the elements with the top-\(k\) noisy counts.  We could then add only \(d\) many noise terms, rather than \(O(d^k)\) noise terms if we were to iteratively run \(k\) different exponential mechanisms.  The question is, does this one-shot top-\(k\) Gumbel noise mechanism ensure the same level of privacy?</p>

<p>Let’s denote the one-shot Gumbel mechanism as \(\tilde{M}^{(k)}\).  At first glance, it does not seem like the one-shot Gumbel mechanism \(\tilde{M}^{(k)}\) should be just as private as the iterative exponential mechanism \(M^{(k)}\), but it turns out they are exactly the same mechanism!  The following result is due to <a href="https://arxiv.org/abs/1905.04273" title="David Durfee, Ryan Rogers. Practical Differentially Private Top-k Selection with Pay-what-you-get Composition. NeurIPS 2019"><strong>[DR19]</strong></a>.</p>

<blockquote>
  <p><strong>Theorem 1</strong>
For any input vector of counts \(h \in \mathbb{N}^d\), the one-shot Gumbel mechanism \(\tilde{M}^{(k)}(h)\) and iteratively applying the exponential mechanism \(M^{(k)}(h)\) are equal in distribution.</p>
</blockquote>

<p><em>Proof.</em> 
Recall the distribution of the iterative exponential mechanism \(M^{(k)}(h)\) from <a href="https://differentialprivacy.org/feed.xml#eq:peelingEM">(1)</a>.
Now we consider the one-shot Gumbel mechanism \(\tilde{M}^{(k)}(h)\) where we use the density of \(X \sim \) Gumbel\( (1/\varepsilon)\) from <a href="https://differentialprivacy.org/feed.xml#eq:GumbelDensity">(2)</a>.<br />
\[
\mathbb{P}[\tilde{M}^{(k)}(h) = (i_1, \cdots, i_k)] \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad 
\]
\[
\qquad = \int_{-\infty}^\infty p(u_1 - h_{i_1}) \int_{-\infty}^{u_1}  p(u_2 - h_{i_2}) \cdots \int_{-\infty}^{u_{k-1}} p(u_k - h_k) 
\]
<a name="eq:integral"></a>
\[
\qquad \qquad \cdot \prod_{j \in [d] \setminus \{i_1, \cdots, i_k \} } \mathbb{P}[ X &lt; u_k - h_j]du_k \cdots du_2 du_1.
\tag{3}
\]
Note that we have 
\[
\mathbb{P}[X &lt; y] = \exp\left( - \exp\left( -\varepsilon y \right) \right).
\]
Let’s focus on the inner integral over \(u_k\) in <a href="https://differentialprivacy.org/feed.xml#eq:integral">(3)</a>.<br />
\[
\int_{-\infty}^{u_{k-1}} p(u_k - h_{i_k} )\prod_{j \in [d] \setminus \{i_1, \cdots, i_k \} } \mathbb{P}[X &lt; u_k - h_j ]du_k \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad 
\]
\[
\quad = \int_{-\infty}^{u_{k-1}} \varepsilon \cdot  \exp\left( - \varepsilon (u_k - h_{i_k}) - e^{ -\varepsilon (u_k - h_{i_k}) } \right) \cdot  \exp\left( -e^{-\varepsilon u_k}  \sum_{j \in [d] \setminus \{i_1, \cdots, i_k \} } e^{\varepsilon h_j}  \right) du_k 
\]
\[
\quad  = \varepsilon e^{\varepsilon h_{i_k}}  \int_{-\infty}^{u_{k-1}} \exp\left( -\varepsilon u_k - e^{-\varepsilon u_k} \left( e^{\varepsilon h_{i_k}} + \sum_{j \in [d] \setminus \{i_1, \cdots i_k \} } e^{\varepsilon h_j} \right) \right) du_k \qquad
\]
<a name="eq:lastLine"></a>
\[
\qquad =  \varepsilon e^{\varepsilon h_{i_k}}  \int_{-\infty}^{u_{k-1}} \exp\left( -\varepsilon u_k - e^{-\varepsilon u_k} \left(\sum_{j \in [d] \setminus \{i_1, \cdots i_{k-1} \} } e^{\varepsilon h_j} \right) \right) du_k. \qquad \qquad
\tag{4}
\]
We now integrate with a \(v\)-substitution,
\[
v =e^{-\varepsilon u_{k}} \sum_{j \in [d] \setminus \{i_1, \cdots i_{k-1} \} } e^{\varepsilon h_j}<br />
\]
\[
dv = - \varepsilon \sum_{j \in [d] \setminus \{i_1, \cdots i_{k-1} \} } e^{\varepsilon h_j}  \cdot e^{-\varepsilon u_{k}} du_{k}.
\]</p>

<p>Continuing with <a href="https://differentialprivacy.org/feed.xml#eq:lastLine">(4)</a>, we get
\[
\int_{-\infty}^{u_{k-1}} p(u_k - h_{i_k} )\prod_{j \in [d] \setminus \{i_1, \cdots, i_k \} } \mathbb{P}[X &lt; u_k - h_j ]du_k \qquad \qquad \qquad \qquad \qquad
\]
\[
\qquad = \frac{e^{\varepsilon h_{i_k} }}{\sum_{j \in [d] \setminus \{i_1, \cdots, i_{k-1} \}} e^{\varepsilon h_j}} \cdot \exp\left( - e^{-\varepsilon u_{k-1}} \cdot \sum_{j \in [d] \setminus \{i_1, \cdots, i_{k-1} \}} e^{\varepsilon h_j} \right)
\]
\[
\qquad = \frac{e^{\varepsilon h_{i_k} }}{\sum_{j \in [d] \setminus \{i_1, \cdots, i_{k-1} \}} e^{\varepsilon h_j}}  \cdot \prod_{j \in [d] \setminus \{i_1, \cdots, i_{k-1} \} } \mathbb{P}[X &lt; u_{k-1} - h_j ] .
\] 
Note how this line has the last term in the expression for \(M^{(k)}(h)\) in <a href="https://differentialprivacy.org/feed.xml#eq:peelingEM">(1)</a>, which is independent of \(u_{k-1}\) and can hence be pulled out of the larger integral in <a href="https://differentialprivacy.org/feed.xml#eq:integral">(3)</a>.  By induction, we have
\[
\mathbb{P}[\tilde{M}^{(k)}(h) = (i_1, \cdots, i_k)] \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad 
\]
\[
\qquad  = \frac{e^{\varepsilon h_{i_1} }}{\sum_{j \in [d]} e^{\varepsilon h_j}}  \cdot \frac{e^{\varepsilon h_{i_2} }}{\sum_{j \in [d] \setminus \{ i_1\}} e^{\varepsilon h_j}}  \cdot \cdots \cdot \frac{e^{\varepsilon h_k }}{\sum_{j \in [d] \setminus \{i_1, \cdots, i_{k-1} \}} e^{\varepsilon h_j}} 
\]
\[
\qquad = \mathbb{P}[M^{(k)}(h) =(i_1, \cdots, i_k)].
\] ∎</p>

<p>So that’s great!  We can now run the one-shot Gumbel mechanism for top-\(k\) and still get the improved composition bounds of the exponential mechanism.  In addition to this achieving better runtime, this analysis can help with proving top-\(k\) DP algorithms over a large domain universe despite giving access to only the true top-\(\bar{k}\) items and their counts where \(\bar{k} &gt; k \), see <a href="https://arxiv.org/abs/1905.04273" title="David Durfee, Ryan Rogers. Practical Differentially Private Top-k Selection with Pay-what-you-get Composition. NeurIPS 2019"><strong>[DR19]</strong></a> for more details.</p>

<h2 id="report-noisy-max-for-dp-top-k">Report Noisy Max for DP Top-\(k\)</h2>

<p>We now turn to comparing this algorithm to some natural alternatives.  As we discussed in the last post, there is a family of mechanisms, report noisy max (RNM) mechanisms, that ensure differential privacy for the selection problem, and hence the top-\(1\) problem.  We showed that the exponential mechanism is equivalent to RNM with Gumbel noise, there is also RNM with Laplace and with Exponential noise, the last being the recently discovered <em>permute-and-flip</em> mechanism <a href="https://arxiv.org/abs/2010.12603" title="Ryan McKenna, Daniel Sheldon. Permute-and-Flip: A new mechanism for differentially private selection . NeurIPS 2020."><strong>[MS20]</strong></a> <a href="https://arxiv.org/abs/2105.07260" title="Zeyu Ding, Daniel Kifer, Sayed M. Saghaian N. E., Thomas Steinke, Yuxin Wang, Yingtai Xiao, Danfeng Zhang. The Permute-and-Flip Mechanism is Identical to Report-Noisy-Max with Exponential Noise. 2021."><strong>[DKSSWXZ21]</strong></a>.</p>

<p>To then use RNM mechanisms for top-\(k\), we can again iteratively apply them and use composition to get the overall privacy guarantee.  However, it turns out that you can also use the Laplace noise version of RNM in one-shot <a href="https://arxiv.org/abs/2105.08233" title="Gang Qiao, Weijie J. Su, Li Zhang. Oneshot Differentially Private Top-k Selection. ICML 2021."><strong>[QSZ21]</strong></a>.</p>

<p>We can compare the relative noise that is added to each count in both the Laplace and Gumbel versions.  Since <a href="https://arxiv.org/abs/2105.08233" title="Gang Qiao, Weijie J. Su, Li Zhang. Oneshot Differentially Private Top-k Selection. ICML 2021."><strong>[QSZ21]</strong></a> gives their privacy guarantee in terms of approximate \((\varepsilon,\delta )\)-DP, we will now make the comparison there.  We first look at the standard deviation for Laplace \( \sigma_{\text{Lap}}\) (using Theorem 2.2 in <a href="https://arxiv.org/abs/2105.08233" title="Gang Qiao, Weijie J. Su, Li Zhang. Oneshot Differentially Private Top-k Selection. ICML 2021."><strong>[QSZ21]</strong></a>).
\[
\sigma_{\text{Lap}} =  \frac{8 \sqrt{2k \ln(d/\delta)}}{\varepsilon}.
\]
Note that the one-shot Laplace mechanism returns counts as well as the indices of the top-\(k\), both of which use Laplace noise with standard deviation \(\sigma_{\text{Lap}}\), so we will also include Laplace noise to the discovered elements in the Gumbel version. That is, we add Gumbel noise with scale \(\sqrt{k}/\varepsilon’\) for the discovery portion and Laplace noise with scale \(2\sqrt{k}/\varepsilon’\) for obtaining their counts, resulting in standard deviation noise \(\sigma_{\text{Gumb}}’\) and \(\sigma_{\text{Lap}}’\), respectively.<br />
\[
\sigma_{\text{Gumb}}’  = \frac{\pi \sqrt{k} }{\sqrt{6}\varepsilon’}, \qquad 
\sigma_{\text{Lap}}’ = \frac{2\sqrt{2k}}{\varepsilon’}.
\]
Recall that adding this scale of Gumbel noise and Laplace noise will ensure \(\tfrac{\varepsilon’^2}{8} \)-CDP each, so combining will ensure \(\tfrac{\varepsilon’^2}{4}\)-CDP.  We could also use Gaussian noise to return the counts since we are using CDP, but we will analyze it with Laplace noise for comparison.  To ensure \((\varepsilon,\delta)\)-DP, we use the CDP to DP conversion from Lemma 3.5 in <a href="https://arxiv.org/abs/1605.02065" title="Mark Bun, Thomas Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. TCC 2016."><strong>[BS16]</strong></a> and solve for \(\varepsilon’\).  Hence, we get for any \(\delta&gt;0\)
\[
\varepsilon’^2/4 = \left( \sqrt{\ln(1/\delta) + \varepsilon} - \sqrt{\ln(1/\delta)} \right)^2 
\]
\[ \implies \varepsilon’ = 2 \sqrt{\ln(1/\delta)} \left( \sqrt{1 + \tfrac{\varepsilon}{\ln(1/\delta)}} - 1 \right).
\]</p>

<p>Let’s consider a typical privacy setting where \(\varepsilon &lt;  \ln(1/\delta)\), and use the inequality \(\sqrt{1+x} \geq 1 + x/4\) for \(0&lt;x&lt;1\).  Here is a short proof of this inequality:
\[
(1 + x/4)^2 = 1 + x/2  + x^2/16  \leq 1 + x/2 + x/2 = 1 + x.<br />
\]
Note that the privacy guarantee for one-shot Laplace noise only holds when \(\varepsilon &lt; 0.2\) and \(\delta &lt; 0.05\) as stated in Theorem 2.2 in <a href="https://arxiv.org/abs/2105.08233" title="Gang Qiao, Weijie J. Su, Li Zhang. Oneshot Differentially Private Top-k Selection. ICML 2021."><strong>[QSZ21]</strong></a>.  In this case, we have 
\[
\varepsilon’ \geq 2 \sqrt{\ln(1/\delta)} \left( 1 + 1/4 \cdot \tfrac{\varepsilon}{\ln(1/\delta)} - 1 \right) = 1/2 \cdot \tfrac{\varepsilon}{\sqrt{\ln(1/\delta)}}.
\]
Plugging \(\varepsilon’\) into the standard deviation of Gumbel and Laplace, we get
\[
\sigma_{\text{Gumb}}’  \leq \frac{2\pi\sqrt{k \ln(1/\delta)}}{\sqrt{6}\cdot \varepsilon}, \qquad \sigma_{\text{Lap}}’ \leq \frac{4\sqrt{2k\ln(1/\delta)}}{\varepsilon}.
\]</p>

<p>Putting this together, we can show that we add significantly less noise for the discovery and releasing noisy count phases, 
\[
\sigma_{\text{Gumb}}’\leq \sigma_{\text{Lap}}/4 ,\qquad  \sigma_{\text{Lap}}’ \leq \sigma_{\text{Lap}}/2.
\]
Note that these bounds can be improved further with similar analysis.</p>

<p>Although it has not been studied yet whether the permute-and-flip mechanism \(M_{\text{PF}} \) can also ensure DP in one shot by using Exponential noise, we briefly discuss whether it can be bounded range for a similar parameter as the Exponential Mechanism, and hence achieve similar composition bounds.  Consider running permute-and-flip on two items \(\{1,2 \}\) with a monotonic quality score \(q: \mathcal{X} \times \{1,2 \} \to \mathbb{R} \) whose sensitivity is 1.  Let \(x, x’ \in \mathcal{X} \) be neighbors where 
\[
q(x,1) = q(x,2) = 0
\]
\[
q(x’,1) = 0 , \quad q(x’,2) = 1.
\]
Hence, permute-and-flip will return outcome \(1\) or \(2\) with half probability each on dataset \(x\), while with dataset \(x’\) outcome \(1\) occurs with probability \(1/2 \cdot  e^{-\varepsilon}\) and outcome \(2\) occurs with probability \( 1/2 + 1/2 \cdot (1 - e^{-\varepsilon})\).  We can then compute the bounded range parameter \(\alpha\) as
\[
\frac{\mathbb{P}[M_{\text{PF}}(x’) = 2 ] }{\mathbb{P}[M_{\text{PF}}(x) = 2 ]}\leq e^{\alpha}\frac{\mathbb{P}[M_{\text{PF}}(x’) = 1 ]}{\mathbb{P}[M_{\text{PF}}(x) = 1 ]} \implies  \alpha \geq \varepsilon + \ln(2 - e^{-\varepsilon} ).
\]
Note that with \(\varepsilon \gg 1\), we get \(\alpha \) close to \(\varepsilon\), which would be the same bounded range parameter as the exponential mechanism.  However, with \(\varepsilon&lt; 1\), we get \(\alpha\) close to \(2\varepsilon\).  This example provides a lower bound on the BR parameter for permute-and-flip.</p>

<h2 id="conclusion">Conclusion</h2>

<p>We have looked at the top-\(k\) selection problem subject to differential privacy and although there are many different mechanisms to use, the exponential mechanism stands out for several reasons:</p>
<ol>
  <li>The exponential mechanism is \(\varepsilon\)-DP and \( \varepsilon^2/8\)-CDP and hence gets improved composition.</li>
  <li>Iteratively applying the exponential mechanism for top-\(k\) can be implemented by adding Gumbel noise to each count and returning the elements with the top-\(k\) noisy counts in one-shot.</li>
  <li>The one-shot Gumbel mechanism returns a ranked list of \(k\) elements, rather than a set of \(k\) elements.</li>
</ol></div>







<p class="date">
by Ryan Rogers <a href="https://differentialprivacy.org/one-shot-top-k/"><span class="datestr">at August 09, 2021 05:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1648249705477846335">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2021/08/combing-two-posts-blankface-scott-aa.html">Combing two posts: Blankface (Scott Aa) and Is Science Slowing Down? (Scott Al)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>(I also posted this to the Less Wrong Website. At least I tried to- I don't quite know if or when it will appear there as its my first post there.) </p><p>Some papers result from taking two papers and combining them. Perhaps nobody else had read both of them so you can say something new! Or (looking over this post) it may guide people to two really good papers, or in this case two really good posts. </p><p>This blog will draw from two excellent blog posts.</p><p>Scott Aaronson  blogged on  his website Aug 2, 2021 about <a href="https://www.scottaaronson.com/blog/?p=5675#comments">blankfaces</a>, people who let stupid or undefined rules dictate what you can do  without apology (see his post for a better explanation). One example that struck me I quote</p><p><i>No, I never applied for that grant. I spend two hours struggling to log in to a web portal designed by the world's top blankfaces until I finally gave up in despair. </i></p><p><i><br /></i></p><p>Scott Alexander blogged  on LessWrong on Nov 26, 2018 about <a href="https://www.lesswrong.com/posts/v7c47vjta3mavY3QC/is-science-slowing-down">Is science slowing down?</a> which answers with an emphatic <i>yes.</i> His point is science-per-researcher is much less than it used to be, and he has graphs and stats to prove it (see his post for the evidence and some speculation as to why this is) One of the reasons he gave struck me which I quote</p><p><i>Certain features of the modern academic system like undepaid PhD's, interminably long postdocs, endless grant writing drudgery, and clueless funders have lowered productivity. The 1930's academic system was ineed 25x more effective at getting researchers to actually do good research.</i></p><p>(A commenter reminded me that Scott Alexander himself dismisses this reason. I do not.) </p><p>(I note that he gives other reasons as well, most notably for our field that the low hanging fruit is gone. Our lack of progress on P vs NP is likely that its a hard problem, rather than the reason above. Of course, if its solved tomorrow by an outsider without funding, I will happily be proven wrong.) </p><p>Scott Alexander hits upon two types of blankfaces (without using the term).</p><p><i>Grant writing drudgery</i>: the rules for how to submit get more and more detailed an onerous. This is  what Scott Aaronson was alluding to. There are other ways its drudgery as well. </p><p><i>Clueless Funders</i>: the people deciding who gets funded might not know the area (actually in my experience the grant I've reviews have been quite good and the problem is more not enough money to award all that are deserving.) </p><p>SO I pose the following non-rhetorically as always</p><p>1) How big a factor is the slowing down of science that blankfaces get in the way?</p><p>2) What can we do about it?</p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><i><br /></i></p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2021/08/combing-two-posts-blankface-scott-aa.html"><span class="datestr">at August 09, 2021 01:50 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2021/08/08/school-on-modern-directions-in-discrete-optimization/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2021/08/08/school-on-modern-directions-in-discrete-optimization/">School on Modern Directions in Discrete Optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
September 13-17, 2021 Online https://www.him.uni-bonn.de/programs/future-programs/future-trimester-programs/discrete-optimization/discrete-optimization-school/ Aims and Scope: The school provides an introduction to some of the main topics of the trimester program on discrete optimization. The lectures will address the interface between tropical geometry and discrete optimization; recent developments in continuous optimization with applications to combinatorial problems; topics in approximation algorithms; and fixed parameter … <a href="https://cstheory-events.org/2021/08/08/school-on-modern-directions-in-discrete-optimization/" class="more-link">Continue reading <span class="screen-reader-text">School on Modern Directions in Discrete Optimization</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2021/08/08/school-on-modern-directions-in-discrete-optimization/"><span class="datestr">at August 08, 2021 02:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/115">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/115">TR21-115 |  On quantum versus classical query complexity | 

	Scott Aaronson, 

	Andris Ambainis, 

	Andrej Bogdanov, 

	Krishnamoorthy Dinesh, 

	Cheung Tsun Ming</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Aaronson and Ambainis (STOC 2015, SICOMP 2018) claimed that the acceptance probability of every quantum algorithm that makes $q$ queries to an $N$-bit string can be estimated to within $\epsilon$ by a randomized classical algorithm of query complexity $O_q((N/\epsilon^2)^{1-1/2q})$.  We describe a flaw in their argument but prove that the dependence on $N$ in this upper bound is correct for one-query quantum algorithms ($q = 1$).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/115"><span class="datestr">at August 08, 2021 12:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1563">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/2021/08/workshop-on-algorithms-for-large-data-we-found-waldo-and-so-can-you/">Workshop on Algorithms for Large Data: We found WALD(O), and so can you!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Ainesh Bakshi, Rajesh Jayaram, and Samson Zhou are organizing a 3-day <a href="https://waldo2021.github.io/">Workshop on Algorithms for Large Data</a> (nicely abbreviated as WALD(O), the O standing for Online), featuring many talks which should be of interest to the readers of this blog, as well as an open problems and a poster sessions, and a junior/senior lunch. As the organizers describe it:</p>



<blockquote class="wp-block-quote"><p>This workshop aims to foster collaborations between researchers across multiple disciplines through a set of central questions and techniques for algorithm design for large data. We will focus on topics such as sublinear algorithms, randomized numerical linear algebra, streaming and sketching, and learning and testing.</p></blockquote>



<p>The workshop will take place on <strong>August 23 — August 25</strong> (ET). Attendance is free, but <a href="https://docs.google.com/forms/d/1VMtDFay1MoiKMAErfkg2ZkAswQQdNWhiDQUKGtPBrzA/viewform">registration</a> is required by <strong>August 20th</strong>. More details at <a href="https://waldo2021.github.io/">https://waldo2021.github.io/</a></p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/2021/08/workshop-on-algorithms-for-large-data-we-found-waldo-and-so-can-you/"><span class="datestr">at August 07, 2021 07:10 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1560">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/2021/08/new-for-july-2021/">New for July 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>This month saw three papers appear online, together covering a rather broad range of topics: testing of regular languages, distribution testing under differential privacy, and local testability from high-dimensional expanders. Let’s dive in!</p>



<p><strong>Property Testing of Regular Languages with Applications to Streaming Property Testing of Visibly Pushdown Languages</strong>, by Gabriel Bathie and Tatiana Starikovskaya (<a href="https://drops.dagstuhl.de/opus/frontdoor.php?source_opus=14188">paper</a>). Let \(L\in \Sigma^\ast\) be a regular language recognized by an automation with \(m\) states and \(k\) connected components: given as input a word \(u\in \Sigma^n\), what is the query complexity to test membership to \(L\) in Hamming distance? Edit distance? Or, more generally, <em>weighted</em> edit distance, where each letter of the word \(u\) comes with a weight? In this paper, the authors focus on non-adaptive, one-sided errors testing algorithms, for which they show an upper bound of \(q=O(k m \log(m/\varepsilon)/\varepsilon)\) queries (with running time \(O(m^2 q)\)), which they complement by a query complexity lower bound of \(\Omega(\log(1/\varepsilon)/\epsilon)\), thus matching the upper bound for languages recognized by constant-size automata. The guarantee for the upper bound is with respected to weighted edit distance, and thus implies the same upper bound for testing with respect to Hamming distance. <br />To conclude, the authors use an existing connection to streaming property testing to obtain new algorithms for property testing of visibly pushdown languages (VPL) in the <em>streaming</em> model, along with a new lower bound in that model.</p>



<p><strong>High dimensional expansion implies amplified local testability</strong>, by Tali Kaufman and Izhar Oppenheim (<a href="https://arxiv.org/abs/2107.10488">arXiv</a>). This paper sets out to show that codes that arise from high-dimensional expanders are locally testable (membership to the code can be tested using very few queries). To do so, the authors define a new notion of <em>high-dimensional expanding system</em> (HDE system), as well as that of <em>amplified</em> local testability, a stronger notion than local testability; they then prove that a code based on a HDE system satisfies this stronger notion. Moreover, they show that many well-known families of codes are, in fact, HDE system codes, and therefore satisfy this stronger notion of local testability as well.</p>



<p>Finally, a survey on differential privacy, with a foray into distribution testing:</p>



<p><strong>Differential Privacy in the Shuffle Model: A Survey of Separations</strong>, by Albert Cheu (<a href="https://arxiv.org/abs/2107.11839">arXiv</a>). If you are familiar with differential privacy (DP), you may recall that there are several notions of DP, each meant to address a different “threat model” (depending on whom you trust with your data). <em>Shuffle DP</em> is one of them, intermediate between “central” DP and the more stringent “local” DP. Long story short: with shuffle DP, the tradeoff between privacy and accuracy can be strictly in-between what’s achievable in central and local DP, and that’s the case for one of the usual suspects of distribution testing, uniformity testing (<em>“I want to test if the data uniformly distributed, but now, with privacy of that data in mind”</em>). The survey discusses what is known about this in Sections 3.3 and 6, and what the implications are; but there are quite a few questions left unanswered… Long story short: a very good introduction to shuffle privacy, and to open problems in that area!</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/2021/08/new-for-july-2021/"><span class="datestr">at August 07, 2021 06:57 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-551003207026816768">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2021/08/interview-with-concur-2021-tot-award.html">Interview with CONCUR 2021 ToT Award Recipients: Uwe Nestmann and Benjamin Pierce</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I am pleased to re-post <a href="https://www.imperial.ac.uk/people/n.yoshida" target="_blank">Nobuko Yoshida</a>'s splendid <a href="http://mrg.doc.ic.ac.uk/concur-tot/" target="_blank">interview</a> with CONCUR 2021 Test-of-Time Award recipients <a href="https://www.mtv.tu-berlin.de/nestmann/" target="_blank">Uwe Nestmann</a> and <a href="https://www.cis.upenn.edu/~bcpierce/" target="_blank">Benjamin Pierce</a>. I thoroughly enjoyed reading it and learnt much from the many pearls of wisdom that pepper the interview. </p><p>Thanks to Benjamin and Uwe for their answers and to Nobuko for conducting such an inspiring interview. Enjoy!<br /></p><p><br /></p></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2021/08/interview-with-concur-2021-tot-award.html"><span class="datestr">at August 06, 2021 09:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2021/08/06/workshop-on-algorithms-for-large-data-online-2021/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2021/08/06/workshop-on-algorithms-for-large-data-online-2021/">Workshop on Algorithms for Large Data (Online) 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
August 23-25, 2021 Online https://waldo2021.github.io/ Registration deadline: August 20, 2021 This workshop aims to foster collaborations between researchers across multiple disciplines through a set of central questions and techniques for algorithm design for large data. We will focus on topics such as sublinear algorithms, randomized numerical linear algebra, streaming and sketching, and learning and testing.</div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2021/08/06/workshop-on-algorithms-for-large-data-online-2021/"><span class="datestr">at August 06, 2021 09:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=2754">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2021/08/06/average-case-fine-grained-hardness-part-iii/">Average-Case Fine-Grained Hardness, Part III</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Continuing our previous discussion, I will show another application of the new recipe described in the <a href="https://theorydish.blog/2021/07/30/average-case-fine-grained-hardness-part-ii/">previous post</a> (i.e., constructing a “good” polynomial for a problem of interest), which will establish average-case hardness of a problem related to the orthogonal vector (OV) problem. (Recall the OV problem: Given <img src="https://s0.wp.com/latex.php?latex=X%3D%5C%7Bx_1%2C%5Cdots%2Cx_n%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="X=\{x_1,\dots,x_n\}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=Y%3D%5C%7By_1%2C%5Cdots%2Cy_n%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="Y=\{y_1,\dots,y_n\}" class="latex" />, where each <img src="https://s0.wp.com/latex.php?latex=x_i%2Cy_i%5Cin%5C%7B0%2C1%5C%7D%5E%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x_i,y_i\in\{0,1\}^{d}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=d%3D%5Comega%28%5Clog+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="d=\omega(\log n)" class="latex" />, decide if there are <img src="https://s0.wp.com/latex.php?latex=x_i%2Cy_j&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x_i,y_j" class="latex" /> such that <img src="https://s0.wp.com/latex.php?latex=%5Clangle+x_i%2Cy_j%5Crangle%3D0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\langle x_i,y_j\rangle=0" class="latex" />. The reader can look up the worst-case hardness of the OV problem in the <a href="https://theorydish.blog/2021/07/23/average-case-fine-grained-hardness-part-i/">first post</a> of the series.)</p>



<p>The motivating question is can we show average-case hardness for counting the number of orthogonal pairs in the OV problem by constructing a “good” polynomial? (One motivation is that such average-case hardness result could serve as the source of reductions for proving average-case hardness for many other problems, because OV is a main source of fine-grained hardness.) There is a good reason to believe the answer is no. Specifically, an <img src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B2-%5Cdelta%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="O(n^{2-\delta})" class="latex" />-time algorithm for counting orthogonal pairs for average-case OV instances (here “average-case” is Erdős–Rényi random input model, and <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\delta" class="latex" /> is a constant that depends on the parameter of the input model) was given in <a href="https://arxiv.org/abs/2008.06591">[DLW20]</a>, while constructing a “good” polynomial would prove <img src="https://s0.wp.com/latex.php?latex=%5COmega%28n%5E%7B2-%5Cvarepsilon%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\Omega(n^{2-\varepsilon})" class="latex" /> average-case hardness for any constant <img src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon%3E0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\varepsilon&gt;0" class="latex" /> assuming randomized SETH. This indicates that sometimes constructing a “good” polynomial might be a little too ambitious goal.</p>



<p>Instead, can we first come up with a nice combinatorial problem that encodes OV on a slightly larger binary input space and then construct a “good” polynomial for counting solutions of this combinatorial problem? (The motivation is that since this combinatorial problems encodes OV, it is at least as hard as OV for worst case, and moreover, if we can construct a “good” polynomial for counting solutions of this combinatorial problem, by the new recipe in the <a href="https://theorydish.blog/2021/07/30/average-case-fine-grained-hardness-part-ii/">previous post</a>, counting solutions of this combinatorial problem for average case is (almost) as hard as that for worst case. Therefore, counting solutions of this combinatorial problem for average case is at least as hard as OV for worst case. More importantly, this combinatorial problem could serve as the source of reductions thanks to its combinatorial structure.) The factored OV problem introduced in <a href="https://arxiv.org/abs/2008.06591">[DLW20]</a> gives a positive answer to this question. Analogously, they proposed factored variants for many other flagship fine-grained hard problems. By reductions to these factored problems, they managed to prove average-case fine-grained hardness for many natural combinatorial problems such as counting regular expression matchings (the featured image of this post is the web of reductions in their paper).</p>



<p>Next, for the purpose of exposition, I briefly sketch the high-level idea behind the factored OV problem (without even explicitly describing its combinatorial interpretation, since I will not show any reduction from this problem). </p>



<p><strong>Counting solutions for factored OV.</strong>  Given an OV instance <img src="https://s0.wp.com/latex.php?latex=X%2CY&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="X,Y" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=d%3Do%28%28%5Clog+n%2F%5Clog%5Clog+n%29%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="d=o((\log n/\log\log n)^2)" class="latex" /> (actually, <img src="https://s0.wp.com/latex.php?latex=d%3Do%28%5Clog%5E2+n%2F%5Clog%5Clog+n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="d=o(\log^2 n/\log\log n)" class="latex" /> would also work, and the choice here is for simplicity), we encode <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5Ed&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x\in\{0,1\}^d" class="latex" /> as <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BEnc%7D%28x%29%3A%3D%5Ctextrm%7BLONG%7D%28x%5B1%3A%5Csqrt%7Bd%7D%5D%29%5Ccirc+%5Ctextrm%7BLONG%7D%28x%5B%5Csqrt%7Bd%7D%2B1%3A2%5Csqrt%7Bd%7D%5D%29%5Ccirc%5Cdots%5Ccirc%5Ctextrm%7BLONG%7D%28x%5Bd-%5Csqrt%7Bd%7D%2B1%3Ad%5D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{Enc}(x):=\textrm{LONG}(x[1:\sqrt{d}])\circ \textrm{LONG}(x[\sqrt{d}+1:2\sqrt{d}])\circ\dots\circ\textrm{LONG}(x[d-\sqrt{d}+1:d])" class="latex" />,<br />where <img src="https://s0.wp.com/latex.php?latex=x%5Bi%3Aj%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x[i:j]" class="latex" /> represents the subvector (block) of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> from the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="i" class="latex" />-th to the <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="j" class="latex" />-th coordinate, and <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BLONG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{LONG}" class="latex" /> is the long code encoding (specifically, <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BLONG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{LONG}" class="latex" /> maps a <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\sqrt{d}" class="latex" />-dimensional binary vector <img src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x'" class="latex" /> to a <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Csqrt%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2^{\sqrt{d}}" class="latex" />-dimensional vector binary vector <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BLONG%7D%28x%27%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{LONG}(x')" class="latex" /> of which all the coordinates are zero except the coordinate indexed by <img src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x'" class="latex" />). Namely, <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BEnc%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{Enc}(x)" class="latex" /> is the concatenation of the long code encoding of each block of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" />, and thus, <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BEnc%7D%28x%29%5Cin%5C%7B0%2C1%5C%7D%5E%7B%5Csqrt%7Bd%7D%5Ccdot+2%5E%7B%5Csqrt%7Bd%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{Enc}(x)\in\{0,1\}^{\sqrt{d}\cdot 2^{\sqrt{d}}}" class="latex" />, and for our choice of <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="d" class="latex" />, we have that <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BEnc%7D%28x%29%5Cin%5C%7B0%2C1%5C%7D%5E%7Bn%5E%7Bo%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{Enc}(x)\in\{0,1\}^{n^{o(1)}}" class="latex" />. Therefore, by taking such encoding for the vectors in the OV instance, we blow up the size of input (and hence weaken the worst-case hardness of OV) very mildly.</p>



<p>The key advantage of such encoding is that the indicator function <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7B1%7D%28x%5B1%3A%5Csqrt%7Bd%7D%5D%5Cperp+y%5B1%3A%5Csqrt%7Bd%7D%5D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbf{1}(x[1:\sqrt{d}]\perp y[1:\sqrt{d}])" class="latex" /> (which outputs <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1" class="latex" /> if the two vectors are orthogonal and <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="0" class="latex" /> otherwise) can be represented as the sum of degree-<img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2" class="latex" /> monomials, of which the variables are the coordinates of <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BLONG%7D%28x%5B1%3A%5Csqrt%7Bd%7D%5D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{LONG}(x[1:\sqrt{d}])" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BLONG%7D%28y%5B1%3A%5Csqrt%7Bd%7D%5D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{LONG}(y[1:\sqrt{d}])" class="latex" />. Indeed, we can first enumerate all the orthogonal pairs of vectors <img src="https://s0.wp.com/latex.php?latex=v_1%2Cv_2%5Cin+%5C%7B0%2C1%5C%7D%5E%7B%5Csqrt%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="v_1,v_2\in \{0,1\}^{\sqrt{d}}" class="latex" />, and we check whether <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BLONG%7D%28x%5B1%3A%5Csqrt%7Bd%7D%5D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{LONG}(x[1:\sqrt{d}])" class="latex" /> has value <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1" class="latex" /> at coordinate <img src="https://s0.wp.com/latex.php?latex=v_1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="v_1" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BLONG%7D%28y%5B1%3A%5Csqrt%7Bd%7D%5D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{LONG}(y[1:\sqrt{d}])" class="latex" /> has value <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1" class="latex" /> at coordinate <img src="https://s0.wp.com/latex.php?latex=v_2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="v_2" class="latex" />, by taking product of these two coordinates, and then, we take the sum of all the products.</p>



<p>Using this approach, for each <img src="https://s0.wp.com/latex.php?latex=x%5Cin+X%2C+y%5Cin+Y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x\in X, y\in Y" class="latex" />, for each <img src="https://s0.wp.com/latex.php?latex=i%5Cin%5B%5Csqrt%7Bd%7D%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="i\in[\sqrt{d}]" class="latex" />, we get a degree-<img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2" class="latex" /> polynomial that computes <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7B1%7D%28x%5B%28i-1%29%5Csqrt%7Bd%7D%2B1%3Ai%5Csqrt%7Bd%7D%5D%5Cperp+y%5B%28i-1%29%5Csqrt%7Bd%7D%2B1%3Ai%5Csqrt%7Bd%7D%5D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbf{1}(x[(i-1)\sqrt{d}+1:i\sqrt{d}]\perp y[(i-1)\sqrt{d}+1:i\sqrt{d}])" class="latex" /> on input <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BEnc%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{Enc}(x)" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BEnc%7D%28y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{Enc}(y)" class="latex" />. The product of these polynomials obviously computes <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7B1%7D%28x%5Cperp+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbf{1}(x\perp y)" class="latex" />, and moreover, this product is a <img src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2\sqrt{d}" class="latex" />-partite polynomial (<img src="https://s0.wp.com/latex.php?latex=d%27&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="d'" class="latex" />-partite polynomial is defined in the <a href="https://theorydish.blog/2021/07/30/average-case-fine-grained-hardness-part-ii/">previous post</a>), where each part corresponds to the coordinates of the long code encoding of a block (subvector) of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="y" class="latex" />. If we sum up these <img src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2\sqrt{d}" class="latex" />-partite polynomials for all pairs <img src="https://s0.wp.com/latex.php?latex=x%5Cin+X%2C+y%5Cin+Y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x\in X, y\in Y" class="latex" />, we get a <img src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2\sqrt{d}" class="latex" />-partite polynomial that precisely counts orthogonal pairs for the OV instance. We can let the field size of this polynomial be a prime <img src="https://s0.wp.com/latex.php?latex=p%3En%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p&gt;n^2" class="latex" /> (<img src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n^2" class="latex" /> is a trivial upper bound of the number of orthogonal pairs) such that the output of this polynomial is indeed the number of orthogonal pairs.</p>



<p>Notice that (i) Since the encoding only blows up the input size mildly, the worst-case hardness of OV (almost) carries over to evaluating this polynomial. (ii) Since <img src="https://s0.wp.com/latex.php?latex=d%3Do%28%28%5Clog+n%2F%5Clog%5Clog+n%29%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="d=o((\log n/\log\log n)^2)" class="latex" />, the <img src="https://s0.wp.com/latex.php?latex=2%5Csqrt%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2\sqrt{d}" class="latex" />-partite polynomial is a “good” polynomial (defined in the <a href="https://theorydish.blog/2021/07/30/average-case-fine-grained-hardness-part-ii/">previous post</a>). It follows from our new recipe in the <a href="https://theorydish.blog/2021/07/30/average-case-fine-grained-hardness-part-ii/">previous post</a> that evaluating this polynomial on binary input for average case (here “average case” means Erdős–Rényi random input model) is (almost) as hard as worst case. (iii) Last but not least, evaluating this polynomial on any <img src="https://s0.wp.com/latex.php?latex=z%5Cin%5C%7B0%2C1%5C%7D%5E%7B%5Csqrt%7Bd%7D%5Ccdot+2%5E%7B%5Csqrt%7Bd%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z\in\{0,1\}^{\sqrt{d}\cdot 2^{\sqrt{d}}}" class="latex" /> (not just <img src="https://s0.wp.com/latex.php?latex=%5Ctextrm%7BEnc%7D%28x%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\textrm{Enc}(x)" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5Ed&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x\in\{0,1\}^d" class="latex" />) can be interpreted as counting solutions for a combinatorial problem, which is the factored OV problem in <a href="https://arxiv.org/abs/2008.06591">[DLW20]</a>. As I mentioned earlier, I will not explain the combinatorial interpretation in details. The takeaway is that counting solutions of such factored problem is average-case fine-grained hard, and its combinatorial structure allows possible reductions to other natural combinatorial problems.</p>



<p>Finally, I mention two broad research directions in this area: (i) design cryptographic primitives, e.g., one-way functions, based on these fine-grained average-case hardness results (or show complexity barriers) and (ii) prove fine-grained average-case hardness for decision problems (or design more efficient algorithms).</p>



<p><strong>Acknowledgements.</strong> I would like to thank my quals committee — Aviad Rubinstein, Tselil Schramm, Li-Yang Tan for valuable feedback to my quals talk. </p></div>







<p class="date">
by Junyao Zhao <a href="https://theorydish.blog/2021/08/06/average-case-fine-grained-hardness-part-iii/"><span class="datestr">at August 06, 2021 03:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/08/05/predicting-weighted-ranks">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/08/05/predicting-weighted-ranks.html">Predicting weighted ranks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>This week’s events have included Olympic sport climbing, for the first time. The NBC livestream of the women’s qualification suffered a bit of an embarrassment, though, as the computer display of the results incorrectly showed some competitors as being guaranteed to qualify when they were not. (Rest of post contains spoilers; don’t click if you don’t want to know about the outcomes of the event.)</p>

<p>For example, the screenshot below shows Viktoriia Meshkova as a qualifier, with Janja Garnbret still to climb, but Meshkova was actually eliminated after Garnbret’s climb. The commentators noticed the problem and had to tell the audience not to pay attention to that part of the display. What went wrong, and how could it have been done correctly?</p>

<p style="text-align: center;"><img width="80%" alt="Ranking with one climb to go in the 2021 Olympic women's sport climbing qualifying event" src="https://11011110.github.io/blog/assets/2021/rank-product/5.jpg" /></p>

<h1 id="background">Background</h1>

<p>The important things to know about this event are:</p>

<ul>
  <li>
    <p>It involves three disciplines, speed, bouldering, and lead, in that order. One discipline finishes before the next one starts (in fact there is a long rest period between each two disciplines).</p>
  </li>
  <li>
    <p>The scores from each discipline are turned into orderings, giving each of the competitors a number from 1 to 20, before combining them into a single outcome.
Each of 20 competitors gets a rank from 1 to 20 in each of the three disciplines.</p>
  </li>
  <li>
    <p>These numbers are multiplied and the eight competitors with the <a href="https://11011110.github.io/blog/2020/07/16/comparing-multi-sport.html">smallest product of ranks</a> advance to the final round.</p>
  </li>
  <li>
    <p>In lead climbing, the ranks are based on how high each competitor climbs, with ties broken by time, so any competitor who has not yet climbed can slot into the ranking in any position.</p>
  </li>
</ul>

<p>In screens like the one shown above, the livestream showed the standings of the competitor, ordered by their product of ranks: the product of two ranks for competitors who had not yet climbed and the product of all three current ranks for competitors who had already climbed. It predicted qualification for competitors who had already climbed and were in the top eight in this ordering. This seems reasonable, at first glance: the ordering among the people who have already climbed is set, and the people who have not yet climbed can only go down in the ordering, so they will stay in the top eight.</p>

<p>But the ordering among competitors who had already climbed is <em>not</em> set. In the example shown above, before Janja Garnbret climbed, Meshkova was ahead of two other climbers, Aleksandra Mirosław and Anouck Jaubert, both of whom had done well in speed and badly in lead. Garnbret climbed better than Meshkova, bumping Meshkova’s lead ranking down from fourth to fifth. That hurt Meshkova’s combined score a lot more than it hurt Mirosław’s and Jaubert’s, because Mirosław and Jaubert already had very high ranks in lead. At the end of the competition, Meshkova was behind Mirosław and Jaubert, and out of the competition.</p>

<h1 id="analysis">Analysis</h1>

<p>We can formulate this as an algorithms problem: Suppose we have \(n\) competitors, numbered \(1\dots n\), each with a weight \(w_i\) (their combined score from the previous disciplines). We have selected an ordering on a set \(X\) of the competitors, while the remaining set \(Y\) have yet to be ordered. The eventual ordering on \(X\cup Y\) must be consistent with the ordering we already know on \(X\). If competitor \(i\) ends up in position \(p_i\), they get a combined score \(w_i\cdot p_i\) and a combined rank based on sorting these combined scores. (To keep the terminology from being confused, I’ll stick to “ordering” for the result of a single discipline, and “ranking” for the combined result of the whole competition.) What we want to know, for each competitor number \(i\), is: what is the maximum possible combined rank \(r_i\)? Before formulating an algorithm for this problem, let’s do some analysis to find simplifying assumptions that can make the algorithm fast.</p>

<p>For the climbing competition, \(n=20\) and we only care whether \(r_i\le 8\) or \(r_i&gt;8\): is competitor \(i\) guaranteed a spot in the final or not? More generally, we can ask the same question for any \(n\) and any threshold on the combined rank. We can also ask this question regardless of whether competitor \(i\) has already competed (that is, whether \(i\in X\)): if not, it’s safe to assume that they will end up last in the ordering, because that’s the slot that will give them the maximum combined rank.</p>

<p>For each competitor \(j\) in the set \(Y\) of not-yet-ordered competitors, it’s always safe to assume that \(j\) will slot in somewhere above \(i\) in the final ordering. Slotting in immediately above \(i\) is always worse for \(i\) than slotting in anywhere below \(i\), because it hurts the ranking for \(i\) more than it hurts anyone else. Therefore, it can only cause \(i\) to go down among the combined rankings of competitors who are already ordered. Once we make this assumption, we know the final position \(p_i\) of competitor \(i\) in our ordering, and therefore we also know the final combined score \(w_i\cdot p_i\). This assumption lets us determine which final scores beat \(i\), and (because the orderings are also fixed by this assumption) determines which of the competitors ordered later than \(i\) in \(X\) end up beating \(i\). What remains to be determined is which of the competitors ordered earlier than \(i\) in \(X\) might beat \(i\), and which of the competitors in \(Y\) might <span style="white-space: nowrap;">beat \(i\).</span></p>

<p>We don’t know how many competitors in \(Y\) beat \(i\), but we can guess; there are only \(\vert Y\vert\lt n\) possibilities to try. Suppose that we guess that this number is \(k\). If our guess is correct, then we can safely assume that these \(k\) better competitors are the ones in \(Y\) with the \(k\) smallest weights. Any other outcome that puts \(k\) competitors in \(Y\) ahead of \(i\) can be swapped to an outcome that puts these \(k\) competitors ahead, without changing the ranks of any competitors <span style="white-space: nowrap;">in \(X\).</span></p>

<p>Once we know which \(k\) competitors in \(Y\) beat \(i\), we also know how good a position \(p_j\) each of these competitors will need to attain, to beat \(i\). We can assign these competitors to these positions, breaking ties by moving some up into higher positions, determining where they all slot into the overall ordering. Among all assignments of positions to these competitors that puts them ahead of \(i\), this is the one that hurts the other competitors of \(i\) the least. Once this is done, we can safely assign all of the remaining competitors in \(Y\) to an ordering that slots them in just ahead of \(i\), again hurting \(i\) while causing the least hurt to the competitors <span style="white-space: nowrap;">of \(i\).</span></p>

<p>With the ordering of competitors completely determined by the choice of \(k\), all we need to do is try all choices of \(k\) and test which ones put the largest number of competitors ahead <span style="white-space: nowrap;">of \(i\)!</span></p>

<p>There is a complication here with tiebreaks that I am not handling. If two competitors get the same combined score, the one who is ahead in two of the three disciplines gets the higher combined rank. If three competitors get the same combined score, and they have a cyclic ordering on tiebreaks, I don’t know what happens, and I suspect the rules don’t cover that situation. To simplify things I will just assume that all tiebreaks go against the candidate (so we might not guarantee qualification until the ties are resolved).</p>

<h1 id="algorithm">Algorithm</h1>

<p>Based on these simplifications, our algorithm for computing the maximum combined rank \(r_i\) of competitor \(i\) performs the following steps:</p>

<ul>
  <li>
    <p>If \(i\) is not already in \(X\), add it to \(X\) with a position after all of the other competitors <span style="white-space: nowrap;">in \(X\).</span></p>
  </li>
  <li>
    <p>Loop through all choices of \(k\) in \(0\dots\vert Y\vert\). For each choice:</p>

    <ul>
      <li>
        <p>Determine, for each \(j\) in the \(k\) smallest-weight competitors in \(Y\), the position \(p_j\) that \(j\) would need to obtain to <span style="white-space: nowrap;">beat \(i\)</span></p>
      </li>
      <li>
        <p>While any two of these competitors have the same value for \(p_j\), decrement one of these two values. If this causes any value to become non-positive, continue the outer loop with the next choice <span style="white-space: nowrap;">of \(k\).</span></p>
      </li>
      <li>
        <p>Place the competitors in \(Y\) that are not among the \(k\) smallest immediately above \(i\) in the ordering</p>
      </li>
      <li>
        <p>Place the \(k\) smallest-weight competitors into positions \(p_j\), preserving the ordering of the remaining competitors.</p>
      </li>
      <li>
        <p>In the resulting ordering, determine how many competitors <span style="white-space: nowrap;">beat \(i\)</span></p>
      </li>
    </ul>
  </li>
  <li>
    <p>Return the maximum number of competitors beating \(i\) in all of the orderings that have been examined</p>
  </li>
</ul>

<p>With some care it should be possible to do all of this in time \(O(nk)\). <a href="https://11011110.github.io/blog/assets/2021/rank-product/qualify.py">My implementation</a> is slower because I was more interested in getting it to work than in optimizing it, and for \(n=20\) it is blazingly fast regardless.</p>

<h1 id="outcomes">Outcomes</h1>

<p>With all that in mind, and assuming that (somehow) I’ve implemented this correctly, let’s look at what this algorithm predicts for the actual data.</p>

<p style="text-align: center;"><img width="80%" alt="Ranking with five climbs to go in the 2021 Olympic women's sport climbing qualifying event" src="https://11011110.github.io/blog/assets/2021/rank-product/2.jpg" /></p>

<p>At this stage of the qualifications, five competitors are left to climb. NBC predicted that Seo, Raboutou, and Pilz had already qualified, and my implementation agrees for Seo and Raboutou (both can finish at worst 8th) but it was incorrect for Pilz, who could drop to 9th if Mirosław miraculously finished 2nd and Garnbret 3rd. More surprising to me, Garnbret was still not an automatic qualifier: if she finished 20th, enough other competitors could better her score to put her into 9th place.</p>

<p style="text-align: center;"><img width="80%" alt="Ranking with three climbs to go in the 2021 Olympic women's sport climbing qualifying event" src="https://11011110.github.io/blog/assets/2021/rank-product/3.jpg" /></p>

<p>After two more climbs, the faulty NBC algorithm claims that five climbers have qualified. My program agrees for Seo (worst rank 6), Nonaka (worst rank 5), Raboutou (worst rank 7), but still not Pilz (worst rank 9) or Jaubert (worst rank 10). My code now thinks Garnbret has locked in a rank of at worst 7th, qualifying without even climbing yet.</p>

<p style="text-align: center;"><img width="80%" alt="Ranking with two climbs to go in the 2021 Olympic women's sport climbing qualifying event" src="https://11011110.github.io/blog/assets/2021/rank-product/4.jpg" /></p>

<p>Shauna Coxsey, climbing with an injured knee, has climbed into the middle of the pack, falling off the top ten ranking, and her place has been taken by Kyra Condie. Garnbret is now at worst 6th and should have been marked as qualified. Noguchi is not quite guaranteed yet, with a scenario in which she could rank 9th. Seo is now at worst 5th, Nonaka at worst 4th, Raboutou at worst 5th, and Pilz at worst 8th (now guaranteeing her spot). But Jaubert and Mirosław each could end 9th; at most one of Jaubert, Mirosław, or Noguchi will be eliminated, but we can’t yet guarantee any of their spots.</p>

<p style="text-align: center;"><img width="80%" alt="Ranking with one climb to go in the 2021 Olympic women's sport climbing qualifying event" src="https://11011110.github.io/blog/assets/2021/rank-product/5.jpg" /></p>

<p>Until now, all of the “Q” markings shown on the livestream, while mathematically incorrect in many cases, were at least correct in hindsight: the people marked that way did end up qualifying. This one, though, a repeat of the first image in this post, gets it wrong in practice as well as in theory. Meshkova is marked as qualifying, but did not. Coxsey has moved back into the top ten. Mirosław and Jaubert could still have ended up 9th (under different scenarios, obviously) and should not have been marked as qualifying. Seo is at worst 4th, Nonaka is at most 3rd, Noguch is at most 4th, Raboutou is at most 5th, and Pilz is at most 6th.</p>

<p>And the final ranking:</p>

<p style="text-align: center;"><img width="80%" alt="Final ranking in the 2021 Olympic women's sport climbing qualifying event, top ten" src="https://11011110.github.io/blog/assets/2021/rank-product/6a.jpg" /></p>

<p style="text-align: center;"><img width="80%" alt="Final ranking in the 2021 Olympic women's sport climbing qualifying event, bottom ten" src="https://11011110.github.io/blog/assets/2021/rank-product/6b.jpg" /></p>

<h1 id="the-future">The future</h1>

<p>I think the moral of the story is that this ranking system is too hard to understand and a little too random (with players trading places too much depending on what other players do). To some extent this is unavoidable (a version of <a href="https://en.wikipedia.org/wiki/Arrow%27s_impossibility_theorem">Arrow’s impossibility theorem for rank aggregation</a>), but the scuttlebutt seems to be that this system will be replaced for future competitions. Which, sadly, makes all of this algorithm design a little redundant…</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106707759220927820">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/08/05/predicting-weighted-ranks.html"><span class="datestr">at August 05, 2021 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5445216218770736629">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2021/08/pole-vault-live-blogging.html">Pole Vault Live Blogging</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>As I write this I'm watching the women's pole vault final in the Olympics. Of the 15 women who made the finals, only four remain after two heights.</p><p>To expand on my <a href="https://twitter.com/fortnow/status/1421510617878437891">tweet</a>, I find the pole vault the purest of the Olympic Sports. No electronic monitors and timers, no biased judges, no video review. No points deducted for bad form or failing to stick the landing. No disqualification for a false start or stepping over a line. Either you clear the bar without knocking it down, or you don't.</p><p>The high jump has similar properties, but just not as cool looking.</p><p>All four made the third height. Now onto 4.85 meters. An American, a Greek, a Brit and a Russian (sorry I meant member of the Russian Olympic Committee).</p><p>Back in the day, the TV coverage was rather limited. We'd only see the Americans and the medal winners with too much time spend on human interest backgrounds. Now in the streaming world I can watch every competitor. The good and the bad. Live as it happens.</p><p>The Russian Anzhelika Sidorova just cleared 4.85 on her first attempt. So did the Brit Holly Bradshaw and the American Katie Nageotte. The Greek Katerina Stefanidi missed her first attempt but decided to pass on the rest. All now go to 4.90 but Stefanidi only gets two attempts while the rest get three.</p><p>Stefanidi missed her first attempt at 4.90. She gets one attempt left.</p><p>Sidorova and Bradshaw fail to even reach the bar. Nageotte can't clear the bar.</p><p>Now the moment that means everything for Stefanidi. Her last attempt. Make it or the rest get the medals. Stefaidi fails to get a good plant and doesn't get into the air at all. Her Olympics are over.</p><p>Second attempt for the others. Sidorva and Bardshaw knock down the bar. Nageotte clears the bar, putting her in prime position. Go USA!</p><p>Imagine if we judged research papers this way. Either they get into a conference or they don't. Wait, that is they way they happen, although not always without biased judging.</p><p>Sidorova is passing on her last attempt at 4.90. Bradshaw goes for it but hits the bar. She has to settle for Bronze.</p><p>Bar is now at 4.95 meters. </p><p>Sidorova gets only one attempt at 4.95. If she makes it, she takes the lead, if she misses, she gets the silver. </p><p>Sidorova doesn't clear and the gold goes to the American Katie Nageotte! </p><p>Just for excitement Nageotte is going for 5.01 meters, which would be her first over five meters in competition. In the men's pole vault, the Swede Armand Duplantis (great pole vault name!) easily won the gold. He moved the bar to 6.19 meters to break his own world record. Came all so close in his first attempt but failed to clear. </p><p>Nageotte is just too excited winning the gold to focus enough to make a serious attempt at 5.01. Can't blame her.</p><p>Thus ends the best sport in the Olympics.</p><div style="clear: both; text-align: center;" class="separator"><a style="margin-left: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-UPu6__YpuCw/YQvp7AHcn7I/AAAAAAAB9pA/W4zoC8Jo9OM8pVQ7NOrPKIpTLrIqAWyewCLcBGAsYHQ/s797/polevault.png"><img src="https://1.bp.blogspot.com/-UPu6__YpuCw/YQvp7AHcn7I/AAAAAAAB9pA/W4zoC8Jo9OM8pVQ7NOrPKIpTLrIqAWyewCLcBGAsYHQ/w400-h229/polevault.png" border="0" width="400" height="229" /></a></div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2021/08/pole-vault-live-blogging.html"><span class="datestr">at August 05, 2021 01:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=21878">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2021/08/05/let-me-tell-you-about-three-of-my-recent-papers/">Let me tell you about three of my recent papers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><img width="605" alt="michaelrabin" src="https://gilkalai.files.wordpress.com/2021/08/michaelrabin.jpg" class="alignnone size-full wp-image-21893" height="403" /></p>
<p> </p>
<p>Let me tell you briefly about three of my papers that were recently accepted for publication. <a href="http://Let F be a fixed field and let X be a simplicial complex on the vertex set V. The Leray number L(X;F) is the minimal d such that for all i≥d and S⊂V, the induced complex X[S] satisfies H~i(X[S];F)=0. Leray numbers play a role in formulating and proving topological Helly type theorems. For two complexes X,Y on the same vertex set V, define the relative Leray number LY(X;F) as the minimal d such that H~i(X[V∖σ];F)=0 for all i≥d and σ∈Y. In this paper we extend the topological colorful Helly theorem to the relative setting. Our main tool is a spectral sequence for the intersection of complexes indexed by a geometric lattice.">Relative Leray numbers via spectral sequences</a> with Roy Meshulam, <a href="https://gilkalai.files.wordpress.com/2021/08/hpaug05.pdf">Helly-type problems</a> with Imre Bárány, and <a href="https://arxiv.org/abs/2008.05177">Statistical aspects of quantum supremacy experiments</a> with Yosi Rinott and Tomer Shoham.</p>
<h3><a href="http://Let F be a fixed field and let X be a simplicial complex on the vertex set V. The Leray number L(X;F) is the minimal d such that for all i≥d and S⊂V, the induced complex X[S] satisfies H~i(X[S];F)=0. Leray numbers play a role in formulating and proving topological Helly type theorems. For two complexes X,Y on the same vertex set V, define the relative Leray number LY(X;F) as the minimal d such that H~i(X[V∖σ];F)=0 for all i≥d and σ∈Y. In this paper we extend the topological colorful Helly theorem to the relative setting. Our main tool is a spectral sequence for the intersection of complexes indexed by a geometric lattice.">Relative Leray numbers via spectral sequences</a></h3>
<blockquote>
<p><span style="color: #ff0000;"><em>We extend the topological colorful Helly theorem to the relative setting. Our main tool is a spectral sequence for the intersection of complexes indexed by a geometric lattice. </em></span></p>
</blockquote>
<p>Roy and I have a<a href="https://scholar.google.com/scholar?hl=iw&amp;as_sdt=0%2C5&amp;q=kalai+and+meshulam&amp;btnG="> long term project</a> of studying topological Helly type theorems. Often, results from convexity give a simple and strong manifestation of theorems from topology: For example, Helly’s theorem manifests the nerve theorem from algebraic topology, and Radon’s theorem can be regarded as an early “linear” version of the Borsuk–Ulam theorem. We have a few more “linear” theorems in need of topologizing on our list. Actually the paper <a href="https://londmathsoc.onlinelibrary.wiley.com/doi/full/10.1112/mtk.12103">already appeared in Mathematika</a> on June 26, 2021. It is dedicated to our dear teacher, colleague and friend  Michael O. Rabin. </p>
<blockquote>
<h3><span style="color: #993300;"> Dedicated to Michael O. Rabin, a trailblazing mathematician and computer scientist</span></h3>
</blockquote>
<h3><a href="https://gilkalai.files.wordpress.com/2021/08/hpaug05.pdf">Helly type problems</a>, to appear in the Bulletin of the American Mathematical Society </h3>
<blockquote>
<p><span style="color: #ff0000;"><em>We present a variety of problems in the interface between combinatorics and geometry around the theorems of Helly, Radon, Carath ́eodory, and Tverberg. Through these problems we describe the fascinating area of Helly-type theorems, and explain some of its main themes and goals.</em></span></p>
</blockquote>
<p>Imre and I have long term common interest in Helly-type problems and often discussed it since we first met in 1982.  We wrote a first joint paper in 2016 and last year we wrote two additional papers with Attila Por.  Last year Imre wrote a great book  “Combinatorial convexity” (AMS, 2021, in press) largely devoted to Helly-type theorems. As for me, I plan on gradually writing on open problems related to my areas of interest. (See <a href="https://www.renyi.hu/conferences/erdos100/slides/kalai.pdf">these slides</a> for some problems.)   </p>
<h3><a href="https://arxiv.org/abs/2008.05177">Statistical aspects of quantum supremacy experiments</a></h3>
<p>Yosi Rinott, Tomer Shoham and I started this project about a year an a half ago. Our paper have now been accepted to Statistical Science where you can <a href="https://www.e-publications.org/ims/submission/STS/user/submissionFile/47360?confirm=ed13d436">download the accepted version</a> along <a href="https://imstat.org/journals-and-publications/statistical-science/statistical-science-future-papers/">many other future papers</a>. This is my second paper in Statistical Science. The first one was “<a href="https://projecteuclid.org/journals/statistical-science/volume-14/issue-2/Solving-the-Bible-Code-Puzzle/10.1214/ss/1009212243.full">Solving the bible code puzzle</a>” with Brendan McKay, Dror Bar-Nathan and Maya Bar-Hillel, that appeared in 1999.     </p>
<blockquote>
<p><span style="color: #ff0000;"><em>In quantum computing, a demonstration of quantum supremacy (or quantum advantage) consists of presenting a task, possibly of no practical value, whose computation is feasible on a quantum device, but cannot be performed by classical computers in any feasible amount of time. The notable claim of quantum supremacy presented by Google’s team in 2019 consists of demonstrating the ability of a quantum circuit to generate, albeit with considerable noise, bitstrings from a distribution that is considered hard to simulate on classical computers. Very </em></span><span style="color: #ff0000;"><em>recently, in 2020, a quantum supremacy claim was presented by a group from the University of Science and Technology of China, using a different technology and generating a different distribution, but sharing some statistical principles with Google’s demonstration. </em></span></p>
<p><span style="color: #ff0000;"><em>Verifying that the generated data is indeed from the claimed distribution and assessing the circuit’s noise level and its fidelity is a statistical undertaking. The objective of this paper is to explain the relations between quantum computing and some of the statistical aspects involved in demonstrating quantum supremacy in terms that are accessible to statisticians, computer scientists, and mathematicians. Starting with the statistical modeling and analysis in Google’s demonstration, which we explain, we study various estimators of the fidelity, and different approaches to testing the distributions generated by the quantum computer. We propose different noise models, and discuss their implications. A preliminary study of the Google data, focusing mostly on circuits of 12 and 14 qubits is given in different parts of the paper</em></span></p>
</blockquote>


<p></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2021/08/05/let-me-tell-you-about-three-of-my-recent-papers/"><span class="datestr">at August 05, 2021 11:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19028">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/08/04/turning-the-tables-on-cheating/">Turning the Tables on Cheating?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><font color="#0044cc"><br />
<em>Colonel Stok: Do you play chess?</em></font></p><font color="#0044cc"><em>
</em><p><em>
Harry Palmer: Yes, but I prefer a game with a better chance of cheating.</em><br />
<font color="#000000"></font></p><font color="#000000">
<p></p><p></p>
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/08/04/turning-the-tables-on-cheating/sleuth-1972-screencaps-michael-caine-5575427-550-330/" rel="attachment wp-att-19031"><img width="154" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/08/Sleuth-1972-Screencaps-michael-caine-5575427-550-330.jpg?resize=154%2C100&amp;ssl=1" class="alignright size-full wp-image-19031" height="100" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><i>Sleuth</i> <a href="https://www.storypick.com/memorable-michael-caine-roles/">source</a></font></td>
</tr>
</tbody>
</table>
<p></p><p>
Michael Caine played <a href="https://en.wikipedia.org/wiki/Harry_Palmer">Harry Palmer</a> in the movie <a href="https://www.quotes.net/mquote/35048">Funeral in Berlin</a>. This was released in 1966—long before computers could play terrific chess. Perhaps he would have a different answer today?</p>
<p>
Today I thought we might look at chess cheating in a way that complements what Ken does.<br />
<span id="more-19028"></span></p>
<p>
Of course Ken refers to Ken Regan. He is one of the world experts at detecting chess cheating. Detection is based solely on the statistics of move choice. The only data given to Ken about the games are the moves that were played and the overall time allowance. But this ignores the players and equipment on the scene. People can cheat in ways that are closer to issues in computer security and protocols.</p>
<p>
Caine knows a lot about the latter. He is a doyen of <a href="https://filmsane.com/5-of-my-favorite-michael-caine-heist-movies/">heist movies</a> and those increasingly involve security. In the 1966 comedy <a href="https://en.wikipedia.org/wiki/Gambit_(1966_film)">Gambit</a> it is as simple as working around an alarm, but the 1969 version of <a href="https://en.wikipedia.org/wiki/The_Italian_Job">The Italian Job</a> has a switch of computer data reels and jamming traffic cameras. His latest movie <a href="https://en.wikipedia.org/wiki/Tenet_(film)">Tenet</a> centers on an algorithm for inverting time and entropy on Earth. He is also a fan of chess. He tangles with his co-star Laurence Olivier <a href="http://www.chess-in-the-cinema.de/showfilm.php?filmfile=7258.txt&amp;pfad=7079">amid</a> chess sets in the movie <a href="https://en.wikipedia.org/wiki/Sleuth_(1972_film)">Sleuth</a>. Most of all, his character in 2009’s <a href="https://en.wikipedia.org/wiki/Harry_Brown_(film)">Harry Brown</a> is a chess player, who <a href="https://www.dailymotion.com/video/xqr41b">discourses</a> on the <a href="https://www.chessgames.com/perl/chessgame?gid=1044731">17th</a> (not 7th as said) game of the 1972 championship between Bobby Fischer and Boris Spassky. </p>
<p>
</p><p></p><h2> Cheating at Chess—the Easy Way </h2><p></p>
<p></p><p>
Derren Brown is an <a href="https://derrenbrown.co.uk">illusionist</a>—a magician. He claims that he is a weak chess player. But he had Britain’s Channel 4 broadcast him playing nine strong players, including two grandmasters. Yet he won the match <b>5-4</b>. </p>
<p>
This is how he did it. He used an ancient <a href="https://en.wikipedia.org/wiki/Cheating_in_chess#Simultaneous_games">trick</a>. Say he plays two games: one against Alice and one against Bob. He plays black against Alice and white against Bob. After he gets Alice’s first move he plays that exact move against Bob. Then after he gets Bob’s move he plays that one against Alice. And so on.</p>
<p>
Suppose he loses both games. Thus Alice wins and Bob wins. But that means that Bob’s answer to Alices’ move was a winner and so on. This is impossible and so he must win at least one of the games. Thus he wins one game unless both end in a tie. </p>
<p>
The illusion is, how could he win five games against nine players given two were grandmasters? Brown played one of the nine games for real—he won that one. The “table trick” only works for an even number of games. It is not, of course, a new <a href="https://en.chessbase.com/post/the-magical-che-experiment">idea</a>: </p>
<blockquote><p><b> </b> <em> Alekhine and his twice world championship challenger Bogoljubov were once challenged separately by a relative patzer to games of correspondence chess at money odds. In effect, of course, the anonymous opportunist was playing in neither game. The story goes that the two players, who were friends away from the board, met up one day and latched on to what was happening. </em>
</p></blockquote>
<p></p><p>
The imitation trick is a real potential issue in <em>Basque chess</em>, where two players play two games simultaneously, one as white and one as black. By copying each other’s moves, they would always tie. An early <a href="https://en.chessbase.com/post/che-magazine-basque-che-does-it-work-for-you-">description</a> noted the issue but Ken has not been able to find how the rules forbid it. </p>
<p>
A similar situation <a href="https://www.chess.com/article/view/chess-arbiters">happened</a> recently in a real tournament—a world championship qualifier, no less. Two games at adjacent tables played almost twenty of the same opening moves. The chief arbiter—someone Ken corresponds with several times a week—moved one of the games to a different area. International Master Danny Rensch, who heads the major online playing site <a href="https://www.chess.com/">Chess.com</a>, made a <a href="https://youtu.be/-6QX53BmDbg">video</a> “Are You Copying Me?” of the incident. None of the four players involved was cheating, but this illustrates the kind of people dynamics one needs to watch for.</p>
<p>
</p><p></p><h2> Cheating at Chess—the Too Easy Way </h2><p></p>
<p></p><p>
This is to cheat by consulting a computer program that is stronger than all human players, such as the free program <a href="https://en.wikipedia.org/wiki/Stockfish_(chess)">Stockfish</a>, without anything impeding one’s ability to access the program’s recommendations during the game. This is often the case in online chess without sophisticated measures to detect the access. </p>
<p>
Ken’s statistical model can still judge the moves, but this is after the fact. We would like to <em>prevent</em> cheating. This hasn’t happened. Already last year, Ken was <a href="https://www.theguardian.com/sport/2020/oct/16/chesss-cheating-crisis-paranoia-has-become-the-culture">quoted</a> in the UK Guardian newspaper saying, “The pandemic has brought me as much work in a single day as I have had in a year previously.” A Wall Street Journal <a href="https://www.wsj.com/articles/the-real-queens-gambit-catching-chess-cheaters-11607439491">story</a> that featured Ken also noted:</p>
<blockquote><p><b> </b> <em> The data showed something curious. More people were playing chess. Yet the fair play violations were surging even faster than the number of overall games. “Which makes us think that there has been an uptick in the rate of cheating,” said Gerard Le-Marechal, head of cheat detection for Chess.com. </em>
</p></blockquote>
<p></p><p>
This year has brought no letup—see Ken’s statement prefacing a non-chess <a href="https://rjlipton.wpcomstaging.com/2021/07/22/the-reach-of-dichotomy/">post</a> that June and July were the worst. Chess.com and Lichess and other playing sites have the final say but Ken is often used for both early warning (his “screening” step is agile and gives officials an informative snapshot of an entire tournament) and for explaining verdicts afterwards, since his model is transparent and not compromised by divulging explanations.</p>
<p>
But again, this is after the fact. I recall a <a href="https://rjlipton.wpcomstaging.com/2016/05/20/making-public-information-secret/">post</a> we wrote about ways computer security is like “closing the barn door after the horse has already left.” The open question that I find interesting is not how cheaters can be detected, but is there some way to make it hard for them to cheat at all. </p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/08/04/turning-the-tables-on-cheating/cainebbb/" rel="attachment wp-att-19037"><img width="295" alt="" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/08/CaineBBB.jpg?resize=295%2C279&amp;ssl=1" class="aligncenter size-full wp-image-19037" height="279" /></a>
</td>
</tr>
<tr>
<td class="caption alignright">
<font size="-2">ARPANET history <a href="https://computer.howstuffworks.com/arpanet.htm#pt1">source</a><br />
</font>
</td>
</tr>
</tbody></table>
<p>
Of course, this is not just about chess, or other games forced online by the pandemic. It extends to administering courses and tests, at a time when the prospect of a “normal” in-person Fall semester is being roiled by the surge we’ve <a href="https://rjlipton.wpcomstaging.com/2021/06/20/the-shape-of-this-summer/">previewed</a> and <a href="https://rjlipton.wpcomstaging.com/2021/07/13/socially-reproduced-experiments/">tracked</a> on this blog. </p>
<p>
</p><p></p><h2> Cheating at Chess—the Harder Way </h2><p></p>
<p></p><p>
The number of ways people have cheated at in-person chess is legion. Wikipedia has a long <a href="https://en.wikipedia.org/wiki/Cheating_in_chess">list</a>. Ken put the ways in cases he’d encountered to a Dr. Seuss rhyme midway through his 2014 TEDx Buffalo <a href="https://www.youtube.com/watch?v=9W3D8xVAKao">talk</a>. </p>
<p>
On March 15, 2020, the New York Times published an <a href="https://www.nytimes.com/2020/03/15/sports/chess-cheating.html">article</a> on tech in chess cheating. It drew analogy to the Houston Astros scandal, including the same example we just <a href="https://rjlipton.wpcomstaging.com/2021/07/13/socially-reproduced-experiments/">covered</a> of whether José Altuve was wired for his series-winning home run in 2019. It touched on online chess and quotes Le-Marechal but <em>showed no inkling of</em> the impending pandemic and its effect on chess. Its first sentence about chess alludes to the 1978 incident in which Viktor Korchnoi alleged that Anatoly Karpov could receive coded information about their match games via the flavor of yogurt delivered to the table. </p>
<p>
I, Ken writing this part, have been part of discussions of how a yogurt <em>spoon</em> dropped audibly could be one of myriad possible signals from the audience. The pandemic caused this year’s Tata Steel tournament to be played <a href="https://www.dutchnews.nl/news/2021/01/no-women-at-tata-steel-chess-this-year-but-game-is-growing-in-popularity/">without</a> audience, while some other elite events are played in an “<a href="https://www.chess.com/news/view/bilbao-chess-outside-in-a-glass-cube">aquarium</a>” with one-way glass. But that does not work for larger-scale Open tournaments. Jamming RF signals is generally illegal. I agree with those recommending that an illusionist like Brown—someone with an eagle eye for watching people—be employed to help the arbiters at large events.</p>
<p>
Yet for all the ways and means out there, it is still <em>hard</em> to cheat at in-person chess. Its state is one that organizers of <em>online chess</em> would gladly reach if they could. FIDE has promoted a <a href="https://en.chessbase.com/post/the-rise-of-hybrid-chess">hybrid</a> form in which players travel to regional rooms watched by arbiters, but this is hard to manage on large scale. Dick and I have debated all year what to do for online chess, and we’ve converged on two poles of answers.</p>
<p>
</p><p></p><h2> Way #1: Standardized Playing Tabletops </h2><p></p>
<p></p><p>
The paradox, noted this week by International Master Nisha Mohota in her recent <a href="https://youtu.be/hpLiG1UgIus">video</a> on cheating, is that the popularity of chess online has burgeoned during the pandemic. But this also enhances the following dilemma:</p>
<ul>
<li>
Having a second camera—side view supplementing screen view—has been an effective measure. <p></p>
</li><li>
But requiring even one camera has been an acknowledged obstacle to expanding the reach of chess tournaments. <p></p>
</li><li>
And it takes extra human resources to monitor two video feeds per player.
</li></ul>
<p>
Online education has also <a href="https://www.erasmusmagazine.nl/en/2021/01/15/students-will-have-to-use-phone-as-a-second-camera-in-proctored-online-exams/">recognized</a> the importance of a second camera, <a href="https://www.theabr.org/announcements/remote-exam-information">requiring</a> one in some cases. Yet allowing the user to control how the side camera is positioned may allow circumventions, and mandating one connotes distrust and negativity in a bare sense. </p>
<p>
My suggestion is to try to turn around the negative aspect into a positive by marketing a standardized and hopefully-inexpensive “Online Tabletop Arena.” It would have three walls to feel like an alcove. The walls, one with a side camera built in, would limit hand movements as well as sight lines. Standardization would lessen stigma and help monitoring. It could also be used for online test taking.</p>
<p>
</p><p></p><h2> Way #2: Give In </h2><p></p>
<p></p><p>
The real import of our mentioned security <a href="https://rjlipton.wpcomstaging.com/2016/05/20/making-public-information-secret/">post</a> is to stop trying to stick thumbs in all the dam holes. Mohota in her video laments kids being exposed to chess programs and advocates training without them, but that strikes us as trying to close ten thousand barn doors while a million free horses are out there. </p>
<p>
So let’s give in: Allow the players to use computers freely. The more, the merrier. But as in the 1967 Caine-as-Harry-Palmer movie <a href="https://en.wikipedia.org/wiki/Billion_Dollar_Brain">Billion Dollar Brain</a>, we reward the humans for how they <em>disobey</em> the computer calling the shots.</p>
<p>
One way to implement this would be to have the chess playing site appoint one unknown (say, randomly selected) strong chess program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{P}" class="latex" /> as the official scorer of all games. A player’s score for a won or drawn game would be proportional to the total difference from <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{P}" class="latex" /> in Ken’s metrics. Perhaps credit could be given also for a valiantly lost game.</p>
<p>
This scheme would directly reward players for the amount of <em>non-</em>cheating they do. Or put more positively, human ingenuity apart from computers would bring the reward. The ability to sleuth strategy beyond computer moves was already <a href="https://www.psychologytoday.com/us/blog/seeing-what-others-dont/201710/the-age-centaurs">demonstrated</a> in so-called <a href="https://en.wikipedia.org/wiki/Advanced_chess">freestyle</a> tournaments held in 2007-08 and 2014. A particularly nice example of playing a sacrifice that the computer does not like was executed at turn 18 by Magnus Carlsen in his World Cup <a href="https://www.chessbomb.com/arena/2021-fide-world-cup/08-01-Fedoseev_Vladimir-Carlsen_Magnus">win</a> today over Vladimir Fedoseev.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We admit the tabletop suggestion is far from electrifying, but has anyone come up with better? As always we welcome suggestions from our readers, or pointers to forum discussions that you agree with.</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/08/04/turning-the-tables-on-cheating/"><span class="datestr">at August 04, 2021 09:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/08/02/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-24-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/08/02/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-24-2021/">Complexity Postdoctoral Fellowship at Santa Fe Institute (apply by October 24, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Unique among postdocs, these 3-year fellowships offer the opportunity to join a collaborative community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science and society. Benefits include research/collaboration funds, paid family leave, and a professional leadership &amp; development program.</p>
<p>Website: <a href="https://santafe.edu/news-center/news/apply-now-santa-fe-institute-postdoctoral-fellowships-2021">https://santafe.edu/news-center/news/apply-now-santa-fe-institute-postdoctoral-fellowships-2021</a><br />
Email: sfifellowship@santafe.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/08/02/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-24-2021/"><span class="datestr">at August 02, 2021 10:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5675">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5675">On blankfaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>For years, I’ve had a private term I’ve used with my family.  To give a few examples of its use:</p>



<blockquote class="wp-block-quote"><p>No, I never applied for that grant. I spent two hours struggling to log in to a web portal designed by the world’s top blankfaces until I finally gave up in despair.</p></blockquote>



<blockquote class="wp-block-quote"><p>No, I paid for that whole lecture trip out of pocket; I never got the reimbursement they promised.  Their blankface administrator just kept sending me back the form, demanding more and more convoluted bank details, until I finally got the hint and dropped it.</p></blockquote>



<blockquote class="wp-block-quote"><p>No, my daughter Lily isn’t allowed in the swimming pool there.  She easily passed their swim test last year, but this year the blankface lifeguard made up a new rule on the spot that she needs to retake the test, so Lily took it again and passed even <em>more</em> easily, but then the lifeguard said she didn’t like the stroke Lily used, so she failed her and didn’t let her retake it.  I complained to their blankface athletic director, who launched an ‘investigation.’  The outcome of the ‘investigation’ was that, regardless of the ground truth about how well Lily can swim, their blankface lifeguard said she’s not allowed in the pool, so being blankfaces themselves, they’re going to stand with the lifeguard.</p></blockquote>



<blockquote class="wp-block-quote"><p>Yeah, the kids spend the entire day indoors, breathing each other’s stale, unventilated air, then they finally go outside and they aren’t allowed on the playground equipment, because of the covid risk from them touching it.  Even though we’ve known for more than a year that covid is an airborne disease.  Everyone I’ve talked there agrees that I have a point, but they say their hands are tied.  I haven’t yet located the blankface who actually made this decision and stands by it.</p></blockquote>



<p>What exactly is a blankface?  He or she is often a mid-level bureaucrat, but not every bureaucrat is a blankface, and not every blankface is a bureaucrat.  A blankface is anyone who enjoys wielding the power entrusted in them to make others miserable by acting like a cog in a broken machine, rather than like a human being with courage, judgment, and responsibility for their actions.  A blankface meets every appeal to facts, logic, and plain compassion with the same repetition of rules and regulations and the same blank stare—a blank stare that, more often than not, conceals a contemptuous smile.</p>



<p>The longer I live, the more I see blankfacedness as one of the fundamental evils of the human condition.  Yes, it contains large elements of stupidity, incuriosity, malevolence, and bureaucratic indifference, but it’s not reducible to any of those.  After enough experience, the first two questions you ask about any organization are:</p>



<ol><li>Who are the blankfaces here?</li><li>Who are the people I can talk with to get around the blankfaces?</li></ol>



<p>As far as I can tell, blankfacedness cuts straight across conventional political ideology, gender, and race.  (Age, too, except that I’ve never once encountered a blankfaced child.)  Brilliance and creativity do seem to offer some protection against blankfacedness—possibly because the smarter you are, the harder it is to justify idiotic rules to yourself—but even there, the protection is far from complete.</p>



<hr class="wp-block-separator" />



<p>Twenty years ago, all the conformists in my age cohort were obsessed with the <em>Harry Potter</em> books and movies—holding parties where they wore wizard costumes, etc.  I decided that the <em>Harry Potter</em> phenomenon was a sort of collective insanity: from what I could tell, the stories seemed like startlingly puerile and unoriginal mass-marketed wish-fulfillment fantasies.</p>



<p>Today, those same conformists in my age cohort are more likely to condemn the <em>Harry Potter</em> series as Problematically white, male, and cisnormative, and J. K. Rowling herself as a monstrous bigot whose acquaintances’ acquaintances should be shunned.  Naturally, then, there was nothing for me to do but finally read the series!  My 8-year-old daughter Lily and I have been partner-reading it for half a year; we’re just finishing book 5.  (<em>After</em> we’ve finished the series, we might start on <em><a href="http://www.hpmor.com/">Harry Potter and the Methods of Rationality</a></em> … which, I confess, I’ve also never read.)</p>



<p>From book 5, I learned something extremely interesting.  The most despicable villain in the <em>Harry Potter</em> universe is not Lord Voldemort, who’s mostly just a faraway cipher and abstract embodiment of pure evil, no more hateable than an earthquake.  Rather, it’s <a href="https://en.wikipedia.org/wiki/Dolores_Umbridge">Dolores Jane Umbridge</a>, the toadlike Ministry of Magic bureaucrat who takes over Hogwarts school, forces out Dumbledore as headmaster, and terrorizes the students with increasingly draconian “Educational Decrees.”  Umbridge’s decrees are mostly aimed at punishing Harry Potter and his friends, who’ve embarrassed the Ministry by telling everyone the truth that Voldemort has returned and by readying themselves to fight him, thereby defying the Ministry’s head-in-the-sand policy.</p>



<p>Anyway, I’ll say this for <em>Harry Potter</em>: Rowling’s portrayal of Umbridge is so spot-on and merciless that, for anyone who knows the series, I could simply <em>define</em> a blankface to be anyone sufficiently Umbridge-like.</p>



<hr class="wp-block-separator" />



<p>This week I <em>also</em> finished reading <em><a href="https://www.amazon.com/Premonition-Pandemic-Story-Michael-Lewis-ebook/dp/B08V91YY8R">The Premonition</a></em>, the thrilling account of the runup to covid by <a href="https://en.wikipedia.org/wiki/Michael_Lewis">Michael Lewis</a> (who also wrote <em><a href="https://www.amazon.com/Big-Short-Inside-Doomsday-Machine/dp/0393338827">The Big Short</a></em>, <em><a href="https://en.wikipedia.org/wiki/Moneyball">Moneyball</a></em>, etc).  Lewis tells the stories of a few individuals scattered across US health and government bureaucracies who figured out over the past 20 years that the US was breathtakingly unprepared for a pandemic, and who struggled against official indifference, mostly unsuccessfully, to try to fix that.  As covid hit the US in early 2020, these same individuals frantically tried to pull the fire alarms, even as the Trump White House, the CDC, and state bureaucrats all did everything in their power to block and sideline them.  We all know the results.</p>



<p>It’s no surprise that, in Lewis’s telling, Trump and his goons come in for world-historic blame: however terrible you thought they were, they were worse.  It seems that John Bolton, in particular, gleefully took an ax to everything the two previous administrations had done to try to prepare the federal government for pandemics—after Tom Bossert, the one guy in Trump’s inner circle who’d actually taken pandemic preparation seriously, was forced out for contradicting Trump about Russia and Ukraine.</p>



<p>But the left isn’t spared either.  The most compelling character in <em>The Premonition</em> is <a href="https://en.m.wikipedia.org/wiki/Charity_Dean">Charity Dean</a>, who escaped from the Christian fundamentalist sect in which she was raised to put herself through medical school and become a crusading public-health officer for Santa Barbara County.  Lewis relates with relish how, again and again, Dean startled the bureaucrats around her by taking matters into her own hands in her war against pathogens—e.g., slicing into a cadaver herself to take samples when the people whose job it was wouldn’t do it.</p>



<p>In 2019, Dean moved to Sacramento to become California’s next chief public health officer, but then Governor Gavin Newsom blocked her expected promotion, instead recruiting someone from the outside named Sonia Angell, who had no infectious disease experience but to whom Dean would have to report.  Lewis reports the following as the reason:</p>



<blockquote class="wp-block-quote"><p>“It was an optics problem,” says a senior official in the Department of Health and Human Services.  “Charity was too young, too blond, too Barbie.  They wanted a person of color.”  Sonia Angell identified as Latina.</p></blockquote>



<p>After it became obvious that the White House and the CDC were both asleep at the wheel, the competent experts’ Plan B was to get California to set a national standard, one that would shame all the other states into acting, by telling the truth about covid and by aggressively testing, tracing, and isolating.  And here comes the tragedy: Charity Dean spent from mid-January till mid-March trying to do exactly that, and Sonia Angell blocked her.  Angell—who comes across as a real-life Dolores Umbridge—banned Dean from using the word “pandemic,” screamed at her for her insubordination, and systematically shut her out of meetings.  Angell’s stated view was that, until and unless the CDC said that there was a pandemic, <em>there was no pandemic</em>—regardless of what hospitals across California might be reporting to the contrary.</p>



<p>As it happens, California <em>was</em> the first state to move aggressively against covid, on March 19—basically because as the bodies started piling up, Dean and her allies finally managed to maneuver around Angell and get the ear of Governor Newsom directly.  Had the response started earlier, the US might have had an outcome more in line with most industrialized countries.  Half of the 630,000 dead Americans might now be alive.</p>



<p>Sonia Angell fully deserves to have her name immortalized by history as one of the blankest of blankfaces.  But of course, Angell was far from alone.  Robert Redfield, Trump’s CDC director, was a blankface extraordinaire.  Nancy Messonnier, who lied to stay in Trump’s good graces, was a blankface too.  The entire CDC and FDA seem to have teemed with blankfaces.  As for Anthony Fauci, he became a national hero, maybe even deservedly so, merely by <em>not being 100%</em> a blankface, when basically every other “expert” in the US with visible power was.  Fauci cleared a depressingly low bar, one that the people profiled by Lewis cleared at Simone-Biles-like heights.</p>



<p>In March 2020, the fundamental question I had was: where are the supercompetent rule-breaking American heroes from the disaster movies?  What’s taking them so long?  <em>The Premonition</em> satisfyingly answers that question.  It turns out that the heroes did exist, scattered across the American health bureaucracy.  They were screaming at the top of their lungs.  But they were outvoted by the critical mass of blankfaces that’s become one of my country’s defining features.</p>



<hr class="wp-block-separator" />



<p>Some people will object that the term “blankface” is dehumanizing.  The reason I disagree is that a blankface is someone who freely chose to dehumanize <em>themselves</em>: to abdicate their human responsibility to see what’s right in front of them, to <em>act like</em> malfunctioning pieces of electronics even though they, like all of us, were born with the capacity for empathy and reason.</p>



<p>With many other human evils and failings, I have a strong inclination toward mercy, because I understand how someone could’ve succumbed to the temptation—indeed, I worry that I myself might’ve succumbed to it “but for the grace of God.”  But here’s the thing about blankfaces: in all my thousands of dealings with them, not once was I ever given cause to wonder whether I might have done the same in their shoes.  It’s like,<em> of course</em> I wouldn’t have!  Even if I were forced (by my own higher-ups, an intransigent computer system, or whatever else) to foist some bureaucratic horribleness on an innocent victim, I’d be sheepish and apologetic about it.  I’d acknowledge the farcical absurdity of what I was making the other person do, or declaring that they couldn’t do.  Likewise, even if I were useless in a crisis, at least I’d <em>get out of the way</em> of the people trying to solve it.  How could I live with myself otherwise?</p>



<p>The fundamental mystery of the blankfaces, then, is how they can be so alien and yet so common.</p>



<hr class="wp-block-separator" />



<p><strong><span class="has-inline-color has-vivid-red-color">Update (Aug. 3):</span></strong> Surprisingly many people seem to have read this post, and come away with the notion that a “blankface” is simply anyone who’s a stickler for rules and formalized procedures.  They’ve then tried to refute me with examples of where it’s <em>good</em> to be a stickler, or where I in particular would believe that it’s good.</p>



<p>But no, that’s not it at all.</p>



<p>Rules can be either good or bad.  All things considered, I’d probably rather be on a plane piloted by a robotic stickler for safety rules, than by someone who ignored the rules at his or her discretion.  And as I said in the post, in the first months of covid, it was ironically the <em>anti</em>-blankfaces who were screaming for rules, regulations, and lockdowns; the blankfaces wanted to continue as though nothing had changed!</p>



<p>Also, “blankface” (just like “homophobe” or “antisemite”) is a serious accusation.  I’d never call anyone a blankface merely for sticking with a defensible rule when it turned out, in hindsight, that the rule could’ve been relaxed.</p>



<p>Here’s how to tell a blankface: suppose you see someone enforcing or interpreting a rule in a way that strikes you as <em>obviously</em> absurd.  And suppose you point it out to them.</p>



<p>Do they say “I disagree, here’s why it actually <em>does</em> make sense”?  They might be mistaken but they’re not a blankface.</p>



<p>Do they say “tell me about it, it makes <em>zero</em> sense, but it’s above my pay grade to change”?  You might wish they were more dogged or courageous but again they’re not a blankface.</p>



<p>Or do they ignore all your arguments and just restate the original rule—seemingly angered by what they understood as a challenge to their authority, and delighted to reassert it?  <em>That’s</em> the blankface.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5675"><span class="datestr">at August 02, 2021 08:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3764738535229441946">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2021/08/do-four-colors-suffice.html">Do Four Colors Suffice?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>(Guest Post by David Marcus)</p><p><i>Comment by Bill:</i> Haken and Appel proved that all planar maps are 4-colorable. Or did they? David Marcus emailed me that its not quite true and I asked him to post on it, so here it is. The meta point is that math can be very subtle.</p><p>And now <i>David Marcus's post:</i></p><p>Is the Four Color Map Theorem true?</p><p>It is commonly believed that the Four Color Map Theorem says that <i>four colors suffice to color a planar</i> <i>map</i>. While this is true for any map a non-mathematician would dream up, it is not true for maps a mathematician might dream up without some restriction on the regions that are allowed. This is shown in Hud Hudson's <a href="https://www.jstor.org/stable/pdf/3647828.pdf">Four Colors Do Not Suffice</a> which appeared in the American Math Monthly, Volume 110,  No. 5, May 2003, pages 417--423. </p><p>Hudson's article is written in a very entertaining style. I recommend that you read it. He constructs a map consisting of six regions R1,...,R6.  Each region is bounded and path connected. There is a line segment B that is  in the boundary of all six regions.  So, six colors are needed, since all six regions share a common boundary. The construction is similar to the topologist's sine curve. For each i , the union of Ri and B is not path connected. Hudson also shows that for any n, there is a map that requires at least n colors.</p><div style="clear: both; text-align: center;" class="separator"><a style="margin-left: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-oSGhAkWvF3M/YQf6m1FWr0I/AAAAAAAB9lQ/6E21cZ9aCnsEU-bh2PNr9P26C5_lcW1sQCLcBGAsYHQ/s737/6%2Bcolors.png"><img src="https://1.bp.blogspot.com/-oSGhAkWvF3M/YQf6m1FWr0I/AAAAAAAB9lQ/6E21cZ9aCnsEU-bh2PNr9P26C5_lcW1sQCLcBGAsYHQ/s320/6%2Bcolors.png" border="0" width="320" height="222" /></a></div><br /><p>Hudson thus disproves the following statement:</p><div><div>1)  Four colors are sufficient to color any map drawn in the plane or on a sphere so that no two regions with a common boundary line are colored with the same color.</div><div><br /></div><div>Appel and Haken actually proved the following:</div><div><br /></div><div>2) Four colors are sufficient to color any planar graph so that no two vertices connected by an edge are colored with the same color.</div></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2021/08/do-four-colors-suffice.html"><span class="datestr">at August 01, 2021 09:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=21845">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2021/08/01/mathematical-news-to-cheer-you-up/">Mathematical news to cheer you up</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h3><img width="592" alt="Anna-Kiesenhofer-Olympics-2021-930x620" src="https://gilkalai.files.wordpress.com/2021/08/anna-kiesenhofer-olympics-2021-930x620-1.webp" class="alignnone  wp-image-21856" height="395" /></h3>
<h3>1.  <span class="d2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j keod5gw0 nxhoafnm aigsh9s9 d3f4x2em fe6kdd0r mau55g9w c8b282yb iv3no6db jq4qci2q a3bd9o3v knj5qynh oo9gr5id hzawbc8m" dir="auto">Anna Kiesenhofer, a PhD mathematician researching PDEs at Ecole Polytechnique Federale Lausanne (EPFL), won the gold medal in the women’s bicycle road race at the Olympics.</span></h3>
<p>Here are two trivia question: a) Which hero of a recent post over here is related to <span class="d2edcug0 hpfvmrgz qv66sw1b c1et5uql lr9zc1uh a8c37x1j keod5gw0 nxhoafnm aigsh9s9 d3f4x2em fe6kdd0r mau55g9w c8b282yb iv3no6db jq4qci2q a3bd9o3v knj5qynh oo9gr5id hzawbc8m" dir="auto">Kiesenhofer’s mathematical side? b) Name another famous connection between EPFL-mathematics and sport. <br /></span></p>
<h3>2. János Nagy and Péter Pál Pach <a href="https://arxiv.org/abs/2107.03956">proved the Alon-Jaeger-Tarsi conjecture via group ring identities</a></h3>
<blockquote>
<p><em>The abstract says it all: In this paper we resolve the Alon-Jaeger-Tarsi conjecture for sufficiently large primes. Namely, we show that for any finite field <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="texatom" id="MathJax-Span-3"><span class="mrow" id="MathJax-Span-4"><span class="mi" id="MathJax-Span-5">F</span></span></span></span></span></span> of size <span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-6"><span class="mrow" id="MathJax-Span-7"><span class="mn" id="MathJax-Span-8">61</span><span class="mo" id="MathJax-Span-9">&lt;</span><span class="texatom" id="MathJax-Span-10"><span class="mrow" id="MathJax-Span-11"><span class="mo" id="MathJax-Span-12">|</span></span></span><span class="texatom" id="MathJax-Span-13"><span class="mrow" id="MathJax-Span-14"><span class="mi" id="MathJax-Span-15">F</span></span></span><span class="texatom" id="MathJax-Span-16"><span class="mrow" id="MathJax-Span-17"><span class="mo" id="MathJax-Span-18">|</span></span></span><span class="mo" id="MathJax-Span-19">≠</span><span class="mn" id="MathJax-Span-20">79</span></span></span></span> and any nonsingular matrix <span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-21"><span class="mrow" id="MathJax-Span-22"><span class="mi" id="MathJax-Span-23">M</span></span></span></span> over <span class="MathJax" id="MathJax-Element-4-Frame"><span class="math" id="MathJax-Span-24"><span class="mrow" id="MathJax-Span-25"><span class="texatom" id="MathJax-Span-26"><span class="mrow" id="MathJax-Span-27"><span class="mi" id="MathJax-Span-28">F</span></span></span></span></span></span> there exists a vector <span class="MathJax" id="MathJax-Element-5-Frame"><span class="math" id="MathJax-Span-29"><span class="mrow" id="MathJax-Span-30"><span class="mi" id="MathJax-Span-31">x</span></span></span></span> such that neither <span class="MathJax" id="MathJax-Element-6-Frame"><span class="math" id="MathJax-Span-32"><span class="mrow" id="MathJax-Span-33"><span class="mi" id="MathJax-Span-34">x</span></span></span></span> nor <span class="MathJax" id="MathJax-Element-7-Frame"><span class="math" id="MathJax-Span-35"><span class="mrow" id="MathJax-Span-36"><span class="mi" id="MathJax-Span-37">A</span><span class="mi" id="MathJax-Span-38">x</span></span></span></span> has a 0 component.</em></p>
</blockquote>
<h3>3. Michael Simkin asymptotically solved <a href="https://arxiv.org/abs/2107.13460">the <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" />-queens problem!</a> (We mentioned this classic problem and earlier progress by Zur Luria<a href="https://gilkalai.wordpress.com/2018/05/10/zur-luria-on-the-n-queens-problem/"> in this post</a>.)</h3>
<blockquote>
<p><em>Abstract: The <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" />-queens problem is to determine <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal+Q%7D%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="{\mathcal Q}(n)" class="latex" />, the number of ways to place <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" /> mutually non-threatening queens on an <img src="https://s0.wp.com/latex.php?latex=n+%5Ctimes+n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n \times n" class="latex" /> board. We show that there exists a constant α=1.942±3×10<sup>-3</sup> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal+Q%7D%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="{\mathcal Q}(n)" class="latex" /><img src="https://s0.wp.com/latex.php?latex=%3D%28%281+%5Cpm+o%281%29%29n+e+%5E%7B-%5Calpha%7D%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="=((1 \pm o(1))n e ^{-\alpha})^n" class="latex" />. The constant α is characterized as the solution to a convex optimization problem in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal+P%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="{\mathcal P}" class="latex" />([−1/2,1/2]<sup>2</sup>), the space of Borel probability measures on the square. The chief innovation is the introduction of limit objects for <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" />-queens configurations, which we call “queenons”. These are a convex set in <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal+P&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\mathcal P" class="latex" />([−1/2,1/2]<sup>2</sup>). We define an entropy function that counts the number of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" />-queens configurations that approximate a given queenon. The upper bound uses the entropy method. For the lower bound we describe a randomized algorithm that constructs a configuration near a prespecified queen on and whose entropy matches that found in the upper bound. The enumeration of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" />-queens configurations is then obtained by maximizing the (concave) entropy function in the space of queenons. Along the way we prove a large deviations principle for n-queens configurations that can be used to study their typical structure.</em></p>
</blockquote>
<p><img width="1600" alt="sun" src="https://gilkalai.files.wordpress.com/2021/08/sun.jpeg" class="alignnone size-full wp-image-21875" height="1200" /></p>
<p>Intermission: the sun over Tel Aviv sea</p>
<h3 class="title mathjax">4. Boris Bukh demonstrated <a href="https://arxiv.org/abs/2107.04167">Extremal graphs without exponentially-small bicliques</a></h3>
<blockquote>
<p><em>Abstract: The Turán problem asks for the largest number of edges in an $latex <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">n$</span></span></span></span>-vertex graph not containing a fixed forbidden subgraph <span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-4"><span class="mrow" id="MathJax-Span-5"><span class="mi" id="MathJax-Span-6">F</span></span></span></span>. We construct a new family of graphs not containing<span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-7"><span class="mrow" id="MathJax-Span-8"><span class="msubsup" id="MathJax-Span-9"><span class="mi" id="MathJax-Span-10"></span><span class="texatom" id="MathJax-Span-11"><span class="mrow" id="MathJax-Span-12"><span class="mi" id="MathJax-Span-13"></span><span class="mo" id="MathJax-Span-14"></span><span class="mi" id="MathJax-Span-15"> <img src="https://s0.wp.com/latex.php?latex=K_%7Bs%2Ct%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="K_{s,t}" class="latex" /></span></span></span></span></span></span></span>, for <span class="MathJax" id="MathJax-Element-4-Frame"><span class="math" id="MathJax-Span-16"><span class="mrow" id="MathJax-Span-17"><span class="mi" id="MathJax-Span-18"></span><span class="mo" id="MathJax-Span-19"></span><span class="msubsup" id="MathJax-Span-20"><span class="mi" id="MathJax-Span-21"></span><span class="mi" id="MathJax-Span-22"><img src="https://s0.wp.com/latex.php?latex=t%3DC%5Es&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="t=C^s" class="latex" /></span></span></span></span></span>, with  <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%5E%7B2-1%2Fs%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\Omega (n^{2-1/s})" class="latex" /> edges matching the upper bound of Kövári, Sós and Turán. </em></p>
</blockquote>
<h3 class="title mathjax">5. Michael Capalbo, <a href="https://link.springer.com/content/pdf/10.1007/s00493-020-3989-0.pdf">Explicit 𝑁-vertex graphs with maximum degree 𝐾 and diameter [1+𝑜(1)]log<sub>𝐾-1</sub> 𝑁 for each 𝐾-1 a prime power</a>,</h3>
<blockquote>
<p><em>Abstract:   Here we first present the solution of a long-standing open question–the explicit construction of an infinite family of N-vertex cubic graphs that have diameter [1+o(1)]log<sub>2</sub> N. We then extend the techniques to construct, for each K of the form 2<sup>s</sup>+1 or K=p<sup>s</sup>+1; s an integer and p a prime, an infinite family of K-regular graphs on N vertices with diameter [1+o(1)]log<sub>K−1</sub> N.</em></p>
</blockquote>
<p>I missed this breakthrough in STOC 2019 but now it appeared in Combinatorica, and Nati told me about it.</p>
<h3 class="title mathjax">6.  A beautiful survey article: <a href="https://arxiv.org/abs/2107.06371">Intersection Problems in Extremal Combinatorics: Theorems, Techniques and Questions Old and New</a>, by David Ellis,</h3>
<blockquote>
<p><em>Abstract: The study of intersection problems in Extremal Combinatorics dates back perhaps to 1938, when Paul Erdős, Chao Ko and Richard Rado proved the (first) `Erdős-Ko-Rado theorem’ on the maximum possible size of an intersecting family of <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">k</span></span></span></span>-element subsets of a finite set. Since then, a plethora of results of a similar flavour have been proved, for a range of different mathematical structures, using a wide variety of different methods. Structures studied in this context have included families of vector subspaces, families of graphs, subsets of finite groups with given group actions, and of course uniform hypergraphs with stronger or weaker intersection conditions imposed. The methods used have included purely combinatorial ones such as shifting/compressions, algebraic methods (including linear-algebraic, Fourier analytic and representation-theoretic), and more recently, analytic, probabilistic and regularity-type methods. As well as being natural problems in their own right, intersection problems have connections with many other parts of Combinatorics and with Theoretical Computer Science (and indeed with many other parts of Mathematics), both through the results themselves, and the methods used. In this survey paper, we discuss both old and new results (and both old and new methods), in the field of intersection problems. Many interesting open problems remain; we will discuss several. For expositional and pedagogical purposes, we also take this opportunity to give slightly streamlined versions of proofs (due to others) of several classical results in the area. This survey is intended to be useful to PhD students, as well as to more established researchers. It is a personal perspective on the field, and is not intended to be exhaustive; we apologise for any omissions. It is an expanded version of a paper that will appear in the Proceedings of the 29th British Combinatorial Conference.</em></p>
</blockquote>
<h3 class="title mathjax">7.  <a href="http://ecajournal.haifa.ac.il/Volume2022/ECA2022_S3I7.pdf">An interview with me</a>; interviewer Toufik Mansour.</h3>
<p> </p>
<div class="authors"> </div>
<div> </div>


<p></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2021/08/01/mathematical-news-to-cheer-you-up/"><span class="datestr">at August 01, 2021 07:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/114">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/114">TR21-114 |  The Space Complexity of Sum Labelling | 

	Henning Fernau, 

	Kshitij Gajjar</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A graph is called a sum graph if its vertices can be labelled by distinct positive integers such that there is an edge between two vertices if and only if the sum of their labels is the label of another vertex of the graph. Most papers on sum graphs consider combinatorial questions like the minimum number of isolated vertices that need to be added to a given graph to make it a sum graph. In this paper, we initiate the study of sum graphs from the viewpoint of computational complexity. Notice that every $n$-vertex sum graph can be represented by a sorted list of $n$ positive integers where edge queries can be answered in $O(\log n)$ time. Therefore, limiting the size of the vertex labels upper-bounds the space complexity of storing the graph in the database.

We show that every $n$-vertex, $m$-edge, $d$-degenerate graph can be made a sum graph by adding at most $m$ isolated vertices to it, such that the size of each vertex label is at most $O(n^2d)$. This enables us to store the graph using $O(m\log n)$ bits of memory. For sparse graphs (graphs with $O(n)$ edges), this matches the trivial lower bound of $\Omega(n\log n)$. As planar graphs and forests have constant degeneracy, our result implies an upper bound of $O(n^2)$ on their label size. The previously best known upper bound on the label size of general graphs with the minimum number of isolated vertices was $O(4^n)$, due to Kratochvil, Miller &amp; Nguyen (2001). Furthermore, their proof was existential, whereas our labelling can be constructed in polynomial time.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/114"><span class="datestr">at August 01, 2021 07:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
