<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at July 18, 2019 07:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07574">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07574">Improved Algorithms for Time Decay Streams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Braverman:Vladimir.html">Vladimir Braverman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lang:Harry.html">Harry Lang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Ullah:Enayat.html">Enayat Ullah</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Samson.html">Samson Zhou</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07574">PDF</a><br /><b>Abstract: </b>In the time-decay model for data streams, elements of an underlying data set
arrive sequentially with the recently arrived elements being more important. A
common approach for handling large data sets is to maintain a \emph{coreset}, a
succinct summary of the processed data that allows approximate recovery of a
predetermined query. We provide a general framework that takes any
offline-coreset and gives a time-decay coreset for polynomial time decay
functions.
</p>
<p>We also consider the exponential time decay model for $k$-median clustering,
where we provide a constant factor approximation algorithm that utilizes the
online facility location algorithm. Our algorithm stores
$\mathcal{O}(k\log(h\Delta)+h)$ points where $h$ is the half-life of the decay
function and $\Delta$ is the aspect ratio of the dataset. Our techniques extend
to $k$-means clustering and $M$-estimators as well.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07574"><span class="datestr">at July 18, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07471">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07471">Interesting Open Problem Related to Complexity of Computing the Fourier Transform and Group Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ailon:Nir.html">Nir Ailon</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07471">PDF</a><br /><b>Abstract: </b>The Fourier Transform is one of the most important linear transformations
used in science and engineering. Cooley and Tukey's Fast Fourier Transform
(FFT) from 1964 is a method for computing this transformation in time $O(n\log
n)$. From a lower bound perspective, relatively little is known. Ailon shows in
2013 an $\Omega(n\log n)$ bound for computing the normalized Fourier Transform
assuming only unitary operations on pairs of coordinates is allowed. The goal
of this document is to describe a natural open problem that arises from this
work, which is related to group theory, and in particular to representation
theory.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07471"><span class="datestr">at July 18, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07441">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07441">Maximum rectilinear convex subsets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gonz=aacute=lez=Aguilar:Hern=aacute=n.html">Hernán González-Aguilar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Orden:David.html">David Orden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/P=eacute=rez=Lantero:Pablo.html">Pablo Pérez-Lantero</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rappaport:David.html">David Rappaport</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seara:Carlos.html">Carlos Seara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tejel:Javier.html">Javier Tejel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Urrutia:Jorge.html">Jorge Urrutia</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07441">PDF</a><br /><b>Abstract: </b>Let $P$ be a set of $n$ points in the plane. We consider a variation of the
classical Erd\H{o}s-Szekeres problem, presenting efficient algorithms with
$O(n^3)$ running time and $O(n^2)$ space complexity that compute: (1) A subset
$S$ of $P$ such that the boundary of the rectilinear convex hull of $S$ has the
maximum number of points from $P$, (2) a subset $S$ of $P$ such that the
boundary of the rectilinear convex hull of $S$ has the maximum number of points
from $P$ and its interior contains no element of $P$, (3) a subset $S$ of $P$
such that the rectilinear convex hull of $S$ has maximum area and its interior
contains no element of $P$, and (4) when each point of $P$ is assigned a
weight, positive or negative, a subset $S$ of $P$ that maximizes the total
weight of the points in the rectilinear convex hull of $S$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07441"><span class="datestr">at July 18, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07367">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07367">Almost tight bound on the query complexity of generalized Simon's problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Ye:Zekun.html">Zekun Ye</a>, Yunqi Huang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yuyi.html">Yuyi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Lvzhou.html">Lvzhou Li</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07367">PDF</a><br /><b>Abstract: </b>Simon's problem played an important role in the history of quantum
algorithms, as it inspired Shor to discover the celebrated quantum algorithm
solving integer factorization in polynomial time. Besides, the quantum
algorithm for Simon's problem has been recently applied to break symmetric
cryptosystems. Generalized Simon's problem is a natural extension of Simon's
problem: Given a function $f:\{0,1\}^n \to \{0,1\}^m$ with $n \le m$ and the
promise that there exists a subgroup $S \le \mathbb{Z}_2^n$ of rank $k$ s.t.
for any $s, x\in\{0,1\}^n, f(x) = f(x\oplus s)$ iff $s\in S$, the goal is to
find $S$. It is not difficult to design a quantum algorithm for solving this
problem exactly with query complexity of $O(n-k)$. However, so far it is not
clear what is the classical deterministic query complexity of this problem. %
Therefore, it is interesting and nontrivial to consider that, not only for
clarifying the gap between quantum and classical computing on this problem, but
also from the viewpoint of classical computing.
</p>
<p>In this paper, we first prove that any classical deterministic algorithm
solving generalized Simon's problem has to query at least $\Omega(\sqrt{k \cdot
2^{n-k}})$ values, clarifying the gap between quantum and classical computing
on this problem. On the other hand, we devise a deterministic algorithm with
query complexity of $O(\sqrt{k \cdot 2^{n - k}})$ in most cases. Therefore, the
obtained bound $\Theta(\sqrt{k \cdot 2^{n-k}})$ is almost optimal, which fills
the blank of classical deterministic query complexity for generalized Simon's
problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07367"><span class="datestr">at July 18, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07230">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07230">The Complexity of Partial Function Extension for Coverage Functions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhaskar:Umang.html">Umang Bhaskar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Gunjan.html">Gunjan Kumar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07230">PDF</a><br /><b>Abstract: </b>Coverage functions are an important subclass of submodular functions, finding
applications in machine learning, game theory, social networks, and facility
location. We study the complexity of partial function extension to coverage
functions. That is, given a partial function consisting of a family of subsets
of $[m]$ and a value at each point, does there exist a coverage function
defined on all subsets of $[m]$ that extends this partial function? Partial
function extension is previously studied for other function classes, including
boolean functions and convex functions, and is useful in many fields, such as
obtaining bounds on learning these function classes.
</p>
<p>We show that determining extendibility of a partial function to a coverage
function is NP-complete, establishing in the process that there is a
polynomial-sized certificate of extendibility. The hardness also gives us a
lower bound for learning coverage functions. We then study two natural notions
of approximate extension, to account for errors in the data set. The two
notions correspond roughly to multiplicative point-wise approximation and
additive $L_1$ approximation. We show upper and lower bounds for both notions
of approximation. In the second case we obtain nearly tight bounds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07230"><span class="datestr">at July 18, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06914">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06914">Persistent homology analysis of multiqubit entanglement</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mengoni:Riccardo.html">Riccardo Mengoni</a>, Alessandra DI Pierro, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Memarzadeh:Laleh.html">Laleh Memarzadeh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mancini:Stefano.html">Stefano Mancini</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06914">PDF</a><br /><b>Abstract: </b>We introduce a homology-based technique for the analysis of multiqubit state
vectors. In our approach, we associate state vectors to data sets by
introducing a metric-like measure in terms of bipartite entanglement, and
investigate the persistence of homologies at different scales. This leads to a
novel classification of multiqubit entanglement. The relative occurrence
frequency of various classes of entangled states is also shown.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06914"><span class="datestr">at July 18, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06857">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06857">Labelings vs. Embeddings: On Distributed Representations of Distances</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filtser:Arnold.html">Arnold Filtser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gottlieb:Lee=Ad.html">Lee-Ad Gottlieb</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krauthgamer:Robert.html">Robert Krauthgamer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06857">PDF</a><br /><b>Abstract: </b>We investigate for which metric spaces the performance of distance labeling
and of $\ell_\infty$-embeddings differ, and how significant can this difference
be. Recall that a distance labeling is a distributed representation of
distances in a metric space $(X,d)$, where each point $x\in X$ is assigned a
succinct label, such that the distance between any two points $x,y \in X$ can
be approximated given only their labels. A highly structured special case is an
embedding into $\ell_\infty$, where each point $x\in X$ is assigned a vector
$f(x)$ such that $\|f(x)-f(y)\|_\infty$ is approximately $d(x,y)$. The
performance of a distance labeling or an $\ell_\infty$-embedding is measured
via its distortion and its label-size/dimension.
</p>
<p>We also study the analogous question for the prioritized versions of these
two measures. Here, a priority order $\pi=(x_1,\dots,x_n)$ of the point set $X$
is given, and higher-priority points should have shorter labels. Formally, a
distance labeling has prioritized label-size $\alpha(.)$ if every $x_j$ has
label size at most $\alpha(j)$. Similarly, an embedding $f: X \to \ell_\infty$
has prioritized dimension $\alpha(.)$ if $f(x_j)$ is non-zero only in the first
$\alpha(j)$ coordinates. In addition, we compare these their prioritized
measures to their classical (worst-case) versions.
</p>
<p>We answer these questions in several scenarios, uncovering a surprisingly
diverse range of behaviors. First, in some cases labelings and embeddings have
very similar worst-case performance, but in other cases there is a huge
disparity. However in the prioritized setting, we most often find a strict
separation between the performance of labelings and embeddings. And finally,
when comparing the classical and prioritized settings, we find that the
worst-case bound for label size often ``translates'' to a prioritized one, but
also a surprising exception to this rule.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06857"><span class="datestr">at July 18, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06814">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06814">A Quantum-inspired Algorithm for General Minimum Conical Hull Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Yuxuan.html">Yuxuan Du</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hsieh:Min=Hsiu.html">Min-Hsiu Hsieh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Tongliang.html">Tongliang Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Dacheng.html">Dacheng Tao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06814">PDF</a><br /><b>Abstract: </b>A wide range of fundamental machine learning tasks that are addressed by the
maximum a posteriori estimation can be reduced to a general minimum conical
hull problem. The best-known solution to tackle general minimum conical hull
problems is the divide-and-conquer anchoring learning scheme (DCA), whose
runtime complexity is polynomial in size. However, big data is pushing these
polynomial algorithms to their performance limits. In this paper, we propose a
sublinear classical algorithm to tackle general minimum conical hull problems
when the input has stored in a sample-based low-overhead data structure. The
algorithm's runtime complexity is polynomial in the rank and polylogarithmic in
size. The proposed algorithm achieves the exponential speedup over DCA and,
therefore, provides advantages for high dimensional problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06814"><span class="datestr">at July 17, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06741">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06741">Full Tilt: Universal Constructors for General Shapes with Uniform External Forces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Balanza=Martinez:Jose.html">Jose Balanza-Martinez</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Caballero:David.html">David Caballero</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cantu:Angel_A=.html">Angel A. Cantu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garcia:Luis_Angel.html">Luis Angel Garcia</a>, Timothy Gomez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luchsinger:Austin.html">Austin Luchsinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reyes:Rene.html">Rene Reyes</a>, Robert Schweller, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wylie:Tim.html">Tim Wylie</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06741">PDF</a><br /><b>Abstract: </b>We investigate the problem of assembling general shapes and patterns in a
model in which particles move based on uniform external forces until they
encounter an obstacle. While previous work within this model of assembly has
focused on designing a specific board configuration for the assembly of a
specific given shape, we propose the problem of designing universal
configurations that are capable of constructing a large class of shapes and
patterns. In particular, for given integers $h,w$, we show that there exists a
strongly universal configuration (no excess particles) with $\mathcal{O}(hw)$
$1 \times 1$ slidable particles that can be reconfigured to build any $h \times
w$ patterned rectangle. We then expand this result to show that there exists a
weakly universal configuration that can build any $h \times w$-bounded size
connected shape. Following these results, we go on to show the existence of a
strongly universal configuration which can assemble any shape within a
previously studied ``drop'' class, while using quadratically less space than
previous results.
</p>
<p>Finally, we include a study of the complexity of motion planning in this
model. We consider the problems of deciding if a board location can be occupied
by any particle (occupancy problem), deciding if a specific particle may be
relocated to another position (relocation problem), and deciding if a given
configuration of particles may be transformed into a second given configuration
(reconfiguration problem). We show all of these problems to be PSPACE-complete
with the allowance of a single $2\times 2$ polyomino in addition to $1\times 1$
tiles. We further show that relocation and occupancy remain PSPACE-complete
even when the board geometry is a simple rectangle if domino polyominoes are
included.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06741"><span class="datestr">at July 18, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blogs.princeton.edu/imabandit/?p=1397">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/bubeck.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/">Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part II</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><a href="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?ssl=1" class="liimagelink"><img width="639" alt="" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?resize=639%2C324&amp;ssl=1" class="alignnone wp-image-1399" height="324" /></a></p>
<p>This is a continuation of <a href="https://lear.inrialpes.fr/people/mairal/" class="liinternal">Julien Mairal</a>‘s guest post on CNNs, see <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" class="liinternal">part I here.</a></p>
<p><strong>Stability to deformations of convolutional neural networks</strong></p>
<p>In their <a href="http://proceedings.mlr.press/v70/zhang17f/zhang17f.pdf" class="lipdf">ICML paper</a> Zhang et al. introduce a functional space for CNNs with one layer, by noticing that for some dot-product kernels, smoothed variants of rectified linear unit activation functions (ReLU) live in the corresponding RKHS, see also <a href="http://proceedings.mlr.press/v48/zhangd16.pdf" class="lipdf">this paper</a> and <a href="https://www.cs.cornell.edu/~sridharan/sicomp.pdf" class="lipdf">that one</a>. By following a similar reasoning with multiple layers, it is then possible to show that the functional space described in <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" class="liinternal">part I</a> <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3e321e5f0406c9879f25b6b1d69a5fc3_l3.png?resize=298%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="20" width="298" alt="\{ f_w: x \mapsto \langle w , \Phi_n(x_0) \rangle; w \in L^2(\Omega,\mathcal{H}_n) \}" class="ql-img-inline-formula " /> contains CNNs with such smoothed ReLU, and that the norm <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-62e1a48032624994ba16c4e26421676e_l3.png?resize=34%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="34" alt="\|f_w\|" class="ql-img-inline-formula " /> of such networks can be controlled by the spectral norms of filter matrices. This is consistent with previous measures of complexity for CNNs, see <a href="https://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks.pdf" class="lipdf">this paper</a> by Bartlett et al.</p>
<p>A perhaps more interesting finding is that the abstract representation <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="45" alt="\Phi_n(x)" class="ql-img-inline-formula " />, which only depends on the network architecture, may provide near-translation invariance and stability to small image deformations while preserving information—that is, <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="10" alt="x" class="ql-img-inline-formula " /> can be recovered from <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="45" alt="\Phi_n(x)" class="ql-img-inline-formula " />. The original characterization we use was introduced by Mallat in <a href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf" class="lipdf">his paper</a> on the scattering transform—a multilayer architecture akin to CNNs based on wavelets, and was extended to <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="21" alt="\Phi_n" class="ql-img-inline-formula " /> by Alberto Bietti, who should be credited for all the hard work here.</p>
<p>Our goal is to understand under which conditions it is possible to obtain a representation that (i) is near-translation invariant, (ii) is stable to deformations, (iii) preserves signal information. Given a <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2e9ea203bbd77c5cd8bee967e2729d8b_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="15" width="20" alt="C^1" class="ql-img-inline-formula " />-diffeomorphism <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c6f8f1dde2ee4682653c2a6b37d8a42d_l3.png?resize=93%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="93" alt="\tau: \mathbb{R}^2 \to \mathbb{R}^2" class="ql-img-inline-formula " /> and denoting by <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-835d9f864f712213ee317332b3f3675a_l3.png?resize=167%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="167" alt="L_\tau x(u) = x(u-\tau(u))" class="ql-img-inline-formula " /> its action operator (for an image defined on the continuous domain <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="15" width="20" alt="\mathbb{R}^2" class="ql-img-inline-formula " />), the main stability bound we obtain is the following one, see Theorem 7 in <a href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf" class="lipdf">Mallat’s paper</a> if <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-758b3cac273166048ed1879acf427860_l3.png?resize=104%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="104" alt="\|\nabla \tau\|_\infty \leq 1/2" class="ql-img-inline-formula " />, for all <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="10" alt="x" class="ql-img-inline-formula " />,</p>
<p style="line-height: 43px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-51041d0067a72066938e31b1f00529fa_l3.png?resize=455%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="43" width="455" alt="\[ \| \Phi_n(L_\tau x) - \Phi_n(x)\| \leq \left ( C_1 (1+n) \|\nabla \tau\|_\infty + \frac{C_2}{\sigma_n} \|\tau\|_\infty \right) \|x\|, \]" class="ql-img-displayed-equation " /></p>
<p>where <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-08d1f29fa9c0981e916619b6c6bc7eee_l3.png?resize=48%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="48" alt="C_1, C_2" class="ql-img-inline-formula " /> are universal constants, <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="18" alt="\sigma_n" class="ql-img-inline-formula " /> is the scale parameter of the pooling operator <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e1872c7d7a65e0dc92f8a4a04608b88a_l3.png?resize=21%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="21" alt="A_n" class="ql-img-inline-formula " /> corresponding to the “amount of pooling” performed up to the last layer, <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c1a5effb150d36de3c7074eaa980c357_l3.png?resize=39%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="39" alt="\|\tau\|_\infty" class="ql-img-inline-formula " /> is the maximum pixel displacement and <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab4c5d3fe8fd25af25beb4f58a55c938_l3.png?resize=53%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="53" alt="\|\nabla \tau\|_\infty" class="ql-img-inline-formula " /> represents the maximum amount of deformation, see <a href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf" class="lipdf">the paper</a> for the precise definitions of all these quantities. Note that when <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b732bf857c5f04c7d10dda247f1a5022_l3.png?resize=85%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="85" alt="C_2/\sigma_n \to 0" class="ql-img-inline-formula " />, the representation <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="21" alt="\Phi_n" class="ql-img-inline-formula " /> becomes translation invariant: indeed, consider the particular case of <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3af6c51247895b176bb502f0ee0857ee_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="10" alt="\tau" class="ql-img-inline-formula " /> being a translation, then <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aa1278a7149925a4f299de0dbb85cec0_l3.png?resize=57%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="14" width="57" alt="\nabla \tau=0" class="ql-img-inline-formula " /> and <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cd1d650abd9970e357384c0653960577_l3.png?resize=186%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="186" alt="\|\Phi_n(L_\tau x) - \Phi_n(x)\| \to 0" class="ql-img-inline-formula " />.</p>
<p>The stability bound and a few additional results tell us a few things about the network architecture: (a) small patches lead to more stable representations (the dependency is hidden in <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-782c65cbd411fb8862688afc92bc1eea_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="19" alt="C_1" class="ql-img-inline-formula " />); (b) signal preservation for discrete signals requires small subsampling factors (and thus small pooling) between layers. In such a setting, the scale parameter <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="18" alt="\sigma_n" class="ql-img-inline-formula " /> still grows exponentially with <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="11" alt="n" class="ql-img-inline-formula " /> and near translation invariance may be achieved with several layers.</p>
<p>Interestingly, we may now come back to the Cauchy-Schwarz inequality from part 1, and note that if <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="21" alt="\Phi_n" class="ql-img-inline-formula " /> is stable, the RKHS norm <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-afe70184469e7e3a14405a7193eedf29_l3.png?resize=24%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="24" alt="\|f\|" class="ql-img-inline-formula " /> is then a natural quantity that provides stability to deformations to the prediction function <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="10" alt="f" class="ql-img-inline-formula " />, in addition to measuring model complexity in a traditional sense.</p>
<p><strong>Feature learning in RKHSs and convolutional kernel networks</strong></p>
<p>The previous paragraph is devoted to the characterization of convolutional architectures such as CNNs but the previous kernel construction can in fact be used to derive more traditional kernel methods. After all, why should one spend efforts defining a kernel between images if not to use it?</p>
<p>This can be achieved by considering finite-dimensional approximations of the previous feature maps. In order to shorten the presentation, we simply describe the main idea based on the Nystrom approximation and refer to <a href="http://papers.nips.cc/paper/6184-end-to-end-kernel-learning-with-supervised-convolutional-kernel-networks.pdf" class="lipdf">the paper</a> for more details. Approximating the infinite-dimensional feature maps <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="x_k" class="ql-img-inline-formula " /> (see the figure at the top of <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" class="liinternal">part I</a>) can be done by projecting each point in <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_k" class="ql-img-inline-formula " /> onto a <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="17" alt="p_k" class="ql-img-inline-formula " />-dimensional subspace <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="20" alt="\mathcal{F}_k" class="ql-img-inline-formula " /> leading to a finite-dimensional feature map <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="17" alt="\tilde{x}_k" class="ql-img-inline-formula " /> akin to CNNs, see the figure at the top of the post.</p>
<p>By parametrizing <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5dd8802df8efddb9acc5056af47339d7_l3.png?resize=297%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="20" width="297" alt="\mathcal{F}_k=\text{span}(\varphi_k(z_1),\varphi_k(z_2),\ldots,\varphi_k(z_{p_k}))" class="ql-img-inline-formula " /> with <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="17" alt="p_k" class="ql-img-inline-formula " /> anchor points <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4614e1cdba47dc6a6db7957fb1d82632_l3.png?resize=123%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="123" alt="Z=[z_1,\ldots,z_{p_k}]" class="ql-img-inline-formula " />, and using a dot-product kernel, a patch <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="9" alt="z" class="ql-img-inline-formula " /> from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="35" alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " /> is encoded through the mapping function</p>
<p style="line-height: 43px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc43da382f024d96cb50e3dc3f051d6f_l3.png?resize=306%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="43" width="306" alt="\[ \psi_k(z) = \|z\| \kappa_k( Z^\top Z)^{-1/2} \kappa_k\left( Z^\top \frac{z}{\|z\|} \right), \]" class="ql-img-displayed-equation " /></p>
<p>where <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="\kappa_k" class="ql-img-inline-formula " /> is applied pointwise. Then, computing <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="17" alt="\tilde{x}_k" class="ql-img-inline-formula " /> from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="35" alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " /> admits a CNN interpretation, where only the normalization and the matrix multiplication by <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a74cffbbd51922298a13f864fbedaa98_l3.png?resize=103%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="21" width="103" alt="\kappa_k( Z^\top Z)^{-1/2}" class="ql-img-inline-formula " /> are not standard operations. It remains now to choose the anchor points:</p>
<ul>
<li><strong>kernel approximation:</strong> a first approach consists of using a variant of the Nystrom method, see <a href="https://papers.nips.cc/paper/1866-using-the-nystrom-method-to-speed-up-kernel-machines.pdf" class="lipdf">this paper</a> and <a href="http://home.cse.ust.hk/~twinsen/nystrom.pdf" class="lipdf">that one</a>. When plugging the corresponding image representation in a linear classifier, the resulting approach behaves as a classical kernel machine. Empirically, we observe that the higher the number of anchor points, the better the kernel approximation, and the higher the accuracy. For instance, a two-layer network with a <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-81a4466abb5fecba81f8a3aa055a1a14_l3.png?resize=36%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="13" width="36" alt="300k" class="ql-img-inline-formula " />-dimensional representations achieves about <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0eea28372ada596bc618b4b94fee69ec_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="32" alt="86\%" class="ql-img-inline-formula " /> accuracy on CIFAR-10 without data augmentation (see <a href="https://gitlab.inria.fr/mairal/ckn-cudnn-matlab" class="liinternal">here</a>).</li>
<li><strong>back-propagation, feature selection</strong>: learning the anchor points <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc9f8fff9fd24060bc054e78f01d5bfb_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="12" alt="Z" class="ql-img-inline-formula " /> can also be done as in a traditional CNN, by optimizing them end-to-end. This allows using deeper lower-dimensional architectures and empirically seems to perform better when enough data is available, e.g., <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-659ab3cccda2422f955af880d20646cf_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="32" alt="92\%" class="ql-img-inline-formula " /> accuracy on CIFAR-10 with simple data augmentation. There, the subspaces <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="20" alt="\mathcal{F}_k" class="ql-img-inline-formula " /> are not learned anymore to provide the best kernel approximation, but the model seems to perform a sort of feature selection in each layer’s RKHS <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_k" class="ql-img-inline-formula " />, which is not well understood yet (This feature selection interpretation is due to my collaborator Laurent Jacob).</li>
</ul>
<p>Note that the first CKN model published <a href="https://papers.nips.cc/paper/5348-convolutional-kernel-networks.pdf" class="lipdf">here</a> was based on a different approximation principle, which was not compatible with end-to-end training. We found this to be less scalable and effective.</p>
<p><strong>Other links between neural networks and kernel methods</strong></p>
<p>Finally, other links between kernels and infinitely-wide neural networks with random weights are classical, but they were not the topic of this blog post (they should be the topic of another one!). In a nutshell, for a large collection of weights distributions and nonlinear functions <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b4680e3f9e8274687d2d04f0a262ed00_l3.png?resize=76%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="13" width="76" alt="s: \mathbb{R} \to \mathbb{R}" class="ql-img-inline-formula " />, the following quantity admits an analytical form</p>
<p style="line-height: 22px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9144f2d0b847adb69db90629ed805148_l3.png?resize=229%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="22" width="229" alt="\[ K(x,x') = \E_{w}[ s(w^\top x) s(w^\top x')], \]" class="ql-img-displayed-equation " /></p>
<p>where the terms <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-da82e444bbc3a5e594b7edbf0b1ba3a0_l3.png?resize=56%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="56" alt="s(w^\top x)" class="ql-img-inline-formula " /> may be seen as an infinitely-wide single-layer neural network. The first time such a relation appears is likely to be in <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf" class="liexternal">the PhD thesis</a> of Radford Neal with a Gaussian process interpretation, and it was revisited later by <a href="http://proceedings.mlr.press/v2/leroux07a/leroux07a.pdf" class="lipdf">Le Roux and Bengio</a> and by <a href="http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf" class="lipdf">Cho and Saul</a> with multilayer models.</p>
<p>In particular, when <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="8" alt="s" class="ql-img-inline-formula " /> is the rectified linear unit and <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="13" alt="w" class="ql-img-inline-formula " /> follows a Gaussian distribution, it is known that we recover the arc-cosine kernel. We may also note that <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf" class="lipdf">random Fourier features</a> also yield a similar interpretation.</p>
<p>Other important links have also been drawn recently between kernel regression and strongly over-parametrized neural networks, see <a href="http://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf" class="lipdf">this paper</a> and <a href="https://arxiv.org/pdf/1812.07956.pdf" class="lipdf">that one</a>, which is another exciting story.</p></div>







<p class="date">
by Sebastien Bubeck <a href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/"><span class="datestr">at July 17, 2019 04:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://minimizingregret.wordpress.com/?p=207">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/hazan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/">Boosting for Dynamical Systems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on <a href="https://arxiv.org/abs/1906.08720">this paper</a> </em></p>
<p>In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was almost correct. How is it that combining the opinions of laymen can somehow arrive at highly reasoned decisions, despite the weak judgment of individual members? This concept of harnessing wisdom from weak rules of thumb to form a highly accurate prediction rule, is the basis of ensemble methods and <b>boosting</b>. Boosting is a theoretically sound methodology that has transformed machine learning across a variety of applications; in classification and regression tasks, online learning, and many more.</p>
<p>In the case of online learning, examples for training a predictor are not available in advance, but are revealed one at a time. Online boosting combines a set of online prediction rules, or <i>weak learners. </i>At every time step, each weak learner outputs a prediction, suffers some loss and is then updated accordingly. The performance of an online learner is measured using the <i>regret</i> criterion, which compares the accumulated loss over time with that of the best fixed decision in hindsight. A <i>Boosting</i> algorithm can choose which examples are fed to each of the weak learners, as well as the losses they incur. Intuitively, the online booster can encourage some weak learners to become really good in predicting certain common cases, while allowing others to focus on edge cases that are harder to predict. Overall, the <a href="http://proceedings.mlr.press/v37/beygelzimer15.pdf">online</a> <a href="https://arxiv.org/abs/1506.04820">boosting</a> framework can achieve low regret guarantees based on the learners’ individual regret values.</p>
<p>However, online learning can become more challenging when our actions have consequences on the environment. This can be illustrated with the following experiment: imagine learning to balance a long pole on your hand. When you move your hand slightly, the pole tilts. You then move your hand in the opposite direction, and it bounces back and tilts to the other side. One jerk the wrong way might have you struggling for a good few seconds to rebalance. In other words, a <u>sequence of decisions</u> you made earlier determines whether or not the pole is balanced at any given time, rather than the single decision you make at that point.<img src="https://minimizingregret.files.wordpress.com/2019/07/image.jpeg?w=136&amp;h=129" title="" height="129" width="136" alt="" class=" aligncenter" /></p>
<p>More generally, consider cases when our environment has a <b>state, </b>and is in some sense “remembering” our past choices. A stateful framework, able to model a wide range of such phenomena, is a <i>dynamical system</i>. A dynamical system can be thought of as a function that determines, given the current state, what the state of the system will be in the next time step. Think of the physical dynamics that determines our pole’s position based on sequential hand movements. Other intuitive examples are the fluctuations of stock prices in the stock market, or the local weather temperatures; these can all be modeled with dynamical systems.</p>
<p>So how can boosting help us make better predictions for a dynamical system? In <a href="https://arxiv.org/abs/1906.08720">recent work</a> we propose an algorithm, which we refer to as DynaBoost, that achieves this goal. In the paper we provide theoretical regret bounds, as well as an empirical evaluation in a variety of applications, such as online control and time-series prediction.</p>
<p><b>Learning for Online Control</b></p>
<p>Control theory is a field of applied mathematics that deals with the control of various physical processes and engineering systems. The objective is to design an action rule, or <i>controller</i>, for a dynamical system such that steady state values are achieved quickly, and the system maintains stability.</p>
<p>Consider a simple Linear Dynamical System (LDS):</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D+%3D+A+x_t+%2B+B+u_t+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_{t+1} = A x_t + B u_t + w_t" class="latex" title="x_{t+1} = A x_t + B u_t + w_t" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=x_t%2Cu_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_t,u_t" class="latex" title="x_t,u_t" /> are the state and control values at time t, respectively. Assume a known transition dynamics specified by the matrices A and B, and an arbitrary disturbance to the system given by <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" />. The goal of the controller is to minimize a convex cost function <img src="https://s0.wp.com/latex.php?latex=c_t%28x_t%2Cu_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="c_t(x_t,u_t)" class="latex" title="c_t(x_t,u_t)" />.</p>
<p>A provably optimal controller for the Gaussian noise case (where <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" /> are normally distributed) and when the cost functions are quadratic, is the Linear Quadratic Regulator (LQR). LQR computes a pre-fixed matrix K such that <img src="https://s0.wp.com/latex.php?latex=u_t%5E%7BLQR%7D+%3D+K+x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t^{LQR} = K x_t" class="latex" title="u_t^{LQR} = K x_t" />. In other words, LQR computes a linear controller – which linearly maps the state into a control at every time step.</p>
<p>A <a href="http://proceedings.mlr.press/v97/agarwal19c/agarwal19c.pdf">recent advancement</a> in online control considers <i>arbitrary</i> disturbances, as opposed to normally distributed noise. In this more general setting, there is no closed form for the optimal controller. Instead, it is proposed to use a weighted sum of previously observed noises, i.e., <img src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%7D+%3D+K+x_t+%2B+%5Csum_%7Bi%3D1%7D%5EH+M_i+w_%7Bt-i%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} " class="latex" title="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} " /> , where <img src="https://s0.wp.com/latex.php?latex=M_1%2C...%2CM_H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="M_1,...,M_H" class="latex" title="M_1,...,M_H" /> are learned parameters, updated in an online fashion. This method is shown to attain vanishing average regret compared to the best fixed linear controller in hindsight, and is applicable for general convex cost functions as opposed to only quadratics.</p>
<p>Crucially, the state-dependent term <img src="https://s0.wp.com/latex.php?latex=Kx_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="Kx_t" class="latex" title="Kx_t" /> is not learned. Since the learned parameters of the above controller therefore considers only a fixed number of recent disturbances, we can apply existing <a href="http://ocobook.cs.princeton.edu/">online convex optimization</a> techniques developed for <a href="https://papers.nips.cc/paper/6025-online-learning-for-adversaries-with-memory-price-of-past-mistakes">learning with loss functions that have bounded memory</a>.</p>
<p><strong>Boosting for Online Control</strong></p>
<p>Using the insights described above to remove state in online control, we can now use techniques from online boosting. DynaBoost maintains multiple copies of the base-controller above, with each copy corresponding to one stage in boosting. At every time step, the control <img src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t" class="latex" title="u_t" /> is obtained from a convex combination of the base-controllers’ outputs <img src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%281%29%7D%2C...%2Cu_t%5E%7BWL%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t^{WL(1)},...,u_t^{WL(N)}" class="latex" title="u_t^{WL(1)},...,u_t^{WL(N)}" />. To update each base-controller’s parameters, DynaBoost feeds each controller with a <i>residual</i> <i>proxy </i>cost function, and seeks to obtain a minimizing point in the direction of the residual loss function’s gradient. Stability ensures that minimizing regret over the proxy costs (which have finite memory) suffices to minimize overall regret. See <a href="https://arxiv.org/abs/1906.08720">our paper</a> for the detailed description of the algorithm and its regret guarantees.</p>
<p><strong>Sanity check experiment</strong></p>
<p>We first conducted experiments for the standard LQR setting with i.i.d. Gaussian noise and known dynamics. We applied our boosting method to the non-optimal controller with learned parameters (Control-WL), and we observe that boosting improves its loss and achieves near-optimal performance (here the optimal controller is given by the fixed LQR solution). We have tested an LDS of different dimensions <img src="https://s0.wp.com/latex.php?latex=d+%3D+1%2C10%2C100&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="d = 1,10,100" class="latex" title="d = 1,10,100" />, and averaged results over multiple runs.</p>
<p><img width="624" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null.png?w=624&amp;h=182" title="" height="182" /></p>
<p><strong>Correlated noise experiment</strong></p>
<p>When the disturbances are not independently drawn, the LQR controller is not guaranteed to perform optimally. We experimented with two LDS settings with correlated disturbances in which (a) the disturbances <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" /> are generated from a Gaussian random-walk, and (b) where they are generated by a sine function applied to the time index. In these cases, boosted controllers perform better compared to the “weak” learned controller, and can also outperform the fixed LQR solution. We have also tested a Recurrent Neural Network, and observed that boosting is effective for RNNs as well.</p>
<p><img width="624" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-1.png?w=624&amp;h=266" title="" height="266" /></p>
<p><strong>Inverted Pendulum experiment</strong></p>
<p>A more challenging experiment with a non-linear dynamical system is the Inverted Pendulum experiment. This is very similar to the pole balancing example we discussed above, and is a standard benchmark for control methods. The goal is to balance the inverted pendulum by applying torque that will stabilize it in a vertically upright position, in the presence of noise. In our experiments, we used correlated disturbances from a Gaussian random-walk. We follow the dynamics implemented in <a href="https://gym.openai.com/">OpenAI Gym</a>, and test the performance of different controllers: LQR, a learned controller, and boosting. The video below visualizes this experiment:</p>
<div class="jetpack-video-wrapper"></div>
<p>When averaging the loss value over multiple experiment runs, we get the following plot:</p>
<p style="text-align: center;"><img width="369" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-2.png?w=369&amp;h=276" title="" height="276" /></p>
<p>It can be seen that the learned controller performs much better than the LQR in the presence of correlated noise, and that boosting can improve its stability and achieve lower average loss.</p>
<p><b>Boosting for Time-Series Prediction</b></p>
<p>Similarly to the control setting, in time-series prediction tasks it is sufficient to use fixed horizons, and online boosting can be efficiently applied here as well. In time-series prediction, the data is often assumed to be generated from an autoregressive moving average (ARMA) model:</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=x_%7Bt%7D+%3D+%5Csum_%7Bi%3D1%7D%5Ek+%5Calpha_i+x_%7Bt-i%7D+%2B+%5Csum_%7Bj%3D1%7D%5Eq+%5Cbeta_j+w_j+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t" class="latex" title="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t" /></p>
<p>In words, each data point <img src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_t" class="latex" title="x_t" /> is given by a weighted sum of previous points, previous noises and a new noise term <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" />, where <img src="https://s0.wp.com/latex.php?latex=%5Calpha%2C%5Cbeta&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\alpha,\beta" class="latex" title="\alpha,\beta" /> are the coefficients vectors.</p>
<p>To test our boosting method, We experimented with 4 simulated settings: 1) normally distributed noises, 2) coefficients of the dynamical system slowly change over time, 3) a single, abrupt, change of the coefficients, and, 4) correlated noise: Gaussian random walk.</p>
<p>The weak learners tested here are the ARMA-ONS (online newton step) and ARMA-OGD (online gradient descent) algorithms for time-series prediction (See <a href="http://proceedings.mlr.press/v30/Anava13.pdf">this</a> paper for more details). We applied our boosting method, as well as a fast version of it, which applies to quadratic loss functions (we used squared difference in this case).</p>
<p><i><b>1) Gaussian Noise </b></i> <i><b>2) Changing Coefficients</b></i></p>
<p><img width="289" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-3.png?w=289&amp;h=217" title="" height="217" /><img width="289" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-4.png?w=289&amp;h=217" title="" height="217" /><img width="292" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-5.png?w=292&amp;h=218" title="" height="218" /><img width="290" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-6.png?w=290&amp;h=217" title="" height="217" /></p>
<p><i><b>3) Abrupt Change </b></i> <i><b>4) Correlated Noise</b></i></p>
<p>We can see in the plots above that all weak learners’ loss values (red) can be improved by online boosting methods (blue). A similar observation arises when experimenting with real-world data; we experimented with the Air Quality dataset from the <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning repository</a>, that contains hourly averaged measurements of air quality properties from an Italian city throughout one year, as measured by chemical sensors. We apply similar weak learners to this task, as well as our boosting algorithms. Here we again obtain better averaged losses for boosted methods (blue) compared to the baselines (red).</p>
<p style="text-align: center;"><img width="498" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-7.png?w=498&amp;h=373" title="" height="373" /></p></div>







<p class="date">
by Elad Hazan <a href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/"><span class="datestr">at July 17, 2019 02:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17564">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/">Dan Romik on the Riemann zeta function</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>This post about the Rieman zeta function, among the most important and mysterious mathematical objects is kindly written by Dan Romik. It is related to his paper <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>,  that we mentioned in <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">this post</a>.</em></p>
<h2>Dan Romik on the Riemann zeta function</h2>
<p>Recently when I was thinking about the Riemann zeta function, I had the double thrill of discovering some new results about it, and then later finding out that my new ideas were closely related to some very classical ideas due to two icons of twentieth-century mathematics, George Pólya and Pál Turán. When you are trying to stand on the shoulders of giants, it’s nice to see other giants right there beside you trying to do the same!</p>
<p>It all goes back to one of the most famous problems in mathematics, the Riemann Hypothesis (RH). Both Pólya and Turán were rather enamored with this problem and published about it extensively; Pólya was said to have been preoccupied with the problem to the very end of his life.(1) And they both recognized that an important first step in trying to prove something about the zeros of the zeta function is having a good representation<br />
for the Riemann zeta function. After all, there are many different formulas that can be used to define or compute the zeta function. If you don’t choose the right one, you probably won’t get very far with your analysis.</p>
<p>Pólya in one of his famous attacks on the problem considered the representation of the zeta function (or more precisely of the Riemann xi function, which is a symmetrized and better-behaved version of the zeta function; see below) as a Fourier transform—a standard representation due (essentially) to Riemann. I’ll have more to say about that later.</p>
<p>Turán also looked at the Riemann xi function, and instead of working with one of the standard “named” representations such as the Fourier transform or Taylor series, looked around a bit more intentionally for a representation of the function that seemed particularly suited to answering the specific question of whether the zeros all lie on a line. In a 1950 address to the Hungarian Academy of Sciences, he put forward his ideas about what he thought was the correct representation to look at: the infinite series expansion of the xi function in the Hermite polynomials. About eighty years after Turán’s discovery, my own investigations led me to discover [5] that the Hermite polynomials are not the only polynomials in which it’s interesting to expand the Riemann xi function. It turns out that there are at least two other families of polynomials for which the respective expansions are no less (and, in some ways, more) well-behaved. My motto for these polynomial families, which are known to experts in special functions but have until now been somewhat esoteric (though I hope that is about to change), is that they are “the coolest polynomials that you never heard of.”</p>
<p>Let’s look at some of the technical details so that I can explain why these new expansions are interesting, and how they relate to Turán’s work and ultimately back to Pólya’s ideas and one of the particular threads that grew out of them. First, define the Riemann xi function as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cxi%28s%29+%3D+%5Cfrac12+s%28s-1%29+%5Cpi%5E%7B-s%2F2%7D+%5CGamma%5Cleft%28%5Cfrac%7Bs%7D%7B2%7D%5Cright%29+%5Czeta%28s%29+%5Cqquad+%28s%5Cin%5Cmathbb%7BC%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), " class="latex" title="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Gamma(z)}" class="latex" title="{\Gamma(z)}" /> is the Euler gamma function and <img src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%28s%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\zeta(s)}" class="latex" title="{\zeta(s)}" /> is the Riemann zeta function. It’s also common to denote<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Cxi%5Cleft%28%5Cfrac12%2Bit%5Cright%29+%5Cqquad+%28t%5Cin%5Cmathbb%7BC%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). " class="latex" title="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). " /></p>
<p>This is Riemann’s “capital xi” function, which is still usually referred to as Riemann’s xi function. (This seems reasonable: the two functions are the same up to a trivial linear change of variables.) The main point of these definitions is that <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> is an entire function of the complex variable <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />, and that RH can now be reformulated as the statement that the zeros of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> all lie on the real line. Moreover, the famous functional equation satisfied by the Riemann zeta function maps to the statement that <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> is an even function.<br />
Now consider the following four ways of representing the xi function:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+a_%7B2n%7D+t%5E%7B2n%7D%2C%7E%7E%7E%7E%7E%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)" class="latex" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+b_%7B2n%7D+H_%7B2n%7D%28t%29%2C%7E%7E%7E%7E%7E%282%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)" class="latex" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+c_%7B2n%7D+f_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29%2C%7E%7E%7E%7E%7E%283%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)" class="latex" title="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+d_%7B2n%7D+g_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29.%7E%7E%7E%7E%7E%284%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)" class="latex" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)" /></p>
<p>Here, the first representation (1) is simply the Taylor expansion of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" />, which contains only even terms since <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> is an even function. The numbers <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_{2n}}" class="latex" title="{a_{2n}}" /> are (up to the <img src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(-1)^n}" class="latex" title="{(-1)^n}" /> sign factor) the Taylor coefficients. Some attempts have been made to understand them, and one interesting and fairly trivial observation (again going back to facts already known to Riemann) is that they are all positive. Some additional and less trivial things can be said—see for example Section 6.1 of my paper [5], and the recent paper by Griffin, Ono, Rolen and Zagier [2]. But at the end of the day, no one has yet succeeded in using the Taylor expansion to prove anything new about the location of the zeros.</p>
<p>The second representation (2) is the infinite series expansion of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> in the classical sequence of Hermite polynomials, defined by the well-known formula</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H_n%28t%29+%3D+%28-1%29%5En+e%5E%7Bt%5E2%7D+%5Cfrac%7Bd%5En%7D%7Bdt%5En%7D+%5Cleft%28+e%5E%7B-t%5E2%7D+%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). " class="latex" title="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). " /></p>
<p>This is the representation whose use was advocated by Turán. His reasoning was that expanding a function of a complex variable (for example, in the simplest case, a polynomial) in monomials <img src="https://s0.wp.com/latex.php?latex=%7Bt%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t^n}" class="latex" title="{t^n}" /> doesn’t provide useful information to easily decide if the function has only real zeros, because the monomials have, roughly speaking, radial symmetry: their level curves are concentric circles. The Hermite polynomials on the other hand, at least heuristically, have level curves that are closer to being straight lines parallel to the real axis, Turán argued; thus, they are more suited to the geometry of the problem we are trying to solve.</p>
<p>Turán’s case for supporting the Hermite polynomials as the right basis to use is quite detailed—you can read about it in his papers [6,7,8] (and no, he was not able to actually prove anything about the zeros of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" />; this is a common theme in most of the attacks on RH to date…). I’ll simply mention that again one interesting and fairly easy observation is that the coefficients <img src="https://s0.wp.com/latex.php?latex=%7Bb_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_{2n}}" class="latex" title="{b_{2n}}" /> in the expansion (2)—adjusted through the introduction of the sign factor <img src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(-1)^n}" class="latex" title="{(-1)^n}" />—end up being positive numbers. Their asymptotic behavior can also be analyzed: I prove a result about this in my paper (though it’s not particularly pretty).</p>
<p>Now comes the part that to me seems the most exciting, involving the expansions (3) and (4). These are the expansions in the more exotic families of polynomials</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_n%28x%29%3D%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+2%5Ek%5Cbinom%7Bn%2B%5Cfrac12%7D%7Bn-k%7D%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k}," class="latex" title="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k}," /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+g_n%28x%29%3D+%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+%5Cfrac%7B%28n%2Bk%2B1%29%21%7D%7B%28n-k%29%21%283%2F2%29_k%5E2%7D+%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}" class="latex" title="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}" /></p>
<p>(where <img src="https://s0.wp.com/latex.php?latex=%7B%283%2F2%29_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(3/2)_n}" class="latex" title="{(3/2)_n}" /> is a <a href="https://en.wikipedia.org/wiki/Falling_and_rising_factorials">Pochhammer symbol</a>), mildly rescaled by replacing <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />  with <img src="https://s0.wp.com/latex.php?latex=%7Bt%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t/2}" class="latex" title="{t/2}" />. In the terminology of the theory of orthogonal polynomials, the family <img src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_n(x)}" class="latex" title="{f_n(x)}" /> is a special case of a two-parameter family <img src="https://s0.wp.com/latex.php?latex=%7BP_n%5E%7B%28%5Clambda%29%7D%28x%3B%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_n^{(\lambda)}(x;\phi)}" class="latex" title="{P_n^{(\lambda)}(x;\phi)}" /> known as the Meixner-Pollaczek polynomials, with the parameters taking the particular values <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%3D%5Cfrac%7B%5Cpi%7D%7B2%7D%2C+%5Clambda%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}" class="latex" title="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}" />. Similarly, the family <img src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_n(x)}" class="latex" title="{g_n(x)}" /> is a special case of the four-parameter family <img src="https://s0.wp.com/latex.php?latex=%7Bp_n%28x%3Ba%2Cb%2Cc%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_n(x;a,b,c,d)}" class="latex" title="{p_n(x;a,b,c,d)}" /> known as the continuous Hahn polynomials, with the parameters taking the particular values <img src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dd%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a=b=c=d=\frac{3}{4}}" class="latex" title="{a=b=c=d=\frac{3}{4}}" />. Their main characterizing property is that they are orthogonal sequences of polynomials for two specific weight functions on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{R}}" class="latex" title="{\mathbb{R}}" />: the <img src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_n(x)}" class="latex" title="{f_n(x)}" /> are orthogonal with respect to the weight function <img src="https://s0.wp.com/latex.php?latex=%7Bw_1%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}" class="latex" title="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}" />, and the <img src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_n(x)}" class="latex" title="{g_n(x)}" /> are orthogonal with respect to <img src="https://s0.wp.com/latex.php?latex=%7Bw_2%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}" class="latex" title="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}" />. Again, fairly esoteric. But interesting!</p>
<p>There are several things that make the expansions (3)–(4) well-behaved. First, the coefficients <img src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_{2n}}" class="latex" title="{c_{2n}}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_{2n}}" class="latex" title="{d_{2n}}" /> are again positive. This actually seems pretty relevant for questions like RH: for example, if we consider “toy” versions of (1)–(3) in which the coefficient sequences <img src="https://s0.wp.com/latex.php?latex=%7Ba_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_n}" class="latex" title="{a_n}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bb_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_n}" class="latex" title="{b_n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bc_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_n}" class="latex" title="{c_n}" /> are replaced by the sequence <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^n}" class="latex" title="{\alpha^n}" /> for fixed <img src="https://s0.wp.com/latex.php?latex=%7B0%3C%5Calpha%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0&lt;\alpha&lt;1}" class="latex" title="{0&lt;\alpha&lt;1}" />, all three expansions sum up to rescaled cosines, which are entire functions that of course have only real zeros. (Without the <img src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(-1)^n}" class="latex" title="{(-1)^n}" /> factor, we would get a hyperbolic cosine, which has imaginary zeros.)</p>
<p>Second, one can derive asymptotics for <img src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_{2n}}" class="latex" title="{c_{2n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_{2n}}" class="latex" title="{d_{2n}}" />, and they are quite a bit nicer than the asymptotic formulas for the Taylor and Hermite expansion coefficients. In my paper, I proved that <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+c_%7B2n%7D+%5Csim+A+%5Csqrt%7Bn%7D+e%5E%7B-B+%5Csqrt%7Bn%7D%7D%2C+%5Cqquad+d_%7B2n%7D+%5Csim+C+n%5E%7B4%2F3%7D+e%5E%7B-D+n%5E%7B2%2F3%7D%7D+%5Cqquad+%5Ctextrm%7Bas+%7Dn%5Crightarrow%5Cinfty%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, " class="latex" title="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, " /> where <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C,D}" class="latex" title="{A,B,C,D}" /> are the constants <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+A+%3D+16%5Csqrt%7B2%7D%5Cpi%5E%7B3%2F2%7D%2C+%5Cqquad+B+%3D+4%5Csqrt%7B%5Cpi%7D%2C+%5Cqquad+C+%3D+%5Cfrac%7B128+%5Ctimes+2%5E%7B1%2F3%7D+%5Cpi%5E%7B2%2F3%7D+e%5E%7B-2%5Cpi+%2F3%7D%7D%7B%5Csqrt%7B3%7D%7D%2C+%5Cqquad+D+%3D+3+%284%5Cpi%29%5E%7B1%2F3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. " class="latex" title="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. " /></p>
<p>Third, the expansions have some conceptual meaning: (3) turns out to be equivalent to the expansion of the elementary function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bd%5E2%7D%7Bdu%5E2%7D+%28u+%5Ccoth%28%5Cpi+u%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{d^2}{du^2} (u \coth(\pi u))}" class="latex" title="{\frac{d^2}{du^2} (u \coth(\pi u))}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bu%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u&gt;0}" class="latex" title="{u&gt;0}" />, in an orthogonal basis of functions related to the Laguerre polynomials <img src="https://s0.wp.com/latex.php?latex=%7BL_n%5E%7B1%2F2%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_n^{1/2}(x)}" class="latex" title="{L_n^{1/2}(x)}" />. And analogously, (4) arises out of the expansion of a certain auxiliary function <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7B%5Cnu%7D%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{\nu}(u)}" class="latex" title="{\tilde{\nu}(u)}" /> (I won’t define it here) in yet another classical family of orthogonal polynomials, the Chebyshev polynomials of the second kind.</p>
<p>Fourth (and fifth, sixth, …): the expansions are just… nice, in the sense that they arise in a way that seems natural when one asks certain questions, that they have excellent convergence properties, and that the coefficients <img src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_{2n}}" class="latex" title="{c_{2n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_{2n}}" class="latex" title="{d_{2n}}" /> have several elegant formulas, each revealing something interesting about them. Read the paper to understand more.</p>
<p>I said I will get back to Pólya’s work on RH. This post is already quite long so I will say only a little bit about this. One of Pólya’s major discoveries was that there are operations on entire functions that (under certain mild assumptions) preserve the property of the function having only real zeros. Specifically this is the case for the operation of multiplying the Fourier transform of the function by the factor <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Clambda+u%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{\lambda u^2}}" class="latex" title="{e^{\lambda u^2}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda&gt;0}" class="latex" title="{\lambda&gt;0}" />  (where <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> is the frequency variable). This opens the way to defining a family of deformations <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi_\lambda(t)}" class="latex" title="{\Xi_\lambda(t)}" /> of the Riemann xi function arising out of this operation, and trying to generalize RH by asking for which values of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> it is the case that <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi_\lambda(t)}" class="latex" title="{\Xi_\lambda(t)}" /> has only real zeros. Since Pólya’s work, and important later extensions of it by De Bruijn and Newman, this has become a very active topic of research, nowadays referred to under the name of the De Bruijn-Newman constant.<br />
See the recent survey of Newman and Wu [3], a 2018 paper by Rodgers and Tao [4] proving a major conjecture of Newman, and the recent paper [9] by the <a href="https://terrytao.wordpress.com/2018/12/28/polymath-15-eleventh-thread-writing-up-the-results-and-exploring-negative-t/">Polymath15 project</a> (mentioned by Gil in his <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">earlier post</a>), for the latest on this subject.</p>
<p>The connection I found between this topic and the idea of expanding the Riemann xi function in families of orthogonal polynomials is the following: expansions such as (2)–(4) suggest yet another natural way of “deforming” the Riemann xi function by adding a parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />: simply multiply the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />th term in the expansion by <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^{2n}}" class="latex" title="{\alpha^{2n}}" /> (the linear operator that does this is called the Poisson kernel, and generalizes the standard Poisson kernel from complex analysis and the theory of harmonic functions). It turns out—and is actually easy to prove, and really isn’t terribly surprising in the grand scheme of things—that in the case of the Hermite expansion (2), this family of deformations is the same, up to some trivial reparametrization, as the family of deformations <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi_\lambda(t)}" class="latex" title="{\Xi_\lambda(t)}" /> that was studied in connection with the work of Pólya, De Bruijn, Newman and their successors. A nice connection between two threads of research that were not previously recognized as being related to each other, I think. Furthermore, this suggests that the Poisson kernel and associated deformations may yet have an important role to play in the context of the new expansions in the orthogonal polynomial families <img src="https://s0.wp.com/latex.php?latex=%7Bf_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_n}" class="latex" title="{f_n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bg_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_n}" class="latex" title="{g_n}" />, where we get genuinely new families of deformations of the Riemann xi function. I explore this idea in my paper and it leads to some interesting things.</p>
<p>So let’s summarize. The key questions you are no doubt wondering about are: where does any of this lead? And do these new ideas say anything really useful or especially relevant for the Riemann hypothesis? The answer is that I don’t know (and I’m wondering about the same things). That being said, these orthogonal polynomial expansions seem quite interesting in their own right. The Riemann zeta function is a mysterious object, and there are <a href="https://en.wikipedia.org/wiki/Lindel%C3%B6f_hypothesis">other things</a> we wish to understand about it beside where its zeros are, so it’s always good to have additional points of view from which to approach it. Moreover, even on the question of the zeros there are reasons to be cautiously optimistic that this approach may have something useful to offer; see Chapter 7 of my paper for a brief discussion of why that is the case.</p>
<h2></h2>
<h2>References</h2>
<p>[1] D. Albers and G. L. Alexanderson, editors. Mathematical People: Profiles and Interviews. A K Peters, 2008.</p>
<p>[2] M. Griffin, K. Ono, L. Rolen and D. Zagier. Jensen polynomials for the Riemann zeta function and other sequences. Preprint (2019), <a href="https://arxiv.org/abs/1902.07321">arXiv:1902.07321</a>.</p>
<p>[3] C. M. Newman. Constants of de Bruijn-Newman type in analytic number theory and statistical physics. To appear in Bull. Amer. Math. Soc.</p>
<p>[4] B. Rodgers and T. Tao. The De Bruijn-Newman constant is nonnegative. Preprint (2018), <a href="https://arxiv.org/abs/1801.05914">arXiv:1801.05914</a>.</p>
<p>[5] D. Romik. <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>. Preprint (2019), <a href="https://arxiv.org/abs/1902.06330">arXiv:1902.06330</a>.</p>
<p>[6] P. Turán. Sur l’algèbre fonctionelle. Pages 279–290 in: Comptes Rendus du Premier Congrès des Mathématiciens Hongrois, 27 Août–2 Septembre 1950. Akadémiai Kiadó, 1952. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 677–688. Akadémiai Kiadó, 1990. An English translation of the paper by Dan Romik <a href="http://math.ucdavis.edu/~romik/data/uploads/misc/turan1952-english.pdf">On functional algebra</a>.</p>
<p>[7] P. Turán. Hermite-expansion and strips for zeros of polynomials. Arch. Math. 5 (1954), 148–152. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 738–742. Akadémiai Kiadó, 1990.</p>
<p>[8]  P. Turán. To the analytical theory of algebraic equations. Bulgar. Akad. Nauk. Otd. Mat. Fiz. Nauk. Izv. Mat. Inst. 3 (1959), 123–137. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 2, pp. 1080–1090. Akadémiai Kiadó, 1990.</p>
<p>[9] D.H.J. Polymath. Effective approximation of heat flow evolution of the Riemann ξ function, and a new upper bound for the de Bruijn-Newman constant. Preprint (2019), <a href="https://arxiv.org/abs/1904.12438">arXiv:1904.12438</a>.</p>
<h2>Notes:</h2>
<p>(1) Alexanderson writes in [1, p. 259]: “A week or so before he died, Pólya asked me to look on his desk at home for some papers on which he said he had written down some interesting ideas he had for proving RH. Of course I could find no such notes, but until the day he died he was thinking about that famous problem.”</p>
<p> </p>
<p>(2) Turán’s Hungarian Academy of Sciences talk was published in a rather obscure French-language paper [6] that seems to have been largely forgotten. It’s an interesting read nonetheless, and to make it more accessible to anyone who may be interested, I recently translated it to English.</p>
<p> </p>
<p>(3) Turán mentions in [8] that he discovered the results on the Hermite expansion in 1938–39, but they were not published until much later. Clearly this was not a convenient time in history for publishing such discoveries; Turán, a Hungarian Jew, spent much of World War II interned in labor camps in Hungary.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/"><span class="datestr">at July 17, 2019 06:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16114">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/07/16/summer-reading-in-theory/">Summer Reading in Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Some formative books in mathematics and computing theory</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg"><img src="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg?w=600" alt="" class="alignright size-full wp-image-16115" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">LSE <a href="https://blogs.lse.ac.uk/maths/2016/04/15/norman-biggs-calculus-on-clay/">source</a>: <i>“Calculus on Clay?”</i></font></td>
</tr>
</tbody>
</table>
<p>
Norman Biggs is the author of the wonderful <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC">book</a> <em>Algebraic Graph Theory</em>. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture. </p>
<p>
Today we wish to ask, <i>What are your top five favorite books on mathematics and theory for summer reading?</i></p>
<p>
There’s an <a href="https://en.wikipedia.org/wiki/Aporia">aporia</a> in that question. A working definition of aporia is: “a self-contradiction that isn’t.” The point is that books for summer reading should be new, so how would you already know which are your favorites? Well, we are thinking of books that are so rich you can always find new things in them—and that also played formative roles earlier in our careers.</p>
<p>
Ken knew Biggs during his first year at Oxford when Biggs was visiting there from London. He took part in a weekly sitting-room seminar organized by Peter Neumann. Biggs’s book was a central reference for Ken’s undergraduate senior thesis at Princeton, and both he and Ken presented material based on it. </p>
<p>
</p><p></p><h2> Best Five Books—Dick </h2><p></p>
<p></p><p>
Here are my votes for all-time best books in mathematics and in computer science theory.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC"><i>Algebraic Graph Theory</i></a>, by Norman Biggs. A wonderful book. First appeared in 1974.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.amazon.com/Introduction-Probability-Theory-Applications-Vol/dp/0471257087/ref=sr_1_1?keywords=William+Feller&amp;qid=1563190401&amp;s=books&amp;sr=1-1"><i> An Introduction to Probability Theory and Its Applications, Vol. 1</i></a>, by William Feller. This is the book I used to learn probability theory.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.amazon.com/gp/product/0199219869/ref=as_li_tl?ie=UTF8&amp;tag=mathblog05-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0199219869&amp;linkId=a71963a143733e948f50588526d624c0"><i> An Introduction to the Theory of Numbers</i></a>, by Godfrey Hardy and Edward Wright. Now updated by Andrew Wiles, Roger Heath-Brown, and Joseph Silverman. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.amazon.com/Elements-Number-Theory-Dover-Mathematics/dp/0486781658/ref=sr_1_1?keywords=Vinogradov&amp;qid=1563190340&amp;s=books&amp;sr=1-1"><i>Elements of Number Theory</i></a>, by Ivan Vinogradov. Another small book that is loaded with ideas. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.abebooks.com/Paul-Erds-Art-Counting-Erdos-Joel/13380002114/bd"><i>The Art of Counting</i></a>, by Paul Erdős and Joel Spencer. This book changed my life. Today the book is of course <a href="https://www.amazon.com/dp/0470170204/?tag=stackoverfl08-20"><i>The Probabilistic Method</i></a>, by Noga Alon and Joel Spencer. </p>
<p>
</p><p></p><h2> Best Five Books—Ken </h2><p></p>
<p></p><p>
Ken reaches back to his teen years but it’s still the same span of years as my list. Here he tells it:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> All books by Martin Gardner—in particular, the books of collections of his “Mathematical Games” columns in <em>Scientific American</em>. Here is an <a href="https://blogs.scientificamerican.com/guest-blog/the-top-10-martin-gardner-scientific-american-articles/">overview</a>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://www.lybrary.com/scarne-on-dice-p-655.html"><i>Scarne on Dice</i></a> and <a href="https://www.lybrary.com/scarne-on-cards-p-759.html"><i> Scarne on Cards</i></a>. Originally it was neither of these books—nor John Scarne’s <em>Complete Guide to Gambling</em>—but a different book on in which both Scarne and Gardner figured prominently. Alas I, Ken, cannot trace it. That’s what I used to learn probability theory.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://www.amazon.com/Spectra-Graphs-Application-Applied-Mathematics/dp/0121951502"><i>Spectra of Graphs</i></a>, by Dragoš Cvetković, Michael Doob, and Horst Sachs. I could put Biggs’s book here, but this is the one that got me on to the whole subject just before my senior year at Princeton. It was fresh out in 1980—I recall the tactile sensation of the dark green spanking new cover in the Fine Hall Library’s copy. A great book with pictures and algebra. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://www.amazon.com/Ideals-Varieties-Algorithms-Computational-Undergraduate/dp/0387356509"><i> Ideals, Varieties, and Algorithms</i></a>, by David Cox, John Little, and Donal O’Shea. Fast forward to 1997. Having realized that techniques from algebraic geometry could surmount the “Natural Proofs” <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">barrier</a> (see also <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">GCT</a>), I went whole-hog after it. See “Manic Monomials” in this <a href="https://rjlipton.wordpress.com/2012/07/04/july-fourth-sale-of-ideas/">post</a> for one thing that tripped it up. The book remains incredibly stimulating. It has a <a href="https://www.amazon.com/Using-Algebraic-Geometry-Graduate-Mathematics/dp/0387984879/">sequel</a>, <em>Using Algebraic Geometry</em>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://en.wikipedia.org/wiki/Quantum_Computation_and_Quantum_Information"><i>Quantum Computation and Quantum Information</i></a> by Michael Nielsen and Isaac Chuang. As with Hardy and Wright, it has its own Wikipedia page. Dick and I can say this is nominating a competitor, but Chaung &amp; Nielsen is really in a class by itself for the sheer richness and writing style. One odd mark of its influence: In 2006 when I reacted to the sensational and frightening accusations of cheating at the world championship <a href="https://en.wikipedia.org/wiki/World_Chess_Championship_2006">match</a>, my first thought was to apply distributional distance measures of the kind used in its later chapters. Among such measures is (quantum) <a href="https://en.wikipedia.org/wiki/Fidelity_of_quantum_states">fidelity</a>, and although I focused more on Jensen-Shannon divergence before deciding on simpler stuff, my chess research <a href="https://cse.buffalo.edu/~regan/chess/fidelity/">website</a> retains “fidelity” in its name as part of a multi-way reference to <a href="https://en.wikipedia.org/wiki/FIDE">FIDE</a>, faith, and playing in good faith.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What books most influenced you? What are your votes for the best books that might influence others?	 </p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/07/16/summer-reading-in-theory/"><span class="datestr">at July 17, 2019 04:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07167">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07167">Fast, Provably convergent IRLS Algorithm for p-norm Linear Regression</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Adil:Deeksha.html">Deeksha Adil</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Richard.html">Richard Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sachdeva:Sushant.html">Sushant Sachdeva</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07167">PDF</a><br /><b>Abstract: </b>Linear regression in $\ell_p$-norm is a canonical optimization problem that
arises in several applications, including sparse recovery, semi-supervised
learning, and signal processing. Generic convex optimization algorithms for
solving $\ell_p$-regression are slow in practice. Iteratively Reweighted Least
Squares (IRLS) is an easy to implement family of algorithms for solving these
problems that has been studied for over 50 years. However, these algorithms
often diverge for p &gt; 3, and since the work of Osborne (1985), it has been an
open problem whether there is an IRLS algorithm that is guaranteed to converge
rapidly for p &gt; 3. We propose p-IRLS, the first IRLS algorithm that provably
converges geometrically for any $p \in [2,\infty).$ Our algorithm is simple to
implement and is guaranteed to find a $(1+\varepsilon)$-approximate solution in
$O(p^{3.5} m^{\frac{p-2}{2(p-1)}} \log \frac{m}{\varepsilon}) \le O_p(\sqrt{m}
\log \frac{m}{\varepsilon} )$ iterations. Our experiments demonstrate that it
performs even better than our theoretical bounds, beats the standard Matlab/CVX
implementation for solving these problems by 10--50x, and is the fastest among
available implementations in the high-accuracy regime.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07167"><span class="datestr">at July 17, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07149">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07149">Step-by-Step Community Detection for Volume-Regular Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Becchetti:Luca.html">Luca Becchetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cruciani:Emilio.html">Emilio Cruciani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pasquale:Francesco.html">Francesco Pasquale</a>, Sara Rizzo <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07149">PDF</a><br /><b>Abstract: </b>Spectral techniques have proved amongst the most effective approaches to
graph clustering. However, in general they require explicit computation of the
main eigenvectors of a suitable matrix (usually the Laplacian matrix of the
graph).
</p>
<p>Recent work (e.g., Becchetti et al., SODA 2017) suggests that observing the
temporal evolution of the power method applied to an initial random vector may,
at least in some cases, provide enough information on the space spanned by the
first two eigenvectors, so as to allow recovery of a hidden partition without
explicit eigenvector computations. While the results of Becchetti et al. apply
to perfectly balanced partitions and/or graphs that exhibit very strong forms
of regularity, we extend their approach to graphs containing a hidden $k$
partition and characterized by a milder form of volume-regularity. We show that
the class of $k$-volume regular graphs is the largest class of undirected
(possibly weighted) graphs whose transition matrix admits $k$ stepwise
eigenvectors (i.e., vectors that are constant over each set of the hidden
partition). To obtain this result, we highlight a connection between volume
regularity and lumpability of Markov chains. Moreover, we prove that if the
stepwise eigenvectors are those associated to the first $k$ eigenvalues and the
gap between the $k$-th and the ($k$+1)-th eigenvalues is sufficiently large,
the Averaging dynamics of Becchetti et al. recovers the underlying community
structure of the graph in logarithmic time, with high probability.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07149"><span class="datestr">at July 17, 2019 11:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07078">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07078">On The Termination of a Flooding Process</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hussak:Walter.html">Walter Hussak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Trehan:Amitabh.html">Amitabh Trehan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07078">PDF</a><br /><b>Abstract: </b>Flooding is among the simplest and most fundamental of all distributed
network algorithms. A node begins the process by sending a message to all its
neighbours and the neighbours, in the next round forward the message to all the
neighbours they did not receive the message from and so on. We assume that the
nodes do not keep a record of the flooding event. We call this amnesiac
flooding (AF). Since the node forgets, if the message is received again in
subsequent rounds, it will be forwarded again raising the possibility that the
message may be circulated infinitely even on a finite graph. As far as we know,
the question of termination for such a flooding process has not been settled -
rather, non-termination is implicitly assumed.
</p>
<p>In this paper, we show that synchronous AF always terminates on any arbitrary
finite graph and derive exact termination times which differ sharply in
bipartite and non-bipartite graphs. Let $G$ be a finite connected graph. We
show that synchronous AF from a single source node terminates on $G$ in $e$
rounds, where $e$ is the eccentricity of the source node, if and only if $G$ is
bipartite. For non-bipartite $G$, synchronous AF from a single source
terminates in $j$ rounds where $e &lt; j \leq e+d+1$ and $d$ is the diameter of
$G$. This limits termination time to at most $d$ and at most $2d + 1$ for
bipartite and non-bipartite graphs respectively. If communication/broadcast to
all nodes is the motivation, our results show that AF is asymptotically time
optimal and obviates the need for construction and maintenance of spanning
structures like spanning trees. The clear separation in the termination times
of bipartite and non-bipartite graphs also suggests mechanisms for distributed
discovery of the topology/distances in arbitrary graphs.
</p>
<p>For comparison, we show that, in asynchronous networks, an adaptive adversary
can force AF to be non-terminating.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07078"><span class="datestr">at July 17, 2019 11:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07020">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07020">Computing Nested Fixpoints in Quasipolynomial Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hausmann:Daniel.html">Daniel Hausmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schr=ouml=der:Lutz.html">Lutz Schröder</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07020">PDF</a><br /><b>Abstract: </b>It is well known that the winning region of a parity game with $n$ nodes and
$k$ priorities can be computed as a $k$-nested fixpoint of a suitable function;
straightforward computation of this nested fixpoint requires
$n^{\lceil\frac{k}{2}\rceil+1}$ iterations of the function. The recent parity
game solving algorithm by Calude et al. runs in quasipolynomial time and
essentially shows how to compute the same fixpoint using only a quasipolynomial
number of iterations. We show that their central idea naturally generalizes to
the computation of $k$-nested fixpoints of any set-valued function; hence
$k$-nested fixpoints of set functions that can be computed in quasipolynomial
time can be computed in quasipolynomial time as well. While this result is of
clear interest in itself, we focus in particular on applications to modal
fixpoint logics beyond relational semantics. For instance, the model checking
problems for the graded and the (two-valued) probabilistic $\mu$-calculus --
with numbers coded in binary -- can be solved by computing nested fixpoints of
functions that differ from the function for parity game solving, but still can
be computed in quasipolynomial time; our result hence implies that model
checking for these $\mu$-calculi is in QP. A second implication of our result
lies in satisfiability checking for generalized $\mu$-calculi, including the
graded, probabilistic and alternating-time variants; in a general setting that
covers all the mentioned cases, our result immediately improves the upper time
bound for satisfiability checking for fixpoint formulas of size $n$ with
alternation-depth $k$ from $2^{\mathcal{O}({n^2k^2\log n})}$ to
$2^{\mathcal{O}({nk\log n})}$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07020"><span class="datestr">at July 17, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06983">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06983">Lossless Prioritized Embeddings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Elkin:Michael.html">Michael Elkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Neiman:Ofer.html">Ofer Neiman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06983">PDF</a><br /><b>Abstract: </b>Given metric spaces $(X,d)$ and $(Y,\rho)$ and an ordering
$x_1,x_2,\ldots,x_n$ of $(X,d)$, an embedding $f: X \rightarrow Y$ is said to
have a prioritized distortion $\alpha(\cdot)$, if for any pair $x_j,x'$ of
distinct points in $X$, the distortion provided by $f$ for this pair is at most
$\alpha(j)$. If $Y$ is a normed space, the embedding is said to have
prioritized dimension $\beta(\cdot)$, if $f(x_j)$ may have nonzero entries only
in its first $\beta(j)$ coordinates.
</p>
<p>The notion of prioritized embedding was introduced by \cite{EFN15}, where a
general methodology for constructing such embeddings was developed. Though this
methodology enables \cite{EFN15} to come up with many prioritized embeddings,
it typically incurs some loss in the distortion. This loss is problematic for
isometric embeddings. It is also troublesome for Matousek's embedding of
general metrics into $\ell_\infty$, which for a parameter $k = 1,2,\ldots$,
provides distortion $2k-1$ and dimension $O(k \log n \cdot n^{1/k})$.
</p>
<p>In this paper we devise two lossless prioritized embeddings. The first one is
an isometric prioritized embedding of tree metrics into $\ell_\infty$ with
dimension $O(\log j)$. The second one is a prioritized Matousek's embedding of
general metrics into $\ell_\infty$, which provides prioritized distortion $2
\lceil k {{\log j} \over {\log n}} \rceil - 1$ and dimension $O(k \log n \cdot
n^{1/k})$, again matching the worst-case guarantee $2k-1$ in the distortion of
the classical Matousek's embedding. We also provide a dimension-prioritized
variant of Matousek's embedding. Finally, we devise prioritized embeddings of
general metrics into (single) ultra-metric and of general graphs into (single)
spanning tree with asymptotically optimal distortion.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06983"><span class="datestr">at July 17, 2019 11:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06786">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06786">Some Black-box Reductions for Objective-robust Discrete Optimization Problems Based on their LP-Relaxations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Khaled Elbassioni <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06786">PDF</a><br /><b>Abstract: </b>We consider robust discrete minimization problems where uncertainty is
defined by a convex set in the objective. We show how an integrality gap
verifier for the linear programming relaxation of the non-robust version of the
problem can be used to derive approximation algorithms for the robust version.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06786"><span class="datestr">at July 17, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06748">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06748">Designing Perfect Simulation Algorithms using Local Correctness</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huber:Mark.html">Mark Huber</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06748">PDF</a><br /><b>Abstract: </b>Consider a randomized algorithm that draws samples exactly from a
distribution using recursion. Such an algorithm is called a perfect simulation,
and here a variety of methods for building this type of algorithm are shown to
derive from the same result: the Fundamental Theorem of Perfect Simulation
(FTPS). The FTPS gives two necessary and sufficient conditions for the output
of a recursive probabilistic algorithm to come exactly from the desired
distribution. First, the algorithm must terminate with probability 1. Second,
the algorithm must be locally correct, which means that if the recursive calls
in the original algorithm are replaced by oracles that draw from the desired
distribution, then this new algorithm can be proven to be correct. While it is
usually straightforward to verify these conditions, they are surprisingly
powerful, giving the correctness of Acceptance/Rejection, Coupling from the
Past, the Randomness Recycler, Read-once CFTP, Partial Rejection Sampling,
Partially Recursive Acceptance Rejection, and various Bernoulli Factories. We
illustrate the use of this algorithm by building a new Bernoulli Factory for
linear functions that is 41\% faster than the previous method.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06748"><span class="datestr">at July 17, 2019 11:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06743">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06743">Binary Decision Diagrams: from Tree Compaction to Sampling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cl=eacute=ment:Julien.html">Julien Clément</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Genitrini:Antoine.html">Antoine Genitrini</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06743">PDF</a><br /><b>Abstract: </b>Any Boolean function corresponds with a complete full binary decision tree.
This tree can in turn be represented in a maximally compact form as a direct
acyclic graph (\textsc{dag}) where common subtrees are factored and shared,
keeping only one copy of each unique subtree. This yields the celebrated and
widely used structure called reduced ordered binary decision diagram
(\textsc{robdd}). We propose to revisit the classical compaction process to
give a new way of enumerating \textsc{robdd}s of a given size without
considering fully expanded trees and the compaction step. Our method also
provides an unranking procedure for the set of \textsc{robdd}s. As a by-product
we get a random uniform and exhaustive sampler for \textsc{robdd}s for a given
number of variables and size. For efficiency our algorithms rely on a
precomputation step. Finally, we give some key ideas to extend the approach to
other strategies of compaction, in relation with variants of \textsc{bdd}s
(namely \textsc{qbdd}s and \textsc{zbdd}s).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06743"><span class="datestr">at July 17, 2019 11:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06731">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06731">Lower Bounding the AND-OR Tree via Symmetrization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretschmer:William.html">William Kretschmer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06731">PDF</a><br /><b>Abstract: </b>We prove a nearly tight lower bound on the approximate degree of the
two-level $\mathsf{AND}$-$\mathsf{OR}$ tree using symmetrization arguments.
Specifically, we show that $\widetilde{\mathrm{deg}}(\mathsf{AND}_m \circ
\mathsf{OR}_n) = \widetilde{\Omega}(\sqrt{mn})$. To our knowledge, this is the
first proof of this fact that relies on symmetrization exclusively; most other
proofs involve formulating approximate degree as a linear program and
exhibiting an explicit dual witness. Our proof relies on a symmetrization
technique involving Laurent polynomials (polynomials with negative exponents)
that was previously introduced by Aaronson, Kothari, Kretschmer, and Thaler
[AKKT19].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06731"><span class="datestr">at July 17, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.06688">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.06688">A row-invariant parameterized algorithm for integer programming</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Martin Koutecky, Daniel Kral <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.06688">PDF</a><br /><b>Abstract: </b>A long line of research on fixed parameter tractability of integer
programming culminated with showing that integer programs with n variables and
a constraint matrix with tree-depth d and largest entry D are solvable in in
time g(d,D)poly(n) for some function g, i.e., fixed parameter tractable when
parameterized by tree-depth d and D. However, the tree-depth of a constraint
matrix depends on the positions of its non-zero entries and thus does not
reflect its geometric nature, in particular, is not invariant under row
operations. We consider a parameterization of the constraint matrix by a
matroid parameter called branch-depth, which is invariant under row operations.
Our main result asserts that integer programs whose matrix has branch-depth d
and largest entry D are solvable in time f(d,D)poly(n). Since every constraint
matrix with small tree-depth has small branch-depth, our result extends the
result above. The parameterization by branch-depth cannot be replaced by the
more permissive notion of branch-width.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.06688"><span class="datestr">at July 17, 2019 11:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6069637759837834972">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html">Guest post by Samir Khuller on attending The TCS Women 2019 meeting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
(I will post the solution to the problem in the last blog later in the week---probably Thursday. Meanwhile, enjoy these thoughts from Samir Khuller on the TCS Women 2019 meeting.)<br />
<br />
Guest Post by Samir Khuller:<br />
<br />
Am I even allowed here?” was the first thought that crossed my mind when I entered the room. It was packed with women (over 95%), however a few minutes later, several men had trickled in. I was at the TCS Women spotlight workshop on the day before STOC. Kudos to Barna Saha, Sofya Raskhodnikova, and Virginia Vassilevska Williams for putting this grand (and long needed) event together, which serves as a role model and showcases some of the recent work by rising stars. In addition to the Sun afternoon workshop, the event was followed by both an all women panel and a poster session (which I sadly did not attend).<br />
<br />
<br />
The rising stars talks were given by Naama Ben-David (CMU), Andrea Lincoln (MIT), Debarati Das (Charles University) and Oxana Poburinnaya (Boston U). After a short break the inspirational talk was by Ronitt Rubinfeld from MIT.  Ronitt’s talk was on the topic of Program Checking, but she made it inspirational by putting us in her shoes as a young graduate student, three decades back, trying to make a dent in research by working on something that her advisor Manuel Blum, and his senior graduate student Sampath Kannan had been working on, and I must say she made a pretty big dent in the process! She also related those ideas to other pieces of work done since in a really elegant manner and how these pieces of work lead to work on property testing.<br />
<br />
<br />
I am delighted to say that NSF supported the workshop along with companies such as Amazon, Akamai, Google and Microsoft. SIGACT plans to be a major sponsor next year.<br />
<br />
<br />
The Full program for the workshop is at the following URL<a href="https://sigact.org/tcswomen/tcs-women-2019/">here.</a><br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html"><span class="datestr">at July 16, 2019 11:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/094">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/094">TR19-094 |  Rainbow coloring hardness via low sensitivity polymorphisms | 

	Venkatesan Guruswami, 

	Sai Sandeep</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A $k$-uniform hypergraph is said to be $r$-rainbow colorable if there is an $r$-coloring of its vertices such that every hyperedge intersects all $r$ color classes. Given as input such a hypergraph, finding a $r$-rainbow coloring of it is NP-hard for all $k \ge 3$ and $r \ge 2$. Therefore, one settles for finding a rainbow coloring with fewer colors (which is an easier task).  When $r=k$ (the maximum possible value), i.e., the hypergraph is $k$-partite, one can efficiently $2$-rainbow color the hypergraph, i.e., $2$-color its vertices so that there are no monochromatic edges. In this work we consider the next smaller value of $r=k-1$, and prove that in this case it is NP-hard to rainbow color the hypergraph with $q :=  \lceil \frac{k-2}{2} \rceil$ colors. In particular, for $k \le 6$, it is NP-hard to $2$-color $(k-1)$-rainbow colorable $k$-uniform hypergraphs.

Our proof follows the algebraic approach to promise constraint satisfaction problems. It proceeds by characterizing the polymorphisms associated with the approximate rainbow coloring problem, which are rainbow colorings of some product hypergraphs on vertex set $[r]^n$. We prove that any such polymorphism $f: [r]^n \to [q]$ must be $C$-fixing, i.e., there is a small subset $S$ of $C$ coordinates and a setting $a \in [q]^S$ such that fixing $x_{|S} = a$ determines the value of $f(x)$. The key step in our proof is bounding the sensitivity of certain rainbow colorings, thereby arguing that they must be juntas. Armed with the $C$-fixing characterization, our NP-hardness is obtained via a reduction from smooth Label Cover.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/094"><span class="datestr">at July 16, 2019 01:19 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/093">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/093">TR19-093 |  Improved 3LIN Hardness via Linear Label Cover | 

	Euiwoong Lee, 

	Subhash Khot, 

	Prahladh Harsha, 

	Devanathan Thiruvenkatachari</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove that for every constant $c$ and $\epsilon = (\log n)^{-c}$, there is no polynomial time algorithm that when given an instance of 3LIN with $n$ variables where an $(1 - \epsilon)$-fraction of the clauses are satisfiable, finds an assignment that satisfies at least $(\frac{1}{2} + \epsilon)$-fraction of clauses unless $\mathbf{NP} \subseteq \mathbf{BPP}$. The previous best hardness using a polynomial time reduction achieves $\epsilon = (\log \log n)^{-c}$, which is obtained by the Label Cover hardness of Moshkovitz and Raz [J. ACM, 57(5), 2010] followed by the reduction from Label Cover to 3LIN of Hastad [J. ACM, 48(4):798--859, 2001].

Our main idea is to prove a hardness result for Label Cover similar to Moshkovitz and Raz where each projection has a linear structure. This linear structure of Label Cover allows us to use Hadamard codes instead of long codes, making the reduction more efficient. For the hardness of Linear Label Cover, we follow the work of Dinur and Harsha [SIAM J. Comput., 42(6):2452--2486, 2013] that simplified the construction of Moshkovitz and Raz, and observe that running their reduction from a hardness of the problem LIN (of unbounded arity) instead of the more standard problem of solving quadratic equations ensures the linearity of the resultant Label Cover.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/093"><span class="datestr">at July 16, 2019 01:10 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/07/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/07/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://www.insidehighered.com/news/2019/07/01/about-700-academics-have-been-criminally-charged-turkey-their-signatures-petition">Turkey has charged over 700 academics with terrorism for signing a peace petition</a> (<a href="https://mathstodon.xyz/@11011110/102367088461002886"></a>). Among the most severely penalized is <a href="https://en.wikipedia.org/wiki/Tuna_Alt%C4%B1nel">Tuna Altınel</a>, a mathematician in France who was arrested visiting family in Turkey, and who <a href="http://math.univ-lyon1.fr/SoutienTunaAltinel/?lang=en">has now been imprisoned for over 50 days</a> (<a href="https://cameroncounts.wordpress.com/2019/05/31/tuna-altnel/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://web.cs.elte.hu/~lovasz/bookxx/geomgraphbook/geombook2019.01.11.pdf">László Lovász’s book “Graphs and Geometry”, on geometric representations of graphs</a> (<a href="https://mathstodon.xyz/@11011110/102374639115017977"></a>, <a href="https://news.ycombinator.com/item?id=20317825">via</a>). <a href="https://bookstore.ams.org/coll-65">The print version</a> should appear in a month or so from the AMS.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/06/28/huge-budget-cut-university-alaska">University of Alaska budget gutted by 40%</a> (<a href="https://mathstodon.xyz/@11011110/102381510293748063"></a>, <a href="https://www.metafilter.com/181768/We-dont-need-no-stinkin-edumaction">see also</a>). The total amount cut over the past five years (including this new biggest cut) is <a href="https://www.chronicle.com/article/Unprecedented-in-Our/246596">more like 63%, from $522M to $192M</a>. And <a href="https://www.npr.org/2019/07/03/738569508/university-of-alaska-readies-for-budget-slash-we-may-likely-never-recover">the likely response is to close one of its three main campuses and all 13 smaller community campuses</a>. Ironically, the cause is right-wing insistence on a universal basic income of $3000/person from fuel extraction revenues.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/category/the-big-internet-math-off/">The annual Big Internet Math-off — view and vote on your favorites!</a> (<a href="https://mathstodon.xyz/@11011110/102385386477969762"></a>). 
The first few matches include <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-1-alex-corner-vs-lucy-rycroft-smith/">commutativity of log-exponentiation vs weather infovis</a>, the <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-2-marianne-rachel-vs-vincent-pantaloni/">geometry of the Sydney Opera House vs straight lines on a donut</a>, <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-3-vicky-neale-vs-jim-propp/">multiplication tables and muffins</a> and <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-4-colin-beveridge-vs-kyle-d-evans/">a video on shapes in La Sagrada Familia (shot on location?!) vs an introduction to fractals</a>. More daily for roughly a month.</p>
  </li>
  <li>
    <p><a href="https://www.scmp.com/magazines/post-magazine/long-reads/article/3016267/chinese-scientists-guilty-researching-while">Chinese scientists guilty of “researching while Asian” in Trump’s America</a> (<a href="https://mathstodon.xyz/@11011110/102390640744960409"></a>, <a href="https://news.ycombinator.com/item?id=20319936">via</a>, <a href="https://www.bloomberg.com/news/features/2019-06-13/the-u-s-is-purging-chinese-americans-from-top-cancer-research">see also</a>). The story focuses on star cancer researcher <a href="https://en.wikipedia.org/wiki/Xifeng_Wu">Xifeng Wu</a>, forced to resign from the University of Texas, apparently because she fostered collaboration with Chinese cancer research institutions at the behest of her higher administration.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@ccppurcell/102133405425258779">Chris Purcell thinks about graphs with degree sequence </a>. They have to have at least one cycle of each parity.</p>
  </li>
  <li>
    <p><a href="https://petapixel.com/2019/07/05/goodbye-aberration-physicist-solves-2000-year-old-optical-problem/">A formula for designing lenses with no spherical aberration</a> (<a href="https://mathstodon.xyz/@11011110/102401888807980335"></a>, <a href="https://news.ycombinator.com/item?id=20369960">via</a>). This seems to have little practical value as there was already a numerical solution, and I don’t think it handles chromatic aberration, but it’s interesting that there is an analytic formula for these shapes.</p>
  </li>
  <li>
    <p>Last week I traveled to Milan for the <a href="https://sgp2019.di.unimi.it/">Symposium on Geometry Processing</a> (<a href="https://mathstodon.xyz/@11011110/102407039766140849"></a>). They also have an <a href="https://twitter.com/geometryprocess">official twitter stream</a>, mostly consisting of event photos. The sightseeing highlight of my trip was seeing pages of <a href="https://www.ambrosiana.it/en/discover/codex-atlanticus/">Da Vinci’s Codex Atlanticus at the Ambrosian Library</a>.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/07/08/check-out-this-cool-synthesize.html">Evoboxx</a> (<a href="https://mathstodon.xyz/@11011110/102412280507996705"></a>), a retro-styled portable device that does only two things: run Conway’s Game of Life and generate sounds from it. Not very practical in these days of cell phones but then maybe that’s what makes it a fun project.</p>
  </li>
  <li>
    <p><a href="http://jdh.hamkins.org/modal-model-theory/">Modal model theory</a> (<a href="https://mathstodon.xyz/@11011110/102418646790775178"></a>). For graphs, this extends first order logic (where the only quantification is over vertices and the only predicate is adjacency) with operators  and .  is true when all supergraphs model  and  is true when at least one supergraph models . This can express nontrivial graph properties like -colorability, and comes in two variants depending on whether you can quantify outside the operators.</p>
  </li>
  <li>
    <p><a href="https://www.instagram.com/p/ByH-R4Ql-NA/">Very quick video tutorial on how to make the Miura-ori fold</a>, by Polly Verity (<a href="https://mathstodon.xyz/@11011110/102429787082169299"></a>, <a href="https://www.thisiscolossal.com/2019/07/new-polly-verity/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://jtra.cz/stuff/essays/math-self-reference-smooth/index.html">Trávník’s smooth self-referential formula</a> (<a href="https://mathstodon.xyz/@11011110/102435762025301458"></a>, <a href="https://twitter.com/johncarlosbaez/status/1141376710551601152">via</a>). It is actually a linked set of formulas, described in a typeset image, that when plotted as described in the image produces the image itself. It follows the same ideas as earlier self-referential formulas like <a href="https://en.wikipedia.org/wiki/Tupper%27s_self-referential_formula">Tupper’s self-referential formula</a> but unlike them describes a smooth vector image based on splines instead of a pixelated bitmap.</p>
  </li>
  <li>
    <p><a href="http://muurformules.nl/">Leiden wall formulas</a> (<a href="https://mathstodon.xyz/@11011110/102444110227078604"></a>). The last time I was in Leiden they were decorating the exterior walls of all their buildings with poems of many different languages. Now they’ve moved on to the language of mathematics.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=eYfpSAxGakI">Numberphile video on Dehn invariants</a> (15-minutes; <a href="https://mathstodon.xyz/@11011110/102448538574760818"></a>). The Dehn invariant is a value derived from a polyhedron that doesn’t change if you cut up the polyhedron into smaller polyhedral pieces and rearrange them into a different polyhedron. It’s 0 for the cube and nonzero for other Platonic solids, proving that they can’t be cut and rearranged into a cube. See <a href="https://en.wikipedia.org/wiki/Dehn_invariant">the Wikipedia article</a> for more technical details.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/07/15/linkage.html"><span class="datestr">at July 15, 2019 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16778">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/">Itai Benjamini and Jeremie Brieussel: Noise Sensitivity Meets Group Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The final  version of my ICM 2018 paper <a href="https://gilkalai.files.wordpress.com/2019/07/main-pf.pdf">Three puzzles on mathematics computation and games</a> is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to advertise one problem that I mentioned in the paper. You can read more about it in the paper  by Itai Benjamini and  Jeremie Brieussel  <a href="https://arxiv.org/abs/1901.03617">Noise sensitivity of random walks on groups</a> and learn about it also from the videotaped lecture by Jeremie. BTW, the name of my ICM paper is a tribute to Avi Wigdeson’s great book <strong><a href="https://www.math.ias.edu/files/Website03-25-19.pdf#page=1" target="”_blank”">Mathematics and Computation</a> </strong>(see <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this post</a>). Click on the title for an  almost final draft of Avi’s book (March, 25, 2019) soon to be published by Princeton University Press<strong>. </strong>(We are negotiating with Avi on showing here first how the cover of his book will look like.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png?w=640&amp;h=381" class="alignnone size-full wp-image-17590" height="381" /></a></p>
<p><a href="http://friendsofnoise.org/about/">source</a></p>
<h2>The problem of Benjamini and Brieussel and their conjecture</h2>
<p> </p>
<p></p>
<p>Consider an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-step simple random walk (SRW) <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> on a Cayley graph of a finitely generated infinite group <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" />. Refresh independently each step with probability <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, to get <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> from <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" />. Are there groups for which at time <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> the positions <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> and <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> are asymptotically independent? That is, does the <img src="https://s0.wp.com/latex.php?latex=l_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="l_1" class="latex" title="l_1" /> (total variation) distance between the chain <img src="https://s0.wp.com/latex.php?latex=%28X_n%2C+Y_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(X_n, Y_n)" class="latex" title="(X_n, Y_n)" /> and two independent copies <img src="https://s0.wp.com/latex.php?latex=%28X%27_n%2C+X%27%27_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(X'_n, X''_n)" class="latex" title="(X'_n, X''_n)" /> go to 0, as <img src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \to \infty" class="latex" title="n \to \infty" />?</p>
<p>Note that on the line <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z" class="latex" title="\mathbb Z" />, they are uniformally correlated, and therefore also on any group with a nontrivial homomorphism to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R" class="latex" title="\mathbb R" />, or on any group that has a finite index subgroup with a nontrivial homomorphism to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R" class="latex" title="\mathbb R" />. On the free group and for any non-Liouville group, <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> and <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> are correlated as well, but for a different reason: both <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> and <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> have a nontrivial correlation with <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" />.</p>
<p>Itai Benjamini and Jeremie Brieussel conjecture that these are the only ways not to be noise sensitive. That is, if a Cayley graph is Liouville and the group does not have a finite index subgroup with a homomorphism to the reals, then the Cayley graph is noise sensitive for the simple random walk. In particular, the Grigorchuk group is noise sensitive for the simple random walk!</p>
<h3>A paragraph of philosophical nature from Benjamini and Brieussel’s paper.</h3>
<p>“Physically, an <em>ℓ</em><img src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="^1" class="latex" title="^1" />-noise sensitive process can somewhat not be observed, since the observation <img src="https://s0.wp.com/latex.php?latex=Y%5E%5Crho_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y^\rho_n" class="latex" title="Y^\rho_n" /> does not provide any significant information on the actual output <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" />. Speculatively, this could account for the rarity of Liouville groups in natural science. Indeed besides virtually nilpotent ones, all known Liouville groups are genuinely mathematical objects .”</p>
<h3>Polytope integrality gap: An update</h3>
<p>An update on polytope integrality gap:  In my ICM paper and also in <a href="https://gilkalai.wordpress.com/2018/01/21/hardness-of-approximating-vertex-cover-polytope-integrality-gap-the-alswede-kachaterian-theorem-and-more/">this post</a>  I asked the beautiful problem that I learned from Anna Karlin if for vertex cover for every graph G and every vector of weights, there is an efficient algorithm achieving the “polytope integrality gap”.  Anna Karlin kindly informed me that <a href="https://www2.isye.gatech.edu/~msingh94/publications.html">Mohit Singh</a> got in touch with her after seeing the conjecture on my blog and pointed out that the hope for approximating the polytope integrality gap for vertex cover is unlikely to be possible because of its relationship to fractional chromatic number. Mohit noted that fractional chromatic number is hard to approximate even when it is constant assuming UGC. I still think that  the notion of polytope integrality gap for vertex cover as well as for more general problems is important and worth further study.</p>
<p> </p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/"><span class="datestr">at July 15, 2019 08:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4254868758435665114">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html">Two infinite hat problem and a question about what is ``well known''</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
This is a joint post with David Marcus. You will see how he is involved in my next post.<br />
<br />
Two infinite hat problems based on one scenario. I am also curious if they are well known.<br />
<br />
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br />
<br />
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br />
<br />
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br />
<br />
4) The people want to minimize how many they get wrong. <br />
<br />
5) The adversary puts on hats to maximize how many they get wrong.<br />
<br />
I ask two questions  and one meta-question:<br />
<br />
Q1: Is there a solution where they get all but a finite number of the guesses right? (I have blogged about a variant of this one a while back.)<br />
<br />
Q2: Is there a solution where they get all but at most (say) 18 wrong. (My students would say <i>the answer has to be YES or he</i> <i>wouldn't ask it</i>. They don't realize that I work on upper AND lower bounds!)<br />
<br />
Q3: How well known is problem Q1 and the solution?  Q2 and the solution? I've seen Q1 and its solution around (not sure where), but the only source on Q2 that I know of is CAN'T TELL YOU IN THIS POST, WILL IN THE NEXT POST. So, please leave a comment telling me if you have seen Q1 or Q2 and solutions. And if so then where.<br />
<br />
Feel free to leave any comments you want; however, I warn readers who want to solve it themselves to not look at the comments, or at my next post.<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/07/two-infinite-hat-problem-and-question.html"><span class="datestr">at July 15, 2019 03:12 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4253">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4253">On two blog posts of Jerry Coyne</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>A few months ago, I got to know <a href="https://en.wikipedia.org/wiki/Jerry_Coyne">Jerry Coyne</a>, the recently-retired biologist at the University of Chicago who writes the blog <a href="https://whyevolutionistrue.wordpress.com/">“Why Evolution Is True.”</a>  The interaction started when Jerry put up a <a href="https://whyevolutionistrue.wordpress.com/2019/01/15/a-computer-scientist-finds-the-question-of-free-will-uninteresting-for-bad-reasons/">bemused post about my thoughts on predictability and free will</a>, and if I pointed out that if he wanted to engage me on those topics, there was <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">more to go on</a> than an 8-minute YouTube video.  I told Coyne that it would be a shame to get off on the wrong foot with him, since perusal of his blog made it obvious that whatever he and I disputed, it was dwarfed by our areas of agreement.  He and I exchanged more emails and had lunch in Chicago.</p>



<p>By way of explaining how he hadn’t read <a href="https://www.scottaaronson.com/papers/giqtm3.pdf">“The Ghost in the Quantum Turing Machine,”</a> Coyne emphasized the difference in my and his turnaround times: while these days I update my blog only a couple times per month, Coyne often updates multiple times per <em>day</em>.  Indeed the sheer volume of material he posts, on subjects from biology to culture wars to <a href="https://whyevolutionistrue.wordpress.com/2019/02/27/the-chicago-hot-dog-museum-and-our-wonderful-hot-dogs/">Chicago hot dogs</a>, would take months to absorb.</p>



<p>Today, though, I want to comment on just two posts of Jerry’s.</p>



<p>The <a href="https://whyevolutionistrue.wordpress.com/2019/05/17/computer-scientist-david-gelertner-drinks-the-academic-kool-aid-buys-into-intelligent-design/">first post</a>, from back in May, concerns <a href="https://en.wikipedia.org/wiki/David_Gelernter">David Gelernter</a>, the computer science professor at Yale who was infamously injured in a 1993 attack by the Unabomber, and who’s now mainly known as a right-wing commentator.  I don’t know Gelernter, though I did once attend a small interdisciplinary workshop in the south of France that Gelernter also attended, wherein I gave a talk about quantum computing and computational complexity in which Gelernter showed no interest.  Anyway, Gelernter, in an <a href="https://www.claremont.org/crb/article/giving-up-darwin/">essay in May for the <em>Claremont Review of Books</em></a>, argued that recent work has definitively disproved Darwinism as a mechanism for generating new species, and until something better comes along, Intelligent Design is the best available alternative.</p>



<p>Curiously, I think that Gelernter’s argument falls flat not for detailed reasons of biology, but mostly just because it indulges in <em>bad math and computer science</em>—in fact, in precisely the sorts of arguments that I was trying to answer in <a href="https://www.scottaaronson.com/blog/?p=1487">my segment on Morgan Freeman’s </a><em><a href="https://www.scottaaronson.com/blog/?p=1487">Through the Wormhole</a></em> (see also Section 3.2 of <a href="https://www.scottaaronson.com/papers/philos.pdf">Why Philosophers Should Care About Computational Complexity</a>).  Gelernter says that</p>



<ol><li>a random change to an amino acid sequence will pretty much always make it worse,</li><li>the probability of finding a useful new such sequence by picking one at random is at most ~1 in 10<sup>77</sup>, and</li><li>there have only been maybe ~10<sup>40</sup> organisms in earth’s history.</li></ol>



<p>Since 10<sup>77</sup> &gt;&gt; 10<sup>40</sup>, Darwinism is thereby refuted—not in principle, but as an explanation for life on earth.  QED. </p>



<p>The most glaring hole in the above argument, it seems to me, is that it simply ignores <em>intermediate</em> possible numbers of mutations.  How hard would it be to change, not 1 or 100, but 5 amino acids in a given protein to get a usefully different one—as might happen, for example, with local optimization methods like simulated annealing run at nonzero temperature?  And how many chances were there for <em>that</em> kind of mutation in the earth’s history?</p>



<p>Gelernter can’t personally see how a path could cut through the exponentially large solution space in a polynomial amount of time, so he asserts that it’s impossible.  Many of the would-be P≠NP provers who email me every week do the same.  But this particular kind of “argument from incredulity” has an abysmal track record: it would’ve applied equally well, for example, to problems like maximum matching that turned out to have efficient algorithms.  This is why, in CS, we demand better evidence of hardness—like completeness results or black-box lower bounds—neither of which seem however to apply to the case at hand.  Surely Gelernter understands all this, but had he not, he could’ve learned it from my lecture at the workshop in France!</p>



<p>Alas, online debate, as it’s wont to do, focused less on Gelernter’s actual arguments and the problems with them, than on the tiresome questions of “standing” and “status.”  In particular: does Gelernter’s authority, as a noted computer science professor, somehow lend new weight to Intelligent Design?  Or conversely: does the very fact that a computer scientist endorsed ID prove that computer science itself isn’t a real science at all, and that its practitioners should never be taken seriously in any statements about the real world?</p>



<p>It’s hard to say which of these two questions makes me want to bury my face deeper into my hands.  <a href="https://en.wikipedia.org/wiki/Serge_Lang">Serge Lang</a>, the famous mathematician and textbook author, spent much of his later life fervently denying the connection between HIV and AIDS.  <a href="https://en.wikipedia.org/wiki/Lynn_Margulis">Lynn Margulis</a>, the discoverer of the origin of mitochondria (and Carl Sagan’s first wife), died a 9/11 truther.  What broader lesson should we draw from any of this?  And anyway, what percentage of computer scientists actually do doubt evolution, and how does it compare to the percentage in other academic fields and other professions?  Isn’t the question of how divorced we computer scientists are from the real world an … ahem … <strong>empirical</strong> matter, one hard to answer on the basis of armchair certainties and anecdotes?</p>



<p>Speaking of empiricism, if you check Gelernter’s <a href="https://dblp.uni-trier.de/pers/hd/g/Gelernter:David">publication list on DBLP</a> and his <a href="https://scholar.google.ca/scholar?hl=en&amp;as_sdt=0%2C5&amp;q=david+gelernter&amp;btnG=&amp;oq=david+geler">Google Scholar page</a>, you’ll find that he did influential work in programming languages, parallel computing, and other areas from 1981 through 1997, and then in the past 22 years published a grand total of … <strong>two</strong> papers in computer science.  One with four coauthors, the other a review/perspective piece about his earlier work.  So it seems fair to say that, some time after receiving tenure in a CS department, Gelernter pivoted (to put it mildly) away from CS and toward conservative punditry.  His recent offerings, in case you’re curious, include the book <a href="https://www.amazon.com/America-Lite-Imperial-Academia-Dismantled-Obamacrats/dp/1594036063/ref=sr_1_1?keywords=david+gelernter&amp;qid=1563047627&amp;s=gateway&amp;sr=8-1">America-Lite: How Imperial Academia Dismantled Our Culture (and Ushered In the Obamacrats)</a>.</p>



<p>Some will claim that this case underscores what’s wrong with the tenure system itself, while others will reply that it’s precisely what tenure was designed for, even if in this instance you happen to disagree with what Gelernter uses his tenured freedom to say.  The point I wanted to make is different, though.  It’s that the question “what kind of a field is computer science, anyway, that a guy can do high-level CS research on Monday, and then on Tuesday reject Darwinism and unironically use the word ‘Obamacrat’?”—well, even if I accepted the immense weight this question places on one atypical example (which I don’t), and even if I dismissed the power of compartmentalization (which I again don’t), the question <em>still</em> wouldn’t arise in Gelernter’s case, since getting from “Monday” to “Tuesday” seems to have taken him 15+ years.</p>



<p>Anyway, the second post of Coyne’s that I wanted to talk about is <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">from just yesterday</a>, and is about Jeffrey Epstein—the financier, science philanthropist, and confessed sex offender, whose appalling crimes you’ll have read all about this week if you weren’t on a long sea voyage without Internet or something.</p>



<p>For the benefit of my many fair-minded friends on Twitter, I should clarify that I’ve never met Jeffrey Epstein, let alone accepted any private flights to his sex island or whatever.  I doubt he has any clue who I am either—even if he did once claim to be <a href="https://web.archive.org/web/20101112131000/http://www.jeffreyepsteinscience.com/2010/10/the-value-of-quantum-computing-to-jeffrey-epstein/">“intrigued”</a> by quantum information.</p>



<p>I do know a few of the scientists who Epstein once hung out with, including Seth Lloyd and Steven Pinker.  Pinker, in particular, is now facing vociferous attacks on Twitter, similar in magnitude perhaps to what I faced in the comment-171 affair, for having been photographed next to Epstein at a 2014 luncheon that was hosted by Lawrence Krauss (a physicist who later faced sexual harassment allegations of his own).  By the evidentiary standards of social media, this photo suffices to convict Pinker as basically a child molester himself, and is <em>also</em> a devastating refutation of any data that Pinker might have adduced in his books about the Enlightenment’s contributions to human flourishing.</p>



<p>From my standpoint, what’s surprising is not that Pinker is up against this, but that it <em>took this long</em> to happen, given that Pinker’s pro-Enlightenment, anti-blank-slate views have had the effect of painting a giant red target on his back.  Despite the near-inevitability, though, you can’t blame Pinker for wanting to defend himself, as I did when it was my turn for the struggle session.</p>



<p>Thus, in response to an emailed inquiry by Jerry Coyne, Pinker shared some detailed reflections about Epstein; Pinker then gave Coyne permission to post those reflections on his blog (though they were originally meant for Coyne only).  Like everything Pinker writes, they’re <a href="https://whyevolutionistrue.wordpress.com/2019/07/12/tarring-steve-pinker-and-others-with-jeffrey-epstein/">worth reading in full</a>.  Here’s the opening paragraph:</p>



<blockquote class="wp-block-quote"><p>The annoying irony is that I could never stand the guy [Epstein], never took research funding from him, and always tried to keep my distance. Friends and colleagues described him to me as a quantitative genius and a scientific sophisticate, and they invited me to salons and coffee klatches at which he held court. But I found him to be a kibitzer and a dilettante — he would abruptly change the subject ADD style, dismiss an observation with an adolescent wisecrack, and privilege his own intuitions over systematic data.</p></blockquote>



<p>Pinker goes on to discuss his record of celebrating, and extensively documenting, the forces of modernity that led to dramatic reductions in violence against women and that have the power to continue doing so.  On Twitter, Pinker had <a href="https://twitter.com/sapinker/status/1149154274787627010">already written</a>: “Needless to say I condemn Epstein’s crimes in the strongest terms.”</p>



<p>I probably should’ve predicted that Pinker would then be attacked again—this time, for having prefaced his condemnation with the phrase “needless to say.”  The argument, as best I can follow, runs like this: given all the isms of which woke Twitter has already convicted Pinker—scientism, neoliberalism, biological determinism, etc.—how could Pinker’s being against Epstein’s crimes (which we recently learned probably include the <a href="https://www.cnn.com/videos/us/2019/07/10/jeffrey-epstein-accuser-speaks-out-today-show-nbc-intv-sot-newday-vpx.cnn">rape</a>, and not only statutorily, of a 15-year-old) <em>possibly</em> be assumed as a given?</p>



<p>For the record, just as Epstein’s friends and enablers weren’t confined to one party or ideology, so the public condemnation of Epstein strikes me as a matter that is (or should be) beyond ideology, with all reasonable dispute now confined to the space between “very bad” and “extremely bad,” between “lock away for years” and “lock away for life.”</p>



<p>While I didn’t need Pinker to tell me <em>that</em>, one reason I personally appreciated his comments is that they helped to answer a question that had bugged me, and that none of the mountains of other condemnations of Epstein had given me a clear sense about.  Namely: supposing, hypothetically, that I’d met Epstein around 2002 or so—without, of course, knowing about his crimes—would I have been as taken with him as many other academics seem to have been?  (Would <em>you</em> have been?  How sure are you?)</p>



<p>Over the last decade, I’ve had the opportunity to meet some titans and semi-titans of finance and business, to discuss quantum computing and other nerdy topics.  For a few (by no means all) of these titans, my overriding impression was <em>precisely</em> their unwillingness to concentrate on any one point for more than about 20 seconds—as though they wanted the crust of a deep intellectual exchange without the meat filling.  My experience with them fit Pinker’s description of Epstein to a T (though I hasten to add that, as far as I know, none of these others ran teenage sex rings).</p>



<p>Anyway, given all the anger at Pinker for having intersected with Epstein, it’s ironic that I could easily imagine Pinker’s comments rattling Epstein the most of anyone’s, if Epstein hears of them from his prison cell.  It’s like: Epstein must have developed a skin like a rhinoceros’s by this point about being called a child abuser, a creep, and a thousand similar (and similarly deserved) epithets.  But “a kibitzer and a dilettante” who merely lured famous intellectuals into his living room, with wads of cash not entirely unlike the ones used to lure teenage girls to his massage table?  Ouch!</p>



<p>OK, but what about Alan Dershowitz—the man who apparently used to be Epstein’s close friend, who still is Pinker’s friend, and who played a crucial role in securing Epstein’s 2008 plea bargain, the one now condemned as a travesty of justice?  I’m not sure how I feel about Dershowitz.  It’s like: I understand that our system requires attorneys willing to mount a vociferous defense even for clients who they privately know or believe to be guilty—and even to get those clients off on technicalities or bargaining whenever they can.  I’m also incredibly grateful that I chose CS rather than law school, because I don’t think I could last an hour advocating causes that I knew to be unjust.  Just like my fellow CS professor, the intelligent design advocate David Gelernter, I have the privilege and the burden of speaking only for myself.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4253"><span class="datestr">at July 13, 2019 11:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html">Connectivity and finiteness in modal graph logic</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I read with interest Joel David Hamkins’ recent blog post on <a href="http://jdh.hamkins.org/modal-model-theory/">modal model theory</a>.
This week, on a long plane flight home from Italy, I was inspired to play with the modal logic of graphs, in which one describes properties of graphs by simpler properties of their (induced) supergraphs. My interest is less in what this says about set theory and model theory, and more in how expressive this language is: which graph properties can it describe? Joel showed in his post how to describe -colorability in this theory, but I thought it would be of interest to start with something simpler than an -complete problem. And what could be simpler for graphs than testing whether a graph is connected or finite?</p>

<h1 id="the-basics-of-modal-graph-logic">The basics of modal graph logic</h1>

<p><a href="https://en.wikipedia.org/wiki/Modal_logic">Modal logic</a> is a logic of “possible worlds” with two operators on formulas,  (it is possible for  to be true, in at least one possible world) and  (it is necessary for  to be true, in all possible worlds).
Modal graph logic applies this idea to the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a>, in which one can quantify over variables that represent graph vertices and use a binary predicate  representing adjacency of pairs of vertices. I’ll assume here that all graphs are simple and undirected (i.e.,  is irreflexive and commutative). A given graph  models a given first-order formula  (written as ) if the formula becomes true when you evaluate it in the obvious way for the given graph. In the modal logic of graphs, the possible worlds are graphs containing  as an induced subgraph. So  means that it is possible for  to be modeled by one of these larger graphs and  means that it is necessary for  to be modeled by all of these larger graphs. If we apply a modal operator to a formula  that is itself modal, the possible worlds of the modal operators within  are supergraphs of these larger graphs, in the same way (in modal logic terminology, we are assuming S4 accessibility of possible worlds).</p>

<p>In some ways this is enormously powerful: the class of all graphs containing  is so big that it’s not even a set, and it can encode arbitrarily complicated structures. In other ways this is more highly constrained than other graph logics like monadic second-order logic (in which one can describe and quantify sets of vertices or edges, but not more complicated structures like sequences of vertices or strategy trees over games defined on the graph). The issue is that in a possible world, one can’t tell the vertices that were part of the base graph apart from the ones that were added later, except possibly for a finite set of vertices named in variables outside the modal operator. So while the possible worlds that model a given formula can be very large and complicated, it can be difficult to anchor these castles in the air to the base graph that you started with.</p>

<p>Joel’s description of how to express -colorability suggests a path around this difficulty: Suppose we want to test a hereditary property  of graphs (one that extends from any graph to its induced subgraphs) such as colorability. Then we should look for a family of self-verifyingly- graphs: a family of graphs with property  such that membership in the family can be tested by a first-order formula  and such that every graph with property  is an induced subgraph of a larger graph in this family. If we can find such a family and first-order formula , then  will describe property  itself. For instance, for colorability, the self-verifyingly--colorable graphs are graphs in which each color class has a universal vertex, every vertex is adjacent to all but one of the universal vertices, and no two adjacent vertices are both non-adjacent to the same universal vertex.</p>

<p>Similar ideas can also work when the property is not hereditary (for instance, a graph has chromatic number 3 when it is 3-colorable but not 2-colorable) or when checking membership in the family of self-verifying graphs itself involves modal logic (as we’ll see for testing finiteness).</p>

<h1 id="connectivity">Connectivity</h1>

<p>Connectivity is not hereditary: every connected graph is part of a larger disconnected graph and vice versa. But the property that some particular pair of vertices  is separated is hereditary: if  is separated from , the two vertices remain separated in any induced subgraph that contains them both. And while it’s not possible to verify this directly in a first order formula, for all graphs, it is possible in a special family of disconnected graphs, the ones containing a <em>transitive vertex</em>, one whose neighborhood forms a connected component of the graph. We can define a formula</p>



<p>which characterizes these transitive vertices. (Here I am using  to mean syntactic equivalence of formulas or definition of the name of a formula, rather than its meaning in Joel’s post, equivalence of models.) Then we can test whether  is separated from  by the formula</p>



<p>(Here, the instance of “transitive” on the right hand side is not a unary predicate, even though it looks like one; it should be expanded by the definition of the “transitive” formula to produce the resulting “separated” formula. Think of it as being like a C preprocessor macro.)
If  is indeed separated from , there is a possible world modeling the formula, in which we add an extra vertex  to the starting graph, adjacent to everything in the connected component of . And in any possible world modeling the formula,  is separated from , and this must remain true in every induced subgraph of this possible world, including the base graph. Finally, a graph is connected if and only if it has no separated pair:</p>



<p>In MSO logic, one of the standard tools is the <em>method of syntactic interpretations</em>. This allows you to modify your base graph  to form a different graph  (for any of certain standard types of modification) and test whether the resulting graph models a given formula . To do this, you instead modify the formula (in certain purely mechanical ways derived from how you were modifying ) and test whether your original graph models the modified formula . The same thing works in first-order logic and in modal logic, and allows such modifications as adding or removing an edge between given vertices, removing any given vertex, restricting to a logically-specified induced subgraph, or adding a new vertex with a logically-specified adjacency relation. I’ll write  for the modified formula that simulates formula  on the modified graph . We can use this idea to extend connectedness to other properties; for instance, a graph is a forest if it has no cycle, and this is true if every edge removal disconnects it:</p>



<h1 id="finiteness">Finiteness</h1>

<p>Following the earlier outline,
I’d like to find a simple family of finite graphs for which their finiteness is
so obvious that it can be tested by a simple logical formula, and then embed
every finite graph into one of these simple finite graphs.</p>

<p>The first natural choice of such a family is the family of paths.
We can define a path to be a connected graph with exactly two degree-one vertices in which all remaining vertices have degree two. Checking the degrees is first order, but I’ll spare you the messy details of the formula. All such graphs are finite, because a graph is connected if and only if every two vertices are a finite distance apart, and when the endpoints of a path are a finite distance apart there can be only finitely many other degree-two vertices between them. Any other vertices outside of this finite set must belong to a different component.</p>

<p>Not every finite graph can be embedded into a path. However, every finite graph has a perfect matching to the vertices of a path. To check the existence of an induced perfect matching between two sets of vertices in a graph, it’s helpful to have an extra vertex  that is not part of the matching, but that distinguishes one side of the matching (the neighbors of ) from the other side:</p>



<p>Here,  is shorthand for the <a href="https://en.wikipedia.org/wiki/Uniqueness_quantification">existence of exactly one thing</a>. With this test for an induced perfect matching in hand, we can check for a perfect matching to a finite path by</p>



<p>where  denotes the open neighborhood of , the graph induced by the vertices adjacent to .</p>

<p>I don’t think it’s possible to test finiteness in the same way in MSO.
We can define paths in MSO, and force them to have a perfect induced matching to the remaining vertices. But the recipe above breaks down at the point where it embeds the given graph into a supergraph, not generally possible in MSO. More generally I don’t think it’s possible in MSO to distinguish the family of finite complete graphs from their limit, the countable complete graph.</p>

<h1 id="additional-properties">Additional properties</h1>

<p>The same technology of paths and matchings can also be used to formulate not-very-natural properties of finite graphs that are definitely not expressible in MSO. For instance, we can check whether a graph  is the disjoint union of two equal-length paths, by first checking that it is a forest with four degree-one vertices and the rest degree-two, and then checking that both paths can be simultaneously perfectly matched to a third path of remaining vertices (with an additional vertex used to distinguish the sides of the matching as above). When this structure exists, the whole graph forms a polyhedron in the form of a  grid with the sides of the grid connected to the distinguishing vertex, and this polyhedral structure can be used to prove that we cannot trick the formula by adding new paths connecting the original path endpoints. In contrast, MSO cannot express equality of path lengths, because (per <a href="https://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle’s theorem</a>) it can only express properties of path-like graphs that can be expressed as regular languages (over bounded-width path-decompositions of the graph), and equality of length is context-free but not regular for path-decompositions that concatenate the two paths separately.</p>

<p>It’s also possible to express that the <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)">degeneracy of a graph</a> is at most some constant  in modal logic. As special cases, the graphs of degeneracy zero are the independent sets (first-order expressible) and the graphs of degeneracy one are the forests, which we’ve already seen how to express. Otherwise, we can represent sequences of vertices by <em>ladders</em>, paths of degree-three vertices matched to independent sets of degree-two vertices, with the represented sequence being the other endpoints of these degree-two vertices. Adding a ladder to a graph of degeneracy at least two doesn’t change its degeneracy, and we can express the existence of a degeneracy ordering of a finite graph (a sequence of the vertices such that all vertices have at most  neighbors that are later in the sequence) by the addition of a ladder with a designated starting vertex that touches all non-ladder vertices.
Each non-ladder vertex  should have at most  neighbors with the property that, within the ladder, the ladder vertex nearest  separates the top of the ladder from the ladder vertices nearest these neighbors.</p>

<p>We can <a href="https://11011110.github.io/blog/2019/01/17/orientations-infinite-graphs.html">extend the concept of degeneracy from finite to infinite graphs</a>
by requiring that every finite subgraph have degeneracy at most .
With this definition, we can identify a finite subgraph as the neighbors of a ladder, and then use the formula for finite-graph degeneracy on these neighbors.
This leads to a modal logic expression for infinite graph degeneracy in which the overall structure of the formula is that it is necessary that, whenever a vertex  forms the start of a ladder, it should be possible for there to exist another ladder defining a degeneracy ordering for ’s ladder and its neighbors.</p>

<p>I suspect, although I haven’t worked out all the details, that planarity testing is also expressible in modal logic. Here’s the outline of an idea for proving this. First, we can check that the graph is finite, to avoid complications of which infinite graphs should be considered to be planar or what a drawing of an infinite planar graph might look like. Next, a graph is planar if and only if it is an induced subgraph of a maximal planar graph, one in which all edges belong to exactly two <a href="https://en.wikipedia.org/wiki/Peripheral_cycle">peripheral triangles</a>. A graph with this two-peripheral-triangle property is planar if and only if one can partition its edges into two subsets, one of which forms a spanning tree for the graph and the other of which forms a spanning tree for the dual graph of the peripheral cycles. (The two-peripheral-triangle property defines a surface embedding which, if non-planar, would have some leftover edges that are neither part of a spanning tree nor a complementary dual spanning tree; see my paper “<a href="https://www.ics.uci.edu/~eppstein/pubs/p-dyngen.html">Dynamic generators of topologically embedded graphs</a>”.) And it should be possible to describe this partition in a planarity-preserving way by decorating the edges on one side of the partition by additional small planar graphs (maybe even just attaching a triangle to each decorated edge). So all we need to check is that it’s possible for the given graph to be part of a larger graph
that looks like a maximal planar graph with some decorated edges (ignoring the decorations, each edge belongs to two peripheral triangles) and that the decorations describe a spanning tree and a dual spanning tree. We already know how to describe spanning trees and dual spanning trees should also be possible using similar logic.</p>

<p>One natural and simple property that I don’t see how to express in modal logic is regularity. One can ask: do each two vertices have the same degree? And equality of sets of vertices can be checked by the existence of perfect matchings, as in the two-equal-paths example. But how do we know, in a possible world, which neighbors of two given vertices are original and which are added? For the same reason, the property of having a perfect matching seems difficult to express in modal logic, even though it is easy in MSO. Again, it seems difficult to impose any extra structure on a supergraph without losing too much information about which parts of the graph are original.</p>

<h1 id="standard-and-nonstandard-models">Standard and nonstandard models</h1>

<p>I have been (deliberately) naive here about what kind of set theory I am using to define my graphs, what “all induced supergraphs” means (do I consider graphs only over some set of candidate vertices, or the proper class of all graphs in some set theory), and whether there is always a “correct” value of  that our models of modal graph logic should produce for a given graph and formula. If these naive assumptions are not valid, the description of what these formulas express may be inaccurate.</p>

<p>In particular, the claim that a graph is connected if and only if every two vertices are a finite distance apart uses concepts of distance that go beyond the first-order theory of graphs. In non-standard models of set theory, or in standard models of set theory but with non-standard collections of possible worlds that are not really the collection of all induced supergraphs of a given graph, that claim may fail to be true. In such cases, the finiteness formula may determine that an infinite graph (one that models the first-order logical formulas stating that there exist at least  distinct vertices, for every finite integer ) is finite. It’s not a bug in the formula, just an indication that you need to be careful about your models. Or in computer science terms, <a href="https://en.wikipedia.org/wiki/Garbage_in,_garbage_out">GIGO</a>.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102438063877916451">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/07/13/connectivity-finiteness-modal.html"><span class="datestr">at July 13, 2019 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16085">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/">Tools and Sensitivity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Cutting right through a 30-year-old conjecture</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/haohuangcropped/" rel="attachment wp-att-16086"><img width="148" alt="" src="https://rjlipton.files.wordpress.com/2019/07/haohuangcropped.jpg?w=148&amp;h=212" class="alignright wp-image-16086" height="212" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Emory <a href="http://www.mathcs.emory.edu/~hhuan30/">homepage</a></font></td>
</tr>
</tbody>
</table>
<p>
Hao Huang is a mathematician and computer scientist at Emory University. Last week he released a <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">paper</a> of only six pages that solves the Boolean Sensitivity Conjecture, which goes back at least to a 1992 <a href="https://www.researchgate.net/publication/2508255_On_the_Degree_of_Boolean_Functions_as_Real_Polynomials">paper</a> by Noam Nisan and Mario Szegedy.</p>
<p>
Today we discuss his brilliant proof and what it means for sensitivity of the <em>tools</em> one employs.<br />
<span id="more-16085"></span></p>
<p>
Several of our blogging friends have <a href="https://www.scottaaronson.com/blog/?p=4229">covered</a> this <a href="https://gilkalai.wordpress.com/2019/07/02/amazing-hao-huang-proved-the-sensitivity-conjecture/">news</a> in <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posts</a> <a href="https://windowsontheory.org/2019/07/02/sensitivity-conjecture-proved/">already</a>, and Ryan O’Donnell even summarized the proof in one <a href="https://twitter.com/BooleanAnalysis/status/1145837576487612416">tweet</a>. Scott Aaronson’s thread includes a <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813116">comment</a> by Huang on how he came by his proof. </p>
<p>
We will try to draw implications for the related matter of how <em>you</em> might come by proofs of <em>other</em> conjectures. We have previously <a href="https://rjlipton.wordpress.com/2016/04/09/missing-mate-in-ten/">discussed</a> the possibility of overlooking short solutions to major problems. Here we will discuss how to <em>find</em> them.</p>
<p>
</p><p></p><h2> A Graph Puzzle </h2><p></p>
<p></p><p>
To get a flavor of what Huang proved, consider the graph of an ordinary <a href="https://commons.wikimedia.org/wiki/File:Cube_graph.png">cube</a>:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph/" rel="attachment wp-att-16087"><img width="192" alt="" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph.png?w=192&amp;h=181" class="aligncenter wp-image-16087" height="181" /></a></p>
<p></p><p><br />
The question is, <em>can you color 5 vertices red so that no red node has 3 red neighbors?</em> Your first impulse might be to color 4 nodes red according to parity so that none has a red neighbor, per below left:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_tries/" rel="attachment wp-att-16088"><img width="450" alt="" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_tries.png?w=450&amp;h=175" class="aligncenter wp-image-16088" height="175" /></a></p>
<p></p><p><br />
But then any 5th node will have 3 red neighbors. Another “greedy” idea is to pack a subgraph of the allowed degree 2 into half the cube, as at right. Any 5th node will again create a degree-3 vertex in the subgraph induced by the red nodes.</p>
<p>
The answer is that actually one can pack 6 nodes that induce a simple cycle:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/cube_graph_solved/" rel="attachment wp-att-16089"><img width="192" alt="" src="https://rjlipton.files.wordpress.com/2019/07/cube_graph_solved.png?w=192&amp;h=181" class="aligncenter wp-image-16089" height="181" /></a></p>
<p></p><p><br />
Now let’s up the dimension by one—that is, take <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 4}" class="latex" title="{n = 4}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En+%3D+16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N = 2^n = 16}" class="latex" title="{N = 2^n = 16}" />. How many nodes can we color red and keep the induced degree 2? </p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph/" rel="attachment wp-att-16091"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph-1.png?w=300&amp;h=230" class="aligncenter wp-image-16091" height="230" /></a></p>
<p></p><p><br />
Again the parity trick gives us degree 0 with 8 nodes, but then we can’t add a 9th. We can greedily try to pack the outer cube with our 6-node solution, but then—perhaps surprisingly—we can add only 2 more red nodes from the inner cube. So we can only do 5 from the outer cube. We can get 9 overall by:</p>
<p><a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/hypercube_graph_try10/" rel="attachment wp-att-16092"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2019/07/hypercube_graph_try10.png?w=300&amp;h=230" class="aligncenter wp-image-16092" height="230" /></a></p>
<p></p><p><br />
The fact that one red node is isolated seems to give room to improve, but there is no way to make 10. </p>
<p>
</p><p></p><h2> The Theorem </h2><p></p>
<p></p><p>
The calculations have left an interesting jump from degree 0 with eight red nodes and degree 2 with nine. How about degree 1? Can we do that with 9 nodes? We can pack four disjoint edges but then there is nowhere to stick an isolated node. </p>
<p>
So for 9 nodes, which is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{N}{2} + 1}" class="latex" title="{\frac{N}{2} + 1}" />, the best we can do is degree 2, which is <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{n}}" class="latex" title="{\sqrt{n}}" />. This is what Huang proved:</p>
<blockquote><p><b>Theorem 1</b> <em><a name="graphs"></a> Every subgraph induced by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\frac{N}{2} + 1}" class="latex" title="{\frac{N}{2} + 1}" /> nodes of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-dimensional hypercube graph has a node of degree at least <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\sqrt{n}}" class="latex" title="{\sqrt{n}}" />. </em>
</p></blockquote>
<p></p><p>
This is completely tight. When <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is a perfect square there is a way to achieve <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{n}}" class="latex" title="{\sqrt{n}}" /> as the maximum degree (shown <a href="https://pdfs.semanticscholar.org/3917/3e0cb4e028c94328f1355bf02febea132127.pdf">here</a>). Otherwise the least integer above <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{n}}" class="latex" title="{\sqrt{n}}" /> is best. Thus every subgraph of the <img src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5}" class="latex" title="{5}" />-cube induced by 17 nodes has a node with three neighbors, but you can go as high as 257 nodes in the <img src="https://s0.wp.com/latex.php?latex=%7B9%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{9}" class="latex" title="{9}" />-cube while keeping the maximum degree to 3.</p>
<p>
We will mention the relation to Boolean sensitivity only briefly. The nodes of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-cube correspond to truth assignments in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0,1\}^n}" class="latex" title="{\{0,1\}^n}" />. Since every red node <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> has <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> neighbors in the cube but at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{n}}" class="latex" title="{\sqrt{n}}" /> red neighbors, the color function is highly sensitive to bitflips. But every flip also changes the parity of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. Hence the <em>exclusive-or</em> of the color function with the parity function has <em>low</em> sensitivity. </p>
<p>
But not too low: Huang proved it is at least <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{n}}" class="latex" title="{\sqrt{n}}" />. That was enough to prove the conjecture. I’ve cut two sections on Boolean sensitivity from this post’s <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">original draft</a>—let’s just say the connection to the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-cube and graph degree was known since this 1992 <a href="https://www.sciencedirect.com/science/article/pii/0097316592900608">paper</a>. Here we’ll focus on what it took to prove this theorem.</p>
<p>
</p><p></p><h2> The Proof </h2><p></p>
<p></p><p>
From my undergrad days I’ve kept an interest in spectral graph theory. One of the basic facts is that the degree <img src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d(G)}" class="latex" title="{d(G)}" /> of a graph <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is always at least as great as the largest eigenvalue <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> of its adjacency matrix <img src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_G}" class="latex" title="{A_G}" />. For a <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-regular graph they are equal. Huang’s first trick is to note that the classic proof of this also allows <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> values on edges:</p>
<blockquote><p><b>Lemma 2</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> be a symmetric matrix obtained from <img src="https://s0.wp.com/latex.php?latex=%7BA_G%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A_G}" class="latex" title="{A_G}" /> by multiplying some entries by <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> any of its eigenvalues. Then <img src="https://s0.wp.com/latex.php?latex=%7Bd%28G%29+%5Cgeq+%7C%5Clambda%7C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{d(G) \geq |\lambda|}" class="latex" title="{d(G) \geq |\lambda|}" />. </em>
</p></blockquote>
<p></p><p>
<em>Proof:</em>  Choose an eigenvector <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BAv+%3D+%5Clambda+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Av = \lambda v}" class="latex" title="{Av = \lambda v}" /> and take an index <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> that maximizes <img src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|v_i|}" class="latex" title="{|v_i|}" />. Then </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7C%5Clambda+v_i%7C+%3D+%7C%28A+v%29_i%7C+%3D+%7C%5Csum_j+A_%7Bi%2Cj%7D+v_j%7C+%5Cleq+%7C%5Csum_j+A_%7Bi%2Cj%7D%7C+%5Ccdot+%7Cv_i%7C+%5Cleq+%5Csum_%7B%28i%2Cj%29+%5Cin+E%28G%29%7D+%7CA_%7Bi%2Cj%7D%7C%5Ccdot+%7Cv_i%7C+%5Cleq+d%28G%29%7Cv_i%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. " class="latex" title="\displaystyle  |\lambda v_i| = |(A v)_i| = |\sum_j A_{i,j} v_j| \leq |\sum_j A_{i,j}| \cdot |v_i| \leq \sum_{(i,j) \in E(G)} |A_{i,j}|\cdot |v_i| \leq d(G)|v_i|. " /></p>
<p>Dividing out <img src="https://s0.wp.com/latex.php?latex=%7B%7Cv_i%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|v_i|}" class="latex" title="{|v_i|}" /> gives the lemma. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p></p><p><br />
So now what we want to do is find conditions that force <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda+%3D+%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda = \sqrt{n}}" class="latex" title="{\lambda = \sqrt{n}}" /> when <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is a <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" />-vertex subgraph of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-cube with <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Cgeq+%5Cfrac%7BN%7D%7B2%7D+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \geq \frac{N}{2} + 1}" class="latex" title="{m \geq \frac{N}{2} + 1}" />, where <img src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N = 2^n}" class="latex" title="{N = 2^n}" />. The trick that Huang realized is that he could do this by making <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> sit inside a matrix <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N}" class="latex" title="{A_N}" /> with at least <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{N}{2}}" class="latex" title="{\frac{N}{2}}" /> eigenvalues of <img src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+\sqrt{n}}" class="latex" title="{+\sqrt{n}}" />. </p>
<p>
To see how, form <img src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{N-1}}" class="latex" title="{A_{N-1}}" /> by knocking out the last row and column of <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N}" class="latex" title="{A_N}" />. Since <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N}" class="latex" title="{A_N}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BA_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{N-1}}" class="latex" title="{A_{N-1}}" /> are both real and symmetric, their eigenvalues are real, so we can order them <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1%2C%5Cdots%2C%5Clambda_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda_1,\dots,\lambda_N}" class="latex" title="{\lambda_1,\dots,\lambda_N}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu_1%2C%5Cdots%2C%5Cmu_%7BN-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu_1,\dots,\mu_{N-1}}" class="latex" title="{\mu_1,\dots,\mu_{N-1}}" /> in nonincreasing order. The basic fact is that they always <em>interlace</em>: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1+%5Cgeq+%5Cmu_1+%5Cgeq+%5Clambda_2+%5Cgeq+%5Cmu_2+%5Cgeq+%5Clambda_3+%5Cgeq+%5Ccdots+%5Cgeq+%5Cmu_%7BN-1%7D+%5Cgeq+%5Clambda_N.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. " class="latex" title="\displaystyle  \lambda_1 \geq \mu_1 \geq \lambda_2 \geq \mu_2 \geq \lambda_3 \geq \cdots \geq \mu_{N-1} \geq \lambda_N. " /></p>
<p>See <a href="https://arxiv.org/pdf/math/0502408.pdf">this</a> for a one-page proof. The neat point is that you can repeat this: if you get <img src="https://s0.wp.com/latex.php?latex=%7BA%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A''}" class="latex" title="{A''}" /> by knocking out another row and corresponding column, and <img src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cnu_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[\nu_i]}" class="latex" title="{[\nu_i]}" /> are its eigenvalues in order, then </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmu_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Cmu_2+%5Cgeq+%5Cnu_2+%5Cgeq+%5Cmu_3+%5Ccdots.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. " class="latex" title="\displaystyle  \mu_1 \geq \nu_1 \geq \mu_2 \geq \nu_2 \geq \mu_3 \cdots. " /></p>
<p>It follows that <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_1+%5Cgeq+%5Cnu_1+%5Cgeq+%5Clambda_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda_1 \geq \nu_1 \geq \lambda_3}" class="latex" title="{\lambda_1 \geq \nu_1 \geq \lambda_3}" />. If you do this again, you get a matrix whose leading eigenvalue is still at least as big as <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda_4}" class="latex" title="{\lambda_4}" />. Do it <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{N}{2} - 1}" class="latex" title="{\frac{N}{2} - 1}" /> times inside <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N}" class="latex" title="{A_N}" />, and you’re still above <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda_%7BN%2F2%7D%28A_N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda_{N/2}(A_N)}" class="latex" title="{\lambda_{N/2}(A_N)}" />, which we just said we will arrange to be <img src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+\sqrt{n}}" class="latex" title="{+\sqrt{n}}" />. Thus if we knock out the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BN%7D%7B2%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{N}{2} - 1}" class="latex" title="{\frac{N}{2} - 1}" /> white nodes, we will get the graph on the red nodes with adjacency matrix <img src="https://s0.wp.com/latex.php?latex=%7BA_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_m}" class="latex" title="{A_m}" /> and conclude: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda_1%28A_N%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) " class="latex" title="\displaystyle  \lambda_1(A_N) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) " /></p>
<p>Plugging into the lemma gives: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++d%28G%29+%5Cgeq+%5Clambda_1%28A_m%29+%5Cgeq+%5Clambda_%7BN%2F2%7D%28A_N%29+%3D+%5Csqrt%7Bn%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. " class="latex" title="\displaystyle  d(G) \geq \lambda_1(A_m) \geq \lambda_{N/2}(A_N) = \sqrt{n}. " /></p>
<p>(In fact, as also <a href="https://www.scottaaronson.com/blog/?p=4229#comment-1813084">noted</a> on Scott’s blog, this case of interlacing can be inferred from simpler reasoning—but our point is that the interlacing theorem was in Huang’s bag of tricks.) </p>
<p>
</p><p></p><h2> Building the Matrix </h2><p></p>
<p></p><p>
Finally, how do we lay hands on <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N}" class="latex" title="{A_N}" />? We want a matrix of trace zero such that <img src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N^2 = nI}" class="latex" title="{A_N^2 = nI}" />. Then all its eigenvalues are <img src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+\sqrt{n}}" class="latex" title="{+\sqrt{n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B-%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-\sqrt{n}}" class="latex" title="{-\sqrt{n}}" />.  They come in equal numbers because they sum to the trace which is zero. So we will have <img src="https://s0.wp.com/latex.php?latex=%7BN%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N/2}" class="latex" title="{N/2}" /> eigenvalues of <img src="https://s0.wp.com/latex.php?latex=%7B%2B%5Csqrt%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+\sqrt{n}}" class="latex" title="{+\sqrt{n}}" />, as needed. And we would want <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N}" class="latex" title="{A_N}" /> to be the matrix of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-cube but that doesn’t work: each <img src="https://s0.wp.com/latex.php?latex=%7Bi%2Cj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i,j}" class="latex" title="{i,j}" /> entry of its square counts all paths of length 2 from node <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> to node <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> and that number can be nonzero.</p>
<p>
This is where the trick of putting <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> on edges comes in, and we can explain it in a way familiar from quantum. We arrange that every 4-cycle of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-cube has exactly one edge with <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" />. Then the pairs of paths from one corner to the opposite corner will always <em>cancel</em>, leaving <img src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^2_{i,j} = 0}" class="latex" title="{A^2_{i,j} = 0}" /> whenever <img src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cneq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i \neq j}" class="latex" title="{i \neq j}" />. And <img src="https://s0.wp.com/latex.php?latex=%7BA%5E2_%7Bi%2Cj%7D+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^2_{i,j} = n}" class="latex" title="{A^2_{i,j} = n}" /> because there are <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> ways to go out and come back along the same edge, always contributing <img src="https://s0.wp.com/latex.php?latex=%7B1%5Ccdot+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1\cdot 1}" class="latex" title="{1\cdot 1}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5Ccdot%28-1%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(-1)\cdot(-1) = 1}" class="latex" title="{(-1)\cdot(-1) = 1}" /> either way. Huang defines the needed labeling explicitly by the recursion: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_2+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+1+%5C%5C+1+%26+0+%5Cend%7Bbmatrix%7D%2C%5Cquad%5Ctext%7Band+for+%7D+N+%3E+2%2C%5Cquad+A_N+%3D+%5Cbegin%7Bbmatrix%7D+A_%7BN%2F2%7D+%26+I+%5C%5C+I+%26+-A_%7BN%2F2%7D+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. " class="latex" title="\displaystyle  A_2 = \begin{bmatrix} 0 &amp; 1 \\ 1 &amp; 0 \end{bmatrix},\quad\text{and for } N &gt; 2,\quad A_N = \begin{bmatrix} A_{N/2} &amp; I \\ I &amp; -A_{N/2} \end{bmatrix}. " /></p>
<p>This puts a <img src="https://s0.wp.com/latex.php?latex=%7B-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-}" class="latex" title="{-}" /> sign on exactly one-fourth of the entries in the needed way. OK, we changed Huang’s subscripts for consistency with “<img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N}" class="latex" title="{A_N}" />” above and also to note that the basis could be <img src="https://s0.wp.com/latex.php?latex=%7BA_1+%3D+%5B0%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_1 = [0]}" class="latex" title="{A_1 = [0]}" />.  Anyway, he verifies <img src="https://s0.wp.com/latex.php?latex=%7BA_N%5E2+%3D+nI%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_N^2 = nI}" class="latex" title="{A_N^2 = nI}" /> directly by simple algebra and induction.  That’s it—that’s the proof.</p>
<p>
Why was it hard to spot? Dick and I believe it was the <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> trick. In the 1980s, I thought about ways to convert undirected graphs into directed ones by putting arrows on the edges, but not <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> signs. The chance of thinking of it maybe rises with knowing quantum ideas such as interference and amplification. Now we can see, OK, <img src="https://s0.wp.com/latex.php?latex=%7BA_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_2}" class="latex" title="{A_2}" /> is the quantum NOT gate and the recursion treats signs in similar fashion to the recursion defining Hadamard matrices.  The matrix <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Csqrt%7Bn%7D%7DA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{1}{\sqrt{n}}A_N}" class="latex" title="{\frac{1}{\sqrt{n}}A_N}" /> is unitary, so it defines a quantum operator. This all goes to our main point about having tools at one’s command—the more tools, the better. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Huang’s theorem still leaves a gap between a quadratic lower bound and his 4th-power upper bound (my longer <a href="https://cse.buffalo.edu/~regan/cse705/wsensitivity.pdf">draft</a> lays this out).  Can this gap be closed?  In discussing this, Huang notes that his spectral methods need not be confined to sub-matrices of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-cube, and our thoughts of involving quantum are similar. Can quantum tools improve the results even further?</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2019/07/12/tools-and-sensitivity/"><span class="datestr">at July 12, 2019 10:51 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1705625191398821823">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html">Degree and Sensitivity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Hao Huang's <a href="https://arxiv.org/abs/1907.00847">proof of the sensitivity conjecture</a> that I <a href="https://blog.computationalcomplexity.org/2019/07/local-kid-makes-history.html">posted on last week</a> relied on a 1992 <a href="https://doi.org/10.1016/0097-3165(92)90060-8">result of Gotsman and Linial</a>. Let's talk about that result.<br />
<br />
Consider the set S={-1,1}<sup>n</sup>. The hypercube of dimension n is the graph with vertex set S and an edge between x = (x<sub>1</sub>,…,x<sub>n</sub>) and y = (y<sub>1</sub>,…,y<sub>n</sub>) in S if there is exactly one i such that x<sub>i</sub> ≠ y<sub>i</sub>. Every vertex has degree n.<br />
<br />
We say a vertex x is odd if x has an odd number of -1 coordinates, even otherwise. Every edge joins an odd and even vertex.<br />
<br />
Let f be a function mapping S to {-1,1}. The sensitivity of f on x is the number of i such that f(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) ≠ f(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>). The sensitivity of f is the maximum over all x in S of the sensitivity of f on x.<br />
<br />
Let g be the same function as f except that we flip the value on all odd vertices. Notice now that the sensitivity of f on x is the number of i such that g(x<sub>1</sub>,…,x<sub>i</sub>,…,x<sub>n</sub>) = g(x<sub>1</sub>,…,-x<sub>i</sub>,…,x<sub>n</sub>).<br />
<br />
Let G be the induced subgraph of vertices of x such that g(x)=-1 and H be induced subgraph on the set of x such that g(x)=1. The sensitivity of f is the maximum number of neighbors of any vertex in G or H.<br />
<br />
Consider f as a multilinear polynomial over the reals. The sensitivity conjecture states there is some α&gt;0 such that if f has degree n then f has sensitivity at least n<sup>α</sup>.<br />
<br />
Note g(x<sub>1</sub>,…,x<sub>n</sub>)=f(x<sub>1</sub>,…,x<sub>n</sub>)x<sub>1</sub>⋯x<sub>n</sub>. If f has a degree n term, the variables in that term cancel out on S (since x<sub>i</sub><sup>2</sup>=1) and the constant of the degree n term of f becomes the constant term of g. The constant term is just the expected value, so f has full degree iff g is unbalanced.<br />
<br />
GL Assumption: Suppose you have a partition of the hypercube into sets A and B with |A| ≠ |B|, and let G and H be the induced subgraphs of A and B. Then there is some constant α&gt;0 such that there is a node of A or B with at least n<sup>α</sup> neighbors.<br />
<br />
The above argument, due to Gotsman and Linial, shows that the GL assumption is equivalent to the sensitivity conjecture.<br />
<br />
Huang proved that given any subset A of the vertices of a hypercube with |A|&gt;2<sup>n</sup>/2 the induced subgraph has a node of degree at least n<sup>1/2</sup>. Since either A or B in the GL assumption has size greater than 2<sup>n</sup>/2, Huang's result gives the sensitivity conjecture.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/07/degree-and-sensitivity.html"><span class="datestr">at July 11, 2019 05:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=656">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/07/10/non-abelian-combinatorics-and-communication-complexity/">Non-abelian combinatorics and communication complexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Below and <a href="http://www.ccs.neu.edu/home/viola/papers/viola-sigact-snafu.pdf">here in pdf</a> is a survey I am writing for SIGACT, due next week.  Comments would be very helpful.</p>
<hr />
<p style="text-align: justify;">Finite groups provide an amazing wealth of problems of interest to complexity theory. And complexity theory also provides a useful viewpoint of group-theoretic notions, such as what it means for a group to be “far from abelian.” The general problem that we consider in this survey is that of computing a <em>group product</em> <img src="https://s0.wp.com/latex.php?latex=g%3Dx_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" title="g=x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" /> over a finite group <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />. Several variants of this problem are considered in this survey and in the literature, including in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKrohnMR66">KMR66</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBarrington89">Bar89</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBen-OrC92">BC92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XImmermanL95">IL95</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBGKL03">BGKL03</a>, <a href="https://emanueleviola.wordpress.com/feed/#XPRS97">PRS97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainis96">Amb96</a>, <a href="https://emanueleviola.wordpress.com/feed/#XAmbainisL00">AL00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaz00">Raz00</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>, <a href="https://emanueleviola.wordpress.com/feed/#XMiles14">Mil14</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<p style="text-align: justify;">Some specific, natural computational problems related to <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> are, from hardest to easiest:</p>
<p style="text-align: justify;">(1) Computing <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" />,</p>
<p style="text-align: justify;">(2) Deciding if <img src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=1_{G}" class="latex" title="g=1_{G}" />, where <img src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{G}" class="latex" title="1_{G}" /> is the identity element of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />, and</p>
<p style="text-align: justify;">(3) Deciding if <img src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=1_{G}" class="latex" title="g=1_{G}" /> under the promise that either <img src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=1_{G}" class="latex" title="g=1_{G}" /> or <img src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=h" class="latex" title="g=h" /> for a fixed <img src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h\ne 1_{G}" class="latex" title="h\ne 1_{G}" />.</p>
<p style="text-align: justify;">Problem (3) is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>. The focus of this survey is on (2) and (3).</p>
<p style="text-align: justify;">We work in the model of <em>communication complexity </em><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XYao79">Yao79</a>]</span>, with which we assume familiarity. For background see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKuN97">KN97</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRaoY2019">RY19</a>]</span>. Briefly, the terms <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i}" class="latex" title="x_{i}" /> in a product <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" class="latex" title="x_{1}\cdot x_{2}\cdot \cdots \cdot x_{n}" /> will be partitioned among collaborating parties – in several ways – and we shall bound the number of bits that the parties need to exchange to solve the problem.</p>
<p style="text-align: justify;"><b>Organization</b>.</p>
<p style="text-align: justify;">We begin in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2</a> with two-party communication complexity. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3</a> we give a streamlined proof, except for a step that is only sketched, of a result of Gowers and the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-2">GVb</a>]</span> about interleaved group products. In particular we present an alternative proof, communicated to us by Will Sawin, of a lemma from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. We then consider two models of three-party communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-70004">4</a> we consider number-in-hand protocols, and we relate the communication complexity to so-called <em>quasirandom groups</em> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span>. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-140006">6</a> we consider number-in-hand protocols, and specifically the problem of separating deterministic and randomized communication. In Section <a href="https://emanueleviola.wordpress.com/feed/#x1-150007">7</a> we give an exposition of a result by Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, and show that it implies a separation that matches the state-of-the-art <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span> but applies to a different problem.</p>
<p style="text-align: justify;">Some of the sections follow closely a set of lectures by the author <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-special-topics17">Vio17</a>]</span>; related material can also be found in the blog posts <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>. One of the goals of this survey is to present this material in a more organized matter, in addition to including new material.</p>
<h3 class="sectionHead"><span class="titlemark">2 </span> <a id="x1-20002"></a>Two parties</h3>
<p style="text-align: justify;">Let <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> be a group and let us start by considering the following basic communication task. Alice gets an element <img src="https://s0.wp.com/latex.php?latex=x%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in G" class="latex" title="x\in G" /> and Bob gets an element <img src="https://s0.wp.com/latex.php?latex=y%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y\in G" class="latex" title="y\in G" /> and their goal is to check if <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot y=1_{G}" class="latex" title="x\cdot y=1_{G}" />. How much communication do they need? Well, <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot y=1_{G}" class="latex" title="x\cdot y=1_{G}" /> is equivalent to <img src="https://s0.wp.com/latex.php?latex=x%3Dy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=y^{-1}" class="latex" title="x=y^{-1}" />. Because Bob can compute <img src="https://s0.wp.com/latex.php?latex=y%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y^{-1}" class="latex" title="y^{-1}" /> without communication, this problem is just a rephrasing of the <em>equality</em> problem, which has a randomized protocol with constant communication. This holds for any group.</p>
<p style="text-align: justify;">The same is true if Alice gets two elements <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}" class="latex" title="x_{1}" /> and <img src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{2}" class="latex" title="x_{2}" /> and they need to check if <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y%5Ccdot+x_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}\cdot y\cdot x_{2}=1_{G}" class="latex" title="x_{1}\cdot y\cdot x_{2}=1_{G}" />. Indeed, it is just checking equality of <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> and <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5E%7B-1%7D%5Ccdot+x_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}^{-1}\cdot x_{2}^{-1}" class="latex" title="x_{1}^{-1}\cdot x_{2}^{-1}" />, and again Alice can compute the latter without communication.</p>
<p style="text-align: justify;">Things get more interesting if both Alice and Bob get two elements and they need to check if the <em>interleaved product</em> of the elements of Alice and Bob equals <img src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{G}" class="latex" title="1_{G}" />, that is, if</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}" class="latex" title="\begin{aligned} x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}. \end{aligned}" /></div>
<p style="text-align: justify;">Now the previous transformations don’t help anymore. In fact, the complexity depends on the group. If it is abelian then the elements can be reordered and the problem is equivalent to checking if <img src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%5Ccdot+x_%7B2%7D%29%5Ccdot+%28y_%7B1%7D%5Ccdot+y_%7B2%7D%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}" class="latex" title="(x_{1}\cdot x_{2})\cdot (y_{1}\cdot y_{2})=1_{G}" />. Again, Alice can compute <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}\cdot x_{2}" class="latex" title="x_{1}\cdot x_{2}" /> without communication, and Bob can compute <img src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_{1}\cdot y_{2}" class="latex" title="y_{1}\cdot y_{2}" /> without communication. So this is the same problem as before and it has a constant communication protocol.</p>
<p style="text-align: justify;">For non-abelian groups this reordering cannot be done, and the problem seems hard. This can be formalized for a class of groups that are “far from abelian” – or we can take this result as a definition of being far from abelian. One of the groups that works best in this sense is the following, first constructed by Galois in the 1830’s.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2001r1"></a> Definition 1. </span>The<em> special linear group </em><img src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL(2,q)" class="latex" title="SL(2,q)" /> is the group of <img src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2\times 2" class="latex" title="2\times 2" /> invertible matrices over the field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{F} _{q}" class="latex" title="\mathbb{F} _{q}" /> with determinant <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The following result was asked in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span> and was proved in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-2002r1"></a></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=SL(2,q)" class="latex" title="G=SL(2,q)" /> and let <img src="https://s0.wp.com/latex.php?latex=h%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h\ne 1_{G}" class="latex" title="h\ne 1_{G}" />. Suppose Alice receives <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1},x_{2}\in G" class="latex" title="x_{1},x_{2}\in G" /> and Bob receives <img src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_{1},y_{2}\in G" class="latex" title="y_{1},y_{2}\in G" />. They are promised that <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}" class="latex" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}" /> either equals <img src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{G}" class="latex" title="1_{G}" /> or <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" />. Deciding which case it is requires randomized communication <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log |G|)" class="latex" title="\Omega (\log |G|)" />.</p>
<p style="text-align: justify;">This bound is tight as Alice can send her input, taking <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\log |G|)" class="latex" title="O(\log |G|)" /> bits. We present the proof of this theorem in the next section.</p>
<p style="text-align: justify;">Similar results are known for other groups as well, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. For example, one group that is “between” abelian groups and <img src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL(2,q)" class="latex" title="SL(2,q)" /> is the following.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2003r2"></a> Definition 2. </span>The<em> alternating group</em> <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" /> is the group of even permutations of <img src="https://s0.wp.com/latex.php?latex=1%2C2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1,2,\ldots ,n" class="latex" title="1,2,\ldots ,n" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">If we work over <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" /> instead of <img src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL(2,q)" class="latex" title="SL(2,q)" /> in Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1</a> then the communication complexity is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log \log |G|)" class="latex" title="\Omega (\log \log |G|)" /> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. The latter bound is tight <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMilesV-leak">MV13</a>]</span>: with knowledge of <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" />, the parties can agree on an element <img src="https://s0.wp.com/latex.php?latex=a%5Cin+%7B1%2C2%2C%5Cldots+%2Cn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\in {1,2,\ldots ,n}" class="latex" title="a\in {1,2,\ldots ,n}" /> such that <img src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h(a)\ne a" class="latex" title="h(a)\ne a" />. Hence they only need to keep track of the image <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" />. This takes communication <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+n%29%3DO%28%5Clog+%5Clog+%7CA_%7Bn%7D%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\log n)=O(\log \log |A_{n}|)" class="latex" title="O(\log n)=O(\log \log |A_{n}|)" /> because <img src="https://s0.wp.com/latex.php?latex=%7CA_%7Bn%7D%7C%3Dn%21%2F2.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|A_{n}|=n!/2." class="latex" title="|A_{n}|=n!/2." /> In more detail, the protocol is as follows. First Bob sends <img src="https://s0.wp.com/latex.php?latex=y_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_{2}(a)" class="latex" title="y_{2}(a)" />. Then Alice sends <img src="https://s0.wp.com/latex.php?latex=x_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{2}y_{2}(a)" class="latex" title="x_{2}y_{2}(a)" />. Then Bob sends <img src="https://s0.wp.com/latex.php?latex=y_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_{1}x_{2}y_{2}(a)" class="latex" title="y_{1}x_{2}y_{2}(a)" /> and finally Alice can check if <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7Dy_%7B1%7Dx_%7B2%7Dy_%7B2%7D%28a%29%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}y_{1}x_{2}y_{2}(a)=a" class="latex" title="x_{1}y_{1}x_{2}y_{2}(a)=a" />.</p>
<p style="text-align: justify;">Interestingly, to decide if <img src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=1_{G}" class="latex" title="g=1_{G}" /> without the promise a stronger lower bound can be proved for many groups, including <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" />, see Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3</a> below.</p>
<p style="text-align: justify;">In general, it seems an interesting open problem to try to understand for which groups Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1</a> applies. For example, is the communication large for every quasirandom group <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>?</p>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1</a> and the corresponding results for other groups also scale with the length of the product: for example deciding if <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdots+x_%7Bn%7D%5Ccdot+y_%7Bn%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}" class="latex" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdots x_{n}\cdot y_{n}=1_{G}" /> over <img src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=SL(2,q)" class="latex" title="G=SL(2,q)" /> requires communication <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (n\log |G|)" class="latex" title="\Omega (n\log |G|)" /> which is tight.</p>
<p style="text-align: justify;">A strength of the above results is that they hold for any choice of <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> in the promise. This makes them equivalent to certain <img src="https://s0.wp.com/latex.php?latex=mixing&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="mixing" class="latex" title="mixing" /> results, discussed below in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-120005.0.1">5.0.1</a>. Next we prove two other lower bounds that do not have this property and can be obtained by reduction from <em>disjointness</em>. First we show that for any non-abelian group <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> there exists an element <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> such that deciding if <img src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=1_{G}" class="latex" title="g=1_{G}" /> or <img src="https://s0.wp.com/latex.php?latex=g%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=h" class="latex" title="g=h" /> requires communication linear in the length of the product. Interestingly, the proof works for any non-abelian group. The choice of <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> is critical, as for some <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> and <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> the problem is easy. For example: take any group <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> and consider <img src="https://s0.wp.com/latex.php?latex=H%3A%3DG%5Ctimes+%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H:=G\times \mathbb {Z}_{2}" class="latex" title="H:=G\times \mathbb {Z}_{2}" /> where <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {Z}_{2}" class="latex" title="\mathbb {Z}_{2}" /> is the group of integers with addition modulo <img src="https://s0.wp.com/latex.php?latex=2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2" class="latex" title="2" />. Distinguishing between <img src="https://s0.wp.com/latex.php?latex=1_%7BH%7D%3D%281_%7BG%7D%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{H}=(1_{G},0)" class="latex" title="1_{H}=(1_{G},0)" /> and <img src="https://s0.wp.com/latex.php?latex=h%3D%281_%7BG%7D%2C1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h=(1_{G},1)" class="latex" title="h=(1_{G},1)" /> amounts to computing the parity of (the <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {Z}_{2}" class="latex" title="\mathbb {Z}_{2}" /> components of) the input, which takes constant communication. <a id="x1-2004r2"></a></p>
<p style="text-align: justify;"><b>Theorem 2.</b> Let <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> be a non-abelian group. There exists <img src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h\in G" class="latex" title="h\in G" /> such that the following holds. Suppose Alice receives <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D%2C%5Cldots+%2Cx_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1},x_{2},\ldots ,x_{n}" class="latex" title="x_{1},x_{2},\ldots ,x_{n}" /> and receives <img src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D%2C%5Cldots+%2Cy_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_{1},y_{2},\ldots ,y_{n}" class="latex" title="y_{1},y_{2},\ldots ,y_{n}" />. They are promised that <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%5Ccdot+%5Ccdots+%5Ccdot+x_%7Bn%7D%5Ccdot+y_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}" class="latex" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}\cdot \cdots \cdot x_{n}\cdot y_{n}" /> either equals <img src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{G}" class="latex" title="1_{G}" /> or <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" />. Deciding which case it is requires randomized communication <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (n)" class="latex" title="\Omega (n)" />.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We reduce from <em>unique set-disjointness</em>, defined below. For the reduction we encode the And of two bits <img src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s,t\in \{0,1\}" class="latex" title="s,t\in \{0,1\}" /> as a group product. This encoding is similar to the famous puzzle that asks to hang a picture on a wall with two nails in such a way that the picture falls if either one of the nails is removed. Since <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is non-abelian, there exist <img src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a,b\in G" class="latex" title="a,b\in G" /> such that <img src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Cneq+b%5Ccdot+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\cdot b\neq b\cdot a" class="latex" title="a\cdot b\neq b\cdot a" />, and in particular <img src="https://s0.wp.com/latex.php?latex=a%5Ccdot+b%5Ccdot+a%5E%7B-1%7D%5Ccdot+b%5E%7B-1%7D%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\cdot b\cdot a^{-1}\cdot b^{-1}=h" class="latex" title="a\cdot b\cdot a^{-1}\cdot b^{-1}=h" /> with <img src="https://s0.wp.com/latex.php?latex=h%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h\neq 1" class="latex" title="h\neq 1" />. We can use this fact to encode the And of <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s" class="latex" title="s" /> and <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7Bs%7D%5Ccdot+b%5E%7Bt%7D%5Ccdot+a%5E%7B-s%7D%5Ccdot+b%5E%7B-t%7D%3D%5Cbegin+%7Bcases%7D+1%7E%7E%5Ctext+%7Bif+And%5Censuremath+%7B%28s%2Ct%29%3D0%7D%7D%5C%5C+h%7E%7E%5Ctext+%7Botherwise%7D+%5Cend+%7Bcases%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}" class="latex" title="\begin{aligned} a^{s}\cdot b^{t}\cdot a^{-s}\cdot b^{-t}=\begin {cases} 1~~\text {if And\ensuremath {(s,t)=0}}\\ h~~\text {otherwise} \end {cases}. \end{aligned}" /></div>
<p style="text-align: justify;">In the disjointness problem Alice and Bob get inputs <img src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y\in \{0,1\}^{n}" class="latex" title="x,y\in \{0,1\}^{n}" /> respectively, and they wish to check if there exists an <img src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\in [n]" class="latex" title="i\in [n]" /> such that <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i}\land y_{i}=1" class="latex" title="x_{i}\land y_{i}=1" />. If you think of <img src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y" class="latex" title="x,y" /> as characteristic vectors of sets, this problem is asking if the sets have a common element or not. The communication of this problem is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (n)" class="latex" title="\Omega (n)" /> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span>. Moreover, in the “unique” variant of this problem where the number of such <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />’s is 0 or 1, the same lower bound <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (n)" class="latex" title="\Omega (n)" /> still applies. This follows from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XKalyanasundaramS92">KS92</a>, <a href="https://emanueleviola.wordpress.com/feed/#XRazborov92">Raz92</a>]</span> – see also Proposition 3.3 in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAMS99">AMS99</a>]</span>. For more on disjointness see the surveys <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XSherstov14-35years">She14</a>, <a href="https://emanueleviola.wordpress.com/feed/journals/sigact/ChattopadhyayP10">CP10</a>]</span>.</p>
<p style="text-align: justify;">We will reduce unique disjointness to group products. For <img src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y\in \{0,1\}^{n}" class="latex" title="x,y\in \{0,1\}^{n}" /> we produce inputs for the group problem as follows:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x+%26+%5Crightarrow+%28a%5E%7Bx_%7B1%7D%7D%2Ca%5E%7B-x_%7B1%7D%7D%2C%5Cldots+%2Ca%5E%7Bx_%7Bn%7D%7D%2Ca%5E%7B-x_%7Bn%7D%7D%29%5C%5C+y+%26+%5Crightarrow+%28b%5E%7By_%7B1%7D%7D%2Cb%5E%7B-y_%7B1%7D%7D%2C%5Cldots+%2Cb%5E%7By_%7Bn%7D%7D%2Cb%5E%7B-y_%7Bn%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}" class="latex" title="\begin{aligned} x &amp; \rightarrow (a^{x_{1}},a^{-x_{1}},\ldots ,a^{x_{n}},a^{-x_{n}})\\ y &amp; \rightarrow (b^{y_{1}},b^{-y_{1}},\ldots ,b^{y_{n}},b^{-y_{n}}). \end{aligned}" /></div>
<p style="text-align: justify;">The group product becomes</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cunderbrace+%7Ba%5E%7Bx_%7B1%7D%7D%5Ccdot+b%5E%7By_%7B1%7D%7D%5Ccdot+a%5E%7B-x_%7B1%7D%7D%5Ccdot+b%5E%7B-y_%7B1%7D%7D%7D_%7B%5Ctext+%7B1+bit%7D%7D%5Ccdots+%5Ccdots+a%5E%7Bx_%7Bn%7D%7D%5Ccdot+b%5E%7By_%7Bn%7D%7D%5Ccdot+a%5E%7B-x_%7Bn%7D%7D%5Ccdot+b%5E%7B-y_%7Bn%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}" class="latex" title="\begin{aligned} \underbrace {a^{x_{1}}\cdot b^{y_{1}}\cdot a^{-x_{1}}\cdot b^{-y_{1}}}_{\text {1 bit}}\cdots \cdots a^{x_{n}}\cdot b^{y_{n}}\cdot a^{-x_{n}}\cdot b^{-y_{n}}. \end{aligned}" /></div>
<p style="text-align: justify;">If there isn’t an <img src="https://s0.wp.com/latex.php?latex=i%5Cin+%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i\in [n]" class="latex" title="i\in [n]" /> such that <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i}\land y_{i}=1" class="latex" title="x_{i}\land y_{i}=1" />, then for each <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> the term <img src="https://s0.wp.com/latex.php?latex=a%5E%7Bx_%7Bi%7D%7D%5Ccdot+b%5E%7By_%7Bi%7D%7D%5Ccdot+a%5E%7B-x_%7Bi%7D%7D%5Ccdot+b%5E%7B-y_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}" class="latex" title="a^{x_{i}}\cdot b^{y_{i}}\cdot a^{-x_{i}}\cdot b^{-y_{i}}" /> is <img src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{G}" class="latex" title="1_{G}" />, and thus the whole product is 1.</p>
<p style="text-align: justify;">Otherwise, there exists a unique <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> such that <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D%5Cland+y_%7Bi%7D%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i}\land y_{i}=1" class="latex" title="x_{i}\land y_{i}=1" /> and thus the product will be <img src="https://s0.wp.com/latex.php?latex=1%5Ccdots+1%5Ccdot+h%5Ccdot+1%5Ccdots+1%3Dh&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1\cdots 1\cdot h\cdot 1\cdots 1=h" class="latex" title="1\cdots 1\cdot h\cdot 1\cdots 1=h" />, with <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> being in the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />-th position. If Alice and Bob can check if the above product is equal to 1, they can also solve the unique set disjointness problem, and thus the lower bound applies for the former. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">We required the uniqueness property, because otherwise we might get a product <img src="https://s0.wp.com/latex.php?latex=h%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h^{c}" class="latex" title="h^{c}" /> that could be equal to 1 in some groups.</p>
<p style="text-align: justify;">Next we prove a result for products of length just <img src="https://s0.wp.com/latex.php?latex=4&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="4" class="latex" title="4" />; it applies to non-abelian groups of the form <img src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=H^{n}" class="latex" title="G=H^{n}" /> and not with the promise. <a id="x1-2005r3"></a></p>
<p style="text-align: justify;"><b>Theorem 3.</b> Let <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> be a non-abelian group and consider <img src="https://s0.wp.com/latex.php?latex=G%3DH%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=H^{n}" class="latex" title="G=H^{n}" />. Suppose Alice receives <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%2Cx_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1},x_{2}" class="latex" title="x_{1},x_{2}" /> and Bob receives <img src="https://s0.wp.com/latex.php?latex=y_%7B1%7D%2Cy_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y_{1},y_{2}" class="latex" title="y_{1},y_{2}" />. Deciding if <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%5Ccdot+y_%7B2%7D%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}" class="latex" title="x_{1}\cdot y_{1}\cdot x_{2}\cdot y_{2}=1_{G}" /> requires randomized communication <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (n)" class="latex" title="\Omega (n)" />.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>The proof is similar to the proof of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2004r2">2</a>. We use coordinate <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> to encode bit <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> of the disjointness instance. If there is no intersection in the latter, the product will be <img src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{G}" class="latex" title="1_{G}" />. Otherwise, at least some coordinate will be <img src="https://s0.wp.com/latex.php?latex=%5Cne+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ne 1_{G}" class="latex" title="\ne 1_{G}" />. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">As a corollary we can prove a lower bound for <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" />.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-2006r3"></a> Corollary 3. </span>Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3</a> holds for <img src="https://s0.wp.com/latex.php?latex=G%3DA_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=A_{n}" class="latex" title="G=A_{n}" />.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Note that <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" /> contains <img src="https://s0.wp.com/latex.php?latex=%28A_%7B4%7D%29%5E%7B%5Clfloor+n%2F4%5Crfloor+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(A_{4})^{\lfloor n/4\rfloor }" class="latex" title="(A_{4})^{\lfloor n/4\rfloor }" /> and that <img src="https://s0.wp.com/latex.php?latex=A_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{4}" class="latex" title="A_{4}" /> is not abelian. Apply Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3</a>. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2005r3">3</a> is tight for constant-size <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />. We do not know if Corollary <a href="https://emanueleviola.wordpress.com/feed/#x1-2006r3">3</a> is tight. The trivial upper bound is <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+%7CA_%7Bn%7D%7C%29%3DO%28n%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\log |A_{n}|)=O(n\log n)" class="latex" title="O(\log |A_{n}|)=O(n\log n)" />.</p>
<h3 class="sectionHead"><span class="titlemark">3 </span> <a id="x1-30003"></a>Proof of Theorem 1</h3>
<p style="text-align: justify;">Several related proofs of this theorem exist, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int">GV15</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>, <a href="https://emanueleviola.wordpress.com/feed/#XShalev16">Sha16</a>]</span>. As in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>, the proof that we present can be broken down in three steps. First we reduce the problem to a statement about conjugacy classes. Second we reduce this to a statement about trace maps. Third we prove the latter. We present the first step in a way that is similar but slightly different from the presentation in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. The second step is only sketched, but relies on classical results about <img src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL(2,q)" class="latex" title="SL(2,q)" /> and can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. For the third we present a proof that was communicated to us by Will Sawin. We thank him for his permission to include it here.</p>
<h4 class="subsectionHead"><span class="titlemark">3.1 </span> <a id="x1-40003.1"></a>Step 1</h4>
<p style="text-align: justify;">We would like to rule out randomized protocols, but it is hard to reason about them directly. Instead, we are going to rule out deterministic protocols on random inputs. First, for any group element <img src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g\in G" class="latex" title="g\in G" /> we define the distribution on quadruples <img src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x_%7B1%7D%2Cy_%7B1%7D%2Cx_%7B2%7D%2C%28x_%7B1%7D%5Ccdot+y_%7B1%7D%5Ccdot+x_%7B2%7D%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)" class="latex" title="D_{g}:=(x_{1},y_{1},x_{2},(x_{1}\cdot y_{1}\cdot x_{2})^{-1}g)" />, where <img src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y\in G" class="latex" title="x,y\in G" /> are uniformly random elements. Note the product of the elements in <img src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_{g}" class="latex" title="D_{g}" /> is always <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" />.</p>
<p style="text-align: justify;">Towards a contradiction, suppose we have a randomized protocol <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> such that</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5BP%28D_%7B1%7D%29%3D1%5D%5Cgeq+%5Cmathbb%7BP%7D+%5BP%28D_%7Bh%7D%29%3D1%5D%2B%5Cfrac+%7B1%7D%7B10%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}" class="latex" title="\begin{aligned} \mathbb{P} [P(D_{1})=1]\geq \mathbb{P} [P(D_{h})=1]+\frac {1}{10}. \end{aligned}" /></div>
<p>This implies a deterministic protocol with the same gap, by fixing the randomness.</p>
<p style="text-align: justify;">We reach a contradiction by showing that for every deterministic protocol <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> using little communication, we have</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" /></div>
<p style="text-align: justify;">We start with the following standard lemma, which describes a protocol using product sets.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-4001r4"></a> Lemma 4. </span>(The set of accepted inputs of) A deterministic <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />-bit protocol for a function <img src="https://s0.wp.com/latex.php?latex=f%3AX%5Ctimes+Y%5Cto+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:X\times Y\to Z" class="latex" title="f:X\times Y\to Z" /> can be written as a disjoint union of <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}" class="latex" title="2^{c}" /> rectangles, where a rectangle is a set of the form <img src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\times B" class="latex" title="A\times B" /> with <img src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\subseteq X" class="latex" title="A\subseteq X" /> and <img src="https://s0.wp.com/latex.php?latex=B%5Csubseteq+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B\subseteq Y" class="latex" title="B\subseteq Y" /> and where <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> is constant.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>(sketch) For every communication transcript <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />, let <img src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S_{t}\subseteq G^{2}" class="latex" title="S_{t}\subseteq G^{2}" /> be the set of inputs giving transcript <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" />. The sets <img src="https://s0.wp.com/latex.php?latex=S_%7Bt%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S_{t}" class="latex" title="S_{t}" /> are disjoint since an input gives only one transcript, and their number is <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}" class="latex" title="2^{c}" />: one for each communication transcript of the protocol. The rectangle property can be proven by induction on the protocol tree. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">Next, we show that any rectangle <img src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\times B" class="latex" title="A\times B" /> cannot distinguish <img src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_{1},D_{h}" class="latex" title="D_{1},D_{h}" />. The way we achieve this is by showing that for every <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> the probability that <img src="https://s0.wp.com/latex.php?latex=%28A%5Ctimes+B%29%28D_%7Bg%7D%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(A\times B)(D_{g})=1" class="latex" title="(A\times B)(D_{g})=1" /> is roughly the same for every <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" />, and is roughly the density of the rectangle. (Here we write <img src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\times B" class="latex" title="A\times B" /> for the characteristic function of the set <img src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\times B" class="latex" title="A\times B" />.) Without loss of generality we set <img src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=1_{G}" class="latex" title="g=1_{G}" />. Let <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> have density <img src="https://s0.wp.com/latex.php?latex=%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha " class="latex" title="\alpha " /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> have density <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta " class="latex" title="\beta " />. We aim to bound above</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29B%28b_%7B1%7D%2Cb_%7B2%7D%29-%5Calpha+%5Cbeta+%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}" class="latex" title="\begin{aligned} \left |\mathbb{E} _{a_{1},b_{1},a_{2},b_{2}:a_{1}b_{1}a_{2}b_{2}=1}A(a_{1},a_{2})B(b_{1},b_{2})-\alpha \beta \right |, \end{aligned}" /></div>
<p>where note the distribution of <img src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%2Cb_%7B1%7D%2Ca_%7B2%7D%2Cb_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_{1},b_{1},a_{2},b_{2}" class="latex" title="a_{1},b_{1},a_{2},b_{2}" /> is the same as <img src="https://s0.wp.com/latex.php?latex=D_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_{1}" class="latex" title="D_{1}" />.</p>
<p style="text-align: justify;">Because the distribution of <img src="https://s0.wp.com/latex.php?latex=%28b_%7B1%7D%2Cb_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(b_{1},b_{2})" class="latex" title="(b_{1},b_{2})" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G^{2}" class="latex" title="G^{2}" />, the above can be rewritten as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7DB%28b_%7B1%7D%2Cb_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3D1%7D%5E%7B2%7D%28A%28a_%7B1%7D%2Ca_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Cbeta+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Bb_%7B1%7D%2Cb_%7B2%7D%2Ca_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7D%27%2Ca_%7B2%7D%27%3Aa_%7B1%7Db_%7B1%7Da_%7B2%7Db_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27b_%7B2%7D%3D1%7DA%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7D%27%2Ca_%7B2%7D%27%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}" class="latex" title="\begin{aligned} &amp; \left |\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}(A(a_{1},a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} _{b_{1},b_{2}}B(b_{1},b_{2})^{2}}\sqrt {\mathbb{E} _{b_{1},b_{2}}\mathbb{E} _{a_{1},a_{2}:a_{1}b_{1}a_{2}b_{2}=1}^{2}(A(a_{1},a_{2})-\alpha )}.\\ &amp; =\sqrt {\beta }\sqrt {\mathbb{E} _{b_{1},b_{2},a_{1},a_{2},a_{1}',a_{2}':a_{1}b_{1}a_{2}b_{2}=a_{1}'b_{1}a_{2}'b_{2}=1}A(a_{1},a_{2})A(a_{1}',a_{2}')-\alpha ^{2}}. \end{aligned}" /></div>
<p style="text-align: justify;">The inequality is Cauchy-Schwarz, and the step after that is obtained by expanding the square and noting that <img src="https://s0.wp.com/latex.php?latex=%28a_%7B1%7D%2Ca_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a_{1},a_{2})" class="latex" title="(a_{1},a_{2})" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G^{2}" class="latex" title="G^{2}" />, so that the expectation of the term <img src="https://s0.wp.com/latex.php?latex=A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Calpha+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(a_{1},a_{2})\alpha " class="latex" title="A(a_{1},a_{2})\alpha " /> is <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha ^{2}" class="latex" title="\alpha ^{2}" />.</p>
<p style="text-align: justify;">Now we do several transformations to rewrite the distribution in the last expectation in a convenient form. First, right-multiplying by <img src="https://s0.wp.com/latex.php?latex=b_%7B2%7D%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b_{2}^{-1}" class="latex" title="b_{2}^{-1}" /> we can rewrite the distribution as the uniform distribution on tuples such that</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B1%7D%27b_%7B1%7Da_%7B2%7D%27.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}" class="latex" title="\begin{aligned} a_{1}b_{1}a_{2}=a_{1}'b_{1}a_{2}'. \end{aligned}" /></div>
<p style="text-align: justify;">The last equation is equivalent to <img src="https://s0.wp.com/latex.php?latex=b_%7B1%7D%5E%7B-1%7D%28a_%7B1%7D%27%29%5E%7B-1%7Da_%7B1%7Db_%7B1%7Da_%7B2%7D%3Da_%7B2%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'" class="latex" title="b_{1}^{-1}(a_{1}')^{-1}a_{1}b_{1}a_{2}=a_{2}'" />.</p>
<p style="text-align: justify;">We can now do a transformation setting <img src="https://s0.wp.com/latex.php?latex=a_%7B1%7D%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_{1}'" class="latex" title="a_{1}'" /> to be <img src="https://s0.wp.com/latex.php?latex=a_%7B1%7Dx%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_{1}x^{-1}" class="latex" title="a_{1}x^{-1}" /> to rewrite the distribution of the four-tuple as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28a_%7B1%7D%2Ca_%7B2%7D%2Ca_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}" class="latex" title="\begin{aligned} (a_{1},a_{2},a_{1}x^{-1},C(x)a_{2}) \end{aligned}" /></div>
<p>where we use <img src="https://s0.wp.com/latex.php?latex=C%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(x)" class="latex" title="C(x)" /> to denote a uniform element from the conjugacy class of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, that is <img src="https://s0.wp.com/latex.php?latex=b%5E%7B-1%7Dxb&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b^{-1}xb" class="latex" title="b^{-1}xb" /> for a uniform <img src="https://s0.wp.com/latex.php?latex=b%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b\in G" class="latex" title="b\in G" />.</p>
<p style="text-align: justify;">Hence it is sufficient to bound</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}" class="latex" title="\begin{aligned} \left |\mathbb{E} A(a_{1},a_{2})A(a_{1}x^{-1},C(x)a_{2})-\alpha ^{2}\right |, \end{aligned}" /></div>
<p>where all the variables are uniform and independent.</p>
<p style="text-align: justify;">With a similar derivation as above, this can be rewritten as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca_%7B2%7D%29%5Cmathbb%7BE%7D+%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%5Cright+%7C%5C%5C+%26+%5Cle+%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7D%2Ca%7B%7D_%7B2%7D%29%5E%7B2%7D%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+_%7Ba_%7B1%7D%2Ca_%7B2%7D%7D%5Cmathbb%7BE%7D+_%7Bx%7D%5E%7B2%7D%28A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29-%5Calpha+%29%7D.%5C%5C+%26+%3D%5Csqrt+%7B%5Calpha+%7D%5Csqrt+%7B%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}" class="latex" title="\begin{aligned} &amp; \left |\mathbb{E} A(a_{1},a_{2})\mathbb{E} (A(a_{1}x^{-1},C(x)a_{2})-\alpha )\right |\\ &amp; \le \sqrt {\mathbb{E} A(a_{1},a{}_{2})^{2}}\sqrt {\mathbb{E} _{a_{1},a_{2}}\mathbb{E} _{x}^{2}(A(a_{1}x^{-1},C(x)a_{2})-\alpha )}.\\ &amp; =\sqrt {\alpha }\sqrt {\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}}. \end{aligned}" /></div>
<p style="text-align: justify;">Here each occurrence of <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> denotes a uniform and independent conjugate. Hence it is sufficient to bound</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2CC%28x%29a_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},C(x)a_{2})A(a_{1}x'^{-1},C(x')a_{2})-\alpha ^{2}\right |. \end{aligned}" /></div>
<p style="text-align: justify;">We can now replace <img src="https://s0.wp.com/latex.php?latex=a_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_{2}" class="latex" title="a_{2}" /> with <img src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7Da_%7B2%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(x)^{-1}a_{2}." class="latex" title="C(x)^{-1}a_{2}." /> Because <img src="https://s0.wp.com/latex.php?latex=C%28x%29%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(x)^{-1}" class="latex" title="C(x)^{-1}" /> has the same distribution of <img src="https://s0.wp.com/latex.php?latex=C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(x^{-1})" class="latex" title="C(x^{-1})" />, it is sufficient to bound</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb%7BE%7D+A%28a_%7B1%7Dx%5E%7B-1%7D%2Ca_%7B2%7D%29A%28a_%7B1%7Dx%27%5E%7B-1%7D%2CC%28x%27%29C%28x%5E%7B-1%7D%29a_%7B2%7D%29-%5Calpha+%5E%7B2%7D%5Cright+%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}" class="latex" title="\begin{aligned} \left |\mathbb{E} A(a_{1}x^{-1},a_{2})A(a_{1}x'^{-1},C(x')C(x^{-1})a_{2})-\alpha ^{2}\right |. \end{aligned}" /></div>
<p style="text-align: justify;">For this, it is enough to show that with high probability <img src="https://s0.wp.com/latex.php?latex=1-1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1-1/|G|^{\Omega (1)}" class="latex" title="1-1/|G|^{\Omega (1)}" /> over <img src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x'" class="latex" title="x'" /> and <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, the distribution of <img src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(x')C(x^{-1})" class="latex" title="C(x')C(x^{-1})" />, over the choice of the two independent conjugates, has statistical distance <img src="https://s0.wp.com/latex.php?latex=%5Cle+1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\le 1/|G|^{\Omega (1)}" class="latex" title="\le 1/|G|^{\Omega (1)}" /> from uniform.</p>
<h4 class="subsectionHead"><span class="titlemark">3.2 </span> <a id="x1-50003.2"></a>Step 2</h4>
<p style="text-align: justify;">In this step we use information on the conjugacy classes of the group to reduce the latter task to one about the equidistribution of the trace map. Let <img src="https://s0.wp.com/latex.php?latex=Tr&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Tr" class="latex" title="Tr" /> be the Trace map:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cbegin+%7Bpmatrix%7Da_%7B1%7D+%26+a_%7B2%7D%5C%5C+a_%7B3%7D+%26+a_%7B4%7D+%5Cend+%7Bpmatrix%7D%3Da_%7B1%7D%2Ba_%7B4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}" class="latex" title="\begin{aligned} Tr\begin {pmatrix}a_{1} &amp; a_{2}\\ a_{3} &amp; a_{4} \end {pmatrix}=a_{1}+a_{4}. \end{aligned}" /></div>
<p style="text-align: justify;">We state the lemma that we want to show.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-5001r5"></a> Lemma 5. </span>Let <img src="https://s0.wp.com/latex.php?latex=a%3A%3D%5Cbegin+%7Bpmatrix%7D0+%26+1%5C%5C+1+%26+w+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}" class="latex" title="a:=\begin {pmatrix}0 &amp; 1\\ 1 &amp; w \end {pmatrix}" /> and <img src="https://s0.wp.com/latex.php?latex=b%3A%3D%5Cbegin+%7Bpmatrix%7Dv+%26+1%5C%5C+1+%26+0+%5Cend+%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}" class="latex" title="b:=\begin {pmatrix}v &amp; 1\\ 1 &amp; 0 \end {pmatrix}" />. For all but <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> values of <img src="https://s0.wp.com/latex.php?latex=w%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w\in \mathbb{F} _{q}" class="latex" title="w\in \mathbb{F} _{q}" /> and <img src="https://s0.wp.com/latex.php?latex=v%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v\in \mathbb{F} _{q}" class="latex" title="v\in \mathbb{F} _{q}" />, the distribution of</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+Tr%5Cleft+%28au%5E%7B-1%7Dbu%5Cright+%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}" class="latex" title="\begin{aligned} Tr\left (au^{-1}bu\right ) \end{aligned}" /></div>
<p>is <img src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1/q)" class="latex" title="O(1/q)" /> close to uniform over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{F} _{q}" class="latex" title="\mathbb{F} _{q}" /> in statistical distance.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">To give some context, in <img src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL(2,q)" class="latex" title="SL(2,q)" /> the conjugacy class of an element is essentially determined by the trace. Moreover, we can think of <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> and <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b" class="latex" title="b" /> as generic elements in <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />. So the lemma can be interpreted as saying that for typical <img src="https://s0.wp.com/latex.php?latex=a%2Cb%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a,b\in G" class="latex" title="a,b\in G" />, taking a uniform element from the conjugacy class of <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b" class="latex" title="b" /> and multiplying it by <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> yields an element whose conjugacy class is uniform among the classes of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />. Using that essentially all conjugacy classes are equal, and some of the properties of the trace map, one can show that the above lemma implies that for typical <img src="https://s0.wp.com/latex.php?latex=x%2Cx%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,x'" class="latex" title="x,x'" /> the distribution of <img src="https://s0.wp.com/latex.php?latex=C%28x%27%29C%28x%5E%7B-1%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(x')C(x^{-1})" class="latex" title="C(x')C(x^{-1})" /> is close to uniform. For more on how this fits we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>.</p>
<h4 class="subsectionHead"><span class="titlemark">3.3 </span> <a id="x1-60003.3"></a>Step 3</h4>
<p style="text-align: justify;">We now present a proof of Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-5001r5">5</a>. The high-level argument of the proof is the same as in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> (Lemma 5.5), but the details may be more accessible and in particular the use of the Lang-Weil theorem <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XLangWeil54">LW54</a>]</span> from algebraic geometry is replaced by a more elementary argument. For simplicity we shall only cover the case where <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> is prime. We will show that for all but <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> values of <img src="https://s0.wp.com/latex.php?latex=v%2Cw%2Cc%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v,w,c\in \mathbb{F} _{q}" class="latex" title="v,w,c\in \mathbb{F} _{q}" />, the probability over <img src="https://s0.wp.com/latex.php?latex=u&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="u" class="latex" title="u" /> that <img src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Tr(au^{-1}bu)=c" class="latex" title="Tr(au^{-1}bu)=c" /> is within <img src="https://s0.wp.com/latex.php?latex=O%281%2Fq%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1/q^{2})" class="latex" title="O(1/q^{2})" /> of <img src="https://s0.wp.com/latex.php?latex=1%2Fq&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/q" class="latex" title="1/q" />, and for the others it is at most <img src="https://s0.wp.com/latex.php?latex=O%281%2Fq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1/q)" class="latex" title="O(1/q)" />. Summing over <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" /> gives the result.</p>
<p style="text-align: justify;">We shall consider elements <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b" class="latex" title="b" /> whose trace is unique to the conjugacy class of <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b" class="latex" title="b" />. (This holds for all but <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> conjugacy classes – see for example <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> for details.) This means that the distribution of <img src="https://s0.wp.com/latex.php?latex=u%5E%7B-1%7Dbu&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="u^{-1}bu" class="latex" title="u^{-1}bu" /> is that of a uniform element in <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> conditioned on having trace <img src="https://s0.wp.com/latex.php?latex=b&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b" class="latex" title="b" />. Hence, we can write the probability that <img src="https://s0.wp.com/latex.php?latex=Tr%28au%5E%7B-1%7Dbu%29%3Dc&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Tr(au^{-1}bu)=c" class="latex" title="Tr(au^{-1}bu)=c" /> as the number of solutions in <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> to the following three equations (divided by the size of the group, which is <img src="https://s0.wp.com/latex.php?latex=q%5E%7B3%7D-q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q^{3}-q" class="latex" title="q^{3}-q" />):</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x_%7B3%7D%2Bx_%7B2%7D%2Bwx_%7B4%7D+%26+%3Dc+%26+%5Chspace+%7B1cm%7D%28Tr%28ax%29%3Dc%29%2C%5C%5C+x_%7B1%7D%2Bx_%7B4%7D+%26+%3Dv+%26+%5Chspace+%7B1cm%7D%28Tr%28x%29%3DTr%28b%29%29%2C%5C%5C+x_%7B1%7Dx_%7B4%7D-x_%7B3%7Dx_%7B3%7D+%26+%3D1+%26+%5Chspace+%7B1cm%7D%28Det%28x%29%3D1%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}" class="latex" title="\begin{aligned} x_{3}+x_{2}+wx_{4} &amp; =c &amp; \hspace {1cm}(Tr(ax)=c),\\ x_{1}+x_{4} &amp; =v &amp; \hspace {1cm}(Tr(x)=Tr(b)),\\ x_{1}x_{4}-x_{3}x_{3} &amp; =1 &amp; \hspace {1cm}(Det(x)=1). \end{aligned}" /></div>
<p style="text-align: justify;">We use the second one to remove <img src="https://s0.wp.com/latex.php?latex=x_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{1}" class="latex" title="x_{1}" /> and the first one to remove <img src="https://s0.wp.com/latex.php?latex=x_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{2}" class="latex" title="x_{2}" /> from the last equation. This gives</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28v-x_%7B4%7D%29x_%7B4%7D-%28c-x_%7B3%7D-wx_%7B4%7D%29x_%7B3%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}" class="latex" title="\begin{aligned} (v-x_{4})x_{4}-(c-x_{3}-wx_{4})x_{3}=1. \end{aligned}" /></div>
<p style="text-align: justify;">This is an equation in two variables. Write <img src="https://s0.wp.com/latex.php?latex=x%3Dx_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=x_{3}" class="latex" title="x=x_{3}" /> and <img src="https://s0.wp.com/latex.php?latex=y%3Dx_%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y=x_{4}" class="latex" title="y=x_{4}" /> and use distributivity to rewrite the equation as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-cx%2Bx%5E%7B2%7D%2Bwxy%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}" class="latex" title="\begin{aligned} -y^{2}+vy-cx+x^{2}+wxy=1. \end{aligned}" /></div>
<p style="text-align: justify;">At least since Lagrange it has been known how to reduce this to a Pell equation <img src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{2}+dy^{2}=e" class="latex" title="x^{2}+dy^{2}=e" />. This is done by applying an invertible affine transformation, which does not change the number of solutions. First set <img src="https://s0.wp.com/latex.php?latex=x%3Dx-wy%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=x-wy/2" class="latex" title="x=x-wy/2" />. Then the equation becomes</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+-y%5E%7B2%7D%2Bvy-c%28x-wy%2F2%29%2B%28x-wy%2F2%29%5E%7B2%7D%2Bw%28x-wy%2F2%29y%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}" class="latex" title="\begin{aligned} -y^{2}+vy-c(x-wy/2)+(x-wy/2)^{2}+w(x-wy/2)y=1. \end{aligned}" /></div>
<p style="text-align: justify;">Equivalently, the cross-term has disappeared and we have</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2By%28v%2Bcw%2F2%29%2Bx%5E%7B2%7D-cx%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}" class="latex" title="\begin{aligned} y^{2}(-1-w^{2}/4)+y(v+cw/2)+x^{2}-cx=1. \end{aligned}" /></div>
<p style="text-align: justify;">Now one can add constants to <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> to remove the linear terms, changing the constant term. Specifically, let <img src="https://s0.wp.com/latex.php?latex=h%3A%3D%28v%2Bcw%2F2%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h:=(v+cw/2)/2" class="latex" title="h:=(v+cw/2)/2" /> and set <img src="https://s0.wp.com/latex.php?latex=y%3Dy-h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y=y-h" class="latex" title="y=y-h" /> and <img src="https://s0.wp.com/latex.php?latex=x%3Dx%2Bc%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=x+c/2" class="latex" title="x=x+c/2" />. The equation becomes</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28y-h%29%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2B%28y-h%292h%2B%28x%2Bc%2F2%29%5E%7B2%7D-c%28x%2Bc%2F2%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}" class="latex" title="\begin{aligned} (y-h)^{2}(-1-w^{2}/4)+(y-h)2h+(x+c/2)^{2}-c(x+c/2)=1. \end{aligned}" /></div>
<p style="text-align: justify;">The linear terms disappear, the coefficients of <img src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{2}" class="latex" title="x^{2}" /> and <img src="https://s0.wp.com/latex.php?latex=y%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y^{2}" class="latex" title="y^{2}" /> do not change and the equation can be rewritten as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+y%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29%2Bh%5E%7B2%7D%28-1-w%5E%7B2%7D%2F4%29-2h%5E%7B2%7D%2Bx%5E%7B2%7D%2B%28c%2F2%29%5E%7B2%7D-c%5E%7B2%7D%2F2%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}" class="latex" title="\begin{aligned} y^{2}(-1-w^{2}/4)+h^{2}(-1-w^{2}/4)-2h^{2}+x^{2}+(c/2)^{2}-c^{2}/2=1. \end{aligned}" /></div>
<p style="text-align: justify;">So this is now a Pell equation</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" /></div>
<p style="text-align: justify;">where <img src="https://s0.wp.com/latex.php?latex=d%3A%3D%28-1-w%5E%7B2%7D%2F4%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d:=(-1-w^{2}/4)" class="latex" title="d:=(-1-w^{2}/4)" /> and</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+e%3A%3D1%2Bh%5E%7B2%7D%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D%3D1%2B%28v%5E%7B2%7D%2B%28cw%2F2%29%5E%7B2%7D%2Bcvw%29%281%2F4%29%283%2Bw%5E%7B2%7D%2F4%29%2B%28c%2F2%29%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}" class="latex" title="\begin{aligned} e:=1+h^{2}(3+w^{2}/4)+(c/2)^{2}=1+(v^{2}+(cw/2)^{2}+cvw)(1/4)(3+w^{2}/4)+(c/2)^{2}. \end{aligned}" /></div>
<p style="text-align: justify;">For all but <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> values of <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w" class="latex" title="w" /> we have that <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> is non-zero. Moreover, for all but <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> values of <img src="https://s0.wp.com/latex.php?latex=v%2Cw&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v,w" class="latex" title="v,w" /> the term <img src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e" class="latex" title="e" /> is a non-zero polynomial in <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />. (Specifically, for any <img src="https://s0.wp.com/latex.php?latex=v%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v\ne 0" class="latex" title="v\ne 0" /> and any <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="w" class="latex" title="w" /> such that <img src="https://s0.wp.com/latex.php?latex=3%2Bw%5E%7B2%7D%2F4%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="3+w^{2}/4\ne 0" class="latex" title="3+w^{2}/4\ne 0" />.) So we only consider the values of <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" /> that make it non-zero. Those where <img src="https://s0.wp.com/latex.php?latex=e%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e=0" class="latex" title="e=0" /> give <img src="https://s0.wp.com/latex.php?latex=O%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(q)" class="latex" title="O(q)" /> solutions, which is fine. We conclude with the following lemma.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-6001r6"></a> Lemma 6. </span>For <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> and <img src="https://s0.wp.com/latex.php?latex=e&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e" class="latex" title="e" /> non-zero, and prime <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" />, the number of solutions over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{F} _{q}" class="latex" title="\mathbb{F} _{q}" /> to the Pell equation</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" class="latex" title="\begin{aligned} x^{2}+dy^{2}=e \end{aligned}" /></div>
<p style="text-align: justify;">is within <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> of <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">This is a basic result from algebraic geometry that can be proved from first principles.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>If <img src="https://s0.wp.com/latex.php?latex=d%3D-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d=-f^{2}" class="latex" title="d=-f^{2}" /> for some <img src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f\in \mathbb{F} _{q}" class="latex" title="f\in \mathbb{F} _{q}" />, then we can replace <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" /> with <img src="https://s0.wp.com/latex.php?latex=fy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="fy" class="latex" title="fy" /> and we can count instead the solutions to the equation</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%5E%7B2%7D-y%5E%7B2%7D%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}" class="latex" title="\begin{aligned} x^{2}-y^{2}=e. \end{aligned}" /></div>
<p style="text-align: justify;">Because <img src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D-y%5E%7B2%7D%3D%28x-y%29%28x%2By%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{2}-y^{2}=(x-y)(x+y)" class="latex" title="x^{2}-y^{2}=(x-y)(x+y)" /> we can set <img src="https://s0.wp.com/latex.php?latex=x%27%3A%3Dx-y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x':=x-y" class="latex" title="x':=x-y" /> and <img src="https://s0.wp.com/latex.php?latex=y%27%3A%3Dx%2By&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y':=x+y" class="latex" title="y':=x+y" />, which preserves the number of solutions, and rewrite the equation as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+x%27y%27%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} x'y'=e. \end{aligned}" class="latex" title="\begin{aligned} x'y'=e. \end{aligned}" /></div>
<p style="text-align: justify;">Because <img src="https://s0.wp.com/latex.php?latex=e%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e\ne 0" class="latex" title="e\ne 0" />, this has <img src="https://s0.wp.com/latex.php?latex=q-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q-1" class="latex" title="q-1" /> solutions: for every non-zero <img src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y'" class="latex" title="y'" /> we have <img src="https://s0.wp.com/latex.php?latex=x%27%3De%2Fy%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x'=e/y'" class="latex" title="x'=e/y'" />.</p>
<p style="text-align: justify;">So now we can assume that <img src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d\ne -f^{2}" class="latex" title="d\ne -f^{2}" /> for any <img src="https://s0.wp.com/latex.php?latex=f%5Cin+%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f\in \mathbb{F} _{q}" class="latex" title="f\in \mathbb{F} _{q}" />. Because the number of squares is <img src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(q+1)/2" class="latex" title="(q+1)/2" />, the range of <img src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{2}" class="latex" title="x^{2}" /> has size <img src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(q+1)/2" class="latex" title="(q+1)/2" />. Similarly, the range of <img src="https://s0.wp.com/latex.php?latex=e-dy%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="e-dy^{2}" class="latex" title="e-dy^{2}" /> also has size <img src="https://s0.wp.com/latex.php?latex=%28q%2B1%29%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(q+1)/2" class="latex" title="(q+1)/2" />. Hence these two ranges intersect, and there is a solution <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a,b)" class="latex" title="(a,b)" />.</p>
<p style="text-align: justify;">We take a line passing through <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a,b)" class="latex" title="(a,b)" />: for parameters <img src="https://s0.wp.com/latex.php?latex=s%2Ct%5Cin+%5Cmathbb%7BF%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s,t\in \mathbb{F} " class="latex" title="s,t\in \mathbb{F} " /> we consider pairs <img src="https://s0.wp.com/latex.php?latex=%28a%2Bt%2Cb%2Bst%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a+t,b+st)" class="latex" title="(a+t,b+st)" />. There is a bijection between such pairs with <img src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\ne 0" class="latex" title="t\ne 0" /> and the points <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)" class="latex" title="(x,y)" /> with <img src="https://s0.wp.com/latex.php?latex=x%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\ne a" class="latex" title="x\ne a" />. Because the number of solutions with <img src="https://s0.wp.com/latex.php?latex=x%3Da&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=a" class="latex" title="x=a" /> is <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" />, using that <img src="https://s0.wp.com/latex.php?latex=d%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d\ne 0" class="latex" title="d\ne 0" />, it suffices to count the solutions with <img src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\ne 0" class="latex" title="t\ne 0" />.</p>
<p style="text-align: justify;">The intuition is that this line has two intersections with the curve <img src="https://s0.wp.com/latex.php?latex=x%5E%7B2%7D%2Bdy%5E%7B2%7D%3De&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{2}+dy^{2}=e" class="latex" title="x^{2}+dy^{2}=e" />. Because one of them, <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a,b)" class="latex" title="(a,b)" />, lies in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D+_%7Bq%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{F} _{q}" class="latex" title="\mathbb{F} _{q}" />, the other has to lie as well there. Algebraically, we can plug the pair in the expression to obtain the equivalent equation</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+a%5E%7B2%7D%2Bt%5E%7B2%7D%2B2at%2Bd%28b%5E%7B2%7D%2Bs%5E%7B2%7Dt%5E%7B2%7D%2B2bst%29%3De.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}" class="latex" title="\begin{aligned} a^{2}+t^{2}+2at+d(b^{2}+s^{2}t^{2}+2bst)=e. \end{aligned}" /></div>
<p style="text-align: justify;">Using that <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a,b)" class="latex" title="(a,b)" /> is a solution this becomes</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%5E%7B2%7D%2B2at%2Bds%5E%7B2%7Dt%5E%7B2%7D%2B2dbst%3D0+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}" class="latex" title="\begin{aligned} t^{2}+2at+ds^{2}t^{2}+2dbst=0 \end{aligned}" /></div>
<p style="text-align: justify;">We can divide by <img src="https://s0.wp.com/latex.php?latex=t%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t\ne 0" class="latex" title="t\ne 0" />. Obtaining</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%281%2Bds%5E%7B2%7D%29%2B2a%2B2dbs%3D0.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}" class="latex" title="\begin{aligned} t(1+ds^{2})+2a+2dbs=0. \end{aligned}" /></div>
<p style="text-align: justify;">We can now divide by <img src="https://s0.wp.com/latex.php?latex=1%2Bds%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1+ds^{2}" class="latex" title="1+ds^{2}" /> which is non-zero by the assumption <img src="https://s0.wp.com/latex.php?latex=d%5Cne+-f%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d\ne -f^{2}" class="latex" title="d\ne -f^{2}" />. This yields</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+t%3D%28-2a-2dbs%29%2F%281%2Bds%5E%7B2%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}" class="latex" title="\begin{aligned} t=(-2a-2dbs)/(1+ds^{2}). \end{aligned}" /></div>
<p style="text-align: justify;">Hence for every value of <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s" class="latex" title="s" /> there is a unique <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> giving a solution. This gives <img src="https://s0.wp.com/latex.php?latex=q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q" class="latex" title="q" /> solutions. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<h3 class="sectionHead"><span class="titlemark">4 </span> <a id="x1-70004"></a>Three parties, number-in-hand</h3>
<p style="text-align: justify;">In this section we consider the following three-party number-in-hand problem: Alice gets <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, Bob gets <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" />, Charlie gets <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z" class="latex" title="z" />, and they want to know if <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot y\cdot z=1_{G}" class="latex" title="x\cdot y\cdot z=1_{G}" />. The communication depends on the group <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />. We present next two efficient protocols for abelian groups, and then a communication lower bound for other groups.</p>
<h4 class="subsectionHead"><span class="titlemark">4.1 </span> <a id="x1-80004.1"></a>A randomized protocol for the hypercube</h4>
<p style="text-align: justify;">We begin with the simplest setting. Let <img src="https://s0.wp.com/latex.php?latex=G%3D%28%5Cmathbb+%7BZ%7D_%7B2%7D%29%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=(\mathbb {Z}_{2})^{n}" class="latex" title="G=(\mathbb {Z}_{2})^{n}" />, that is <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-bit strings with bit-wise addition modulo 2. The parties want to check if <img src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x+y+z=0^{n}" class="latex" title="x+y+z=0^{n}" />. They can do so as follows. First, they pick a hash function <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> that is linear: <img src="https://s0.wp.com/latex.php?latex=h%28x%2By%29%3Dh%28x%29%2Bh%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h(x+y)=h(x)+h(y)" class="latex" title="h(x+y)=h(x)+h(y)" />. Specifically, for a uniformly random <img src="https://s0.wp.com/latex.php?latex=a%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\in \{0,1\}^{n}" class="latex" title="a\in \{0,1\}^{n}" /> define <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3A%3D%5Csum+a_%7Bi%7Dx_%7Bi%7D%5Cmod+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x):=\sum a_{i}x_{i}\mod 2" class="latex" title="h_{a}(x):=\sum a_{i}x_{i}\mod 2" />. Then, the protocol is as follows.</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x)" class="latex" title="h_{a}(x)" />,</li>
<li class="itemize">Bob send <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(y)" class="latex" title="h_{a}(y)" />,</li>
<li class="itemize">Charlie accepts if and only if <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3D0s&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s" class="latex" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=0s" />.</li>
</ul>
<p style="text-align: justify;">The hash function outputs 1 bit, so the communication is constant. By linearity, the protocol accepts iff <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x+y+z)=0" class="latex" title="h_{a}(x+y+z)=0" />. If <img src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x+y+z=0" class="latex" title="x+y+z=0" /> this is always the case, otherwise it happens with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2" class="latex" title="1/2" />.</p>
<h4 class="subsectionHead"><span class="titlemark">4.2 </span> <a id="x1-90004.2"></a>A randomized protocol for <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BZ%7D_%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {Z}_{N}" class="latex" title="\mathbb {Z}_{N}" /></h4>
<p style="text-align: justify;">This protocol is from <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. For simplicity we only consider the case <img src="https://s0.wp.com/latex.php?latex=N%3D2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N=2^{n}" class="latex" title="N=2^{n}" /> here – the protocol for general <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N" class="latex" title="N" /> is in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XViola-ccsum">Vio14</a>]</span>. Again, the parties want to check if <img src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0%5Cmod+N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x+y+z=0\mod N" class="latex" title="x+y+z=0\mod N" />. For this group, there is no 100% linear hash function but there are almost linear hash functions <img src="https://s0.wp.com/latex.php?latex=h%3A%5Cmathbb+%7BZ%7D_%7BN%7D%5Crightarrow+%5Cmathbb+%7BZ%7D_%7B2%5E%7B%5Cell+%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}" class="latex" title="h:\mathbb {Z}_{N}\rightarrow \mathbb {Z}_{2^{\ell }}" /> that satisfy the following properties. Note that the inputs to <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> are interpreted modulo <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="N" class="latex" title="N" /> and the outputs modulo <img src="https://s0.wp.com/latex.php?latex=2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{\ell }" class="latex" title="2^{\ell }" />.</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9002x1">for all <img src="https://s0.wp.com/latex.php?latex=a%2Cx%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a,x,y" class="latex" title="a,x,y" /> there is <img src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c\in \{0,1\}" class="latex" title="c\in \{0,1\}" /> such that <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3Dh_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bc&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c" class="latex" title="h_{a}(x+y)=h_{a}(x)+h_{a}(y)+c" />,</li>
<li class="enumerate" id="x1-9004x2">for all <img src="https://s0.wp.com/latex.php?latex=x%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\neq 0" class="latex" title="x\neq 0" /> we have <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7Ba%7D%5Bh_%7Ba%7D%28x%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D%5D%5Cleq+O%281%2F2%5E%7B%5Cell+%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })" class="latex" title="\mathbb{P} _{a}[h_{a}(x)\in \{-2,-1,0,1,2\}]\leq O(1/2^{\ell })" />,</li>
<li class="enumerate" id="x1-9006x3"><img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%280%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(0)=0" class="latex" title="h_{a}(0)=0" />.</li>
</ol>
<p style="text-align: justify;">Assuming some random hash function <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> that satisfies the above properties the protocol works similarly to the previous one:</p>
<ul class="itemize1">
<li class="itemize">Alice sends <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x)" class="latex" title="h_{a}(x)" />,</li>
<li class="itemize">Bob sends <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(y)" class="latex" title="h_{a}(y)" />,</li>
<li class="itemize">Charlie accepts if and only if <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}" class="latex" title="h_{a}(x)+h_{a}(y)+h_{a}(z)\in \{-2,-1,0\}" />.</li>
</ul>
<p style="text-align: justify;">We can set <img src="https://s0.wp.com/latex.php?latex=%5Cell+%3DO%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell =O(1)" class="latex" title="\ell =O(1)" /> to achieve constant communication and constant error.</p>
<p style="text-align: justify;">To prove correctness of the protocol, first note that <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%2Bh_%7Ba%7D%28y%29%2Bh_%7Ba%7D%28z%29%3Dh_%7Ba%7D%28x%2By%2Bz%29-c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c" class="latex" title="h_{a}(x)+h_{a}(y)+h_{a}(z)=h_{a}(x+y+z)-c" /> for some <img src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c\in \{0,1,2\}" class="latex" title="c\in \{0,1,2\}" />. Then consider the following two cases:</p>
<ul class="itemize1">
<li class="itemize">if <img src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x+y+z=0" class="latex" title="x+y+z=0" /> then <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%3Dh_%7Ba%7D%280%29-c%3D-c%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x+y+z)-c=h_{a}(0)-c=-c," class="latex" title="h_{a}(x+y+z)-c=h_{a}(0)-c=-c," /> and the protocol is always correct.</li>
<li class="itemize">if <img src="https://s0.wp.com/latex.php?latex=x%2By%2Bz%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x+y+z\neq 0" class="latex" title="x+y+z\neq 0" /> then the probability that <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29-c%5Cin+%5C%7B-2%2C-1%2C0%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x+y+z)-c\in \{-2,-1,0\}" class="latex" title="h_{a}(x+y+z)-c\in \{-2,-1,0\}" /> for some <img src="https://s0.wp.com/latex.php?latex=c%5Cin+%5C%7B0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c\in \{0,1,2\}" class="latex" title="c\in \{0,1,2\}" /> is at most the probability that <img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%2Bz%29%5Cin+%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}" class="latex" title="h_{a}(x+y+z)\in \{-2,-1,0,1,2\}" /> which is <img src="https://s0.wp.com/latex.php?latex=%5Cleq+2%5E%7B-%5COmega+%28%5Cell+%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\leq 2^{-\Omega (\ell )}" class="latex" title="\leq 2^{-\Omega (\ell )}" />; so the protocol is correct with high probability.</li>
</ul>
<p style="text-align: justify;"><b>The hash function.</b>.</p>
<p style="text-align: justify;">For the hash function we can use a function analyzed in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XDietzfelbingerHKP97">DHKP97</a>]</span>. Let <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> be a random odd number modulo <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{n}" class="latex" title="2^{n}" />. Define</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+h_%7Ba%7D%28x%29%3A%3D%28a%5Ccdot+x%5Cgg+n-%5Cell+%29%5Cmod+2%5E%7B%5Cell+%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}" class="latex" title="\begin{aligned} h_{a}(x):=(a\cdot x\gg n-\ell )\mod 2^{\ell } \end{aligned}" /></div>
<p>where the product <img src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\cdot x" class="latex" title="a\cdot x" /> is integer multiplication, and <img src="https://s0.wp.com/latex.php?latex=%5Cgg+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\gg " class="latex" title="\gg " /> is bit-shift. In other words we output the bits <img src="https://s0.wp.com/latex.php?latex=n-%5Cell+%2B1%2Cn-%5Cell+%2B2%2C%5Cldots+%2Cn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n-\ell +1,n-\ell +2,\ldots ,n" class="latex" title="n-\ell +1,n-\ell +2,\ldots ,n" /> of the integer product <img src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\cdot x" class="latex" title="a\cdot x" />.</p>
<p style="text-align: justify;">We now verify that the above hash function family satisfies the three properties we required above.</p>
<p style="text-align: justify;">Property (3) is trivially satisfied.</p>
<p style="text-align: justify;">For property (1) we have the following. Let <img src="https://s0.wp.com/latex.php?latex=s%3Da%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s=a\cdot x" class="latex" title="s=a\cdot x" /> and <img src="https://s0.wp.com/latex.php?latex=t%3Da%5Ccdot+y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=a\cdot y" class="latex" title="t=a\cdot y" /> and <img src="https://s0.wp.com/latex.php?latex=u%3Dn-%5Cell+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="u=n-\ell " class="latex" title="u=n-\ell " />. To recap, by definition we have:</p>
<ul class="itemize1">
<li class="itemize"><img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%2By%29%3D%28%28s%2Bt%29%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell }," class="latex" title="h_{a}(x+y)=((s+t)\gg u)\mod 2^{\ell }," /></li>
<li class="itemize"><img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28s%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x)=(s\gg u)\mod 2^{\ell }" class="latex" title="h_{a}(x)=(s\gg u)\mod 2^{\ell }" />,</li>
<li class="itemize"><img src="https://s0.wp.com/latex.php?latex=h_%7Ba%7D%28x%29%3D%28t%5Cgg+u%29%5Cmod+2%5E%7B%5Cell+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{a}(x)=(t\gg u)\mod 2^{\ell }" class="latex" title="h_{a}(x)=(t\gg u)\mod 2^{\ell }" />.</li>
</ul>
<p style="text-align: justify;">Notice that if in the addition <img src="https://s0.wp.com/latex.php?latex=s%2Bt&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s+t" class="latex" title="s+t" /> the carry into the <img src="https://s0.wp.com/latex.php?latex=u%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="u+1" class="latex" title="u+1" /> bit is <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />, then</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}" class="latex" title="\begin{aligned} (s\gg u)+(t\gg u)=(s+t)\gg u \end{aligned}" /></div>
<p>otherwise</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28s%5Cgg+u%29%2B%28t%5Cgg+u%29%2B1%3D%28s%2Bt%29%5Cgg+u+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}" class="latex" title="\begin{aligned} (s\gg u)+(t\gg u)+1=(s+t)\gg u \end{aligned}" /></div>
<p>which concludes the proof for property (1).</p>
<p style="text-align: justify;">Finally, we prove property (2). We start by writing <img src="https://s0.wp.com/latex.php?latex=x%3Ds%5Ccdot+2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=s\cdot 2^{c}" class="latex" title="x=s\cdot 2^{c}" /> where <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s" class="latex" title="s" /> is odd. So the binary representation of <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> looks like</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ccdots+%5Ccdots+1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" title="\begin{aligned} (\cdots \cdots 1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" /></div>
<p>The binary representation of the product <img src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\cdot x" class="latex" title="a\cdot x" /> for a uniformly random <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> looks like</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28%5Ctextit+%7Buniform%7D%7E1%5Cunderbrace+%7B0%5Ccdots+0%7D_%7Bc%7E%5Ctextrm+%7Bbits%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" class="latex" title="\begin{aligned} (\textit {uniform}~1\underbrace {0\cdots 0}_{c~\textrm {bits}}). \end{aligned}" /></div>
<p>We consider the two following cases for the product <img src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\cdot x" class="latex" title="a\cdot x" />:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-9008x1">If <img src="https://s0.wp.com/latex.php?latex=a%5Ccdot+x%3D%28%5Cunderbrace+%7B%5Ctextit+%7Buniform%7D%7E1%5Coverbrace+%7B00%7D%5E%7B2%7Ebits%7D%7D_%7B%5Cell+%7Ebits%7D%5Ccdots+0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)" class="latex" title="a\cdot x=(\underbrace {\textit {uniform}~1\overbrace {00}^{2~bits}}_{\ell ~bits}\cdots 0)" />, or equivalently <img src="https://s0.wp.com/latex.php?latex=c%5Cgeq+n-%5Cell+%2B2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c\geq n-\ell +2" class="latex" title="c\geq n-\ell +2" />, the output never lands in the bad set <img src="https://s0.wp.com/latex.php?latex=%5C%7B-2%2C-1%2C0%2C1%2C2%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{-2,-1,0,1,2\}" class="latex" title="\{-2,-1,0,1,2\}" />;</li>
<li class="enumerate" id="x1-9010x2">Otherwise, the hash function output has <img src="https://s0.wp.com/latex.php?latex=%5Cell+-O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell -O(1)" class="latex" title="\ell -O(1)" /> uniform bits. For any set <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" />, the probability that the output lands in <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> is at most <img src="https://s0.wp.com/latex.php?latex=%7CB%7C%5Ccdot+2%5E%7B-%5Cell+%2BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|B|\cdot 2^{-\ell +O(1)}" class="latex" title="|B|\cdot 2^{-\ell +O(1)}" />.</li>
</ol>
<h4 class="subsectionHead"><span class="titlemark">4.3 </span> <a id="x1-100004.3"></a>Quasirandom groups</h4>
<p style="text-align: justify;">What happens in other groups? The hash function used in the previous result was fairly non-trivial. Do we have an almost linear hash function for <img src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2\times 2" class="latex" title="2\times 2" /> matrices? The answer is negative. For <img src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL_{2}(q)" class="latex" title="SL_{2}(q)" /> and <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" /> the problem is hard, even under the promise. For a group <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> the complexity can be expressed in terms of a parameter <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> which comes from representation theory. We will not formally define this parameter here, but several qualitatively equivalent formulations can be found in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>]</span>. Instead the following table shows the <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />’s for the groups we’ve introduced.</p>
<div style="text-align: center;">
<div class="tabular">
<table cellpadding="0" cellspacing="0" class="tabular" id="TBL-1">
<colgroup id="TBL-1-1g">
<col id="TBL-1-1" /></colgroup>
<colgroup id="TBL-1-2g">
<col id="TBL-1-2" /></colgroup>
<colgroup id="TBL-1-3g">
<col id="TBL-1-3" /></colgroup>
<colgroup id="TBL-1-4g">
<col id="TBL-1-4" /></colgroup>
<colgroup id="TBL-1-5g">
<col id="TBL-1-5" /></colgroup>
<tbody>
<tr class="hline">
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
</tr>
<tr style="vertical-align: baseline;" id="TBL-1-1-">
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-1-1"><img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /></td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-1-2">:</td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-1-3">abelian</td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-1-4"><img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" /></td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-1-5"><img src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL_{2}(q)" class="latex" title="SL_{2}(q)" /></td>
</tr>
<tr class="hline">
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
</tr>
<tr style="vertical-align: baseline;" id="TBL-1-2-">
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-2-1"><img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /></td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-2-2">:</td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-2-3"><img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /></td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-2-4"><img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Cfrac+%7B%5Clog+%7CG%7C%7D%7B%5Clog+%5Clog+%7CG%7C%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\frac {\log |G|}{\log \log |G|})" class="latex" title="\Omega (\frac {\log |G|}{\log \log |G|})" /></td>
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-2-5"><img src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|G|^{\Omega (1)}" class="latex" title="|G|^{\Omega (1)}" /></td>
</tr>
<tr class="hline">
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
<td>
<hr />
</td>
</tr>
<tr style="vertical-align: baseline;" id="TBL-1-3-">
<td style="white-space: nowrap; text-align: center;" class="td11" id="TBL-1-3-1"></td>
</tr>
</tbody>
</table>
</div>
<p>.</p>
</div>
<p> </p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> be a group, and let <img src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h\in G" class="latex" title="h\in G" />. Let <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> be the minimum dimension of any irreducible representation of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />. Suppose Alice, Bob, and Charlie receive <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, y, and <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z" class="latex" title="z" /> respectively. They are promised that <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot y\cdot z" class="latex" title="x\cdot y\cdot z" /> either equals <img src="https://s0.wp.com/latex.php?latex=1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1_{G}" class="latex" title="1_{G}" /> or <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" />. Deciding which case it is requires randomized communication complexity <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+d%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log d)" class="latex" title="\Omega (\log d)" />.</p>
<p style="text-align: justify;">This result is tight for the groups we have discussed so far. The arguments are the same as before. Specifically, for <img src="https://s0.wp.com/latex.php?latex=SL_%7B2%7D%28q%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL_{2}(q)" class="latex" title="SL_{2}(q)" /> the communication is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log |G|)" class="latex" title="\Omega (\log |G|)" />. This is tight up to constants, because Alice and Bob can send their elements. For <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" /> the communication is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log \log |G|)" class="latex" title="\Omega (\log \log |G|)" />. This is tight as well, as the parties can again just communicate the images of an element <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" /> such that <img src="https://s0.wp.com/latex.php?latex=h%28a%29%5Cne+a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h(a)\ne a" class="latex" title="h(a)\ne a" />, as discussed in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1</a>. This also gives a computational proof that <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> cannot be too large for <img src="https://s0.wp.com/latex.php?latex=A_%7Bn%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_{n}" class="latex" title="A_{n}" />, i.e., it is at most <img src="https://s0.wp.com/latex.php?latex=%28%5Clog+%7CG%7C%29%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\log |G|)^{O(1)}" class="latex" title="(\log |G|)^{O(1)}" />. For abelian groups we get nothing, matching the efficient protocols given above.</p>
<h3 class="sectionHead"><span class="titlemark">5 </span> <a id="x1-110005"></a>Proof of Theorem 1</h3>
<p style="text-align: justify;">First we discuss several “mixing” lemmas for groups, then we come back to protocols and see how to apply one of them there.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.1 </span> <a id="x1-120005.0.1"></a><img src="https://s0.wp.com/latex.php?latex=XY&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="XY" class="latex" title="XY" /> mixing</h5>
<p style="text-align: justify;">We want to consider “high entropy” distributions over <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />, and state a fact showing that the multiplication of two such distributions “mixes” or in other words increases the entropy. To define entropy we use the norms <img src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7Bc%7D%3D%5Cleft+%28%5Csum+_%7Bx%7DA%28x%29%5E%7Bc%7D%5Cright+%29%5E%7B%5Cfrac+%7B1%7D%7Bc%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}" class="latex" title="\lVert A\rVert _{c}=\left (\sum _{x}A(x)^{c}\right )^{\frac {1}{c}}" />. Our notion of (non-)entropy will be <img src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert A\rVert _{2}" class="latex" title="\lVert A\rVert _{2}" />. Note that <img src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert A\rVert _{2}^{2}" class="latex" title="\lVert A\rVert _{2}^{2}" /> is exactly the <em>collision probability</em> <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5BA%3DA%27%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} [A=A']" class="latex" title="\mathbb{P} [A=A']" /> where <img src="https://s0.wp.com/latex.php?latex=A%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A'" class="latex" title="A'" /> is independent and identically distributed to <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />. The smaller this quantity, the higher the entropy of <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />. For the uniform distribution <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> we have <img src="https://s0.wp.com/latex.php?latex=%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%3D%5Cfrac+%7B1%7D%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}" class="latex" title="\lVert U\rVert _{2}^{2}=\frac {1}{|G|}" /> and so we can think of <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|" class="latex" title="1/|G|" /> as maximum entropy. If <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> is uniform over <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (|G|)" class="latex" title="\Omega (|G|)" /> elements, we have <img src="https://s0.wp.com/latex.php?latex=%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D%3DO%281%2F%7CG%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert A\rVert _{2}^{2}=O(1/|G|)" class="latex" title="\lVert A\rVert _{2}^{2}=O(1/|G|)" /> and we think of <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> as having “high” entropy.</p>
<p style="text-align: justify;">Because the entropy of <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> is small, we can think of the distance between <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> in the 2-norm as being essentially the entropy of <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+A-U%5CrVert+_%7B2%7D%5E%7B2%7D+%26+%3D%5Csum+_%7Bx%5Cin+G%7D%5Cleft+%28A%28x%29-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5Cright+%29%5E%7B2%7D%5C%5C+%26+%3D%5Csum+_%7Bx%5Cin+G%7DA%28x%29%5E%7B2%7D-2A%28x%29%5Cfrac+%7B1%7D%7B%7CG%7C%7D%2B%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B2%7D%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5Cfrac+%7B1%7D%7B%7CG%7C%7D%5C%5C+%26+%3D%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D-%5ClVert+U%5CrVert+_%7B2%7D%5E%7B2%7D%5C%5C+%26+%5Capprox+%5ClVert+A%5CrVert+_%7B2%7D%5E%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}" class="latex" title="\begin{aligned} \lVert A-U\rVert _{2}^{2} &amp; =\sum _{x\in G}\left (A(x)-\frac {1}{|G|}\right )^{2}\\ &amp; =\sum _{x\in G}A(x)^{2}-2A(x)\frac {1}{|G|}+\frac {1}{|G|^{2}}\\ &amp; =\lVert A\rVert _{2}^{2}-\frac {1}{|G|}\\ &amp; =\lVert A\rVert _{2}^{2}-\lVert U\rVert _{2}^{2}\\ &amp; \approx \lVert A\rVert _{2}^{2}. \end{aligned}" /></div>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-12001r7"></a> Lemma 7. </span><span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowers08">Gow08</a>, <a href="https://emanueleviola.wordpress.com/feed/#XBabaiNP08">BNP08</a>]</span> If <img src="https://s0.wp.com/latex.php?latex=X%2CY&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X,Y" class="latex" title="X,Y" /> are independent over <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />, then</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}" class="latex" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{2}\leq \lVert X\rVert _{2}\lVert Y\rVert _{2}\sqrt {\frac {|G|}{d}}, \end{aligned}" /></div>
<p>where <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> is the minimum dimension of an irreducible representation of <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">By this lemma, for high entropy distributions <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" />, we get <img src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7B%7CG%7Cd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}" class="latex" title="\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {|G|d}}" />. The factor <img src="https://s0.wp.com/latex.php?latex=1%2F%5Csqrt+%7B%7CG%7C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/\sqrt {|G|}" class="latex" title="1/\sqrt {|G|}" /> allows us to pass to <em>statistical distance </em><img src="https://s0.wp.com/latex.php?latex=%5ClVert+.%5CrVert+_%7B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert .\rVert _{1}" class="latex" title="\lVert .\rVert _{1}" /> using Cauchy-Schwarz:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B1%7D%5Cleq+%5Csqrt+%7B%7CG%7C%7D%5ClVert+X%5Ccdot+Y-U%5CrVert+_%7B2%7D%5Cleq+%5Cfrac+%7BO%281%29%7D%7B%5Csqrt+%7Bd%7D%7D.%7E%7E%7E%7E%281%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}" class="latex" title="\begin{aligned} \lVert X\cdot Y-U\rVert _{1}\leq \sqrt {|G|}\lVert X\cdot Y-U\rVert _{2}\leq \frac {O(1)}{\sqrt {d}}.~~~~(1) \end{aligned}" /></div>
<p style="text-align: justify;">This is the way in which we will use the lemma.</p>
<p style="text-align: justify;">Another useful consequence of this lemma, which however we will not use directly, is this. Suppose now you have <img src="https://s0.wp.com/latex.php?latex=three&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="three" class="latex" title="three" /> independent, high-entropy variables <img src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X,Y,Z" class="latex" title="X,Y,Z" />. Then for every <img src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g\in G" class="latex" title="g\in G" /> we have</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX%5Ccdot+Y%5Ccdot+Z%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5ClVert+Z%5CrVert+_%7B2%7D%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D.%7E%7E%7E%7E%282%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}" class="latex" title="\begin{aligned} |\mathbb{P} [X\cdot Y\cdot Z=g]-1/|G||\le \lVert X\rVert _{2}\lVert Y\rVert _{2}\lVert Z\rVert _{2}\sqrt {\frac {|G|}{d}}.~~~~(2) \end{aligned}" /></div>
<p style="text-align: justify;">To show this, set <img src="https://s0.wp.com/latex.php?latex=g%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g=1_{G}" class="latex" title="g=1_{G}" /> without loss of generality and rewrite the left-hand-side as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Csum+_%7Bh%5Cin+G%7D%5Cmathbb%7BP%7D+%5BX%3Dh%5D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}" class="latex" title="\begin{aligned} |\sum _{h\in G}\mathbb{P} [X=h](\mathbb{P} [YZ=h^{-1}]-1/|G|)|. \end{aligned}" /></div>
<p>By Cauchy-Schwarz this is at most</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Csqrt+%7B%5Csum+_%7Bh%7D%5Cmathbb%7BP%7D+%5E%7B2%7D%5BX%3Dh%5D%7D%5Csqrt+%7B%5Csum+_%7Bh%7D%28%5Cmathbb%7BP%7D+%5BYZ%3Dh%5E%7B-1%7D%5D-1%2F%7CG%7C%29%5E%7B2%7D%7D%3D%5ClVert+X%5ClVert+_%7B2%7D%5ClVert+YZ-U%5ClVert+_%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}" class="latex" title="\begin{aligned} \sqrt {\sum _{h}\mathbb{P} ^{2}[X=h]}\sqrt {\sum _{h}(\mathbb{P} [YZ=h^{-1}]-1/|G|)^{2}}=\lVert X\lVert _{2}\lVert YZ-U\lVert _{2} \end{aligned}" /></div>
<p>and we can conclude by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7</a>. Hence the product of three high-entropy distributions is close to uniform in a point-wise sense: each group element is obtained with roughly probability <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|" class="latex" title="1/|G|" />.</p>
<p style="text-align: justify;">At least over <img src="https://s0.wp.com/latex.php?latex=SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="SL(2,q)" class="latex" title="SL(2,q)" />, there exists an alternative proof of this fact that does not mention representation theory (see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span> and <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups">Vioa</a>, <a href="https://emanueleviola.wordpress.com/feed/#Xviola-blog-mixing-in-groups-ii">Viob</a>]</span>).</p>
<p style="text-align: justify;">With this notation in hand, we conclude by stating a “mixing” version of Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-20002">2</a>. For more on this perspective we refer the reader to <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. <a id="x1-12002r1"></a></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=SL(2,q)" class="latex" title="G=SL(2,q)" />. Let <img src="https://s0.wp.com/latex.php?latex=X%3D%28X_%7B1%7D%2CX_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X=(X_{1},X_{2})" class="latex" title="X=(X_{1},X_{2})" /> and <img src="https://s0.wp.com/latex.php?latex=Y%3D%28Y_%7B1%7D%2CY_%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y=(Y_{1},Y_{2})" class="latex" title="Y=(Y_{1},Y_{2})" /> be two distributions over <img src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G^{2}" class="latex" title="G^{2}" />. Suppose <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> is independent from <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" />. Let <img src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g\in G" class="latex" title="g\in G" />. We have</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5BX_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D%3Dg%5D-1%2F%7CG%7C%7C%5Cle+%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}" class="latex" title="\begin{aligned} |\mathbb{P} [X_{1}Y_{1}X_{2}Y_{2}=g]-1/|G||\le |G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}. \end{aligned}" /></div>
<p style="text-align: justify;">For example, when <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> have high entropy over <img src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G^{2}" class="latex" title="G^{2}" /> (that is, are uniform over <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%7CG%7C%5E%7B2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (|G|^{2})" class="latex" title="\Omega (|G|^{2})" /> pairs), we have <img src="https://s0.wp.com/latex.php?latex=%5ClVert+X%5CrVert+_%7B2%7D%5Cle+%5Csqrt+%7BO%281%29%2F%7CG%7C%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}" class="latex" title="\lVert X\rVert _{2}\le \sqrt {O(1)/|G|^{2}}" />, and so <img src="https://s0.wp.com/latex.php?latex=%7CG%7C%5E%7B1-%5COmega+%281%29%7D%5ClVert+X%5CrVert+_%7B2%7D%5ClVert+Y%5CrVert+_%7B2%7D%5Cle+1%2F%7CG%7C%5E%7B1%2B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}" class="latex" title="|G|^{1-\Omega (1)}\lVert X\rVert _{2}\lVert Y\rVert _{2}\le 1/|G|^{1+\Omega (1)}" />. In particular, <img src="https://s0.wp.com/latex.php?latex=X_%7B1%7DY_%7B1%7DX_%7B2%7DY_%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_{1}Y_{1}X_{2}Y_{2}" class="latex" title="X_{1}Y_{1}X_{2}Y_{2}" /> is <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|^{\Omega (1)}" class="latex" title="1/|G|^{\Omega (1)}" /> close to uniform over <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> in statistical distance.</p>
<h5 class="subsubsectionHead"><span class="titlemark">5.0.2 </span> <a id="x1-130005.0.2"></a>Back to protocols</h5>
<p style="text-align: justify;">As in the beginning of Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3</a>, for any group element <img src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g\in G" class="latex" title="g\in G" /> we define the distribution on triples <img src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D%3A%3D%28x%2Cy%2C%28x%5Ccdot+y%29%5E%7B-1%7Dg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_{g}:=(x,y,(x\cdot y)^{-1}g)" class="latex" title="D_{g}:=(x,y,(x\cdot y)^{-1}g)" />, where <img src="https://s0.wp.com/latex.php?latex=x%2Cy%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y\in G" class="latex" title="x,y\in G" /> are uniform and independent. Note the product of the elements in <img src="https://s0.wp.com/latex.php?latex=D_%7Bg%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_{g}" class="latex" title="D_{g}" /> is always <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" />. Again as in Section <a href="https://emanueleviola.wordpress.com/feed/#x1-30003">3</a>, it suffices to show that for every <em>deterministic</em> protocols <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> using little communication we have</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5CPr+%5BP%28D_%7B1%7D%29%3D1%5D-%5CPr+%5BP%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cfrac+%7B1%7D%7B100%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" class="latex" title="\begin{aligned} |\Pr [P(D_{1})=1]-\Pr [P(D_{h})=1]|\leq \frac {1}{100}. \end{aligned}" /></div>
<p style="text-align: justify;">Analogously to Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4</a>, the following lemma describes a protocol using rectangles. The proof is nearly identical and is omitted.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13001r8"></a> Lemma 8. </span>(The set of accepted inputs of) A deterministic <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />-bit number-in-hand protocol with three parties can be written as a disjoint union of <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}" class="latex" title="2^{c}" /> “rectangles,” that is sets of the form <img src="https://s0.wp.com/latex.php?latex=A%5Ctimes+B%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\times B\times C" class="latex" title="A\times B\times C" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Next we show that these product sets cannot distinguish these two distributions <img src="https://s0.wp.com/latex.php?latex=D_%7B1%7D%2CD_%7Bh%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_{1},D_{h}" class="latex" title="D_{1},D_{h}" />, via a straightforward application of lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7</a>.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-13002r9"></a> Lemma 9. </span>For all <img src="https://s0.wp.com/latex.php?latex=A%2CB%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A,B,C\subseteq G" class="latex" title="A,B,C\subseteq G" /> we have <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+1%2Fd%5E%7B%5COmega+%281%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}." class="latex" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq 1/d^{\Omega (1)}." /></p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Pick any <img src="https://s0.wp.com/latex.php?latex=h%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h\in G" class="latex" title="h\in G" /> and let <img src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y,z" class="latex" title="x,y,z" /> be the inputs of Alice, Bob, and Charlie respectively. Then</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%3D%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Ccdot+%5Cmathbb%7BP%7D+%5B%28x%5Ccdot+y%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%7C%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%2C%7E%7E%7E%7E%283%29+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}" class="latex" title="\begin{aligned} \mathbb{P} [(A\times B\times C)(D_{h})=1]=\mathbb{P} [(x,y)\in A\times B]\cdot \mathbb{P} [(x\cdot y)^{-1}\cdot h\in C|(x,y)\in A\times B],~~~~(3) \end{aligned}" /></div>
<p>where <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)" class="latex" title="(x,y)" /> is uniform in <img src="https://s0.wp.com/latex.php?latex=G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G^{2}" class="latex" title="G^{2}" />. If either <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> or <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> is small, that is <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} [x\in A]\leq \epsilon " class="latex" title="\mathbb{P} [x\in A]\leq \epsilon " /> or <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%5Cleq+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} [y\in B]\leq \epsilon " class="latex" title="\mathbb{P} [y\in B]\leq \epsilon " />, then also <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5B%28x%2Cy%29%5Cin+A%5Ctimes+B%5D%5Cle+%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} [(x,y)\in A\times B]\le \epsilon " class="latex" title="\mathbb{P} [(x,y)\in A\times B]\le \epsilon " /> and hence (??) is at most <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " /> as well. This holds for every <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" />, so we also have <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BP%7D+%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cleq+%5Cepsilon+.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ." class="latex" title="|\mathbb{P} (A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\leq \epsilon ." /> We will choose <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " /> later.</p>
<p style="text-align: justify;">Otherwise, <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> are large: <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5Bx%5Cin+A%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} [x\in A]&gt;\epsilon " class="latex" title="\mathbb{P} [x\in A]&gt;\epsilon " /> and <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+%5By%5Cin+B%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} [y\in B]&gt;\epsilon " class="latex" title="\mathbb{P} [y\in B]&gt;\epsilon " />. Let <img src="https://s0.wp.com/latex.php?latex=%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x',y')" class="latex" title="(x',y')" /> be the distribution of <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)" class="latex" title="(x,y)" /> conditioned on <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A%5Ctimes+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)\in A\times B" class="latex" title="(x,y)\in A\times B" />. We have that <img src="https://s0.wp.com/latex.php?latex=x%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x'" class="latex" title="x'" /> and <img src="https://s0.wp.com/latex.php?latex=y%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y'" class="latex" title="y'" /> are independent and each is uniform over at least <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon |G|" class="latex" title="\epsilon |G|" /> elements. By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7</a> this implies <img src="https://s0.wp.com/latex.php?latex=%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B2%7D%5Cleq+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B%7CG%7C%7D%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}" class="latex" title="\lVert x'\cdot y'-U\rVert _{2}\leq \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {|G|}{d}}" />, where <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> is the uniform distribution. As mentioned after the lemma, by Cauchy–Schwarz we obtain</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5ClVert+x%27%5Ccdot+y%27-U%5CrVert+_%7B1%7D%5Cleq+%7CG%7C%5Ccdot+%5ClVert+x%27%5CrVert+_%7B2%7D%5Ccdot+%5ClVert+y%27%5CrVert+_%7B2%7D%5Ccdot+%5Csqrt+%7B%5Cfrac+%7B1%7D%7Bd%7D%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}" class="latex" title="\begin{aligned} \lVert x'\cdot y'-U\rVert _{1}\leq |G|\cdot \lVert x'\rVert _{2}\cdot \lVert y'\rVert _{2}\cdot \sqrt {\frac {1}{d}}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}, \end{aligned}" /></div>
<p>where the last inequality follows from the fact that <img src="https://s0.wp.com/latex.php?latex=%5ClVert+x%5CrVert+_%7B2%7D%2C%5ClVert+y%5CrVert+_%7B2%7D%5Cleq+%5Csqrt+%7B%5Cfrac+%7B1%7D%7B%5Cepsilon+%7CG%7C%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}" class="latex" title="\lVert x\rVert _{2},\lVert y\rVert _{2}\leq \sqrt {\frac {1}{\epsilon |G|}}" />.</p>
<p style="text-align: justify;">This implies that <img src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" title="\lVert (x'\cdot y')^{-1}-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" /> and <img src="https://s0.wp.com/latex.php?latex=%5ClVert+%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h-U%5CrVert+_%7B1%7D%5Cleq+%5Cfrac+%7B1%7D%7B%5Cepsilon+%7D%5Ccdot+%5Cfrac+%7B1%7D%7B%5Csqrt+%7Bd%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" class="latex" title="\lVert (x'\cdot y')^{-1}\cdot h-U\rVert _{1}\leq \frac {1}{\epsilon }\cdot \frac {1}{\sqrt {d}}" />, because taking inverses and multiplying by <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h" class="latex" title="h" /> does not change the distance to uniform. These two last inequalities imply that</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Cin+C%5D-%5Cmathbb%7BP%7D+%5B%28x%27%5Ccdot+y%27%29%5E%7B-1%7D%5Ccdot+h%5Cin+C%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29%3B+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}" class="latex" title="\begin{aligned} |\mathbb{P} [(x'\cdot y')^{-1}\in C]-\mathbb{P} [(x'\cdot y')^{-1}\cdot h\in C]|\le O(\frac {1}{\epsilon \sqrt {d}}); \end{aligned}" /></div>
<p>and thus we get that</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7B1%7D%29%3D1%5D-%5Cmathbb%7BP%7D+%5B%28A%5Ctimes+B%5Ctimes+C%29%28D_%7Bh%7D%29%3D1%5D%7C%5Cle+O%28%5Cfrac+%7B1%7D%7B%5Cepsilon+%5Csqrt+%7Bd%7D%7D%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}" class="latex" title="\begin{aligned} |\mathbb{P} [(A\times B\times C)(D_{1})=1]-\mathbb{P} [(A\times B\times C)(D_{h})=1]|\le O(\frac {1}{\epsilon \sqrt {d}}). \end{aligned}" /></div>
<p>Picking <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon =1/d^{1/4}" class="latex" title="\epsilon =1/d^{1/4}" /> completes the proof. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">Returning to arbitrary deterministic protocols <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> (as opposed to rectangles), write <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> as a union of <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}" class="latex" title="2^{c}" /> disjoint rectangles by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8</a>. Applying Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-13002r9">9</a> and summing over all rectangles we get that the distinguishing advantage of <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is at most <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D%2Fd%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}/d^{1/4}" class="latex" title="2^{c}/d^{1/4}" />. For <img src="https://s0.wp.com/latex.php?latex=c%5Cleq+%281%2F100%29%5Clog+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c\leq (1/100)\log d" class="latex" title="c\leq (1/100)\log d" /> the advantage is at most <img src="https://s0.wp.com/latex.php?latex=1%2F100&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/100" class="latex" title="1/100" />, concluding the proof.</p>
<h3 class="sectionHead"><span class="titlemark">6 </span> <a id="x1-140006"></a>Three parties, number-on-forehead</h3>
<p style="text-align: justify;">In number-on-forehead (NOH) communication complexity <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XCFL83">CFL83</a>]</span> with <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> parties, the input is a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-tuple <img src="https://s0.wp.com/latex.php?latex=%28x_%7B1%7D%2C%5Cdotsc+%2Cx_%7Bk%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x_{1},\dotsc ,x_{k})" class="latex" title="(x_{1},\dotsc ,x_{k})" /> and each party <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> sees all of it except <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i}" class="latex" title="x_{i}" />. For background, it is not known how to prove negative results for <img src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k\ge \log n" class="latex" title="k\ge \log n" /> parties.</p>
<p style="text-align: justify;">We mention that Theorem <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1</a> can be extended to the multiparty setting, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGowersV-cc-int-journal">GVa</a>]</span>. Several questions arise here, such as whether this problem remains hard for <img src="https://s0.wp.com/latex.php?latex=k%5Cge+%5Clog+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k\ge \log n" class="latex" title="k\ge \log n" />, and what is the minimum length of an interleaved product that is hard for <img src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k=3" class="latex" title="k=3" /> parties (the proof in <a href="https://emanueleviola.wordpress.com/feed/#x1-2002r1">1</a> gives a large constant).</p>
<p style="text-align: justify;">However in this survey we shall instead focus on the problem of separating deterministic and randomized communication. For <img src="https://s0.wp.com/latex.php?latex=k%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k=2" class="latex" title="k=2" />, we know the optimal separation: The equality function requires <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (n)" class="latex" title="\Omega (n)" /> communication for deterministic protocols, but can be solved using <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> communication if we allow the protocols to use public coins. For <img src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k=3" class="latex" title="k=3" />, the best known separation between deterministic and randomized protocol is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log n)" class="latex" title="\Omega (\log n)" /> vs <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" /> <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>. In the following we give a new proof of this result, for a different function: <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x,y,z)=1_{G}" class="latex" title="f(x,y,z)=1_{G}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+z%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot y\cdot z=1" class="latex" title="x\cdot y\cdot z=1" /> for <img src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz%5Cin+SL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y,z\in SL(2,q)" class="latex" title="x,y,z\in SL(2,q)" />. As is true for some functions in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XBeameDPW10">BDPW10</a>]</span>, a stronger separation could hold for <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" />. For context, let us state and prove the upper bound for randomized communication.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14001r10"></a> Claim 10. </span><img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> has randomized communication complexity <img src="https://s0.wp.com/latex.php?latex=O%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1)" class="latex" title="O(1)" />.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>In the number-on-forehead model, computing <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> reduces to two-party equality with no additional communication: Alice computes <img src="https://s0.wp.com/latex.php?latex=y%5Ccdot+z%3D%3Aw&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y\cdot z=:w" class="latex" title="y\cdot z=:w" /> privately, then Alice and Bob check if <img src="https://s0.wp.com/latex.php?latex=x%3Dw%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=w^{-1}" class="latex" title="x=w^{-1}" />. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">To prove the lower bound for deterministic protocols we reduce the communication problem to a combinatorial problem.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14002r11"></a> Definition 11. </span>A <em>corner</em> in a group <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is a set <img src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}" class="latex" title="\{(x,y),(xz,y),(x,zy)\}\subseteq G^{2}" />, where <img src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y" class="latex" title="x,y" /> are arbitrary group elements and <img src="https://s0.wp.com/latex.php?latex=z%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z\neq 1_{G}" class="latex" title="z\neq 1_{G}" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">For intuition, if <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is the abelian group of real numbers with addition, a corner becomes <img src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28x%2Bz%2Cy%29%2C%28x%2Cy%2Bz%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{(x,y),(x+z,y),(x,y+z)\}" class="latex" title="\{(x,y),(x+z,y),(x,y+z)\}" /> for <img src="https://s0.wp.com/latex.php?latex=z%5Cneq+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z\neq 0" class="latex" title="z\neq 0" />, which are the coordinates of an isosceles triangle. We now state the theorem that connects corners and lower bounds.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-14003r12"></a> Lemma 12. </span>Let <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> be a group and <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta " class="latex" title="\delta " /> a real number. Suppose that every subset <img src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\subseteq G^{2}" class="latex" title="A\subseteq G^{2}" /> with <img src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|A|/|G^{2}|\ge \delta " class="latex" title="|A|/|G^{2}|\ge \delta " /> contains a corner. Then the deterministic communication complexity of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> (defined as <img src="https://s0.wp.com/latex.php?latex=f%28x%2Cy%2Cz%29%3D1%5Ciff+x%5Ccdot+y%5Ccdot+z%3D1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}" class="latex" title="f(x,y,z)=1\iff x\cdot y\cdot z=1_{G}" />) is <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%281%2F%5Cdelta+%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log (1/\delta ))" class="latex" title="\Omega (\log (1/\delta ))" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">It is known that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolyloglog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta \ge 1/\mathrm {polyloglog}|G|" class="latex" title="\delta \ge 1/\mathrm {polyloglog}|G|" /> implies a corner for certain abelian groups <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />, see <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XMR2289954">LM07</a>]</span> for the best bound and pointers to the history of the problem. For <img src="https://s0.wp.com/latex.php?latex=G%3DSL%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=SL(2,q)" class="latex" title="G=SL(2,q)" /> a stronger result is known: <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Cmathrm+%7Bpolylog%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta \ge 1/\mathrm {polylog}|G|" class="latex" title="\delta \ge 1/\mathrm {polylog}|G|" /> implies a corner <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. This in turn implies communication <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+%5Clog+%7CG%7C%29%3D%5COmega+%28%5Clog+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log \log |G|)=\Omega (\log n)" class="latex" title="\Omega (\log \log |G|)=\Omega (\log n)" />.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We saw already twice that a number-in-hand <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />-bit protocol can be written as a disjoint union of <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}" class="latex" title="2^{c}" /> rectangles (Lemmas <a href="https://emanueleviola.wordpress.com/feed/#x1-4001r4">4</a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-13001r8">8</a>). Likewise, a number-on-forehead <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />-bit protocol <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> can be written as a disjoint union of <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}" class="latex" title="2^{c}" /> cylinder intersections <img src="https://s0.wp.com/latex.php?latex=C_%7Bi%7D%3A%3D%5C%7B%28x%2Cy%2Cz%29%3Af_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29%3D1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}" class="latex" title="C_{i}:=\{(x,y,z):f_{i}(y,z)g_{i}(x,z)h_{i}(x,y)=1\}" /> for some <img src="https://s0.wp.com/latex.php?latex=f_%7Bi%7D%2Cg_%7Bi%7D%2Ch_%7Bi%7D%5Ccolon+G%5E%7B2%7D%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}" class="latex" title="f_{i},g_{i},h_{i}\colon G^{2}\to \{0,1\}" />:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+P%28x%2Cy%2Cz%29%3D%5Csum+_%7Bi%3D1%7D%5E%7B2%5E%7Bc%7D%7Df_%7Bi%7D%28y%2Cz%29g_%7Bi%7D%28x%2Cz%29h_%7Bi%7D%28x%2Cy%29.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}" class="latex" title="\begin{aligned} P(x,y,z)=\sum _{i=1}^{2^{c}}f_{i}(y,z)g_{i}(x,z)h_{i}(x,y). \end{aligned}" /></div>
<p>The proof idea of the above fact is to consider the <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{c}" class="latex" title="2^{c}" /> transcripts of <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />, then one can see that the inputs giving a fixed transcript are a cylinder intersection.</p>
<p style="text-align: justify;">Let <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> be a <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />-bit protocol. Consider the inputs <img src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{(x,y,(xy)^{-1})\}" class="latex" title="\{(x,y,(xy)^{-1})\}" /> on which <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> accepts. Note that at least <img src="https://s0.wp.com/latex.php?latex=2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{-c}" class="latex" title="2^{-c}" /> fraction of them are accepted by some cylinder intersection <img src="https://s0.wp.com/latex.php?latex=C%3Df%5Ccdot+g%5Ccdot+h&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C=f\cdot g\cdot h" class="latex" title="C=f\cdot g\cdot h" />. Let <img src="https://s0.wp.com/latex.php?latex=A%3A%3D%5C%7B%28x%2Cy%29%3A%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C%5C%7D%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}" class="latex" title="A:=\{(x,y):(x,y,(xy)^{-1})\in C\}\subseteq G^{2}" />. Since the first two elements in the tuple determine the last, we have <img src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%5E%7B2%7D%7C%5Cge+2%5E%7B-c%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|A|/|G^{2}|\ge 2^{-c}" class="latex" title="|A|/|G^{2}|\ge 2^{-c}" />.</p>
<p style="text-align: justify;">Now suppose <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> contains a corner <img src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{(x,y),(xz,y),(x,zy)\}" class="latex" title="\{(x,y),(xz,y),(x,zy)\}" />. Then</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%28x%2Cy%29%5Cin+A+%26+%5Cimplies+%28x%2Cy%2C%28xy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+h%28x%2Cy%29%3D1%2C%5C%5C+%28xz%2Cy%29%5Cin+A+%26+%5Cimplies+%28xz%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+f%28y%2C%28xyz%29%5E%7B-1%7D%29%3D1%2C%5C%5C+%28x%2Czy%29%5Cin+A+%26+%5Cimplies+%28x%2Czy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C+%26+%26+%5Cimplies+g%28x%2C%28xyz%29%5E%7B-1%7D%29%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}" class="latex" title="\begin{aligned} (x,y)\in A &amp; \implies (x,y,(xy)^{-1})\in C &amp; &amp; \implies h(x,y)=1,\\ (xz,y)\in A &amp; \implies (xz,y,(xzy)^{-1})\in C &amp; &amp; \implies f(y,(xyz)^{-1})=1,\\ (x,zy)\in A &amp; \implies (x,zy,(xzy)^{-1})\in C &amp; &amp; \implies g(x,(xyz)^{-1})=1. \end{aligned}" /></div>
<p>This implies <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%2C%28xzy%29%5E%7B-1%7D%29%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y,(xzy)^{-1})\in C" class="latex" title="(x,y,(xzy)^{-1})\in C" />, which is a contradiction because <img src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z\neq 1" class="latex" title="z\neq 1" /> and so <img src="https://s0.wp.com/latex.php?latex=x%5Ccdot+y%5Ccdot+%28xzy%29%5E%7B-1%7D%5Cneq+1_%7BG%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}" class="latex" title="x\cdot y\cdot (xzy)^{-1}\neq 1_{G}" />. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<h3 class="sectionHead"><span class="titlemark">7 </span> <a id="x1-150007"></a>The corners theorem for quasirandom groups</h3>
<p style="text-align: justify;">In this section we prove the corners theorem for quasirandom groups, following Austin <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>. Our exposition has several minor differences with that in <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XAustin2016">Aus16</a>]</span>, which may make it more computer-science friendly. Possibly a proof can also be obtained via certain local modifications and simplifications of Green’s exposition <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XGre04-finite">Gre05b</a>, <a href="https://emanueleviola.wordpress.com/feed/#XGreen-supplement">Gre05a</a>]</span> of an earlier proof for the abelian case. We focus on the case <img src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=\textit {SL}(2,q)" class="latex" title="G=\textit {SL}(2,q)" /> for simplicity, but the proof immediately extends to other quasirandom groups (with corresponding parameters). <a id="x1-15001r1"></a></p>
<p style="text-align: justify;"><b>Theorem 1.</b> Let <img src="https://s0.wp.com/latex.php?latex=G%3D%5Ctextit+%7BSL%7D%282%2Cq%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G=\textit {SL}(2,q)" class="latex" title="G=\textit {SL}(2,q)" />. Every subset <img src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\subseteq G^{2}" class="latex" title="A\subseteq G^{2}" /> of density <img src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cgeq+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|A|/|G|^{2}\geq 1/\log ^{a}|G|" class="latex" title="|A|/|G|^{2}\geq 1/\log ^{a}|G|" /> contains a corner <img src="https://s0.wp.com/latex.php?latex=%5C%7B%28x%2Cy%29%2C%28xz%2Cy%29%2C%28x%2Czy%29%7E%7C%7Ez%5Cneq+1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}" class="latex" title="\{(x,y),(xz,y),(x,zy)~|~z\neq 1\}" />.</p>
<h4 class="subsectionHead"><span class="titlemark">7.1 </span> <a id="x1-160007.1"></a>Proof idea</h4>
<p style="text-align: justify;">For intuition, suppose <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> is a product set, i.e., <img src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A=B\times C" class="latex" title="A=B\times C" /> for <img src="https://s0.wp.com/latex.php?latex=B%2CC%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B,C\subseteq G" class="latex" title="B,C\subseteq G" />. Let’s look at the quantity</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BA%28x%2Cy%29A%28xz%2Cy%29A%28x%2Czy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[A(x,y)A(xz,y)A(x,zy)] \end{aligned}" /></div>
<p>where <img src="https://s0.wp.com/latex.php?latex=A%28x%2Cy%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(x,y)=1" class="latex" title="A(x,y)=1" /> iff <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%5Cin+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)\in A" class="latex" title="(x,y)\in A" />. Note that the random variable in the expectation is equal to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> exactly when <img src="https://s0.wp.com/latex.php?latex=x%2Cy%2Cz&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y,z" class="latex" title="x,y,z" /> form a corner in <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />. We’ll show that this quantity is greater than <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|" class="latex" title="1/|G|" />, which implies that <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> contains a corner (where <img src="https://s0.wp.com/latex.php?latex=z%5Cneq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z\neq 1" class="latex" title="z\neq 1" />). Since we are taking <img src="https://s0.wp.com/latex.php?latex=A%3DB%5Ctimes+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A=B\times C" class="latex" title="A=B\times C" />, we can rewrite the above quantity as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28y%29B%28x%29C%28zy%29%5D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28xz%29C%28zy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cz%5Cleftarrow+G%7D%5BB%28x%29C%28y%29B%28z%29C%28x%5E%7B-1%7Dzy%29%5D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(y)B(x)C(zy)] &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(xz)C(zy)]\\ &amp; =\mathbb {E}_{x,y,z\leftarrow G}[B(x)C(y)B(z)C(x^{-1}zy)] \end{aligned}" /></div>
<p>where the last line follows by replacing <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z" class="latex" title="z" /> with <img src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dz&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{-1}z" class="latex" title="x^{-1}z" /> in the uniform distribution. If <img src="https://s0.wp.com/latex.php?latex=%7CA%7C%2F%7CG%7C%5E%7B2%7D%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|A|/|G|^{2}\ge \delta " class="latex" title="|A|/|G|^{2}\ge \delta " />, then both |B|/|G|<img src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ge \delta " class="latex" title="\ge \delta " /> and <img src="https://s0.wp.com/latex.php?latex=%7CB%7C%2F%7CG%7C%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|B|/|G|\ge \delta " class="latex" title="|B|/|G|\ge \delta " />. Condition on <img src="https://s0.wp.com/latex.php?latex=x%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in B" class="latex" title="x\in B" />, <img src="https://s0.wp.com/latex.php?latex=y%5Cin+C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y\in C" class="latex" title="y\in C" />, <img src="https://s0.wp.com/latex.php?latex=z%5Cin+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="z\in B" class="latex" title="z\in B" />. Then the distribution <img src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{-1}zy" class="latex" title="x^{-1}zy" /> is a product of three independent distributions, each uniform on a set of density <img src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cdelta+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ge \delta " class="latex" title="\ge \delta " />. (In fact, two distributions would suffice for this.) By Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7</a>, <img src="https://s0.wp.com/latex.php?latex=x%5E%7B-1%7Dzy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x^{-1}zy" class="latex" title="x^{-1}zy" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5E%7B-1%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta ^{-1}/|G|^{\Omega (1)}" class="latex" title="\delta ^{-1}/|G|^{\Omega (1)}" /> close to uniform in statistical distance. This implies that the above expectation equals</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cfrac+%7B%7CA%7C%7D%7B%7CG%7C%5E%7B2%7D%7D%5Ccdot+%5Cfrac+%7B%7CB%7C%7D%7B%7CG%7C%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7B%7CC%7C%7D%7B%7CG%7C%7D%5Cpm+%5Cfrac+%7B%5Cdelta+%5E%7B-1%7D%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29+%26+%5Cgeq+%5Cdelta+%5E%7B2%7D%5Cleft+%28%5Cdelta+-%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D%5Cright+%29%5Cgeq+%5Cdelta+%5E%7B3%7D%2F2%3E1%2F%7CG%7C%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}" class="latex" title="\begin{aligned} \frac {|A|}{|G|^{2}}\cdot \frac {|B|}{|G|}\cdot \left (\frac {|C|}{|G|}\pm \frac {\delta ^{-1}}{|G|^{\Omega (1)}}\right ) &amp; \geq \delta ^{2}\left (\delta -\frac {1}{|G|^{\Omega (1)}}\right )\geq \delta ^{3}/2&gt;1/|G|, \end{aligned}" /></div>
<p style="text-align: justify;">for <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta &gt;1/|G|^{c}" class="latex" title="\delta &gt;1/|G|^{c}" /> for a small enough constant <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" />. Hence, product sets of density polynomial in <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|" class="latex" title="1/|G|" /> contain corners.</p>
<p style="text-align: justify;">Given the above, it is natural to try to decompose an arbitrary set <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> into product sets. We will make use of a more general result.</p>
<h4 class="subsectionHead"><span class="titlemark">7.2 </span> <a id="x1-170007.2"></a>Weak Regularity Lemma</h4>
<p style="text-align: justify;">Let <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> be some universe (we will take <img src="https://s0.wp.com/latex.php?latex=U%3DG%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U=G^{2}" class="latex" title="U=G^{2}" />) and let <img src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:U\rightarrow [-1,1]" class="latex" title="f:U\rightarrow [-1,1]" /> be a function (for us, <img src="https://s0.wp.com/latex.php?latex=f%3D1_%7BA%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f=1_{A}" class="latex" title="f=1_{A}" />). Let <img src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" title="D\subseteq \{d:U\rightarrow [-1,1]\}" /> be some set of functions, which can be thought of as “easy functions” or “distinguishers” (these will be rectangles or closely related to them). The next theorem shows how to decompose <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> into a linear combination <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> of the <img src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_{i}" class="latex" title="d_{i}" /> up to an error which is polynomial in the length of the combination. More specifically, <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> will be indistinguishable from <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> by the <img src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_{i}" class="latex" title="d_{i}" />.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-17001r13"></a> Lemma 13. </span>Let <img src="https://s0.wp.com/latex.php?latex=f%3AU%5Crightarrow+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:U\rightarrow [-1,1]" class="latex" title="f:U\rightarrow [-1,1]" /> be a function and <img src="https://s0.wp.com/latex.php?latex=D%5Csubseteq+%5C%7Bd%3AU%5Crightarrow+%5B-1%2C1%5D%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D\subseteq \{d:U\rightarrow [-1,1]\}" class="latex" title="D\subseteq \{d:U\rightarrow [-1,1]\}" /> a set of functions. For all <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon &gt;0" class="latex" title="\epsilon &gt;0" />, there exists a function <img src="https://s0.wp.com/latex.php?latex=g%3A%3D%5Csum+_%7Bi%5Cle+s%7Dc_%7Bi%7D%5Ccdot+d_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g:=\sum _{i\le s}c_{i}\cdot d_{i}" class="latex" title="g:=\sum _{i\le s}c_{i}\cdot d_{i}" /> where <img src="https://s0.wp.com/latex.php?latex=d_%7Bi%7D%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d_{i}\in D" class="latex" title="d_{i}\in D" />, <img src="https://s0.wp.com/latex.php?latex=c_%7Bi%7D%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c_{i}\in \mathbb {R}" class="latex" title="c_{i}\in \mathbb {R}" /> and <img src="https://s0.wp.com/latex.php?latex=s%3D1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s=1/\epsilon ^{2}" class="latex" title="s=1/\epsilon ^{2}" /> such that for all <img src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d\in D" class="latex" title="d\in D" /></p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleft+%7C%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bf%28x%29%5Ccdot+d%28x%29%5D-%5Cmathbb+%7BE%7D_%7Bx%5Cleftarrow+U%7D%5Bg%28x%29%5Ccdot+d%28x%29%5D%5Cright+%7C%5Cle+%5Cepsilon+.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}" class="latex" title="\begin{aligned} \left |\mathbb {E}_{x\leftarrow U}[f(x)\cdot d(x)]-\mathbb {E}_{x\leftarrow U}[g(x)\cdot d(x)]\right |\le \epsilon . \end{aligned}" /></div>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">A different way to state the conclusion, which we will use, is to say that we can write <img src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f=g+h" class="latex" title="f=g+h" /> so that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+%5Bh%28x%29%5Ccdot+d%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{E} [h(x)\cdot d(x)]" class="latex" title="\mathbb{E} [h(x)\cdot d(x)]" /> is small.</p>
<p style="text-align: justify;">The lemma is due to Frieze and Kannan <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/conf/focs/FriezeK96">FK96</a>]</span>. It is called “weak” because it came after Szemerédi’s regularity lemma, which has a stronger distinguishing conclusion. However, the lemma is also “strong” in the sense that Szemerédi’s regularity lemma has <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s" class="latex" title="s" /> as a tower of <img src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/\epsilon " class="latex" title="1/\epsilon " /> whereas here we have <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s" class="latex" title="s" /> polynomial in <img src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/\epsilon " class="latex" title="1/\epsilon " />. The weak regularity lemma is also simpler. There also exists a proof <span class="cite">[<a href="https://emanueleviola.wordpress.com/feed/#XTao2017-szemerediproof">Tao17</a>]</span> of Szemerédi’s theorem (on arithmetic progressions), which uses weak regularity as opposed to the full regularity lemma used initially.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will construct the approximation <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> through an iterative process producing functions <img src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%2Cg_%7B1%7D%2C%5Cdots+%2Cg&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_{0},g_{1},\dots ,g" class="latex" title="g_{0},g_{1},\dots ,g" />. We will show that <img src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7Bi%7D%7C%7C_%7B2%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="||f-g_{i}||_{2}^{2}" class="latex" title="||f-g_{i}||_{2}^{2}" /> decreases by <img src="https://s0.wp.com/latex.php?latex=%5Cge+%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ge \epsilon ^{2}" class="latex" title="\ge \epsilon ^{2}" /> each iteration.</p>
<p style="text-align: justify;"><b>Start</b>: Define <img src="https://s0.wp.com/latex.php?latex=g_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g_{0}=0" class="latex" title="g_{0}=0" /> (which can be realized setting <img src="https://s0.wp.com/latex.php?latex=c_%7B0%7D%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c_{0}=0" class="latex" title="c_{0}=0" />).</p>
<p style="text-align: justify;"><b>Iterate</b>: If not done, there exists <img src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d\in D" class="latex" title="d\in D" /> such that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%7C%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon " class="latex" title="|\mathbb {E}[(f-g)\cdot d]|&gt;\epsilon " />. Assume without loss of generality <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28f-g%29%5Ccdot+d%5D%3E%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon " class="latex" title="\mathbb {E}[(f-g)\cdot d]&gt;\epsilon " />.</p>
<p style="text-align: justify;"><b>Update</b>: <img src="https://s0.wp.com/latex.php?latex=g%27%3A%3Dg%2B%5Clambda+d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g':=g+\lambda d" class="latex" title="g':=g+\lambda d" /> where <img src="https://s0.wp.com/latex.php?latex=%5Clambda+%5Cin+%5Cmathbb+%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda \in \mathbb {R}" class="latex" title="\lambda \in \mathbb {R}" /> shall be picked later.</p>
<p style="text-align: justify;">Let us analyze the progress made by the algorithm.</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%7Cf-g%27%7C%7C_%7B2%7D%5E%7B2%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%27%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g-%5Clambda+d%29%5E%7B2%7D%28x%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5E%7B2%7D%5D%2B%5Cmathbb+%7BE%7D_%7Bx%7D%5B%5Clambda+%5E%7B2%7Dd%5E%7B2%7D%28x%29%5D-2%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29%5Ccdot+%5Clambda+d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28f-g%29d%28x%29%5D%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D%2B%5Clambda+%5E%7B2%7D-2%5Clambda+%5Cepsilon+%5C%5C+%26+%5Cleq+%7C%7Cf-g%7C%7C_%7B2%7D%5E%7B2%7D-%5Cepsilon+%5E%7B2%7D+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}" class="latex" title="\begin{aligned} ||f-g'||_{2}^{2} &amp; =\mathbb {E}_{x}[(f-g')^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g-\lambda d)^{2}(x)]\\ &amp; =\mathbb {E}_{x}[(f-g)^{2}]+\mathbb {E}_{x}[\lambda ^{2}d^{2}(x)]-2\mathbb {E}_{x}[(f-g)\cdot \lambda d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \mathbb {E}_{x}[(f-g)d(x)]\\ &amp; \leq ||f-g||_{2}^{2}+\lambda ^{2}-2\lambda \epsilon \\ &amp; \leq ||f-g||_{2}^{2}-\epsilon ^{2} \end{aligned}" /></div>
<p>where the last line follows by taking <img src="https://s0.wp.com/latex.php?latex=%5Clambda+%3D%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lambda =\epsilon " class="latex" title="\lambda =\epsilon " />. Therefore, there can only be <img src="https://s0.wp.com/latex.php?latex=1%2F%5Cepsilon+%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/\epsilon ^{2}" class="latex" title="1/\epsilon ^{2}" /> iterations because <img src="https://s0.wp.com/latex.php?latex=%7C%7Cf-g_%7B0%7D%7C%7C_%7B2%7D%5E%7B2%7D%3D%7C%7Cf%7C%7C_%7B2%7D%5E%7B2%7D%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1" class="latex" title="||f-g_{0}||_{2}^{2}=||f||_{2}^{2}\leq 1" />. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<h4 class="subsectionHead"><span class="titlemark">7.3 </span> <a id="x1-180007.3"></a>Getting more for rectangles</h4>
<p style="text-align: justify;">Returning to the main proof, we will use the weak regularity lemma to approximate the indicator function for arbitrary <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> by rectangles. That is, we take <img src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D" class="latex" title="D" /> to be the collection of indicator functions for all sets of the form <img src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S\times T" class="latex" title="S\times T" /> for <img src="https://s0.wp.com/latex.php?latex=S%2CT%5Csubseteq+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S,T\subseteq G" class="latex" title="S,T\subseteq G" />. The weak regularity lemma shows how to decompose <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> into a linear combination of rectangles. These rectangles may overlap. However, we ideally want <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> to be a linear combination of <em>non-overlapping</em> rectangles. In other words, we want a <em>partition </em>of rectangles. It is possible to achieve this at the price of exponentiating the number of rectangles. Note that an exponential loss is necessary even if <img src="https://s0.wp.com/latex.php?latex=S%3DG&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S=G" class="latex" title="S=G" /> in every <img src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S\times T" class="latex" title="S\times T" /> rectangle; or in other words in the uni-dimensional setting. This is one step where the terminology “rectangle” may be misleading – the set <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> is not necessarily an interval. If it was, a polynomial rather than exponential blow-up would have sufficed to remove overlaps.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18001r14"></a> Claim 14. </span>Given a decomposition of <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> into rectangles from the weak regularity lemma with <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s" class="latex" title="s" /> functions, there exists a decomposition with <img src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{O(s)}" class="latex" title="2^{O(s)}" /> rectangles which don’t overlap.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Exercise. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">In the above decomposition, note that it is natural to take the coefficients of rectangles to be the density of points in <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> that are in the rectangle. This gives rise to the following claim.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-18002r15"></a> Claim 15. </span>The weights of the rectangles in the above claim can be the average of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> in the rectangle, at the cost of doubling the error.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">Consequently, we have that <img src="https://s0.wp.com/latex.php?latex=f%3Dg%2Bh&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f=g+h" class="latex" title="f=g+h" />, where <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> is the sum of <img src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{O(s)}" class="latex" title="2^{O(s)}" /> non-overlapping rectangles <img src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S\times T" class="latex" title="S\times T" /> with coefficients <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BP%7D+_%7B%28x%2Cy%29%5Cin+S%5Ctimes+T%7D%5Bf%28x%2Cy%29%3D1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]" class="latex" title="\mathbb{P} _{(x,y)\in S\times T}[f(x,y)=1]" />.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Let <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> be a partition decomposition with arbitrary weights. Let <img src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g'" class="latex" title="g'" /> be a partition decomposition with weights being the average of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" />. It is enough to show that for all rectangle distinguishers <img src="https://s0.wp.com/latex.php?latex=d%5Cin+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d\in D" class="latex" title="d\in D" /></p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}" class="latex" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|. \end{aligned}" /></div>
<p>By the triangle inequality, we have that</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C%2B%7C%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}" class="latex" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq |\mathbb {E}[(f-g)d]|+|\mathbb {E}[(g-g')d]|. \end{aligned}" /></div>
<p>To bound <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}[(g-g')d]|" class="latex" title="\mathbb {E}[(g-g')d]|" />, note that the error is maximized for a <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> that respects the decomposition in non-overlapping rectangles, i.e., <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" /> is the union of some non-overlapping rectangles from the decomposition. This can be argued using that, unlike <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" />, the value of <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> and <img src="https://s0.wp.com/latex.php?latex=g%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g'" class="latex" title="g'" /> on a rectangle <img src="https://s0.wp.com/latex.php?latex=S%5Ctimes+T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S\times T" class="latex" title="S\times T" /> from the decomposition is fixed. But, from the point of “view” of such <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />, <img src="https://s0.wp.com/latex.php?latex=g%27%3Df&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g'=f" class="latex" title="g'=f" />! More formally, <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5B%28g-g%27%29d%5D%3D%5Cmathbb+%7BE%7D%5B%28g-f%29d%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]" class="latex" title="\mathbb {E}[(g-g')d]=\mathbb {E}[(g-f)d]" />. This gives</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%7C%5Cmathbb+%7BE%7D%5B%28f-g%27%29d%5D%7C%5Cleq+2%7C%5Cmathbb+%7BE%7D%5B%28f-g%29d%5D%7C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}" class="latex" title="\begin{aligned} |\mathbb {E}[(f-g')d]|\leq 2|\mathbb {E}[(f-g)d]| \end{aligned}" /></div>
<p>and concludes the proof. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">We need to get still a little more from this decomposition. In our application of the weak regularity lemma above, we took the set of distinguishers to be characteristic functions of rectangles. That is, distinguishers that can be written as <img src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(x)\cdot V(y)" class="latex" title="U(x)\cdot V(y)" /> where <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> and <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> map <img src="https://s0.wp.com/latex.php?latex=G%5Cto+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G\to \{0,1\}" class="latex" title="G\to \{0,1\}" />. We will use that the same guarantee holds for <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> and <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> with range <img src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[-1,1]" class="latex" title="[-1,1]" />, up to a constant factor loss in the error. Indeed, let <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> and <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> have range <img src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[-1,1]" class="latex" title="[-1,1]" />. Write <img src="https://s0.wp.com/latex.php?latex=U%3DU_%7B%2B%7D-U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U=U_{+}-U_{-}" class="latex" title="U=U_{+}-U_{-}" /> where <img src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{+}" class="latex" title="U_{+}" /> and <img src="https://s0.wp.com/latex.php?latex=U_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{-}" class="latex" title="U_{-}" /> have range <img src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[0,1]" class="latex" title="[0,1]" />, and the same for <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" />. The error for distinguisher <img src="https://s0.wp.com/latex.php?latex=U%5Ccdot+V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U\cdot V" class="latex" title="U\cdot V" /> is at most the sum of the errors for distinguishers <img src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{+}\cdot V_{+}" class="latex" title="U_{+}\cdot V_{+}" />, <img src="https://s0.wp.com/latex.php?latex=U_%7B%2B%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{+}\cdot V_{-}" class="latex" title="U_{+}\cdot V_{-}" />, <img src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B%2B%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{-}\cdot V_{+}" class="latex" title="U_{-}\cdot V_{+}" />, and <img src="https://s0.wp.com/latex.php?latex=U_%7B-%7D%5Ccdot+V_%7B-%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{-}\cdot V_{-}" class="latex" title="U_{-}\cdot V_{-}" />. So we can restrict our attention to distinguishers <img src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(x)\cdot V(y)" class="latex" title="U(x)\cdot V(y)" /> where <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> and <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> have range <img src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[0,1]" class="latex" title="[0,1]" />. In turn, a function <img src="https://s0.wp.com/latex.php?latex=U%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(x)" class="latex" title="U(x)" /> with range <img src="https://s0.wp.com/latex.php?latex=%5B0%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[0,1]" class="latex" title="[0,1]" /> can be written as an expectation <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{E} _{a}U_{a}(x)" class="latex" title="\mathbb{E} _{a}U_{a}(x)" /> for functions <img src="https://s0.wp.com/latex.php?latex=U_%7Ba%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{a}" class="latex" title="U_{a}" /> with range <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{0,1\}" class="latex" title="\{0,1\}" />, and the same for <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" />. We conclude by observing that</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29%5Cmathbb%7BE%7D+_%7Ba%7DU_%7Ba%7D%28x%29%5Ccdot+%5Cmathbb%7BE%7D+_%7Bb%7DV_%7Bb%7D%28y%29%5D%5Cle+%5Cmax+_%7Ba%2Cb%7D%5Cmathbb%7BE%7D+_%7Bx%2Cy%7D%5B%28f-g%29%28x%2Cy%29U_%7Ba%7D%28x%29%5Ccdot+V_%7Bb%7D%28y%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}" class="latex" title="\begin{aligned} \mathbb{E} _{x,y}[(f-g)(x,y)\mathbb{E} _{a}U_{a}(x)\cdot \mathbb{E} _{b}V_{b}(y)]\le \max _{a,b}\mathbb{E} _{x,y}[(f-g)(x,y)U_{a}(x)\cdot V_{b}(y)]. \end{aligned}" /></div>
<h4 class="subsectionHead"><span class="titlemark">7.4 </span> <a id="x1-190007.4"></a>Proof</h4>
<p style="text-align: justify;">Let us now finish the proof by showing a corner exists for sufficiently dense sets <img src="https://s0.wp.com/latex.php?latex=A%5Csubseteq+G%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A\subseteq G^{2}" class="latex" title="A\subseteq G^{2}" />. We’ll use three types of decompositions for <img src="https://s0.wp.com/latex.php?latex=f%3AG%5E%7B2%7D%5Crightarrow+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:G^{2}\rightarrow \{0,1\}" class="latex" title="f:G^{2}\rightarrow \{0,1\}" />, with respect to the following three types of distinguishers, where <img src="https://s0.wp.com/latex.php?latex=U_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{i}" class="latex" title="U_{i}" /> and <img src="https://s0.wp.com/latex.php?latex=V_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V_{i}" class="latex" title="V_{i}" /> have range <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{0,1\}" class="latex" title="\{0,1\}" />:</p>
<ol class="enumerate1">
<li class="enumerate" id="x1-19002x1"><img src="https://s0.wp.com/latex.php?latex=U_%7B1%7D%28x%29%5Ccdot+V_%7B1%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{1}(x)\cdot V_{1}(y)" class="latex" title="U_{1}(x)\cdot V_{1}(y)" />,</li>
<li class="enumerate" id="x1-19004x2"><img src="https://s0.wp.com/latex.php?latex=U_%7B2%7D%28xy%29%5Ccdot+V_%7B2%7D%28y%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{2}(xy)\cdot V_{2}(y)" class="latex" title="U_{2}(xy)\cdot V_{2}(y)" />,</li>
<li class="enumerate" id="x1-19006x3"><img src="https://s0.wp.com/latex.php?latex=U_%7B3%7D%28x%29%5Ccdot+V_%7B3%7D%28xy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{3}(x)\cdot V_{3}(xy)" class="latex" title="U_{3}(x)\cdot V_{3}(xy)" />.</li>
</ol>
<p style="text-align: justify;">The first type is just rectangles, what we have been discussing until now. The distinguishers in the last two classes can be visualized over <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BR%7D%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {R}^{2}" class="latex" title="\mathbb {R}^{2}" /> as parallelograms with a 45-degree angle. The same extra properties we discussed for rectangles can be verified hold for them too.</p>
<p style="text-align: justify;">Recall that we want to show</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%3E%5Cfrac+%7B1%7D%7B%7CG%7C%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]&gt;\frac {1}{|G|}. \end{aligned}" /></div>
<p>We’ll decompose the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />-th occurrence of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> via the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />-th decomposition listed above. We’ll write this decomposition as <img src="https://s0.wp.com/latex.php?latex=f%3Dg_%7Bi%7D%2Bh_%7Bi%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f=g_{i}+h_{i}" class="latex" title="f=g_{i}+h_{i}" />. We apply this in a certain order to produce sums of products of three functions. The inputs to the functions don’t change, so to avoid clutter we do not write them, and it is understood that in each product of three functions the inputs are, in order <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29%2C%28xg%2Cy%29%2C%28x%2Cgy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y),(xg,y),(x,gy)" class="latex" title="(x,y),(xg,y),(x,gy)" />. The decomposition is:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+fff%5C%5C+%3D+%26+ffg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+fg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D%5C%5C+%3D+%26+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bh_%7B1%7Dg_%7B2%7Dg_%7B3%7D%2Bfh_%7B2%7Dg_%7B3%7D%2Bffh_%7B3%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}" class="latex" title="\begin{aligned} &amp; fff\\ = &amp; ffg_{3}+ffh_{3}\\ = &amp; fg_{2}g_{3}+fh_{2}g_{3}+ffh_{3}\\ = &amp; g_{1}g_{2}g_{3}+h_{1}g_{2}g_{3}+fh_{2}g_{3}+ffh_{3}. \end{aligned}" /></div>
<p style="text-align: justify;">We first show that the expectation of the first term is big. This takes the next two claims. Then we show that the expectations of the other terms are small.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19007r16"></a> Claim 16. </span>For all <img src="https://s0.wp.com/latex.php?latex=g%5Cin+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g\in G" class="latex" title="g\in G" />, the expectations <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28xg%2Cy%29g_%7B3%7D%28x%2Cgy%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]" class="latex" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(xg,y)g_{3}(x,gy)]" /> are the same up to an error of <img src="https://s0.wp.com/latex.php?latex=2%5E%7BO%28s%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{O(s)}/|G|^{\Omega (1)}" class="latex" title="2^{O(s)}/|G|^{\Omega (1)}" />.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We just need to get error <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7B%5COmega+%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|^{\Omega (1)}" class="latex" title="1/|G|^{\Omega (1)}" /> for any product of three functions for the three decomposition types. We have:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bc_%7B1%7DU_%7B1%7D%28x%29V_%7B1%7D%28y%29%5Ccdot+c_%7B2%7DU_%7B2%7D%28xgy%29V_%7B2%7D%28y%29%5Ccdot+c_%7B3%7DU_%7B3%7D%28x%29V_%7B3%7D%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28xgy%29%5D%5C%5C+%3D+%26+c_%7B1%7Dc_%7B2%7Dc_%7B3%7D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D%5Ccdot+%5Cmathbb+%7BE%7D_%7Bz%7D%5B%28U_%7B2%7D%5Ccdot+V_%7B3%7D%29%28z%29%5D%5Cpm+%5Cfrac+%7B1%7D%7B%7CG%7C%5E%7B%5COmega+%281%29%7D%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}" class="latex" title="\begin{aligned} &amp; \mathbb {E}_{x,y}[c_{1}U_{1}(x)V_{1}(y)\cdot c_{2}U_{2}(xgy)V_{2}(y)\cdot c_{3}U_{3}(x)V_{3}(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\mathbb {E}_{x,y}[(U_{1}\cdot U_{3})(x)(V_{1}\cdot V_{2})(y)(U_{2}\cdot V_{3})(xgy)]\\ = &amp; c_{1}c_{2}c_{3}\cdot \mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]\cdot \mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]\cdot \mathbb {E}_{z}[(U_{2}\cdot V_{3})(z)]\pm \frac {1}{|G|^{\Omega (1)}}. \end{aligned}" /></div>
<p style="text-align: justify;">This is similar to what we discussed in the overview, and is where we use mixing. Specifically, if <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%7D%5B%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]" class="latex" title="\mathbb {E}_{x}[(U_{1}\cdot U_{3})(x)]" /> or <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7By%7D%5B%28V_%7B1%7D%5Ccdot+V_%7B2%7D%29%28y%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]" class="latex" title="\mathbb {E}_{y}[(V_{1}\cdot V_{2})(y)]" /> are at most <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|^{c}" class="latex" title="1/|G|^{c}" /> for a small enough constant <img src="https://s0.wp.com/latex.php?latex=c&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c" class="latex" title="c" /> than we are done. Otherwise, conditioned on <img src="https://s0.wp.com/latex.php?latex=%28U_%7B1%7D%5Ccdot+U_%7B3%7D%29%28x%29%3D1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(U_{1}\cdot U_{3})(x)=1" class="latex" title="(U_{1}\cdot U_{3})(x)=1" />, the distribution on <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" /> is uniform over a set of density <img src="https://s0.wp.com/latex.php?latex=1%2F%7CG%7C%5E%7Bc%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/|G|^{c}" class="latex" title="1/|G|^{c}" />, and the same holds for <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y" class="latex" title="y" />, and the result follows by Lemma <a href="https://emanueleviola.wordpress.com/feed/#x1-12001r7">7</a>. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">Recall that we start with a set of density <img src="https://s0.wp.com/latex.php?latex=%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ge 1/\log ^{a}|G|" class="latex" title="\ge 1/\log ^{a}|G|" />.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19008r17"></a> Claim 17. </span><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Bg_%7B1%7D%28x%2Cy%29g_%7B2%7D%28x%2Cy%29g_%7B3%7D%28x%2Cy%29%5D%3E1%2F%5Clog+%5E%7B4a%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|" class="latex" title="\mathbb {E}_{x,y}[g_{1}(x,y)g_{2}(x,y)g_{3}(x,y)]&gt;1/\log ^{4a}|G|" />.</p>
<p style="text-align: justify;">
</p></div>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>We will relate the expectation over <img src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y" class="latex" title="x,y" /> to <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> using the Hölder inequality: For random variables <img src="https://s0.wp.com/latex.php?latex=X_%7B1%7D%2CX_%7B2%7D%2C%5Cldots+%2CX_%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_{1},X_{2},\ldots ,X_{k}" class="latex" title="X_{1},X_{2},\ldots ,X_{k}" />,</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5BX_%7B1%7D%5Cdots+X_%7Bk%7D%5D%5Cleq+%5Cprod+_%7Bi%3D1%7D%5E%7Bk%7D%5Cmathbb+%7BE%7D%5BX_%7Bi%7D%5E%7Bc_%7Bi%7D%7D%5D%5E%7B1%2Fc_%7Bi%7D%7D%5Ctext+%7B+such+that+%7D%5Csum+1%2Fc_%7Bi%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}[X_{1}\dots X_{k}]\leq \prod _{i=1}^{k}\mathbb {E}[X_{i}^{c_{i}}]^{1/c_{i}}\text { such that }\sum 1/c_{i}=1. \end{aligned}" /></div>
<p style="text-align: justify;">To apply this inequality in our setting, write</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+f%3D%28f%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%29%5E%7B1%2F4%7D%5Ccdot+%5Cleft+%28%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%29%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}" class="latex" title="\begin{aligned} f=(f\cdot g_{1}g_{2}g_{3})^{1/4}\cdot \left (\frac {f}{g_{1}}\right )^{1/4}\cdot \left (\frac {f}{g_{2}}\right )^{1/4}\cdot \left (\frac {f}{g_{3}}\right )^{1/4}. \end{aligned}" /></div>
<p>By the Hölder inequality the expectation of the right-hand side is</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B1%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B2%7D%7D%5Cright+%5D%5E%7B1%2F4%7D%5Cmathbb+%7BE%7D%5Cleft+%5B%5Cfrac+%7Bf%7D%7Bg_%7B3%7D%7D%5Cright+%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}" class="latex" title="\begin{aligned} \leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\mathbb {E}\left [\frac {f}{g_{1}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{2}}\right ]^{1/4}\mathbb {E}\left [\frac {f}{g_{3}}\right ]^{1/4}. \end{aligned}" /></div>
<p>The last three terms equal to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> because</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7Bg_%7Bi%7D%28x%2Cy%29%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7Bf%28x%2Cy%29%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5Cfrac+%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%7B%5Cmathbb+%7BE%7D_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7D%5Bf%28x%27%2Cy%27%29%5D%7D%3D1.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}_{x,y}\frac {f(x,y)}{g_{i}(x,y)} &amp; =\mathbb {E}_{x,y}\frac {f(x,y)}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=\mathbb {E}_{x,y}\frac {\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}{\mathbb {E}_{x',y'\in \textit {Cell}(x,y)}[f(x',y')]}=1. \end{aligned}" /></div>
<p>where <img src="https://s0.wp.com/latex.php?latex=%5Ctextit+%7BCell%7D%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\textit {Cell}(x,y)" class="latex" title="\textit {Cell}(x,y)" /> is the set in the partition that contains <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)" class="latex" title="(x,y)" />. Putting the above together we obtain</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bf%5D%5Cleq+%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}[f]\leq \mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}. \end{aligned}" /></div>
<p>Finally, because the functions are positive, we have that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bf%5Ccdot+g_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D%5Cleq+%5Cmathbb+%7BE%7D%5Bg_%7B1%7Dg_%7B2%7Dg_%7B3%7D%5D%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}" class="latex" title="\mathbb {E}[f\cdot g_{1}g_{2}g_{3}]^{1/4}\leq \mathbb {E}[g_{1}g_{2}g_{3}]^{1/4}" />. This concludes the proof. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">It remains to show the other terms are small. Let <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " /> be the error in the weak regularity lemma with respect to distinguishers with range <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{0,1\} " class="latex" title="\{0,1\} " />. Recall that this implies error <img src="https://s0.wp.com/latex.php?latex=O%28%5Cepsilon+%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\epsilon )" class="latex" title="O(\epsilon )" /> with respect to distinguishers with range <img src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[-1,1]" class="latex" title="[-1,1]" />. We give the proof for one of the terms and then we say little about the other two.</p>
<div class="newtheorem">
<p style="text-align: justify;"><span class="head"> <a id="x1-19009r18"></a> Claim 18. </span><img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb+%7BE%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%7C%5Cleq+O%28%5Cepsilon+%29%5E%7B1%2F4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}" class="latex" title="|\mathbb {E}[f(x,y)f(xg,y)h_{3}(x,gy)]|\leq O(\epsilon )^{1/4}" />.</p>
<p style="text-align: justify;">
</p></div>
<p style="text-align: justify;">The proof involves changing names of variables and doing Cauchy-Schwarz to remove the terms with <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> and bound the expectation above by <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]" class="latex" title="\mathbb {E}[h_{3}(x,g)U(x)V(xg)]" />, which is small by the regularity lemma.</p>
<div class="proof">
<p style="text-align: justify;"><span class="head"> Proof. </span>Replace <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" /> with <img src="https://s0.wp.com/latex.php?latex=gy%5E%7B-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="gy^{-1}" class="latex" title="gy^{-1}" /> in the uniform distribution to get</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29h_%7B3%7D%28x%2Cgy%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5E%7B4%7D%5Bf%28x%2Cy%29f%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B4%7D%5Bf%28x%2Cy%29%5Cmathbb+%7BE%7D_%7Bg%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Bf%5E%7B2%7D%28x%2Cy%29%5D%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cy%7D%5E%7B2%7D%5Cmathbb+%7BE%7D_%7Bg%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28xgy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%29f%28xg%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cg%27%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}" class="latex" title="\begin{aligned} &amp; \mathbb {E}_{x,y,g}^{4}[f(x,y)f(xg,y)h_{3}(x,gy)]\\ &amp; =\mathbb {E}_{x,y,g}^{4}[f(x,y)f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y}^{4}[f(x,y)\mathbb {E}_{g}[f(xgy^{-1},y)h_{3}(x,g)]]\\ &amp; \leq \mathbb {E}_{x,y}^{2}[f^{2}(x,y)]\mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; \leq \mathbb {E}_{x,y}^{2}\mathbb {E}_{g}^{2}[f(xgy^{-1},y)h_{3}(x,g)]\\ &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(xgy^{-1},y)h_{3}(x,g)f(xg'y^{-1},y)h_{3}(x,g')], \end{aligned}" /></div>
<p>where the first inequality is by Cauchy-Schwarz.</p>
<p style="text-align: justify;">Now replace <img src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+x%5E%7B-1%7Dg%2Cg%27%5Crightarrow+x%5E%7B-1%7Dg&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g" class="latex" title="g\rightarrow x^{-1}g,g'\rightarrow x^{-1}g" /> and reason in the same way:</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%26+%3D%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%2Cg%27%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29f%28g%27y%5E%7B-1%7D%2Cy%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5C%5C+%26+%3D%5Cmathbb+%7BE%7D_%7Bg%2Cg%27%2Cy%7D%5E%7B2%7D%5Bf%28gy%5E%7B-1%7D%2Cy%29%5Ccdot+f%28g%27y%5E%7B-1%7D%2Cy%29%5Cmathbb+%7BE%7D_%7Bx%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29%5Ccdot+h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29%5D%5D%5C%5C+%26+%5Cleq+%5Cmathbb+%7BE%7D_%7Bx%2Cx%27%2Cg%2Cg%27%7D%5Bh_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" title="\begin{aligned} &amp; =\mathbb {E}_{x,y,g,g'}^{2}[f(gy^{-1},y)h_{3}(x,x^{-1}g)f(g'y^{-1},y)h_{3}(x,x^{-1}g')]\\ &amp; =\mathbb {E}_{g,g',y}^{2}[f(gy^{-1},y)\cdot f(g'y^{-1},y)\mathbb {E}_{x}[h_{3}(x,x^{-1}g)\cdot h_{3}(x,x^{-1}g')]]\\ &amp; \leq \mathbb {E}_{x,x',g,g'}[h_{3}(x,x^{-1}g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}g)h_{3}(x',x'^{-1}g')]. \end{aligned}" /></div>
<p style="text-align: justify;">Replace <img src="https://s0.wp.com/latex.php?latex=g%5Crightarrow+xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g\rightarrow xg" class="latex" title="g\rightarrow xg" /> to rewrite the expectation as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29h_%7B3%7D%28x%2Cx%5E%7B-1%7Dg%27%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dxg%29h_%7B3%7D%28x%27%2Cx%27%5E%7B-1%7Dg%27%29%5D.+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)h_{3}(x,x^{-1}g')h_{3}(x',x'^{-1}xg)h_{3}(x',x'^{-1}g')]. \end{aligned}" /></div>
<p style="text-align: justify;">We want to view the last three terms as a distinguisher <img src="https://s0.wp.com/latex.php?latex=U%28x%29%5Ccdot+V%28xg%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(x)\cdot V(xg)" class="latex" title="U(x)\cdot V(xg)" />. First, note that <img src="https://s0.wp.com/latex.php?latex=h_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{3}" class="latex" title="h_{3}" /> has range <img src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[-1,1]" class="latex" title="[-1,1]" />. This is because <img src="https://s0.wp.com/latex.php?latex=h_%7B3%7D%28x%2Cy%29%3Df%28x%2Cy%29-%5Cmathbb%7BE%7D+_%7Bx%27%2Cy%27%5Cin+%5Ctextit+%7BCell%7D%28x%2Cy%29%7Df%28x%27%2Cy%27%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')" class="latex" title="h_{3}(x,y)=f(x,y)-\mathbb{E} _{x',y'\in \textit {Cell}(x,y)}f(x',y')" /> and <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> has range <img src="https://s0.wp.com/latex.php?latex=%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{0,1\}" class="latex" title="\{0,1\}" />, where recall that <img src="https://s0.wp.com/latex.php?latex=Cell%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Cell(x,y)" class="latex" title="Cell(x,y)" /> is the set in the partition that contains <img src="https://s0.wp.com/latex.php?latex=%28x%2Cy%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(x,y)" class="latex" title="(x,y)" />. Fix <img src="https://s0.wp.com/latex.php?latex=x%27%2Cg%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x',g'" class="latex" title="x',g'" />. The last term in the expectation becomes a constant <img src="https://s0.wp.com/latex.php?latex=c%5Cin+%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c\in [-1,1]" class="latex" title="c\in [-1,1]" />. The second term only depends on <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />, and the third only on <img src="https://s0.wp.com/latex.php?latex=xg&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="xg" class="latex" title="xg" />. Hence for appropriate functions <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> and <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> with range <img src="https://s0.wp.com/latex.php?latex=%5B-1%2C1%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[-1,1]" class="latex" title="[-1,1]" /> this expectation can be rewritten as</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D%5Bh_%7B3%7D%28x%2Cg%29U%28x%29V%28xg%29%5D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}[h_{3}(x,g)U(x)V(xg)], \end{aligned}" /></div>
<p>which concludes the proof. <img src="https://s0.wp.com/latex.php?latex=%5Csquare+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\square " class="latex" title="\square " /></p>
</div>
<p style="text-align: justify;">There are similar proofs to show the remaining terms are small. For <img src="https://s0.wp.com/latex.php?latex=fh_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="fh_{2}g_{3}" class="latex" title="fh_{2}g_{3}" />, we can perform simple manipulations and then reduce to the above case. For <img src="https://s0.wp.com/latex.php?latex=h_%7B1%7Dg_%7B2%7Dg_%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_{1}g_{2}g_{3}" class="latex" title="h_{1}g_{2}g_{3}" />, we have a slightly easier proof than above.</p>
<h5 class="subsubsectionHead"><span class="titlemark">7.4.1 </span> <a id="x1-200007.4.1"></a>Parameters</h5>
<p style="text-align: justify;">Suppose our set has density <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cge+1%2F%5Clog+%5E%7Ba%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta \ge 1/\log ^{a}|G|" class="latex" title="\delta \ge 1/\log ^{a}|G|" />, and the error in the regularity lemma is <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon " class="latex" title="\epsilon " />. By the above results we can bound</p>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Baligned%7D+%5Cmathbb+%7BE%7D_%7Bx%2Cy%2Cg%7D%5Bf%28x%2Cy%29f%28xg%2Cy%29f%28x%2Cgy%29%5D%5Cge+1%2F%5Clog+%5E%7B4a%7D%7CG%7C-2%5E%7BO%281%2F%5Cepsilon+%5E%7B2%7D%29%7D%2F%7CG%7C%5E%7B%5COmega+%281%29%7D-%5Cepsilon+%5E%7B%5COmega+%281%29%7D%2C+%5Cend%7Baligned%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}" class="latex" title="\begin{aligned} \mathbb {E}_{x,y,g}[f(x,y)f(xg,y)f(x,gy)]\ge 1/\log ^{4a}|G|-2^{O(1/\epsilon ^{2})}/|G|^{\Omega (1)}-\epsilon ^{\Omega (1)}, \end{aligned}" /></div>
<p>where the terms in the right-hand size come, left-to-right from Claim <a href="https://emanueleviola.wordpress.com/feed/#x1-19008r17">17</a>, <a href="https://emanueleviola.wordpress.com/feed/#x1-19007r16">16</a>, and <a href="https://emanueleviola.wordpress.com/feed/#x1-19009r18">18</a>. Picking <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D1%2F%5Clog+%5E%7B1%2F3%7D%7CG%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon =1/\log ^{1/3}|G|" class="latex" title="\epsilon =1/\log ^{1/3}|G|" /> the proof is completed for sufficiently small <img src="https://s0.wp.com/latex.php?latex=a&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a" class="latex" title="a" />.</p>
<h3 class="likesectionHead"><a id="x1-210007.4.1"></a>References</h3>
<div class="thebibliography">
<p class="bibitem"><span class="biblabel"> [AL00] <span class="bibsp">   </span></span><a id="XAmbainisL00"></a>Andris Ambainis and Satyanarayana V. Lokam. Imroved upper bounds on the simultaneous messages complexity of the generalized addressing function. In Latin American Symposium on Theoretical Informatics (LATIN), pages 207–216, 2000.</p>
<p class="bibitem"><span class="biblabel"> [Amb96] <span class="bibsp">   </span></span><a id="XAmbainis96"></a>Andris Ambainis. Upper bounds on multiparty communication complexity of shifts. In Symp. on Theoretical Aspects of Computer Science (STACS), pages 631–642, 1996.</p>
<p class="bibitem"><span class="biblabel"> [AMS99] <span class="bibsp">   </span></span><a id="XAMS99"></a>Noga Alon, Yossi Matias, and Mario Szegedy. The space complexity of approximating the frequency moments. J. of Computer and System Sciences, 58(1, part 2):137–147, 1999.</p>
<p class="bibitem"><span class="biblabel"> [Aus16] <span class="bibsp">   </span></span><a id="XAustin2016"></a>Tim Austin. Ajtai-Szemerédi theorems over quasirandom groups. In Recent trends in combinatorics, volume 159 of IMA Vol. Math. Appl., pages 453–484. Springer, [Cham], 2016.</p>
<p class="bibitem"><span class="biblabel"> [Bar89] <span class="bibsp">   </span></span><a id="XBarrington89"></a>David A. Mix Barrington. Bounded-width polynomial-size branching programs recognize exactly those languages in NC<img src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="^1" class="latex" title="^1" />. J. of Computer and System Sciences, 38(1):150–164, 1989.</p>
<p class="bibitem"><span class="biblabel"> [BC92] <span class="bibsp">   </span></span><a id="XBen-OrC92"></a>Michael Ben-Or and Richard Cleve. Computing algebraic formulas using a constant number of registers. SIAM J. on Computing, 21(1):54–58, 1992.</p>
<p class="bibitem"><span class="biblabel"> [BDPW10]<span class="bibsp">   </span></span><a id="XBeameDPW10"></a>Paul Beame, Matei David, Toniann Pitassi, and Philipp Woelfel. Separating deterministic from randomized multiparty communication complexity. Theory of Computing, 6(1):201–225, 2010.</p>
<p class="bibitem"><span class="biblabel"> [BGKL03] <span class="bibsp">   </span></span><a id="XBGKL03"></a>László Babai, Anna Gál, Peter G. Kimmel, and Satyanarayana V. Lokam. Communication complexity of simultaneous messages. SIAM J. on Computing, 33(1):137–166, 2003.</p>
<p class="bibitem"><span class="biblabel"> [BNP08] <span class="bibsp">   </span></span><a id="XBabaiNP08"></a>László Babai, Nikolay Nikolov, and László Pyber. Product growth and mixing in finite groups. In ACM-SIAM Symp. on Discrete Algorithms (SODA), pages 248–257, 2008.</p>
<p class="bibitem"><span class="biblabel"> [CFL83] <span class="bibsp">   </span></span><a id="XCFL83"></a>Ashok K. Chandra, Merrick L. Furst, and Richard J. Lipton. Multi-party protocols. In 15th ACM Symp. on the Theory of Computing (STOC), pages 94–99, 1983.</p>
<p class="bibitem"><span class="biblabel"> [CP10] <span class="bibsp">   </span></span><a id="XDBLP:journals/sigact/ChattopadhyayP10"></a>Arkadev Chattopadhyay and Toniann Pitassi. The story of set disjointness. SIGACT News, 41(3):59–85, 2010.</p>
<p class="bibitem"><span class="biblabel"> [DHKP97] <span class="bibsp">   </span></span><a id="XDietzfelbingerHKP97"></a>Martin Dietzfelbinger, Torben Hagerup, Jyrki Katajainen, and Martti Penttonen. A reliable randomized algorithm for the closest-pair problem. J. Algorithms, 25(1):19–51, 1997.</p>
<p class="bibitem"><span class="biblabel"> [FK96] <span class="bibsp">   </span></span><a id="XDBLP:conf/focs/FriezeK96"></a>Alan M. Frieze and Ravi Kannan. The regularity lemma and approximation schemes for dense problems. In IEEE Symp. on Foundations of Computer Science (FOCS), pages 12–20, 1996.</p>
<p class="bibitem"><span class="biblabel"> [Gow08] <span class="bibsp">   </span></span><a id="XGowers08"></a>W. T. Gowers. Quasirandom groups. Combinatorics, Probability &amp; Computing, 17(3):363–387, 2008.</p>
<p class="bibitem"><span class="biblabel"> [Gre05a] <span class="bibsp">   </span></span><a id="XGreen-supplement"></a>Ben Green. An argument of Shkredov in the finite field setting, 2005. Available at people.maths.ox.ac.uk/greenbj/papers/corners.pdf.</p>
<p class="bibitem"><span class="biblabel"> [Gre05b] <span class="bibsp">   </span></span><a id="XGre04-finite"></a>Ben Green. Finite field models in additive combinatorics. Surveys in Combinatorics, London Math. Soc. Lecture Notes 327, 1-27, 2005.</p>
<p class="bibitem"><span class="biblabel"> [GVa] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-journal"></a>W. T. Gowers and Emanuele Viola. Interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GVb] <span class="bibsp">   </span></span><a id="XGowersV-cc-int-2"></a>W. T. Gowers and Emanuele Viola. The multiparty communication complexity of interleaved group products. SIAM J. on Computing.</p>
<p class="bibitem"><span class="biblabel"> [GV15] <span class="bibsp">   </span></span><a id="XGowersV-cc-int"></a>W. T. Gowers and Emanuele Viola. The communication complexity of interleaved group products. In ACM Symp. on the Theory of Computing (STOC), 2015.</p>
<p class="bibitem"><span class="biblabel"> [IL95] <span class="bibsp">   </span></span><a id="XImmermanL95"></a>Neil Immerman and Susan Landau. The complexity of iterated multiplication. Inf. Comput., 116(1):103–116, 1995.</p>
<p class="bibitem"><span class="biblabel"> [KMR66] <span class="bibsp">   </span></span><a id="XKrohnMR66"></a>Kenneth Krohn, W. D. Maurer, and John Rhodes. Realizing complex Boolean functions with simple groups. Information and Control, 9:190–195, 1966.</p>
<p class="bibitem"><span class="biblabel"> [KN97] <span class="bibsp">   </span></span><a id="XKuN97"></a>Eyal Kushilevitz and Noam Nisan. Communication complexity. Cambridge University Press, 1997.</p>
<p class="bibitem"><span class="biblabel"> [KS92] <span class="bibsp">   </span></span><a id="XKalyanasundaramS92"></a>Bala Kalyanasundaram and Georg Schnitger. The probabilistic communication complexity of set intersection. SIAM J. Discrete Math., 5(4):545–557, 1992.</p>
<p class="bibitem"><span class="biblabel"> [LM07] <span class="bibsp">   </span></span><a id="XMR2289954"></a>Michael T. Lacey and William McClain. On an argument of Shkredov on two-dimensional corners. Online J. Anal. Comb., (2):Art. 2, 21, 2007.</p>
<p class="bibitem"><span class="biblabel"> [LW54] <span class="bibsp">   </span></span><a id="XLangWeil54"></a>Serge Lang and André Weil. Number of points of varieties in finite fields. American Journal of Mathematics, 76:819–827, 1954.</p>
<p class="bibitem"><span class="biblabel"> [Mil14] <span class="bibsp">   </span></span><a id="XMiles14"></a>Eric Miles. Iterated group products and leakage resilience against <img src="https://s0.wp.com/latex.php?latex=NC%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="NC^1" class="latex" title="NC^1" />. In ACM Innovations in Theoretical Computer Science conf. (ITCS), 2014.</p>
<p class="bibitem"><span class="biblabel"> [MV13] <span class="bibsp">   </span></span><a id="XMilesV-leak"></a>Eric Miles and Emanuele Viola. Shielding circuits with groups. In ACM Symp. on the Theory of Computing (STOC), 2013.</p>
<p class="bibitem"><span class="biblabel"> [PRS97] <span class="bibsp">   </span></span><a id="XPRS97"></a>Pavel Pudlák, Vojtěch Rödl, and Jiří Sgall. Boolean circuits, tensor ranks, and communication complexity. SIAM J. on Computing, 26(3):605–633, 1997.</p>
<p class="bibitem"><span class="biblabel"> [Raz92] <span class="bibsp">   </span></span><a id="XRazborov92"></a>Alexander A. Razborov. On the distributional complexity of disjointness. Theor. Comput. Sci., 106(2):385–390, 1992.</p>
<p class="bibitem"><span class="biblabel"> [Raz00] <span class="bibsp">   </span></span><a id="XRaz00"></a>Ran Raz. The BNS-Chung criterion for multi-party communication complexity. Computational Complexity, 9(2):113–122, 2000.</p>
<p class="bibitem"><span class="biblabel"> [RY19] <span class="bibsp">   </span></span><a id="XRaoY2019"></a>Anup Rao and Amir Yehudayoff. Communication complexity. 2019. <a href="https://homes.cs.washington.edu/ anuprao/pubs/book.pdf" rel="nofollow">https://homes.cs.washington.edu/ anuprao/pubs/book.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Sha16] <span class="bibsp">   </span></span><a id="XShalev16"></a>Aner Shalev. Mixing, communication complexity and conjectures of Gowers and Viola. Combinatorics, Probability and Computing, pages 1–13, 6 2016. arXiv:1601.00795.</p>
<p class="bibitem"><span class="biblabel"> [She14] <span class="bibsp">   </span></span><a id="XSherstov14-35years"></a>Alexander A. Sherstov. Communication complexity theory: Thirty-five years of set disjointness. In Symp. on Math. Foundations of Computer Science (MFCS), pages 24–43, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Tao17] <span class="bibsp">   </span></span><a id="XTao2017-szemerediproof"></a>Terence Tao. Szemerédiâs proof of Szemerédiâs theorem, 2017. <a href="https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf" rel="nofollow">https://terrytao.files.wordpress.com/2017/09/szemeredi-proof1.pdf</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vioa] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups"></a>Emanuele Viola. Thoughts: Mixing in groups. <a href="https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/" rel="nofollow">https://emanueleviola.wordpress.com/2016/10/21/mixing-in-groups/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Viob] <span class="bibsp">   </span></span><a id="Xviola-blog-mixing-in-groups-ii"></a>Emanuele Viola. Thoughts: Mixing in groups ii. <a href="https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/" rel="nofollow">https://emanueleviola.wordpress.com/2016/11/15/mixing-in-groups-ii/</a>.</p>
<p class="bibitem"><span class="biblabel"> [Vio14] <span class="bibsp">   </span></span><a id="XViola-ccsum"></a>Emanuele Viola. The communication complexity of addition. Combinatorica, pages 1–45, 2014.</p>
<p class="bibitem"><span class="biblabel"> [Vio17] <span class="bibsp">   </span></span><a id="Xviola-special-topics17"></a>Emanuele Viola. Special topics in complexity theory. Lecture notes of the class taught at Northeastern University. Available at <a href="http://www.ccs.neu.edu/home/viola/classes/spepf17.html" rel="nofollow">http://www.ccs.neu.edu/home/viola/classes/spepf17.html</a>, 2017.</p>
<p class="bibitem"><span class="biblabel"> [Yao79] <span class="bibsp">   </span></span><a id="XYao79"></a>Andrew Chi-Chih Yao. Some complexity questions related to distributive computing. In 11th ACM Symp. on the Theory of Computing (STOC), pages 209–213, 1979.</p>
</div>
<p> </p>
<p> </p></div>







<p class="date">
by Emanuele <a href="https://emanueleviola.wordpress.com/2019/07/10/non-abelian-combinatorics-and-communication-complexity/"><span class="datestr">at July 10, 2019 05:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2019/07/10/trajectories-linear-nets/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2019/07/10/trajectories-linear-nets/">Understanding implicit regularization in deep learning by analyzing trajectories of gradient descent</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Sanjeev’s <a href="http://www.offconvex.org/2019/06/03/trajectories/">recent blog post</a> suggested that the conventional view of optimization is insufficient for understanding deep learning, as the value of the training objective does not reliably capture generalization.
He argued that instead, we need to consider the <em>trajectories</em> of optimization.
One of the illustrative examples given was our <a href="https://arxiv.org/abs/1905.13655">new paper with Sanjeev Arora and Yuping Luo</a>, which studies the use of deep linear neural networks for solving <a href="https://en.wikipedia.org/wiki/Matrix_completion"><em>matrix completion</em></a> more accurately than the classic convex programming approach. 
The current post provides more details on this result.</p>

<p>Recall that in matrix completion we are given some entries $\{ M_{i, j} : (i, j) \in \Omega \}$ of an unknown <em>ground truth</em> matrix $M$, and our goal is to recover the remaining entries.
This can be thought of as a supervised learning (regression) problem, where the training examples are the observed entries of $M$, the model is a matrix $W$ trained with the loss:
[
L(W) = \sum\nolimits_{(i, j) \in \Omega} (W_{i, j} - M_{i, j})^2 ~,
]
and generalization corresponds to how similar $W$ is to $M$ in the unobserved locations.
Obviously the problem is ill-posed if we assume nothing about $M$ $-$ the loss $L(W)$ is underdetermined, i.e. has multiple optima, and it would be impossible to tell (without access to unobserved entries) if one solution is better than another.
The standard assumption (which has many <a href="https://en.wikipedia.org/wiki/Matrix_completion#Applications">practical applications</a>) is that the ground truth matrix $M$ is low-rank, and thus the goal is to find, from among all global minima of the loss $L(W)$, one with minimal rank. 
The classic algorithm for achieving this is to find the matrix with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms"><em>nuclear norm</em></a>. 
This is a convex program, which <em>given enough observed entries</em> (and under mild technical assumptions $-$ “incoherence”) recovers the ground truth exactly (cf. <a href="https://statweb.stanford.edu/~candes/papers/MatrixCompletion.pdf">Candes and Recht</a>). 
We’re interested in the regime where the number of revealed entries is too small for the classic algorithm to succeed.
There it can be beaten by a simple deep learning approach, as described next.</p>

<h2 id="linear-neural-networks-lnn">Linear Neural Networks (LNN)</h2>

<p>A linear neural network (LNN) is a fully-connected neural network with linear activation (i.e. no non-linearity).
If $W_j$ is the weight matrix in layer $j$ of a depth $N$ network, the <em>end-to-end matrix</em> is given by $W = W_N W_{N-1} \cdots W_1$.
Our method for solving matrix completion involves minimizing the loss $L(W)$ by running gradient descent (GD) on this (over-)parameterization, with depth $N \geq 2$ and hidden dimensions that do not constrain rank.
This can be viewed as a deep learning problem with $\ell_2$ loss, and GD can be implemented through the chain rule as usual.
Note that the training objective does not include any regularization term controlling the individual layer matrices $\{ W_j \}_j$.</p>

<p>At first glance our algorithm seems naive, since parameterization by an LNN (that does not constrain rank) is equivalent to parameterization by a single matrix $W$, and obviously running GD on $L(W)$ directly with no regularization is not a good approach (nothing will be learned in the unobserved locations).
However, since matrix completion is an underdetermined problem (has multiple optima), the optimum reached by GD can vary depending on the chosen parameterization.
Our setup isolates the role of over-parameterization in implicitly biasing GD towards certain optima (that hopefully generalize well).</p>

<p>Note that in the special case of depth $N = 2$ our method reduces to a traditional approach for matrix completion,  named <em>matrix factorization</em>. 
By analogy, we refer to the case $N \geq 3$ as <em>deep matrix factorization</em>. 
The table below shows reconstruction errors (generalization) on a matrix completion task where the number of observed entries is too small for nuclear norm minimization to succeed.
As can be seen, it is outperformed by matrix factorization, which itself is outperformed by deep matrix factorization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-reconst-errs.png" style="width: 700px;" />
<br />
<b>Table 1:</b> Results for matrix completion with small number of observations.
</div>
<p><br />
The main focus of our paper is on developing a theoretical understanding of this phenomenon.</p>

<h2 id="trajectory-analysis-implicit-regularization-towards-low-rank">Trajectory Analysis: Implicit Regularization Towards Low Rank</h2>

<p>We are interested in understanding what end-to-end matrix $W$ emerges when we run GD on an LNN to minimize a general convex loss $L(W)$, and in particular the matrix completion loss given above. 
Note that $L(W)$ is convex, but the objective obtained by over-parameterizing with an LNN is not.
We analyze the trajectories of $W$, and specifically the dynamics of its singular value decomposition.
Denote the singular values by $\{ \sigma_r \}_r$, and the corresponding left and right singular vectors by $\{ \mathbf{u}_r \}_r$ and $\{ \mathbf{v}_r \}_r$ respectively.</p>

<p>We start by considering GD applied to $L(W)$ directly (no over-parameterization).</p>

<blockquote>
  <p><strong>Known result:</strong>
Minimizing $L(W)$ directly by GD (with small learning rate $\eta$) leads the singular values of $W$ to evolve by:
[
\sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle ~.
\qquad (1)
]</p>
</blockquote>

<p>This statement implies that the movement of a singular value is proportional to the projection of the gradient onto the corresponding singular component.</p>

<p>Now suppose that we parameterize $W$ with an $N$-layer LNN, i.e. as $W = W_N W_{N-1} \cdots W_1$.
In previous work (described in <a href="http://www.offconvex.org/2018/03/02/acceleration-overparameterization/">Nadav’s earlier blog post</a>) we have shown that running GD on the LNN, with small learning rate $\eta$ and initialization close to the origin, leads the end-to-end matrix $W$ to evolve by:</p>



<p>In the new paper we rely on this result to prove the following:</p>

<blockquote>
  <p><strong>Theorem:</strong>
Minimizing $L(W)$ by running GD (with small learning rate $\eta$ and initialization close to the origin) on an $N$-layer LNN leads the singular values of $W$ to evolve by:
[ \sigma_r(t + 1) \leftarrow \sigma_r(t) - \eta \cdot \langle \nabla L(W(t)) , \mathbf{u}_r(t) \mathbf{v}_r^\top(t) \rangle \cdot \color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}} ~.
]</p>
</blockquote>

<p>Comparing this to Equation $(1)$, we see that over-parameterizing the loss $L(W)$ with an $N$-layer LNN introduces the multiplicative factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$ to the evolution of singular values.
While the constant $N$ does not change relative dynamics (can be absorbed into the learning rate $\eta$), the terms $(\sigma_r(t))^{2 - 2 / N}$ do $-$ they enhance movement of large singular values, and on the hand attenuate that of small ones.
Moreover, the enhancement/attenuation becomes more significant as $N$ (network depth) grows.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-thm-dynamics.png" style="width: 900px;" />
<br />
<b>Figure 1:</b> Over-parameterizing with LNN modifies dynamics of singular values.
</div>
<p><br /></p>

<p>The enhancement/attenuation effect induced by an LNN (factors $\color{purple}{N \cdot (\sigma_r(t))^{2 - 2 / N}}$) leads each singular value to progress very slowly after initialization, when close to zero, and then, upon reaching a certain threshold, move rapidly, with the transition from slow to rapid movement being sharper in case of a deeper network (larger $N$).
If the loss $L(W)$ is underdetermined (has multiple optima) these dynamics promote solutions that have a few large singular values and many small ones (that have yet to reach the phase transition between slow to rapid movement), with a gap that is more extreme the deeper the network is. 
This is an implicit regularization towards low rank, which intensifies with depth.
In the paper we support the intuition with empirical evaluations and theoretical illustrations, demonstrating how adding depth to an LNN can lead GD to produce solutions closer to low-rank.
For example, the following plots, corresponding to a task of matrix completion, show evolution of singular values throughout training of networks with varying depths $-$ as can be seen, adding layers indeed admits a final solution whose spectrum is closer to low-rank, thereby improving generalization.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/trajectories-linear-nets-exp-dynamics.png" style="width: 900px;" />
<br />
<b>Figure 2:</b> Dynamics of singular values in training matrix factorizations (LNN).
</div>

<h2 id="do-the-trajectories-minimize-some-regularized-objective">Do the Trajectories Minimize Some Regularized Objective?</h2>

<p>In recent years, researchers have come to realize the importance of implicit regularization induced by the choice of optimization algorithm.
The strong gravitational pull of the conventional view on optimization (see <a href="http://www.offconvex.org/2019/06/03/trajectories/">Sanjeev’s post</a>) has led most papers on this line to try and capture the effect in the language of regularized objectives. 
For example, it is known that over linear models, i.e. depth $1$ networks, GD finds the solution with minimal Frobenius norm (cf. Section 5 in <a href="https://openreview.net/pdf?id=Sy8gdB9xx">Zhang et al.</a>), and a common hypothesis is that this persists over more elaborate neural networks, with Frobenius norm potentially replaced by some other norm (or quasi-norm) that depends on network architecture.
<a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a> explicitly conjectured:</p>

<blockquote>
  <p><strong>Conjecture (by <a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al.</a>, informally stated):</strong>
GD (with small learning rate and near-zero initialization) training a matrix factorization finds a solution with minimum <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms">nuclear norm</a>.</p>
</blockquote>

<p>This conjecture essentially states that matrix factorization (i.e. $2$-layer LNN) trained by GD is equivalent to the famous method of nuclear norm minimization.
Gunasekar et al. motivated the conjecture with some empirical evidence, as well as mathematical evidence in the form of a proof for a (very) restricted setting.</p>

<p>Given the empirical observation by which adding depth to a matrix factorization can improve results in matrix completion, it would be natural to extend the conjecture of Gunasekar et al., and assert that the implicit regularization with depth $3$ or higher corresponds to minimizing some other norm (or quasi-norm) that approximates rank better than nuclear norm does.
For example, a natural candidate would be a <a href="https://en.wikipedia.org/wiki/Schatten_norm">Schatten-$p$ quasi-norm</a> with some $0 &lt; p &lt; 1$.</p>

<p>Our investigation began with this approach, but ultimately, we became skeptical of the entire “implicit regularization as norm minimization” line of reasoning, and in particular of the conjecture by Gunasekar et al.</p>

<blockquote>
  <p><strong>Theorem (mathematical evidence against the conjecture):</strong>
In the same restricted setting for which Gunasekar et al. proved their conjecture, nuclear norm is minimized by GD over matrix factorization not only with depth $2$, but with any depth $\geq 3$ as well.</p>
</blockquote>

<p>This theorem disqualifies Schatten quasi-norms as the implicit regularization in deep matrix factorizations, and instead suggests that all depths correspond to nuclear norm.
However, empirically we found a notable difference in performance between different depths, so the conceptual leap from a proof in the restricted setting to a general conjecture, as done by Gunasekar et al., seems questionable.</p>

<p>In the paper we conduct a systematic set of experiments to empirically evaluate the conjecture.
We find that in the regime where nuclear norm minimization is suboptimal (few observed entries), matrix factorizations consistently outperform it (see for example Table 1).
This holds in particular with depth $2$, in contrast to the conjecture’s prediction.
Together, our theory and experiments lead us to believe that it may not be possible to capture the implicit regularization in LNN with a single mathematical norm (or quasi-norm).</p>

<p>Full details behind our results on “implicit regularization as norm minimization” can be found in Section 2 of <a href="https://arxiv.org/abs/1905.13655">the paper</a>.
The trajectory analysis we discussed earlier appears in Section 3 there.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The <a href="http://www.offconvex.org/2019/06/03/trajectories/">conventional view of optimization</a> has been integral to the theory of machine learning. 
Our study suggests that the associated vocabulary may not suffice for understanding generalization in deep learning, and one should instead analyze trajectories of optimization, taking into account that speed of convergence does not necessarily correlate with generalization.
We hope this work will motivate development of a new vocabulary for analyzing deep learning.</p></div>







<p class="date">
<a href="http://offconvex.github.io/2019/07/10/trajectories-linear-nets/"><span class="datestr">at July 10, 2019 05:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blogs.princeton.edu/imabandit/?p=1382">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/bubeck.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/">Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part I</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p> </p>
<p><a href="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/kernel_fig.jpg?ssl=1" class="liimagelink"><img width="646" alt="" src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/kernel_fig.jpg?resize=646%2C368&amp;ssl=1" class="alignnone wp-image-1393" height="368" /></a></p>
<p> </p>
<p>I (<em>n.b., <a href="https://lear.inrialpes.fr/people/mairal/" class="liinternal">Julien Mairal</a></em>) have been interested in drawing links between neural networks and kernel methods for some time, and I am grateful to Sebastien for giving me the opportunity to say a few words about it on his blog. My initial motivation was not to provide another “why deep learning works” theory, but simply to encode into kernel methods a few successful principles from convolutional neural networks (CNNs), such as the ability to model the local stationarity of natural images at multiple scales—we may call that modeling receptive fields—along with feature compositions and invariant representations. There was also something challenging in trying to reconcile end-to-end deep neural networks and non-parametric methods based on kernels that typically decouple data representation from the learning task.</p>
<p>The main goal of this blog post is then to discuss the construction of a particular multilayer kernel for images that encodes the previous principles, derive some invariance and stability properties for CNNs, and also present a simple mechanism to perform feature learning in reproducing kernel Hilbert spaces. In other words, we should not see any intrinsic contradiction between kernels and representation learning.</p>
<p><strong>Preliminaries on kernel methods</strong></p>
<p>Given data living in a set <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="15" alt="\mathcal{X}" class="ql-img-inline-formula " />, a positive definite kernel <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-f0d19a1401658006e20eb7aff7c20689_l3.png?resize=124%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="13" width="124" alt="K: \mathcal{X} \times \mathcal{X} \to \mathbb{R}" class="ql-img-inline-formula " /> implicitly defines a Hilbert space <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="15" alt="\mathcal{H}" class="ql-img-inline-formula " /> of functions from <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e44d6dd2d58e906a7f3ec11d7f3cac9c_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="15" alt="\mathcal{X}" class="ql-img-inline-formula " /> to <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="13" alt="\mathbb{R}" class="ql-img-inline-formula " />, called reproducing kernel Hilbert space (RKHS), along with a mapping function <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-075eb9a40ac7f19fc1d24932d430cf57_l3.png?resize=84%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="84" alt="\varphi: \mathcal{X} \to \mathcal{H}" class="ql-img-inline-formula " />.</p>
<p>A predictive model <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="10" alt="f" class="ql-img-inline-formula " /> in <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d8c7ae0e5e08bd1b3f5ef053720bf142_l3.png?resize=15%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="15" alt="\mathcal{H}" class="ql-img-inline-formula " /> associates to every point <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="10" alt="x" class="ql-img-inline-formula " /> a label in <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b2c3c459eddec9847f841b19a2274a3d_l3.png?resize=13%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="13" alt="\mathbb{R}" class="ql-img-inline-formula " />, and admits a simple form <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-af2242f529038b9f66bdd803a7fcf32d_l3.png?resize=138%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="138" alt="f(x) =\langle f, \varphi(x) \rangle_{\mathcal{H}}" class="ql-img-inline-formula " />. Then, Cauchy-Schwarz inequality gives us a first basic stability property</p>
<p style="line-height: 21px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ba1f97e9889116f67e3caf7d27f6dca2_l3.png?resize=418%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="21" width="418" alt="\[ \forall x, x'\in \mathcal{X},~~~~~ |f(x)-f(x')| \leq \|f\|_{\mathcal{H}} \| \varphi(x) - \varphi(x')\|_\mathcal{H}. \]" class="ql-img-displayed-equation " /></p>
<p>This relation exhibits a discrepancy between neural networks and kernel methods. Whereas neural networks optimize the data representation for a specific task, the term on the right involves the product of two quantities where data representation and learning are decoupled:</p>
<p><img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9b7eefc0051c0b86a82ee0265f44a085_l3.png?resize=125%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="125" alt="\|\varphi(x)-\varphi(x')\|_\mathcal{H}" class="ql-img-inline-formula " /> is a distance between two data representations <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-41c6c60616e1acea2bdd02deee51011e_l3.png?resize=83%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="83" alt="\varphi(x),\varphi(x')" class="ql-img-inline-formula " />, which are independent of the learning process, and <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c755a8a9349d0895075e9494d1b11fc1_l3.png?resize=38%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="38" alt="\|f\|_\mathcal{H}" class="ql-img-inline-formula " /> is a norm on the model <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="10" alt="f" class="ql-img-inline-formula " /> (typically optimized over data) that acts as a measure of complexity.</p>
<p>Thinking about neural networks in terms of kernel methods then requires defining the underlying representation <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-eb419c2adecf84ed9a2d9693bc58d101_l3.png?resize=35%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="35" alt="\varphi(x)" class="ql-img-inline-formula " />, which can only depend on the network architecture, and the model <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="10" alt="f" class="ql-img-inline-formula " />, which will be parametrized by (learned) network’s weights.</p>
<p><strong>Building a convolutional kernel for convolutional neural networks</strong></p>
<p>Following <a href="http://jmlr.org/papers/volume20/18-190/18-190.pdf" class="lipdf">Alberto Bietti’s paper</a>, we now consider the direct construction of a multilayer convolutional kernel for images. Given a two-dimensional image <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="x_0" class="ql-img-inline-formula " />, the main idea is to build a sequence of “feature maps” <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4e504020251e8444e8047821206317fa_l3.png?resize=71%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="71" alt="x_1,x_2,\ldots" class="ql-img-inline-formula " /> that are two-dimensional spatial maps carrying information about image neighborhoods (a.k.a receptive fields) at every location. As we proceed in this sequence, the goal is to model larger neighborhoods with more “invariance”.</p>
<p>Formally, an input image <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-55b536a6647748d6c0c6b58015805c68_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="x_0" class="ql-img-inline-formula " /> is represented as a square-integrable function in <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b1cdcac953d52ed35e77925a243c3df7_l3.png?resize=76%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="76" alt="L^2(\Omega,\mathcal{H}_0)" class="ql-img-inline-formula " />, where <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="12" alt="\Omega" class="ql-img-inline-formula " /> is a set of pixel coordinates, and <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_0" class="ql-img-inline-formula " /> is a Hilbert space. <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec0c546b6596f336d8e1d41bb064b951_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="12" alt="\Omega" class="ql-img-inline-formula " /> may be a discrete grid or a continuous domain such as <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="15" width="20" alt="\mathbb{R}^2" class="ql-img-inline-formula " />, and <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c58a47e1230e20fa0f090bbe6e111ba7_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_0" class="ql-img-inline-formula " /> may simply be <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-97886402213f48c46e631e5331a34035_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="15" width="20" alt="\mathbb{R}^3" class="ql-img-inline-formula " /> for RGB images. Then, a feature map <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="x_k" class="ql-img-inline-formula " /> in <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-66fdb69a62e8ec8647eac89f54998a71_l3.png?resize=77%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="77" alt="L^2(\Omega,\mathcal{H}_k)" class="ql-img-inline-formula " /> is obtained from a previous layer <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="35" alt="x_{k-1}" class="ql-img-inline-formula " /> as follows:</p>
<ul>
<li><em> modeling larger neighborhoods than in the previous layer:</em> we map neighborhoods (patches) from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="35" alt="x_{k-1}" class="ql-img-inline-formula " /> to a new Hilbert space <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_k" class="ql-img-inline-formula " />. Concretely, we define a homogeneous dot-product kernel between patches <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ce80943b7f55934d998e09542933b73e_l3.png?resize=30%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="30" alt="z, z'" class="ql-img-inline-formula " /> from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="35" alt="x_{k-1}" class="ql-img-inline-formula " />:
<p style="line-height: 43px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e98e6c584e7aa34a129d04fa46a6981c_l3.png?resize=304%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="43" width="304" alt="\[ K_k(z,z') = \|z\| \|z'\| \kappa_k \left( \left\langle \frac{z}{\|z\|}, \frac{z'}{\|z'\|} \right\rangle \right), \]" class="ql-img-displayed-equation " /></p>
<p> where <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b62527a227d32e3e2f43b8b9b2b31ad5_l3.png?resize=29%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="29" alt="\langle . , . \rangle" class="ql-img-inline-formula " /> is an inner-product derived from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ec7eee8a3bac08b4c319cfce53408682_l3.png?resize=39%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="39" alt="\mathcal{H}_{k-1}" class="ql-img-inline-formula " />, and <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="\kappa_k" class="ql-img-inline-formula " /> is a non-linear function that ensures positive definiteness, <em>e.g.</em>, <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-46c64b76ccc9f508d30fec2fb80e244d_l3.png?resize=289%2C23&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="23" width="289" alt="\kappa_k(\langle u,u'\rangle ) = e^{\alpha (\langle u,u'\rangle -1)} = e^{-\frac{\alpha}{2}\|u-u'\|^2}" class="ql-img-inline-formula " /> for vectors <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0b88ce07daf9a52ba8a46659cff355fd_l3.png?resize=32%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="32" alt="u, u'" class="ql-img-inline-formula " /> with unit norm, see <a href="http://jmlr.org/papers/volume20/18-190/18-190.pdf" class="lipdf">this paper</a>. By doing so, we implicitly define a kernel mapping <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-243ed60e88d807834cd7cb1e1fbe0658_l3.png?resize=19%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="19" alt="\varphi_k" class="ql-img-inline-formula " /> that maps patches from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="35" alt="x_{k-1}" class="ql-img-inline-formula " /> to a new Hilbert space <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_k" class="ql-img-inline-formula " />. This mechanism is illustrated in the picture at the beginning of the post, and produces a spatial map that carries these patch representations.</p></li>
<li><em>increasing invariance:</em> to gain invariance to small deformations, we smooth~<img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="35" alt="x_{k-1}" class="ql-img-inline-formula " /> with a linear filter, as shown in the picture at the beginning of the post, which may be interpreted as anti-aliasing (in terms of signal processing) or linear pooling (in terms of neural networks).</li>
</ul>
<p>Formally, the previous construction amounts to applying operators <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4726bbf70431cf284be54bbc6a04ad60_l3.png?resize=18%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="18" alt="P_k" class="ql-img-inline-formula " /> (patch extraction), <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78f07026bc8c5150a11bf9e00756b7a7_l3.png?resize=24%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="24" alt="M_k" class="ql-img-inline-formula " /> (kernel mapping), and <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-866de181a59a21d2ca2306a9adbd9bc1_l3.png?resize=20%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="20" alt="A_k" class="ql-img-inline-formula " /> (smoothing/pooling operator) to <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-246f2a4e2f0c791d5589f43eca6383b8_l3.png?resize=35%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="35" alt="x_{k-1}" class="ql-img-inline-formula " /> such that the <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="11" alt="n" class="ql-img-inline-formula " />-th layer representation can be written as</p>
<p style="line-height: 21px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e8c2d99cc679426d1af08e6d15510211_l3.png?resize=437%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="21" width="437" alt="\[ \Phi_n(x_0)= x_n= A_n M_n P_n \ldots A_1 M_1 P_1 x_0~~~\text{in}~~~~L^2(\Omega,\mathcal{H}_n). \]" class="ql-img-displayed-equation " /></p>
<p>We may finally define a kernel for images as <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-16be084d5dd2ed3d7a18cdcf70c33fe2_l3.png?resize=231%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="231" alt="\mathcal{K}_n(x_0,x_0')=\langle \Phi_n(x_0), \Phi_n(x_0') \rangle" class="ql-img-inline-formula " />, whose RKHS contains the functions <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-95aa9a4388dd5f5da6292875abe6596a_l3.png?resize=162%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="162" alt="f_w(x_0) = \langle w , \Phi_n(x_0) \rangle" class="ql-img-inline-formula " /> for <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="13" alt="w" class="ql-img-inline-formula " /> in <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-502d385c60e5ecdb1a0f26ee770d30b1_l3.png?resize=77%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="77" alt="L^2(\Omega,\mathcal{H}_n)" class="ql-img-inline-formula " />. Note now that we have introduced a concept of image representation <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="21" alt="\Phi_n" class="ql-img-inline-formula " />, which only depends on some network architecture (amounts of pooling, patch size), and predictive model <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-fb636251e88ba51d909c76c1110eed5e_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="19" alt="f_w" class="ql-img-inline-formula " /> parametrized by <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="13" alt="w" class="ql-img-inline-formula " />.</p>
<p>From such a construction, we will now derive stability results for classical convolutional neural networks (CNNs) and then derive non-standard CNNs based on kernel approximations that we call convolutional kernel networks (CKNs).</p>
<p> </p>
<p>Next week, we will see how to perform feature (end-to-end) learning with the previous kernel representation, and also discuss other classical links between neural networks and kernel methods.</p>
<p> </p>
<p> </p></div>







<p class="date">
by Sebastien Bubeck <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/"><span class="datestr">at July 10, 2019 03:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/092">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/092">TR19-092 |  Revisiting Alphabet Reduction in Dinur&amp;#39;s PCP | 

	Venkatesan Guruswami, 

	Jakub Opršal, 

	Sai Sandeep</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Dinur's celebrated proof of the PCP theorem alternates two main steps in several iterations: gap amplification to increase the soundness gap by a large constant factor (at the expense of much larger alphabet size), and a composition step that brings back the alphabet size to an absolute constant (at the expense of a fixed constant factor loss in the soundness gap). We note that the gap amplification can produce a Label Cover CSP. This allows us to reduce the alphabet size via a direct long-code based reduction from Label Cover to a Boolean CSP. Our composition step thus bypasses the concept of Assignment Testers from Dinur's proof, and we believe it is more intuitive --- it is just a gadget reduction. The analysis also uses only elementary facts (Parseval's identity) about Fourier Transforms over the hypercube.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/092"><span class="datestr">at July 09, 2019 04:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17523">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/">Imre Bárány: Limit shape</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>Limit shapes are fascinating objects in the interface between probability and geometry and between the discrete and the continuous. This post is kindly contributed by Imre Bárány.</em></p>
<h3><a href="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg"><img src="https://gilkalai.files.wordpress.com/2019/07/imre_barany_2011.jpg?w=640" alt="" class="alignnone size-full wp-image-17560" /></a></h3>
<h2>What is a limit shape?</h2>
<p>There are finitely many convex lattice polygons contained in the <img src="https://s0.wp.com/latex.php?latex=%7B%5B0%2Cn%5D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[0,n]^2}" class="latex" title="{[0,n]^2}" /> square. Their number turns out to be</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cexp%5C%7B3%5Csqrt%5B3%5D%7B%5Czeta%283%29%2F%5Czeta%282%29%7Dn%5E%7B2%2F3%7D%281%2Bo%281%29%29%5C%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)" class="latex" title="\displaystyle \exp\{3\sqrt[3]{\zeta(3)/\zeta(2)}n^{2/3}(1+o(1))\}. \ \ \ \ \ (1)" /></p>
<p>This is a large number. How does a typical element of this large set look? Is there a<br />
limit shape of these convex lattice polygons?</p>
<p>To answer this question it is convenient to consider the lattice <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%3D%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}" class="latex" title="{{\mathbb{Z}}_n=\frac 1n {\mathbb{Z}}^2}" /> and define <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n}" class="latex" title="{\mathcal{F}^n}" /> as the family of all convex <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb{Z}}_n}" class="latex" title="{{\mathbb{Z}}_n}" />-lattice polygons lying in the unit square <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" />. The polygons in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n}" class="latex" title="{\mathcal{F}^n}" /> have a limit shape (as <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\rightarrow \infty}" class="latex" title="{n\rightarrow \infty}" />) if there is a convex set <img src="https://s0.wp.com/latex.php?latex=%7BK%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K\subset Q}" class="latex" title="{K\subset Q}" /> such that the overwhelming majority of the polygons in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n}" class="latex" title="{\mathcal{F}^n}" /> are very close to <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" />. In other words, for every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon&gt;0}" class="latex" title="{\epsilon&gt;0}" /> the number of polygons in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n}" class="latex" title="{\mathcal{F}^n}" /> that are farther than <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> from <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> (in Hausdorff distance, say) is a minute part of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n}" class="latex" title="{\mathcal{F}^n}" />, that is, <img src="https://s0.wp.com/latex.php?latex=%7Bo%28%7C%5Cmathcal%7BF%7D%5En%7C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{o(|\mathcal{F}^n|)}" class="latex" title="{o(|\mathcal{F}^n|)}" /> as <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \rightarrow \infty}" class="latex" title="{n \rightarrow \infty}" />. To put it differently, the average of the characteristic functions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_P%28.%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_P(.)}" class="latex" title="{\chi_P(.)}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P\in \mathcal{F}^n}" class="latex" title="{P\in \mathcal{F}^n}" /> tends to a zero-one function:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clim+%7B%5Crm+Ave%7D_%7BP%5Cin+%5Cmathcal%7BF%7D%5En%7D%5Cchi_P%28x%29%3D%5Cbegin%7Bcases%7D+1%26+%5Cmbox%7B+if+%7D+x+%5Cin+K%2C%5C%5C+0%26+%5Cmbox%7B+if+%7D+x+%5Cnotin+K.+%5Cend%7Bcases%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} " class="latex" title="\lim {\rm Ave}_{P\in \mathcal{F}^n}\chi_P(x)=\begin{cases} 1&amp; \mbox{ if } x \in K,\\ 0&amp; \mbox{ if } x \notin K. \end{cases} " /></p>
<h2>The limit shape theorem</h2>
<h3></h3>
<p>The limit shape theorem says that such a <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> exists, its boundary consists of four parabola arcs each touching consecutive sides of <img src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Q" class="latex" title="Q" /> at their midpoints, see the figure.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/limitshape.png"><img src="https://gilkalai.files.wordpress.com/2019/07/limitshape.png?w=640" alt="" class="alignnone size-full wp-image-17536" /></a></p>
<h3>Generating functions and saddle point methods</h3>
<p>The proof is based on the fact that a convex (lattice or non-lattice) polygon with vertices <img src="https://s0.wp.com/latex.php?latex=v_1%2C%5Cldots%2Cv_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v_1,\ldots,v_n" class="latex" title="v_1,\ldots,v_n" /> (in this order on its boundary) is uniquely determined by the edge-vectors <img src="https://s0.wp.com/latex.php?latex=v_2-v_1%2C%5Cldots%2Cv_n-v_%7Bn-1%7D%2C+v_1-v_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n" class="latex" title="v_2-v_1,\ldots,v_n-v_{n-1}, v_1-v_n" />. Using this one can write down the generating function of the number of convex lattice paths from <img src="https://s0.wp.com/latex.php?latex=%280%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(0,0)" class="latex" title="(0,0)" /> to <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29%5Cin+%5Cmathbb%7BZ%7D%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a,b)\in \mathbb{Z}^2" class="latex" title="(a,b)\in \mathbb{Z}^2" /> lying in the triangle whose vertices are <img src="https://s0.wp.com/latex.php?latex=%280%2C0%29%2C%28a%2C0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(0,0),(a,0)" class="latex" title="(0,0),(a,0)" /> and <img src="https://s0.wp.com/latex.php?latex=%28a%2Cb%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(a,b)" class="latex" title="(a,b)" />. And this number can be estimated by saddle point methods (from complex variables). This is also how formula (1) for <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathcal%7BF%7D%5En%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\mathcal{F}^n|" class="latex" title="|\mathcal{F}^n|" /> can be established.</p>
<h3>A beautiful geometric result</h3>
<p>On the geometry part one needs a beautiful (and almost elementary) result saying that, in a triangle <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T" class="latex" title="T" /> with vertices <img src="https://s0.wp.com/latex.php?latex=1%2C2%2C3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1,2,3" class="latex" title="1,2,3" /> and with subtriangles <img src="https://s0.wp.com/latex.php?latex=T_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T_1" class="latex" title="T_1" /> and <img src="https://s0.wp.com/latex.php?latex=T_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T_2" class="latex" title="T_2" /> (see the figure)</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)" class="latex" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, \ \ \ \ \ (2)" /></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/triangle.png"><img src="https://gilkalai.files.wordpress.com/2019/07/triangle.png?w=640" alt="" class="alignnone size-full wp-image-17537" /></a></p>
<p>with equality iff the line segment 46 is touches the special parabola arc at point 5. The special parabola arc is the one that touches sides 12 and 13 of <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> at points 2 and 3. I was very proud of inequality (2) but it turned out that it had been known for long (cf Blaschke: Vorlesungen Über Differentialgeometrie II, (1923) page 38).</p>
<p>In the proof one needs a slightly stronger version of (2). Assuming point 4 (resp. 6) divides segment 12 (and 13) in ratio <img src="https://s0.wp.com/latex.php?latex=%7B1-a%3Aa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1-a:a}" class="latex" title="{1-a:a}" />, (and <img src="https://s0.wp.com/latex.php?latex=%7Bb%3A1-b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b:1-b}" class="latex" title="{b:1-b}" />), the stronger inequality says that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T%7D%5Cleft%281-%5Cfrac13+%28a-b%29%5E2%5Cright%29%5Cge+%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_1%7D%2B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+T_2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, " class="latex" title="\displaystyle \sqrt[3]{\textrm{Area} \; T}\left(1-\frac13 (a-b)^2\right)\ge \sqrt[3]{\textrm{Area} \; T_1}+\sqrt[3]{\textrm{Area} \; T_2}, " /></p>
<p>which was probably not known to Blaschke.</p>
<p>It is important to point out that <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> is the unique convex subset of <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" /> whose affine perimeter is the largest among all convex subsets of <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" />. I’ll return to the affine perimeter later.</p>
<p>Yakov Sinai came up with a different, elegant, and more powerful proof using canonical ensembles from statistical physics. His method was developed further by Vershik and Zeitouni, by Bureaux and Enriquez, by Bogachev and Zarbaliev.</p>
<h2>Limit shapes for polygons in convex bodies</h2>
<p>More generally, one can consider a convex body (compact convex set with non-empty interior) <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> in the plane and the family <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n(C)}" class="latex" title="{\mathcal{F}^n(C)}" /> of all convex <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb{Z}}_n}" class="latex" title="{{\mathbb{Z}}_n}" />-lattice polygons contained in <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, and ask whether a similar limit shape exists in this case. The answer is yes. The limit shape, <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" />, is the unique convex subset of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> whose affine perimeter is maximal among all convex subsets of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. The affine perimeter is upper semicontinuous, implying the existence of convex subset of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> with maximal affine perimeter. The proof of its uniqueness requires extra effort. In the case when <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> is the unit square <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" />, the limit shape <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> is equal to <img src="https://s0.wp.com/latex.php?latex=%7BQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_0}" class="latex" title="{Q_0}" />. Note that for every convex body <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> with <img src="https://s0.wp.com/latex.php?latex=%7BQ_0%5Csubset+C+%5Csubset+Q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_0\subset C \subset Q}" class="latex" title="{Q_0\subset C \subset Q}" />, <img src="https://s0.wp.com/latex.php?latex=%7BC_0%3DQ_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0=Q_0}" class="latex" title="{C_0=Q_0}" />.</p>
<h2>Random points vs. lattice points</h2>
<p>What happens if, instead of the <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb{Z}}_n}" class="latex" title="{{\mathbb{Z}}_n}" />-lattice points in <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, we take a random sample <img src="https://s0.wp.com/latex.php?latex=%7BX_n%3D%5C%7Bx_1%2C%5Cldots%2Cx_n%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_n=\{x_1,\ldots,x_n\}}" class="latex" title="{X_n=\{x_1,\ldots,x_n\}}" /> of points from <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, chosen independently and uniformly? Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{G}(X_n)}" class="latex" title="{\mathcal{G}(X_n)}" /> be the set of all polygons whose vertices belong to <img src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_n}" class="latex" title="{X_n}" />. This is again a finite set and one can show that<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E%7B-1%2F3%7D%5Clog+%5Cmathop%7B%5Cmathbb+E%7D%28+%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%3D3%5Ccdot2%5E%7B-2%2F3%7D%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" title="\displaystyle \lim_{n\rightarrow \infty} n^{-1/3}\log \mathop{\mathbb E}( |\mathcal{G}(X_n)|)=3\cdot2^{-2/3}\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^*(C)}" class="latex" title="{A^*(C)}" /> is equal to the affine perimeter, <img src="https://s0.wp.com/latex.php?latex=%7BAP%28C_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{AP(C_0)}" class="latex" title="{AP(C_0)}" />, of <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" />. This confirms the philosophy (or my intuition) that random points and lattice points in convex bodies behave similarly. Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5Cmathcal%7BG%7D%28X_n%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}" class="latex" title="{\mathop{\mathbb E}|\mathcal{G}(X_n)|}" /> is of order <img src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_1n%5E%7B1%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\exp\{c_1n^{1/3}\}}" class="latex" title="{\exp\{c_1n^{1/3}\}}" /> while <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5Cmathcal%7BF%7D%5En%28C%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\mathcal{F}^n(C)|}" class="latex" title="{|\mathcal{F}^n(C)|}" /> is of order <img src="https://s0.wp.com/latex.php?latex=%7B%5Cexp%5C%7Bc_2n%5E%7B2%2F3%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\exp\{c_2n^{2/3}\}}" class="latex" title="{\exp\{c_2n^{2/3}\}}" /> which is fine as number of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb{Z}}_n}" class="latex" title="{{\mathbb{Z}}_n}" />-lattice points in <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> is approximately <img src="https://s0.wp.com/latex.php?latex=%7Bn%5E2+%5Ctextrm%7BArea%7D+%5C%3B+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n^2 \textrm{Area} \; C}" class="latex" title="{n^2 \textrm{Area} \; C}" />.</p>
<p>Even more interestingly, the limit shape of the polygons in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{G}(X_n)}" class="latex" title="{\mathcal{G}(X_n)}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" />, in the sense that, in expectation, the overwhelming majority of polygons in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D%28X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{G}(X_n)}" class="latex" title="{\mathcal{G}(X_n)}" /> is very close to <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" />. More precisely, for every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon&gt;0}" class="latex" title="{\epsilon&gt;0}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn+%5Crightarrow+%5Cinfty%7D+%5Cfrac%7B%5Cmathop%7B%5Cmathbb+E%7D%7C%5C%7BP%5Cin+%5Cmathcal%7BG%7D%28X_n%29%3A%5Cdelta%28P%2CC_0%29%3E%5Cepsilon%5C%7D%7C%7D%7B%5Cmathop%7B%5Cmathbb+E%7D%28%7C%5Cmathcal%7BG%7D%28X_n%29%7C%29%7D%3D0%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, " class="latex" title="\displaystyle \lim_{n \rightarrow \infty} \frac{\mathop{\mathbb E}|\{P\in \mathcal{G}(X_n):\delta(P,C_0)&gt;\epsilon\}|}{\mathop{\mathbb E}(|\mathcal{G}(X_n)|)}=0, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> stands for the Hausdorf distance.</p>
<p>The proof of the lattice case does not work here. The edge vectors determine the convex polygon, still, but the edge vectors can’t be used, there is no generating function, etc. Instead the proof is based on the following two theorems. For the first let <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" /> be a triangle with two specified vertices <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> say, and let <img src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_k}" class="latex" title="{X_k}" /> be a random independent sample of <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> uniform points from <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_k}" class="latex" title="{X_k}" /> is called a convex chain (from <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />) if the convex hull of <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Ba%2Cb%5C%7D%5Cbigcup+X_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{a,b\}\bigcup X_k}" class="latex" title="{\{a,b\}\bigcup X_k}" /> is a convex polygon with exactly <img src="https://s0.wp.com/latex.php?latex=%7Bk%2B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k+2}" class="latex" title="{k+2}" /> vertices. Then<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CPr%5BX_k+%5Cmbox%7B+is+a+convex+chain%7D%5D%3D%5Cfrac+%7B2%5Ek%7D%7Bk%21%28k%2B1%29%21%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, " class="latex" title="\displaystyle \Pr[X_k \mbox{ is a convex chain}]=\frac {2^k}{k!(k+1)!}, " /></p>
<p>a surprisingly precise result (due to Pavel Valtr).</p>
<p>For the second theorem let <img src="https://s0.wp.com/latex.php?latex=%7Bp%28n%2CC%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p(n,C)}" class="latex" title="{p(n,C)}" /> denote the probability that the random sample <img src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_n}" class="latex" title="{X_n}" /> (independent and uniform again) lands in convex position, that is, their convex hull is a convex <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-gon. For <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=4}" class="latex" title="{n=4}" /> this is Sylvester’s famous four point problem from 1864 (although he did not specify the underlying convex body <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />). Then<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Clim_%7Bn%5Crightarrow+%5Cinfty%7D+n%5E2%5Csqrt%5Bn%5D%7Bp%28n%2CC%29%7D%3D%5Cfrac+%7Be%5E2%7D4%5Cfrac%7BA%5E%2A%28C%29%7D%7B%5Csqrt%5B3%5D%7B%5Ctextrm%7BArea%7D+%5C%3B+C%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " class="latex" title="\displaystyle \lim_{n\rightarrow \infty} n^2\sqrt[n]{p(n,C)}=\frac {e^2}4\frac{A^*(C)}{\sqrt[3]{\textrm{Area} \; C}}, " /></p>
<p>with the same <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^*(C)}" class="latex" title="{A^*(C)}" /> as before. The proof of this theorem uses the previous result of Valtr about convex chains in triangles and the properties of <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" />, the largest affine area convex subset of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. The set <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" /> appears again: it is the limit shape of <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7Bconv%7DX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\textrm{conv}X_n}" class="latex" title="{\textrm{conv}X_n}" /> under the condition that <img src="https://s0.wp.com/latex.php?latex=%7BX_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_n}" class="latex" title="{X_n}" /> landed in convex position.</p>
<p>The map <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Crightarrow+C_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C \rightarrow C_0}" class="latex" title="{C \rightarrow C_0}" /> is affinely equivariant and has interesting properties. <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" /> turns out to be the limit shape in some further cases as well. For instance, the maximal number of vertices of the polygons in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n(C)}" class="latex" title="{\mathcal{F}^n(C)}" /> equals</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac+%7B3n%5E%7B2%2F3%7D%7D%7B%282%5Cpi%29%5E%7B2%2F3%7D%7DA%5E%2A%28C%29%281%2Bo%281%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), " class="latex" title="\displaystyle \frac {3n^{2/3}}{(2\pi)^{2/3}}A^*(C)(1+o(1)), " /></p>
<p>as <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \rightarrow \infty}" class="latex" title="{n \rightarrow \infty}" />. This is of course the same as the maximal number of points in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%5Ccap+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb{Z}}_n\cap C}" class="latex" title="{{\mathbb{Z}}_n\cap C}" /> that are in convex position. Although the convex <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb%7BZ%7D%7D_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb{Z}}_n}" class="latex" title="{{\mathbb{Z}}_n}" />-lattice polygon <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n(C)}" class="latex" title="{\mathcal{F}^n(C)}" /> with maximal number of vertices is not necessary unique, they have a limit shape which is again <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" />. The same happens in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BG%7D_n%28C%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{G}_n(C)}" class="latex" title="{\mathcal{G}_n(C)}" /> as well. In this case, however, the expectation of the maximal number of vertices is equal to constant times <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%2A%28C%29n%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^*(C)n^{1/3}}" class="latex" title="{A^*(C)n^{1/3}}" /> but the value of this (positive) constant is not known. The reason is the following. In the triangle <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" /> with specified vertices <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />, and random sample <img src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_k}" class="latex" title="{X_k}" /> we define <img src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_k}" class="latex" title="{L_k}" /> as the maximal number of points from <img src="https://s0.wp.com/latex.php?latex=%7BX_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_k}" class="latex" title="{X_k}" /> that form a convex chain in <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" /> from <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />. The random variable <img src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_k}" class="latex" title="{L_k}" /> is concentrated around its expectation, which is equal to some non-negative constant times <img src="https://s0.wp.com/latex.php?latex=%7Bk%5E%7B1%2F3%7D%281%2Bo%281%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k^{1/3}(1+o(1))}" class="latex" title="{k^{1/3}(1+o(1))}" /> as <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Crightarrow+%5Cinfty%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k \rightarrow \infty}" class="latex" title="{k \rightarrow \infty}" /> but this constant is not known. Experiments suggest that it is equal to 3 but there is no proof in sight. Not surprisingly, the limit shape of these maximal convex chains is again the special parabola arc in <img src="https://s0.wp.com/latex.php?latex=%7B%5CDelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Delta}" class="latex" title="{\Delta}" />. This question about the random variable <img src="https://s0.wp.com/latex.php?latex=%7BL_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_k}" class="latex" title="{L_k}" /> is similar to the longest increasing subsequence problem but much less is known about it.</p>
<h2>Open Problem: high dimensions</h2>
<p>What remains of the limit shape phenomenon in higher dimensions? Well, hardly anything has been proved. In the simplest case, let <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" /> denote the unit cube in 3-space, and let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5En%28Q%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}^n(Q)}" class="latex" title="{\mathcal{F}^n(Q)}" /> denote the set of all convex <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac+1n+%7B%5Cmathbb%7BZ%7D%7D%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac 1n {\mathbb{Z}}^3}" class="latex" title="{\frac 1n {\mathbb{Z}}^3}" />-lattice polygons contained in <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" />. It is known that <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+%7C%5Cmathcal%7BF%7D%5En%28Q%29%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log |\mathcal{F}^n(Q)|}" class="latex" title="{\log |\mathcal{F}^n(Q)|}" /> is between <img src="https://s0.wp.com/latex.php?latex=%7Bc_1n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_1n^{1/2}}" class="latex" title="{c_1n^{1/2}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bc_2+n%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_2 n^{1/2}}" class="latex" title="{c_2 n^{1/2}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B0%3Cc_1%3Cc_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0&lt;c_1&lt;c_2}" class="latex" title="{0&lt;c_1&lt;c_2}" />, but nothing more precise. Probably there is a limit shape here as well, and it might be the convex subset of <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" /> that has the largest affine surface area. The existence of such a set follows the same way as above but its uniqueness is not known.</p>
<h2>The affine perimeter</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/affper.png"><img src="https://gilkalai.files.wordpress.com/2019/07/affper.png?w=640" alt="" class="alignnone size-full wp-image-17542" /></a></p>
<p> </p>
<p>Finally a few words about the affine perimeter. Given a convex curve <img src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Gamma}" class="latex" title="{\Gamma}" /> in the plane, choose points <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2C+x_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0,\ldots, x_n}" class="latex" title="{x_0,\ldots, x_n}" /> on it, take the tangent lines at these points and form the triangles <img src="https://s0.wp.com/latex.php?latex=%7BT_1%2C%5Cldots%2CT_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_1,\ldots,T_n}" class="latex" title="{T_1,\ldots,T_n}" /> as in the figure. By definition, the affine perimeter <img src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{AP(\Gamma)}" class="latex" title="{AP(\Gamma)}" /> is the infimum of the sum <img src="https://s0.wp.com/latex.php?latex=%7B2%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" title="{2\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" /> as the subdivision <img src="https://s0.wp.com/latex.php?latex=%7Bx_0%2C%5Cldots%2Cx_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_0,\ldots,x_n}" class="latex" title="{x_0,\ldots,x_n}" /> gets finer and finer. The affine perimeter of the unit circle is <img src="https://s0.wp.com/latex.php?latex=%7B2%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2\pi}" class="latex" title="{2\pi}" /> which explains the constant <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> in front of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_1%5En%28%5Ctextrm%7BArea%7D+%5C%3B+T_i%29%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" class="latex" title="{\sum_1^n(\textrm{Area} \; T_i)^{1/3}}" />. The exponent <img src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/3}" class="latex" title="{1/3}" /> is the right choice here: for larger exponent the sum is zero, and for smaller it is infinity (for the circle for instance). Inequality (2) shows that infimum in the definition can be replaced by limit. The affine perimeter of a convex polygon is zero.</p>
<p>For a twice differentiable curve <img src="https://s0.wp.com/latex.php?latex=%7BAP%28%5CGamma%29+%3D+%5Cint_%7B%5CGamma%7D%5Ckappa%5E%7B1%2F3%7Dds%3D%5Cint_%7B%5CGamma%7Dr%5E%7B-1%2F3%7Dds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}" class="latex" title="{AP(\Gamma) = \int_{\Gamma}\kappa^{1/3}ds=\int_{\Gamma}r^{-1/3}ds}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Ckappa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\kappa}" class="latex" title="{\kappa}" /> is the curvature and <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> the radius of curvature and <img src="https://s0.wp.com/latex.php?latex=%7Bds%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ds}" class="latex" title="{ds}" /> means integration with arc length. The affine perimeter is an affine invariant or rather equivariant meaning that <img src="https://s0.wp.com/latex.php?latex=%7BAP%28S%28%5CGamma%29%29%3D%5Csqrt%5B3%5D%7B%7C%5Cdet+S%7C%7D+AP%28%5CGamma%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}" class="latex" title="{AP(S(\Gamma))=\sqrt[3]{|\det S|} AP(\Gamma)}" /> for a non-degenerate affine transformation <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. Quite often the affine perimeter (and the affine surface area) appears in connection with affine equivariant properties of the convex set <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. One example is best approximation by inscribed polygons <img src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_n}" class="latex" title="{P_n}" /> on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> vertices. When approximation is measured by <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctextrm%7BArea%7D%5C%3B%28C%5Cbackslash+P_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\textrm{Area}\;(C\backslash P_n)}" class="latex" title="{\textrm{Area}\;(C\backslash P_n)}" /> then the best approximating polygon <img src="https://s0.wp.com/latex.php?latex=%7BP_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_n}" class="latex" title="{P_n}" /> satisfies the estimate<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Ctextrm%7BArea%7D+%5C%3B+%28C%5Cbackslash+P_n%29%3D+%5Cfrac+1%7B4%5Csqrt+3%7D+%5Cfrac+%7BAP%28C%29%5E3%7D%7Bn%5E2%7D%281%2Bo%281%29%29.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)" class="latex" title="\displaystyle \textrm{Area} \; (C\backslash P_n)= \frac 1{4\sqrt 3} \frac {AP(C)^3}{n^2}(1+o(1)). \ \ \ \ \ (3)" /></p>
<p>The set <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" />, the convex subset of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> with maximal affine perimeter has interesting properties. For instance its boundary contains no line segment, and if some piece of its boundary lies in the interior of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, then this piece is a parabola arc. It has positive curvature everywhere. It is of course affinely equivariant meaning that <img src="https://s0.wp.com/latex.php?latex=%7BS%28C_0%29%3D+S%28C%29_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(C_0)= S(C)_0}" class="latex" title="{S(C_0)= S(C)_0}" />. According to (3) <img src="https://s0.wp.com/latex.php?latex=%7BC_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_0}" class="latex" title="{C_0}" /> has the worst approximation properties among all convex subsets of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{C}" class="latex" title="{C}" />.  This might explain why it comes up as the limit shape so often. Actually, the high dimensional analogue of (3) suggests that the limit shape in higher dimensions is again connected to the maximal affine surface area subset of the underlying convex body.</p>
<p> </p>
<p>More reading: Imre Bárány, <a href="https://www.ams.org/journals/bull/2008-45-03/S0273-0979-08-01210-X/">Random points and lattice points in convex bodies</a>, Bull AMS (2008)</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/07/09/imre-barany-limit-shape/"><span class="datestr">at July 09, 2019 08:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8041836663315088806">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html">Fortran is underated!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
(Joint Post with David Marcus who was a classmate of mine at SUNY Stony Brook [now called Stony Brook University]. I was class of 1980, he was class of 1979. We were both math majors.)<br />
<br />
David has been reading <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a POINT</a> (I'm glad someone is reading it) and emailed me a comment on the following passage which was essentially <a href="https://blog.computationalcomplexity.org/2012/02/dusting-off-my-bookshelf-i-find-book-on.html">this post</a>. I paraphrase what I wrote:<br />
<br />
PASSAGE IN BOOK:<br />
I dusted off my book shelves and found a book on Fortran. On the back it said:<br />
<br />
FORTRAN is one of the oldest high-level languages and remains the premier language for writing code for science and engineering applications. (NOTE- The back of the book uses Fortran but the spell checker I am using insists on FORTRAN. As a fan of capital letters, I don't mind going along.)<br />
<br />
When was the book written?<br />
<br />
The answer was surprising in that it was 2012 (the Chapter title was <i>Trick Question or Stupid Question</i>. This was a Trick Question.) I would have thought that FORTRAN was no longer the premier language by then. I also need to dust my bookshelves more often.<br />
END OF PASSAGE IN BOOK<br />
<br />
David Marcus emailed me the following:<br />
<br />
DAVID'S EMAIL<br />
Page 201. Fortran. One clue is that it said "Fortran" rather than"FORTRAN". Fortran 90 changed the name from all upper case. Whether it is the "premier language" depends on what you mean by "premier". It is probably the best language for scientific computing. I used it pretty much exclusively (by choice) in my previous job that I left in 2006. The handling of arrays is better than any other language I've used. Maybe there are some better languages that I'm not familiar with, but the huge number of high-quality scientific libraries available for Fortran makes it hard to beat. On the other hand, I never wrote a GUI app with it (Delphi is best for that).<br />
END OF DAVID'S EMAIL<br />
<br />
In later emails we agreed that Fortran is not used that much (there are lists of most-used languages and neither Fortran nor FORTRAN is ever in the top 10).  But what intrigued me was the following contrast:<br />
<br />
1) David says that its the BEST language for Scientific Computing.  I will assume he is right.<br />
<br />
2) I doubt much NEW code is being written in it.  I will assume I am right.<br />
<br />
So---what's up with that? Some options<br />
<br />
OPTION 1) People SHOULD use Fortran but DON'T. If so, why is that?  Fortran is not taught in schools. People are used to what they already know.  Perhaps people who do pick up new things easily and want to use new things would rather use NEW things rather than NEW-TO-THEM-BUT-NOT-TO-THEIR-GRANDMOTHER things. Could be a coolness factor.  Do the advantages of Fortran outweight the disadvantages?  Is what they are using good enough?<br />
<br />
OPTION 2) The amount of Scientific computing software being written is small since we already have these great Fortran packages. So it may be a victim of its own success.<br />
<br />
CAVEAT: When I emailed David a first draft of the post he pointed out the following which has to do with the lists of most-used programming languages:<br />
<br />
DAVIDS EMAIL:<br />
The problem with the lists you were looking at is that most people in the world are not scientists, so most software being written is not for scientists. Scientists and technical people are writing lots of new code.  If you look at a list of scientific languages, you will see Fortran, e.g., <a href="https://en.wikipedia.org/wiki/Scientific_programming_language">here</a> and <a href="https://en.wikipedia.org/wiki/Fortran#Science_and_engineering">here</a>.<br />
<br />
<br />
There are several Fortran compilers available. One of the best was bought by Intel some time back and they still sell it. I doubt they would do that if no one was using it. Actually, I think Intel had a compiler, but bought the Compaq compiler (which used to be the Digital Equipment compiler) and merged the Compaq team with their team. Something like that. I was using the Compaq compiler around that time.<br />
END OF DAVID's EMAIL<br />
<br />
One quote from the second pointer I find intriguing.  (Second use of the word <i>intriguing</i>. It was my word-of-the-day on my word-calendar).<br />
<br />
<i>... facilities for inter-operation with C were added to Fortran 2003 and enhanced by ISO/ICE technical specification 29113, which will be incorporated into Fortran 2018. </i><br />
<br />
I (Bill) don't know what some of that means; however, it does mean that Fortran is still active.<br />
<br />
<br />
One fear: with its not being taught that much, will knowledge of it die out.  We be like Star Trek aliens:<br />
<br />
<i>The old ones built these machines, but then died and we can't fix them!<br />
<br />
<br />
<br />
</i></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/07/fortran-is-underated.html"><span class="datestr">at July 08, 2019 03:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/091">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/091">TR19-091 |  A Sublinear-space and Polynomial-time Separator Algorithm for Planar Graphs | 

	Ryo Ashida, 

	Tatsuya Imai, 

	Kotaro Nakagawa, 

	A.  Pavan, 

	Vinodchandran Variyam, 

	Osamu Watanabe</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In [12] (CCC 2013), the authors presented an algorithm for the reachability problem over directed planar graphs that runs in polynomial-time and uses $O(n^{1/2+\epsilon})$ space. A critical ingredient  of their algorithm is a polynomial-time, $\tldO(\sqrt{n})$-space algorithm to compute a separator of a planar graph. The conference version provided a sketch of the algorithm and many nontrivial details were left unexplained. In this work, we provide a detailed construction of their algorithm.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/091"><span class="datestr">at July 07, 2019 11:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
