<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at August 19, 2019 02:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.06059">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.06059">Low-rank approximation in the Frobenius norm by column and row subset selection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cortinovis:Alice.html">Alice Cortinovis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kressner:Daniel.html">Daniel Kressner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.06059">PDF</a><br /><b>Abstract: </b>A CUR approximation of a matrix $A$ is a particular type of low-rank
approximation $A \approx C U R$, where $C$ and $R$ consist of columns and rows
of $A$, respectively. One way to obtain such an approximation is to apply
column subset selection to $A$ and $A^T$. In this work, we describe a
numerically robust and much faster variant of the column subset selection
algorithm proposed by Deshpande and Rademacher, which guarantees an error close
to the best approximation error in the Frobenius norm. For cross approximation,
in which $U$ is required to be the inverse of a submatrix of $A$ described by
the intersection of $C$ and $R$, we obtain a new algorithm with an error bound
that stays within a factor $k + 1$ of the best rank-$k$ approximation error in
the Frobenius norm. To the best of our knowledge, this is the first
deterministic polynomial-time algorithm for which this factor is bounded by a
polynomial in $k$. Our derivation and analysis of the algorithm is based on
derandomizing a recent existence result by Zamarashkin and Osinsky. To
illustrate the versatility of our new column subset selection algorithm, an
extension to low multilinear rank approximations of tensors is provided as
well.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.06059"><span class="datestr">at August 19, 2019 01:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05966">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05966">LaserTank is NP-complete</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alexandersson:Per.html">Per Alexandersson</a>, Petter Restadh <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05966">PDF</a><br /><b>Abstract: </b>We show that the classical game LaserTank is $\mathrm{NP}$-complete, even
when the tank movement is restricted to a single column and the only blocks
appearing on the board are mirrors and solid blocks. We show this by reducing
$3$-SAT instances to LaserTank puzzles.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05966"><span class="datestr">at August 19, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05944">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05944">Parallel Computation of Alpha Complex for Biomolecules</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Masood:Talha_Bin.html">Talha Bin Masood</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ray:Tathagata.html">Tathagata Ray</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Natarajan:Vijay.html">Vijay Natarajan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05944">PDF</a><br /><b>Abstract: </b>Alpha complex, a subset of the Delaunay triangulation, has been extensively
used as the underlying representation for biomolecular structures. We propose a
GPU based parallel algorithm for the computation of the alpha complex, which
exploits the knowledge of typical spatial distribution and sizes of atoms in a
biomolecule. Unlike existing methods, this algorithm does not require prior
construction of the Delaunay triangulation. The algorithm computes the alpha
complex in two stages. The first stage proceeds in a bottom up fashion and
computes a superset of the edges, triangles, and tetrahedra belonging to the
alpha complex. The false positives from this estimation stage are removed in a
subsequent pruning stage to obtain the correct alpha complex. Computational
experiments on several biomolecules demonstrate the superior performance of the
algorithm, upto 50x when compared to existing methods that are optimized for
biomolecules.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05944"><span class="datestr">at August 19, 2019 01:56 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05943">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05943">Algorithms and Complexity for Functions on General Domains</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Novak:Erich.html">Erich Novak</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05943">PDF</a><br /><b>Abstract: </b>Error bounds and complexity bounds in numerical analysis and
information-based complexity are often proved for functions that are defined on
very simple domains, such as a cube, a torus, or a sphere. We study optimal
error bounds for the approximation or integration of functions defined on $D_d
\subset R^d$ and only assume that $D_d$ is a bounded Lipschitz domain. Some
results are even more general. We study three different concepts to measure the
complexity: order of convergence, asymptotic constant, and explicit uniform
bounds, i.e., bounds that hold for all $n$ (number of pieces of information)
and all (normalized) domains. It is known for many problems that the order of
convergence of optimal algorithms does not depend on the domain $D_d \subset
R^d$. We present examples for which the following statements are true:
</p>
<p>1) Also the asymptotic constant does not depend on the shape of $D_d$ or the
imposed boundary values, it only depends on the volume of the domain.
</p>
<p>2) There are explicit and uniform lower (or upper, respectively) bounds for
the error that are only slightly smaller (or larger, respectively) than the
asymptotic error bound.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05943"><span class="datestr">at August 19, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05930">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05930">Efficient Online String Matching Based on Characters Distance Text Sampling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Faro:Simone.html">Simone Faro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pavone:Arianna.html">Arianna Pavone</a>, Francesco Pio Marino <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05930">PDF</a><br /><b>Abstract: </b>Searching for all occurrences of a pattern in a text is a fundamental problem
in computer science with applications in many other fields, like natural
language processing, information retrieval and computational biology. Sampled
string matching is an efficient approach recently introduced in order to
overcome the prohibitive space requirements of an index construction, on the
one hand, and drastically reduce searching time for the online solutions, on
the other hand. In this paper we present a new algorithm for the sampled string
matching problem, based on a characters distance sampling approach. The main
idea is to sample the distances between consecutive occurrences of a given
pivot character and then to search online the sampled data for any occurrence
of the sampled pattern, before verifying the original text. From a theoretical
point of view we prove that, under suitable conditions, our solution can
achieve both linear worst-case time complexity and optimal average-time
complexity. From a practical point of view it turns out that our solution shows
a sub-linear behaviour in practice and speeds up online searching by a factor
of up to 9, using limited additional space whose amount goes from 11% to 2.8%
of the text size, with a gain up to 50% if compared with previous solutions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05930"><span class="datestr">at August 19, 2019 01:27 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05855">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05855">Distributed Edge Partitioning for Trillion-edge Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanai:Masatoshi.html">Masatoshi Hanai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suzumura:Toyotaro.html">Toyotaro Suzumura</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Wen_Jun.html">Wen Jun Tan</a>, Elvis Liu, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Theodoropoulos:Georgios.html">Georgios Theodoropoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:Wentong.html">Wentong Cai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05855">PDF</a><br /><b>Abstract: </b>We propose Distributed Neighbor Expansion (Distributed NE), a parallel and
distributed edge partitioning method that can scale to trillion-edge graphs
while providing high partitioning quality. Distributed NE is based on a new
heuristic, called parallel expansion, where each partition is constructed in
parallel by greedily expanding its edge set from a single vertex in such a way
that the increase of the vertex cuts becomes local minimal. We theoretically
prove that the proposed method has the upper bound in the partitioning quality.
The empirical evaluation with various graphs shows that the proposed method
produces higher-quality partitions than the state-of-the-art distributed graph
partitioning algorithms. The performance evaluation shows that the space
efficiency of the proposed method is an order-of-magnitude better than the
existing algorithms, keeping its time efficiency comparable. As a result,
Distributed NE can handle a trillion-edge graph using only a few hundreds of
machines.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05855"><span class="datestr">at August 19, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05706">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05706">Homotopy height, grid-major height and graph-drawing height</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Therese Biedl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chambers:Erin_Wolf.html">Erin Wolf Chambers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, Arnaud De Mesmay, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ophelders:Tim.html">Tim Ophelders</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05706">PDF</a><br /><b>Abstract: </b>It is well-known that both the pathwidth and the outer-planarity of a graph
can be used to obtain lower bounds on the height of a planar straight-line
drawing of a graph. But both bounds fall short for some graphs. In this paper,
we consider two other parameters, the (simple) homotopy height and the (simple)
grid-major height. We discuss the relationship between them and to the other
parameters, and argue that they give lower bounds on the straight-line drawing
height that are never worse than the ones obtained from pathwidth and
outer-planarity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05706"><span class="datestr">at August 19, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05700">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05700">Distributed Backup Placement in One Round and its Applications to Maximum Matching Approximation and Self-Stabilization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barenboim:Leonid.html">Leonid Barenboim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oren:Gal.html">Gal Oren</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05700">PDF</a><br /><b>Abstract: </b>In the distributed backup-placement problem each node of a network has to
select one neighbor, such that the maximum number of nodes that make the same
selection is minimized. This is a natural relaxation of the perfect matching
problem, in which each node is selected just by one neighbor. Previous
(approximate) solutions for backup placement are non-trivial, even for simple
graph topologies, such as dense graphs. In this paper we devise an algorithm
for dense graph topologies, including unit disk graphs, unit ball graphs, line
graphs, graphs with bounded diversity, and many more. Our algorithm requires
just one round, and is as simple as the following operation. Consider a
circular list of neighborhood IDs, sorted in an ascending order, and select the
ID that is next to the selecting vertex ID. Surprisingly, such a simple
one-round strategy turns out to be very efficient for backup placement
computation in dense networks. Not only that it improves the number of rounds
of the solution, but also the approximation ratio is improved by a
multiplicative factor of at least $2$.
</p>
<p>Our new algorithm has several interesting implications. In particular, it
gives rise to a $(2 + \epsilon)$-approximation to maximum matching within
$O(\log^* n)$ rounds in dense networks. The resulting algorithm is very simple
as well, in sharp contrast to previous algorithms that compute such a solution
within this running time. Moreover, these algorithms are applicable to a
narrower graph family than our algorithm. For the same graph family, the best
previously-known result has $O(\log {\Delta} + \log^* n)$ running time. Another
interesting implication is the possibility to execute our backup placement
algorithm as-is in the self-stabilizing setting. This makes it possible to
simplify and improve other algorithms for the self-stabilizing setting, by
employing helpful properties of backup placement.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05700"><span class="datestr">at August 19, 2019 01:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05666">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05666">Resolvable Designs for Speeding up Distributed Computing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Konstantinidis:Konstantinos.html">Konstantinos Konstantinidis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramamoorthy:Aditya.html">Aditya Ramamoorthy</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05666">PDF</a><br /><b>Abstract: </b>Distributed computing frameworks such as MapReduce are often used to process
large computational jobs. They operate by partitioning each job into smaller
tasks executed on different servers. The servers also need to exchange
intermediate values to complete the computation. Experimental evidence suggests
that this so-called Shuffle phase can be a significant part of the overall
execution time for several classes of jobs. Prior work has demonstrated a
natural tradeoff between computation and communication whereby running
redundant copies of jobs can reduce the Shuffle traffic load, thereby leading
to reduced overall execution times. For a single job, the main drawback of this
approach is that it requires the original job to be split into a number of
files that grows exponentially in the system parameters. When extended to
multiple jobs (with specific function types), these techniques suffer from a
limitation of a similar flavor, i.e., they require an exponentially large
number of jobs to be executed. In practical scenarios, these requirements can
significantly reduce the promised gains of the method. In this work, we show
that a class of combinatorial structures called resolvable designs can be used
to develop efficient coded distributed computing schemes for both the single
and multiple job scenarios considered in prior work. We present both
theoretical analysis and exhaustive experimental results (on Amazon EC2
clusters) that demonstrate the performance advantages of our method. For the
single and multiple job cases, we obtain speed-ups of 4.69x (and 2.6x over
prior work) and 4.31x over the baseline approach, respectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05666"><span class="datestr">at August 19, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/107">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/107">TR19-107 |  The Power of a Single Qubit: Two-way Quantum/Classical Finite Automata and the Word Problem for Linear Groups | 

	Zachary Remscrim</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The two-way quantum/classical finite automaton (2QCFA), defined by Ambainis and Watrous, is a model of quantum computation whose quantum part is extremely limited; however, as they showed, 2QCFA are surprisingly powerful: a 2QCFA, with a single qubit, can recognize, with one-sided bounded-error, the language $L_{eq}=\{a^m b^m |m \in \mathbb{N}\}$ in expected polynomial time and the language $L_{pal}=\{w \in \{a,b\}^*|w \text{ is a palindrome}\}$ in expected exponential time.  

We further demonstrate the power of 2QCFA by showing that they can recognize the word problems of a broad class of groups. In particular, we first restrict our attention to 2QCFA that: $(1)$ have a single qubit, $(2)$ recognize their language with one-sided bounded-error, and $(3)$ have transition amplitudes which are algebraic numbers. We show that such 2QCFA can recognize the word problem of any finitely-generated virtually abelian group in expected polynomial time, as well as the word problem of a large class of linear groups in expected exponential time. This latter class includes all groups whose word problem is a context-free language as well as all groups whose word problem is known to be the intersection of finitely many context-free languages. As a corollary, we obtain a direct improvement on the original Ambainis and Watrous result by showing that $L_{eq}$ can be recognized by a 2QCFA with better parameters. 

We also consider those word problems which a 2QCFA can recognize with one-sided unbounded-error, and show that this class includes the word problem of more exotic groups such as the free product of any finite collection of finitely-generated free abelian groups. As a corollary of this result, we demonstrate that a new class of group word problems are co-stochastic languages. Lastly, we exhibit analogous results for 2QCFA with any finite number of qubits or with more general transition amplitudes, as well as results for other classic QFA models.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/107"><span class="datestr">at August 18, 2019 01:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/106">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/106">TR19-106 |  Semialgebraic Proofs and Efficient Algorithm Design | 

	Noah Fleming, 

	Pravesh Kothari, 

	Toniann Pitassi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Over the last twenty years, an exciting interplay has emerged between proof systems and algorithms. Some natural families of algorithms can be viewed as a generic translation from a proof that a solution exists into an algorithm for finding the solution itself. This connection has perhaps been the most consequential in the context of semi-algebraic proof systems and basic primitives in algorithm design such as linear and semidefinite programming. The proof system perspective, in this context, has provided fundamentally new tools for both algorithm design and analysis. These news tools have helped in both designing better algorithms for well-studied problems and proving tight lower bounds on such techniques.

This monograph is aimed at expositing this interplay between proof systems and efficient algorithm design and surveying the state-of-the-art for two of the most important semi-algebraic proof systems: Sherali-Adams and Sum-of-Squares.

We rigorously develop and survey the state-of-the-art for Sherali-Adams and Sum-of-Squares both as proof systems, as well as a general family of optimization algorithms, stressing that  these perspectives are formal duals to one-another. Our treatment relies on interpreting the outputs of the Sum-of-Squares and Sherali-Adams algorithms as generalized expectation functions -- a viewpoint that has been essential in obtaining both algorithmic results and lower bounds. The emphasis is on illustrating the main ideas by presenting a small fraction of representative results with detailed intuition and commentary. The monograph is self-contained and includes a review of the necessary mathematical background including basic theory of linear and semi-definite programming.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/106"><span class="datestr">at August 18, 2019 06:14 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5432">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2019/08/18/abstraction-is-hard/">Abstraction is Hard</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A few weeks ago I read Malcolm Gladwell’s book The Tipping Point. The book doesn’t really deal with mathematics, but it does contain one math-related anecdote. This anecdote demonstrates an interesting principle of learning mathematics, so I wanted to share it. Problem 1. We have a deck of cards, such that each card contains a […]</div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2019/08/18/abstraction-is-hard/"><span class="datestr">at August 18, 2019 02:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05445">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05445">Tracking Paths in Planar Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eppstein:David.html">David Eppstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:James_A=.html">James A. Liu</a>, Pedro A. Matias <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05445">PDF</a><br /><b>Abstract: </b>We consider the NP-complete problem of tracking paths in a graph, first
introduced by Banik et. al. [3]. Given an undirected graph with a source $s$
and a destination $t$, find the smallest subset of vertices whose intersection
with any $s-t$ path results in a unique sequence. In this paper, we show that
this problem remains NP-complete when the graph is planar and we give a
4-approximation algorithm in this setting. We also show, via Courcelle's
theorem, that it can be solved in linear time for graphs of bounded-clique
width, when its clique decomposition is given in advance.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05445"><span class="datestr">at August 18, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05415">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05415">"LOADS of Space": Local Order Agnosticism and Bit Flip Efficient Data Structure Codes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gray:Matthew.html">Matthew Gray</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05415">PDF</a><br /><b>Abstract: </b>Algorithms, data structures, coding techniques, and other methods that reduce
bit-flips are being sought to best utilize hardware where flipping bits is the
dominating cost. Write efficient memories were introduced by Ahlswede and Zhang
as a model for storage systems with these kinds of arbitrary read, write, and
update costs. The introduction of non-volatile Random Access Memories like
phase-change RAM, which have asymmetric read-write costs has re-motivated the
field. Our work focuses on potential bit-flip efficiencies to be gained at the
data structure layer. We examine Local Order Agnostic Data Structures (LOADS),
data structures in which local order does not convey information and in which
cells are modified individually. We found that because these data structures
have a limited set of valid values and transitions, that bit flipping wins
should be possible without the use of additional hardware.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05415"><span class="datestr">at August 18, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05361">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05361">Placing quantified variants of 3-SAT and Not-All-Equal 3-SAT in the polynomial hierarchy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/D=ouml=cker:Janosch.html">Janosch Döcker</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dorn:Britta.html">Britta Dorn</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Linz:Simone.html">Simone Linz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Semple:Charles.html">Charles Semple</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05361">PDF</a><br /><b>Abstract: </b>The complexity of variants of 3-SAT and Not-All-Equal 3-SAT is well studied.
However, in contrast, very little is known about the complexity of the
problems' quantified counterparts. In the first part of this paper, we show
that $\forall \exists$ 3-SAT is $\Pi_2^P$-complete even if (1) each variable
appears exactly twice unnegated and exactly twice negated, (2) each clause is a
disjunction of exactly three distinct variables, and (3) the number of
universal variables is equal to the number of existential variables.
Furthermore, we show that the problem remains $\Pi_2^P$-complete if (1a) each
universal variable appears exactly once unnegated and exactly once negated,
(1b) each existential variable appears exactly twice unnegated and exactly
twice negated, and (2) and (3) remain unchanged. On the other hand, the problem
becomes NP-complete for certain variants in which each universal variable
appears exactly once. In the second part of the paper, we establish
$\Pi_2^P$-completeness for $\forall \exists$ Not-All-Equal 3-SAT even if (1')
the Boolean formula is linear and monotone, (2') each universal variable
appears exactly once and each existential variable appears exactly three times,
and (3') each clause is a disjunction of exactly three distinct variables that
contains at most one universal variable. On the positive side, we uncover
variants of $\forall \exists$ Not-All-Equal 3-SAT that are co-NP-complete or
solvable in polynomial time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05361"><span class="datestr">at August 18, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1908.05345">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1908.05345">On Strict (Outer-)Confluent Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/F=ouml=rster:Henry.html">Henry Förster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganian:Robert.html">Robert Ganian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klute:Fabian.html">Fabian Klute</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/N=ouml=llenburg:Martin.html">Martin Nöllenburg</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1908.05345">PDF</a><br /><b>Abstract: </b>A strict confluent (SC) graph drawing is a drawing of a graph with vertices
as points in the plane, where vertex adjacencies are represented not by
individual curves but rather by unique smooth paths through a planar system of
junctions and arcs. If all vertices of the graph lie in the outer face of the
drawing, the drawing is called a strict outerconfluent (SOC) drawing. SC and
SOC graphs were first considered by Eppstein et al. in Graph Drawing 2013.
Here, we establish several new relationships between the class of SC graphs and
other graph classes, in particular string graphs and unit-interval graphs.
Further, we extend earlier results about special bipartite graph classes to the
notion of strict outerconfluency, show that SOC graphs have cop number two, and
establish that tree-like ($\Delta$-)SOC graphs have bounded cliquewidth.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1908.05345"><span class="datestr">at August 18, 2019 11:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/08/17/footprints-in-snow">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/08/17/footprints-in-snow.html">Footprints in the snow</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Given an abstract optimization problem with multiple solutions, how much partial information about a solution do you have to know in order to uniquely identify that solution? That has been the topic of some of my earlier research, on <a href="https://11011110.github.io/blog/2014/10/08/forced-creases-in.html">how many creases of an origami folding pattern you have to force to be mountain or valley folds in order to cause the remaining folds to go the way you want</a>. And it’s the topic of my new preprint “Tracking paths in planar graphs” (<a href="https://arxiv.org/abs/1908.05445">arXiv:1908.05445</a>, with Mike Goodrich, James Liu, and Pedro Matias).</p>

<p>There’s an old story about how to design the footpaths on a college campus: wait for it to snow, see where the heaviest sets of footprints cross the snow from building to building, and then once the snow melts place paths in those same places. But what if you live somewhere like Irvine where it never snows? Or what if you want to perform some other type of data analysis on a data set of the paths that people take? For instance, in order to design improvements to the road networks used by commuter traffic, it would be helpful to figure out where all the traffic actually goes each day. How can you collect that data?</p>

<p>Our paper takes the point of view that you can attach sensors to the network that record the times and identities of people passing by them, but that these sensors are expensive. The goal is (for a given network with designated start and destination vertices  and ) to place as few of these sensors as possible at graph vertices, in such a way that every simple -path is uniquely identified by the sequence of sensors that it passes through.</p>

<p>The problem turns out to be -complete, even on planar networks. But there’s a simple approximation ratio based on the idea that the optimal number of sensors is always going to be proportional to the number of faces in the network. Each face (in the sequence of biconnected components between  and ) has to have at least one sensor, to distinguish paths that go one way around the face from paths that go the other way around. It turns out that placing one sensor at a vertex shared by many faces doesn’t work — those faces still need a proportional number of additional sensors. And our approximation algorithm ensures that the number of sensors is at most proportional to the number of faces.</p>

<p>We also use <a href="https://en.wikipedia.org/wiki/Courcelle%27s_theorem">Courcelle’s theorem</a> to prove that the exact solution is fixed-parameter tractable in the clique-width of the graph. Like most or all uses of Courcelle’s theorem, the resulting algorithm is impractical, so it would be of interest to find a more direct algorithm, perhaps for a weaker parameter.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102634545213040458">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/08/17/footprints-in-snow.html"><span class="datestr">at August 17, 2019 02:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/105">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/105">TR19-105 |  A note on the relation between XOR and Selective XOR Lemmas | 

	Ragesh Jaiswal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Given an unpredictable Boolean function $f: \{0, 1\}^n \rightarrow \{0, 1\}$, the standard Yao's XOR lemma is a statement about the unpredictability of computing $\oplus_{i \in [k]}f(x_i)$ given $x_1, ..., x_k \in \{0, 1\}^n$, whereas the Selective XOR lemma is a statement about the unpredictability of computing $\oplus_{i \in S}f(x_i)$ given $x_1, ..., x_k \in \{0, 1\}^n$ and $S \subseteq \{1, ..., k\}$. We give a reduction from the Selective XOR lemma to the standard XOR lemma. Our reduction gives better quantitative bounds for certain choice of parameters and does not require the assumption of being able to sample $(x, f(x))$ pairs.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/105"><span class="datestr">at August 16, 2019 08:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16160">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/">Predicting Chess and Horses</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Using predictivity both to sharpen and cross-check models</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/patti-miller-and-jeff-seder-of-eqb-agents-consulting-2/" rel="attachment wp-att-16163"><img src="https://rjlipton.files.wordpress.com/2019/08/patti-miller-and-jeff-seder-of-eqb-agents-consulting-1.jpg?w=212&amp;h=204" alt="" width="212" class="aligncenter wp-image-16163" height="204" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from article <a href="https://www.inverse.com/article/31250-jeff-seder-kentucky-derby-horse-genetics-big-data">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Patrice Miller and Jeff Seder look under the hide of horses. Their company <a href="https://www.eqb.com/">EQB</a> does predictive modeling for horse racing based on biometric data. They are famous for having <a href="https://www.nytimes.com/2015/06/05/sports/american-pharoah-cant-erase-all-of-ahmed-zayats-missteps.html">advised</a> the owner of American Pharoah not to sell because the horse had a powerful heart. In 2015, American Pharoah became the first Triple Crown winner since the also-hearty Secretariat in 1978.</p>
<p>
Today I am happy to announce an extended version of my predictive model for chess and discuss how it gains accuracy by looking under the hood of chess positions.</p>
<p>
I had thought to credit Charles Babbage and Ada Lovelace for being the first to envision computational predictive modeling, but the evidence connected to her design of betting schemes for horse racing is scant and <a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/babbage/bio.htm">secondhand</a> <a href="https://blog.stephenwolfram.com/2015/12/untangling-the-tale-of-ada-lovelace/">accounts</a> <a href="https://books.google.com/books?id=RUDdYIL5TG0C&amp;pg=PR21&amp;lpg=PR21&amp;dq=charles+babbage+horse+races&amp;source=bl&amp;ots=VxqMznLIj0&amp;sig=ACfU3U0d6jICkDy2sSZ0MVlPyLQT_rGj6g&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwj5iNLB_ITkAhUB2VkKHYMyAoA4ChDoATAEegQICRAB#v=onepage&amp;q=charles babbage horse races&amp;f=false">differ</a>. It is known that Babbage compiled voluminous data on the medical fitness and diet of animals, including heart function by taking their pulse. We have discussed their computing work <a href="https://rjlipton.wordpress.com/2010/03/23/its-ada-lovelace-day/">here</a> and <a href="https://rjlipton.wordpress.com/2015/02/17/ada-the-amplifier/">here</a>. </p>
<p>
I will use horse racing as a device for explaining the main new ingredient of my model. It sharpens the prediction of moves—and the results of cheating tests—by using deeper information to “beat the bookie” as Lovelace tried to do. I have described the basic form of my model—and previous efforts to extend it—in <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">several</a> <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">previous</a> <a href="https://rjlipton.wordpress.com/2016/11/08/unskewing-the-election/">posts</a> <a href="https://rjlipton.wordpress.com/2017/05/23/stopped-watches-and-data-analytics/">on</a> <a href="https://rjlipton.wordpress.com/2012/03/30/when-is-a-law-natural/">this</a> <a href="https://rjlipton.wordpress.com/2013/09/17/littlewoods-law/">blog</a>. Last month, besides being involved in <a href="https://www.spiegel.de/sport/sonst/schach-wie-der-weltverband-betrueger-erwischt-a-1277439.html">several</a> <a href="https://www.foxnews.com/world/chess-grandmaster-caught-using-phone-inside-bathroom-during-a-tournament">media</a> <a href="https://www.chess.com/news/view/igors-rausis-58-under-investigation-of-cheating">stories</a> involving a grandmaster caught in the act of cheating in France, I was invited to discuss this work by Ben Johnson for his “Perpetual Chess” <a href="https://www.perpetualchesspod.com/new-blog/2019/7/23/episode-136-im-kenneth-regan">podcast</a>.</p>
<p>
</p><p></p><h2> Betting the Favorite </h2><p></p>
<p></p><p>
My chess model does the same thing to a chess position—given information about the skill set of the player deciding on a move—that a bookie does to a horse race. It sets odds on each legal move <img src="https://s0.wp.com/latex.php?latex=%7Bm_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m_i}" class="latex" title="{m_i}" /> to “win” by being played in the game. The probabilities <img src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_i}" class="latex" title="{p_i}" /> need to be accurate for the same reason bookmakers need their “initial betting lines” to be close to how bets will ultimately balance, so they can preserve their <a href="https://en.wikipedia.org/wiki/Vigorish">margin</a>. A horse with highest <img src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_i}" class="latex" title="{p_i}" />—perhaps a tie—is the bookie’s <em>favorite</em>. The favorite might be “odds-on,” meaning <img src="https://s0.wp.com/latex.php?latex=%7Bp_i+%5Cgg+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_i \gg 0.5}" class="latex" title="{p_i \gg 0.5}" />, or might be a “narrow favorite” among several horses with near-equal chances.</p>
<p>
Suppose you don’t care how much money you might win but just want to maximize your chance of being right—of winning something. Unless you have reason to doubt the bookie, you should bet on the favorite. That is what my basic chess model does. Whichever move is given the highest value by the computer at the end of its search is declared the favorite, regardless of the player’s <a href="https://en.wikipedia.org/wiki/Elo_rating_system">Elo rating</a> or other skill factors. </p>
<p>
That the best move—we’ll label it <img src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m_1}" class="latex" title="{m_1}" />—should <em>always</em> be most likely even for the weakest players runs counter to sense. Aren’t weaker players weaker because they prefer weaker moves? When the right move is obvious, say a forced recapture or a checkmate in one, of course we expect any player to find it. But when <img src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m_1}" class="latex" title="{m_1}" /> is subtle, what then? </p>
<p></p><p><br />
My basic model still makes it the favorite. This doesn’t mean its probability <img src="https://s0.wp.com/latex.php?latex=%7Bp_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_1}" class="latex" title="{p_1}" /> is greater than half. My model might make <img src="https://s0.wp.com/latex.php?latex=%7Bp_1+%5Cgg+0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_1 \gg 0.5}" class="latex" title="{p_1 \gg 0.5}" /> for world champion level players but only, say, <img src="https://s0.wp.com/latex.php?latex=%7Bp_1+%3D+0.25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_1 = 0.25}" class="latex" title="{p_1 = 0.25}" /> for beginning players. Thus it will still say the beginner is 75% likely to play an inferior move. What my base model shies away from is saying any other particular move—any other horse—is more likely to win than <img src="https://s0.wp.com/latex.php?latex=%7Bm_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m_1}" class="latex" title="{m_1}" />. As the rating gets lower it bunches up the probabilities so that while <img src="https://s0.wp.com/latex.php?latex=%7Bp_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_1}" class="latex" title="{p_1}" /> is lower, no other probability passes it.</p>
<p>
This is borne out in practice. The lowest Elo rating used by the World Chess Federation (FIDE) is 1000. Let’s take ratings between that and 1200 (which used to be the lowest rating) as denoting the novice class. Consider only those positions that have many reasonable choices—say at least ten moves valued within 0.25 (figuratively, a quarter of a pawn) of optimal. My main training set has 6.082 such positions in games between evenly-matched players of this level. Here are the frequencies of their playing the best through the tenth-best move in such <em>many-choice positions</em>:</p>
<p align="center">
</p><table align="center">
<tbody><tr>
<td align="right"> Rank </td>
<td align="right"> Pct.</td>
<td></td>
<td></td>
</tr>
<tr>
<td align="right"> 1 </td>
<td align="right"> 17.76%</td>
</tr>
<tr>
<td align="right"> 2 </td>
<td align="right"> 13.22%</td>
</tr>
<tr>
<td align="right"> 3 </td>
<td align="right"> 9.95%</td>
</tr>
<tr>
<td align="right"> 4 </td>
<td align="right"> 7.66%</td>
</tr>
<tr>
<td align="right"> 5 </td>
<td align="right"> 6.25%</td>
</tr>
<tr>
<td align="right"> 6 </td>
<td align="right"> 5.18%</td>
</tr>
<tr>
<td align="right"> 7 </td>
<td align="right"> 4.41%</td>
</tr>
<tr>
<td align="right"> 8 </td>
<td align="right"> 4.55%</td>
</tr>
<tr>
<td align="right"> 9 </td>
<td align="right"> 3.50%</td>
</tr>
<tr>
<td align="right"> 10 </td>
<td align="right"> 3.03%</td>
</tr>
<tr>
<td align="right"> 11+ </td>
<td align="right"> 24.49%</td>
</tr>
<tr>
<td align="right"> </td>
</tr>
</tbody></table>
<p>
Both my basic model and the new one, when fitted over the entire training set for this class but then restricted to the many-choices subset, give projections close to these actual values. The basic model, always betting the favorite, is right on under 18% of its projections. Can we do better? That is, can we “beat the bookie” at chess? </p>
<p>
</p><p></p><h2> Predicting Inferior Moves </h2><p></p>
<p></p><p>
It is almost four years since the idea for improving predictions was <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">described</a> on this blog. In place of “weaker players prefer weaker moves,” it advanced a hypothesis that we can state as follows:</p>
<blockquote><p><b> </b> <em> Weaker players are more likely to be diverted by shiny objects. </em>
</p></blockquote>
<p></p><p>
Most in particular, they will fall for moves that look attractive early on, but which are revealed (by the computer) to be inferior after deeper consideration. The computer programs output values for each depth of search, and when these moves’ values are graphed against the depth, they start high but “swing down” at higher depths. Weaker players are more likely to be satisfied by the early flash and not think deeper. The old <a href="https://rjlipton.wordpress.com/2015/10/06/depth-of-satisficing/">post</a> has a great example of such a move from the pivotal game in the 2008 world championship match, where Viswanathan Anand set a deep trap that caught the previous world champion, Vladimir Kramnik. </p>
<p>
The flip side are moves that look poor at low depths but whose high value emerges at high depths. My basic model, which uses only the final values of moves, gives too high a projection on these cases, and too low a likelihood of falling into traps. I have figured that these two kinds of ‘misses’ offset over a few dozen positions. Moreover, in both kinds of misses, the player is given express benefit of doubt by the projections. It is edgier, after all, to project that a player is more likely to fall into a trap than to find the safest and best move.</p>
<p>
The effect of lower-depth values is still too powerful to ignore in identifiable cases. Including them, however, makes the whole model edgier, as I have <a href="https://rjlipton.wordpress.com/2016/11/08/unskewing-the-election/">described</a> here <a href="https://rjlipton.wordpress.com/2017/05/23/stopped-watches-and-data-analytics/">before</a>. Simply put, the lower-depth values are subject to more noise, from which we are trying to extract greater information. It has been like trying to catch lightning—or <a href="https://www.pppl.gov/news/2019/08/improving-magnetic-bottle-controls-fusion-power-earth">fusion</a>—in a bottle.</p>
<p>
</p><p></p><h2> Modest But Effective Success </h2><p></p>
<p></p><p>
My new model implements the “swing” feature without adding any more free parameters for fitting. It has new parameters but those are set “by hand” after an initial fitting of the free parameters under the “sliding-scale” regime I <a href="https://rjlipton.wordpress.com/2018/09/07/sliding-scale-problems/">described</a> last September, which is followed by a second round of re-fitting. It required heavy clamps on the weighting of lower-depth values and more-intense conditioning of inputs overall. It required a solution to the “firewall at zero” <a href="https://rjlipton.wordpress.com/2016/01/21/a-chess-firewall-at-zero/">phenomenon</a> that was the exact opposite of what I’d envisioned.</p>
<p>
After all this, here is what it delivers in the above case—and quite generally:</p>
<blockquote><p><b> </b> <em> It improves the prediction success rate—for the weakest players in the most difficult kind of positions to forecast—from 17.76% to <b>20.04%</b>. </em>
</p></blockquote>
<p></p><p>
For the elite class—2600 to 2800—in the same kind of many-choice positions, the new model does even better. Much more data on elite players is available, so I have 49,793 such positions faced by them: </p>
<blockquote><p><b> </b> <em> Whereas elite players found the best move in 30.85% of these difficult positions, my new model finds <b>their</b> move in <b>34.64%</b> of them. </em>
</p></blockquote>
<p></p><p>
Over all positions, the average <em>prediction gain</em> ranges from about 1 percentage point for the lowest players to over 2% for masters. These gains may not sound like much, but for cheating tests they give prime value. The reasons are twofold:</p>
<ul>
<li>
The gained predictions are all <em>against</em> their finding the computer’s move, so the act of finding the best move is more exposed. <p></p>
</li><li>
The standard deviation is typically 3–5 percentage points depending on the volume of moves. Thus the prediction gain can enhance the measured <a href="https://en.wikipedia.org/wiki/Standard_score">z-score</a> by upwards of 0.5 or more.
</li></ul>
<p>
Initial applications in recent cases seem to prove this out more often than not. Of course, the larger purpose is to have a better model of human chess play overall.</p>
<p>
</p><p></p><h2> Cross-Checks and Caveats </h2><p></p>
<p></p><p>
In recent years, several new dimensions of quality and safety with predictive models have emerged. They supplement the two classic ones:</p>
<ul>
<li>
<em>Avoiding false positives.</em> In particular, over a natural population (such as the mass of honest players), the rate of outlier scores generated by the model must stay within the bounds of natural frequency for the population. Call this “natural safety.” <p></p>
</li><li>
<em>Avoiding false negatives</em>. The model should provide enough <a href="https://en.wikipedia.org/wiki/Power_(statistics)">statistical power</a> to flag unnatural outliers without becoming unsafe.
</li></ul>
<p>
I vetted my model’s natural safety by processing tens of millions of generated z-scores under resampling after my final design tweaks earlier this month. This was over a link between departmental machines and UB’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>) where my data is generated. The previous discussion has all been about greater power. The first new factor updates the idea of <a href="https://en.wikipedia.org/wiki/Calibration_(statistics)#In_prediction_and_forecasting">calibration</a>:</p>
<ul>
<li>
<em>Non-bias and fairness.</em> More general than the societal context, which we discussed <a href="https://rjlipton.wordpress.com/2017/11/20/a-magic-madison-visit/">here</a>, this means avoiding bias along functional lines that the model is not intended to distinguish.
</li></ul>
<p>
I have a suite of cross-checking measures besides those tests that are expressly fitted to be unbiased estimators. They include checking how my model performs on various different types of positions, such as those with many choices as above, or the opposite: those having one standout move. For example, the model’s best-move projection in the many-choice positions by elite players, using the general settings for 2700 rating, is 31.07%. That’s within 0.28%. Another check is figuratively how much “probability money” my model wagered to get its 34.64% hit rate. The sum of <img src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_i}" class="latex" title="{p_i}" /> it projected on its own most-likely moves, in the 68.4% of the many-choice positions where it agreed with the computer’s favorite plus 31.6% where it did not, was 35.00%. If I fit all 282,060 positions by these players, rather than use “2700,” and then re-select the subset, the model comes within <b>0.01%</b> on the first-move projection and <b>0.11%</b> on its own betting forecasts. I will say more about the cross-checks, use of <a href="https://en.wikipedia.org/wiki/Brier_score">prediction</a>–<a href="https://en.wikipedia.org/wiki/Score_(statistics)">scoring</a> <a href="https://en.wikipedia.org/wiki/Scoring_rule">metrics</a>, and conformance to normal distribution at a later time. The relevant point is to ask:</p>
<blockquote><p><b> </b> <em> How well does your model perform on pertinent tests besides those it was expressly trained for? </em>
</p></blockquote>
<p></p><p>
Beyond fairness, good <em>wide-range</em> calibration alleviates dangers of “mission creep.” </p>
<p>
The second newer factor is:</p>
<ul>
<li>
<em><a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">Adversarial</a> performance.</em> This is apart from “natural safety.” Simply put: how resistant is the model to being deceived? Can it be gamed?
</li></ul>
<p>
My impressions over the long haul of this work is that the new model’s more-powerful heart inevitably brings greater “springiness.” By dint of its being more sensitive to moves whose high value emerges only after deep search, it is possible to create shorter sequences of such moves that make it jump to conclusions. The z-score vetting turned up a few games that were agreed drawn after some “book” moves—openings known by heart to many professional players—whose entirety the model would flag, except for the standard procedure of identifying and removing book moves from cheating tests. These outliers came from over a hundred thousand games between evenly-matched players, so they still conformed to the natural rate, but one can be concerned about the “unnatural rate.” On the flip side, I believe my more-intensive conditioning of values has made the model more robust against being gamed by cheaters playing a few inferior moves to cover their tracks. </p>
<p>
In general, and especially with nonlinear models, the caveat is that amplifying statistical power brings greater susceptibility to adversarial conditions. Trying to “beat the bookie” requires more model introspection. My model retains its <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence">explainability</a> and ability to provide audits for its determinations. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What lessons from similar situations with other predictive models can be identified and brought to bear on this one?</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2019/08/15/predicting-chess-and-horses/"><span class="datestr">at August 16, 2019 12:52 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/08/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/08/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="http://homepages.gac.edu/~jsiehler/games/pyramids-start.html">Tricolor pyramids</a> (<a href="https://mathstodon.xyz/@11011110/102546072670351246"></a>). In this logic puzzle by @jsiehler, you have to 3-color hexagonal tiles avoiding 2-colored upright triangles. What interests me is not that, but the following: it’s the time-space diagram of a 3-state cellular automaton (with time flowing upward and each cell taking the color that makes the triangle below it work). But turned  it’s still the time-space diagram of the same automaton! I haven’t seen this sort of CA symmetry before.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/08/02/publicsphere-v-elsevier.html">Elsevier sends copyright threat to site for linking to Sci-Hub</a> (<a href="https://mathstodon.xyz/@11011110/102551592262978036"></a>). Apparently if you tell people they can find free copies of paywalled journal papers on pirate web site sci-hub, and link directly to sci-hub to make it even easier to find free copies of paywalled journal papers, you get a nasty letter from the corporate leeches who made it necessary to set up a pirate web site for free copies of paywalled journal papers . But if you <a href="https://en.wikipedia.org/wiki/Sci-Hub">go to Wikipedia</a> you can find the link in the infobox. And it turns out that <a href="https://eve.gd/2019/08/03/elsevier-threatens-others-for-linking-to-sci-hub-but-does-it-itself/">Elsevier journals themselves contain plenty of links to sci-hub</a> (<a href="https://boingboing.net/2019/08/03/zero">via</a>). Sci-hub sci-hub sci-hub.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@Breakfastisready/102554576764536048">@Breakfastisready recommends the new graphic novel “Prime Suspects”</a>, by Andrew and Jennifer Granville with illustrations by Robert J. Lewis: “It’s all about analytic number theory in metaphors.”</p>
  </li>
  <li>
    <p><a href="https://mati.naukas.com/">Mati y sus mateaventuras</a> (<a href="https://mathstodon.xyz/@11011110/102559401183096120"></a>), blog of popularized mathematics stories by mathematician Clara Grima and illustrator Raquel Gu (in Spanish). The latest one (from a year ago; it hasn’t updated much recently) is <a href="https://en.wikipedia.org/wiki/Wythoff%27s_game">on Wythoff’s game</a>.</p>
  </li>
  <li>
    <p><a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">Manu suggests reducing our impact on the planet by making conferences virtual</a> (<a href="https://mathstodon.xyz/@11011110/102568139862446088"></a>). Or we could, you know, publish our papers in journals instead of conferences, like everyone else, and not need to go to quite so many conferences.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html">Why modern integer factoring algorithms have the time bounds they do, and what would be needed to improve them</a> (<a href="https://mathstodon.xyz/@11011110/102577633871564197"></a>).</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/08/08/california-scientists-pull-support-elsevier-journals">The University of California’s fight with Elsevier spills over to editorships</a> (<a href="https://mathstodon.xyz/@11011110/102584940498877427"></a>). 30 UC editors of Elsevier journals “will no longer provide editorial services” to Elsevier unless/until a satisfactory deal with Elsevier is reached.</p>
  </li>
  <li>
    <p><a href="https://senate.universityofcalifornia.edu/_files/reports/rm-jn-racialization-academic-espionage-concerns.pdf">A letter from the University of California Academic Council</a> (<a href="https://mathstodon.xyz/@11011110/102601263075559877"></a>) expressing their alarm at “the increasingly racialized ways in which international scholars and students—especially those from China, Iran, and Russia—are being targeted in national conversations about academic espionage” and their support for the open exchange of research.</p>
  </li>
  <li>
    <p><a href="https://blogs.scientificamerican.com/roots-of-unity/the-longest-matrilineal-chain-in-math/">The longest matrilineal chain in math</a> (<a href="https://mathstodon.xyz/@11011110/102604836636431847"></a>). Evelyn Lamb finds “five advisor-advisee chains of length four containing only women” in the Mathematics Genealogy Project, all starting with Olga Ladyzhenskaya and her student Nina Ivochkina. But her searches were haphazard so there may be longer ones still to find.</p>
  </li>
  <li>
    <p><a href="https://mathenchant.wordpress.com/2018/08/16/knots-and-narnias/">Knots and Narnias</a> (<a href="https://mathstodon.xyz/@11011110/102613921012752632"></a>). Riffing on a video of a Bill Thurston lecture, Jim Propp explains that when a portal to another dimension has a knotted boundary, it can actually be a portal to several other dimensions.</p>
  </li>
  <li>
    <p><a href="https://gi.de/meldung/konrad-zuse-medaille-dorothea-wagner-erhaelt-hoechste-informatik-auszeichnung/">Dorothea Wagner wins the 2019 Konrad Zuse Medal</a> (<a href="https://mathstodon.xyz/@11011110/102616186862477955"></a>). This is the highest award of the German Computer Science Society, and the first time since its establishment in 1987 that the winner is a woman. Dorothea’s research includes graph drawing, route planning, optimization, and social network analysis; see <a href="https://en.wikipedia.org/wiki/Dorothea_Wagner">her Wikipedia article</a> for more.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/new-proof-settles-how-to-approximate-numbers-like-pi-20190814/">Duffin–Schaeffer conjecture solved</a> (<a href="https://mathstodon.xyz/@11011110/102623251151301461"></a>, <a href="https://arxiv.org/abs/1907.04593">original paper</a>). This is about finding rational approximations to irrational numbers, like . Given a criterion for how good an approximation you want, depending only on the denominator (for instance, allowing only prime denominators and seeking an approximation accurate to  for denominator ) the new theorem tells you when almost all irrationals have a good-enough approximation.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/08/15/linkage.html"><span class="datestr">at August 15, 2019 04:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16151">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/08/11/leaps-and-bounds-practice-meets-theory/">Leaps and Bounds: Practice Meets Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Solving the runtime selection problem</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png"><img src="https://rjlipton.files.wordpress.com/2019/08/lucierszepesvari.png?w=180&amp;h=129" alt="" width="180" class="alignright wp-image-16153" height="129" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite from <a href="https://www.microsoft.com/en-us/research/people/brlucier/">src1</a>, <a href="https://www.microsoft.com/en-us/research/video/sparse-stochastic-bandits/">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Brendan Lucier and Csaba Szepesvári were consecutive speakers at this week’s <a href="http://www.cs.cmu.edu/~ckingsf/AutoAlg2019/">workshop</a> at the Toyota Technological Institute in Chicago on “Automated Algorithm Design.”</p>
<p>
Today I will discuss their talks, which I enjoyed greatly at the workshop.<br />
<span id="more-16151"></span></p>
<p>
The workshop’s general theme was the use of machine-learning techniques to improve the tuning of algorithms. Indeed, the goal is to have the algorithm tune itself by selecting strategies from a collection of possible ones. Besides better performance with less human work, this promises better logical reliability than with hand-tuning programs and debugging. </p>
<p>
A common component of this work used in both talks is an interesting oracle model. Since oracles are familiar to many of us theorists this will give us an avenue into the talks and the <a href="https://pdfs.semanticscholar.org/0dce/10ed863423e2e9b1b77a0becfc23111578be.pdf">two</a> recent <a href="https://arxiv.org/pdf/1807.00755.pdf">papers</a> they were based on.</p>
<p>
</p><p></p><h2> Runtime Oracles </h2><p></p>
<p></p><p>
The oracle has a nonnegative matrix <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> of shape <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \times M}" class="latex" title="{n \times M}" />. Think of the entry <img src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(i,j)}" class="latex" title="{R(i,j)}" /> as the <i>runtime</i> of the <img src="https://s0.wp.com/latex.php?latex=%7Bi%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i^{th}}" class="latex" title="{i^{th}}" /> program on the <img src="https://s0.wp.com/latex.php?latex=%7Bj%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j^{th}}" class="latex" title="{j^{th}}" /> input. You know <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, but must ask the oracle for information about <img src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(i,j)}" class="latex" title="{R(i,j)}" />. You may ask the oracle a question <img src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(i,j,t)}" class="latex" title="{(i,j,t)}" />:</p>
<blockquote><p><b> </b> <em> <i>Is the entry <img src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R(i,j)}" class="latex" title="{R(i,j)}" /> less than or equal to <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />?</i> </em>
</p></blockquote>
<p></p><p>
Here <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> is a time bound. Further they assume that the oracle charges you 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmin%28R%28i%2Cj%29%2Ct%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \min(R(i,j),t). " class="latex" title="\displaystyle  \min(R(i,j),t). " /></p>
<p>Thus an algorithm is charged in total 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bt%7D+%5Cmin%28R%28i%2Cj%29%2Ct%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{t} \min(R(i,j),t), " class="latex" title="\displaystyle  \sum_{t} \min(R(i,j),t), " /></p>
<p>where the sum is over all questions <img src="https://s0.wp.com/latex.php?latex=%7B%28i%2Cj%2Ct%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(i,j,t)}" class="latex" title="{(i,j,t)}" /> you asked. 	 The rationale is that the oracle can run a program <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> on a task <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> and stop after at most <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> steps. Thus returning the minimum is realistic. Since their research is motivated by practical problems, this is a useful model for studying questions about program performance. </p>
<p>
In passing I believe the reason this oracle model is new is that theorists do not often think about running arbitrary programs. Well those in recursion type did, but those designing classic algorithms do not. </p>
<p>
</p><p></p><h2> A Selection Problem </h2><p></p>
<p></p><p>
This model to used to study a selection problem. Assume <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> is as above. The task is to find the row with the smallest row sum <img src="https://s0.wp.com/latex.php?latex=%7Bs_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s_{i}}" class="latex" title="{s_{i}}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%3D+%5Csum_%7Bj%3D1%7D%5E%7BM%7D+R%28i%2Cj%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). " class="latex" title="\displaystyle  s_{i} = \sum_{j=1}^{M} R(i,j). " /></p>
<p>That is to find the program that takes the least total time on the inputs—hence the least average time.</p>
<p>
The trouble is that in the worst case this can require examining all the entries. So they introduce approximations to make the problem doable, but still useful in practice:</p>
<ol>
<li>
The rows need only be a <img src="https://s0.wp.com/latex.php?latex=%7B%281%2B%5Cepsilon%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1+\epsilon)}" class="latex" title="{(1+\epsilon)}" /> approximation to the smallest row. <p></p>
</li><li>
The entries can be assumed to be truncated by a value <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tau}" class="latex" title="{\tau}" />. That is you can assume that 	<p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R%28i%2Cj%29+%5Cle+%5Ctau.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  R(i,j) \le \tau. " class="latex" title="\displaystyle  R(i,j) \le \tau. " /></p>
</li><li>
The governing algorithm can be randomized and need only meet the performance goal with high probability.
</li></ol>
<p>
Now we can state the problem formally. It is parameterized by <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C+%5Ctau%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon, \tau)}" class="latex" title="{(\epsilon, \tau)}" />:</p>
<blockquote><p><b> </b> <em> <b>Runtime Selection Problem (RSP)</b>: Given a matrix <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> with all entries bounded by <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctau%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\tau}" class="latex" title="{\tau}" />, find a row <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> so that 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++s_%7Bi%7D+%5Cle+%281+%2B+%5Cepsilon%29s_%7Bk%7D%2C+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, " class="latex" title="\displaystyle  s_{i} \le (1 + \epsilon)s_{k}, " /></p>
</em><p><em>for all <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, while minimizing the oracle charges for all questions “is <img src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cleq+t%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R(i,j) \leq t}" class="latex" title="{R(i,j) \leq t}" />?” that are asked. </em>
</p></blockquote>
<p>The talks gave a variety of randomized algorithms that solve such problems for various parameter assumptions. </p>
<p>
</p><p></p><h2> Fast and Slow </h2><p></p>
<p></p><p>
See their papers for details on the results. The algorithms they have are interesting not only from a theory viewpoint but also in practice. Indeed, they not only prove theorems but also give experimental timings.</p>
<p>
In order to establish some intuition, let’s look at the following simple case. Assume that all entries <img src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(i,j)}" class="latex" title="{R(i,j)}" /> are either <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> or some <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha \gg 1}" class="latex" title="{\alpha \gg 1}" />. This is the “fast-or-slow” running time stipulation. As theorists we often are drawn to binary values, so this might be a good case to look at initially.</p>
<p>
The first observation is that we will always ask questions of the form 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28i%2C+j%2C+1.0001%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (i, j, 1.0001). " class="latex" title="\displaystyle  (i, j, 1.0001). " /></p>
<p>This gives us the value of the entry <img src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(i,j)}" class="latex" title="{R(i,j)}" /> for almost unit cost: if it is the <img src="https://s0.wp.com/latex.php?latex=%7BR%28i%2Cj%29+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(i,j) \gg 1}" class="latex" title="{R(i,j) \gg 1}" /> case then we are only charged <img src="https://s0.wp.com/latex.php?latex=%7B1.0001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1.0001}" class="latex" title="{1.0001}" />. Thus, we have reduced the original problem to a classic oracle problem. There is no complicated oracle cost measure: the cost is just the number of entries we read. Well okay the cost is slightly higher, but we can make it as close as we wish.</p>
<p>
The selection problem then comes down to this: </p>
<ul>
<li>
We have a <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Ctimes+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \times M}" class="latex" title="{n \times M}" /> nonnegative matrix <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> whose entries are all either <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />. <p></p>
</li><li>
We must find a row sum that is within a factor of <img src="https://s0.wp.com/latex.php?latex=%7B1%2B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1+\epsilon}" class="latex" title="{1+\epsilon}" /> of the smallest.
</li></ul>
<p>
I believe that the analysis of this problem should be generally known. In any event it seems clear that randomly sampling each row is a good start.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Are there other natural problems where the runtime cost oracle is useful?</p>
<p>[Edited typo]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/08/11/leaps-and-bounds-practice-meets-theory/"><span class="datestr">at August 12, 2019 02:34 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/104">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/104">TR19-104 |  Reconstruction of Depth-$4$ Multilinear Circuits | 

	Vishwas Bhargava, 

	Shubhangi Saraf, 

	Ilya Volkovich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We present a deterministic algorithm for reconstructing multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits, i.e. multilinear depth-$4$ circuits with fan-in $k$ at the top $+$ gate. For any fixed $k$, given black-box access to a polynomial $f \in \mathbb{F}[x_{1},x_{2},\ldots ,x_{n}]$ computable by a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size $s$, the algorithm runs in time quasi-poly($n,s,{|\mathbb{F}|}$) and outputs a multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuit of size quasi-poly($n,s$) that computes $f$. 

Our result solves an open problem posed in \cite{GKL12} (STOC, 2012). Indeed, prior to our work, efficient reconstruction algorithms for multilinear $\Sigma\Pi\Sigma\Pi(k)$ circuits were known only for the case of $k=2$ \cite{GKL12, Volkovich17}.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/104"><span class="datestr">at August 11, 2019 04:14 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/103">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/103">TR19-103 |  Query-to-Communication Lifting Using Low-Discrepancy Gadgets | 

	Or Meir, 

	Sajin Koroth, 

	Arkadev Chattopadhyay, 

	Toniann Pitassi, 

	Yuval Filmus</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Lifting theorems are theorems that relate the query complexity of a function $f:\left\{ 0,1 \right\}^n\to \left\{ 0,1 \right\}$ to the communication complexity of the composed function $f\circ g^n$, for some “gadget” $g:\left\{ 0,1 \right\}^b\times \left\{ 0,1 \right\}^b\to \left\{ 0,1 \right\}$. Such theorems allow transferring lower bounds from query complexity to the communication complexity, and have seen numerous applications in the recent years. In addition, such theorems can be viewed as a strong generalization of a direct-sum theorem for the gadget $g$.

We prove a new lifting theorem that works for all gadgets $g$ that have logarithmic length and exponentially-small discrepancy, for both deterministic and randomized communication complexity. Thus, we significantly increase the range of gadgets for which such lifting theorems hold.

Our result has two main motivations: First, allowing a larger variety of gadgets may support more applications. In particular, our work is the first to prove a randomized lifting theorem for logarithmic-size gadgets, thus improving some applications of the theorem. Second, our result can be seen as a strong generalization of a direct-sum theorem for functions with low discrepancy.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/103"><span class="datestr">at August 11, 2019 04:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blog.ilyaraz.org/rss/12">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ilya.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.ilyaraz.org/?go=all/cuckoo-hashing-for-sketching-sets/">Cuckoo hashing for sketching sets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><i>Sign up for the new posts via the <a href="https://blog.ilyaraz.org/rss/">RSS feed</a></i>.</p>
<p>Below I show a neat application of <a href="https://en.wikipedia.org/wiki/Perfect_hash_function">perfect hashing</a>, which is one of my favorite (cluster of) algorithms. Amazingly, we use it to obtain a purely information-theoretic (rather than algorithmic) statement.</p>
<p>Suppose we have a finite universe $U$ of size $n$ and a $k$-element subset of it $S \subseteq U$ with $k \ll n$. How many bits do we need to encode it? The obvious answer is $\log_2 \binom{n}{k} = \Theta(k \cdot \log(n / k))$.<br />
Can we, however, improve this bound if we allow some approximation?</p>
<p>Even if $n = 2k$, it is not difficult to show the lower bound of $k \cdot \log_2(1 / \delta)$ bits if we allow to be wrong when answering queries “does $x$ belong to $S$?” with probability at most $\delta$ (hint: $\varepsilon$-nets). Can we match this lower bound?</p>
<p>One approach that does not quite work is to hash each element of $S$ to an $l$-bit string using a sufficiently good hash function $h \colon U \to \{0, 1\}^l$, and, when checking if $x$ lies in $S$, compute $h(x)$ and check if this value is among the hashes of $S$. To see why it does not work, let us analyze it: if $x \notin S$, then the probability that $h(x)$ coincides with at least one hash of an element of $S$ is around $k \cdot 2^{-l}$. To make the latter less than $\delta$, we need to take $l = \log_2(k / \delta)$ yielding the overall bound of $k \cdot \log_2(k / \delta)$ falling short of the desired size.</p>
<p>To get the optimal size, we need to avoid using the union bound in the above argument. In order to accomplish this, let us use perfect hashing on top of the above hashing scheme! It is convenient to use a particular approach to perfect hashing called <a href="https://en.wikipedia.org/wiki/Cuckoo_hashing">Cuckoo hashing</a>. In short, there is a way to generate two simple hash functions $h_1, h_2 \in U \to [m]$ for $m = O(k)$ and place the elements of our set $S$ into $m$ bins without collisions so that for every $x \in S$, the element $x$ is placed either in $h_1(x)$ or in $h_2(x)$. Now, to encode our set $S$, we build a Cuckoo hash table for it, and then for each of the $m$ bins, we either store one bit indicating that it’s empty, or store an $l$-bit hash of an element that is placed into it. Now we can set $l = \log_2(2 / \delta)$, since we compare the hash of a query to merely two hashes, instead of $k$. This gives the overall size $m + k \cdot \log_2 (2 / \delta) = k \cdot (\log_2(1 / \delta) + O(1))$, which is optimal up to a low-order term. Of course, the encoding should include $h_1$, $h_2$ and $h$, but it turns out they can be taken to be sufficiently simple so that their size does not really matter.</p>
<p>Two remarks are in order. First, in this context people usually bring up <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom filters</a>. However, they require space, which is $1.44$ times bigger, and, arguably, they are more mysterious (if technically simple). Second, one may naturally wonder why anyone would care about distinguishing bounds like $k \cdot \log_2 (1 / \delta)$ and $k \cdot \log_2(k / \delta)$. In my opinion, there are two answers to this. First, it is just a cool application of perfect hashing (an obligatory link to <a href="https://www.smbc-comics.com/comic/2010-12-09">one of my favorite comic strips</a>). Second, compressing sets is actually important in practice and constant factors do matter, for instance when we are aiming to transfer the set over the network.</p>
<p><b>Update</b> <a href="https://cs.au.dk/~larsen/">Kasper Green Larsen</a> observed that we can combine the naive and not-quite-working solutions to obtain the optimal bound. Namely, by hashing everything to $\log_2(k / \delta)$ bits, we effectively reduce the universe size to $n’ = k / \delta$. Then, the naive encoding takes $\log_2 \binom{n’}{k} \approx H(\delta) \cdot n’ = H(\delta) \cdot k / \delta \approx<br />
k \cdot \log_2 (1 / \delta)$ bits.</p></div>







<p class="date">
<a href="https://blog.ilyaraz.org/?go=all/cuckoo-hashing-for-sketching-sets/"><span class="datestr">at August 11, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/102">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/102">TR19-102 |  Testing Isomorphism in the Bounded-Degree Graph Model | 

	Oded Goldreich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We consider two versions of the problem of testing graph isomorphism in the bounded-degree graph model: A version in which one graph is fixed, and a version in which the input consists of two graphs.
We essentially determine the query complexity of these testing problems in the special case of $n$-vertex graphs with connected components of size at most $\poly(\log n)$. 
This is done by showing that these problems are computationally equivalent (up to polylogarithmic factors) to corresponding problems regarding isomorphism between sequences (over a large alphabet). 
Ignoring the dependence on the proximity parameter, our main results are: 
\begin{enumerate}
\item 
The query complexity of testing isomorphism to a fixed object (i.e., an $n$-vertex graph or an $n$-long sequence) is ${\widetilde{\Theta}(n^{1/2})$. 
\item 
The query complexity of testing isomorphism between two input objects is ${\widetilde{\Theta}}(n^{2/3})$. 
\end{enumerate}
Testing isomorphism between two sequences is shown to be related to testing that two distributions are equivalent, and this relation yields reductions in three of the four relevant cases. 
Failing to reduce the problem of testing the equivalence of two distribution to the problem of testing isomorphism between two sequences, we adapt the proof of the lower bound on the complexity of the first problem to the second problem.
This adaptation constitutes the main technical contribution of the current work. 

Determining the complexity of testing graph isomorphism (in the bounded-degree graph model), in the general case (i.e., for arbitrary bounded-degree graphs), is left open.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/102"><span class="datestr">at August 10, 2019 04:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/08/10/report-from-cccg">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/08/10/report-from-cccg.html">Report from CCCG</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>After <a href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html">WADS</a>, I stayed in Edmonton for <a href="https://sites.ualberta.ca/~cccg2019/">CCCG</a>. The two conferences have not always been in the same places, but this year they were co-located, and the plan is to continue that pattern in odd years (when WADS is held). As far as I know there are no plans to move CCCG to Scandinavia for SWAT in the even years.</p>

<p>Like WADS, CCCG had three invited speakers. In past years, two were named the Paul Erdős Memorial Lecture and the Ferran Hurtado Memorial Lecture. This year, sadly, the third one has also been named, as the Godfried Toussaint Memorial Lecture.</p>

<ul>
  <li>
    <p>The Erdős Lecture was by Vida Dujmović, who spoke on her breakthrough work with several other Barbados workshop participants showing that <a href="https://arxiv.org/abs/1904.04791">every planar graph is a subgraph of a strong product of a path graph and a bounded-pathwidth graph</a>, from which it follows that these graphs have bounded <a href="https://en.wikipedia.org/wiki/Queue_number">queue number</a>, that they can be embedded into 3d grids of linear volume, and many other nice properties. The timing of the lecture invitation to Vida was good, as the breakthrough happened after she had already agreed to speak!</p>
  </li>
  <li>
    <p>The Toussaint Lecture was by Joseph O’Rourke. Joe spoke on <a href="https://en.wikipedia.org/wiki/Net_(polyhedron)">polyhedral unfolding</a>, the problem of cutting the boundary of a polyhedron into a surface that can unfold into a simple polygon in the plane. One of the points of his talk was to rationalize some of the terminology in this area. The standard version of the problem asks for (in his new terminology) an <em>edge-unfolding</em>, a set of cuts along edges of the polyhedron, forming a spanning tree for its vertices, such that the resulting cut surface unfolds to a flat polygon. But one can also ask for an anycut-unfolding, using cuts that do not have to follow the edges. Or one can ask for an edge-unzipping or anycut-unzipping, in which the cuts must form a single (Hamiltonian) path through the vertices of the polyhedron. In this terminology <a href="http://www.openproblemgarden.org/op/d_urers_conjecture">Dürer’s conjecture</a> becomes the statement that every convex polyhedron has an edge-unfolding, and the example I recently posted of a <a href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html">zipless polycube</a> shows that not every polycube has an edge-unzipping. Another well-known open question in this area asks whether every polycube whose boundary forms a topological sphere has an edge-unfolding. Joe conjectured that with high probability the convex hull of many random points on a sphere does not have an anycut-unzipping.</p>
  </li>
  <li>
    <p>Mark de Berg presented the Hurtado Lecture. His topic involved subexponential algorithms for disk intersection graphs and <a href="https://en.wikipedia.org/wiki/Unit_disk_graph">unit disk graphs</a>. At STOC 2018 he had a paper on <a href="https://arxiv.org/abs/1803.10633">finding the maximum independent set in disk graphs</a> in time , matching the time for planar graphs. In planar graphs, you can use the <a href="https://en.wikipedia.org/wiki/Planar_separator_theorem">planar separator theorem</a>: for each of the  independent subsets of the separator, recurse on both sides. This turns out to work in disk graphs by replacing the usual size bound on the separator (it should have  vertices) with a decomposition into a union of cliques  with . The separators can be found analogously to classical circle-packing methods for planar separators. Each clique can contribute one vertex to any independent set from which it follows that the separator again has  independent subsets. The same idea works for other problems like dominating sets in unit disk graphs (where the unit assumption is used to get a bounded contribution from each clique), and generalizes to fat objects in higher dimensions. The time bound is optimal assuming the <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">exponential time hypothesis</a>. And in FOCS 2018 de Berg obtained similar <a href="https://arxiv.org/abs/1807.06933">ETH-tight time bounds for the Euclidean traveling salesperson problem</a> by using separators of point sets with the property that few points are very close to the separator boundary.</p>
  </li>
</ul>

<p>I can’t find links for all the contributed papers, but you can find them in the <a href="https://sites.ualberta.ca/~cccg2019/cccg2019_proceedings.pdf">complete proceedings</a>. Among them:</p>

<ul>
  <li>
    <p>In “Three-Coloring Three-Dimensional Uniform Hypergraphs”, Biniaz, Bose, Cardinal, and Payne prove that, for  points in the plane and a fixed triangle shape, one can -color the points so that every scaled and translated copy of the triangle containing six or more points has more than one color. It was already known that if you change “six or more” to “two or more” you need four colors, and if you change it to “nine or more” you need only two colors.</p>
  </li>
  <li>
    <p>Audrey St. John’s talk on “Redundant Persistent Acyclic Formations for Vision-Based Control of Distributed Multi-Agent Formations” (with Burns, Klemperer, and Solyst) was beset by technical difficulties, but from it I learned that there is a theory of directed bar-and-joint frameworks, analogous to undirected rigidity theory, called “persistence theory”, and that the <a href="https://11011110.github.io/blog/2013/12/07/kinematic-chains-and.html">pebble game</a> for testing rigidity of an undirected framework produces an orientation of the network that is persistent. She used the analogy of a flock of geese, walking in formation: each goose pays attention only to the other geese in front, but the whole formation can keep its shape as the leading goose moves arbitrarily. Her goal is to get robots to do the same thing.</p>
  </li>
  <li>
    <p>In “Chirotopes of Random Points in Space are Realizable on a Small Integer Grid”, Cardinal, Fabila-Monroy and Hidalgo-Toscano prove that, with high probability, random point sets in  can be rounded to a grid of polynomial size without changing their order type.</p>
  </li>
  <li>
    <p>We had enough folding and unfolding papers to spill out over more than one section. Among them, I particularly liked “Efficient Segment Folding is Hard” by Klute, Parada, Horiyama, Korman, Uehara and Yamanaka. The question they asked is: given disjoint line segments on a piece of paper, when can you make a sequence of simple folds (that is, for a given fold line, folding all the layers of the paper that are crossed by the line), with each fold on a line through one of the segments that misses all the other segments? It turns out to be -complete. If you do allow fold lines to pass through other segments, folding sequences can be infinite, and it’s unknown whether every set of segments has a finite sequence.</p>
  </li>
  <li>
    <p>Pilar Cano spoke on generating triangulations of point sets in an affine-invariant way (“Affine invariant triangulations” with Bose and Silveira). The main trick is to use covariance to choose a canonical affine transformation for the points, after which you can use Delaunay, minimum weight, or your favorite other triangulation algorithm. But there are necessarily some general position assumptions (as there already are for using Delaunay triangulation without the affine invariance): for points in a parallelogram, there is no affine-invariant way of choosing which diagonal to use.</p>
  </li>
</ul>

<p>The excursion was to the <a href="https://royalalbertamuseum.ca/">Royal Alberta Museum</a>, where I skipped the special exhibit on Vikings (having gone to museum exhibits on them in Copenhagen a year earlier) and instead learned much about Great Plains geology and the historical mistreatment of the <a href="https://en.wikipedia.org/wiki/M%C3%A9tis">Métis</a>, local people descending both from First Nations and Europeans. (The First Nations themselves were of course also badly mistreated, but I had more of an idea of that already.)</p>

<p>From the business meeting, we heard that the acceptance ratio was a little higher than last year, but still approximately . Two papers were withdrawn because the authors had visa issues, double the number from last year, and several others were presented by non-authors after their authors were unable to attend. One possible improvement would be to move the submission and acceptance dates earlier to provide authors more time to obtain visas. The main topic of discussion was the conference’s status as a conference: should papers at CCCG continue to count as publications (in which case why are they still limited to only six pages) or should they be considered as preliminary announcements of papers that can still be sent to other more prestigious symposia? One possible compromise involves giving authors a choice: either publish your paper in the proceedings or give up the proceedings slot but still present your work in some other way (possibly as a poster, as GD does).</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102595225020207137">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/08/10/report-from-cccg.html"><span class="datestr">at August 10, 2019 03:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/08/09/university-alberta-botanic">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/08/09/university-alberta-botanic.html">University of Alberta Botanic Gardens</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The WADS excursion was to the University of Alberta Botanic Gardens.
Here are a few photos I took there:</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanSourceFountain.html"><img width="300" alt="University of Alberta Botanic Gardens, Aga Khan Garden, Source Fountain" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanSourceFountain-m.jpg" /></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanJilauKhana.html"><img width="405" alt="University of Alberta Botanic Gardens, Aga Khan Garden, Jilau Khana" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanJilauKhana-m.jpg" /></a></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanMahtabi.html"><img width="390" alt="University of Alberta Botanic Gardens, Aga Khan Garden, Mahtabi" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/uabg/AgaKhanMahtabi-m.jpg" /></a></td>
<td style="padding: 10px;"><a href="http://www.ics.uci.edu/~eppstein/pix/uabg/WetlandWalkMaysDock.html"><img width="385" alt="University of Alberta Botanic Gardens, Wetland Walk, May's Dock" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/uabg/WetlandWalkMaysDock-m.jpg" /></a></td>
</tr></tbody></table></div>

<p>(<a href="https://mathstodon.xyz/@11011110/102588301669141700">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/08/09/university-alberta-botanic.html"><span class="datestr">at August 09, 2019 11:46 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17820">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/">Two Important Quantum Announcements!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I am very happy to announce two quantum events. First, I would like to announce a course “Computation, quantization, symplectic geometry, and information” in the first 2019/2020 semester  at the Hebrew University of Jerusalem (HUJI). The course will by on Sundays 14:00-16:00. Second, I would also like to announce The 4th Advanced School in Computer Science and Engineering on <a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation </a> on December 15 – December 19, 2019, at IIAS HUJI.</p>
<h2><a href="https://gilkalai.files.wordpress.com/2019/08/ghen.png"><img src="https://gilkalai.files.wordpress.com/2019/08/ghen.png?w=300&amp;h=190" alt="" width="300" class="alignnone size-medium wp-image-17833" height="190" /></a></h2>
<p><span style="color: #ff0000;">Emmy Noether (left) Grete Hermann (right)</span></p>
<h2>A quantum “Kazhdan’s seminar” at HUJI: Computation, quantization, symplectic geometry, and information.</h2>
<p>“In the fall of 2019 Dorit Aharonov, Gil Kalai, Guy Kindler and Leonid Polterovich intend to run a new one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.  The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. (See below for a full description.)”</p>
<p>The course will by on Sundays 14:00-16:00 in Ross building.</p>
<p>See also the post  <a href="https://gilkalai.wordpress.com/2013/01/01/symplectic-geometry-quantization-and-quantum-noise/" rel="bookmark">Symplectic Geometry, Quantization, and Quantum Noise</a> from January 2013. (The seminar was initially planned to 2014 but some bumps in the road delayed it to 2019.)</p>
<h2>A winter school at IIAS: The Mathematics of Quantum Computation</h2>
<p><a href="http://ias.huji.ac.il/SchoolCSE4">The Mathematics of Quantum Computation</a><br />
The 4th Advanced School in Computer Science and Engineering<br />
Event date: December 15 – December 19, 2019</p>
<p>“We will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area. (See below for a full description.)</p>
<p>Organizers: Dorit Aharonov, Zvika Brakerski, Or Sattath, Amnon Ta-Shma,</p>
<p dir="LTR"><strong>Main (confirmed) Speakers: </strong>Sergey Bravyi, Matthias Christandl, Sandy Irani, Avishay Tal, Thomas Vidick, (1-2 additional speakers may be added later).</p>
<p dir="LTR"><strong>Additional (confirmed) lectures will be given by: </strong>Dorit Aharonov,  Zvika Brakerski,  and/ Or Sattath. (1-2 additional speakers may be added later).”</p>
<p dir="LTR">The Isreali Institute of Advanced Study hosted already a 2014 <a href="http://www.as.huji.ac.il/schools/phys31">school about quantum information</a> as part of its legendary physics series of schools, and also hosted <a href="https://gilkalai.wordpress.com/2013/04/12/qstart/">QSTART</a> in 2013.</p>
<h2>More details</h2>
<p><span id="more-17820"></span></p>
<h3><strong><span style="color: #ff0000;">Kazhdan’s seminar: Computation, quantization, symplectic geometry, and information.</span></strong></h3>
<p>In the fall of 2019 Aharonov, Kalai, Kindler and Polterovich intend to run a new<br />
one semester course (as a Kazhdan seminar) attempting to connect questions about noise and complexity in quantum computation, with ideas and methods about “classical-quantum correspondence”.that are well studied in symplectic geometry. The course will be<br />
highly research-oriented, and will attempt to teach the basics in both areas, and define and clarify the interesting research questions related to the connections between these areas, with the hope that this will lead to interesting insights.</p>
<p>The course is oriented to grad students (and faculty), with reasonable background in mathematics, and with interest in the connections between mathematical and computational aspects of quantum mechanics. Students who attend it will be awarded two N”Z after passing an exam. The goal of the course is to initiate and lead to new connections between the seemingly unrelated areas of quantum computation and symplectic geometry.</p>
<p>The topics will include:</p>
<p>– Introduction to quantum computation, quantum universality, quantum algorithms<br />
and quantum computational complexity classes such as BQP and Quantum NP (QMA)</p>
<p>– quantum measurement and quantum noise explained using the standard quantum computational model.</p>
<p>– questions about quantum error correction and quantum noise – fault tolerance,<br />
quantum error correcting codes, and the breakdown of robustness when the locality of<br />
the noise does not hold.</p>
<p>– quantum measurement/quantum information (noise and speed limit) having classical counterparts, studied from the symplectic geometry perspective.</p>
<p>– Konsevich theorem and quantization,</p>
<p>– towards a the semi classical approximation of quantum computers.</p>
<p>Examples of questions we would like to initiate research on are:</p>
<p>1) what would be a semi classical model of quantum computation, and what would be<br />
its computational power?</p>
<p>2) what is a good notion of complexity in a symplextic geometry computational model?</p>
<p>3) What can we learn from basic symplectic geometry results (such as non squeezing)<br />
about the limitations on quantum computation in the semi classical limit?</p>
<p>4) Can noise in quantum computation be related in any way with the semi classical limit<br />
of quantum computing systems?</p>
<p>5) can we learn anything about the possible noise models in quantum computers,<br />
using our knowledge from symplectic geometry?</p>
<p>Hope to see you in the course!</p>
<h3><span style="color: #ff0000;"><strong>The Mathematics of Quantum Computation -The 4th Advanced School in Computer Science and Engineering</strong></span></h3>
<p>On 15-19 December 2019, we will be organizing a math-oriented quantum computation school in the IIAS at the Hebrew university. No prior knowledge on quantum will be assumed.  The school will introduce TCS and math students and faculty, who are interested in the more mathematical side of the area, to the beautiful and fascinating mathematical open questions in quantum computation, starting from scratch. We hope to reach a point where participants gain initial tools and basic perspective to start working in this area.</p>
<p>To achieve this, we will have several mini-courses, each of two or three hours, about central topics in the area.   These will include quantum algorithms, quantum error correction, quantum supremacy, delegation and verification, interactive proofs, cryptography, and Hamiltonian complexity. We will emphasize concepts, open questions, and links to mathematics. We will have daily TA sessions with hands-on exercises, to allow for a serious process of learning.</p>
<p>There will be two rounds of registration. The first deadline is 23rd of August. If there is room, there will be another deadline sometime in October; please follow <a href="http://ias.huji.ac.il/SchoolCSE4">this page</a> for further announcements.</p>
<p>Hope to see you this coming December!</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/08/09/two-important-quantum-announcements/"><span class="datestr">at August 09, 2019 08:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/">Complexity Postdoctoral Fellowship at Santa Fe Institute (apply by October 27, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The SFI Complexity Postdoctoral Fellowships offer early-career scholars the opportunity to join a collaborative research community that nurtures creative, transdisciplinary thought in pursuit of key insights about the complex systems that matter most for science &amp; society. SFI offers a competitive salary, discretionary research/travel funds, paid family leave, &amp; professional development.</p>
<p>Website: <a href="https://santafe.edu/sfifellowship">https://santafe.edu/sfifellowship</a><br />
Email: sfifellowship@santafe.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/08/08/complexity-postdoctoral-fellowship-at-santa-fe-institute-apply-by-october-27-2019/"><span class="datestr">at August 08, 2019 07:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/">Faculty at Chennai Mathematical Institute, Chennai, India. (apply by September 30, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>We are looking for faculty in the areas of Optimization, Algorithms, Machine learning, Data Sciences, Cryptography, Quantum computing/ information, Complexity theory, Formal Verification, Logic and Automata.</p>
<p>Website: <a href="http://www.cmi.ac.in">http://www.cmi.ac.in</a><br />
Email: registrar@cmi.ac.in</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/08/08/faculty-at-chennai-mathematical-institute-chennai-india-apply-by-september-30-2019/"><span class="datestr">at August 08, 2019 03:48 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-337501791513204418">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html">Obstacles to improving Classical Factoring Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In Samuel Wagstaff's excellent book The Joy of Factoring (see <a href="https://mathcs.clarku.edu/~fgreen/SIGACTReviews/bookrev/47-2.pdf">here</a> for a review) there is a discussion towards the end about why factoring algorithms have not made much progress recently. I<br />
paraphrase it:<br />
<br />
<br />
--------------------------------------------------------<br />
<br />
The time complexities of the fastest known algorithms can be expressed as a formula of the following form (where N is the number to be factored):<br />
<br />
(*)                      exp(c(ln N)^t (ln(ln N))^{1-t})<br />
<br />
for some constants c and for 0 &lt; t &lt; 1.  For the Quadratic Sieve (QS) and Elliptic Curve Method (ECM) t=1/2. For the Number Field Sieve (NFS) t=1/3. The reason for this shape for the time complexity is the requirement of finding one or more smooth numbers (numbers that have only small primes as factors).<br />
<br />
----------------------------------------------------------<br />
<br />
This got me thinking: Okay, there may not be a drastic improvement anytime soon but what about just improving t? Is there a mathematical reason<br />
why an algorithm with (say) t=1/4 has not been discovered? In an earlier era I would have had to write a letter to Dr. Wagstaff to ask him. Buy an envelope, buy a  stamp, find his address, the whole nine yards (my younger readers should ask their grandparents what envelopes and stamps were). In the current era I emailed him. And got a response.<br />
<br />
<br />
Samuel Wagstaff:<br />
<br />
The fastest known factoring algorithms find smooth numbers subject to parameter choice(s).  In all these algorithms, one parameter choice is the smoothness bound B:  a number is smooth if all its prime factors are &lt; B. The NFS has the degree of a polynomial as an additional parameter.<br />
<br />
One analyzes the complexity of these algorithms by estimating the total work required (to find enough smooth numbers) for an arbitrary parameter choice using Dickman's function to predict the density of smooth numbers.  Then one uses calculus to find the parameter choice(s) that minimize the total work function.  Calculus also yields the optimal values for the parameter(s).<br />
<br />
If you have k parameters to choose, you will get the time complexity (*) with t = 1/(1+k).  If you have no parameters (k = 0),you get (*) with t = 1, basically exponential time N^c.  With one parameter to optimize, as in CFRAC  (continued fractions algorithm) and QS, you get t = 1/2.  NFS has two parameters, so t = 1/3. ECM also has t = 1/2 because it uses only one parameter, the smoothness bound B. If you want to get t = 1/4, you have to find a third parameter to optimize.  No one has found one yet. That is the answer to your question.<br />
<br />
Note that some choices made in some factoring algorithms don't count as parameters.  For example, the number of polynomials used in the multiple-polynomial quadratic sieve, and the upper bound on large primes kept, don't affect t.  They affect the running time only in making c smaller.  So you have to find a third parameter that matters in order to get (*) with t = 1/4.  Or find three completely different new parameters.<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/08/obstacles-to-improving-classical.html"><span class="datestr">at August 07, 2019 07:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/08/07/report-from-wads">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html">Report from WADS</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I’m in Edmonton, Canada for <a href="http://wads.org/">WADS</a>, which just finished, and <a href="http://cccg.ca/">CCCG</a>, which is just about to begin.</p>

<p>The three invited talks at WADS were by Rasmus Pagh, Bob Tarjan, and me. Pagh spoke on methods for representing sets of elements by concise sketches so that the size of intersections or unions of the sets could be rapidly and accurately estimated. A famous method for this is <a href="https://en.wikipedia.org/wiki/MinHash">MinHash</a>, in which one represents a set by the  elements with the smallest values of some hash function; the size of the overlap in representations is then an accurate estimator for the <a href="https://en.wikipedia.org/wiki/Jaccard_index">Jaccard similarity</a> of pairs of sets. New to me were -bit variations of MinHash, in which you can get almost as accurate a representation in much less space by mapping each element of the MinHash set to  by another hash function. This works well when the Jaccard similarity is bounded away from both  and , and Pagh spoke about some recent research he and others had done on finding even more accurate methods when it is near  or near .</p>

<p>Tarjan spoke about <a href="https://arxiv.org/abs/1812.06177">parallel algorithms for connected components in graphs</a>, an old area but one in which apparently there have been frequent published mistakes. He presented a modular analysis of the algorithms in this area according to some basic operations they perform (hooking together roots of trees on components, propagating that root information downwards through the trees, flattening the trees to make the information propagate more quickly, and the like) and showed that simple combinations of these operations lead to new, simple, efficient and more importantly provably-correct algorithms.</p>

<p>My talk, “Graphs in Nature”, was about finding graph-theoretic characterizations of surface-embedded graphs arising in natural processes, and using those characterizations to find algorithms to reconstruct synthetic geometric structures of the same type from their graphs. I also gave roughly the same talk a month earlier, at the Symposium on Geometry Processing in Milan. <a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-WADS-19.pdf">I’ve put my talk slides online</a> in case anyone else is interested.</p>

<p>The best paper award went to Hüseyin Acan, Sankardeep Chakraborty, Seungbum Jo and Srinivasa Rao Satti for their paper “<a href="https://arxiv.org/abs/1902.09228">Succinct Data Structures for Families of Interval Graphs</a>”. I can’t tell you much about the talk because, unfortunately, I missed it. I didn’t know it was the best paper until the business meeting that evening, so I went to the other parallel session instead.</p>

<p>I think the contributed talk from Tuesday that most stood out to me was Bryce Sandlund’s, on offline dynamic graph algorithms. This is a type of problem <a href="https://doi.org/10.1006/jagm.1994.1033">I worked on long ago for minimum spanning trees</a> in which you get as input a whole sequence of edge insertions and deletions in a graph, and must produce as output the sequence of changes to the solution to whatever you’re trying to solve. <a href="http://doi.org/10.1007/978-3-030-24766-9_40">Bryce’s new paper with Peng and Sleator</a> solves similar problems for higher-order graph connectivity. The main idea is to hierarchically decompose the update sequence into intervals, and then represent the non-dynamic part of the graph within each interval by a smaller equivalent replacement graph whose size is proportional to the interval length. At the end of his talk, Bryce hinted that he could also solve incremental problems (where the updates are given one at a time rather than all in advance, but are only insertions) using similar methods in a forthcoming paper.</p>

<p>I was inspired by Caleb Levy’s talk on <a href="https://en.wikipedia.org/wiki/Splay_tree">splay trees</a> (in which he showed that <a href="https://arxiv.org/abs/1907.06309">inserting elements in either the preorder or postorder of another binary search tree takes linear time</a>) to ask the following question: we know either by time-reversing the tree rotation operations or from the <a href="https://en.wikipedia.org/wiki/Geometry_of_binary_search_trees">geometric model of dynamic search trees</a> that any given access sequence should have the same optimal cost as its reverse. So from the <a href="https://en.wikipedia.org/wiki/Optimal_binary_search_tree">dynamic optimality conjecture</a> it should also be true that (up to constant factors) splay trees have the same performance on the reverse of any access sequence as they do on the unreversed sequence. Can this be proven?</p>

<p>From the business meeting, we learned that attendance and paper submissions were down by around 15% from the previous WADS. The acceptance rate is roughly the same, just under 50%. I suspect the smaller size is because the location is not as appealing, but it turns out to be a perfectly pleasant place to have a conference: the weather in Edmonton is pleasant this time of year (except for the thunderstorm), and there are abundant restaurants, good coffee shops, and lodging within walking distance of the conference center. WADS alternates with SWAT, which next year will be in the Faroe Islands. And then WADS 2021 (and CCCG 2021) will be in Halifax, Nova Scotia, which is both more touristy than Edmonton and easier to reach from the east coast and Europe. So I suspect the numbers will improve again.</p>

<p>WADS is moving towards a more democratically elected steering committee formed from some combination of past PC chairs and at-large elections. They have already started implementing the <a href="https://www.ics.uci.edu/~irani/safetoc.html">SafeTOC recommendations</a> for combatting harassment and discrimination in theory conferences. And in a show of hands at the business meeting, the attendees were strongly in favor of moving towards double blind peer review for submissions. The conference is not really open access, though (its proceedings are published by Springer LNCS with special issues in Springer’s <em>Algorithmica</em> and Elsevier’s <em>Computational Geometry</em>) and there seems to be little pressure for that to change any time soon.</p>

<p>On to CCCG!</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102578298917323647">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/08/07/report-from-wads.html"><span class="datestr">at August 07, 2019 05:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16143">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/08/06/code-it-up/">Code It Up</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>So you think you have a proof that P=NP</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png"><img src="https://dickken.files.wordpress.com/2019/08/anhonestliarposter.png?w=144&amp;h=192" alt="" width="144" class="alignright wp-image-18" height="192" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Randi 2014 documentary <a href="https://en.wikipedia.org/wiki/An_Honest_Liar">source</a></font></td>
</tr>
</tbody>
</table>
<p>
James Randi is a magician who has challenged paranormal claims of all kinds.</p>
<p>
Today Ken and I want to make a suggestion to those who claim they have proved P=NP.<br />
<span id="more-16143"></span></p>
<p>
No the claim to have a proof that P=NP is not a paranormal claim. But such claims are related to Randi—or the Amazing Randi as he is called. We talked about him before <a href="https://rjlipton.wordpress.com/2012/02/23/an-amazing-result/">here</a>.</p>
<p>
Randi once helped run a contest to see who could find gold with their dowsing rod. He explained why he doubted one contestant: </p>
<blockquote><p><b> </b> <em> If they really could find gold, why were they dressed so poorly, and why were they so interested in winning the prize? </em>
</p></blockquote>
<p></p><p>
I have the same question about those who claim that they have a proof that P=NP. Usually the proof is constructive and I agree with Randi:</p>
<blockquote><p><b> </b> <em> If they really could solve P=NP, why <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /> </em>
</p></blockquote>
<p></p><p>
You get the idea.</p>
<p>
Ken adds the obvious remark that if a foreign power or intelligence agency discovered P=NP, or factoring in P, they would still keep the lean-and-hungry look. But they are not the kind we are addressing here.</p>
<p>
</p><p></p><h2> Coding Helps </h2><p></p>
<p></p><p>
Let’s look at a claims that P=NP is resolved. Yes, such a result is unlikely—many would say impossible. But we do get claims like this:</p>
<blockquote><p><b> </b> <em> The following <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\cal H}" class="latex" title="{\cal H}" /> is known to be a NP-complete problem; the following <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\cal E}" class="latex" title="{\cal E}" /> is known to be a polynomial time problem. I can reduce <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\cal H}" class="latex" title="{\cal H}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\cal E}" class="latex" title="{\cal E}" /> in polynomial time. </em>
</p></blockquote>
<p></p><p>
Usually the reduction is the reason their proof fails. Their claims about <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal H}" class="latex" title="{\cal H}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccal+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cal E}" class="latex" title="{\cal E}" /> are usually correct, since they are in the literature. </p>
<p>
The reduction is often complicated, often poorly defined, often defined by example. Giving a precise definition for the reduction is critical. This is the reason we suggest the following: </p>
<blockquote><p><b> </b> <em> <i>Write the reduction down in code.</i> </em>
</p></blockquote>
<p>Even better, write it as a program in a real language such as Python. </p>
<p>
There are two advantages in doing this. </p>
<ul>
<li>
Writing it as a program in a real language will likely force one to define it precisely. <p></p>
</li><li>
Writing it down will also allow one to run the program on examples.
</li></ul>
<p>
The later point is the key point. Even trying your method on tiny examples is useful. Even better if you can say the following we might read the proof: </p>
<blockquote><p><b> </b> <em> <i>I have tried my code on the following public set of difficult SAT problems. The code solved all in less than three minutes each.</i> </em>
</p></blockquote>
<p>This claim would greatly improve the likelihood that people might take your claims seriously. That your code worked correctly, forgetting the running time, would improve confidence. Greatly. </p>
<p>
</p><p></p><h2> The Animal Farm View<img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /> </h2><p></p>
<p></p><p>
Ken worries that some NP-complete problems are more equal than others. That is some problems, even though they are NP-complete may require reductions that blow up when encoding SAT. </p>
<p>
We wrote about this <a href="https://rjlipton.wordpress.com/2012/04/22/the-travelling-salesmans-power/">before</a> regarding the “Power Index” idea of Richard Stearns and Harry Hunt III. In their <a href="http://www.cs.albany.edu/~res/powerindex.pdf">paper</a> they gave evidence that the reductions from SAT <em>to</em> many familiar NP-complete problems <em>must</em> expand the size of instances quadratically, insofar as those problems have <em>power index</em> <img src="https://s0.wp.com/latex.php?latex=%7B0.5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0.5}" class="latex" title="{0.5}" />. This was based on their “SAT Hypothesis” which anticipated current forms of the Exponential Time Hypothesis, which we have <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">discussed</a>.</p>
<p>
Ken ponders a related issue. Even problems with power index <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> run into the success of practical solvers. This means: </p>
<blockquote><p><b> </b> <em> Anyone citing algorithmic success as evidence toward a claim of P=NP must compete with the real-world success of algorithms that do not represent claims of P=NP. </em>
</p></blockquote>
<p></p><p>
We have <a href="https://rjlipton.wordpress.com/2014/02/28/practically-pnp/">several</a> <a href="https://rjlipton.wordpress.com/2015/10/22/rankings-versus-ratings/">times</a> <a href="https://rjlipton.wordpress.com/2016/07/10/the-world-turned-upside-down/">discussed</a> the practical success of SAT-solvers on myriad real-world instances. </p>
<p>
This situation has become real in the argument over achieving quantum <a href="https://en.wikipedia.org/wiki/Quantum_supremacy">supremacy</a>. One who claims that quantum is superior to classic must worry that that classical algorithms can improve without making P=NP. A headline example from last year was when Ewin Tang—as a high-school senior—<a href="https://arxiv.org/abs/1807.04271">found</a> a classical way to remove a plausible quantum advantage in a matrix-completion problem that <a href="https://www.quantamagazine.org/teenager-finds-classical-alternative-to-quantum-recommendation-algorithm-20180731/">underlies</a> recommender systems.  There are many “industrial strength” examples in this argument—see this May 2019 <a href="https://www.technologyreview.com/s/613507/the-new-benchmark-quantum-computers-must-beat-to-achieve-quantum-supremacy/">story</a> for a start.</p>
<p>
</p><p></p><h2> But… </h2><p></p>
<p></p><p>
Ken’s insightful comments aside, the key point is still: </p>
<blockquote><p><b> </b> <em> <i>Coding up your claimed algorithm for that NP-complete problem will still enhance belief.</i> </em>
</p></blockquote>
<p>This will happen even if the algorithm only succeeds on tiny examples. Indeed, if you cannot do this then I suggest that you will have an impossible time getting anyone to listen.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
How useful is this advice for the vast majority of us who are <em>not</em> claiming P=NP or the opposite?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/08/06/code-it-up/"><span class="datestr">at August 06, 2019 08:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/08/06/machine-learning-for-communication-systems-and-networks/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/08/06/machine-learning-for-communication-systems-and-networks/">Machine Learning for Communication Systems and Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
September 2-4, 2019 Trinity College Dublin, Dublin, Ireland https://connectcentre.ie/summer-school/ The Summer School will include a technical track with lectures and workshops on various aspects of Machine Learning, as well as associated training in areas such as research ethics, career development, communicating research, innovation, and public engagement. It will also include social and networking events. Speakers … <a href="https://cstheory-events.org/2019/08/06/machine-learning-for-communication-systems-and-networks/" class="more-link">Continue reading <span class="screen-reader-text">Machine Learning for Communication Systems and Networks</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/08/06/machine-learning-for-communication-systems-and-networks/"><span class="datestr">at August 06, 2019 06:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/101">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/101">TR19-101 |  Streaming Verification of Graph Computations via Graph Structure | 

	Amit Chakrabarti, 

	Prantar Ghosh</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give new algorithms in the annotated data streaming setting---also known as verifiable data stream computation---for certain graph problems. This setting is meant to model outsourced computation, where a space-bounded verifier limited to sequential data access seeks to overcome its computational limitations by engaging a powerful prover, without needing to trust the prover. As is well established, several problems that admit no sublinear-space algorithms under traditional streaming do allow protocols using a sublinear amount of prover/verifier communication and sublinear-space verification.  We give algorithms for many well-studied graph problems including triangle counting, its generalization to subgraph counting, maximum matching, problems about the existence (or not) of short paths, finding the shortest path between two vertices, and testing for an independent set. While some of these problems have been studied before, our results achieve new tradeoffs between space and communication costs that were hitherto unknown. In particular, two of our results disprove explicit conjectures of Thaler (ICALP, 2016) by giving triangle counting and maximum matching algorithms for $n$-vertex graphs, using $o(n)$ space and $o(n^2)$ communication.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/101"><span class="datestr">at August 05, 2019 04:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/08/05/full-professor-on-the-interface-of-computer-science-and-mathematics-at-university-of-warwick-apply-by-september-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/08/05/full-professor-on-the-interface-of-computer-science-and-mathematics-at-university-of-warwick-apply-by-september-1-2019/">Full Professor on the interface of Computer Science and Mathematics at University of Warwick (apply by September 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at the University of Warwick and the Warwick Mathematics Institute invite applications for a full Professor post in the areas on the interface of Computer Science and Mathematics, including Discrete Mathematics, Algorithms and Complexity, Theoretical Computer Science.</p>
<p>Website: <a href="https://warwick.ac.uk/fac/sci/dcs/jobs/?newsItem=8a1785d86c613bc7016c614a2c0f0046">https://warwick.ac.uk/fac/sci/dcs/jobs/?newsItem=8a1785d86c613bc7016c614a2c0f0046</a><br />
Email: R.S.Lazic@warwick.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/08/05/full-professor-on-the-interface-of-computer-science-and-mathematics-at-university-of-warwick-apply-by-september-1-2019/"><span class="datestr">at August 05, 2019 10:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/08/05/faculty-openings-in-computer-science-at-the-open-university-of-israel-apply-by-october-31-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/08/05/faculty-openings-in-computer-science-at-the-open-university-of-israel-apply-by-october-31-2019/">Faculty Openings in Computer Science at The Open University of Israel (apply by October 31, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Mathematics and Computer Science at the Open University of Israel invites applications in all areas of computer science for several senior faculty positions at all ranks (assistant professor, associate professor, professor)</p>
<p>Website: <a href="https://www.openu.ac.il/about/departments/academic_secretary/messages/FacultyOpeningsCS.aspx">https://www.openu.ac.il/about/departments/academic_secretary/messages/FacultyOpeningsCS.aspx</a><br />
Email: search@openu.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/08/05/faculty-openings-in-computer-science-at-the-open-university-of-israel-apply-by-october-31-2019/"><span class="datestr">at August 05, 2019 05:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=658">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">Because of pollution, conferences should be virtual</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Perhaps conferences made sense fifty years ago. We did not have internet, and the pollution was not as bad. Today, we can have effective virtual meetings, while the pollution has reached a level of crisis, see this <a href="https://www.ted.com/talks/greta_thunberg_school_strike_for_climate_save_the_world_by_changing_the_rules/transcript?language=en">moving talk by Greta_Thunberg</a>. Moving to a system of virtual conferences is I believe a duty of every scientist. Doing so will cut the significant air travel emissions that come from shipping scientists across the world. To attend a climate summit in the USofA, <a href="https://www.forbes.com/sites/davidebanis/2019/07/29/gretha-thunberg-will-sail-across-the-atlantic-to-attend-un-climate-conferences/#27e93f87c3b2">Greta will sail across the Atlantic ocean on a zero emission boat</a><a href="https://www.ted.com/talks/greta_thunberg_school_strike_for_climate_save_the_world_by_changing_the_rules/transcript?language=en">.</a></p>
<p>We can keep everything the way it is, but simply give the talks online. This change doesn’t involve anybody higher up in the political ladder. It only involves us, the program chairs, the steering committees.</p>
<p>While we wait for that, we can begin by virtualizing the physical STOC/FOCS PC meetings,<a href="https://emanueleviola.wordpress.com/2017/07/28/stocfocs-pc-meetings-does-nature-of-decisions-justify-cost/"> whose added value over a virtual meeting, if any, does not justify the cost</a>; and by holding conferences where the center of mass is, instead of exotic places where one can combine the trip with a vacation at the expense of tax payers’ money and everybody’s health. And that is also why I put a bid to hold the 2021 Conference on Computational Complexity in Boston.</p>
<p>NSF panels, making decisions worth millions, routinely have virtual panelists (I was the last few times). So why do we insist on shipping scientists across the globe multiple times a year to give 15-minute talks which to most people are less useful than spending 20 minutes reading the paper on the arxiv?</p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/"><span class="datestr">at August 04, 2019 10:58 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17603">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/08/04/avi-wigdersons-integrating-computational-modeling-algorithms-and-complexity-into-theories-of-nature-marks-a-new-scientific-revolution-an-invitation-for-a-discussion/">Avi Wigderson’s: “Integrating computational modeling, algorithms, and complexity into theories of nature, marks a new scientific revolution!” (An invitation for a discussion.)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/avi-book-cover.png"><img src="https://gilkalai.files.wordpress.com/2019/07/avi-book-cover.png?w=640" alt="" class="alignnone size-full wp-image-17611" /></a></p>
<p><span style="color: #ff0000;">The cover of Avi Wigderson’s book “Mathematics and computation” as was first exposed to the public in <a href="https://drive.google.com/file/d/1zxctNw-mA3hOT1tktE_dYjnmvOzZmC_A/view">Avi’s Knuth Prize videotaped lecture</a>. (I had trouble with 3 of the words: What is EGDE L WONK 0?  what is GCAAG?GTAACTC ?  TACGTTC ?  I only figured out the first.)</span></p>
<p>Avi Wigderson’s book  “<span style="color: #000000;"><a href="https://www.math.ias.edu/avi/book">Mathematics and computation, a theory revolutionizing technology and science</a>” is about to be published by Princeton University Press. The link is to a free copy of the book which will always be available on Avi’s homepage. (See also <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this re-blogged post here</a> of Boaz Barak.)</span></p>
<p><span style="color: #000000;">One main theme of the book is the rich connection between the theory of computing and other areas (in fact, most areas) of mathematics. See also this self contained survey (based on Chapter 13 of the book) by Avi <a href="https://arxiv.org/abs/1710.09780">Interactions of Computational Complexity Theory and Mathematics,</a> which in 27 pages overviews relations to number theory, Geometry, Operator Theory, Metric Geometry, Group Theory, Statistical Physics, Analysis and Probability, Lattice Theory and Invariant Theory. Of course, Avi himself is among the main heroes in finding many paths between mathematics and the theory of computing over the last four decades.</span></p>
<p><span style="color: #000000;">Another theme of the book and of several talks by Avi is that the theory of computing has revolutionary connections with many fields of science and technology. Again, this theme is present in the entire book and is emphasized in Chapter 20, which also appeared as a self contained paper  “<a href="http://www.math.ias.edu/~avi/PUBLICATIONS/Wigderson2018.pdf">On the nature of the Theory of Computation (ToC).</a>”  Let me quote one sentence from Avi’s book that I propose for discussion. (For the complete quote see the end of the post.)</span></p>
<p> </p>
<blockquote>
<h3>The intrinsic study of computation transcends human-made artifacts, and its expanding connections and interactions with all sciences, integrating computational modeling, algorithms,  and complexity into theories of nature and society, marks a new scientific revolution!</h3>
</blockquote>
<p>Of course, <span style="color: #000000;">similar ideas were also expressed by several other prominent scientists, and let me mention Bernard Chazelle’s essay: <a href="https://www.cs.princeton.edu/~chazelle/pubs/algorithm.html">The Algorithm: Idiom of Modern Science</a>. (Feel free to give further examples and links in the comment section.)</span></p>
<h3>Let’s discuss:  Integrating computational modeling, algorithms,  and complexity into theories of nature, marks a new scientific revolution!</h3>
<p><span style="color: #000000;">I propose to discuss in the comment section the idea that the theory of computing offers a scientific revolution. Very nice cases to examine are the computational study of randomness and connections to statistics, connections with economy and connections with biology. Comments on the relations between the theory of computation and other areas of mathematics are also very welcome.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/avi-c-3.png"><img src="https://gilkalai.files.wordpress.com/2019/08/avi-c-3.png?w=640&amp;h=329" alt="" width="640" class="alignnone size-full wp-image-17795" height="329" /></a></p>
<p><span style="color: #ff0000;">Avi’s concluding slide compared these three great theories of human understanding.</span></p>
<p><span style="color: #000000;"> (Previous attempts of open discussions were made in the following posts on this blog: </span><a href="https://gilkalai.wordpress.com/2019/03/26/10-milestones-in-the-history-of-mathematics-according-to-nati-and-me/" rel="bookmark">10 Milestones in the History of Mathematics according to Nati and Me</a>; <a href="https://gilkalai.wordpress.com/2013/05/23/why-is-mathematics-possible/" rel="bookmark">Why is mathematics possible?</a> (and a <a href="https://gilkalai.wordpress.com/2013/06/19/why-is-mathematics-possible-tim-gowerss-take-on-the-matter/">follow up post</a>); <a href="https://gilkalai.wordpress.com/2010/03/06/when-it-rains-it-pours/">When it rains it pours</a>;  <a href="https://gilkalai.wordpress.com/2019/03/31/is-it-legitimate-ethical-for-google-to-close-google/" rel="bookmark">Is it Legitimate/Ethical for Google to close Google+?</a>; <a href="https://gilkalai.wordpress.com/2009/03/25/an-open-discussion-and-polls-around-roths-theorem/" rel="bookmark">An Open Discussion and Polls: Around Roth’s Theorem</a>; <a href="https://gilkalai.wordpress.com/2008/05/25/is-mathematics-a-science/" rel="bookmark">Is Mathematics a Science?</a>)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/avi-c3.png"><img src="https://gilkalai.files.wordpress.com/2019/07/avi-c3.png?w=640&amp;h=317" alt="" width="640" class="alignnone size-full wp-image-17640" height="317" /></a></p>
<p><span style="color: #ff0000;">Avi promotes the idea of the central place of the theory of computing in his talks and writings</span><span id="more-17603"></span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/avi-c2.png"><img src="https://gilkalai.files.wordpress.com/2019/07/avi-c2.png?w=640&amp;h=229" alt="" width="640" class="alignnone size-full wp-image-17639" height="229" /></a></p>
<p><span style="color: #ff0000;">And at the same time he is also humorously skeptical about it. (And mainly emphasizes that his far reaching claim requires careful discussion and ample evidence.)   </span></p>
<p> </p>
<h3>The full quote of Avi:</h3>
<blockquote><p><em>The Theory of Computation is as revolutionary, fundamental and beautiful as major theories of mathematics, physics, biology, economics… that are regularly hailed as such. Its impact has been similarly staggering. The mysteries still baffling ToC are as challenging as those left open in other fields. And quite uniquely, the theory of computation is central to most other sciences. In creating the theoretical foundations of computing systems ToC has already played, and continues to play a major part in one of the greatest scientific and technological revolutions in human history. But the intrinsic study of computation transcends man-made artifacts. ToC has already established itself as an important mathematical discipline, with growing connections to nearly all mathematical areas. And its expanding connections and interactions with all sciences, naturally integrating computational modeling, algorithms and complexity into theories of nature and society, marks the beginning of another scientific revolution!</em></p></blockquote>
<h3>More related material:</h3>
<ol>
<li>Avi’s talk <a href="https://youtu.be/Z4nhNbpx_u0">Scientific revolutions, ToC and PCP</a>  at the Tel Aviv PCP meeting and an <a href="https://youtu.be/-GQnK6ys6C0">interview of Avi by Alon Rosen</a>.</li>
<li><a href="https://video.ias.edu/csdm/stepanov"> A talk by Avi on the Stepanov method</a></li>
<li>The recent works on polytopes arising from moment maps and related optimization problems and algorithmic aspects.  <a href="https://drive.google.com/file/d/1zxctNw-mA3hOT1tktE_dYjnmvOzZmC_A/view">Avi’s Knuth prize videotaped lecture</a>; Avi’s lecture  <a href="http://www.fields.utoronto.ca/talks/Complexity-Optimization-and-Math-or-Can-we-prove-P-NP-gradient-descent">Complexity, Optimization and Math (or, Can we prove that P != NP by gradient descent?)</a> in the recent conference honoring Bill Cook. (I plan to come back to this fascinating topic.)</li>
<li><span style="color: #000000;">An essay by Oded Goldreich and Avi Wigderson (essentially from 1996) <a href="http://www.wisdom.weizmann.ac.il/~oded/PDF/toc-sp2.pdf">“The theory of computing –  a scientific perspective.”</a></span></li>
</ol>
<p><a href="https://gilkalai.files.wordpress.com/2019/08/blog-comments.png"><img src="https://gilkalai.files.wordpress.com/2019/08/blog-comments.png?w=300&amp;h=300" alt="" width="300" class="alignnone size-medium wp-image-17771" height="300" /></a></p>
<p><span style="color: #ff0000;">The volume of comments in the first decade of this blog was modest. I recently read, however, wordpress’s advice on how to reply to blog comments like a pro. </span></p>
<p>And finally, EGDE L WONK 0 is 0-knowledge.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/08/04/avi-wigdersons-integrating-computational-modeling-algorithms-and-complexity-into-theories-of-nature-marks-a-new-scientific-revolution-an-invitation-for-a-discussion/"><span class="datestr">at August 04, 2019 08:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1144">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1144">News for July 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>We saw quite an activity last month, with a total of 9 papers on property testing or related areas.</p>



<p>Let’s start with a paper on PCPs:<br /><strong>Revisiting Alphabet Reduction in Dinur’s PCP</strong>, by Venkatesan Guruswami, Jakub Opršal, and Sai Sandeep  (<a href="https://eccc.weizmann.ac.il/report/2019/092/">ECCC</a>). As mentioned in the title, this work provides an alternate proof of one of the two parts of the Dinur’s PCP theorem proof. In that proof, the argument goes by alternating two main steps: (i) amplifying the soundness gap, at the price of increasing the alphabet size (and the instance size); (ii) reducing the alphabet size, at the price of increasing the  instance size. From the observation that step (i) creates some structure in the instances that can be leveraged, the authors provide an alternative construction for (ii), leading to an arguably simpler analysis of the soundness of the underlying test. A nice throwback to some of the roots of property testing.</p>



<p>Then, four papers on distribution testing:<br /><strong>Testing Mixtures of Discrete Distributions</strong>, by Maryam Aliakbarpour, Ravi Kumar, Ronitt Rubinfeld (<a href="https://arxiv.org/abs/1907.03190">arXiv</a>). One of the most studied problems in distribution testing is <em>identity testing</em> (a.k.a., goodness-of-fit): given a reference distribution \(q\) over a domain of size \(n\) and i.i.d. samples from an unknown \(p\), decide between \(p=q\) and \(d_\textrm{TV}(p,q) &gt; \varepsilon\). While this is now well-understood and can be done with a strongly sublinear number of samples (namely, \(\sqrt{n})\)), the case of <em>tolerant</em> testing is much sadder: Valiant and Valiant proved that \(\Theta(n/\log n)\) samples were required for distinguishing \(d_\textrm{TV}(p,q) &lt; \varepsilon/2\) from \(d_\textrm{TV}(p,q) &gt; \varepsilon\). So, noise-tolerance is almost as hard as it gets… <em>except</em>, as this works suggests and studies, if one has some guarantees on the noise! What if the noise in the completeness case was just that \(q\) is perturbed by some (known, or available via samples as well) noise coming from a second distribution \(\eta\)? I.e., the question is now to test whether \(p\) if of the form \(\alpha q + (1-\alpha) \eta\) for some \(\alpha\in [0,1]\), or if it is \(\varepsilon\)-far from all mixtures of \(q\) and \(\eta\). The authors have various results on this question and some extensions, but the upshot is: “with structured noise, strongly sublinear sample complexity is once again possible.”<br /><strong><br />Can Distributed Uniformity Testing Be Local?</strong>, by Uri Meir, Dor Mintzer, and Rotem Oshman (<a href="https://dl.acm.org/citation.cfm?id=3331613">ACM PODC Proceedings</a>). More on identity testing, specifically uniformity testing. No noise here, but another constraint: the samples are distributed. There are \(k\) players, each holding \(q\) i.i.d. samples from a distribution \(p\) over \([n]\); each can send \(\ell=1\) bit to a central referee, in a non-interactive fashion. Is \(p\) the uniform distribution, or is it \(\varepsilon\)-far from it? The authors here consider the case where \(k,n,\varepsilon\) are fixed, and prove lower bounds on the number \(q=q(k,n,\varepsilon)\) of samples each player must hold in order to perform this uniformity testing task. (Note: their lower bounds hold even in the public-randomness setting.) Motivated by the LOCAL model, they focus on 3 cases of interest, for which they obtain tight or near-tight bounds on \(q\) (in view of upper bounds from previous work of a subset of the authors): (1)  when the referee’s decision has to be the \(\textsf{AND}\) of all \(n\) bits she receives; (2) when the referee can do something more involved, and use a threshold function; and (3) when the referee can use an arbitrary function of those \(n\) messages. Underlying those lower bounds is a neat application of Boolean Fourier analysis, recasting the analysis of the standard “Paninski” lower bound instance and the player’s decision functions as a question on Boolean functions.<br /><br /><strong>Domain Compression and its Application to Randomness-Optimal  Distributed Goodness-of-Fit</strong>, by Jayadev Acharya, Clément Canonne, Yanjun Han, Ziteng Sun, and Himanshu Tyagi (<a href="https://arxiv.org/abs/1907.08743">arXiv</a>,<a href="https://eccc.weizmann.ac.il/report/2019/098/">ECCC</a>). Remember the paper just above? Now, focus on the case (3), where the referee can use any function of the message, allow each player to send \(\ell\) bits instead of one, but give only one sample (instead of \(q\)) to each player. This becomes a setting we have talked about before on this blog (specifically, with three papers on <a href="https://ptreview.sublinear.info/?p=990">these</a> <a href="https://ptreview.sublinear.info/?p=1030">three</a> <a href="https://ptreview.sublinear.info/?p=1075">months</a>). Those three papers established the optimal number of player \(k\), in terms of  the domain size \(n\), the distance parameter \(\varepsilon\), and the number of bits per player \(\ell\), in both the private-coin and public-coin settings. This new work interpolates between those two extremes, and gives the tight answer to the general question: if there are \( 0\leq s \leq \log n\) bits of public randomness available, what is the optimal number of players to perform identity testing? Behind the upper bounds is a new notion of (randomness-efficient) <em>domain compression</em> they introduce: how to reduce the domain size of the probability distributions while preserving the \(\ell_1\) distances between them as much as possible?<br /><br /><strong>Towards Testing Monotonicity of Distributions Over General Posets</strong>, by Maryam Aliakbarpour, Themis Gouleakis, John Peebles, Ronitt Rubinfeld, and Anak Yodpinyanee (<a href="https://arxiv.org/abs/1907.03182">arXiv</a>). Away from identity testing, let’s now consider another central question, testing <em>monotonicity</em> of distributions. Specifically, a distribution \(p\) over a given poset \((\mathcal{X}, \prec)\) is said to be monotone if \(p(x) \leq p(y)\) whenever \(x\prec y\). While the question is fully understood for the familiar case of the line \(\mathcal{X} = \{1,2,\dots,n\}\), the case of general posets is much murkier, and more or less uncharted. This paper initiates a general study of the question, improving on previously known bounds for the matching poset and Boolean hypercube, and providing several new results and techniques for the general case, to establish both upper and lower bounds on the sample complexity.</p>



<p>And now… graphs!<br /><strong>Expansion Testing using Quantum Fast-Forwarding and Seed Sets</strong>, by Simon Apers (<a href="https://arxiv.org/abs/1907.02369">arXiv</a>). This paper is concerned with (bicriteria) testing of vertex expansion of a given graph \(G=(V,E)\) in the bounded-degree graph model. Loosely speaking, given a value \(\Phi\) and query access <em>(i.e., sampling a node u.a.r., querying the degree of a node, and querying the \(i\)-th neighbor of a node) </em>to a graph \(G\) with maximum degree \(d=\Theta(1)\), the goal is to distinguish between (i) \(G\) has vertex expansion at most \(\Phi\) and (ii) \(G\) is \(\varepsilon\)-far from any \(G’\) with vertex expansion at most \(\Phi^2\) <em>(simplifying and dropping some technicalities)</em>. The previous state-of-the-art was a \(\tilde{O}_{\varepsilon}(n^{1/2}/\Phi^2)\) query complexity for classical algorithms, and a \(\tilde{O}_{\varepsilon}(\min(n^{1/3}/\Phi^2),n^{1/2}/\Phi^2))\) query complexity upper bound for quantum testers. The current work improves on this by providing a \(\tilde{O}_{\varepsilon}(n^{1/3}/\Phi)\) quantum tester. Graphs expand—and so does the gap between classical and quantum testing.<br /><br /><strong>Walking Randomly, Massively, and Efficiently</strong>, by Jakub Łącki, Slobodan Mitrović, Krzysztof Onak, and Piotr Sankowski  (<a href="https://arxiv.org/abs/1907.05391">arXiv</a>). One very useful primitive, in many graph property testing results and of course well beyond property testing, is the ability to perform random walks on graphs. In the case of large, distributed (or merely impractically massive) graphs, however, it is not clear how to implement this primitive efficiently. This work addresses this question in the MPC (Massive Parallel Computation) model, and shows how to perform independently, from all of the \(n\) nodes of a graph (i.e., machine), an \(\ell\)-length random walk with only \(O(\log \ell)\) rounds of communication and \(O(n^\alpha)\) space per machine, for any constant \(\alpha \in(0,1)\). This round complexity matches a known (conditional) lower bound, and thus the result is as good as it gets — further, the authors obtain such MPC algorithms for both undirected and directed graph, somehow leveraging the latter case to handle the (significantly more complicated) directed case. As an application of this efficient random walk primitive, they provide MPC property testing algorithms for both bipartiteness and vertex expansion<em> (same definition as in the paper above: vertex expansion \(\Phi\) vs. \(\varepsilon\)-far from any \(G’\) with vertex expansion \(\Phi^2\))</em> in the general graph model. (Beyond property testing, another application—the main one in the paper— is computing PageRank in both graphs and directed graphs.)<br /><strong><br />A Lower Bound on Cycle-Finding in Sparse Digraphs</strong>, by Xi Chen, Tim Randolph, Rocco Servedio, and Timothy Sun (<a href="https://arxiv.org/abs/1907.12106">arXiv</a>). In this paper, the authors tackle the problem of one-sided testing of acyclicity of directed graphs, in the bounded-degree graph model (equivalently, on the task of finding a cycle in a digraph promised to be far from acyclic). Previously, an \(\Omega(\sqrt{n})\) lower bound for this task had been shown by Bender and Ron, based on a birthday-paradox-type argument; this work improves on this hardness result, showing that \(\tilde{\Omega}(n^{5/9})\) queries are necessary. Interestingly, whether achieving any \(o(n)\) query complexity is possible remains open.<br /><br /><strong>Constant-Time Dynamic \((\Delta+1)\)-Coloring and Weight Approximation for  Minimum Spanning Forest: Dynamic Algorithms Meet Property Testing</strong>, by Monika Henzinger and Pan Peng (<a href="https://arxiv.org/abs/1907.04745">arXiv</a>). Finally, the last paper covered this month is concerned with <em>dynamic graph algorithms</em>: where updates to a graph (which can be both edge additions <em>and</em> deletions) come sequentially, and the objective is to maintain, e.g., a coloring, or an approximation of some function of the graph, at any time using as little time per update. This paper advocates the use of techniques from property testing <em>(loosely speaking, as their locality and query-efficiency translates to fast update times)</em> to design better dynamic graph algorithms. It illustrates this idea by obtaining several new results, in particular an (amortized) \(O(1)\)-update-time randomized algorithm to maintain a \((\Delta+1)\)-coloring in a graph with degree bound \(\Delta\). The algorithm relies on a random ranking of the nodes which, combined with a suitable randomized update rule for recoloring a vertex when needed, ensure that the recolorings will not (with high probability) “propagate” to much. This is the first time that this idea, previously used in several testing and sublinear-time papers, is used in the context of dynamic graph algorithms—adding an edge between the two areas, hopefully only the first of many.<br /></p>



<p><strong>Update:</strong> we did miss a paper! Make it <strong>ten</strong> in July…<br /><strong>Nearly optimal edge estimation with independent set queries</strong>, by Xi Chen, Amit Levi, Erik Waingarten (<a href="https://arxiv.org/abs/1907.04381">arXiv</a>). Consider the following type of access to an unknown graph \(G=(V,E)\) on \(n=|V|\) nodes: on query \(S\subseteq V\), the oracle returns 1 if \(S\) is is an independent set, and 0 otherwise. <em>(This sounds quite a bit like what is allowed in the group testing literature.)</em> How many such queries are necessary to get a multiplicative estimate of the number of edges, \(m=|E|\)? In this paper, the authors improve on the previous bound of \(\min(\sqrt{m}, n^2/m)\) (ignoring logarithmic factors), obtaining an \(\min(\sqrt{m}, n/m)\) upper bound — complemented by a (nearly, up to those pesky log factors) matching lower bound.</p>



<p><em>If we missed a paper this month, or represented some result above, please mention it in the comments.</em></p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1144"><span class="datestr">at August 04, 2019 12:56 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
