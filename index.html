<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at September 12, 2019 10:22 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.05023">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.05023">A Quantum Search Decoder for Natural Language Processing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bausch:Johannes.html">Johannes Bausch</a>, Sathyawageeswar Subramanian, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Piddock:Stephen.html">Stephen Piddock</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05023">PDF</a><br /><b>Abstract: </b>Probabilistic language models, e.g. those based on an LSTM, often face the
problem of finding a high probability prediction from a sequence of random
variables over a set of words. This is commonly addressed using a form of
greedy decoding such as beam search, where a limited number of
highest-likelihood paths (the beam width) of the decoder are kept, and at the
end the maximum-likelihood path is chosen. The resulting algorithm has linear
runtime in the beam width. However, the input is not necessarily distributed
such that a high-likelihood input symbol at any given time step also leads to
the global optimum. Limiting the beam width can thus result in a failure to
recognise long-range dependencies. In practice, only an exponentially large
beam width can guarantee that the global optimum is found: for an input of
length $n$ and average parser branching ratio $R$, the baseline classical
algorithm needs to query the input on average $R^n$ times. In this work, we
construct a quantum algorithm to find the globally optimal parse with high
constant success probability. Given the input to the decoder is distributed
like a power-law with exponent $k&gt;0$, our algorithm yields a runtime $R^{n
f(R,k)}$, where $f\le 1/2$, and $f\rightarrow 0$ exponentially quickly for
growing $k$. This implies that our algorithm always yields a super-Grover type
speedup, i.e. it is more than quadratically faster than its classical
counterpart. We further modify our procedure to recover a quantum beam search
variant, which enables an even stronger empirical speedup, while sacrificing
accuracy. Finally, we apply this quantum beam search decoder to Mozilla's
implementation of Baidu's DeepSpeech neural net, which we show to exhibit such
a power law word rank frequency, underpinning the applicability of our model.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.05023"><span class="datestr">at September 12, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.05007">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.05007">Optimality of the Subgradient Algorithm in the Stochastic Setting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Daron Anderson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leith:Douglas.html">Douglas Leith</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.05007">PDF</a><br /><b>Abstract: </b>Recently Jaouad Mourtada and St\' ephane Ga\"iffas showed the anytime hedge
algorithm has pseudo-regret $O(\log (d) / \Delta)$ if the cost vectors are
generated by an i.i.d sequence in the cube $[0,1]^d$. Here $d$ is the dimension
and $\Delta$ the suboptimality gap. This is remarkable because the Hedge
algorithm was designed for the antagonistic setting. We prove a similar result
for the anytime subgradient algorithm on the simplex. Given i.i.d cost vectors
in the unit ball our pseudo-regret bound is $O(1/\Delta)$ and does not depend
on the dimension of the problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.05007"><span class="datestr">at September 12, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04910">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04910">An exact solution framework for the multiple gradual cover location problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Eduardo Álvarez-Miranda, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinnl:Markus.html">Markus Sinnl</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04910">PDF</a><br /><b>Abstract: </b>Facility and covering location models are key elements in many decision aid
tools in logistics, supply chain design, telecommunications, public
infrastructure planning, and many other industrial and public sectors. In many
applications, it is likely that customers are not dichotomously covered by
facilities, but gradually covered according to, e.g., the distance to the open
facilities. Moreover, customers are not served by a single facility, but by a
collection of them, which jointly serve them. In this paper we study the
recently introduced multiple gradual cover location problem (MGCLP). The MGCLP
addresses both of the issues described above.
</p>
<p>We provide four different mixed-integer programming formulations for the
MGCLP, all of them exploiting the submodularity of the objective function and
developed a branch-and-cut framework based one these formulations. The
framework is further enhanced by starting and primal heuristics and
initialization procedures.
</p>
<p>The computational results show that our approach allows to effectively
address different sets of instances. We provide optimal solution values for 13
instances from literature, where the optimal solution was not known, and
additionally provide improved solution values for seven instances. Many of
these instances can be solved within a minute. We also analyze the dependence
of the solution-structure on instance-characteristics.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04910"><span class="datestr">at September 12, 2019 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04905">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04905">SwarmMesh: A Distributed Data Structure for Cooperative Multi-Robot Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Majcherczyk:Nathalie.html">Nathalie Majcherczyk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pinciroli:Carlo.html">Carlo Pinciroli</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04905">PDF</a><br /><b>Abstract: </b>We present an approach to the distributed storage of data across a swarm of
mobile robots that forms a shared global memory. We assume that external
storage infrastructure is absent, and that each robot is capable of devoting a
quota of memory and bandwidth to distributed storage. Our approach is motivated
by the insight that in many applications data is collected at the periphery of
a swarm topology, but the periphery also happens to be the most dangerous
location for storing data, especially in exploration missions. Our approach is
designed to promote data storage in the locations in the swarm that best suit a
specific feature of interest in the data, while accounting for the constantly
changing topology due to individual motion. We analyze two possible features of
interest: the data type and the data item position in the environment. We
assess the performance of our approach in a large set of simulated experiments.
The evaluation shows that our approach is capable of storing quantities of data
that exceed the memory of individual robots, while maintaining near-perfect
data retention in high-load conditions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04905"><span class="datestr">at September 12, 2019 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04878">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04878">Promises Make Finite (Constraint Satisfaction) Problems Infinitary</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barto:Libor.html">Libor Barto</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04878">PDF</a><br /><b>Abstract: </b>The fixed template Promise Constraint Satisfaction Problem (PCSP) is a
recently proposed significant generalization of the fixed template CSP, which
includes approximation variants of satisfiability and graph coloring problems.
All the currently known tractable (i.e., solvable in polynomial time) PCSPs
over finite templates can be reduced, in a certain natural way, to tractable
CSPs. However, such CSPs are often over infinite domains. We show that the
infinity is in fact necessary by proving that a specific finite-domain PCSP,
namely (1-in-3-SAT, Not-All-Equal-3-SAT), cannot be naturally reduced to a
tractable finite-domain CSP, unless P=NP.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04878"><span class="datestr">at September 12, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04871">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04871">Algebraic Theory of Promise Constraint Satisfaction Problems, First Steps</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Barto:Libor.html">Libor Barto</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04871">PDF</a><br /><b>Abstract: </b>What makes a computational problem easy (e.g., in P, that is, solvable in
polynomial time) or hard (e.g., NP-hard)? This fundamental question now has a
satisfactory answer for a quite broad class of computational problems, so
called fixed-template constraint satisfaction problems (CSPs) -- it has turned
out that their complexity is captured by a certain specific form of symmetry.
This paper explains an extension of this theory to a much broader class of
computational problems, the promise CSPs, which includes relaxed versions of
CSPs such as the problem of finding a 137-coloring of a 3-colorable graph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04871"><span class="datestr">at September 12, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04785">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04785">Kronecker powers of tensors and Strassen's laser method</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Conner:Austin.html">Austin Conner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gesmundo:Fulvio.html">Fulvio Gesmundo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Landsberg:Joseph_M=.html">Joseph M. Landsberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Ventura:Emanuele.html">Emanuele Ventura</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04785">PDF</a><br /><b>Abstract: </b>We answer a question, posed implicitly by Coppersmith-Winogrand and
Buergisser et. al. and explicitly by Blaeser, showing the border rank of the
Kronecker square of the little Coppersmith-Winograd tensor is the square of the
border rank of the tensor for all q&gt;2, a negative result for complexity theory.
We further show that when q&gt;4, the analogous result holds for the Kronecker
cube. In the positive direction, we enlarge the list of explicit tensors
potentially useful for the laser method. We observe that a well-known tensor,
the 3x3 determinant polynomial regarded as a tensor, could potentially be used
in the laser method to prove the exponent of matrix multiplication is two.
Because of this, we prove new upper bounds on its Waring rank and rank (both
18), border rank and Waring border rank (both 17), which, in addition to being
promising for the laser method, are of interest in their own right. We discuss
"skew" cousins of the little Coppersmith-Winograd tensor and indicate whey they
may be useful for the laser method. We establish general results regarding
border ranks of Kronecker powers of tensors, and make a detailed study of
Kronecker squares of tensors of dimensions (3,3,3). In particular we show
numerically that for generic tensors in this space, the rank and border rank
are strictly sub-multiplicative.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04785"><span class="datestr">at September 12, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04774">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04774">Coding for Sunflowers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rao:Anup.html">Anup Rao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04774">PDF</a><br /><b>Abstract: </b>A sunflower is a family of sets that have the same pairwise intersections. We
simplify a recent result of Alweiss, Lovett, Wu and Zhang that gives an upper
bound on the size of every family of sets of size $k$ that does not contain a
sunflower. We show how to use the converse of Shannon's noiseless coding
theorem to give a cleaner proof of their result.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04774"><span class="datestr">at September 12, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04759">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04759">Electrical Flows over Spanning Trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gupta:Swati.html">Swati Gupta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khodabakhsh:Ali.html">Ali Khodabakhsh</a>, Hassan Mortagy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nikolova:Evdokia.html">Evdokia Nikolova</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04759">PDF</a><br /><b>Abstract: </b>This is the first paper to give provable approximation guarantees for the
network reconfiguration problem from power systems. The problem seeks to find a
rooted tree such that the energy of the (unique) feasible electrical flow is
minimized. The tree requirement is motivated by operational constraints in
electricity distribution networks. The bulk of existing results on the
structure of electrical flows, Laplacian solvers, bicriteria tree
approximations, etc., do not easily give guarantees for this problem, while
many heuristic methods have been used in the power systems community as early
as 1989. Our main contribution is to advance the theory for network
reconfiguration by providing novel lower bounds and corresponding approximation
factors for various settings ranging from $O(n)$ for general graphs, to
$O(\sqrt{n})$ over grids with uniform resistances on edges, and $O(1)$ for
grids with uniform edge resistances and demands. We also provide a new method
for (approximate) graph sparsification that maintains the original resistances
of the edges.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04759"><span class="datestr">at September 12, 2019 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=363">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/09/11/the-fall-season-of-tcs-is-upon-us/">The Fall season of TCS+ is upon us!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>With the summer winding down, the Fall ’19 season of TCS+ is coming fast! We’re excited to bring to you, over the next few months, great speakers and amazing results, right into the comfort of your home institution (or home <em>home</em>, for that matter).</p>
<p>As a teaser, here are the first three talks of the season:</p>
<ul>
<li>
<ul>
<li><a href="http://web.stanford.edu/~msellke/main" target="_blank" rel="noopener">Mark Sellke</a> (Stanford) will tell us, on September 25th, about his recent work on <em>Chasing Convex Bodies.</em><em><br />
</em></li>
<li><a href="https://cseweb.ucsd.edu/~slovett/" target="_blank" rel="noopener">Shachar Lovett</a> (UCSD) will on October 9th present his new results on the Sunflower Lemma.</li>
<li><a href="http://www.mathcs.emory.edu/~hhuan30/">Hao Huang</a> (Emory University) will talk on October 22nd <em>(note: a Tuesday)</em> about his recent proof of the Sensitivity Conjecture.</li>
</ul>
</li>
</ul>
<p>Stay tuned for those, and the following!</p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/09/11/the-fall-season-of-tcs-is-upon-us/"><span class="datestr">at September 11, 2019 07:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04613">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04613">Faster quantum and classical SDP approximations for quadratic binary optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Fernando G. S L. Brandão, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kueng:Richard.html">Richard Kueng</a>, Daniel Stilck França <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04613">PDF</a><br /><b>Abstract: </b>We give a quantum speedup for solving the canonical semidefinite programming
relaxation for binary quadratic optimization. The class of relaxations for
combinatorial optimization has so far eluded quantum speedups. Our methods
combine ideas from quantum Gibbs sampling and matrix exponent updates. A
de-quantization of the algorithm also leads to a faster classical solver. For
generic instances, our quantum solver gives a nearly quadratic speedup over
state-of-the-art algorithms. We also provide an efficient randomized rounding
procedure that converts approximately optimal SDP solutions into constant
factor approximations of the original quadratic optimization problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04613"><span class="datestr">at September 11, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04611">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04611">Approximating Vertex Cover using Structural Rounding</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lavallee:Brian.html">Brian Lavallee</a>, Hayley Russell, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sullivan:Blair_D=.html">Blair D. Sullivan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Poel:Andrew_van_der.html">Andrew van der Poel</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04611">PDF</a><br /><b>Abstract: </b>In this work, we provide the first practical evaluation of the structural
rounding framework for approximation algorithms. Structural rounding works by
first editing to a well-structured class, efficiently solving the edited
instance, and "lifting" the partial solution to recover an approximation on the
input. We focus on the well-studied Vertex Cover problem, and edit to the class
of bipartite graphs (where Vertex Cover has an exact polynomial time
algorithm). In addition to the naive lifting strategy for Vertex Cover
described by Demaine et al., we introduce a suite of new lifting strategies and
measure their effectiveness on a large corpus of synthetic graphs. We find that
in this setting, structural rounding significantly outperforms standard
2-approximations. Further, simpler lifting strategies are extremely competitive
with the more sophisticated approaches. The implementations are available as an
open-source Python package, and all experiments are replicable.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04611"><span class="datestr">at September 11, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04481">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04481">Well-behaved Online Load Balancing Against Strategic Jobs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Bo.html">Bo Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Minming.html">Minming Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wu:Xiaowei.html">Xiaowei Wu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04481">PDF</a><br /><b>Abstract: </b>In the online load balancing problem on related machines, we have a set of
jobs (with different sizes) arriving online, and we need to assign each job to
a machine immediately upon its arrival, so as to minimize the makespan, i.e.,
the maximum completion time. In classic mechanism design problems, we assume
that the jobs are controlled by selfish agents, with the sizes being their
private information. Each job (agent) aims at minimizing its own cost, which is
its completion time plus the payment charged by the mechanism. Truthful
mechanisms guaranteeing that every job minimizes its cost by reporting its true
size have been well-studied [Aspnes et al. JACM 1997, Feldman et al. EC 2017].
</p>
<p>In this paper, we study truthful online load balancing mechanisms that are
well-behaved [Epstein et al., MOR 2016]. Well-behavior is important as it
guarantees fairness between machines, and implies truthfulness in some cases
when machines are controlled by selfish agents. Unfortunately, existing
truthful online load balancing mechanisms are not well-behaved. We first show
that to guarantee producing a well-behaved schedule, any online algorithm (even
non-truthful) has a competitive ratio at least $\Omega(\sqrt{m})$, where m is
the number of machines. Then we propose a mechanism that guarantees
truthfulness of the online jobs, and produces a schedule that is almost
well-behaved. We show that our algorithm has a competitive ratio of $O(\log
m)$. Moreover, for the case when the sizes of online jobs are bounded, the
competitive ratio of our algorithm improves to $O(1)$. Interestingly, we show
several cases for which our mechanism is actually truthful against selfish
machines.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04481"><span class="datestr">at September 11, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04419">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04419">Bisecting three classes of lines</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilz:Alexander.html">Alexander Pilz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schnider:Patrick.html">Patrick Schnider</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04419">PDF</a><br /><b>Abstract: </b>We consider the following problem: Let $\mathcal{L}$ be an arrangement of $n$
lines in $\mathbb{R}^3$ colored red, green, and blue. Does there exist a
vertical plane $P$ such that a line on $P$ simultaneously bisects all three
classes of points in the cross-section $\mathcal{L} \cap P$? Recently, Schnider
[SoCG 2019] used topological methods to prove that such a cross-section always
exists. In this work, we give an alternative proof of this fact, using only
methods from discrete geometry. With this combinatorial proof at hand, we
devise an $O(n^2\log^2(n))$ time algorithm to find such a plane and the
bisector of the induced cross-section. We do this by providing a general
framework, from which we expect that it can be applied to solve similar
problems on cross-sections and kinetic points.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04419"><span class="datestr">at September 11, 2019 11:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04396">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04396">Constant factor approximation of MAX CLIQUE</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Toivonen:Tapani.html">Tapani Toivonen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karttunen:Janne.html">Janne Karttunen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04396">PDF</a><br /><b>Abstract: </b>MAX CLIQUE problem (MCP) is an NPO problem, which asks to find the largest
complete sub-graph in a graph $G, G = (V, E)$ (directed or undirected). MCP is
well known to be $NP-Hard$ to approximate in polynomial time with an
approximation ratio of $1 + \epsilon$, for every $\epsilon &gt; 0$ [9] (and even a
polynomial time approximation algorithm with a ratio $n^{1 - \epsilon}$ has
been conjectured to be non-existent [2] for MCP). Up to this date, the best
known approximation ratio for MCP of a polynomial time algorithm is
$O(n(log_2(log_2(n)))^2 / (log_2(n))^3)$ given by Feige [1]. In this paper, we
show that MCP can be approximated with a constant factor in polynomial time
through approximation ratio preserving reductions from MCP to MAX DNF and from
MAX DNF to MIN SAT. A 2-approximation algorithm for MIN SAT was presented in
[6]. An approximation ratio preserving reduction from MIN SAT to min vertex
cover improves the approximation ratio to $2 - \Theta(1/ \sqrt{n})$ [10]. Hence
we prove false the infamous conjecture, which argues that there cannot be a
polynomial time algorithm for MCP with an approximation ratio of any constant
factor.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04396"><span class="datestr">at September 11, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04268">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04268">The Outer Limits of Contention Resolution on Matroids and Connections to the Secretary Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dughmi:Shaddin.html">Shaddin Dughmi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04268">PDF</a><br /><b>Abstract: </b>Contention resolution schemes have proven to be a useful and unifying
abstraction for a variety of constrained optimization problems, in both offline
and online arrival models. Much of prior work restricts attention to product
distributions for the input set of elements, and studies contention resolution
for increasingly general packing constraints, both offline and online. In this
paper, we instead focus on generalizing the input distribution, restricting
attention to matroid constraints in both the offline and online random arrival
models. In particular, we study contention resolution when the input set is
arbitrarily distributed, and may exhibit positive and/or negative correlations
between elements. We characterize the distributions for which offline
contention resolution is possible, and establish some of their basic closure
properties. Our characterization can be interpreted as a distributional
generalization of the matroid covering theorem. For the online random arrival
model, we show that contention resolution is intimately tied to the secretary
problem via two results. First, we show that a competitive algorithm for the
matroid secretary problem implies that online contention resolution is
essentially as powerful as offline contention resolution for matroids, so long
as the algorithm is given the input distribution. Second, we reduce the matroid
secretary problem to the design of an online contention resolution scheme of a
particular form.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04268"><span class="datestr">at September 11, 2019 11:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04244">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04244">Contraction: a Unified Perspective of Correlation Decay and Zero-Freeness of 2-Spin Systems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shao:Shuai.html">Shuai Shao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yuxin.html">Yuxin Sun</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04244">PDF</a><br /><b>Abstract: </b>We study complex zeros of the partition function of 2-spin systems, viewed as
a multivariate polynomial in terms of the edge interaction parameters and the
uniform external field. We obtain new zero-free regions in which all these
parameters are complex-valued. Crucially based on the zero-freeness, we show
the existence of correlation decay in these regions. As a consequence, we
obtain an FPTAS for computing the partition function of 2-spin systems on
graphs of bounded degree for these parameter settings. One innovative aspect of
this work is to introduce the contraction property, which provides a unified
sufficient condition to devise FPTAS, via either Weitz's algorithm or
Barvinok's algorithm. Our main technical contribution is a very simple but
general approach to extend any real parameter of which the 2-spin system
exhibits correlation decay to its complex neighborhood where the partition
function is zero-free and correlation decay still exists. This result formally
establishes the inherent connection between two distinct notions of phase
transition for 2-spin systems: the existence of correlation decay and the
zero-freeness of the partition function, via a unified perspective,
contraction.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04244"><span class="datestr">at September 11, 2019 11:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1909.04135">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1909.04135">On CDCL-based proof systems with the ordered decision strategy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mull:Nathan.html">Nathan Mull</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pang:Shuo.html">Shuo Pang</a>, Alexander Razborov <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1909.04135">PDF</a><br /><b>Abstract: </b>We prove that conflict-driven clause learning SAT-solvers with the ordered
decision strategy and the DECISION learning scheme are equivalent to ordered
resolution. We also prove that, by replacing this learning scheme with its
opposite that stops after the first new clause when backtracking, they become
equivalent to general resolution. To the best of our knowledge, this is the
first theoretical study of the interplay between specific decision strategies
and clause learning.
</p>
<p>For both results, we allow nondeterminism in the solver's ability to perform
unit propagation, conflict analysis, and restarts, in a way that is similar to
previous works in the literature. To aid the presentation of our results, and
possibly future research, we define a model and language for discussing
CDCL-based proof systems that allows for succinct and precise theorem
statements.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1909.04135"><span class="datestr">at September 11, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/117">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/117">TR19-117 |  Locally Testable Non-Malleable Codes | 

	Silas Richelson, 

	Sourya Roy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work we adapt the notion of non-malleability for codes or Dziembowski, Pietrzak and Wichs (ICS 2010) to locally testable codes. Roughly speaking, a locally testable code is non-malleable if any tampered codeword which passes the local test with good probability is close to a valid codeword which either encodes the original, or an unrelated message.
We instantiate our definition by proving that a Reed-Muller-type code is non-malleable in the following sense: any adversary who independently tampers the coordinates of the code so that the tampered code passes the test with good probability, is tampering the underlying polynomial according to an affine transformation.
To the best of our knowledge, prior to this work, polynomial codes were not known to possess any non-malleability guarantees. Our analysis builds on the sampler-based decoding techniques common to several recent works.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/117"><span class="datestr">at September 10, 2019 12:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-25562705.post-4980143336209093039">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/roth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://aaronsadventures.blogspot.com/2019/09/a-new-analysis-of-adaptive-data-analysis.html">A New Analysis of "Adaptive Data Analysis"</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div style="text-align: center;"><i>This is a blog post about our new paper, which you can read here: </i><a href="https://arxiv.org/abs/1909.03577">https://arxiv.org/abs/1909.03577</a> </div><div style="text-align: center;"><br /></div>The most basic statistical estimation task is estimating the expected value of some predicate $q$ over a distribution $\mathcal{P}$: $\mathrm{E}_{x \sim \mathcal{P}}[q(x)]$, which I'll just write as $q(\mathcal{P})$. Think about estimating the mean of some feature in your data, or the error rate of a classifier that you have just trained.  There's a really obvious way to come up with a good estimate if you've got a dataset $S \sim \mathcal{P}^n$ of $n$ points that were sampled i.i.d. from the distribution: just use the empirical mean $a = \frac{1}{n}\sum_{i=1}^n q(S_i)$! In fact, this is a great way to estimate the values of a really large number of predicates, so long as they were chosen <i>non-adaptively</i>: that is, so long as you came up with all of the predicates you wanted to estimate before you estimated any of the answers. This phenomenon is, for example, what classical generalization theorems in machine learning rely on: the empirical error of a set of classifiers in some model class will be a good estimate of their actual, out-of-sample error, so long as your dataset is at least as large as the logarithm of your model class.<br /><div><br /></div><div>But this guarantee breaks down if the predicates that you want to estimate are chosen in sequence, adaptively. For example, suppose you are trying to fit a machine learning model to data. If you train your first model, estimate its error, and then as a result of the estimate tweak your model and estimate its error again, you are engaging in exactly this kind of adaptivity. If you repeat this many times (as you might when you are tuning hyper-parameters in your model) you could quickly get yourself into big trouble. Of course there is a simple way around this problem: just don't re-use your data. The most naive baseline that gives statistically valid answers is called "data splitting". If you want to test k models in sequence, just randomly partition your data into k equal sized parts, and test each model on a fresh part. The holdout method is just the special case of k = 2.  But this "naive" method doesn't make efficient use of data: its data requirements grow <i>linearly</i> with the number of models you want to estimate. </div><div><br /></div><div>It turns out its possible to do better by perturbing the empirical means with a little bit of noise before you use them: this is what we (Dwork, Feldman, Hardt, Pitassi, Reingold, and Roth --- DFHPRR) showed back in 2014 in <a href="https://arxiv.org/abs/1411.2664">this paper</a>, which helped kick off a small subfield known as "adaptive data analysis". In a nutshell, we proved a "transfer theorem" that says the following: if your statistical estimator is simultaneously <i>differentially private</i> and <i>sample accurate</i> --- meaning that with high probability it provides estimates that are close to the empirical means, then it will also be accurate out of sample. When paired with a simple differentially private mechanism for answering queries --- just perturbing their answers with Gaussian noise --- this gave a significant asymptotic improvement in data efficiency over the naive baseline! You can see how well it does in this figure (click to enlarge it): </div><div style="clear: both; text-align: center;" class="separator"><a style="margin-left: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-Eip3yKJl5mE/XXWfXoqt8KI/AAAAAAAATxY/FMSJHq4ClJgZXOhuACMC5ZMFFQ0W8cmOgCLcBGAs/s1600/DFHPRRonly.png"><img width="320" src="https://1.bp.blogspot.com/-Eip3yKJl5mE/XXWfXoqt8KI/AAAAAAAATxY/FMSJHq4ClJgZXOhuACMC5ZMFFQ0W8cmOgCLcBGAs/s320/DFHPRRonly.png" border="0" height="205" /></a></div><div style="text-align: left;">Well... Hmm. In this figure, we are plotting how many adaptively chosen queries can be answered accurately as a function of dataset size. By "accurately" we have arbitrarily chosen to mean: answers that have confidence intervals of width 0.1 and uniform coverage probability 95%. On the x axis, we've plotted the dataset size n, ranging from 100,000 to about 12 million. And we've plotted two methods: the "naive" sample splitting baseline, and using the sophisticated Gaussian perturbation technique, as analyzed by the bound we proved in the "DFHPRR" paper. (Actually --- a numerically optimized variant of that bound!) You can see the problem. Even with a dataset size in the tens of millions, the sophisticated method does substantially worse than the naive method! You can extrapolate from the curve that the DFHPRR bound will <i>eventually</i> beat the naive bound, but it would require a truly enormous dataset. When I try extending the plot out that far my optimizer runs into numeric instability issues. </div><div style="text-align: left;"><br /></div><div style="text-align: left;">There has been improvement since then. In particular, DFHPRR didn't even obtain the best bound asymptotically. It is folklore that differentially private estimates generalize in expectation: the trickier part is to show that they enjoy <i>high probability</i> generalization bounds. This is what we showed in a sub-optimal way in DFHPRR. In 2015, a <a href="https://arxiv.org/abs/1511.02513">beautiful paper</a> by Bassily, Nissim, Steinke, Smith, Stemmer, and Ullman (BNSSSU) introduced the amazing "monitor technique" to obtain the asymptotically optimal high probability bound. An upshot of the bound was that the Gaussian mechanism can be used to answer roughly $k = n^2$ queries --- a quadratic improvement over the naive sample splitting mechanism! You can read about this technique in the lecture notes of the <a href="https://adaptivedataanalysis.com/">adaptive data analysis class</a> Adam Smith and I taught a few years back.  Lets see how it does (click to enlarge):</div><div style="clear: both; text-align: center;" class="separator"><a style="margin-left: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-C83SCyN8uzc/XXWjUcHmTHI/AAAAAAAATxk/GbtveNxoh18E7xOA2HQf67OGj9ujeCAuwCLcBGAs/s1600/DFHPRRandBNSSSU.png"><img width="320" src="https://1.bp.blogspot.com/-C83SCyN8uzc/XXWjUcHmTHI/AAAAAAAATxk/GbtveNxoh18E7xOA2HQf67OGj9ujeCAuwCLcBGAs/s320/DFHPRRandBNSSSU.png" border="0" height="206" /></a></div><div style="text-align: left;">Substantially better! Now we're plotting n from 100,000 up to about only 1.7 million. At this scale, the DFHPRR bound appears to be constant (at essentially 0), whereas the BNSSSU bound clearly exhibits quadratic behavior. It even beats the baseline --- by a little bit, so long as your dataset has somewhat more than a million entries... I should add that what we're plotting here is again a numerically optimized variant of the BNSSSU bound, not the closed-form version from their paper. So maybe not yet a practical technique. The problem is that the monitor argument --- while brilliant --- seems unavoidably to lead to large constant overhead.  </div><div style="text-align: left;"><br /></div><div style="text-align: left;">Which brings us to our new work (this is joint work with Christopher Jung, Katrina Ligett, Seth Neel, Saeed Sharifi-Malvajerdi, and Moshe Shenfeld). We give a brand new proof of the transfer theorem. It is elementary, and in particular, obtains high probability generalization bounds directly from high probability sample-accuracy bounds, avoiding the need for the monitor argument. I think the proof is the most interesting part --- its simple and (I think) illuminating --- but an upshot is that we get <i>substantially</i> better bounds, even though the improvement is just in the constants (the existing BNSSSU bound is known to be asymptotically tight). Here's the plot with our bound included --- the x-axis is the same, but note the substantially scaled-up y axis (click to enlarge): </div><div style="text-align: left;"><br /></div><div style="clear: both; text-align: center;" class="separator"><a style="margin-left: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-oR4HDFR07bE/XXWlv1vVIDI/AAAAAAAATxw/Fqbm-weNbMoQ5WbOgeOY3f0p6N2QN9bMACLcBGAs/s1600/allthree.png"><img width="320" src="https://1.bp.blogspot.com/-oR4HDFR07bE/XXWlv1vVIDI/AAAAAAAATxw/Fqbm-weNbMoQ5WbOgeOY3f0p6N2QN9bMACLcBGAs/s320/allthree.png" border="0" height="200" /></a></div><div style="text-align: center;"><br /></div><div style="text-align: left;"><br /><b><u>Proof Sketch</u></b><br />Ok: on to the proof. Here is the trick. In actuality, the dataset S is first sampled from $\mathcal{P}^n$, and then some data analyst interacts with a differentially private statistical estimator, resulting in some transcript $\pi$ of query answer pairs. But now imagine that <i>after the interaction is complete</i>, S is <i>resampled</i> from $Q_\pi = (\mathcal{P}^n)|\pi$, the posterior distribution on datasets conditioned on $\pi$. If you reflect on this for a moment, you'll notice that this resampling experiment doesn't change the joint distribution on dataset transcript pairs $(S,\pi)$ at all. So if the mechanism promised high probability sample accuracy bounds, it still promises them in this resampling experiment. But lets think about what that means: the mechanism can <i>first commit</i> to some set of answers $a_i$, and promise that with high probability, <i>after</i> S is resampled from $Q_\pi$, $|a_i - \frac{1}{n}\sum_{j=1}^n q_i(S_j)|$ is small. But under the resampling experiment, it is quite likely that the empirical value of the query $\frac{1}{n}\sum_{j=1}^n q_i(S_j)$ will end up being close to its expectation over the posterior: $q_i(Q_{\pi}) = \mathrm{E}_{S \sim Q_{\pi}}[\frac{1}{n}\sum_{j=1}^n q_i(S_j)]$. So the only way that a mechanism can promise high probability sample accuracy is if it actually promises high probability posterior accuracy: i.e. with high probability, for every query $q_i$ that was asked and answered, we must have that $|a_i - q_i(Q_\pi)|$ is small.<br /><br />That part of the argument was generic --- it didn't use differential privacy at all! But it serves to focus attention on these posterior distributions $Q_\pi$ that our statistical estimator induces. And it turns out its not hard to see that the expected value of queries on posteriors induced by differentially private mechanisms have to be close to their true answers. For $(\epsilon,0)$-differential privacy, it follows almost immediately from the definition. Here is the derivation. Pick your favorite query $q$ and your favorite transcript $\pi$, and write $S_j \sim S$ to denote a uniformly randomly selected element of a dataset $S$:</div><div style="text-align: left;">$$q (Q_\pi) =  \sum_{x} q (x) \cdot \Pr_{S \sim \mathcal{P}^n, S_j \sim S} [S_j = x | \pi]= \sum_{x} q (x) \cdot \frac{\Pr [\pi | S_j = x ] \cdot \Pr_{S \sim \mathcal{P}^n, S_j \sim S} [S_j = x]}{\Pr[\pi]}$$<br />$$\leq \sum_{x} q (x) \cdot \frac{e^\epsilon \Pr [\pi] \cdot \Pr_{S_j \sim \mathcal{P}} [S_j = x]}{\Pr[\pi]}<br />= e^\epsilon \cdot q (\mathcal{P})$$<br /><br />Here, the inequality follows from the definition of differential privacy, which controls the effect that fixing a single element of the dataset to any value $(S_j = x)$ can have on the probability of any transcript: it can increase it multiplicatively by a factor of at most $e^\epsilon$. </div><div style="text-align: left;"><br />And thats it: So we must have that (with probability 1!), $|q(Q_\pi) - q(\mathcal{P})| \leq e^\epsilon-1 \approx \epsilon$. The transfer theorem then follows from the triangle inequality. We get a high probability bound for free, with no need for any heavy machinery.<br /><br />The argument is just a little more delicate in the case of $(\epsilon,\delta)$-differential privacy, and can be extended beyond linear queries --- but I think this gives the basic idea. The details are in <a href="https://arxiv.org/abs/1909.03577">our new "JLNRSS" paper</a>. Incidentally, once nice thing about having many different proofs of the same theorem is that you can start to see some commonalities. One seems to be: it takes six authors to prove a transfer theorem!</div><div style="text-align: left;"><br /></div><div style="text-align: left;"><br /></div></div>







<p class="date">
by Aaron (noreply@blogger.com) <a href="http://aaronsadventures.blogspot.com/2019/09/a-new-analysis-of-adaptive-data-analysis.html"><span class="datestr">at September 10, 2019 10:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4301">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4301">Paul Bernays Lectures</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Last week, I had the honor of giving the annual <a href="https://gess.ethz.ch/en/news-and-events/paul-bernays-lectures.html">Paul Bernays Lectures</a> at ETH Zürich.  My opening line: “as I look at the list of previous Bernays Lecturers—many of them Nobel physics laureates, Fields Medalists, etc.—I think to myself, how badly did you have to screw up this year in order to end up with me?”</p>



<p><a href="https://en.wikipedia.org/wiki/Paul_Bernays">Paul Bernays</a> was the primary assistant to David Hilbert, before Bernays (being Jewish by birth) was forced out of Göttingen by the Nazis in 1933.  He spent most of the rest of his career at ETH.  He’s perhaps best known for the <a href="https://en.wikipedia.org/wiki/Von_Neumann%E2%80%93Bernays%E2%80%93G%C3%B6del_set_theory">von Neumann-Bernays-Gödel set theory</a>, and for writing (in a volume by “Hilbert and Bernays,” but actually just Bernays) arguably the first full proof of Gödel’s <a href="https://en.wikipedia.org/wiki/G%C3%B6del%27s_incompleteness_theorems#Second_incompleteness_theorem">Second Incompleteness Theorem</a>.</p>



<p>Anyway, the idea of the Paul Bernays Lectures is to rotate between Bernays’s different interests in his long, distinguished career—interests that included math, philosophy, logic, and the foundations of physics.  I mentioned that, if there’s any benefit to carting me out to Switzerland for these lectures, it’s that quantum computing theory combines <em>all</em> of these interests.  And this happens to be the moment in history right before we start finding out, directly from experiments, whether quantum computers can indeed solve certain special problems much faster.</p>



<p>The general theme for my three lectures was “Quantum Computing and the Fundamental Limits of Computation.”  The attendance was a few hundred.  My idea was to take the audience from Church and Turing in the 1930s, all the way to the quantum computational supremacy experiments that Google and others are doing now—as part of a single narrative.</p>



<p>If you’re interested, streaming video of the lectures is available as of today (though I haven’t watched it—let me know if the quality is OK!), as well as of course my slides.  Here you go:</p>



<p><strong>Lecture 1: The Church-Turing Thesis and Physics (<a href="https://video.ethz.ch/speakers/bernays/2019/7b11b50e-f813-4d26-95e0-616cc350708c.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays1.ppt">PowerPoint slides</a>)</strong> <strong>(with an intro in German by Giovanni Sommaruga, who knew Bernays, and a second intro in English by Renato Renner, who appeared on this blog <a href="https://www.scottaaronson.com/blog/?p=3975">here</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Is nature computable?  What should we even mean in formulating such a question?  For generations, the identification of “computable” with “computable by a Turing machine” has been seen as either an arbitrary mathematical definition, or a philosophical or psychological claim.  The rise of quantum computing and information, however, has brought a fruitful new way to look at the Church-Turing Thesis: namely, as a falsifiable empirical claim about the physical universe.  This talk seeks to examine the computability of the laws of physics from a modern standpoint—one that fully incorporates the insights of quantum mechanics, quantum field theory, quantum gravity, and cosmology.  We’ll critically assess ‘hypercomputing’ proposals involving (for example) relativistic time dilation, black holes, closed timelike curves, and exotic cosmologies, and will make a 21st-century case for the physical Church-Turing Thesis.</p></blockquote>



<p><strong>Lecture 2: The Limits of Efficient Computation (<a href="https://video.ethz.ch/speakers/bernays/2019/5564a353-d71b-46d4-bfc0-fa907de5de25.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays2.ppt">PowerPoint slides</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Computer scientists care about what’s computable not only in principle, but within the resource constraints of the physical universe.  Closely related, which types of problems are solvable using a number of steps that scales reasonably (say, polynomially) with the problem size?  This lecture will examine whether the notorious NP-complete problems, like the Traveling Salesman Problem, are efficiently solvable using the resources of the physical world.  We’ll start with P=?NP problem of classical computer science—its meaning, history, and current status.  We’ll then discuss quantum computers: how they work, how they can sometimes yield exponential speedups over classical computers, and why many believe that not even they will do so for the NP-complete problems.  Finally, we’ll critically assess proposals that would use exotic physics to go even beyond quantum computers, in terms of what they would render computable in polynomial time. </p></blockquote>



<p><strong>Lecture 3: The Quest for Quantum Computational Supremacy (<a href="https://video.ethz.ch/speakers/bernays/2019/2a08c4a0-67e1-4e1f-8019-3e557fcb4cde.html">watch streaming</a> / <a href="https://www.scottaaronson.com/talks/bernays3.ppt">PowerPoint slides</a>)</strong></p>



<blockquote class="wp-block-quote"><p><em>Abstract:</em> Can useful quantum computers be built in our world?  This talk will discuss the current status of the large efforts currently underway at Google, IBM, and many other places to build noisy quantum devices, with 50-100 qubits, that can clearly outperform classical computers at least on some specialized tasks — a milestone that’s been given the unfortunate name of “quantum supremacy.”  We’ll survey recent theoretical work (on BosonSampling, random circuit sampling, and more) that aims to tell us: which problems should we give these devices, that we’re as confident as possible are hard for classical computers?  And how should we check whether the devices indeed solved them?  We’ll end by discussing a new protocol, for generating certified random bits, that can be implemented almost as soon as quantum supremacy itself is achieved, and which might therefore become the first application of quantum computing to be realized.</p></blockquote>



<p>Finally, thanks so much to Giovanni Sommaruga and everyone else at ETH for arranging a fantastic visit.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4301"><span class="datestr">at September 09, 2019 10:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/116">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/116">TR19-116 |  $d$-to-$1$ Hardness of Coloring $4$-colorable Graphs with $O(1)$ colors | 

	Venkatesan Guruswami, 

	Sai Sandeep</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The $d$-to-$1$ conjecture of Khot asserts that it is hard to satisfy an $\epsilon$ fraction of constraints of a satisfiable $d$-to-$1$ Label Cover instance, for arbitrarily small $\epsilon &gt; 0$. We prove that the $d$-to-$1$ conjecture for any fixed $d$ implies the hardness of coloring a $4$-colorable graph with $C$ colors for arbitrarily large integers $C$. Earlier, this implication was only known under the $2$-to-$1$ conjecture, which is the strongest in the family of $d$-to-$1$ conjectures.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/116"><span class="datestr">at September 09, 2019 08:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/09/09/quics-hartree-postdoctoral-fellowship-at-university-of-maryland-apply-by-december-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/09/09/quics-hartree-postdoctoral-fellowship-at-university-of-maryland-apply-by-december-1-2019/">QuICS Hartree Postdoctoral Fellowship at University of Maryland (apply by December 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Joint Center for Quantum Information and Computer Science seeks exceptional candidates for QuICS Hartree Postdoctoral Fellowships in Quantum Information and Computer Science. QuICS postdocs will interact with leading computer scientists and physicists at the University of Maryland and the National Institute of Standards and Technology.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/14493">https://academicjobsonline.org/ajo/jobs/14493</a><br />
Email: quics-coordinator@umiacs.umd.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/09/09/quics-hartree-postdoctoral-fellowship-at-university-of-maryland-apply-by-december-1-2019/"><span class="datestr">at September 09, 2019 04:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5655789602676044507">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/09/are-there-any-natural-problems-complete.html">Are there any natural problems complete for NP INTER TALLY? NP INTER SPARSE?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
Recall:<br />
<br />
A is a <i>tally set</i> if A ⊆ 1<sup>*</sup>. <br />
<br />
<br />
A is a <i>sparse set</i> if there is a polynomial p such that the number of strings of length n is ≤ p(n). <br />
<br />
<br />
If there exists a sparse set A that is NP-hard under m-reductions (even btt-reductions) then P=NP. (See <a href="https://blog.computationalcomplexity.org/2006/04/favorite-theorems-small-sets.html">this post</a>.)<br />
<br />
If there exists a sparse set A that is NP-hard under T-reductions then PH collapses. (See <a href="https://blog.computationalcomplexity.org/2006/11/favorite-theorems-nonuniform.html">this post</a>.)<br />
<br />
Okay then!<br />
<br />
I have sometimes had a tally set or a sparse set that is in NP and I think that its not in P. I would like to prove, or at least conjecture, that it's NP-complete. But alas, I cannot since then P=NP. (Clarification: If my set is NP-complete then P=NP. I do not mean that the very act of conjecturing it would make P=NP. That would be an awesome superpower.)<br />
<br />
So what to do?  <br />
<br />
A is <i>NPSPARSE-complete </i> if A is in NP, A is sparse, and for all B that are in NP and sparse, B ≤<sub>m</sub> A.<br />
<br />
Similar for NPTALLY and one can also look at other types of reductions.<br />
<br />
So, can I show that my set is NPSPARSE-complete? Are there any NPSPARSE-complete sets? Are there NATURAL ones? (Natural is a slippery notion- see this <a href="https://blog.computationalcomplexity.org/2004/03/unnatural-post.html">post by Lance</a>.)<br />
<br />
Here is what I was able to find out (if more is known then please leave comments with pointers.)<br />
<br />
1) It was observed by <a href="https://lance.fortnow.com/papers/files/npsparse.pdf">Bhurman, Fenner, Fortnow, van Velkebeek</a> that the following set is NPTALLY-complete:<br />
<br />
Let M<sub>1</sub>, M<sub>2</sub>, ... be a standard list of NP-machines. Let<br />
<br />
A = { 1<sup>(i,n,t)</sup> : M<sub>i</sub>(1<sup>n</sup>) accepts on some path within t steps }'<br />
<br />
The set involves Turing Machines so its not quite what I want.<br />
<br />
<br />
2) <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/messnertoran.pdf">Messner and Toran</a> show that, under an unlikely assumption about proof systems there exists an NPSPARSE-complete set. The set involves Turing Machines. Plus it uses an unlikely assumption. Interesting, but not quite what I want.<br />
<br />
<br />
3) Buhrman, Fenner, Fortnow, van Melkebeek also showed that there are relativized worlds where there are no NPSPARSE sets (this was their main result). Interesting but not quite what I want.  <br />
<br />
4) If A is NE-complete then the tally version: { 1<sup>x</sup> : x is in A } is likely NPTALLY-complete. This may help me get what I want.<br />
<br />
Okay then!<br />
<br />
Are there any other sets that are NPTALLY-complete. NPSPARSE-complete? The obnoxious answer is to take finite variants of A.  What I really want a set of such problems so that we can proof other problems NPTALLY-complete or NPSPARSE-complete with the ease we now prove problems NP-complete.<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/09/are-there-any-natural-problems-complete.html"><span class="datestr">at September 09, 2019 02:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/09/09/multiple-postdoc-positions-at-irif-paris-france-apply-by-november-3-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/09/09/multiple-postdoc-positions-at-irif-paris-france-apply-by-november-3-2019/">Multiple Postdoc Positions at IRIF, Paris, France (apply by November 3, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>IRIF is seeking excellent candidates for postdoctoral positions in all areas of the Foundations of Computer Science.</p>
<p>Candidates must hold a Ph.D. degree in Computer Science or a related area before the starting date of the position. Knowledge of French is not required.</p>
<p>For a list of specific openings as well as instructions how to apply please visit the webpage mentioned below.</p>
<p>Website: <a href="https://www.irif.fr/postes/postdoc">https://www.irif.fr/postes/postdoc</a><br />
Email: postdoc-advice@irif.fr</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/09/09/multiple-postdoc-positions-at-irif-paris-france-apply-by-november-3-2019/"><span class="datestr">at September 09, 2019 09:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/115">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/115">TR19-115 |  Parameterized Intractability of Even Set and Shortest Vector Problem | 

	Arnab Bhattacharyya, 

	Édouard Bonnet, 

	László Egri, 

	Suprovat Ghoshal, 

	Karthik  C. S., 

	Bingkai Lin, 

	Pasin Manurangsi, 

	Dániel Marx</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The k-Even Set problem is a parameterized variant of the Minimum Distance Problem of linear codes over $\mathbb{F}_2$, which can be stated as follows: given a generator matrix A and an integer k, determine whether the code generated by A has distance at most k, or in other words, whether there is a nonzero vector x such that Ax has at most k nonzero coordinates. The question of whether k-Even Set is fixed parameter tractable (FPT) parameterized by the distance k has been repeatedly raised in literature; in fact, it is one of the few remaining open questions from the seminal book of Downey and Fellows (1999). In this work, we show that k-Even Set is W[1]-hard under randomized reductions.

We also consider the parameterized k-Shortest Vector Problem (SVP), in which we are given a lattice whose basis vectors are integral and an integer k, and the goal is to determine whether the norm of the shortest vector (in the $\ell_p$ norm for some fixed p) is at most k. Similar to k-Even Set, understanding the complexity of this problem is also a long-standing open question in the field of Parameterized Complexity. We show that, for any p&gt;1, k-SVP is W[1]-hard to approximate (under randomized reductions) to some constant factor.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/115"><span class="datestr">at September 09, 2019 06:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17957">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/09/09/paul-balister-bela-bollobas-robert-morris-julian-sahasrabudhe-and-marius-tiba-flat-polynomials-exist/">Paul Balister, Béla Bollobás, Robert Morris, Julian Sahasrabudhe, and Marius Tiba: Flat polynomials exist!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-2.png"><img src="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-2.png?w=640" alt="" class="alignnone size-full wp-image-18015" /></a></p>
<p><span style="color: #ff0000;" class="caption-text">Béla Bollobás and Paul Erdős at the University of Cambridge in 1990. </span><span class="credit"><span style="color: #ff0000;"><span class="visually-hidden">Credit</span> George Csicsery (from the 1993 film “N is a Number”)</span> <a href="https://wordplay.blogs.nytimes.com/2013/07/08/bollobas/">(source)</a></span></p>
<p>(I thank Gady Kozma for telling me about the result.)</p>
<p>An old problem from analysis with a rich history and close ties with combinatorics is now solved!</p>
<p>The paper is: Paul Balister, Béla Bollobás, Robert Morris, Julian Sahasrabudhe, and Marius Tiba,  <a href="https://arxiv.org/abs/1907.09464">Flat Littelwood Polynomials exist</a></p>
<p><strong>Abstract:</strong> We show that there exist absolute constants <span class="MathJax" id="MathJax-Element-1-Frame"><span class="math" id="MathJax-Span-1"><span class="mrow" id="MathJax-Span-2"><span class="mi" id="MathJax-Span-3">Δ </span><span class="mo" id="MathJax-Span-4">&gt; </span><span class="mi" id="MathJax-Span-5">δ </span><span class="mo" id="MathJax-Span-6">&gt; </span><span class="mn" id="MathJax-Span-7">0</span></span></span></span> such that, for all <em><span class="MathJax" id="MathJax-Element-2-Frame"><span class="math" id="MathJax-Span-8"><span class="mrow" id="MathJax-Span-9"><span class="mi" id="MathJax-Span-10">n</span><span class="mo" id="MathJax-Span-11">⩾</span><span class="mn" id="MathJax-Span-12">2</span></span></span></span></em>, there exists a polynomial <em><span class="MathJax" id="MathJax-Element-3-Frame"><span class="math" id="MathJax-Span-13"><span class="mrow" id="MathJax-Span-14"><span class="mi" id="MathJax-Span-15">P</span></span></span></span></em> of degree <em><span class="MathJax" id="MathJax-Element-4-Frame"><span class="math" id="MathJax-Span-16"><span class="mrow" id="MathJax-Span-17"><span class="mi" id="MathJax-Span-18">n</span></span></span></span></em>, with <span class="MathJax" id="MathJax-Element-5-Frame"><span class="math" id="MathJax-Span-19"><span class="mrow" id="MathJax-Span-20"><span class="mo" id="MathJax-Span-21">±</span><span class="mn" id="MathJax-Span-22">1</span></span></span></span> coefficients, such that</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Csqrt+n+%5Cle+%7CP%28z%29%7C+%5Cle+%5CDelta+%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta \sqrt n \le |P(z)| \le \Delta \sqrt n" class="latex" title="\delta \sqrt n \le |P(z)| \le \Delta \sqrt n" /></p>
<p>for all <em><span class="MathJax" id="MathJax-Element-7-Frame"><span class="math" id="MathJax-Span-45"><span class="mrow" id="MathJax-Span-46"><span class="mi" id="MathJax-Span-47">z </span><span class="mo" id="MathJax-Span-48">∈ </span><span class="texatom" id="MathJax-Span-49"><span class="mrow" id="MathJax-Span-50"><span class="mi" id="MathJax-Span-51">C</span></span></span></span></span></span></em> with <em><span class="MathJax" id="MathJax-Element-8-Frame"><span class="math" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="texatom" id="MathJax-Span-54"><span class="mrow" id="MathJax-Span-55"><span class="mo" id="MathJax-Span-56">|</span></span></span><span class="mi" id="MathJax-Span-57">z</span><span class="texatom" id="MathJax-Span-58"><span class="mrow" id="MathJax-Span-59"><span class="mo" id="MathJax-Span-60">|</span></span></span><span class="mo" id="MathJax-Span-61">=</span><span class="mn" id="MathJax-Span-62">1</span></span></span></span></em>. This confirms a conjecture of Littlewood from 1966.</p>
<h3><span style="color: #0000ff;">A little more about the result</span></h3>
<p>It is still a major open problem to replace <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\delta" class="latex" title="\delta" /> by <img src="https://s0.wp.com/latex.php?latex=%281-o%281%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(1-o(1))" class="latex" title="(1-o(1))" /> and <img src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta" class="latex" title="\Delta" /> by <img src="https://s0.wp.com/latex.php?latex=1%2Bo%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1+o(1)" class="latex" title="1+o(1)" /> (ultra-flat polynomials).</p>
<p>The problem can be traced back to a 1916 paper by Hardy and Littlewood.</p>
<p>Shapiro (1959) and Rudin (1959) showed the existence of such polynomials when you only require <img src="https://s0.wp.com/latex.php?latex=P%28z%29+%5Cle+%5CDelta+%5Csqrt+n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(z) \le \Delta \sqrt n" class="latex" title="P(z) \le \Delta \sqrt n" /> for all <em><span class="MathJax" id="MathJax-Element-7-Frame"><span class="math" id="MathJax-Span-45"><span class="mrow" id="MathJax-Span-46"><span class="mi" id="MathJax-Span-47">z </span><span class="mo" id="MathJax-Span-48">∈ </span><span class="texatom" id="MathJax-Span-49"><span class="mrow" id="MathJax-Span-50"><span class="mi" id="MathJax-Span-51">C</span></span></span></span></span></span></em> with <em><span class="MathJax" id="MathJax-Element-8-Frame"><span class="math" id="MathJax-Span-52"><span class="mrow" id="MathJax-Span-53"><span class="texatom" id="MathJax-Span-54"><span class="mrow" id="MathJax-Span-55"><span class="mo" id="MathJax-Span-56">|</span></span></span><span class="mi" id="MathJax-Span-57">z</span><span class="texatom" id="MathJax-Span-58"><span class="mrow" id="MathJax-Span-59"><span class="mo" id="MathJax-Span-60">|</span></span></span><span class="mo" id="MathJax-Span-61">=</span><span class="mn" id="MathJax-Span-62">1</span></span></span></span></em>.</p>
<p>The new result confirms a conjecture of Littlewood from 1966 and answers a question by Erdős from 1957.</p>
<p>If one allows complex coefficients of absolute value one, ultra flat polynomials exist by a result of Kahane (1980). Bombieri and Bourgain (2009) gave an explicit construction with sharper bounds.</p>
<p>The proof relies strongly on Spencer’s famous result :”Six standard deviation suffices”.  (In fact, on a version of Spencer’s result by Lovett and Meka.)<span id="more-17957"></span></p>
<h3><span style="color: #0000ff;">Six standard deviation suffices</span></h3>
<p>Here is a reminder of Spencer’s theorem. (See <a href="https://rjlipton.wordpress.com/2019/07/25/discrepancy-games-and-sensitivity/">this GLL post;</a> We talked about it before and also on related results in Discrepancy’s theory, see <a href="https://gilkalai.wordpress.com/2011/08/28/discrepancy-the-beck-fiala-theorem-and-the-answer-to-test-your-intuition-14/">this post</a> and <a href="https://gilkalai.wordpress.com/2013/08/08/poznan-random-structures-and-algorithms-2013/">this one</a> and also <a href="https://gowers.wordpress.com/2012/08/27/edp23-second-guest-post-by-gil-kalai/">this one</a> on Gowers’s blog.)</p>
<p>Spencer’s “Six standard deviation suffices” theorem:  If <img src="https://s0.wp.com/latex.php?latex=L_i%28x_1%2C%5Cdots%2Cx_n%29%3D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L_i(x_1,\dots,x_n)=" class="latex" title="L_i(x_1,\dots,x_n)=" /> <img src="https://s0.wp.com/latex.php?latex=%3D+a_%7Bi1%7D+x_1+%2B+%5Cdots+%2B+a_%7Bin%7D+x_n%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="= a_{i1} x_1 + \dots + a_{in} x_n," class="latex" title="= a_{i1} x_1 + \dots + a_{in} x_n," /> <img src="https://s0.wp.com/latex.php?latex=%5Cquad+1+%5Cleq+i+%5Cleq+n%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\quad 1 \leq i \leq n," class="latex" title="\quad 1 \leq i \leq n," /> are <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> linear forms in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> variables with all <img src="https://s0.wp.com/latex.php?latex=%7Ca_%7Bij%7D%7C+%5Cleq+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|a_{ij}| \leq 1" class="latex" title="|a_{ij}| \leq 1" />, then there exist numbers <img src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon_1%2C%5Cdots%2C%5Cvarepsilon_n+%5Cin+%5C%7B-1%2C%2B1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\varepsilon_1,\dots,\varepsilon_n \in \{-1,+1\}" class="latex" title="\varepsilon_1,\dots,\varepsilon_n \in \{-1,+1\}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7CL_i%28%5Cvarepsilon_1%2C%5Cdots%2C%5Cvarepsilon_n%29%7C+%5Cleq+K+%5Csqrt%7Bn%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|L_i(\varepsilon_1,\dots,\varepsilon_n)| \leq K \sqrt{n}," class="latex" title="|L_i(\varepsilon_1,\dots,\varepsilon_n)| \leq K \sqrt{n}," /> for all <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />.</p>
<h3><span style="color: #0000ff;">My favorite (rather) flat polynomial: the determinant</span></h3>
<p>The determinant thought of as a polynomial of <img src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n^2" class="latex" title="n^2" /> variable is rather flat as far as upper bounds are concerned.  (Moreover, if you restrict yourself to matrices where the rows are orthonormal then the determinant is constant.) I will be happy to learn about  other rather-flat examples of explicit and algebraically significant polynomials. (Even on sub-varieties.)</p>
<p>Remark: Here is <a href="https://arxiv.org/abs/1904.04806">a paper by the same team</a> on Erdős’ covering systems.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-1.png"><img src="https://gilkalai.files.wordpress.com/2019/09/bollobas-erdos-1.png?w=640" alt="" class="alignnone size-full wp-image-18016" /></a></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/09/09/paul-balister-bela-bollobas-robert-morris-julian-sahasrabudhe-and-marius-tiba-flat-polynomials-exist/"><span class="datestr">at September 09, 2019 05:01 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16231">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/">Separating Words by Automata</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Another exponential gap in complexity theory?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/unknown-127/" rel="attachment wp-att-16234"><img src="https://rjlipton.files.wordpress.com/2019/09/unknown-1.jpeg?w=600" alt="" class="alignright size-full wp-image-16234" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ From his home page ]</font></td>
</tr>
</tbody>
</table>
<p>
Jeffrey Shallit is a famous researcher into many things, including number theory and being a skeptic. He has a colorful website with an extensive quotation <a href="https://cs.uwaterloo.ca/~shallit/quotes.html">page</a>—one of my favorites by Howard Aiken is right at the top:</p>
<blockquote><p><b> </b> <em> Don’t worry about people stealing an idea. If it’s original, you will have to ram it down their throats. </em>
</p></blockquote>
<p></p><p>
Today I thought I would discuss a wonderful problem that Jeffrey has worked on.</p>
<p>
Jeffrey’s <a href="https://arxiv.org/abs/1103.4513">paper</a> is joint with Erik Demaine, Sarah Eisenstat, and David Wilson. See also his <a href="https://cs.uwaterloo.ca/~shallit/Talks/bc4.pdf">talk</a>. They say in their introduction:</p>
<blockquote><p><b> </b> <em> Imagine a computing device with very limited powers. What is the simplest computational problem you could ask it to solve? It is not the addition of two numbers, nor sorting, nor string matching—it is telling two inputs apart: distinguishing them in some way. </em>
</p></blockquote>
<p></p><p>
More formally: </p>
<blockquote><p><b> </b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> be two distinct <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> long strings over the usual binary alphabet. What is the size of the smallest deterministic automaton <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> that can accept one of the strings and reject the other? </em>
</p></blockquote>
<p></p><p>
That is, how hard is it for a simple type of machine to tell <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> apart from <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />? There is no super cool name for the question—it is called the <i>Separating Words Problem</i> (<a href="https://en.wikipedia.org/wiki/Separating_words_problem">SWP</a>). </p>
<p>
</p><p></p><h2> Some History </h2><p></p>
<p></p><p>
Pavel Goral&amp;ccaron;ik and Vaclav Koubek introduced the problem in 1986—see their paper <a href="https://link.springer.com/chapter/10.1007/3-540-16761-7_61">here</a>. Suppose that <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> are distinct binary words of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. Define <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BSEP%7D%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bf{SEP}(x,y)}" class="latex" title="{\bf{SEP}(x,y)}" /> to be the number of states of the smallest automaton that accepts <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and rejects <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> or vice-versa. They proved the result that got people interested:</p>
<blockquote><p><b>Theorem 1</b> <em> For all distinct binary words <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cy%29+%3Do%28n%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  {\bf SEP}(x,y) =o(n). " class="latex" title="\displaystyle  {\bf SEP}(x,y) =o(n). " /></p>
</em><p><em></em>
</p></blockquote>
<p>That is the size of the automaton is asymptotically sub-linear. Of course there is trivially a way to tell the words apart with order <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> states. The surprise is that one can do better, always.</p>
<p>
In 1989 John Robson obtained the best known result: </p>
<blockquote><p><b>Theorem 2</b> <em> For all distinct binary words <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cy%29+%3D+O%28n%5E%7B2%2F5%7D%28%5Clog+n%29%5E%7B3%2F5%7D%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  {\bf SEP}(x,y) = O(n^{2/5}(\log n)^{3/5}). " class="latex" title="\displaystyle  {\bf SEP}(x,y) = O(n^{2/5}(\log n)^{3/5}). " /></p>
</em><p><em></em>
</p></blockquote>
<p></p><p>
This bound is pretty strange. We rarely see bounds like it. This suggest to me that it is either special or it is not optimal. Not clear which is the case. By the way it is also known that there are <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> so that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cy%29+%3D+%5COmega%28%5Clog+n%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  {\bf SEP}(x,y) = \Omega(\log n). " class="latex" title="\displaystyle  {\bf SEP}(x,y) = \Omega(\log n). " /></p>
<p>Thus there is an exponential gap between the known lower and upper bounds. Welcome to complexity theory.</p>
<p>
What heightens interest in this gap is that whenever the words have different lengths, there is always a logarithmic-size automaton that separates them. The reason is our old friend, the Chinese Remainder Theorem. Simply, if <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m &lt; n}" class="latex" title="{m &lt; n}" /> there is always a short prime <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> that does not divide <img src="https://s0.wp.com/latex.php?latex=%7Bn+-+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n - m}" class="latex" title="{n - m}" />, which means that the DFA that goes in a cycle of length <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> will end in a different state on any <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> of length <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> from the state on any <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. Moreover, the strings <img src="https://s0.wp.com/latex.php?latex=%7B0%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0^m}" class="latex" title="{0^m}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B0%5EN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0^N}" class="latex" title="{0^N}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> equals <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> plus the least common multiple of <img src="https://s0.wp.com/latex.php?latex=%7B1%2C%5Cdots%2Cm%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1,\dots,m+1}" class="latex" title="{1,\dots,m+1}" /> require <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28%5Clog+N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(\log N)}" class="latex" title="{\Omega(\log N)}" /> states to separate. Padding these with <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />s gives equal-length pairs of all lengths <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> giving <b>SEP</b>(x,y)<img src="https://s0.wp.com/latex.php?latex=%7B%5Csim+%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sim \log n}" class="latex" title="{\sim \log n}" />.</p>
<p>
Some other facts about SWP can be found in the paper:</p>
<ul>
<li>
(a) It does not matter whether the alphabet is binary or larger. <p></p>
</li><li>
(b) For random distinct <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y}" class="latex" title="{x,y}" />, the expected number of states needed to separate them is at most <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" />. <p></p>
</li><li>
(c) All length-<img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> pairs <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y}" class="latex" title="{x,y}" /> can be distinguished by deterministic pushdown automata (with two-way input tape) of size <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" />.
</li></ul>
<p>
Point (b) underscores why it has been hard to find “bad pairs” that defeat all small DFAs. All this promotes belief that logarithmic is the true upper bound as well. Jeffrey stopped short of calling this a conjecture in his talk, but he did offer a 100-pound prize (the talk was in Britain) for improving Robson’s bound. </p>
<p>
</p><p></p><h2> Some Questions </h2><p></p>
<p></p><p>
There are many partial results in cases where <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> are restricted in some way. See the papers for details. I thought I would just repeat a couple of interesting open cases.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> How hard is it to tell words from their reversal? That is, if <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is a word can we prove a better bound on 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7B%5Cbf+SEP%7D%28x%2Cx%5E%7BR%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  {\bf SEP}(x,x^{R}). " class="latex" title="\displaystyle  {\bf SEP}(x,x^{R}). " /></p>
<p>Recall <img src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^{R}}" class="latex" title="{x^{R}}" /> is the reversal of the word <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" />. Of course we assume that <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is not the same as its reversal—that is, we assume that <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is not a palindrome.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> How hard is it to tell words apart from their cyclic shifts?</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> How hard is it to tell words from their <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /> You get the idea: try other operations on words. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
The SWP is a neat question in my opinion. I wonder if there would be some interesting consequence if we could always tell two words apart with few states. The good measure of a conjecture is: how many consequences are there that follow from it? I wonder if there could be some interesting applications. What do you think?</p>
<p></p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/"><span class="datestr">at September 08, 2019 08:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/114">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/114">TR19-114 |  Singular tuples of matrices is not a null cone (and, the symmetries of algebraic varieties) | 

	Visu Makam, 

	Avi Wigderson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The following multi-determinantal algebraic variety plays a central role in algebra, algebraic geometry and computational complexity theory: ${\rm SING}_{n,m}$, consisting of all $m$-tuples of $n\times n$ complex matrices which span only singular matrices. In particular, an efficient deterministic algorithm testing membership in ${\rm SING}_{n,m}$ will imply super-polynomial circuit lower bounds, a holy grail of the theory of computation.
  A sequence of recent works suggests such efficient algorithms for memberships in a general class of algebraic varieties, namely the null cones of linear group actions. Can this be used for the problem above? Our main result is negative: ${\rm SING}_{n,m}$ is not the null cone of any (reductive) group action! This stands in stark contrast to a non-commutative analog of this variety, and points to an inherent structural difficulty of ${\rm SING}_{n,m}$.
  To prove this result we identify precisely the group of symmetries of ${\rm SING}_{n,m}$. We find this characterization, and the tools we introduce to prove it, of independent interest. Our work significantly generalizes a result of Frobenius for the special case $m=1$, and suggests a general method for determining the symmetries of algebraic varieties.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/114"><span class="datestr">at September 08, 2019 06:43 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-2445620530813705016">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2019/09/off-to-algoesa-2019.html">Off to ALGO/ESA 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I'm shortly hopping on a plane to head to ALGO/ESA.  I'll be giving a survey-ish talk on Learning Augmented Algorithms, covering my work so far in the area as well as some of the work by others.  I think it's a highly promising direction fitting in the framework of Beyond Worst Case Analysis, so I'm excited to give the talk, and hoping it's still a novel enough area to be new to most of the audience. <br /><br />For those of you who are there, feel free to say hi -- I'm looking forward to talking to people. <br /><br /><br /></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2019/09/off-to-algoesa-2019.html"><span class="datestr">at September 07, 2019 07:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4297">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4297">A rare classified ad</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Dana and I are searching for a live-in nanny for our two kids, Lily (age 6) and Daniel (age 2).  We can offer $750/week.  We can also offer a private room with a full bathroom and a beautiful view in our home in central Austin, TX, as well as free food and other amenities.  The responsibilities include helping to take the kids to and from school and drive them to various activities, helping to get them ready for school/daycare in the morning and ready for sleep at night, cooking and other housework.  We’d ask for no more than 45 hours per week, and could give several days off at a time depending on scheduling constraints.</p>



<p>If interested, please shoot me an email, tell me all about yourself and provide references.</p>



<p>Obviously, feel free to let anyone else know who you think might be interested (but who might not read this blog).</p>



<p>I’m really sorry to be doing this here!  We tried on classified sites and didn’t find a good match.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4297"><span class="datestr">at September 07, 2019 03:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1092995341963635215">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/09/transitioning.html">Transitioning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
You may have noticed, or not, that I haven't posted or tweeted much in the last month. I've had a busy time moving back to Chicago and starting my new position as Dean of the College of Science at Illinois Tech.<br />
<div>
<br /></div>
<div>
Part of that trip involved driving my electric Chevy Bolt from Atlanta to Chicago. You can do it, but it got a bit nerve wracking. There is only one high-speed charging station between Indianapolis and Chicago and you pray the charger outside the Lafayette Walmart actually works (it did). We passed many Tesla charging superstations, I will have to admit they have the better network. </div>
<div>
<br /></div>
<div>
Theoremwise, Ryan Alweiss, Shachar Lovett, Kewen Wu and Jiapeng Zhang had <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">significant improvements on the sunflower conjecture</a>. I posted on the sunflower theorem for Richard Rado's <a href="https://blog.computationalcomplexity.org/2006/04/richard-rado-1906-1989.html">centenary</a>. Nice to see there is still some give in it.</div>
<div>
<br /></div>
<div>
I probably will post less often in this new position. Bill asked me "Why is being a dean (or maybe its just the move) more time then being a chair? Were you this busy when you moved and first became chair?"<br />
<br />
When I moved to Atlanta, I moved a year ahead of the rest of the family and rented a condo. We had plenty of time to search for a house in Atlanta and plan the move. Here it all happened in a much more compressed time schedule and, since we've bought a condo, into a much more compressed space.</div>
<div>
<br /></div>
<div>
Being a chair certainly ate up plenty of time but it feels different as dean with a more external focus. I won't give up the blog but you'll probably hear a lot more from Bill than from me at least in the near future.</div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/09/transitioning.html"><span class="datestr">at September 05, 2019 04:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/113">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/113">TR19-113 |  Instance Complexity and Unlabeled Certificates in the Decision Tree Model | 

	Tomer Grossman, 

	Ilan Komargodski, 

	Moni Naor</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Instance complexity is a measure of goodness of an algorithm in which the performance of one algorithm is compared to others per input. This is in sharp contrast to worst-case and average-case complexity measures, where the performance is compared either on the worst input or on an average one, respectively.

  We initiate the systematic study of instance complexity and optimality in the query model (a.k.a. the decision tree model). In this model, instance optimality of an algorithm for computing a function is the requirement that the complexity of an algorithm on any input is at most a constant factor larger than the complexity of the best correct algorithm. That is we compare the decision tree to one that receives a certificate and its complexity is measured only if the certificate is correct (but correctness should hold on any input).  We study both deterministic and randomized decision trees and provide various characterizations and barriers for more general results.

  We introduce a new measure of complexity called unlabeled-certificate complexity, appropriate for graph properties and other functions with symmetries, where information about the structure of the graph is given as a certificate, but not labels of individual vertices. More precisely, the certificate is some permutation of the input (rather than the input itself) and the correctness should be maintained even if the certificate is wrong. We study both worst case complexity and instance optimality with respect to this measure of complexity. In this setting an algorithm is said to be instance optimal if for every input it performs roughly as well as the best algorithm that is given an unlabeled certificate (but is correct on every input).  We show that instance optimality depends on the group of permutations in consideration. Our proofs rely on techniques from hypothesis testing and analysis of random graphs.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/113"><span class="datestr">at September 05, 2019 03:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=662">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/09/05/e-ink-monitor-the-best-money-i-have-ever-spent-on-electronics/">E-ink monitor: the best money I have ever spent on electronics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p style="text-align: justify;">We briefly interrupt the <a href="https://emanueleviola.wordpress.com/2019/08/04/because-of-pollution-conferences-should-be-virtual/">on-flight entertainment</a> for an update on e-ink monitors (see previous posts <a href="https://emanueleviola.wordpress.com/2019/05/05/e-ink-on-the-move/">here</a> and <a href="https://emanueleviola.wordpress.com/2019/03/07/a-dream-come-true-sort-of-e-ink-monitors/">here</a>).  I am happy to report that during the summer my e-ink monitor worked extremely well.  Writing as I am doing now with the sun shining through my window is fantastic.  My entire summer production — including this <a href="https://emanueleviola.wordpress.com/2019/07/10/non-abelian-combinatorics-and-communication-complexity/">survey on non-abelian combinatorics</a> — was written exclusively on the e-ink monitor. I don’t think I ever felt so good about a piece of electronics since relentless market pressure forced me to abandon Amiga.</p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2019/09/05/e-ink-monitor-the-best-money-i-have-ever-spent-on-electronics/"><span class="datestr">at September 05, 2019 01:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1178">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1178">News for August 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>A comparatively slow month, as summer draws to a close: we found three papers online. Please let us know if we missed any! <em>(Edit: And we added two papers missed from June.) </em></p>



<p><strong>Testing convexity of functions over finite domains</strong>, by Aleksandrs Belovs, Eric Blais, and Abhinav Bommireddi (<a href="https://eccc.weizmann.ac.il/report/2019/092/">arXiv</a>). This paper studies the classic problem of convexity testing, and proves a number of interesting results on the adaptive and non-adaptive complexity of this problem in single- and multi-dimensional settings. In the single-dimensional setting on domain \([n]\), they show that adaptivity doesn’t help: the complexity will be \(O(\log n)\) in both cases. However, in the simplest two-dimensional setting, a domain of \([3] \times [n]\), they give a polylogarithmic upper bound in the adaptive setting, but a polynomial lower bound in the non-adaptive setting, showing a strong separation. Finally, they provide a lower bound for \([n]^d\) which scales exponentially in the dimension. This leaves open the tantalizing open question: is it possible to avoid the curse of dimensionality when testing convexity?</p>



<p><strong>Testing Isomorphism in the Bounded-Degree Graph Model</strong>, by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2019/102/">ECCC</a>). This work investigates the problem of testing isomorphism of graphs, focusing on the special case when the connected components are only polylogarithmically large (the general bounded-degree case is left open). One can consider when a graph is given as input, and we have to query a graph to test if they are isomorphic. This can be shown to be equivalent (up to polylogarithmic factors) to testing (from queries) whether a sequence is a permutation of a reference sequence. In turn, this can be shown to be equivalent to the classic distribution testing question of testing (from samples) whether a distribution is equal to some reference distribution. The same sequence of equivalences <em>almost</em> works for the case where there is no reference graph/sequence/distribution, but we only have query/query/sample access to the object. The one exception is that the reduction doesn’t work to reduce from testing distributions to testing whether a sequence is a permutation, due to challenges involving sampling with and without replacement. However, the author still shows the lower bound which would be implied by such a reduction by adapting Valiant’s proof for the distribution testing problem to this case.   </p>



<p><strong>Learning Very Large Graphs with Unknown Vertex Distributions</strong>, by Gábor Elek (<a href="https://arxiv.org/abs/1908.10170">arXiv</a>). In this note, the author studies a variant of distribution-free property testing on graphs, in which (roughly) neighboring vertices have probabilities of bounded ratio, and a query reveals this ratio. Applications to local graph algorithms and connections to dynamical systems are also discussed.</p>



<p>EDIT: We apparently missed two papers from June — the  first paper was accepted to NeurIPS 2019, the second to COLT 2019.<br /><strong>The Broad Optimality of Profile Maximum Likelihood</strong>, by Yi Hao and Alon Orlitsky (<a href="https://arxiv.org/abs/1908.10170">arXiv</a>). Recently, Acharya, Das, Orlitsky, and Suresh (ICML 2017) showed that the Profile Maximum Likelihood (PML) estimator enables a unified framework for estimating a number of distribution properties, including support size, support coverage, entropy, and distance to uniformity, obtaining estimates which are competitive with the best possible. The approach is rather clean: simply estimate the PML of the distribution (i.e., the maximum likelihood distribution of the data, if the the labels are discarded and only the multiplicities of elements are kept), and apply the plug-in estimator (i.e., if you want to estimate entropy, compute the entropy of the resulting PML distribution). The present work shows that PML is even more broadly applicable — such an approach applies to <em>any</em> property which is additive, symmetric, and appropriately Lipschitz. They also show specific results for many other properties which have been considered in the past, including Rényi entropy, distribution estimation, and identity testing.</p>



<p><strong>Sample-Optimal Low-Rank Approximation of Distance Matrices</strong> by Piotr Indyk, Ali Vakilian, Tal Wagner, David Woodruff (<a href="https://arxiv.org/abs/1906.00339">arXiv</a>). Getting a rank \(k\) approximation of an \(n \times m\) matrix \(M\) is about as classic a problem as it gets. Suppose we wanted a running time of \(O(n+m)\), which is sublinear in the matrix size. In general, this is not feasible, since there could be a single large entry that dominates the matrix norm. This paper studies the case where the matrix is itself a <em>distance matrix</em>. So there is an underlying point set in a metric space, and the \(i, j\)th entry of \(M\) is the distance between the $i$th and $j$th point. Previous work showed the existence of \(O((n+m)^{1+\gamma})\) time algorithms (for arbitrary small constant $\gamma &gt; 0$, with polynomial dependence on \(k\) and error parameters). This work gives an algorithm that runs in \(\widetilde{O}(n+m)\) time. The main idea is to sample the rows and columns according to row/column norms. </p></div>







<p class="date">
by Gautam Kamath <a href="https://ptreview.sublinear.info/?p=1178"><span class="datestr">at September 04, 2019 09:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17977">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/09/04/computer-science-and-its-impact-on-our-future/">Computer Science and its Impact on our Future</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A couple weeks ago I told you about <a href="https://gilkalai.wordpress.com/2019/08/04/avi-wigdersons-integrating-computational-modeling-algorithms-and-complexity-into-theories-of-nature-marks-a-new-scientific-revolution-an-invitation-for-a-discussion/">Avi Wigderson’s vision</a> on the connections between the theory of computing and other areas of mathematics on the one hand and between computer science and other areas of science, technology and society on the other hand.  In this spirit I am happy to inform about the conference “<a href="https://academy.ac.il/Index/Entry.aspx?nodeId=741&amp;entryId=21026">Computer Science and its Impact on the Future</a>” to be held in Jerusalem, September 16-18, 2019.  This is a joint conference of the Israel Academy of Science and Humanities and the (US) National academy of Science.  Incidentally, September 17 2019 is the general elections day in Israel which will also have some impact on our future.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/cs-academy.jpg"><img src="https://gilkalai.files.wordpress.com/2019/09/cs-academy.jpg?w=640&amp;h=1274" alt="" width="640" class="alignnone size-full wp-image-17978" height="1274" /></a></p>
<p>The program has sessions on quantum science and technology, computer science and society, computation and the life sciences, and AI and autonomous systems. The keynote speaker is Amnon Shashua who will speak on the promise of machime learning and AI in transforming industries. Other speakers are: Charles Bennett, Adi Stern, Dorit Aharonov, and Thomas Vidick (quantum); Noam Nisan, Omer Reingold, Shafi Goldwasser, and Moshe Vardi (society); Aviv Regev, Ron Shamir, Uri Alon and Leroy Hood (biology), Sarit Kraus, Eva Tardos, Naftali Tishby, and Gal Kaminka (AI), and David Harel (closing remarks).</p>
<p>As for startling connections between the theory of computation and other areas of mathematics let me refer to the <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">very recent post</a> with the big news on the sunflower conjecture.</p>
<p><span style="color: #000080;">In the spirit of the coming Israeli elections let me promise to report more on our recent great Oberwolfach conference, on my visit to CERN, and to tell more about the sunflower progress, and about various combinatorics (and more) news I heard about. </span></p>
<p><strong>Update: </strong>in partial fulfillment of my promises here are a couple of pictures from CERN and Oberwolfach.</p>
<p><span id="more-17977"></span></p>
<p><a href="https://gilkalai.files.wordpress.com/2019/09/d7a2d79fd79ad7a7d7a8d7a9d79ed791d7a7d7a8d79e.jpg"><img src="https://gilkalai.files.wordpress.com/2019/09/d7a2d79fd79ad7a7d7a8d7a9d79ed791d7a7d7a8d79e.jpg?w=640" alt="עןךקרשמבקרמ" class="alignnone size-full wp-image-17986" /></a><a href="https://gilkalai.files.wordpress.com/2019/09/atlas.jpg"><img src="https://gilkalai.files.wordpress.com/2019/09/atlas.jpg?w=640" alt="ATLAS" class="alignnone size-full wp-image-17987" /></a><a href="https://gilkalai.files.wordpress.com/2019/09/ow.jpg"><img src="https://gilkalai.files.wordpress.com/2019/09/ow.jpg?w=640" alt="OW" class="alignnone size-full wp-image-17988" /></a></p>
<p>ATLAS@CERN with my son in law Eran Shriker; The view at Oberwolfach.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/09/04/computer-science-and-its-impact-on-our-future/"><span class="datestr">at September 04, 2019 06:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7547">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/09/04/make-equations-blue-in-powerpoint/">Make equations blue in powerpoint</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Microsoft Powerpoint has a surprisingly powerful equation editor, which also allows to use latex macros such as <code>\alpha </code>to get <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" />. </p>



<p>I’ve blogged about the equation editor <a href="https://windowsontheory.org/2013/01/31/alt-equals/">before</a> but one pet peeve of mine was that I like to have my math in a different color, but never found a way to do this automatically. I finally decided to invest the time and find out how to do it. After a mere several years of investigation, I am happy to report that it is in fact possible to do so using Visual Basic for Applications (VBA). </p>



<p>You can view the developer tab by following <a href="https://support.office.com/en-us/article/show-the-developer-tab-e1192344-5e56-4d45-931b-e5fd9bea2d45">these instructions</a>, and then click on “macros”, type a name such as <code>All_eqs</code> and click on  “create” at which point you can add the following code:</p>


<pre class="brush: vb; gutter: false; title: ; notranslate">Sub All_eqs()

Dim oSld As Slide
Dim oShp As Shape
Dim oShapes As Shapes
 
For Each oSld In ActivePresentation.Slides
  Set oShapes = oSld.Shapes
  For Each oShp In oShapes
   If oShp.HasTextFrame Then
      If oShp.TextFrame.HasText Then
                With oShp.TextFrame.TextRange
                    For x = 1 To .Characters.Count
                        If .Characters(x).Font.Name = "Cambria Math" Then
                            .Characters(x).Font.Color.RGB = RGB(0, 112, 192)
                        End If
                    Next x
                End With

    End If
    End If
    Next oShp
 Next oSld
End Sub

</pre></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2019/09/04/make-equations-blue-in-powerpoint/"><span class="datestr">at September 04, 2019 03:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16223">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/09/04/self-play-is-key/">Self-Play Is Key?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Self-play and Ramsey numbers</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/09/04/self-play-is-key/unknown-126/" rel="attachment wp-att-16226"><img src="https://rjlipton.files.wordpress.com/2019/09/unknown.jpeg?w=600" alt="" class="alignright size-full wp-image-16226" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Talking about worst case ]</font></td>
</tr>
</tbody>
</table>
<p>
Avrim Blum is the CAO for TTIC. That is he is the Chief Academic Officer at the Toyota Technological Institute of Chicago. Avrim has and continues to make key contributions to many areas of theory—including machine learning, approximation algorithms, on-line algorithms, algorithmic game theory, the theory of database privacy, and non-worst-case analysis of algorithms. </p>
<p>
Today I want to discuss a suggestion of Avrim for research on self-play.<span id="more-16223"></span></p>
<p>
Self-play is the key to many recent AI results on playing games. These results include essentially solving the games Chess, Go, Shogi, forms of poker, and many others. They were solved by algorithms that start with no knowledge of the game, save the rules. The algorithm then learn the secrets of playing the game by self-play: by playing games against itself. For example, the AI chess programs did not know that “a rook is worth more than a pawn.” But they discover that by playing the game over and over. Impressive. </p>
<p>
For example, David Sweet on his hacker <a href="https://hackernoon.com/self-play-1f69ceb06a4d">site</a> says referring to self-play: </p>
<blockquote><p><b> </b> <em> This is mysterious to me. If it only played against itself, where did new information come from? How did it know if it was doing well? If I play a game of chess against myself, should I say I did well if I beat myself? But when I beat myself, I also lose to myself. And how could I ever know if I’d do well against someone else? </em>
</p></blockquote>
<p>
</p><p></p><h2> Planted Clique Problem </h2><p></p>
<p></p><p>
I was at TTIC last month and over lunch we discussed self-play possibilities for theory problems. I suggested that the planted clique <a href="https://en.wikipedia.org/wiki/Planted_clique">problem</a> might be a potential example. Recall the planted clique problem is the task of distinguishing two types of graphs:</p>
<ul>
<li>
Random graphs on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> vertices generated with <img src="https://s0.wp.com/latex.php?latex=%7Bp%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p=1/2}" class="latex" title="{p=1/2}" />, the probability that there is an edge between each pair of nodes; <p></p>
</li><li>
Random graphs on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> vertices generated with <img src="https://s0.wp.com/latex.php?latex=%7Bp%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p=1/2}" class="latex" title="{p=1/2}" />, with a clique of size <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> added, the planted clique.
</li></ul>
<p>
If <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> is large, it is easy to tell these apart—just count the number of edges. If <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> is small enough, it is open if one can tell them apart. The largest clique in a random graph typically has size near <img src="https://s0.wp.com/latex.php?latex=%7Bk%3D2%5Clog_%7B2%7D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k=2\log_{2} n}" class="latex" title="{k=2\log_{2} n}" />. This implies that there is a quasi-polynomial time average-case algorithm: just try all subsets of size around <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />.</p>
<p>
My intuition was that a program might be able to exploit self-play to solve planted clique problems. The point is that it is easy, by definition, to generate “yes” and “no” examples for this problem. Note, this is not known for SAT problems—generating hard instances there is not clear. This was my point. Could the AI methods somehow divine the planted clique version of “a rook is worth more than a pawn”? Could they use self-play to solve planted clique problems?</p>
<p>
I wondered to the lunch group about all this. It left the group unexcited. </p>
<p>
</p><p></p><h2> Ramsey Problem </h2><p></p>
<p></p><p>
Then Avrim asked a better question. He wondered if self-play methods could be used to solve a long standing problem concerning Ramsey numbers. Recall the Ramsey number <img src="https://s0.wp.com/latex.php?latex=%7BR%28s%2Cs%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(s,s)}" class="latex" title="{R(s,s)}" /> is defined as the smallest <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> such every red-green coloring of the edges of the complete graph <img src="https://s0.wp.com/latex.php?latex=%7BK_%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K_{n}}" class="latex" title="{K_{n}}" /> has either a red or a green subgraph of size at least <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" />.</p>
<p>
The exact value of <img src="https://s0.wp.com/latex.php?latex=%7BR%285%2C+5%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(5, 5)}" class="latex" title="{R(5, 5)}" /> is unknown, although it is known to lie between <img src="https://s0.wp.com/latex.php?latex=%7B43%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{43}" class="latex" title="{43}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B48%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{48}" class="latex" title="{48}" />. See a <a href="https://gilkalai.wordpress.com/2017/03/29/r55">post</a> by Gil Kalai on his blog for some discussions. Joel Spencer quotes Paul Erdős: </p>
<blockquote><p><b> </b> <em> Erdős asks us to imagine an alien force, vastly more powerful than us, landing on Earth and demanding the value of <img src="https://s0.wp.com/latex.php?latex=%7BR%285%2C+5%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R(5, 5)}" class="latex" title="{R(5, 5)}" /> or they will destroy our planet. In that case, he claims, we should marshal all our computers and all our mathematicians and attempt to find the value. But suppose, instead, that they ask for <img src="https://s0.wp.com/latex.php?latex=%7BR%286%2C+6%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R(6, 6)}" class="latex" title="{R(6, 6)}" />. In that case, he believes, we should attempt to destroy the aliens.	 </em>
</p></blockquote>
<p></p><p>
Aliens are not attacking currently, but Avrim’s idea is that perhaps we could organize a self-play attack on the <img src="https://s0.wp.com/latex.php?latex=%7BR%285%2C5%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(5,5)}" class="latex" title="{R(5,5)}" /> problem. The idea would be to try to build a “game” version of this question. The algorithm would try to create a strategy that finds a red/green coloring for the complete graph so that no <img src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5}" class="latex" title="{5}" />-clique is all red or all green. </p>
<p>
We need to arrange the computation of the Ramsey number as the result of some type of game. The paradox to me is that the play of a game suggests <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPSPACE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{PSPACE}}" class="latex" title="{\mathsf{PSPACE}}" />, while the Ramsey calculation is clearly of complexity <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" />. So how do we make the Ramsey calculation into a game? Ken and I wonder if there is a natural game <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> so that playing the game well yields insight into the value of a Ramsey number.</p>
<blockquote><p><b> </b> <em> <i>Is there a game <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> with simple rules so that playing it well yields bounds on general Ramsey numbers?</i> </em>
</p></blockquote>
<p>
</p><p></p><h2> Attacks on Ramsey Numbers </h2><p></p>
<p></p><p>
There have been several attempts to use non-standard methods to compute Ramsey numbers. See the following: </p>
<ul>
<li>
In this <a href="https://link.springer.com/article/10.1007/s11128-013-0541-9">article</a>, quantum methods studied for the future, when hopefully quantum computers will be available. <p></p>
</li><li>
In this <a href="https://themusegarden.wordpress.com/2013/05/11/a-genetic-algorithm-approach-to-ramsey-theory/">project</a> genetic methods are used on related Ramsey numbers. <p></p>
</li><li>
In this <a href="https://arxiv.org/pdf/1512.01613.pdf">approach</a>, AI methods are used on related Ramsey numbers.
</li></ul>
<p>
See also this <a href="https://pdfs.semanticscholar.org/0662/893d7e04745a0709b3f1a092574f9dd3bf7b.pdf">survey</a> on computational methods in general.</p>
<p>
The asymmetry between the upper and lower bounds shapes approaches. The lower bound of 43 was proved by finding a two-coloring of the edges of <img src="https://s0.wp.com/latex.php?latex=%7BK_%7B42%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K_{42}}" class="latex" title="{K_{42}}" /> without a green or red <img src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5}" class="latex" title="{5}" />-clique. Once a single coloring is guessed its property is easy to prove. The <a href="https://arxiv.org/abs/1703.08768">improvement</a> of the upper bound from 49 to 48 two years ago <a href="https://gilkalai.wordpress.com/2017/03/29/r55">needed</a> checking two trillion cases in order to fence-away all possible colorings. This has led to a common belief that 43 is the answer—if it were higher then a coloring of <img src="https://s0.wp.com/latex.php?latex=%7BK_%7B43%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K_{43}}" class="latex" title="{K_{43}}" /> would have been found by now.</p>
<p>
Can we use self-play to turn this belief into something more concrete? The training would begin on running self-play on the known cases <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots+38%2C39%2C40%2C41%2C42%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots 38,39,40,41,42}" class="latex" title="{\dots 38,39,40,41,42}" />. This should create a neural net that is highly skilled at finding colorings that are free of small monochrome cliques. The question is how to leverage its presumed failure once we hit size <img src="https://s0.wp.com/latex.php?latex=%7B43%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{43}" class="latex" title="{43}" />.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Perhaps someone should take Avrim’s suggestion and try it out. A natural idea would be to see if this approach could compute the known smaller Ramsey numbers—getting their exact upper bounds. </p>
<p></p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/09/04/self-play-is-key/"><span class="datestr">at September 04, 2019 01:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-8050522808291360907">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2019/09/happy-new-academic-year-teaching.html">Happy New Academic Year:  Teaching Randomized Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
It seems I haven't written on this blog for a while.<br /><br />Today was the start of a new semester.  I'll be teaching Randomized Algorithms and Probabilistic Analysis, using the new edition of my book with Eli Upfal as a base, and throwing in other material.  (Everyone should buy the book!  <a href="https://www.amazon.com/gp/product/110715488X/ref=as_li_tl?ie=UTF8&amp;tag=michaelmitzen-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=110715488X&amp;linkId=d598fb636637ebb656410099e7042a7c">Here's a link</a>.)  <br /><br />It's a graduate level class, but generally designed for first year graduate students, and there were a lot of undergrads "shopping" it today.  (We don't do pre-registration at Harvard, and students get the first week to choose classes, known as shopping.)  So many that people were standing out the doors of the room.  But because we have a bit of a shortage of classes this semester, I'm guessing there's a good fraction of students just checking it out.  We'll see Thursday, but for now I'll predict we'll fit in the classroom, and wait to see if I'm wrong.  (If I'm wrong, that's wonderful too.)    <br /><br />It's been four years since I last taught the course, so this time I'm trying something new.  When I've previously taught the course, I tried to make the class inviting and friendly by telling the class we'd begin without assuming the class knew probability, and so the first couple of weeks would be reviewing basics (like, say, linearity of expectations and union bounds), albeit in a CS algorithms context.  This time, I let the class know I'm assuming they know (or will pick up) basic probability, and so they should read chapters 1-4 on their own, and we'll start with Chapter 5, Balls and Bins models.  Over the last decade, I've seen a huge shift in probability knowledge -- Stat 110, Harvard's probability course, has become one of Harvard's biggest classes.  Many students have already taking AI or ML or even data science courses where they've done some (further) probability.  It feels appropriate (and safe) to assume people entering in the class know probability, or can review what they need on their own, and start the class further along.<br /><br />Now finally, a request.  It's actually hard for me to teach when using this book, because I don't want to just read the book to the students.  That's boring.  On the other hand, if I thought something was important, I most likely already put it in the book.  We have to mix up the standard lecturing format a bit.  So two things we'll be doing are<br /><br />1)  doing some "puzzle problems" at the beginning of most classes, so people can try to solve problems.  (Kind of a flipped classroom approach, but not a full commitment.)<br />2)  reading papers, related to the class topics.<br /><br />So if you have any good suggestions of probability puzzle problems, or readable papers (particularly application papers) that use relatively basic probabilistic analysis in neat ways, send them over.  I've got a semester to fill.<br /><br />For curious people, here's one of today's starting problems, which I first learned about in graduate school.  (I'm pretty sure I owe thanks to Claire Kenyon for teaching it.  I'll link to the corresponding Wikipedia page on the problem maybe later.)<br /><br />After lunch, Bob suggests the following game to see who pays.  Alice and Bob will each choose a different sequence of three flips.  (So they could choose "Heads-Tails-Heads'', or "Tails-Tails-Tails'' for example.)  After they choose, a fair coin will be tossed until one of their sequences appears as a consecutive subsequence of the coin tosses.  The player whose sequence appears first wins. (Note that if they choose the above sequences, and if the flips come up Heads-Tails-Tails-Tails, the player that chose Tails-Tails-Tails would win as soon as their subsequence appears;  it's not three flips, then start over again.)  Bob politely says that Alice can choose first, and after she chooses and tells him her sequence he'll choose a different sequence.  What should Alice choose?</div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2019/09/happy-new-academic-year-teaching.html"><span class="datestr">at September 04, 2019 04:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5440">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2019/09/03/were-hiring/">We’re Hiring!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Come join us! This year our math department has two types of positions available. We have a standard tenure track position, which would hopefully continue our awesome sequence of recent hires. But this post is not about the standard position. Instead, I’d like to talk a bit about our other type of position – a […]</div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2019/09/03/were-hiring/"><span class="datestr">at September 03, 2019 03:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
