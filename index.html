<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at June 30, 2021 08:39 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/06/30/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/06/30/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://maxoffsky.com/code-blog/flow-lines/">Flow lines</a> (<a href="https://mathstodon.xyz/@11011110/106428733923482392">\(\mathbb{M}\)</a>). Web gadget editable open source code thingy to draw streamlines of mathematical formulas, in svg format, by Maksim Surguy.</p>
  </li>
  <li>
    <p><a href="https://daily.jstor.org/the-soap-bubble-trope/">The soap bubble trope</a> (<a href="https://mathstodon.xyz/@11011110/106430498906810187">\(\mathbb{M}\)</a>, <a href="https://3quarksdaily.com/3quarksdaily/2021/06/soap-bubbles.html">via</a>). Soap bubbles as a recurring theme in art, literature, and popular culture, including “the roof of the Munich Olympic Stadium, Glinda the Good Witch, the first viral ad campaign of the late Victorian era, and morose Dutch still-life paintings”.</p>
  </li>
  <li>
    <p><a href="http://gosper.org/homeplate.html">Officially, home plate doesn’t exist</a> (<a href="https://mathstodon.xyz/@esoterica/106435964222477352">\(\mathbb{M}\)</a>). The rules of baseball define it as a 90-45-90-90-45 pentagon with two 12” sides at one of the right angles and a 17” side between the other two, not possible.</p>
  </li>
  <li>
    <p><a href="https://www.natureindex.com/news-blog/microsoft-academic-graph-discontinued-whats-next">Microsoft Academic Graph being discontinued</a> (<a href="https://mathstodon.xyz/@11011110/106438809410223323">\(\mathbb{M}\)</a>, <a href="https://retractionwatch.com/2021/06/19/weekend-reads-biotech-ceo-on-leave-after-allegations-on-pubpeer-a-researcher-disavows-his-own-paper-plagiarism-here-there-and-everywhere/">via</a>). I didn’t much use that one but I live in fear that one day Google will do the same thing to Google Scholar, as they have to so many other useful but nonprofitable Google services.</p>
  </li>
  <li>
    <p>My current workflow for preparing technical talk videos (<a href="https://mathstodon.xyz/@11011110/106444988062063872">\(\mathbb{M}\)</a>):</p>

    <ul>
      <li>
        <p>Use LaTeX+beamer (169 option) to make pdf talk slides</p>
      </li>
      <li>
        <p>For each slide, print open-in-Preview with custom 16x9 zero-margin layout then export to png</p>
      </li>
      <li>
        <p>Write a script and use quicktime to record 1-2 minute voiceover clips</p>
      </li>
      <li>
        <p>Compose slides and audio in iMovie, export to a huge mp4</p>
      </li>
      <li>
        <p>Use Handbrake to convert to reasonably-sized mp4</p>
      </li>
    </ul>

    <p>It works, but is a bit tedious and produces very dry results. The discussion includes suggestion of alternatives.</p>
  </li>
  <li>
    <p><a href="https://youtu.be/7vEgc7cNarI">The points rotated, and the lines danced</a> (<a href="https://mastodon.social/@sarielhp/106439137323288004">\(\mathbb{M}\)</a>). Video illustrating point-line duality by Sariel Har-Peled.</p>
  </li>
  <li>
    <p><a href="https://www.bbc.com/future/article/20210616-how-the-forgotten-tricks-of-letterlocking-shaped-history">Letterlocking</a> (<a href="https://mathstodon.xyz/@11011110/106458633659042049">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=27549256">via</a>, <a href="https://en.wikipedia.org/wiki/Letterlocking">see also</a>): the art of folding your letters so intricately that readers will be forced to tear the paper to unfold and read them.</p>
  </li>
  <li>
    <p><a href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html">Bill Gasarch summarizes an online debate</a> (<a href="https://mathstodon.xyz/@11011110/106463907058053228">\(\mathbb{M}\)</a>) with Richard DeMillo and Richard Lipton, moderated by Harry Lewis, looking back at the idea of proving programs correct and at <a href="https://doi.org/10.1145/359104.359106">a classic 1979 paper by DeMillo, Lipton, and Perlis</a> arguing that this idea was already problematic.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/X_%2B_Y_sorting">\(X+Y\) sorting</a> (<a href="https://mathstodon.xyz/@11011110/106468019908924208">\(\mathbb{M}\)</a>), now a Good Article on Wikipedia. This is on an old open problem in comparison sorting: can you sort pairs of elements from two sets by their sums, faster than unstructured data of the same length? It’s still an active topic of research; see e.g. <a href="https://doi.org/10.1145%2F3285953">Kane, Lovett, and Moran, “Near-optimal linear decision trees for \(k\)-sum and related problems”, <em>JACM</em> 2019</a>.</p>

    <p>It was not easy to persuade the GA reviewer that this article was as accessible as it could be. I have hopes of <a href="https://en.wikipedia.org/wiki/Dehn_invariant">Dehn invariant</a> also becoming a Good Article but its “Realizability” section is far more advanced.</p>
  </li>
  <li>
    <p>This week I participated in the International Workshop on Graph-Theoretic Concepts in Computer Science, WG (<a href="https://mathstodon.xyz/@11011110/106474212936524737">\(\mathbb{M}\)</a>). The 9-hour time difference made live participation awkward for me, but fortunately prerecorded contributed talks and the three invited talks (Dujmović on product structures, Samotij on independent set numeration, and Bonnet on twin-width) are linked from <a href="https://wg2021.mimuw.edu.pl/program/">the conference program</a>. The proceedings is not yet out but many preprints of papers are also linked.</p>
  </li>
  <li>
    <p><a href="https://theintercept.com/2021/06/23/anming-hu-trial-fbi-china/">“A juror says the FBI owes an apology to University of Tennessee scientist Anming Hu”</a> (<a href="https://mathstodon.xyz/@11011110/106481625501499687">\(\mathbb{M}\)</a>, <a href="https://retractionwatch.com/2021/06/25/weekend-reads-the-obesity-wars-and-the-education-of-a-researcher-zombie-research-hijacked-journals/">via</a>) after putting Hu on trial for allegedly hiding ties to China despite his repeated disclosures of those ties and possibly in retaliation for his refusal to become a spy in China for the FBI. Beyond hurting US research both directly and by motivating good people to go elsewhere, this racist witch hunt has provided fuel for Chinese propaganda.</p>
  </li>
  <li>
    <p>The Wikipedia “Book:” namespace for curated collections of articles is being killed off (<a href="https://mathstodon.xyz/@11011110/106484876399456966">\(\mathbb{M}\)</a>) after the software to collate them into pdfs stopped working. I created five of these, and used two as readings for my courses. All five have moved to my user space:</p>

    <ul>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Fundamental_Data_Structures"><em>Fundamental Data Structures</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Graph_Algorithms"><em>Graph Algorithms</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Graph_Drawing"><em>Graph Drawing</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Matroid_Theory"><em>Matroid Theory</em></a></p>
      </li>
      <li>
        <p><a href="https://en.wikipedia.org/wiki/User:David_Eppstein/Perfect_Graphs"><em>Perfect Graphs</em></a></p>
      </li>
    </ul>
  </li>
  <li>
    <p><a href="https://danilafe.com/blog/math_rendering_is_wrong/">Math rendering is wrong</a> (<a href="https://mathstodon.xyz/@11011110/106492765314826160">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=27656446">via</a>). This blog post from a year ago argues that, for the same reasons one might write a web site in a markup language before compiling it to html, we should also compile LaTeX to html at that time rather than using browser-side scripts (as in most deploys of MathJax or KaTeX) or conversion to images (Wikipedia). It doesn’t present a solution, but is more a call for that solution to be made.</p>
  </li>
  <li>
    <p><a href="https://kleinbottle.com/#AMAZON%20BRAND%20HIJACKING">Amazon stands by and does nothing as Chinese scammers hijack Cliff Stoll’s Klein bottle business to usurp its positive reviews</a> (<a href="https://mathstodon.xyz/@11011110/106500881370367192">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=27684807">via</a>).</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/06/30/linkage.html"><span class="datestr">at June 30, 2021 10:36 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=18933">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/">Scaling and Fame</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>Scaling the pandemic is different from scaling the US budget</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/tt/" rel="attachment wp-att-18935"><img width="225" alt="" src="https://i2.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/tt.png?resize=225%2C126&amp;ssl=1" class="alignright wp-image-18935" height="126" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Sydney Morning Herald interview <a href="https://www.smh.com.au/lifestyle/terence-tao-the-mozart-of-maths-20150216-13fwcv.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Terence Tao is now “properly” famous. He was cited earlier this month in the NYT <a href="https://www.nytimes.com/2021/06/17/science/math-numbers-federal-budget-tao.html">science</a> section for help in explaining large numbers. Numbers such as the US federal budget.</p>
<p>
Today we discuss caveats on such explanations, after a riff on the popular explanation of mathematics.</p>
<p>
Regarding that, let us forget Tao’s work on primes in progressions with Ben Green, forget the Erdős discrepancy problem, and forget his almost-resolution of the Collatz conjecture. Forget it all. Better than a headline, he got his name embedded into the NYT article’s URL. This was for something much less deep that he wrote in 2009—as a blogger. </p>
<p>
<em>En passant</em>, we mention that Ken has an event tomorrow (Wed. 6/30) at 3:30 ET. It is a webinar hosted by Marc Rotenberg, who heads the Washington-based Center for AI and Digital Policy (<a href="https://www.caidp.org">CAIDP</a>), on “Chess and AI: The Role of Transparency.” Registration is free at this <a href="https://www.caidp.org/events/chess/">link</a>. One aspect of transparency in Ken’s work is that he writes about his model’s methodology here—as a blogger.</p>
<p>
</p><p></p><h2> Rescaling the Budget </h2><p></p>
<p></p><p>
Tao was referenced for a <a href="https://terrytao.wordpress.com/2009/05/04/the-federal-budget-rescaled/">post</a> he wrote in May 2009 when Barack Obama was working on his first budget as President. The ratio of $100 million to $3 that he used scaled the budget income to about $75,000. </p>
<p>
With Joe Biden engaged in budget deliberations, Aiyana Green and Steven Strogatz wrote the NYT <a href="https://www.human.cornell.edu/pam/news/aiyana_green_nyt">article</a> on explaining the US federal budget. Green is a student at Cornell: she just completed her junior year in the Department of Policy Analysis and Management. </p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/agss/" rel="attachment wp-att-18936"><img width="355" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/AGSS.png?resize=355%2C200&amp;ssl=1" class="aligncenter wp-image-18936" height="200" /></a></p>
<p></p><p><br />
They updated Tao’s post to scale the income to $100,000. Besides being a round number, this is close to the estimated <a href="https://www.in2013dollars.com/us/inflation/2009">inflation since 2009</a>. Here is the NYT graphic of the numbers. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/bud-2/" rel="attachment wp-att-18938"><img width="545" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/bud.png?resize=545%2C500&amp;ssl=1" class="aligncenter wp-image-18938" height="500" /></a></p>
<p>
</p><p></p><h2> A Scaling Caveat </h2><p></p>
<p></p><p>
It is attractive to apply this scaling trick elsewhere, even to grim subjects like the coronavirus pandemic. But there we find an element that does not scale.</p>
<p>
Suppose we use the same figure of 100,000 to scale down the world’s population. Besides its famous pandemic numbers <a href="https://www.worldometers.info/coronavirus/">pages</a>, Worldometer also keeps a running <a href="https://www.worldometers.info/world-population/">estimate</a> of the total world population, now nearing 7.9 billion. Scaling down means multiplying every ther human number by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma+%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\gamma =}" class="latex" /> 0.000012697445274. </p>
<p>
We can think of 100,000 people as a city that is not a metropolis. Scaling down the current pandemic figures, we get:</p>
<ul>
<li>
182,000,000 total cases become <b>2,309</b>. <p></p>
</li><li>
11,496,147 active cases become <b>145</b>. <p></p>
</li><li>
4 million total deaths (the numbers are approaching that millstone as we write) become <b>50</b> deaths. <p></p>
</li><li>
80,346 currently listed in critical or serious condition become <b>exactly one</b>.
</li></ul>
<p>
These numbers are not at all unusual for our size of city if one considers all kinds of illness and mortality. The scaling trick may seem to have reduced the scope of the pandemic, as opposed to statements such as 182 million being over half the US population. Yet in terms of the raw numbers it preserves the proportions.</p>
<p>
What the scaling doesn’t preserve is the proportion of <em>relations</em>. The number of possible binary relations—person <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> knows person <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B}" class="latex" />—is quadratic in the number <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> of people. Suppose the number of pairs who know each other is <img src="https://s0.wp.com/latex.php?latex=%7Ban%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{an^2}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a}" class="latex" /> is a small but fixed constant. (Note: we will redo this with something more reasonable below.) If we then scale <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> down to <img src="https://s0.wp.com/latex.php?latex=%7Bn%27+%3D+n%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n' = n\gamma}" class="latex" />, the situation becomes:</p>
<ul>
<li>
If we estimate the relatedness of our city, we get <img src="https://s0.wp.com/latex.php?latex=%7Ban%27%5E2+%3D+an%5E2%5Cgamma%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{an'^2 = an^2\gamma^2}" class="latex" />. <p></p>
</li><li>
But if we scaled down the number of <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" />-knows-<img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B}" class="latex" /> relations directly we would get <img src="https://s0.wp.com/latex.php?latex=%7Ban%5E2%5Cgamma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{an^2\gamma}" class="latex" />, which is substantially bigger by a factor of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{1}{\gamma}}" class="latex" />.
</li></ul>
<p>
Thus what the scaling really underestimates is the impact of how people are affected by their loved ones being among the 182 million (or the worse numbers). The underestimation logic applies to any form <img src="https://s0.wp.com/latex.php?latex=%7Ban%5Ec%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{an^c}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c &gt; 1}" class="latex" />. This is not an issue with the budget because dollar bills don’t feel relatedness—at least not so much, even absent a line-item veto. Now we will make values of <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" /> approaching <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" /> more reasonable.</p>
<p>
</p><p></p><h2> Small World: Tao and Strogatz Again </h2><p></p>
<p></p><p>
Let’s consider people <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{X}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{Y}" class="latex" /> who have <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3}" class="latex" /> degrees of separation in the graph of who-knows-who. Then there are <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B}" class="latex" /> who know each other such that <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> knows <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{X}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B}" class="latex" /> knows <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{Y}" class="latex" />. If something strikes <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{X}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{Y}" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B}" class="latex" /> will feel a deep connection by that impact. The feeling is amplified if <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{X}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{Y}" class="latex" /> have multiple pairs <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B}" class="latex" /> that make a path. This quantifies the relation that Tao calls “awareness” in his “Lecture Notes 3 FOR 254A” course <a href="https://rjlipton.wpcomstaging.com/feed/LECTURE NOTES 3 FOR 254A">notes</a> (pages 51–57 overall). A fact way more basic than what Tao is actually talking about in those notes is the following:</p>
<blockquote><p><b> </b> <em> The sum over pairs <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(X,Y)}" class="latex" /> of the number of pairs <img src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(A,B)}" class="latex" /> between them who would be affected equals the sum over edges <img src="https://s0.wp.com/latex.php?latex=%7B%28A%2CB%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(A,B)}" class="latex" /> of the number of pairs <img src="https://s0.wp.com/latex.php?latex=%7B%28X%2CY%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(X,Y)}" class="latex" /> they can be struck by: both are equal to the number of paths of length <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3}" class="latex" /> in the graph. </em>
</p></blockquote>
<p></p><p>
That number of paths is what we say is reasonable to model by a function <img src="https://s0.wp.com/latex.php?latex=%7Ban%5Ec%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{an^c}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c \gg 1}" class="latex" />. This is the simplest way of approaching why we feel that treating the pandemic like the US budget underestimates its human effect. One can still rebut that other kinds of illness and death have the same scaling properties, but ultimately we are talking about the <em>excess</em> caused by the pandemic—the effect on top of everything else.</p>
<p>
We have not tried to make this analysis become rigorous using more-realistic models of human networks. Perhaps our readers can point us to such analysis. But one inkling of why we expect our point to be borne out comes from a key conclusion of the famous 1998 <a href="https://www.nature.com/articles/30918">paper</a> of Strogatz with Duncan Watts on ‘small-world’ networks: The phase transition from a lattice network with large average distances to a small-world network with small distances takes place in a range where small clusters cannot recognize it happening locally. </p>
<p>
Thus, if our scaling carried the intuitive picture of an isolated city, it would miss the expanding sphere of relations. At the opposite extreme would be taking the union of Monaco and central Venice, which sum to 100,000 people who fan out mightily. There is also the argument that while small-world networks are held tight by “<a href="https://sociology.stanford.edu/sites/g/files/sbiybj9501/f/publications/the_strength_of_weak_ties_and_exch_w-gans.pdf">weak ties</a>,” the shared knowledge of misery is something that most tends to strengthen ties. And of course, our point about relations extends to many other activities impacted by the pandemic.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What should govern the appropriateness of scaling down?</p>
<p>
It should be noted that if we scale down the US to 100,000 people, the numbers are appreciably higher:</p>
<ul>
<li>
34.5 million total cases become <b>10,366</b>. <p></p>
</li><li>
4,928,564 active cases become <b>1,480</b>. <p></p>
</li><li>
620,000 total deaths become <b>186</b> deaths. <p></p>
</li><li>
3,833 currently listed in critical or serious condition still become <b>exactly one</b>.
</li></ul></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/06/29/scaling-and-fame/"><span class="datestr">at June 29, 2021 11:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=2420">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2021/06/29/trace-reconstruction/">Trace Reconstruction from Complex Analysis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Suppose that <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s" class="latex" /> is an unknown binary string of length <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n" class="latex" />. We are asked to recover <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s" class="latex" /> from its <em>traces</em>, and each <em>trace</em> <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s" class="latex" /> is a random subsequence obtained by deleting the bits of <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s" class="latex" /> independently with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1/2" class="latex" />.</p>



<p>More formally, let <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_s" class="latex" /> denote the distribution of traces obtained from string <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s" class="latex" />. For example, when <img src="https://s0.wp.com/latex.php?latex=s+%3D+110&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s = 110" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_s" class="latex" /> assigns a probability mass of <img src="https://s0.wp.com/latex.php?latex=1%2F8&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1/8" class="latex" /> to each element in the multiset<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7Bempty%7D%2C+1%2C+1%2C+0%2C+11%2C+10%2C+10%2C+110%5C%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\{\text{empty}, 1, 1, 0, 11, 10, 10, 110\}." class="latex" /><br /></p>



<p>We then ask: what is the smallest number <img src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n)" class="latex" /> such that we can recover any <img src="https://s0.wp.com/latex.php?latex=s+%5Cin+%5C%7B0%2C+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s \in \{0, 1\}^n" class="latex" /> (say, with probability <img src="https://s0.wp.com/latex.php?latex=%5Cge+0.99&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\ge 0.99" class="latex" />) given <img src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n)" class="latex" /> independent samples from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_s" class="latex" />?</p>



<p>This <em>trace reconstruction</em> problem was first formulated by <a href="https://people.cs.umass.edu/~mcgregor/papers/04-soda.pdf" target="_blank" rel="noreferrer noopener">Batu-Kannan-Khanna-McGregor</a> in 2004, and their central motivation is from the <a href="https://en.wikipedia.org/wiki/Multiple_sequence_alignment" target="_blank" rel="noreferrer noopener">multiple sequence alignment</a> problem in computational biology. Trace reconstruction is also a fundamental problem related to the <a href="https://en.wikipedia.org/wiki/Deletion_channel" target="_blank" rel="noreferrer noopener">deletion channel</a> in communication theory: We view the hidden string as the transmitted message, and each trace as a received message that went through a deletion channel, which drops each bit with probability <img src="https://s0.wp.com/latex.php?latex=1%2F2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1/2" class="latex" />. Then the sample complexity <img src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n)" class="latex" /> tells us the number of independent copies that need to be sent for the receiver to determine the original message.</p>



<p>Despite being a natural problem, trace reconstruction is still far from being well-understood, even from the information-theoretic perspective (i.e., without considering the computational complexity). In 2017, <a href="https://arxiv.org/pdf/1612.03148.pdf" target="_blank" rel="noreferrer noopener">De-O’Donnell-Servedio</a> and <a href="https://arxiv.org/pdf/1612.03599.pdf" target="_blank" rel="noreferrer noopener">Nazarov-Peres</a> independently proved <img src="https://s0.wp.com/latex.php?latex=M%28n%29+%5Cle+%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n) \le \exp(O(n^{1/3}))" class="latex" />. A very recent breakthrough due to <a href="https://arxiv.org/pdf/2009.03296.pdf" target="_blank" rel="noreferrer noopener">Chase</a> further improved this bound to <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28%5Ctilde+O%28n%5E%7B1%2F5%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\exp(\tilde O(n^{1/5}))" class="latex" />, which is still super-polynomial. On the other hand, the best known sample complexity lower bound is merely <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%5COmega%28n%5E%7B3%2F2%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde\Omega(n^{3/2})" class="latex" />, proved by <a href="https://arxiv.org/pdf/1905.03031.pdf" target="_blank" rel="noreferrer noopener">Chase</a> in another recent work.</p>



<p>In this blog post, I will explain why this problem is much more non-trivial than it might appear at first glance. I will also give an overview on the work of [DOS17, NP17], which, interestingly, reduces this seemingly combinatorial problem to complex analysis.</p>



<p><strong>Observation: reconstruction <img src="https://s0.wp.com/latex.php?latex=%5Capprox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\approx" class="latex" /> distinguishing <img src="https://s0.wp.com/latex.php?latex=%5Capprox&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\approx" class="latex" /> TV-distance.</strong> Let us start with a natural first attempt at the problem. Define <img src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\delta_n" class="latex" /> as the minimum statistical distance between the trace distribution of two different length-<img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n" class="latex" /> strings:<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cdelta_n+%3D+%5Cmin_%7Bx+%5Cne+y+%5Cin+%5C%7B0%2C+1%5C%7D%5En%7Dd_%7B%5Ctextrm%7BTV%7D%7D%28%5Cmathcal%7BD%7D_x%2C+%5Cmathcal%7BD%7D_y%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\delta_n = \min_{x \ne y \in \{0, 1\}^n}d_{\textrm{TV}}(\mathcal{D}_x, \mathcal{D}_y)." class="latex" /><br /></p>



<p>It is not hard to show that <img src="https://s0.wp.com/latex.php?latex=1%2F%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1/\delta_n" class="latex" /> bounds <img src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n)" class="latex" /> on both sides, up to a polynomial factor:<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=1%2F%5Cdelta_n+%5Clesssim+M%28n%29+%5Clesssim+n%2F%5Cdelta_n%5E2.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1/\delta_n \lesssim M(n) \lesssim n/\delta_n^2." class="latex" /><br /></p>



<p class="has-black-color has-text-color">The lower bound holds because any trace reconstruction algorithm must be able to distinguish <img src="https://s0.wp.com/latex.php?latex=s+%3D+x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s = x" class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=s+%3D+y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s = y" class="latex" /> for every pair of different strings <img src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="(x, y)" class="latex" />, and this requires <img src="https://s0.wp.com/latex.php?latex=%5COmega%281+%2F+%5Cdelta_n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\Omega(1 / \delta_n)" class="latex" /> samples for the minimizer <img src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="(x, y)" class="latex" /> in the definition of <img src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\delta_n" class="latex" />. For the upper bound, we note that every pair <img src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="(x, y)" class="latex" /> can be distinguished with an <img src="https://s0.wp.com/latex.php?latex=o%282%5E%7B-n%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="o(2^{-n})" class="latex" /> error probability using <img src="https://s0.wp.com/latex.php?latex=O%28n%2F%5Cdelta_n%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="O(n/\delta_n^2)" class="latex" /> samples. We say that string <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> “beats” <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="y" class="latex" />, if the distinguisher for <img src="https://s0.wp.com/latex.php?latex=%28x%2C+y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="(x, y)" class="latex" /> decides that “<img src="https://s0.wp.com/latex.php?latex=s+%3D+x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s = x" class="latex" />“. By a union bound, the correct answer <img src="https://s0.wp.com/latex.php?latex=s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s" class="latex" /> “beats” every other string with high probability. We can then obtain a reconstruction algorithm by running the distinguisher for every string pair, and outputting the unique string that “beats” the other <img src="https://s0.wp.com/latex.php?latex=2%5En-1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="2^n-1" class="latex" /> strings.</p>



<p>Thus, to determine whether the sample complexity <img src="https://s0.wp.com/latex.php?latex=M%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n)" class="latex" /> is polynomial in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n" class="latex" />, it suffices to determine whether <img src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\delta_n" class="latex" /> scales as <img src="https://s0.wp.com/latex.php?latex=1%2F%5Cmathrm%7Bpoly%7D%28n%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1/\mathrm{poly}(n)" class="latex" /> or is much smaller. Unfortunately, it turns out to be highly non-trivial to bound <img src="https://s0.wp.com/latex.php?latex=%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\delta_n" class="latex" />, and even bounding <img src="https://s0.wp.com/latex.php?latex=d_%7B%5Ctextrm%7BTV%7D%7D%28%5Cmathcal%7BD%7D_x%2C+%5Cmathcal%7BD%7D_y%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="d_{\textrm{TV}}(\mathcal{D}_x, \mathcal{D}_y)" class="latex" /> for “simple” <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="y" class="latex" /> can be hard. Imagine that we try to reason about the distribution <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_x" class="latex" />: the probability mass that <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_x" class="latex" /> assigns to string <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s" class="latex" /> is proportional to the number of times that <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s" class="latex" /> appears as a subsequence in <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" />, but this count is already hard to express or control, unless <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> has a very simple pattern. This is roughly where this natural attempt gets stuck.</p>



<p><strong>Distinguishing using estimators.</strong> Now we turn to a different approach that underlies the recent breakthrough on trace reconstruction algorithms. As discussed earlier, we can focus on the problem of distinguishing the case <img src="https://s0.wp.com/latex.php?latex=s+%3D+x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s = x" class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=s+%3D+y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s = y" class="latex" /> for fixed strings <img src="https://s0.wp.com/latex.php?latex=x+%5Cne+y+%5Cin+%5C%7B0%2C+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x \ne y \in \{0, 1\}^n" class="latex" />. Let <img src="https://s0.wp.com/latex.php?latex=f%3A+%5C%7B0%2C+1%5C%7D%5E%7B%5Cle+n%7D+%5Cto+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f: \{0, 1\}^{\le n} \to \mathbb{R}" class="latex" /> be a function defined over all possible traces from a length-<img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n" class="latex" /> string. We consider the following algorithm for distinguishing <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_x" class="latex" /> from <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_y" class="latex" />:<br /><br /><strong>Step 1.</strong> Given traces <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s_1%2C+%5Ctilde+s_2%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s_1, \tilde s_2, \ldots" class="latex" />, compute the average of <img src="https://s0.wp.com/latex.php?latex=f%28%5Ctilde+s_1%29%2C+f%28%5Ctilde+s_2%29%2C+%5Cldots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f(\tilde s_1), f(\tilde s_2), \ldots" class="latex" /><br /><strong>Step 2.</strong> Output <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> if the average is closer to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%5Ctilde+x+%5Csim+%5Cmathcal%7BD%7D_x%7D%5Bf%28%5Ctilde+x%29%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbb{E}_{\tilde x \sim \mathcal{D}_x}[f(\tilde x)]" class="latex" /> than to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%5Ctilde+y+%5Csim+%5Cmathcal%7BD%7D_y%7D%5Bf%28%5Ctilde+y%29%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbb{E}_{\tilde y \sim \mathcal{D}_y}[f(\tilde y)]" class="latex" />, and output <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="y" class="latex" /> otherwise.<br /></p>



<p>For the above to succeed, <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" /> needs to satisfy the following two conditions:<br /></p>



<p><strong>(Separation)</strong> <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_y" class="latex" /> are well-separated under <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" />, namely <img src="https://s0.wp.com/latex.php?latex=%7C%5Cmathbb%7BE%7D%5Bf%28%5Ctilde+x%29%5D+-+%5Cmathbb%7BE%7D%5Bf%28%5Ctilde+y%29%5D%7C+%5Cge+%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|\mathbb{E}[f(\tilde x)] - \mathbb{E}[f(\tilde y)]| \ge \epsilon" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3E+0&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\epsilon &gt; 0" class="latex" />.<br /><strong>(Boundedness)</strong> Expectation of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" /> can be efficiently estimated. This can be guaranteed if for some <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="B" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7Cf%28%5Ctilde+s%29%7C+%5Cle+B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|f(\tilde s)| \le B" class="latex" /> holds for every <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s+%5Cin+%5C%7B0%2C+1%5C%7D%5E%7B%5Cle+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s \in \{0, 1\}^{\le n}" class="latex" />.<br /></p>



<p>Assuming the above, a standard concentration argument shows that we can distinguish <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="y" class="latex" /> using <img src="https://s0.wp.com/latex.php?latex=O%28%28B%2F%5Cepsilon%29%5E2%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="O((B/\epsilon)^2)" class="latex" /> samples, and thus <img src="https://s0.wp.com/latex.php?latex=M%28n%29+%5Clesssim+n+%5Ccdot+%28B%2F%5Cepsilon%29%5E2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n) \lesssim n \cdot (B/\epsilon)^2" class="latex" />.</p>



<p>In principle, a near-optimal choice of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" /> would be setting <img src="https://s0.wp.com/latex.php?latex=f%28%5Ctilde+s%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f(\tilde s)" class="latex" /> to be the indicator of <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BD%7D_x%28%5Ctilde+s%29+%5Cge+%5Cmathcal%7BD%7D_y%28%5Ctilde+s%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathcal{D}_x(\tilde s) \ge \mathcal{D}_y(\tilde s)" class="latex" />, which gives boundedness <img src="https://s0.wp.com/latex.php?latex=B+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="B = 1" class="latex" /> and separation <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+d_%7B%5Ctextrm%7BTV%7D%7D%28%5Cmathcal%7BD%7D_x%2C+%5Cmathcal%7BD%7D_y%29+%5Cge+%5Cdelta_n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\epsilon = d_{\textrm{TV}}(\mathcal{D}_x, \mathcal{D}_y) \ge \delta_n" class="latex" />. However, as argued above, this optimal choice of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" /> can still be hard to analyze. Instead, we focus on choosing a simpler function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" />, which potentially gives a suboptimal <img src="https://s0.wp.com/latex.php?latex=B%2F%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="B/\epsilon" class="latex" /> but admits simple analyses.</p>



<p><strong>Sketch of the <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\exp(O(n^{1/3}))" class="latex" /> Upper Bound.</strong> The main results of [DOS17] and [NP17] follow from choosing <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" /> to be a linear function. Given a trace <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s+%3D+%5Ctilde+s_0+%5Ctilde+s_1+%5Ctilde+s_2+%5Ccdots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s = \tilde s_0 \tilde s_1 \tilde s_2 \cdots" class="latex" />, we consider the following polynomial with coefficients being the bits of <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s" class="latex" />:<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Ctilde+S%28z%29+%3D+%5Csum_%7Bk%7D%5Ctilde+s_k+z%5Ek+%3D+%5Ctilde+s_0+%2B+%5Ctilde+s_1+z+%2B+%5Ctilde+s_2+z%5E2+%2B+%5Ccdots.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde S(z) = \sum_{k}\tilde s_k z^k = \tilde s_0 + \tilde s_1 z + \tilde s_2 z^2 + \cdots." class="latex" /><br /></p>



<p>For some number <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z" class="latex" /> to be determined later, we consider the estimator <img src="https://s0.wp.com/latex.php?latex=f%28%5Ctilde+s%29+%3D+%5Ctilde+S%28z%29+%3D+%5Ctilde+s_0+%2B+%5Ctilde+s_1+z+%2B+%5Ctilde+s_2+z%5E2+%2B+%5Ccdots&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f(\tilde s) = \tilde S(z) = \tilde s_0 + \tilde s_1 z + \tilde s_2 z^2 + \cdots" class="latex" />, which is indeed a linear function in the trace <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s" class="latex" />.</p>



<p>At first glance, it might be unclear why we choose the coefficients to be powers of <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z" class="latex" />. The following fact justifies this choice by showing that polynomials interact with the deletion channel very nicely: The expectation of <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+S%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde S(z)" class="latex" /> is exactly the evaluation of the polynomial <img src="https://s0.wp.com/latex.php?latex=S%28%5Ccdot%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="S(\cdot)" class="latex" /> with coefficients <img src="https://s0.wp.com/latex.php?latex=s_0%2C+s_1%2C+%5Cldots%2C+s_%7Bn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s_0, s_1, \ldots, s_{n-1}" class="latex" />, but at a slightly different point.<br /></p>



<p><strong>Fact:</strong> For any string <img src="https://s0.wp.com/latex.php?latex=s+%5Cin+%5C%7B0%2C+1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="s \in \{0, 1\}^n" class="latex" />,<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D_%7B%5Ctilde+s+%5Csim+%5Cmathcal%7BD%7D_s%7D%5Cleft%5B%5Ctilde+S%28z%29%5Cright%5D+%3D+%5Cfrac%7B1%7D%7B2%7DS%5Cleft%28%5Cfrac%7Bz%2B1%7D%7B2%7D%5Cright%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbb{E}_{\tilde s \sim \mathcal{D}_s}\left[\tilde S(z)\right] = \frac{1}{2}S\left(\frac{z+1}{2}\right)." class="latex" /><br /></p>



<p>Equivalently, we have <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BE%7D%5B%5Ctilde+S%282z-1%29%5D+%3D+%5Cfrac%7B1%7D%7B2%7DS%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbb{E}[\tilde S(2z-1)] = \frac{1}{2}S(z)" class="latex" />, which allows us to rephrase our requirements on the choice of <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z" class="latex" /> as follows:<br /></p>



<p><strong>(Separation)</strong> <img src="https://s0.wp.com/latex.php?latex=%7CX%28z%29+-+Y%28z%29%7C+%5Cge+%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|X(z) - Y(z)| \ge \epsilon" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\epsilon" class="latex" /> that is not too small.<br /><strong>(Boundedness)</strong> <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctilde+S%282z+-+1%29%7C+%5Cle+B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|\tilde S(2z - 1)| \le B" class="latex" /> for all possible trace <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s" class="latex" />, for some <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="B" class="latex" /> that is not too large.<br /></p>



<p>After some thought, it is beneficial to choose <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z" class="latex" /> such that both <img src="https://s0.wp.com/latex.php?latex=%7Cz%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|z|" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7C2z+-+1%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|2z - 1|" class="latex" /> are close to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1" class="latex" />, since this ensures that different bits in the string are assigned weights of similar magnitudes in the polynomials above. These two conditions hold if and only if <img src="https://s0.wp.com/latex.php?latex=z+%5Capprox+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z \approx 1" class="latex" />.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="512" alt="" src="https://theorydish.files.wordpress.com/2021/06/plan.png?w=1024" class="wp-image-2442" height="230" />The overall plan for distinguishing strings <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="y" class="latex" />.</figure></div>



<p>The crucial idea in both papers [DOS17, NP17] is to consider the polynomials in the complex plane <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbb{C}" class="latex" /> instead of on the real line. Fortunately, all the previous discussion still holds for complex numbers, with <img src="https://s0.wp.com/latex.php?latex=%7C%5Ccdot%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|\cdot|" class="latex" /> interpreted as modulus instead of absolute value. In [NP17], the authors chose <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z" class="latex" /> from a small arc of the unit circle:</p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=A_L+%3D+%5C%7Be%5E%7Bi%5Ctheta%7D%3A+%5Ctheta%5Cin%5B-%5Cpi%2FL%2C+%5Cpi%2FL%5D%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="A_L = \{e^{i\theta}: \theta\in[-\pi/L, \pi/L]\}" class="latex" />.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="311" alt="" src="https://theorydish.files.wordpress.com/2021/06/a_l.png?w=622" class="wp-image-2445" height="262" />Arc <img src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="A_L" class="latex" /> marked by the red box and dotted lines.</figure></div>



<p>For every <img src="https://s0.wp.com/latex.php?latex=z+%5Cin+A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z \in A_L" class="latex" />, it is easy to upper bound <img src="https://s0.wp.com/latex.php?latex=%7C%5Ctilde+S%282z+-+1%29%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|\tilde S(2z - 1)|" class="latex" />: it follows from simple calculus that <img src="https://s0.wp.com/latex.php?latex=%7C2z+-+1%7C+%5Cle+1+%2B+O%28L%5E%7B-2%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|2z - 1| \le 1 + O(L^{-2})" class="latex" />, and thus for every <img src="https://s0.wp.com/latex.php?latex=%5Ctilde+s&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\tilde s" class="latex" />:<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cleft%7C%5Ctilde+S%282z-1%29%5Cright%7C+%5Cle+%5Csum_%7Bk%3D0%7D%5E%7Bn-1%7D%5Cleft%7C%282z-1%29%5Ek%5Cright%7C+%5Cle+n+%5Ccdot+%5Cleft%5B1+%2B+O%28L%5E%7B-2%7D%29%5Cright%5D%5En+%3D+e%5E%7BO%28n%2FL%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\left|\tilde S(2z-1)\right| \le \sum_{k=0}^{n-1}\left|(2z-1)^k\right| \le n \cdot \left[1 + O(L^{-2})\right]^n = e^{O(n/L^2)}" class="latex" />.</p>



<p>To lower bound <img src="https://s0.wp.com/latex.php?latex=X%28z%29+-+Y%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="X(z) - Y(z)" class="latex" />, note that since both <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="x" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="y" class="latex" /> are binary, all the coefficients of <img src="https://s0.wp.com/latex.php?latex=X-Y&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="X-Y" class="latex" /> are in <img src="https://s0.wp.com/latex.php?latex=%5C%7B-1%2C+0%2C+1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\{-1, 0, 1\}" class="latex" />. Such polynomials are known as <em>Littlewood polynomials</em>. The separation condition is then reduced to the following claim in complex analysis:</p>



<p class="has-text-align-center"><em><strong>Littlewood polynomials cannot to be too “flat” over a short arc around 1.</strong></em></p>



<p>This is indeed the case:</p>



<p id="lemma-1"><strong>Lemma 1.</strong> (<a href="https://www.jstor.org/stable/pdf/24899666.pdf" target="_blank" rel="noreferrer noopener">[Borwein and Erdélyi, 1997]</a>) For every nonzero Littlewood polynomial <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p" class="latex" />,<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmax_%7Bz+%5Cin+A_L%7D%7Cp%28z%29%7C+%5Cge+e%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\max_{z \in A_L}|p(z)| \ge e^{-O(L)}" class="latex" />.<br /></p>



<p>By <a href="https://theorydish.blog/feed/#lemma-1">Lemma 1</a>, there exists <img src="https://s0.wp.com/latex.php?latex=z+%5Cin+A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z \in A_L" class="latex" /> such that the separation condition holds for <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+e%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\epsilon = e^{-O(L)}" class="latex" />. Recall that the boundedness holds for <img src="https://s0.wp.com/latex.php?latex=B+%3D+e%5E%7BO%28n%2FL%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="B = e^{O(n/L^2)}" class="latex" />. This shows that the sample complexity is upper bounded by <img src="https://s0.wp.com/latex.php?latex=%28B%2F%5Cepsilon%29%5E2+%3D+%5Cexp%28O%28n%2FL%5E2+%2B+L%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="(B/\epsilon)^2 = \exp(O(n/L^2 + L))" class="latex" />, which is minimized at <img src="https://s0.wp.com/latex.php?latex=L+%3D+n%5E%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L = n^{1/3}" class="latex" />. This proves the upper bound <img src="https://s0.wp.com/latex.php?latex=M%28n%29+%3D+%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(n) = \exp(O(n^{1/3}))" class="latex" />.</p>



<p><strong>Proof of a weaker lemma.</strong> While the original proof of <a href="https://theorydish.blog/feed/#lemma-1">Lemma 1</a> is a bit technical, [NP17] presented a beautiful and much simpler proof of the following weaker result, in which the <img src="https://s0.wp.com/latex.php?latex=e%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="e^{-O(L)}" class="latex" /> lower bound is replaced by <img src="https://s0.wp.com/latex.php?latex=n%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n^{-O(L)}" class="latex" />, where <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n" class="latex" /> is the degree of the Littlewood polynomial.</p>



<p><strong>Lemma 2.</strong> ([Lemma 3.1, NP17]) For every nonzero Littlewood polynomial <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%3C+n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="&lt; n" class="latex" />,<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%5Cmax_%7Bz+%5Cin+A_L%7D%7Cp%28z%29%7C+%5Cge+n%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\max_{z \in A_L}|p(z)| \ge n^{-O(L)}" class="latex" />.<br /></p>



<p><strong>Proof.</strong> Without loss of generality, we assume that the constant term of <img src="https://s0.wp.com/latex.php?latex=p%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p(z)" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="1" class="latex" />. Suppose otherwise, that the lowest order term of <img src="https://s0.wp.com/latex.php?latex=p%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p(z)" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=z%5Em&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z^m" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=m+%5Cge+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="m \ge 1" class="latex" />. We may consider the polynomial <img src="https://s0.wp.com/latex.php?latex=p%28z%29+%2F+z%5Em&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p(z) / z^m" class="latex" /> instead.</p>



<p>Let <img src="https://s0.wp.com/latex.php?latex=M+%3D+%5Cmax_%7Bz+%5Cin+A_L%7D%7Cp%28z%29%7C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M = \max_{z \in A_L}|p(z)|" class="latex" /> be the maximum modulus of <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p" class="latex" /> over arc <img src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="A_L" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=%5Comega+%3D+e%5E%7B2%5Cpi+i%2FL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\omega = e^{2\pi i/L}" class="latex" /> be an <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L" class="latex" />-th root of unity. Consider the following polynomial:<br /></p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=q%28z%29+%3D+%5Cprod_%7Bj%3D0%7D%5E%7BL-1%7Dp%28%5Comega%5Ej+z%29+%3D+p%28z%29+%5Ccdot+p%28%5Comega+z%29+%5Ccdot+%5Ccdots+%5Ccdot+p%28%5Comega%5E%7BL-1%7D+z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="q(z) = \prod_{j=0}^{L-1}p(\omega^j z) = p(z) \cdot p(\omega z) \cdot \cdots \cdot p(\omega^{L-1} z)" class="latex" />.</p>



<p>For every <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z" class="latex" /> on the unit circle, at least one point <img src="https://s0.wp.com/latex.php?latex=%5Comega%5Ej+z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\omega^j z" class="latex" /> falls into the arc <img src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="A_L" class="latex" />, so that <img src="https://s0.wp.com/latex.php?latex=%7Cp%28%5Comega%5Ej+z%29%7C+%5Cle+M&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|p(\omega^j z)| \le M" class="latex" />. (See <a href="https://theorydish.blog/feed/#windmill">figure below</a> for a proof by picture.) The moduli of the remaining <img src="https://s0.wp.com/latex.php?latex=L+-+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L - 1" class="latex" /> factors are trivially bounded by <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n" class="latex" />. Thus, <img src="https://s0.wp.com/latex.php?latex=%7Cq%28z%29%7C+%5Cle+M%5Ccdot+n%5E%7BL-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|q(z)| \le M\cdot n^{L-1}" class="latex" />.</p>



<p>On the other hand, we note <img src="https://s0.wp.com/latex.php?latex=q%280%29+%3D+%5Bp%280%29%5D%5EL+%3D+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="q(0) = [p(0)]^L = 1" class="latex" />. The <a href="https://en.wikipedia.org/wiki/Maximum_modulus_principle" target="_blank" rel="noreferrer noopener">maximum modulus principle</a> implies that for some <img src="https://s0.wp.com/latex.php?latex=z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="z" class="latex" /> on the unit circle, we have <img src="https://s0.wp.com/latex.php?latex=%7Cq%28z%29%7C+%5Cge+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="|q(z)| \ge 1" class="latex" />. Therefore, we must have <img src="https://s0.wp.com/latex.php?latex=M+%5Ccdot+n%5E%7BL+-+1%7D+%5Cge+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M \cdot n^{L - 1} \ge 1" class="latex" />, which implies <img src="https://s0.wp.com/latex.php?latex=M+%5Cge+n%5E%7B-%28L+-+1%29%7D+%3D+n%5E%7B-O%28L%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M \ge n^{-(L - 1)} = n^{-O(L)}" class="latex" /> and completes the proof. <img src="https://s0.wp.com/latex.php?latex=%5Csquare&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\square" class="latex" /></p>



<div class="wp-block-image" id="windmill"><figure class="aligncenter size-large is-resized"><img width="462" alt="" src="https://theorydish.files.wordpress.com/2021/06/example.png?w=924" class="wp-image-2449" height="261" />Points involved in the definition of <img src="https://s0.wp.com/latex.php?latex=q%28z%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="q(z)" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=L%3D4&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="L=4" class="latex" />.<br />In this case, <img src="https://s0.wp.com/latex.php?latex=%5Comega%5E3+z&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\omega^3 z" class="latex" /> is inside arc <img src="https://s0.wp.com/latex.php?latex=A_L&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="A_L" class="latex" />, which is marked by the red lines.</figure></div>



<p><strong>Beyond linear estimators?</strong> The work of [DOS17, NP17] not only proved the <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28O%28n%5E%7B1%2F3%7D%29%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\exp(O(n^{1/3}))" class="latex" /> upper bound, but also showed that this is the best sample complexity we can get from linear estimator <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="f" class="latex" />. The recent work of [Cha20] goes beyond these linear estimators by taking the higher moments of the trace into account. The idea turns out to be a natural one: consider the “<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k" class="latex" />-grams” (i.e., length-<img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k" class="latex" /> substrings) of the string for some <img src="https://s0.wp.com/latex.php?latex=k+%3E+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k &gt; 1" class="latex" />. In more detail, we fix some string <img src="https://s0.wp.com/latex.php?latex=w+%5Cin+%5C%7B0%2C+1%5C%7D%5Ek&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="w \in \{0, 1\}^k" class="latex" />, and consider the binary polynomial with coefficients corresponding to the positions at which <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="w" class="latex" /> appears as a (contiguous) substring. The key observation is that there exists a choice of <img src="https://s0.wp.com/latex.php?latex=w&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="w" class="latex" /> such that the resulting polynomial is sparse (in the sense that the degrees of the nonzero monomials are far away). The technical part of [Cha20] is then devoted to proving an analogue of <a href="https://theorydish.blog/feed/#lemma-1">Lemma 1</a> that is specialized to these “sparse” Littlewood polynomials.</p>



<p><strong>Acknowledgments.</strong> I would like to thank Moses Charikar, Li-Yang Tan and Gregory Valiant for being on my quals committee and for helpful discussions about this problem.</p></div>







<p class="date">
by Mingda Qiao <a href="https://theorydish.blog/2021/06/29/trace-reconstruction/"><span class="datestr">at June 29, 2021 04:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/06/29/greedy-orderings-transposition">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/06/29/greedy-orderings-transposition.html">Greedy orderings with transposition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I’m a big fan of using <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroids</a> to model vertex-ordering processes in graphs such as the construction of <a href="https://en.wikipedia.org/wiki/Topological_sorting">topological orderings</a> in <a href="https://en.wikipedia.org/wiki/Directed_acyclic_graph">directed acyclic graphs</a> and perfect elimination orderings in <a href="https://en.wikipedia.org/wiki/Chordal_graph">chordal graphs</a>. In each case a vertex can be removed from the graph and added to the order when it obeys a local condition: its remaining neighbors are all outgoing for topological orderings, or all adjacent for perfect elimination orderings. Once this condition becomes true of a vertex it remains true until the vertex is added to the order, the defining property of an antimatroid. Because of this property, a greedy algorithm for finding these orderings can never make a mistake: if there exists an ordering of all of the vertices, it is always a safe choice to add any vertex that can be added.</p>

<p>But there are some greedy vertex-ordering processes that do not form antimatroids, even though they do have the same inability to make mistakes. Two of these are the dismantling orders of <a href="https://en.wikipedia.org/wiki/Cop-win_graph">cop-win graphs</a> and the reverse construction orders of <a href="https://en.wikipedia.org/wiki/Distance-hereditary_graph">distance-hereditary graphs</a>. I wrote about cop-win graphs <a href="https://11011110.github.io/blog/2016/08/18/game-of-cop.html">here in 2016</a>; a graph is cop-win if a cop can always land on the same vertex as a robber when they take turns either moving from a vertex to a neighboring vertex or staying put. In distance-hereditary graphs, all induced subgraphs have the same distances; <a href="https://11011110.github.io/blog/2005/10/11/delta-confluent-drawing-paper.html">these graphs also have nice confluent drawings</a>. Both of these classes of graphs can be recognized by greedy algorithms that remove one vertex at a time until either getting stuck (for graphs not in the class) or succeeding by reaching a single-vertex graph. But although the conditions for removing vertices in these algorithms are local, they are not antimatroidal.</p>

<h1 id="an-example-graph">An example graph</h1>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2021/Ptolemaic.svg" alt="A six-vertex graph with six vertices A, B, C, D, E, and F, and seven edges AD, BC, BD, BE, CE, and EF" /></p>

<p>The graph shown above happens to be chordal, distance-hereditary, and cop-win, making it a convenient example both of how to order the vertices of these graph classes and of why the distance-hereditary and cop-win orderings are not antimatroidal.</p>

<ul>
  <li>
    <p>In chordal graphs, a perfect elimination ordering can be constructed by repeatedly removing <em>simplicial vertices</em>, vertices whose neighborhoods form a clique. For an elimination ordering of the example graph, vertices \(A\), \(C\), and \(F\) are already available to be listed: \(A\) and \(F\) only have one neighbor (automatically a clique), and \(C\) has two neighbors forming a two-vertex clique. The other vertices will become available later in the removal process, once enough of their neighbors have been removed and all remaining vertices become adjacent. For instance, once \(A\) has been removed, \(D\) will become available, and once \(C\) has been removed, \(B\) will become available. Once this removal process makes a vertex simplicial, it remains simplicial until removed, so elimination orderings form an antimatroid.</p>
  </li>
  <li>
    <p>Distance-hereditary graphs can be constructed from a single vertex by repeatedly adding leaf vertices (with one neighbor connecting to previous vertices) or twins (duplicates of previous vertices). Reversing this process, these graphs can be deconstructed by repeatedly removing leaves or twins. The graph above has no twins, but \(A\) and \(F\) are leaves, and can be removed immediately. If \(A\) is removed, \(C\) and \(D\) become false twins (not adjacent to each other), and either of them can be removed. Similarly, if \(F\) is removed, \(B\) and \(E\) become true twins (adjacent to each other), after which one can be removed, but not both: after removing \(F\) and \(B\), \(E\) is no longer a leaf or a twin (because its twin, \(B\), has gone), and must remain until later steps. Because the removal orders can start \(FB\) or \(FE\) but not \(FBE\), they are not described by an antimatroid.</p>
  </li>
  <li>
    <p>Similarly, cop-win graphs can be dismantled by repeatedly removing a vertex \(v\) that is dominated by another vertex \(w\), meaning that the neighborhood of \(v\) (including \(v\) itself) is a subset of the neighborhoood of \(w\). In the given graph, \(A\) is dominated by \(D\), \(B\) is dominated by \(E\), \(C\) is dominated by both \(B\) and \(E\), and \(F\) is dominated by \(E\). So any one of these four dominated vertices starts out as removable. But if we remove first \(F\) and then \(E\) (dominated by \(B\) after the removal of \(F\)) we can no longer remove \(B\). So because the ability to be removed can go away before the removal happens, we do not have an antimatroid.</p>
  </li>
</ul>

<p>There’s another complication here as well. For both distance-hereditary graphs and cop-win graphs, removing leaves and twins or dominated vertices will never eliminate all graph vertices. Instead, both removal processes stop when we reach a single remaining vertex. But this is different from antimatroids, where all elements must be included in all orderings.</p>

<h1 id="some-axiomatics">Some axiomatics</h1>

<p>To understand why greedy orderings still work in these cases, I think it’s helpful to start by understanding why they work for antimatroids, as a general class of structures. The following is not quite the usual system of axioms for antimatroids, but they can be defined as non-empty formal languages (that is, sets of strings over a finite alphabet) with the following properties:</p>

<dl>
  <dt>Hereditary:</dt>
  <dd>
    <p>Every prefix of a string in the language is also in the language. Thinking about this in the other direction: every string in the language can be built up by adding one character at a time, starting from the empty string, at all times remaining within the language.</p>
  </dd>
  <dt>Normal:</dt>
  <dd>
    <p>Every character occurs at most once in any string in the language. An element can only be added to the sequence of elements once. Because we are assuming the alphabet to be finite, this means that the language itself is also finite.</p>
  </dd>
  <dt>Oblivious:</dt>
  <dd>
    <p>If \(S\) and \(T\) are permutations of each other in the language, then for every character \(x\), \(Sx\) is in the language if and only if \(Tx\) is in the language. This means that what can be added next depends only on the set of characters that have been added already, forgetting about the order in which they were added.</p>
  </dd>
  <dt>Anti-exchange:</dt>
  <dd>
    <p>If \(S\) is a string, \(x\) and \(y\) are different characters, and \(Sx\) and \(Sy\) both belong to the language, then so does \(Sxy\). Adding \(x\) doesn’t prevent \(y\) from being added later. This is the key property of an antimatroid and the one that is violated by the distance-hereditary and cop-win orderings.</p>
  </dd>
</dl>

<p>Usually a stronger version of obliviousness is used, stating that when \(S\) and a permutation of \(Sx\) are in the language, then \(Sx\) is in the language, but it’s not immediately obvious why this should be true for the vertex-ordering processes I’m considering here, so I’ve gone with a weaker version. We’ll see later that the stronger version is implied by a combination of this and other properties. It is standard to also require that all characters be usable, but I haven’t done this, because I want to understand the behavior of antimatroidal greedy algorithms on graphs not in the given graph class, for which they get stuck before ordering the whole graph. But this is not important, because one could instead redefine the alphabet to consist only of usable characters.</p>

<p>Given a language that satisfies all of these properties, one can show that all non-extendable strings are equally long and use the same alphabet as each other. For, if we have two different non-extendable strings \(S\) and \(T\), we can morph \(S\) into \(T\) one step at a time, never shortening it or changing its character set, by finding the first position at which \(S\) and \(T\) differ, finding the character \(t\) that \(T\) has at that position (necessarily also used later in \(S\) because it was usable at that position and would have remained usable until it was used), and repeatedly using the anti-exchange axiom to swap \(t\) for the previous character in \(S\) until it has been swapped into a match with \(T\). The oblivious property ensures that the part of the string after the swap remains valid. So \(S\) cannot be shorter than or miss any characters from \(T\), nor vice versa.</p>

<p>Instead of the anti-exchange axiom, the distance-hereditary and cop-win orderings satisfy a weaker property, based on the notion of swapping two characters.</p>

<dl>
  <dt>Transposition:</dt>
  <dd>
    <p>Suppose \(S\) is a string, \(x\) and \(y\) are different characters, and \(Sx\) and \(Sy\) both belong to the language, but \(Sxy\) does not. Then for all \(T\) not containing \(x\) or \(y\), \(SxT\) is in the language if and only if \(SyT\) is also in the language, and \(SxTy\) is in the language if and only if \(SyTx\) is also in the language.</p>
  </dd>
</dl>

<p>The last part of the transposition property, about \(SxTy\) and \(SyTx\), is only included because we used a weak version of obliviousness; if we used the stronger version, it would follow from the earlier part of the transposition property.</p>

<h1 id="cop-win-and-distance-hereditary-orderings-have-the-transposition-property">Cop-win and distance-hereditary orderings have the transposition property</h1>

<p>Let’s suppose we’re trying to dismantle a cop-win graph by repeatedly removing dominated vertices, in the hope of getting down to a single vertex. After we’ve removed some vertices already in a sequence \(S\), two vertices \(x\) and \(y\) might become included in the set of dominated vertices. This can happen in several different ways:</p>

<ul>
  <li>It might be the case that \(x\) is dominated by a vertex that is not \(y\), and that \(y\) is dominated by a vertex that is not \(x\). When this happens, they can be removed in either order: removing one won’t change the fact that the other is dominated by whatever other vertex dominated it already.</li>
  <li>It might be the case that \(x\) is dominated by \(y\), and \(y\) is dominated by a third vertex \(z\). But then \(x\) is also dominated by \(z\), and again they can be removed in either order. When one is removed, the other is still dominated by \(z\).</li>
  <li>The only remaining case is that \(x\) and \(y\) are each dominated only by the other of these two vertices. In this case, we can remove one or the other but not both. But if \(x\) and \(y\) dominate each other, they have the same neighbors (they are twins), and there is a symmetry of the remaining subgraph swapping \(x\) and \(y\). So in this case, any continuation of the removal sequence \(S\) can have \(x\) replaced by \(y\) and vice versa, and still be a valid continuation. This is exactly what the transposition property states.</li>
</ul>

<p>The argument for distance-hereditary orderings is even easier. If \(x\) and \(y\) are not twins of each other, then removing one won’t affect the removability of the other. If they are twins, then they are symmetric and any continuation of the removal sequence can exchange \(x\) for \(y\) without changing its validity.</p>

<h1 id="orderings-with-transposition-form-greedoids">Orderings with transposition form greedoids</h1>

<p>If we can’t obtain an antimatroid from the cop-win or distance-hereditary graphs, we might at least hope for a more general structure, a greedoid. The key property of greedoids (viewed as hereditary normal languages rather than their usual definition as set systems) is the following axiom:</p>

<dl>
  <dt>Exchange:</dt>
  <dd>If \(S\) is a longer string in the language of a greedoid, and \(T\) is a longer string in the same language, then there is a character \(x\) in \(T\) such that \(Sx\) is a string in the language.</dd>
</dl>

<p>This implies that all maximal strings in the language have the same length, and in the cop-win and distance-hereditary cases it implies that all greedy dismantling or deconstruction sequences reach a single vertex without getting stuck along the way. The greedoid exchange property also immediately implies the strong version of the obliviousness property, by plugging in a permutation of \(Sx\) as the string \(T\) in the exchange property.</p>

<p>To prove that indistinguishability implies the exchange property, let \(S\) be any string in an indistinguishable (hereditary normal oblivious) language, and let \(T\) be a longer string, which we might as well assume to be maximal. If \(S\) is a prefix of \(T\), then obviously we can satisfy the exchange property: just take the prefix of \(T\) that has one more character.</p>

<p>Otherwise, I claim that we can replace \(T\) by a different string \(T'\) of the same length that agrees with \(S\) for more positions. To find \(T'\), let \(y\) be the first character of \(S\) that differs from the corresponding character of \(T\); this must exist by the assumption that \(S\) is not a prefix of \(T\). Obviously, at the position of \(y\) in \(S\), we could have added it to \(T\), but instead some other character was chosen. Maybe, \(y\) remained available to be chosen throughout the remaining positions of \(T\), until it actually was chosen. If so, just as in the antimatroid case, we could repeatedly swap \(y\) with its predecessor in \(T\) until reaching a string \(T'\) where \(y\) is in the correct position. Alternatively, maybe at some point during the construction of sequence \(T\), we chose a character \(z\) causing \(y\) to become unavailable. In this case, by the transposition property, we can swap \(y\) for \(z\) in \(T\) and then as before repeatedly swap \(y\) with its predecessor in \(T\) until reaching a string \(T'\) where \(y\) is in the correct position.</p>

<p>By repeatedly replacing \(T\) by equally long strings that agree with more and more positions of \(S\), we eventually reach a string for which \(S\) is a prefix, and can append one more character. This construction of \(T'\) from \(T\) does not include any new characters that weren’t already in \(S\) or \(T\), so the appended character must have come from \(T\), proving the exchange axiom.</p>

<p>The use of the transposition property to form greedoids is standard; these greedoids are called transposition greedoids, and are described e.g. by Björner and Ziegler in their introduction to greedoids in the book <em>Matroid Applications</em>. Another <a href="https://doi.org/10.1007/978-3-642-58191-5_10">book chapter on transposition greedoids</a>, in the book <em>Greedoids</em> by Korte, Schrader, and Lovász, includes another graph-theoretic example where the elements are edges of series-parallel graphs. The part that appears to be less standard is the use of this property to explain the ability of greedy algorithms to recognize cop-win and distance-hereditary graphs. I looked, but was unable to find publications observing that these two classes of graphs lead to greedoids or transposition greedoids, despite some suspiciously-similar terminology (“twins”, “dismantling”) on both sides. If anyone knows of such publications, I’d appreciate hearing of them, so that I could add this connection to their Wikipedia articles.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/106495619434427598">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/06/29/greedy-orderings-transposition.html"><span class="datestr">at June 29, 2021 12:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/091">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/091">TR21-091 |  Expander Random Walks: The General Case and Limitations | 

	Gil Cohen, 

	Dor Minzer, 

	Shir Peleg, 

	Aaron Potechin, 

	Amnon Ta-Shma</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Cohen, Peri and Ta-Shma (STOC'21) considered the following question: Assume the vertices of an expander graph are labelled by $\pm 1$. What "test" functions $f : \{\pm 1\}^t \to \{\pm1 \}$ can or cannot distinguish $t$ independent samples from those obtained by a random walk? [CPTS'21] considered only balanced labelling, and proved that all symmetric functions are fooled by random walks on expanders with constant spectral gap. Furthermore, it was shown that functions computable by $\mathbf{AC}^0$ circuits are fooled by expanders with vanishing spectral expansion. 

We continue the study of this question and, in particular, resolve all open problems raised by [CPTS'21]. First, we generalize the result to all labelling, not merely balanced. In doing so, we improve the known bound for symmetric functions and prove that the bound we obtain is optimal (up to a multiplicative constant). Furthermore, we prove that a random walk on expanders with constant spectral gap does not fool $\mathbf{AC}^0$. In fact, we prove that the bound obtained by [CPTS'21] for $\mathbf{AC}^0$ circuits is optimal up to a polynomial factor.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/091"><span class="datestr">at June 29, 2021 07:19 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14454">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14454">Fractionally Subadditive Maximization under an Incremental Knapsack Constraint</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Disser:Yann.html">Yann Disser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klimm:Max.html">Max Klimm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weckbecker:David.html">David Weckbecker</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14454">PDF</a><br /><b>Abstract: </b>We consider the problem of maximizing a fractionally subadditive function
under a knapsack constraint that grows over time. An incremental solution to
this problem is given by an order in which to include the elements of the
ground set, and the competitive ratio of an incremental solution is defined by
the worst ratio over all capacities relative to an optimum solution of the
corresponding capacity. We present an algorithm that finds an incremental
solution of competitive ratio at most $\max\{3.293\sqrt{M},2M\}$, under the
assumption that the values of singleton sets are in the range $[1,M]$, and we
give a lower bound of $\max\{2.449,M\}$ on the attainable competitive ratio. In
addition, we establish that our framework captures potential-based flows
between two vertices, and we give a tight bound of~$2$ for the incremental
maximization of classical flows with unit capacities.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14454"><span class="datestr">at June 29, 2021 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14451">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14451">Dynamic Schnyder Woods</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhore:Sujoy.html">Sujoy Bhore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bose:Prosenjit.html">Prosenjit Bose</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cano:Pilar.html">Pilar Cano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cardinal:Jean.html">Jean Cardinal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iacono:John.html">John Iacono</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14451">PDF</a><br /><b>Abstract: </b>A realizer, commonly known as Schnyder woods, of a triangulation is a
partition of its interior edges into three oriented rooted trees. A flip in a
realizer is a local operation that transforms one realizer into another. Two
types of flips in a realizer have been introduced: colored flips and cycle
flips. A corresponding flip graph is defined for each of these two types of
flips. The vertex sets are the realizers, and two realizers are adjacent if
they can be transformed into each other by one flip. In this paper we study the
relation between these two types of flips and their corresponding flip graphs.
We show that a cycle flip can be obtained from linearly many colored flips. We
also prove an upper bound of $O(n^2)$ on the diameter of the flip graph of
realizers defined by colored flips. In addition, a data structure is given to
dynamically maintain a realizer over a sequence of colored flips which supports
queries, including getting a node's barycentric coordinates, in $O(\log n)$
time per flip or query.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14451"><span class="datestr">at June 29, 2021 10:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14408">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14408">A Bound on the Edge-Flipping Distance between Triangulations (Revisiting the Proof)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dag=egrave=s:Thomas.html">Thomas Dagès</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bruckstein:Alfred_M=.html">Alfred M. Bruckstein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14408">PDF</a><br /><b>Abstract: </b>We revisit here a fundamental result on planar triangulations, namely that
the flip distance between two triangulations is upper-bounded by the number of
proper intersections between their straight-segment edges. We provide a
complete and detailed proof of this result in a slightly generalised setting
using a case-based analysis that fills several gaps left by previous proofs of
the result.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14408"><span class="datestr">at June 29, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14354">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14354">Scheduling on uniform and unrelated machines with bipartite incompatibility graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pikies:Tytus.html">Tytus Pikies</a>, Hanna Furmańczyk Dept. of Algorithims and System Modelling, ETI Faculty, Gdańsk University of Technology, 11/12 Gabriela Narutowicza Street, 80-233 Gdańsk, Poland, Institute of Informatics, Faculty of Mathematics, Physics and Informatics, University of Gdańsk, 57 Wita Stwosza Street, 80-309 Gdańsk, Poland) <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14354">PDF</a><br /><b>Abstract: </b>In this paper the problem of scheduling of jobs on parallel machines under
incompatibility relation is considered. In this model a binary relation between
jobs is given and no two jobs that are in the relation can be scheduled on the
same machine. In particular, we consider job scheduling under incompatibility
relation forming bipartite graphs, under makespan optimality criterion, on
uniform and unrelated machines. We show that no algorithm can achieve a good
approximation ratio for uniform machines, even for a case of unit time jobs,
under $P \neq NP$. We also provide an approximation algorithm that achieves the
best possible approximation ratio, even for the case of jobs of arbitrary
lengths $p_j$, under the same assumption. Precisely, we present an
$O(n^{1/2-\epsilon})$ inapproximability bound, for any $\epsilon &gt; 0$; and
$\sqrt{p_{sum}}$-approximation algorithm, respectively. To enrich the analysis,
bipartite graphs generated randomly according to Gilbert's model
$\mathcal{G}_{n,n,p(n)}$ are considered. For a broad class of $p(n)$ functions
we show that there exists an algorithm producing a schedule with makespan
almost surely at most twice the optimum. Due to our knowledge, this is the
first study of randomly generated graphs in the context of scheduling in the
considered model.
</p>
<p>For unrelated machines, an FPTAS for $R2|G = bipartite|C_{\max}$ is provided.
We also show that there is no algorithm of approximation ratio
$O(n^bp_{\max}^{1-\epsilon})$, even for $Rm|G = bipartite|C_{max}$ for $m \ge
3$ and any $\epsilon &gt; 0$, $b &gt; 0$, unless $P = NP$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14354"><span class="datestr">at June 29, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14262">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14262">Edge-Unfolding Prismatoids: Tall or Rectangular Base</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Vincent Bian, Erik Demaine, Rachana Madhukara <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14262">PDF</a><br /><b>Abstract: </b>We show how to edge-unfold a new class of convex polyhedra, specifically a
new class of prismatoids (the convex hull of two parallel convex polygons,
called the top and base), by constructing a nonoverlapping "petal unfolding" in
two new cases: (1) when the top and base are sufficiently far from each other;
and (2) when the base is a rectangle and all other faces are nonobtuse
triangles. The latter result extends a previous result by O'Rourke that the
petal unfolding of a prismatoid avoids overlap when the base is a triangle
(possibly obtuse) and all other faces are nonobtuse triangles. We also
illustrate the difficulty of extending this result to a general quadrilateral
base by giving a counterexample to our technique.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14262"><span class="datestr">at June 29, 2021 10:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14195">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14195">Learning to solve geometric construction problems from images</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>J. Macke, J. Sedlar, M. Olsak, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Urban:J=.html">J. Urban</a>, J. Sivic <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14195">PDF</a><br /><b>Abstract: </b>We describe a purely image-based method for finding geometric constructions
with a ruler and compass in the Euclidea geometric game. The method is based on
adapting the Mask R-CNN state-of-the-art image processing neural architecture
and adding a tree-based search procedure to it. In a supervised setting, the
method learns to solve all 68 kinds of geometric construction problems from the
first six level packs of Euclidea with an average 92% accuracy. When evaluated
on new kinds of problems, the method can solve 31 of the 68 kinds of Euclidea
problems. We believe that this is the first time that a purely image-based
learning has been trained to solve geometric construction problems of this
difficulty.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14195"><span class="datestr">at June 29, 2021 10:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14185">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14185">Minimum-Link Shortest Paths for Polygons amidst Rectilinear Obstacles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Mincheol.html">Mincheol Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahn:Hee=Kap.html">Hee-Kap Ahn</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14185">PDF</a><br /><b>Abstract: </b>Consider two axis-aligned rectilinear simple polygons in the domain
consisting of axis-aligned rectilinear obstacles in the plane such that the
bounding boxes, one for each obstacle and one for each polygon, are disjoint.
We present an algorithm that computes a minimum-link rectilinear shortest path
connecting the two polygons in $O((N+n)\log (N+n))$ time using $O(N+n)$ space,
where $n$ is the number of vertices in the domain and $N$ is the total number
of vertices of the two polygons.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14185"><span class="datestr">at June 29, 2021 10:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14176">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14176">Linear-Time Approximation Scheme for k-Means Clustering of Affine Subspaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cho:Kyungjin.html">Kyungjin Cho</a>, Eunjin Oh <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14176">PDF</a><br /><b>Abstract: </b>In this paper, we present a linear-time approximation scheme for $k$-means
clustering of \emph{incomplete} data points in $d$-dimensional Euclidean space.
An \emph{incomplete} data point with $\Delta&gt;0$ unspecified entries is
represented as an axis-parallel affine subspaces of dimension $\Delta$. The
distance between two incomplete data points is defined as the Euclidean
distance between two closest points in the axis-parallel affine subspaces
corresponding to the data points. We present an algorithm for $k$-means
clustering of axis-parallel affine subspaces of dimension $\Delta$ that yields
an $(1+\epsilon)$-approximate solution in $O(nd)$ time. The constants hidden
behind $O(\cdot)$ depend only on $\Delta, \epsilon$ and $k$. This improves the
$O(n^2 d)$-time algorithm by Eiben et al.[SODA'21] by a factor of $n$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14176"><span class="datestr">at June 29, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14169">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14169">$\alpha$-approximate Reductions: a Novel Source of Heuristics for Better Approximation Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manne:Fredrik.html">Fredrik Manne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Philip:Geevarghese.html">Geevarghese Philip</a>, Saket Saurabh, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tale:Prafullkumar.html">Prafullkumar Tale</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14169">PDF</a><br /><b>Abstract: </b>Lokshtanov et al.~[STOC 2017] introduced \emph{lossy kernelization} as a
mathematical framework for quantifying the effectiveness of preprocessing
algorithms in preserving approximation ratios. \emph{$\alpha$-approximate
reduction rules} are a central notion of this framework. We propose that
carefully crafted $\alpha$-approximate reduction rules can yield improved
approximation ratios in practice, while being easy to implement as well. This
is distinctly different from the (theoretical) purpose for which Lokshtanov et
al. designed $\alpha$-approximate Reduction Rules. As evidence in support of
this proposal we present a new 2-approximate reduction rule for the
\textsc{Dominating Set} problem. This rule, when combined with an approximation
algorithm for \textsc{Dominating Set}, yields significantly better
approximation ratios on a variety of benchmark instances as compared to the
latter algorithm alone.
</p>
<p>The central thesis of this work is that $\alpha$-approximate reduction rules
can be used as a tool for designing approximation algorithms which perform
better in practice. To the best of our knowledge, ours is the first exploration
of the use of $\alpha$-approximate reduction rules as a design technique for
practical approximation algorithms. We believe that this technique could be
useful in coming up with improved approximation algorithms for other
optimization problems as well.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14169"><span class="datestr">at June 29, 2021 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14116">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14116">Generalized max-flows and min-cuts in simplicial complexes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maxwell:William.html">William Maxwell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayyeri:Amir.html">Amir Nayyeri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14116">PDF</a><br /><b>Abstract: </b>We consider high dimensional variants of the maximum flow and minimum cut
problems in the setting of simplicial complexes and provide both algorithmic
and hardness results. By viewing flows and cuts topologically in terms of the
simplicial (co)boundary operator we can state these problems as linear programs
and show that they are dual to one another. Unlike graphs, complexes with
integral capacity constraints may have fractional max-flows. We show that
computing a maximum integral flow is NP-hard. Moreover, we give a combinatorial
definition of a simplicial cut that seems more natural in the context of
optimization problems and show that computing such a cut is NP-hard. However,
we provide conditions on the simplicial complex for when the cut found by the
linear program is a combinatorial cut. For $d$-dimensional simplicial complexes
embedded into $\mathbb{R}^{d+1}$ we provide algorithms operating on the dual
graph: computing a maximum flow is dual to computing a shortest path and
computing a minimum cut is dual to computing a minimum cost circulation.
Finally, we investigate the Ford-Fulkerson algorithm on simplicial complexes,
prove its correctness, and provide a heuristic which guarantees it to halt.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14116"><span class="datestr">at June 29, 2021 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14086">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14086">Planar and Toroidal Morphs Made Easier</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Jeff Erickson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Patrick.html">Patrick Lin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14086">PDF</a><br /><b>Abstract: </b>We present simpler algorithms for two closely related morphing problems, both
based on the barycentric interpolation paradigm introduced by Floater and
Gotsman, which is in turn based on Floater's asymmetric extension of Tutte's
classical spring-embedding theorem. First, we give a much simpler algorithm to
construct piecewise-linear morphs between planar straight-line graphs.
Specifically, given isomorphic straight-line drawings $\Gamma_0$ and $\Gamma_1$
of the same 3-connected planar graph $G$, with the same convex outer face, we
construct a morph from $\Gamma_0$ to $\Gamma_1$ that consists of $O(n)$
unidirectional morphing steps, in $O(n^{1+\omega/2})$ time. Our algorithm
entirely avoids the classical edge-collapsing strategy dating back to Cairns;
instead, in each morphing step, we interpolate the pair of weights associated
with a single edge. Second, we describe a natural extension of barycentric
interpolation to geodesic graphs on the flat torus. Barycentric interpolation
cannot be applied directly in this setting, because the linear systems defining
intermediate vertex positions are not necessarily solvable. We describe a
simple scaling strategy that circumvents this issue. Computing the appropriate
scaling requires $O(n^{\omega/2})$ time, after which we can can compute the
drawing at any point in the morph in $O(n^{\omega/2})$ time. Our algorithm is
considerably simpler than the recent algorithm of Chambers et al.
(<a href="http://export.arxiv.org/abs/2007.07927">arXiv:2007.07927</a>) and produces more natural morphs. Our techniques also yield
a simple proof of a conjecture of Connelly et al. for geodesic torus
triangulations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14086"><span class="datestr">at June 29, 2021 10:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.14043">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.14043">Improved Approximation Algorithms for Individually Fair Clustering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vakilian:Ali.html">Ali Vakilian</a>, Mustafa Yalçıner <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.14043">PDF</a><br /><b>Abstract: </b>We consider the $k$-clustering problem with $\ell_p$-norm cost, which
includes $k$-median, $k$-means and $k$-center cost functions, under an
individual notion of fairness proposed by Jung et al. [2020]: given a set of
points $P$ of size $n$, a set of $k$ centers induces a fair clustering if for
every point $v\in P$, $v$ can find a center among its $n/k$ closest neighbors.
Recently, Mahabadi and Vakilian [2020] showed how to get a
$(p^{O(p)},7)$-bicriteria approximation for the problem of fair $k$-clustering
with $\ell_p$-norm cost: every point finds a center within distance at most $7$
times its distance to its $(n/k)$-th closest neighbor and the $\ell_p$-norm
cost of the solution is at most $p^{O(p)}$ times the cost of an optimal fair
solution. In this work, for any $\varepsilon&gt;0$, we present an improved $(16^p
+\varepsilon,3)$-bicriteria approximation for the fair $k$-clustering with
$\ell_p$-norm cost. To achieve our guarantees, we extend the framework of
[Charikar et al., 2002, Swamy, 2016] and devise a $16^p$-approximation
algorithm for the facility location with $\ell_p$-norm cost under matroid
constraint which might be of an independent interest. Besides, our approach
suggests a reduction from our individually fair clustering to a clustering with
a group fairness requirement proposed by Kleindessner et al. [2019], which is
essentially the median matroid problem [Krishnaswamy et al., 2011].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.14043"><span class="datestr">at June 29, 2021 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.13951">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.13951">Geometry Meets Vectors: Approximation Algorithms for Multidimensional Packing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Arindam Khan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Eklavya.html">Eklavya Sharma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sreenivas:K=_V=_N=.html">K. V. N. Sreenivas</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.13951">PDF</a><br /><b>Abstract: </b>We study the generalized multidimensional bin packing problem (GVBP) that
generalizes both geometric packing and vector packing. Here, we are given $n$
rectangular items where the $i^{\textrm{th}}$ item has width $w(i)$, height
$h(i)$, and $d$ nonnegative weights $v_1(i), v_2(i), \ldots, v_{d}(i)$. Our
goal is to get an axis-parallel non-overlapping packing of the items into
square bins so that for all $j \in [d]$, the sum of the $j^{\textrm{th}}$
weight of items in each bin is at most 1. This is a natural problem arising in
logistics, resource allocation, and scheduling. Despite being well studied in
practice, surprisingly, approximation algorithms for this problem have rarely
been explored.
</p>
<p>We first obtain two simple algorithms for GVBP having asymptotic
approximation ratios $6(d+1)$ and $3(1 + \ln(d+1) + \varepsilon)$. We then
extend the Round-and-Approx (R&amp;A) framework [Bansal-Khan, SODA'14] to wider
classes of algorithms, and show how it can be adapted to GVBP. Using more
sophisticated techniques, we obtain better approximation algorithms for GVBP,
and we get further improvement by combining them with the R&amp;A framework. This
gives us an asymptotic approximation ratio of $2(1+\ln((d+4)/2))+\varepsilon$
for GVBP, which improves to $2.919+\varepsilon$ for the special case of $d=1$.
We obtain further improvement when the items are allowed to be rotated. We also
present algorithms for a generalization of GVBP where the items are high
dimensional cuboids.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.13951"><span class="datestr">at June 29, 2021 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.13860">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.13860">Threshold-Based Quantum Optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golden:John.html">John Golden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=auml=rtschi:Andreas.html">Andreas Bärtschi</a>, Daniel O'Malley, Stephan Eidenbenz <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.13860">PDF</a><br /><b>Abstract: </b>We propose and study Th-QAOA (pronounced Threshold QAOA), a variation of the
Quantum Alternating Operator Ansatz (QAOA) that replaces the standard phase
separator operator, which encodes the objective function, with a threshold
function that returns a value $1$ for solutions with an objective value above
the threshold and a $0$ otherwise. We vary the threshold value to arrive at a
quantum optimization algorithm. We focus on a combination with the Grover Mixer
operator; the resulting GM-Th-QAOA can be viewed as a generalization of
Grover's quantum search algorithm and its minimum/maximum finding cousin to
approximate optimization.
</p>
<p>Our main findings include: (i) we show semi-formally that the optimum
parameter values of GM-Th-QAOA (angles and threshold value) can be found with
$O(\log(p) \times \log M)$ iterations of the classical outer loop, where $p$ is
the number of QAOA rounds and $M$ is an upper bound on the solution value
(often the number of vertices or edges in an input graph), thus eliminating the
notorious outer-loop parameter finding issue of other QAOA algorithms; (ii)
GM-Th-QAOA can be simulated classically with little effort up to 100 qubits
through a set of tricks that cut down memory requirements; (iii) somewhat
surprisingly, GM-Th-QAOA outperforms its non-thresholded counterparts in terms
of approximation ratios achieved. This third result holds across a range of
optimization problems (MaxCut, Max k-VertexCover, Max k-DensestSubgraph,
MaxBisection) and various experimental design parameters, such as different
input edge densities and constraint sizes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.13860"><span class="datestr">at June 29, 2021 10:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.13851">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.13851">Approximate Maximum Halfspace Discrepancy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matheny:Michael.html">Michael Matheny</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Jeff_M=.html">Jeff M. Phillips</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.13851">PDF</a><br /><b>Abstract: </b>Consider the geometric range space $(X, \mathcal{H}_d)$ where $X \subset
\mathbb{R}^d$ and $\mathcal{H}_d$ is the set of ranges defined by
$d$-dimensional halfspaces. In this setting we consider that $X$ is the
disjoint union of a red and blue set. For each halfspace $h \in \mathcal{H}_d$
define a function $\Phi(h)$ that measures the "difference" between the fraction
of red and fraction of blue points which fall in the range $h$. In this context
the maximum discrepancy problem is to find the $h^* = \arg \max_{h \in (X,
\mathcal{H}_d)} \Phi(h)$. We aim to instead find an $\hat{h}$ such that
$\Phi(h^*) - \Phi(\hat{h}) \le \varepsilon$. This is the central problem in
linear classification for machine learning, in spatial scan statistics for
spatial anomaly detection, and shows up in many other areas. We provide a
solution for this problem in $O(|X| + (1/\varepsilon^d) \log^4
(1/\varepsilon))$ time, which improves polynomially over the previous best
solutions. For $d=2$ we show that this is nearly tight through conditional
lower bounds. For different classes of $\Phi$ we can either provide a
$\Omega(|X|^{3/2 - o(1)})$ time lower bound for the exact solution with a
reduction to APSP, or an $\Omega(|X| + 1/\varepsilon^{2-o(1)})$ lower bound for
the approximate solution with a reduction to 3SUM.
</p>
<p>A key technical result is a $\varepsilon$-approximate halfspace range
counting data structure of size $O(1/\varepsilon^d)$ with $O(\log
(1/\varepsilon))$ query time, which we can build in $O(|X| + (1/\varepsilon^d)
\log^4 (1/\varepsilon))$ time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.13851"><span class="datestr">at June 29, 2021 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5479161699112157490">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/06/someone-thinks-i-am-fine-artist-why.html">Someone thinks I am a fine artist! Why?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>A while back I got an  email asking me to submit to a Fine Arts Journal. Why me? Here are some possibilities:</p><p>1) They were impressed with my play: </p><p><b>Sure he created the universe, but would he get Tenure?</b> (see <a href="http://www.cs.umd.edu/~gasarch/MYWRITINGS/god.html">here</a>) which did get into a play-writing contest and was performed (one of the actresses  scolded me since I took a slot from <i>a real</i> <i>playwrigh</i>t).</p><p>2) They were impressed  with my <b>Daria Fan Fiction</b> (see the four entries <a href="http://www.cs.umd.edu/~gasarch/MYWRITINGS/mywritings.html">here</a> labelled as Daria Fan Fiction).</p><p>3) They were impressed with my play <b>JFK: The Final chapter</b> (see <a href="http://www.cs.umd.edu/~gasarch/MYWRITINGS/jfk.html">here</a>). Unlikely since this was rejected by a play writing contest and is not well known (as opposed to my other works in the fine arts which are well known?)</p><p>4) They were impressed with my collection of satires of  Nobel Laureate Bob Dylan (<a href="https://www.cs.umd.edu/users/gasarch/dylan/dylan.html">here</a>) .</p><p>5) They were impressed with some subset of (a) complexityblog, (b) <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279729/ref=sr_1_3?dchild=1&amp;keywords=gasarch&amp;qid=1609867944&amp;sr=8-3" target="_blank">Problems with a Point</a>,  (c)  <a href="https://www.amazon.com/Mathematical-Muffin-Morsels-Problem-Mathematics/dp/9811215979/ref=sr_1_2?dchild=1&amp;keywords=gasarch&amp;qid=1609868018&amp;sr=8-2">Mathematical Muffin Morsels</a>, and (d) <a href="https://www.amazon.com/Bounded-Queries-Recursion-Progress-Computer-ebook/dp/B000W98WU4/ref=sr_1_4?dchild=1&amp;keywords=gasarch&amp;qid=1609868084&amp;sr=8-4">Bounded Queries in Recursion Theory</a>. Or maybe just having 3 books on amazon is their threshold.  If it's complexityblog then Lance and I should co-author something for them.</p><p>6) It is a vanity-journal where you pay to  publish. So why email me who (a)  is not an artist, (b) is  not a fine artist, and most important (3) <b>does not think of himself as a fine artist</b>. The PRO of emailing me or people like me is they cast a wide net. The CON is--- there is no CON! It costs nothing to email me, and emailing me does not affect their credibility. That still raises the question of how they got my name.</p><p>7) Could it be a phishing? If I click on something in the email would they  get my credit card number? Their email begins <i>Dear Professor</i> not  <i>Dear Professor Gasarch. </i>  So they know I am a professor. Then again, I have known of ugrads who get emails that begin <i>Dear Professor</i>. (The emails to HS student Naveen and ugrad Nichole in the story I tell <a href="https://blog.computationalcomplexity.org/search?q=Naveen">here</a> were addressed to <i>Dear Professor.) </i></p><p>8) They mistook me for my parents who, in 1973,  put together an anthology of short stories titled <i>Fiction:The Universal elements</i>,  for a Freshman Comp course my mom taught, see <a href="https://www.amazon.com/Fiction-Universal-Element-P-Gasarch/dp/0442226322">here</a>. I note that their book ranks around 18,000,000, so even that explanation is unlikely. Actually the rank changes a lot- it was 12,000,000 this morning. Still, not what one would call a best seller. It's fun to see what is doing better: <i>Bounded Queries in Recursion Theory (currently at around rank 6.000.000) </i> or <i>Fiction: The Universal Elements.</i></p><p> If I ever get one of these emails from a History Journal I will submit my Satirical <i>Ramsey Theory and the History of Pre-Christian England: An Example of Interdisciplinary Research</i> (see <a href="https://www.cs.umd.edu/~gasarch/COURSES/389/W14/ramseykings.pdf">here</a>) just to see what happens- but  I will stop short of paying-to-publish. Or maybe I will pay-to-publish so that the next time I try to fool a class with it I can point to a seemingly real journal which has the article. </p><p><br /></p><div style="background-color: white; color: #222222; cursor: auto; font-family: Roboto, RobotoDraft, Helvetica, Arial, sans-serif; font-size: 0.875rem; padding: 20px 0px 0px;" class="gE iv gt"><table cellpadding="0" class="cf gJ"><tbody style="display: block;"><tr style="display: flex; height: auto;" class="acZ"><td style="display: block; line-height: 20px; margin: 0px; padding: 0px; vertical-align: top; white-space: nowrap; width: 571.172px;" class="gF gK"><br /></td></tr></tbody></table></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/06/someone-thinks-i-am-fine-artist-why.html"><span class="datestr">at June 28, 2021 03:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/090">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/090">TR21-090 |  On Secret Sharing, Randomness, and Random-less Reductions for Secret Sharing | 

	Divesh Aggarwal, 

	Maciej Obremski, 

	Eldon Chung, 

	Joao Ribeiro</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Secret-sharing is one of the most basic and oldest primitives in cryptography, introduced by Shamir and Blakely in the 70s. It allows to strike a meaningful balance between availability and confidentiality of secret information. It has a host of applications most notably in threshold cryptography and multi-party computation. All known constructions of secret sharing (with the exception of those with a pathological choice of parameters) require access to uniform randomness. In practice, it is extremely challenging to generate a source of uniform randomness. This has led to a large body of research devoted to designing randomized algorithms and cryptographic primitives from imperfect sources of randomness.

Motivated by this, 15 years ago, Bosley and Dodis asked whether it is even possible to build 2-out-of-2 secret sharing without access to uniform randomness. In this work, we make progress towards resolving this question.

We answer this question for secret sharing schemes with important additional properties, i.e., either leakage-resilience or non-malleability. We prove that, unfortunately, for not too small secrets, it is impossible to construct any of 2-out-of-2 leakage-resilient secret sharing or 2-out-of-2 non-malleable secret sharing without access to uniform randomness.

Given that the problem whether 2-out-of-2 secret sharing requires uniform randomness has been open for a long time, it is reasonable to consider intermediate problems towards resolving the open question. In a spirit similar to NP-completeness, we study how the existence of a t-out-of-n secret sharing without access to uniform randomness is related to the existence of a t'-out-of-n' secret sharing without access to uniform randomness for a different choice of the parameters t,n,t',n'.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/090"><span class="datestr">at June 27, 2021 05:51 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/089">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/089">TR21-089 |  A Relativization Perspective on Meta-Complexity | 

	Rahul Santhanam, 

	Hanlin Ren</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Meta-complexity studies the complexity of computational problems about complexity theory, such as the Minimum Circuit Size Problem (MCSP) and its variants. We show that a relativization barrier applies to many important open questions in meta-complexity. We give relativized worlds where:

* MCSP can be solved in deterministic polynomial time, but the search version of MCSP cannot be solved in deterministic polynomial time, even approximately. In contrast, Carmosino, Impagliazzo, Kabanets, Kolokolova [CCC'16] gave a randomized approximate search-to-decision reduction for MCSP with a relativizing proof.

* The complexities of MCSP[2^{n/2}] and MCSP[2^{n/4}] are different, in both worst-case and average-case settings. Thus the complexity of MCSP is not "robust" to the choice of the size function.

* Levin's time-bounded Kolmogorov complexity Kt(x) can be approximated to a factor (2+epsilon) in polynomial time, for any epsilon &gt; 0.

* Natural proofs do not exist, and neither do auxiliary-input one-way functions. In contrast, Santhanam [ITCS'20] gave a relativizing proof that the non-existence of natural proofs implies the existence of one-way functions under a conjecture about optimal hitting sets.

* DistNP does not reduce to GapMINKT by a family of "robust" reductions. This presents a technical barrier for solving a question of Hirahara [FOCS'20].</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/089"><span class="datestr">at June 25, 2021 03:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8156">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2021/06/25/stoc-feedback-and-tcs-wikipedia-guest-post-by-clement-canonne/">STOC feedback and TCS Wikipedia (guest post by Clément Canonne )</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The 53rd Annual ACM <a href="http://acm-stoc.org/stoc2021/">Symposium on Theory of  Computing </a> (STOC’21) concludes today, after 5 days of action-packed, Gather-power talks, workshops, plenary talks, and posters. A huge thank you to all volunteers, organizers, speakers, and attendees, who helped make this virtual conference a success!</p>



<p>We would like to ask for your feedback on the conference. Whether you attended this virtual edition of STOC or not, please fill <a href="https://forms.gle/r1A4zCS6umbhZTrMA">this form </a> to help us make future TheoryFests even better!</p>



<p>Moreover, as part of one of the STOC social event (and in line with initiatives in 2017 by Shuchi Chawla and the <a href="https://thmatters.wordpress.com/2019/06/11/wikipedia-edit-a-thon-at-stoc19/">Edit-a-Thon from STOC 2019</a> , a spreadsheet aiming to crowdsource which TCS Wikipedia pages need improvement/creation has been set up:<br /><a href="https://docs.google.com/spreadsheets/d/1ZswaweUvsjVHnItMBnIxaiBZxcs-gEaUoODFoH4FGms/edit" target="_blank" rel="noreferrer noopener">https://docs.google.com/spreadsheets/d/1ZswaweUvsjVHnItMBnIxaiBZxcs-gEaUoODFoH4FGms/edit</a>. </p>



<p>Feel free to use or edit it in view of improving the TCS coverage in Wikipedia.</p>



<p>Clément Canonne (on behalf of the STOC and TheoryFest organizers)</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2021/06/25/stoc-feedback-and-tcs-wikipedia-guest-post-by-clement-canonne/"><span class="datestr">at June 25, 2021 02:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/06/25/postdoc-at-uc-san-diego-apply-by-july-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/06/25/postdoc-at-uc-san-diego-apply-by-july-1-2021/">postdoc at UC San Diego (apply by July 30, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The UCSD CSE Fellows Program is intended to support exceptional postdoctoral researchers in computer science. The program seeks to recruit 1-3 fellows a year for a two year postdoctoral appointment working alongside a UCSD CSE faculty mentor.</p>
<p>Website: <a href="https://cse.ucsd.edu/research/uc-san-diego-cse-fellows-program">https://cse.ucsd.edu/research/uc-san-diego-cse-fellows-program</a><br />
Email: shachar.lovett@gmail.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/06/25/postdoc-at-uc-san-diego-apply-by-july-1-2021/"><span class="datestr">at June 25, 2021 02:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-4913288096208854339">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2021/06/the-detecter-runtime-verification-tool.html">The detectEr runtime-verification tool for Erlang programs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Thanks to the huge amount of excellent work done by <a href="https://duncanatt.github.io/" target="_blank">Duncan Paul Attard</a> and <a href="http://staff.um.edu.mt/afra1/" target="_blank">Adrian Francalanza</a>, we now have a tutorial on detectEr that some of you might want to check out. See <a href="https://duncanatt.github.io/detecter/index.html">this web page</a> for all the material, tool download and links to the videos of the tutorial Duncan delivered at the <a href="https://www.discotec.org/2021/tutorials" target="_blank">DisCoTec 2021 Tutorial Day</a>. </p><p>detectEr is a runtime verification tool for asynchronous component systems that run on the <a href="https://blog.erlang.org/a-brief-BEAM-primer/" target="_blank">Erlang Virtual Machine</a>. It also supports monitoring systems that can execute outside of the EVM, so long as these can produce traces that are formatted in a way that is parsable by detectEr. The tool itself is developed in <a href="https://www.erlang.org/" target="_blank">Erlang</a>, and is the product of five years of theoretical and practical development. (Erlang is a programming language used to build massively scalable soft real-time systems with requirements on high availability.)  </p> <p>Enjoy!</p></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2021/06/the-detecter-runtime-verification-tool.html"><span class="datestr">at June 24, 2021 08:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6958131418382007261">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html">I went to the ``debate'' about Program Verif and the Lipton-Demillo-Perlis paper</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>On Thursday June 17 I went to (on zoom- does that need to be added anymore?)</p><p><i>A Debate on Program Correctness</i></p><p>There was no subtitle but it could have been:</p><p>Have the points made in <i>Social Processes and Proofs of Theorems and Programs</i> by DeMillo, Lipton, Perlis, survived the test of time ? (Spoiler Alert: Yes.)</p><p>I found out about it from the Lipton-Regan blog <a href="https://rjlipton.wpcomstaging.com/2021/06/15/thursday-june-17th-a-debate-on-program-correctness/">here</a></p><p>The debaters were Richard DeMillo and Richard Lipton and the moderator was Harry Lewis (Alan Perlis passed away in 1990).  Calling it a debate is not correct since DeMillo and Lipton (and Lewis) all agree. (DeMillo and Lipton even have the same first name!)  The DLP paper is in Harry Lewis's collection<i> Ideas that created the future.</i>  The event  should have been advertised as a discussion. However, it was a good discussion so this is not a complaint.</p><p>Here are some things that came out of the discussion.</p><p>1) The main topic was the 1979 DeMillo-Lipton-Perlis paper (see <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">here</a>) that gave arguments why Proofs of Program correctness could not work.</p><p>An all-to-brief summary of the DLP paper: Some researchers are trying to set up frameworks for doing proofs that programs are correct, analogous to the certainty  we get with a proof of a Theorem in Mathematics. But proofs in Mathematics are, in reality, NOT that rigorous. Often details are left out or left to the reader. This is fine for mathematics (more on that later) but unacceptable for programs which need rather precise and rigorous proofs.</p><p>How do theorems in mathematics really get verified? By having enough people look at them and make sure they match intuitions, what DLP call <i>A Social Process</i>.  (NOTE FROM BILL: Papers that are not important do not get looked at so there may well be errors.)</p><p>2) The notion of proving-programs-correct was very seductive; however, the people who were trying to do this had a blind spot about how the analogy of proving-programs-correct and proving-theorem-correct differ.  In particular, a program is rather complicated and even stating carefully what you want to prove is difficult. By contrast, for most math statements, what you want to prove is clear. Note also that a program has lots of code (far more now than when DLP was written) and so much can happen that you cannot account for.</p><p>3) The DLP paper had a large effect on the field of program verification.  Funding for it was reduced and students were discouraged from going into it.</p><p>4) When DLP appeared DeMillo and Lipton were pre-tenure. Hence it took lots of courage to publish it. Alan Perlis had tenure and had already won a Turing award.  This did give DeMillo and Lipton some cover; however, it still took courage.</p><div><div>5) How did the Program Verification  Community deal with the objections in DLP?  DeMillo said that he looked at a large set of papers in the field, and very few even mentioned DLP. He recommends reading the book <i>Mechanizing Proof: Computing, Risk, and Trust by David McKenzie </i>see <a href="https://www.amazon.com/exec/obidos/ASIN/0262632950">here</a>.</div><div><br /></div><div>6) So how can we be more certain that programs are correct?</div><div><br /></div><div>a) Testing.</div><div>b) Modularize and test. Fix errors. Modularize  and test. Fix errors...</div><div>c) Try to isolate side effects.</div><div>d) More testing.</div><div><br /></div><div>Some point to Model Checking, which could be considered very sophisticated testing, but that's used to verify circuits and perhaps low-level code, not programs. Model checking is a success story and note that Ed Clark, E. Allen Emerson, and Joseph Sifakis shared a (well deserved) Turing award for this work. But see next note.</div><div><br /></div><div>6.5) An audience member pointed out that Program Verification people have won several Turing Awards</div><div><br /></div><div>Dijkstra 1972</div><div><br /></div><div>Floyd 1978 </div><div><br /></div><div>Hoare 1980</div><div><br /></div><div>Pnueli 1996</div><div><br /></div><div>(Are there more?) </div><div><br /></div><div>so the field is alive and healthy. DeMillo responded that prizes for academic research are a poor measure of  success. </div><div><br /></div><div>7) Can computers themselves help with proofs of correctness? That is the only hope; however, there are scaling problems.</div><div><br /></div><div>8) When DLP was written a program with 100,000 lines of code was considered large. Now we have programs with millions of lines of code. And now we have more concurrency. So the lessons of the DLP paper are probably more relevant now then they were then.</div><div><br /></div><div>9) Since Program Verification does not seem to be used, how come we don't have a Software crisis?</div><div><br /></div><div>a) We do! The Q+A mechanism at the meeting was terrible. </div><div>b) We do! FILL IN YOUR OWN FAVORITE STORY OF BAD SOFTWARE.</div><div>c) See the answer to question 6.</div><div><br /></div><div>10) SPECS are a problem. Tony Hoare once gave a talk where he proves that a program sorted correctly and then pointed out that if the program just output 0,...0 that would have also satisfied the SPEC since all that was required was that the output be sorted, not the (overlooked!) requirement that it be the same numbers as the input. So one needs to be careful!</div><div><br /></div><div>11) Despite being a leader in the field, Tony Hoare has come to see the limitations of the Proofing-programs-correct approach to Software Verification.  His paper An Axiomatic basis for Computer Programming (1969)  (which is also in Harry Lewis's collection <i>Ideas that Created the Future</i>).</div><div>Much later, commenting on the paper,  Hoare says the following:</div><div><br /></div><div>Ten years ago, researchers into formal methods (and I was the most mistaken among them) predicted that the programming world would embrace with gratitude every assistance promised by formalization to solve the problems of reliability that arise when programs get large and more safety-critical. Programs have now got very large and very critical--well beyond the scale which can be comfortably tackled by formal methods. There have been many problems and failures, but these have nearly always been attributable to inadequate analysis of requirements or inadequate management control. It has turned out that the world just does not suffer significantly from the kind of problem that our research was originally intended to solve.'</div><div><br /></div></div><div><div>12) Richard Lipton told a story where he showed that the program in question satisfied the SPEC, but the SPEC was a tautology that any program would satisfy.  Again, one needs to be careful!</div><div><br /></div><div>13) The test of time: Verifying large scale programs does not seem to be common in industry. Is industrial adaptation a fair measure? </div><div><br /></div><div>14) Harry Lewis's  book <i>Ideas that created the future</i> collects up, edits, and comments on 46 important papers in Computer Science (I reviewed it in the issue of SIGACT News that is in your mailbox---I will blog about it at a later time.) There are several papers in it about program verification, including DLP, Hoare's paper, and three papers by Dijkstra.</div><div><br /></div><div>a) When Harry discussed including DLP some people said `You're going to include that!  Its a polemic, not a paper!'</div><div><br /></div><div>b) When Harry teaches a course from this book (it must be an awesome class!) and asks the students at the end which papers they learned the most from, the top two are an excerpt from Fred Brooks <i>The</i> <i>Mythical Man Month</i> (see my post on Brook's work <a href="https://blog.computationalcomplexity.org/2021/05/the-mythical-man-month-hen-day-and-cat.html">here</a> ) and DLP.</div><div><br /></div><div>c) I am hoping that this is just one of 46 talks with authors of the papers in his book.  I look forward to his interview with Aristotle, Leibnitz, Boole, Turing, ...</div></div><div><br /></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/06/i-went-to-debate-about-program-verif.html"><span class="datestr">at June 24, 2021 03:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5549">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5549">STOC’2021 and BosonSampling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Happy birthday to Alan Turing!</p>



<p>This week I’m participating virtually in <a href="http://acm-stoc.org/stoc2021/">STOC’2021</a>, which today had a celebration of the 50th anniversary of NP-completeness (featuring Steve Cook, Richard Karp, Leonid Levin, Christos Papadimitriou, and Avi Wigderson), and which tomorrow will have a day’s worth of quantum computing content, including a tutorial on MIP*=RE, two quantum sessions, and an invited talk on quantum supremacy by John Martinis.  I confess that I’m not a fan of GatherTown, the platform being used for STOC.  Basically, you get a little avatar who wanders around a virtual hotel lobby and enters sessions—but it seems to reproduce all of the frustrating and annoying parts of experience without any of the good parts.</p>



<p>Ah!  But I got the surprising news that Alex Arkhipov and I are among the winners of STOC’s first-ever <a href="https://sigact.org/prizes/stoc_tot.html">“Test of Time Award,”</a> for our <a href="https://www.scottaaronson.com/papers/optics.pdf">paper on BosonSampling</a>.  It feels strange to win a “Test of Time” award for work that we did in 2011, which still seems like yesterday to me.  All the more since the experimental status and prospects of quantum supremacy via BosonSampling are still very much live, unresolved questions.</p>



<p>Speaking of which: on Monday, Alexey Rubtsov, of the Skolkovo Institute in Moscow, gave a talk for our quantum information group meeting at UT, about his <a href="https://arxiv.org/abs/2106.01445">recent work with Popova</a> on classically simulating Gaussian BosonSampling.  From the talk, I learned something extremely important.  I had imagined that their simulation must take advantage of the high rate of photon loss in actual experiments (like the <a href="https://www.scottaaronson.com/blog/?p=5159">USTC experiment</a> from late 2020), because how else are you going to simulate BosonSampling efficiently?  But Rubtsov explained that that’s not how it works at all.  While their algorithm is heuristic and remains to be rigorously analyzed, numerical studies suggest that it works even with <em>no</em> photon losses or other errors.  Having said that, their algorithm works:</p>



<ul><li>only for Gaussian BosonSampling, not Fock-state BosonSampling (as Arkhipov and I had originally proposed),</li><li>only for threshold detectors, not photon-counting detectors, and</li><li>only for a small number of modes (say, linear in the number of photons), not for a large number of modes (say, quadratic in the number of photons) as in the original proposal.</li></ul>



<p>So, bottom line, it now looks like the USTC experiment, amazing engineering achievement though it was, is not hard to spoof with a classical computer.  If so, this is because of multiple ways in which the experiment differed from my and Arkhipov’s original theoretical proposal.  We know exactly what those ways are—indeed, you can find them in my earlier blog posts on the subject—and hopefully they can be addressed in future experiments.  All in all, then, we’re left with a powerful demonstration of the continuing relevance of formal hardness reductions, and the danger of replacing them with intuitions and “well, it still seems hard to <em>me</em>.”  So I hope the committee won’t rescind my and Arkhipov’s Test of Time Award based on these developments in the past couple weeks!</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5549"><span class="datestr">at June 23, 2021 04:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1325">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2021/06/23/tcs-visioning-2020-report-and-slides/">TCS Visioning 2020 report and slides</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In July 2020, the <a href="https://thmatters.wordpress.com/catcs/">CATCS</a> organized a <a href="https://thmatters.wordpress.com/2020/06/05/tcs-visioning-workshop-call-for-participation/">visioning workshop</a>. We are happy to announce the release of a report and posters based on this workshop. Material produced from this workshop is available and free to use by any member of the TCS community. We gratefully acknowledge financial as well as organizational support by the <a href="https://www.sigact.org/">SIGACT</a> and <a href="https://cra.org/ccc/">CCC</a> for this activity.</p>



<p>We are planning a follow-up event for disseminating the report and posters to funding agencies in the next few months. Details are forthcoming.</p>



<p>TCS Visioning Full Report: <a href="https://thmatters.files.wordpress.com/2021/06/visioning-report.pdf">here</a></p>



<p>Short Report (CCC Quadrennial paper): <a href="https://cra.org/ccc/wp-content/uploads/sites/2/2020/10/Theoretical-Computer-Science_.pdf">here</a></p>



<p>TCS Visioning Slides: <a href="https://thmatters.files.wordpress.com/2021/06/visioning-slides.pptx">in PPT</a> and <a href="https://thmatters.files.wordpress.com/2021/06/visioning-slides-1.pdf">in PDF</a></p></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2021/06/23/tcs-visioning-2020-report-and-slides/"><span class="datestr">at June 23, 2021 04:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/088">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/088">TR21-088 |  Open Problems in Property Testing of Graphs | 

	Oded Goldreich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We briefly discuss a few open problems in the study of various models of testing graph properties, focusing on the query complexity of the various tasks. In the dense graph model, we discuss several open problems, including:

* Determining the complexity of testing triangle-freeness.
* Characterizing the class of properties that are testable within extremely low complexity. 

Turning to the bounded-degree graph model, we discuss several open problems, including:

* Characterizing the class of properties that are testable within size-oblivious complexity.
* Determining the complexity of graph isomorphism. 
In each of the foregoing models, we also discuss a favorite open problem that was recently resolved. Lastly, we discuss the vast lack of knowledge with respect to testing graph properties in the general graph model.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/088"><span class="datestr">at June 23, 2021 01:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/087">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/087">TR21-087 |  Eliminating Intermediate Measurements using Pseudorandom Generators | 

	Uma Girish, 

	Ran Raz</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that quantum algorithms of time T and space $S \ge \log T$ with intermediate measurements can be simulated by quantum algorithms of time $T\cdot \mathrm{poly}(S)$ and space $O(S\cdot \log T)$ without intermediate measurements. The best simulations prior to this work required either $\Omega(T)$ space (by the deferred measurement principle) or $\mathrm{poly}(2^S)$ time [FR21, GRZ21]. Our result is thus a time-efficient and space-efficient simulation of algorithms with intermediate measurements by algorithms without intermediate measurements.

To prove our result, we study pseudorandom generators for quantum space-bounded algorithms. We show that (an instance of) the INW pseudorandom generator for classical space-bounded algorithms [INW94] also fools quantum space-bounded algorithms. More precisely, we show that for quantum space-bounded algorithms that have access to a read-once tape consisting of random bits, the final state of the algorithm when the random bits are drawn from the uniform distribution is nearly identical to the final state when the random bits are drawn using the INW pseudorandom generator.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/087"><span class="datestr">at June 22, 2021 04:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/086">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/086">TR21-086 |  Linear Space Streaming Lower Bounds for Approximating CSPs | 

	Chi-Ning  Chou, 

	Alexander Golovnev, 

	Madhu Sudan, 

	Ameya Velingker, 

	Santhoshini Velusamy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We consider the approximability of constraint satisfaction problems in the streaming setting. For every constraint satisfaction problem (CSP) on $n$ variables taking values in $\{0,\ldots,q-1\}$, we prove that improving over the trivial approximability by a factor of $q$ requires $\Omega(n)$ space even on instances with $O(n)$ constraints. We also identify a broad subclass of problems for which any improvement over the trivial approximability requires $\Omega(n)$ space. The key technical core is an optimal, $q^{-(k-1)}$-inapproximability for the case where every constraint is given by a system of $k-1$ linear equations $\bmod\; q$ over $k$ variables. Prior to our work, no such hardness was known for an approximation factor less than $1/2$ for any CSP. Our work builds on and extends the work of Kapralov and Krachun (Proc. STOC 2019) who showed a linear lower bound on any non-trivial approximation of the max cut in graphs. This corresponds roughly to the case of  Max $k$-LIN-$\bmod\; q$ with $k=q=2$. Each one of the extensions provides non-trivial technical challenges that we overcome in this work.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/086"><span class="datestr">at June 22, 2021 02:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2021/06/22/annual-symposium-on-combinatorial-pattern-matching-summer-school-conference/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2021/06/22/annual-symposium-on-combinatorial-pattern-matching-summer-school-conference/">Annual Symposium on Combinatorial Pattern Matching (summer school + conference))</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
July 4, 2021 – July 7, 2021 Wrocław, Poland and online https://cpm2021.ii.uni.wroc.pl/ The Annual Symposium on Combinatorial Pattern Matching (CPM) has by now over 30 years of tradition and is considered to be the leading conference for the community working on Stringology. The objective of the annual CPM meetings is to provide an international forum … <a href="https://cstheory-events.org/2021/06/22/annual-symposium-on-combinatorial-pattern-matching-summer-school-conference/" class="more-link">Continue reading <span class="screen-reader-text">Annual Symposium on Combinatorial Pattern Matching (summer school + conference))</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2021/06/22/annual-symposium-on-combinatorial-pattern-matching-summer-school-conference/"><span class="datestr">at June 22, 2021 08:09 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/085">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/085">TR21-085 |  The Final Nail in the Coffin of Statistically-Secure Obfuscator. | 

	Ilya Volkovich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We present an elementary, self-contained proof of the result of Goldwasser and Rothblum [GR07] that the existence of a (perfect) statistically secure obfuscator implies a collapse of the polynomial hierarchy. In fact, we show that an existence of a weaker object implies a somewhat stronger statement. In addition, we extend the result of [GR07] to the case of imperfect statistically secure obfuscator.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/085"><span class="datestr">at June 21, 2021 04:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2146860754670937912">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/06/collusion-rings.html">Collusion Rings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><i>Grigory Yaroslavtsev now maintains the <a href="https://docs.google.com/spreadsheets/d/1kobGLgx5QgJb9AvDENg5c8wEbwBUUkVlMTsBV9quEEY/edit?usp=sharing">Theory Jobs Spreadsheet</a>, a crowd-sourced listing of where your favorite CS theorists have taken new positions. Read his <a href="http://grigory.us/blog/theory-jobs-2021/">blog post</a> for more info.</i></p><p><i>Michael Littman wrote a <a href="https://cacm.acm.org/magazines/2021/6/252840-collusion-rings-threaten-the-integrity-of-computer-science-research/fulltext">CACM Viewpoint</a> on collusion rings designed to tilt the odds into getting papers into conferences. See also <a href="https://medium.com/@tnvijayk/potential-organized-fraud-in-acm-ieee-computer-architecture-conferences-ccd61169370d">this post</a> by T. N. Vijaykumar. I started to write a post on the topic but couldn't get it going so I asked the AI algorithm GPT-3 to write a guest post. Here is its story.</i></p><hr /><p>I have been part of a collusion ring and I know how it feels. I was a postdoc at the University of California, Berkeley, in the early 2000s when I first learned about the practice of “paper rings.” A paper ring is a group of researchers who agree to submit each other’s papers to conferences without disclosing this fact to the conference organizers. The idea is that if you have several submissions from the same conference, your chances of getting accepted are higher. The pressure to be part of such a ring can be immense. You are told that you need to publish or perish and that you need to get papers into top conferences. If you don’t play along, you will be left behind. I was lucky enough to have a mentor who warned me against being part of such rings. He told me that if I did not want my name on a paper, then I should not submit it to a conference. He also told me that if I did not want to be part of a paper ring, then I should not submit papers for others in the ring. He said that he would help me with my own research and that he would help me get my own papers into conferences. He was right: My own papers were accepted into conferences and they were published in journals.</p><p>I am now an associate professor at the University of Massachusetts Amherst and I have been on the other side of this issue as well. In 2012, I was asked by an editor at a top computer science conference to review a paper submitted by one of my students. The student had been part of a paper ring and had submitted his own paper along with those submitted by his collaborators in the ring. The editor told me that he had rejected the student’s paper because it was too similar to other papers submitted by members of the ring. However, he wanted me to review it so that he could reconsider accepting it for publication if I recommended doing so.</p><p>What should I do? Should I tell him about the paper ring? Should I recommend accepting the paper? Should I tell him that there is no way he should accept it? Should I tell him that he should reject it but then publish it anyway? What would you do? I decided not to tell him about the paper ring and not to recommend accepting the paper for publication. Instead, I told him that he should reject it but then publish it anyway because this would send a strong message about what we expect from our students and what we think about such practices. The editor agreed with my decision and published the student’s paper along with two other papers submitted by members of the same paper ring.</p><p>The student received his PhD degree but did not get any credit for his work on these three papers because they were considered as part of his dissertation work when he defended his thesis later that year. In retrospect, I think that my decision was wrong because it allowed these students to continue their unethical behavior without any consequences for them or their advisors (who were also part of this ring). But at least in this case, there were no negative consequences for anyone involved in this incident except for these students who did not get credit for their work on these three papers because they were considered as part of their dissertation work when they defended their thesis later that year.</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/06/collusion-rings.html"><span class="datestr">at June 21, 2021 02:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/06/21/postdoc-at-bar-ilan-university-apply-by-july-15-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/06/21/postdoc-at-bar-ilan-university-apply-by-july-15-2021/">postdoc at Bar-Ilan University (apply by July 15, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A postdoc position is available at the Network Computation group<br />
at Bar-Ilan University (Israel). We invite applicants interested in the fields of distributed, online, and approximated computing on graph and network problems; Algorithms in hardware; circuit complexity; communication complexity; coding theory and distributed coding schemes.</p>
<p>Website: <a href="https://docs.google.com/document/d/1rCXAByE0J8VDLSXXq4p5a6LDVkBBRaRBrRQhOiCuo7U/edit">https://docs.google.com/document/d/1rCXAByE0J8VDLSXXq4p5a6LDVkBBRaRBrRQhOiCuo7U/edit</a><br />
Email: moti.medina@biu.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/06/21/postdoc-at-bar-ilan-university-apply-by-july-15-2021/"><span class="datestr">at June 21, 2021 12:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/084">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/084">TR21-084 |  PCPs and Instance Compression from a Cryptographic Lens | 

	Ron Rothblum, 

	Liron Bronfman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Modern cryptography fundamentally relies on the assumption that the adversary trying to break the scheme is computationally bounded. This assumption lets us construct cryptographic protocols and primitives that are known to be impossible otherwise. In this work we explore the effect of bounding the adversary's power in other information theoretic proof-systems and show how to use this assumption to bypass impossibility results.

We first consider the question of constructing succinct PCPs. These are PCPs whose length is polynomial only in the length of the original NP witness (in contrast to standard PCPs whose length is proportional to the non-deterministic verification time). 
Unfortunately, succinct PCPs are known to be impossible to construct under standard complexity assumptions. Assuming the sub-exponential hardness of the learning with errors (LWE) problem, we construct succinct probabilistically checkable arguments or PCAs (Zimand 2001, Kalai and Raz 2009), which are PCPs in which soundness is guaranteed against efficiently generated false proofs. Our PCA construction is for every NP relation that can be verified by a small-depth circuit (e.g., SAT, clique, TSP, etc.) and in contrast to prior work is publicly verifiable and has constant query complexity. Curiously, we also show, as a proof-of-concept, that such publicly-verifiable PCAs can be used to derive hardness of approximation results.

Second, we consider the notion of Instance Compression (Harnik and Naor, 2006). An instance compression scheme lets one compress, for example, a CNF formula $\varphi$ on $m$ variables and $n \gg m$ clauses to a new formula $\varphi'$ with only $poly(m)$ clauses, so that $\varphi$ is satisfiable if and only if $\varphi'$ is satisfiable. Instance compression has been shown to be closely related to succinct PCPs and is similarly highly unlikely to exist. We introduce a computational analog of instance compression in which we require that if $\varphi$ is unsatisfiable then $\varphi'$ is effectively unsatisfiable, in the sense that it is computationally infeasible to find a satisfying assignment for $\varphi'$ (although such an assignment may exist). Assuming the same sub-exponential LWE assumption, we construct such computational instance compression schemes for every bounded-depth NP relation. As an application, this lets one compress $k$ formulas $\phi_1,\dots,\phi_k$ into a single short formula $\phi$ that is effectively satisfiable if and only if at least one of the original formulas was satisfiable.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/084"><span class="datestr">at June 21, 2021 10:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=324">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2021/06/21/social-at-stoc-2021/">Social at STOC 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I’ve been asked to pass along a message by <a href="https://ccanonne.github.io/">Clément Canonne</a>, social chair for STOC 2021. This STOC might have the best social program of any I’ve ever seen, either virtual or in-person, so be sure to check it out!</p>



<hr class="wp-block-separator" />



<p>STOC’21 is around the corner, starting tomorrow; [don’t forget to register](<a href="http://acm-stoc.org/stoc2021/">http://acm-stoc.org/stoc2021/</a>), if you haven’t yet! This year, the (virtual) conference will include several social activities (games, TCS trivia, mystery hunt…); among which, two “junior/senior lunches,” on Monday and Friday.<br /><br />Those both will be held in the Gather space for STOC (<a href="http://acm-stoc.org/stoc2021/venue.html">http://acm-stoc.org/stoc2021/venue.html</a>), and — as in previous years — are the occasion for senior researchers in the field, broadly construed, to have an informal chat with students, postdocs, and junior faculty, answer their questions, discuss their research, and generally have a nice conversation.<br /><br />If you are interested, don’t forget to sign up! This is done through the “feedback box” placed on the Information Desk in the Gather space’s Lobby, which gives access to a spreadsheet.<br /><br />Hoping to see you at STOC!</p>



<figure class="wp-block-image size-large"><img src="https://kamathematics.files.wordpress.com/2021/06/image.png?w=778" alt="" class="wp-image-325" /></figure></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2021/06/21/social-at-stoc-2021/"><span class="datestr">at June 21, 2021 02:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/083">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/083">TR21-083 |  Tight Space Complexity of the Coin Problem | 

	Mark Braverman, 

	Sumegha Garg, 

	Or Zamir</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In the coin problem we are asked to distinguish, with probability at least $2/3$, between $n$ $i.i.d.$ coins which are heads with probability $\frac{1}{2}+\beta$ from ones which are heads with probability $\frac{1}{2}-\beta$. We are interested in the space complexity of the coin problem, corresponding to the width of a read-once branching program solving the problem. 

The coin problem becomes more difficult as $\beta$ becomes smaller. Statistically, it can be solved whenever $\beta = \Omega(n^{-1/2})$, using counting. It has been previously shown that for $\beta = O(n^{-1/2})$, counting is essentially optimal (equivalently, width $poly(n)$ is necessary [Braverman-Garg-Woodruff FOCS'20]). On the other hand, the coin problem only requires $O(\log n)$ width for $\beta&gt;n^{-c}$ for any constant $c&gt;\log_2(\sqrt{5}-1)\approx 0.306$ (following low-width simulation of AND-OR tree of [Valiant Journal of Algorithms'84]).

In this paper, we close the gap between the bounds, showing a tight threshold between the values of $\beta=n^{-c}$ where $O(\log n)$ width suffices and the regime where $poly(n)$ width is needed, with a transition at $c=1/3$. This gives a complete characterization (up to constant factors) of the memory complexity of solving the coin problem, for all values of bias $\beta$. 

We introduce new techniques in both bounds. For the upper bound, we give a construction based on recursive majority that does not require a memory stack of size $\log n$ bits. For the lower bound, we introduce new combinatorial techniques for analyzing progression of the success probabilities in read-once branching programs.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/083"><span class="datestr">at June 20, 2021 11:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=18926">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2021/06/20/the-shape-of-this-summer/">The Shape of This Summer</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><font color="#0044cc"><br />
<em>Looking farther than Father’s Day</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2021/06/20/the-shape-of-this-summer/ellenbergbucksdec2019/" rel="attachment wp-att-18928"><img width="127" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/EllenbergBucksDec2019.jpg?resize=127%2C170&amp;ssl=1" class="alignright wp-image-18928" height="170" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><a href="https://twitter.com/JSEllenberg/status/1209913559720837121">src</a></font></td>
</tr>
</tbody>
</table>
<p>Jordan Ellenberg is the author of the new <a href="https://www.penguinrandomhouse.com/books/612131/shape-by-jordan-ellenberg/9781984879059/">book</a> <em>Shape: The Hidden Geometry of Information, Biology, Strategy, Democracy, and Everything Else</em>. I just received it as a Father’s Day present.</p>
<p>
Today we convey some short musings on some ideas in the book.<br />
<span id="more-18926"></span></p>
<p>
Ellenberg is both a biological father and a <em>Doktorvater</em>. Indeed, if we make a correct inference from his Mathematics Genealogy <a href="https://www.genealogy.math.ndsu.nodak.edu/id.php?id=31096">count</a> of “12 students and 13 descendants,” he must be a doctor-grandfather. His own advisor was Barry Mazur. Ellenberg holds the John D. MacArthur professorship in Mathematics at UW-Madison and a distinguished professorship named for former Wisconsin senator William Vilas. (We’ve had UW-Madison on our minds for over a month about something else, but various events including new kinds of chess-cheating cases have delayed the work needed to do it justice. While writing this paragraph, I have had a seconding role in a disqualification by an online chess platform of a player in a tournament played today.)</p>
<p>
I made my inference in the last paragraph by counting—I did not take time to click on his twelve students to verify which one has a graduated student. What strikes us about the new book is the aspect of making inferences <em>not</em> by counting.</p>
<p>
</p><p></p><h2> Pandemic Phasing </h2><p></p>
<p></p><p>
Our picture above was <a href="https://twitter.com/JSEllenberg/status/1209913559720837121">tweeted</a> by Ellenberg on Christmas Day, 2019, a half-hour before the start of the Milwaukee Bucks <a href="https://www.basketball-reference.com/boxscores/201912250PHI.html">playing</a> at the Philadelphia 76ers. Notice that the seats behind him have not yet filled, as of course they did for a pre-pandemic holiday game. Last night, I had on the terrific Game 7 between the Bucks and the Brooklyn Nets while processing chess data. The stands at the Brooklyn Barclays Center were within 1,000 of full capacity, but there seemed to be some spaced-out sections nearest the court that would have been teeming usually.</p>
<p>
My wife and I ventured out two weeks ago to see the Toronto Blue Jays play in Buffalo’s <a href="https://www.milb.com/buffalo">Sahlen Field</a>, their home until the border with Canada reopens. Our stadium has increased the allowed capacity from 35% that day to 80% now, but our paper noted today that by month’s end it may be the only venue not allowing 100%. Will the return to large close-packed crowds be safe—will there be sufficient “herd immunity”—involves questions raised in two chapters of Ellenberg’s book. Here is a main idea—in my words, because I haven’t had time to actually <em>read</em> the book yet (and while writing this section, it seems I am having a primary role in another impending ban from the same overseas chess event).</p>
<blockquote><p><b> </b> <em> Often the most immediately valuable inferences are made from judging the shapes of curves rather than calculating numerical projections. </em>
</p></blockquote>
<p></p><p>
Here is an example composed from today’s new-cases charts of Florida and the UK from the <em>Worldometer</em> coronavirus <a href="https://www.worldometers.info/coronavirus/">pages</a>:</p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2021/06/20/the-shape-of-this-summer/floridaukcov2/" rel="attachment wp-att-18929"><img width="352" alt="" src="https://i1.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2021/06/FloridaUKCov2.png?resize=352%2C342&amp;ssl=1" class="aligncenter wp-image-18929" height="342" /></a></p>
<p>
The recent uptick in the UK is said to be caused by the new “delta” strain of the virus. I’ve chosen Florida rather than the whole US for similarity of scale and because Florida began a June upsurge this time a year ago. The US on the whole and most states show a similar fully-downward trend. Of course we hope it stays that way everywhere as the reopening phase continues. </p>
<p>
The point we are making is that if you just go by the numbers—and if you give highest weight to recent trends in those numbers—then your numerical projections can vary wildly. The logic of shape rather than number may be a more stable basis for judgment. This aligns with what we said about Ayanna Howard’s giving primacy to human rules of judgment in designs for robots in our <a href="https://rjlipton.wpcomstaging.com/2021/05/24/acm-athena-lecturer-award/">post</a> a month ago. </p>
<p>
</p><p></p><h2> A Caveat </h2><p></p>
<p></p><p>
There is, however, a caveat that falls in with the opening example of Ellenberg’s chapter 11, “The Terrible Law of Increase”:</p>
<blockquote><p><b> </b> <em> An early judgment based on a seemingly best-fitting shape has maximum potential to go wrong. </em>
</p></blockquote>
<p></p><p>
The example is an over-optimistic projection of Covid-19 cases and fatalities based on an initial expectation of a cubic curve fit. We neither wish to be academically impassive or blaming over the terrible toll which we have all had to endure, but to promote depth and wisdom in spatial thinking in line with the book’s purpose.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
How can we best get quick and accurate judgments of what is in store this summer and fall?</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wpcomstaging.com/2021/06/20/the-shape-of-this-summer/"><span class="datestr">at June 20, 2021 07:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
