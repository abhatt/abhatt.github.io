<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/27705661/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at April 15, 2020 08:22 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/045">TR20-045 |  Learning sums of powers of low-degree polynomials in the non-degenerate case | 

	Ankit Garg, 

	Neeraj Kayal, 

	Chandan Saha</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We develop algorithms for writing a polynomial as sums of powers of low degree polynomials. Consider an $n$-variate degree-$d$ polynomial $f$ which can be written as
$$f = c_1Q_1^{m} + \ldots + c_s Q_s^{m},$$
where each $c_i\in \mathbb{F}^{\times}$, $Q_i$ is a homogeneous polynomial of degree $t$, and $t m = d$. In this paper, we give a $\text{poly}((ns)^t)$-time learning algorithm for finding the $Q_i$'s given (black-box access to) $f$, if the $Q_i's$ satisfy certain non-degeneracy conditions and $n$ is larger than $d^2$. The set of degenerate $Q_i$'s (i.e., inputs for which the algorithm does not work) form a non-trivial variety and hence if the $Q_i$'s are chosen according to any reasonable (full-dimensional) distribution, then they are non-degenerate with high probability (if $s$ is not too large). This problem generalizes symmetric tensor decomposition, which corresponds to the $t = 1$ case and is widely studied, having many applications in machine learning. Our algorithm (for $t=2$) allows us to solve the moment problem for mixtures of zero-mean Gaussians in the non-degenerate case.

Our algorithm is based on a scheme for obtaining a learning algorithm for an arithmetic circuit model from a lower bound for the same model, provided certain non-degeneracy conditions hold. The scheme reduces the learning problem to the problem of decomposing two vector spaces under the action of a set of linear operators, where the spaces and the operators are derived from the input circuit and the complexity measure used in a typical lower bound proof. The non-degeneracy conditions are certain restrictions on how the spaces decompose. Such a scheme is present in a rudimentary form in an earlier work of Kayal and Saha. Here, we make it more general and detailed, and potentially applicable to learning other circuit models.

An exponential lower bound for the representation above (also known as homogeneous $\Sigma \wedge \Sigma \Pi^{[t]}$ circuits) is known using the shifted partials measure. However, the number of linear operators in shifted partials is exponential and also the non-degeneracy condition emerging out of this measure is unlikely to be satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit when the number of variables is large with respect to the degree. We bypass this hurdle by proving a lower bound (which is nearly as strong as the previous bound) using a novel variant of the partial derivatives measure, namely affine projections of partials (APP). The non-degeneracy conditions appearing from this new measure are satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit. The APP measure could be of independent interest for proving other lower bounds.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/045"><span class="datestr">at April 15, 2020 07:50 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4740">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4740">The quantum computer that knows all</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>This is my first post in more than a month that’s totally unrelated the covid crisis.  Or rather, it’s related only insofar as it’s about a Hulu miniseries, the sort of thing that many of us have more occasion to watch while holed up at home.</p>



<p>Three weeks ago, a journalist named Ben Lindbergh—who’d previously asked me to <a href="https://www.scottaaronson.com/blog/?p=4184">comment on the scientific accuracy of <em>Avengers: Endgame</em></a>—asked me the same question about the miniseries <a href="https://en.wikipedia.org/wiki/Devs_(miniseries)">Devs</a>, which I hadn’t previously heard of.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">[Warning: Spoilers follow]</span></strong></p>



<p>‘Devs,’ I learned, is a spooky sci-fi action thriller about a secretive Silicon Valley company that builds a quantum computer that can perfectly reconstruct the past, down to what Jesus looked like on the cross, and can also (at least up to a point) predict the future.</p>



<p>And I was supposed, not only to endure such a show, but to comment on the <em>accuracy</em> of its invocations of quantum computing?  This didn’t sound promising.</p>



<p>But, y’know, I was at home quarantined.  So I agreed to watch the first episode.  Which quickly turned into the second, third, fourth, fifth, sixth, and seventh episodes (the eighth and final one isn’t out yet).</p>



<p>It turns out that ‘Devs’ isn’t too bad, <em>except</em> that it’s not particularly about quantum computers.  The latter is simply a buzzword chosen by the writers for a plot concept that would’ve been entirely familiar to the ancient Greeks, who called it the Delphic Oracle.  You know, the mysterious entity that prophesies your fate, so then you try to escape the prophecy, but your very evasive maneuvers make the prophecy come true?  Picture that, except with qubits—and for some reason, in a gleaming golden laboratory that has components that float in midair.</p>



<figure class="wp-block-image"><img src="https://cdn1-www.comingsoon.net/assets/uploads/2020/01/Screen-Shot-2020-01-09-at-2.52.52-PM.png" alt="Devs Trailer Reveals New Look at FX-Hulu's Upcoming Limited Series" />If you’re never visited a real quantum computing lab: they’re messier and a lot less golden.</figure>



<p>At this point, I’ll just link you to Ben Lindbergh’s article about the show: <a href="https://www.theringer.com/tv/2020/4/10/21216149/devs-hulu-quantum-physics-philosophy-alex-garland">Making Sense of the Science and Philosophy of ‘Devs.’</a>  His long and excellent piece quotes me extensively enough that I see no need <em>also</em> to analyze the show in this blog post.  (It also quotes several academic philosophers.)</p>



<p>Instead, I’ll just share a few tidbits that Ben left out, but that might be amusing to quantum computing fans.</p>



<ul><li>The first episode opens with a conversation between two characters about how even “elliptical curve” cryptography is insecure against attack by quantum computers.  So I immediately knew <em>both</em> that the writers had one or more consultants who actually knew something about QC, and also that those consultants were not as heavily involved as they could’ve been.</li></ul>



<ul><li>Similarly: in a later scene, some employees at the secretive company hold what appears to be a reading group about Shor’s algorithm.  They talk about waves that interfere and cancel each other out, which is great, but beyond that their discussion sounded to me like nonsense.  In particularly, their idea seemed to be that the waves would reinforce at the prime factors p and q themselves, rather than at inverse multiples of the period of a periodic function that only indirectly encodes the factoring problem.  (What do you say: should we let this one slide?)</li></ul>



<ul><li>“How many qubits does this thing have?” “A number that there would be no point in describing as a number.”  ROFL</li></ul>



<ul><li>In the show, a crucial break comes when the employees abandon a prediction algorithm based on the deBroglie-Bohm pilot wave interpretation, and substitute one based on Everett’s many-worlds interpretation.  Which I could actually <em>almost</em> believe, except that the many-worlds interpretation seems to contradict the entire premise of the rest of the show?</li></ul>



<ul><li>A new employee, after he sees the code of the superpowerful quantum computer for the first time, is so disoriented and overwhelmed that he runs and vomits into a toilet.  I, too, have had that reaction to the claims of certain quantum computing companies, although in some sense for the opposite reason.</li></ul>



<p>Anyway, none of the above addresses the show’s central conceit: namely, that the <a href="https://en.wikipedia.org/wiki/Laplace%27s_demon">Laplace demon</a> can be made real, the past and future rendered fully knowable (with at most occasional breaks and exceptions) by a machine that’s feasible to build.  This conceit is fascinating to explore, but also <em>false</em>.</p>



<p>In the past, if you’d asked me to justify its falsity, I would’ve talked about chaos, and quantum mechanics, and the unknowability of the fine details of the universe’s state; I might’ve even pointed you to my <a href="https://arxiv.org/abs/1306.0159">Ghost in the Quantum Turing Machine</a> essay.  I also would’ve mentioned the severe conceptual difficulties in forcing Nature to find a fixed-point of a universe where you get to see your own future and act on that information (these difficulties are just a variant of the famous <a href="https://en.wikipedia.org/wiki/Grandfather_paradox">Grandfather Paradox</a>).</p>



<p>But it occurs to me that, just as the coronavirus has now made plain the nature of exponential growth, even to the world’s least abstract-minded person, so too it’s made plain the universe’s unpredictability.  Let’s put it this way: do you find it plausible that the quantum computer from ‘Devs,’ had you booted it up six months ago, would’ve known the exact state of every nucleotide in every virus in every bat in Wuhan?  No?  Then it wouldn’t have known our future.</p>



<p>And I see now that I’ve violated my promise that this post would have nothing to do with covid.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4740"><span class="datestr">at April 15, 2020 12:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06690">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06690">Online Graph Exploration on Trees, Unicyclic Graphs and Cactus Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Robin Fritsch <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06690">PDF</a><br /><b>Abstract: </b>We study the problem of exploring all vertices of an undirected weighted
graph that is initially unknown to the searcher. An edge of the graph is only
revealed when the searcher visits one of its endpoints. Beginning at some start
node, the searcher's goal is to visit every vertex of the graph before
returning to the start node on a tour as short as possible.
</p>
<p>We prove that the Nearest Neighbor algorithm's competitive ratio on trees
with $n$ vertices is $\Theta(\log n)$, i.e. no better than on general graphs.
This also yields a lower bound on the quality of the Nearest Neighbor heuristic
for the traveling salesperson problem on trees. Furthermore, we examine the
algorithm Blocking for a range of parameters not considered previously and
prove it is 3-competitive on unicyclic graphs as well as $5/2+\sqrt{2}\approx
3.91$-competitive on cactus graphs. The best-known lower bound for these two
graph classes is 2.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06690"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06620">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06620">Dichotomy for Graph Homomorphisms with Complex Values on Bounded Degree Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:Jin=Yi.html">Jin-Yi Cai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Govorov:Artem.html">Artem Govorov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06620">PDF</a><br /><b>Abstract: </b>The complexity of graph homomorphisms has been a subject of intense study
[11, 12, 4, 42, 21, 17, 6, 20]. The partition function $Z_{\mathbf A}(\cdot)$
of graph homomorphism is defined by a symmetric matrix $\mathbf A$ over
$\mathbb C$. We prove that the complexity dichotomy of [6] extends to bounded
degree graphs. More precisely, we prove that either $G \mapsto Z_{\mathbf
A}(G)$ is computable in polynomial-time for every $G$, or for some $\Delta &gt; 0$
it is #P-hard over (simple) graphs $G$ with maximum degree $\Delta(G) \le
\Delta$. The tractability criterion on $\mathbf A$ for this dichotomy is
explicit, and can be decided in polynomial-time in the size of $\mathbf A$. We
also show that the dichotomy is effective in that either a P-time algorithm
for, or a reduction from #SAT to, $Z_{\mathbf A}(\cdot)$ can be constructed
from $\mathbf A$, in the respective cases.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06620"><span class="datestr">at April 15, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06595">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06595">Counting Small Induced Subgraphs Satisfying Monotone Properties</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roth:Marc.html">Marc Roth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmitt:Johannes.html">Johannes Schmitt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wellnitz:Philip.html">Philip Wellnitz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06595">PDF</a><br /><b>Abstract: </b>Given a graph property $\Phi$, the problem $\#\mathsf{IndSub}(\Phi)$ asks, on
input a graph $G$ and a positive integer $k$, to compute the number of induced
subgraphs of size $k$ in $G$ that satisfy $\Phi$. The search for explicit
criteria on $\Phi$ ensuring that $\#\mathsf{IndSub}(\Phi)$ is hard was
initiated by Jerrum and Meeks [J. Comput. Syst. Sci. 15] and is part of the
major line of research on counting small patterns in graphs. However, apart
from an implicit result due to Curticapean, Dell and Marx [STOC 17] proving
that a full classification into "easy" and "hard" properties is possible and
some partial results on edge-monotone properties due to Meeks [Discret. Appl.
Math. 16] and D\"orfler et al. [MFCS 19], not much is known.
</p>
<p>In this work, we fully answer and explicitly classify the case of monotone,
that is subgraph-closed, properties: We show that for any non-trivial monotone
property $\Phi$, the problem $\#\mathsf{IndSub}(\Phi)$ cannot be solved in time
$f(k)\cdot |V(G)|^{o(k/ {\log^{1/2}(k)})}$ for any function $f$, unless the
Exponential Time Hypothesis fails. By this, we establish that any significant
improvement over the brute-force approach is unlikely; in the language of
parameterized complexity, we also obtain a $\#\mathsf{W}[1]$-completeness
result.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06595"><span class="datestr">at April 15, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06521">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06521">Quantum speedups of some general-purpose numerical optimisation algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Cezar-Mihail Alexandru, Ella Bridgett-Tomkinson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Linden:Noah.html">Noah Linden</a>, Joseph MacManus, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montanaro:Ashley.html">Ashley Montanaro</a>, Hannah Morris <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06521">PDF</a><br /><b>Abstract: </b>We give quantum speedups of several general-purpose numerical optimisation
methods for minimising a function $f:\mathbb{R}^n \to \mathbb{R}$. First, we
show that many techniques for global optimisation under a Lipschitz constraint
can be accelerated near-quadratically. Second, we show that backtracking line
search, an ingredient in quasi-Newton optimisation algorithms, can be
accelerated up to quadratically. Third, we show that a component of the
Nelder-Mead algorithm can be accelerated by up to a multiplicative factor of
$O(\sqrt{n})$. Fourth, we show that a quantum gradient computation algorithm of
Gily\'en et al. can be used to approximately compute gradients in the framework
of stochastic gradient descent. In each case, our results are based on applying
existing quantum algorithms to accelerate specific components of the classical
algorithms, rather than developing new quantum techniques.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06521"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06474">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06474">Two halves of a meaningful text are statistically different</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:Weibing.html">Weibing Deng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xie:R=.html">R. Xie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:S=.html">S. Deng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Allahverdyan:Armen_E=.html">Armen E. Allahverdyan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06474">PDF</a><br /><b>Abstract: </b>Which statistical features distinguish a meaningful text (possibly written in
an unknown system) from a meaningless set of symbols? Here we answer this
question by comparing features of the first half of a text to its second half.
This comparison can uncover hidden effects, because the halves have the same
values of many parameters (style, genre {\it etc}). We found that the first
half has more different words and more rare words than the second half. Also,
words in the first half are distributed less homogeneously over the text in the
sense of of the difference between the frequency and the inverse spatial
period. These differences hold for the significant majority of several hundred
relatively short texts we studied. The statistical significance is confirmed
via the Wilcoxon test. Differences disappear after random permutation of words
that destroys the linear structure of the text. The differences reveal a
temporal asymmetry in meaningful texts, which is confirmed by showing that
texts are much better compressible in their natural way (i.e. along the
narrative) than in the word-inverted form. We conjecture that these results
connect the semantic organization of a text (defined by the flow of its
narrative) to its statistical features.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06474"><span class="datestr">at April 15, 2020 01:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06455">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06455">Tensor Network Rewriting Strategies for Satisfiability and Counting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beaudrap:Niel_de.html">Niel de Beaudrap</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kissinger:Aleks.html">Aleks Kissinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meichanetzidis:Konstantinos.html">Konstantinos Meichanetzidis</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06455">PDF</a><br /><b>Abstract: </b>We provide a graphical treatment of SAT and \#SAT on equal footing. Instances
of \#SAT can be represented as tensor networks in a standard way. These tensor
networks are interpreted by diagrams of the ZH-calculus: a system to reason
about tensors over $\mathbb{C}$ in terms of diagrams built from simple
generators, in which computation may be carried out by \emph{transformations of
diagrams alone}. In general, nodes of ZH diagrams take parameters over
$\mathbb{C}$ which determine the tensor coefficients; for the standard
representation of \#SAT instances, the coefficients take the value $0$ or $1$.
Then, by choosing the coefficients of a diagram to range over $\mathbb B$, we
represent the corresponding instance of SAT. Thus, by interpreting a diagram
either over the boolean semiring or the complex numbers, we instantiate either
the \emph{decision} or \emph{counting} version of the problem. We find that for
classes known to be in P, such as $2$SAT and \#XORSAT, the existence of
appropriate rewrite rules allows for efficient simplification of the diagram,
producing the solution in polynomial time. In contrast, for classes known to be
NP-complete, such as $3$SAT, or \#P-complete, such as \#$2$SAT, the
corresponding rewrite rules introduce hyperedges to the diagrams, in numbers
which are not easily bounded above by a polynomial. This diagrammatic approach
unifies the diagnosis of the complexity of CSPs and \#CSPs and shows promise in
aiding tensor network contraction-based algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06455"><span class="datestr">at April 15, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06439">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06439">The quantum query complexity of composition with a relation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Belovs:Aleksandrs.html">Aleksandrs Belovs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Troy.html">Troy Lee</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06439">PDF</a><br /><b>Abstract: </b>The negative weight adversary method, $\mathrm{ADV}^\pm(g)$, is known to
characterize the bounded-error quantum query complexity of any Boolean function
$g$, and also obeys a perfect composition theorem $\mathrm{ADV}^\pm(f \circ
g^n) = \mathrm{ADV}^\pm(f) \mathrm{ADV}^\pm(g)$. Belovs gave a modified version
of the negative weight adversary method, $\mathrm{ADV}_{rel}^\pm(f)$, that
characterizes the bounded-error quantum query complexity of a relation $f
\subseteq \{0,1\}^n \times [K]$, provided the relation is efficiently
verifiable. A relation is efficiently verifiable if $\mathrm{ADV}^\pm(f_a) =
o(\mathrm{ADV}_{rel}^\pm(f))$ for every $a \in [K]$, where $f_a$ is the Boolean
function defined as $f_a(x) = 1$ if and only if $(x,a) \in f$. In this note we
show a perfect composition theorem for the composition of a relation $f$ with a
Boolean function $g$ \[ \mathrm{ADV}_{rel}^\pm(f \circ g^n) =
\mathrm{ADV}_{rel}^\pm(f) \mathrm{ADV}^\pm(g) \enspace . \] For an efficiently
verifiable relation $f$ this means $Q(f \circ g^n) = \Theta(
\mathrm{ADV}_{rel}^\pm(f) \mathrm{ADV}^\pm(g) )$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06439"><span class="datestr">at April 15, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06436">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06436">Round-Efficient Distributed Byzantine Computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hitron:Yael.html">Yael Hitron</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parter:Merav.html">Merav Parter</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06436">PDF</a><br /><b>Abstract: </b>We present the first round efficient algorithms for several fundamental
distributed tasks in the presence of a Byzantine edge. Our algorithms work in
the CONGEST model of distributed computing. In the \emph{Byzantine Broadcast}
problem, given is a network $G=(V,E)$ with an unknown Byzantine edge $e'$.
There is a source node $s$ holding an initial message $m_0$, and the goal is
for all the nodes in the network to receive a copy of $m_0$, while ignoring all
other messages. Perhaps surprisingly, to the best of our knowledge, all
existing algorithms for the problem either assume that the Byzantine behavior
is probabilistic, use polynomially large messages or else suffer from a large
round complexity.
</p>
<p>We give an $\widetilde{O}(D^2)$-round \footnote{The notion $\widetilde{O}$
hides poly-logarithmic terms, and the notion $\widehat{O}$ hides a
multiplicative factor of an $2^{O(\sqrt{\log n})}$ term.} algorithm for the
Byzantine Broadcast problem, where $D$ is the diameter of the graph. The
communication graph is required to be $3$-edge connected, which is known to be
a necessary condition. We also provide a Leader Election algorithm in the
presence of a Byzantine edge with the same round complexity of
$\widetilde{O}(D^2)$ rounds. We use these algorithms to provide the efficient
construction of \emph{Byzantine cycle covers} which serve the basis for (i)
Byzantine BFS algorithms and (ii) a general compiler for algorithms in the
presence of a Byzantine edge.
</p>
<p>We hope that the tools provided in this paper will pave the way towards
obtaining \textbf{round-efficient algorithms} for many more distributed
problems in the presence of Byzantine edges and nodes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06436"><span class="datestr">at April 15, 2020 01:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06367">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06367">Enumerating Chemical Graphs with Mono-block 2-Augmented Tree Structure from Given Upper and Lower Bounds on Path Frequencies</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Yuui Tamura, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nishiyama:Yuhei.html">Yuhei Nishiyama</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Chenxi.html">Chenxi Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Yanming.html">Yanming Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shurbevski:Aleksandar.html">Aleksandar Shurbevski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagamochi:Hiroshi.html">Hiroshi Nagamochi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Akutsu:Tatsuya.html">Tatsuya Akutsu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06367">PDF</a><br /><b>Abstract: </b>We consider a problem of enumerating chemical graphs from given constraints
concerning their structures, which has an important application to a novel
method for the inverse QSAR/QSPR recently proposed. In this paper, the
structure of a chemical graph is specified by a feature vector each of whose
entries represents the frequency of a prescribed path. We call a graph a
2-augmented tree if it is obtained from a tree (an acyclic graph) by adding
edges between two pairs of nonadjacent vertices. Given a set of feature vectors
as the interval between upper and lower bounds of feature vectors, we design an
efficient algorithm for enumerating chemical 2-augmented trees that satisfy the
path frequency specified by some feature vector in the set. We implemented the
proposed algorithm and conducted some computational experiments.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06367"><span class="datestr">at April 15, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06340">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06340">Hierarchical and Modularly-Minimal Vertex Colorings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valdivia:Dulce_I=.html">Dulce I. Valdivia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gei=szlig=:Manuela.html">Manuela Geiß</a>, Maribel Hernández Rosales, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stadler:Peter_F=.html">Peter F. Stadler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hellmuth:Marc.html">Marc Hellmuth</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06340">PDF</a><br /><b>Abstract: </b>Cographs are exactly the hereditarily well-colored graphs, i.e., the graphs
for which a greedy vertex coloring of every induced subgraph uses only the
minimally necessary number of colors $\chi(G)$. We show that greedy colorings
are a special case of the more general hierarchical vertex colorings, which
recently were introduced in phylogenetic combinatorics. Replacing cotrees by
modular decomposition trees generalizes the concept of hierarchical colorings
to arbitrary graphs. We show that every graph has a modularly-minimal coloring
$\sigma$ satisfying $|\sigma(M)|=\chi(M)$ for every strong module $M$ of $G$.
This, in particular, shows that modularly-minimal colorings provide a useful
device to design efficient coloring algorithms for certain hereditary graph
classes. For cographs, the hierarchical colorings coincide with the
modularly-minimal coloring. As a by-product, we obtain a simple linear-time
algorithm to compute a modularly-minimal coloring of $P_4$-sparse graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06340"><span class="datestr">at April 15, 2020 01:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06278">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06278">Squares: A Fast Counter-Based RNG</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Widynski:Bernard.html">Bernard Widynski</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06278">PDF</a><br /><b>Abstract: </b>In this article, we present a new counter-based random number generator (RNG)
based on John von Neumann's middle square. We've discovered that only three
rounds of squaring are sufficient to provide satisfactory random data. This
appears to be one of the fastest counter-based RNGs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06278"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06263">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06263">Coresets for Clustering in Euclidean Spaces: Importance Sampling is Nearly Optimal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Lingxiao.html">Lingxiao Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vishnoi:Nisheeth_K=.html">Nisheeth K. Vishnoi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06263">PDF</a><br /><b>Abstract: </b>Given a collection of $n$ points in $\mathbb{R}^d$, the goal of the
$(k,z)$-clustering problem is to find a subset of $k$ ``centers'' that
minimizes the sum of the $z$-th powers of the Euclidean distance of each point
to the closest center. Special cases of the $(k,z)$-clustering problem include
the $k$-median and $k$-means problems. Our main result is a unified two-stage
importance sampling framework that constructs an $\varepsilon$-coreset for the
$(k,z)$-clustering problem. Compared to the results for $(k,z)$-clustering in
[Feldman and Langberg, STOC 2011], our framework saves a $\varepsilon^2 d$
factor in the coreset size. Compared to the results for $(k,z)$-clustering in
[Sohler and Woodruff, FOCS 2018], our framework saves a
$\operatorname{poly}(k)$ factor in the coreset size and avoids the
$\exp(k/\varepsilon)$ term in the construction time. Specifically, our coreset
for $k$-median ($z=1$) has size $\tilde{O}(\varepsilon^{-4} k)$ which, when
compared to the result in [Sohler and Woodruff, STOC 2018], saves a $k$ factor
in the coreset size. Our algorithmic results rely on a new dimensionality
reduction technique that connects two well-known shape fitting problems:
subspace approximation and clustering, and may be of independent interest. We
also provide a size lower bound of $\Omega\left(k\cdot \min \left\{2^{z/20},d
\right\}\right)$ for a $0.01$-coreset for $(k,z)$-clustering, which has a
linear dependence of size on $k$ and an exponential dependence on $z$ that
matches our algorithmic results.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06263"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06167">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06167">Continuous Credit Networks and Layer 2 Blockchains: Monotonicity and Sampling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goel:Ashish.html">Ashish Goel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramseyer:Geoffrey.html">Geoffrey Ramseyer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06167">PDF</a><br /><b>Abstract: </b>To improve transaction rates, many cryptocurrencies have implemented
so-called ''Layer-2'' transaction protocols, where payments are routed across
networks of private payment channels. However, for a given transaction, not
every network state provides a feasible route to perform the payment; in this
case, the transaction must be put on the public ledger. The payment channel
network thus multiplies the transaction rate of the overall system; the less
frequently it fails, the higher the multiplier.
</p>
<p>We build on earlier work on credit networks and show that this network
liquidity problem is connected to the combinatorics of graphical matroids.
Earlier work could only analyze the (unnatural) scenario where transactions had
discrete sizes.
</p>
<p>Superficially, it might seem like the continuous case would be harder to
examine. However, removing this assumption lets us make progress in two
important directions. First, we give a partial answer to the ``monotonicity
conjecture'' that previous work left open. This conjecture asks that the
network's performance not degrade as capacity on any edge increases. And
second, we construct here a network state sampling procedure with much faster
asymptotic performance than off-the-shelf Markov chains ($O(\vert E\vert
\beta(\vert E\vert))$, where $\beta(x)$ is the complexity of solving a linear
program on $x$ constraints.)
</p>
<p>We obtain our results by mapping the underlying graphs to convex bodies and
then showing that the liquidity and sampling problems reduce to bounding and
computing the volumes of these bodies. The transformation relies crucially on
the combinatorial properties of the underlying graphic matroid, as do the
proofs of monotonicity and fast sampling.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06167"><span class="datestr">at April 15, 2020 01:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.06036">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.06036">Exact and Approximate Algorithms for Computing a Second Hamiltonian Cycle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deligkas:Argyrios.html">Argyrios Deligkas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mertzios:George_B=.html">George B. Mertzios</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spirakis:Paul_G=.html">Paul G. Spirakis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zamaraev:Viktor.html">Viktor Zamaraev</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.06036">PDF</a><br /><b>Abstract: </b>In this paper we consider the following total functional problem: Given a
cubic Hamiltonian graph $G$ and a Hamiltonian cycle $C_0$ of $G$, how can we
compute a second Hamiltonian cycle $C_1 \neq C_0$ of $G$? Cedric Smith proved
in 1946, using a non-constructive parity argument, that such a second
Hamiltonian cycle always exists. Our main result is an algorithm which computes
the second Hamiltonian cycle in time $O(n \cdot 2^{(0.3-\varepsilon)n})$ time,
for some positive constant $\varepsilon&gt;0$, and in polynomial space, thus
improving the state of the art running time for solving this problem. Our
algorithm is based on a fundamental structural property of Thomason's lollipop
algorithm, which we prove here for the first time. In the direction of
approximating the length of a second cycle in a Hamiltonian graph $G$ with a
given Hamiltonian cycle $C_0$ (where we may not have guarantees on the
existence of a second Hamiltonian cycle), we provide a linear-time algorithm
computing a second cycle with length at least $n - 4\alpha
(\sqrt{n}+2\alpha)+8$, where $\alpha = \frac{\Delta-2}{\delta-2}$ and
$\delta,\Delta$ are the minimum and the maximum degree of the graph,
respectively. This approximation result also improves the state of the art.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.06036"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05975">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05975">Adversarially Robust Streaming Algorithms via Differential Privacy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hassidim:Avinatan.html">Avinatan Hassidim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mansour:Yishay.html">Yishay Mansour</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matias:Yossi.html">Yossi Matias</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stemmer:Uri.html">Uri Stemmer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05975">PDF</a><br /><b>Abstract: </b>A streaming algorithm is said to be adversarially robust if its accuracy
guarantees are maintained even when the data stream is chosen maliciously, by
an adaptive adversary. We establish a connection between adversarial robustness
of streaming algorithms and the notion of differential privacy. This connection
allows us to design new adversarially robust streaming algorithms that
outperform the current state-of-the-art constructions for many interesting
regimes of parameters.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05975"><span class="datestr">at April 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05961">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05961">Non-clairvoyant Scheduling of Coflows</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhimaraju:Akhil.html">Akhil Bhimaraju</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayak:Debanuj.html">Debanuj Nayak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaze:Rahul.html">Rahul Vaze</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05961">PDF</a><br /><b>Abstract: </b>The coflow scheduling problem is considered: given an input/output switch
with each port having a fixed capacity, find a scheduling algorithm that
minimizes the weighted sum of the coflow completion times respecting the port
capacities, where each flow of a coflow has a demand per input/output port, and
coflow completion time is the finishing time of the last flow of the coflow.
The objective of this paper is to present theoretical guarantees on
approximating the sum of coflow completion time in the non-clairvoyant setting,
where on a coflow arrival, only the number of flows, and their input-output
port is revealed, while the critical demand volumes for each flow on the
respective input-output port is unknown. The main result of this paper is to
show that the proposed BlindFlow algorithm is $8p$-approximate, where $p$ is
the largest number of input-output port pairs that a coflow uses. This result
holds even in the online case, where coflows arrive over time and the scheduler
has to use only causal information. Simulations reveal that the experimental
performance of BlindFlow is far better than the theoretical guarantee.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05961"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05954">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05954">A General Framework for Approximating Min Sum Ordering Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Happach:Felix.html">Felix Happach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hellerstein:Lisa.html">Lisa Hellerstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lidbetter:Thomas.html">Thomas Lidbetter</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05954">PDF</a><br /><b>Abstract: </b>We consider a large family of problems in which an ordering of a finite set
must be chosen to minimize some weighted sum of costs. This family includes
variations of Min Sum Set Cover, several scheduling and search problems, and
problems in Boolean function evaluation. We define a new problem, called the
Min Sum Ordering Problem (MSOP) which generalizes all these problems using a
cost and a weight function on subsets of a finite set. Assuming a polynomial
time $\alpha$-approximation algorithm for the problem of finding a subset whose
ratio of weight to cost is maximal, we show that under very minimal
assumptions, there is a polynomial time $4 \alpha$-approximation algorithm for
MSOP. This approximation result generalizes a proof technique used for several
distinct problems in the literature. We apply our approximation result to
obtain a number of new approximation results.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05954"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05946">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05946">Reconstructing a Polyhedron between Polygons in Parallel Slices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Therese Biedl, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatovic:Pavle.html">Pavle Bulatovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Irvine:Veronika.html">Veronika Irvine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lubiw:Anna.html">Anna Lubiw</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Merkel:Owen.html">Owen Merkel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naredla:Anurag_Murty.html">Anurag Murty Naredla</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05946">PDF</a><br /><b>Abstract: </b>Given two $n$-vertex polygons, $P=(p_1, \ldots, p_n)$ lying in the $xy$-plane
at $z=0$, and $P'=(p'_1, \ldots, p'_n)$ lying in the $xy$-plane at $z=1$, a
banded surface is a triangulated surface homeomorphic to an annulus connecting
$P$ and $P'$ such that the triangulation's edge set contains vertex disjoint
paths $\pi_i$ connecting $p_i$ to $p'_i$ for all $i =1, \ldots, n$. The surface
then consists of bands, where the $i$th band goes between $\pi_i$ and
$\pi_{i+1}$. We give a polynomial-time algorithm to find a banded surface
without Steiner points if one exists. We explore connections between banded
surfaces and linear morphs, where time in the morph corresponds to the $z$
direction. In particular, we show that if $P$ and $P'$ are convex and the
linear morph from $P$ to $P'$ (which moves the $i$th vertex on a straight line
from $p_i$ to $p'_i$) remains planar at all times, then there is a banded
surface without Steiner points.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05946"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05942">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05942">Pentagon contact representations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Felsner:Stefan.html">Stefan Felsner</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schrezenmaier:Hendrik.html">Hendrik Schrezenmaier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Steiner:Raphael.html">Raphael Steiner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05942">PDF</a><br /><b>Abstract: </b>Representations of planar triangulations as contact graphs of a set of
internally disjoint homothetic triangles or of a set of internally disjoint
homothetic squares have received quite some attention in recent years. In this
paper we investigate representations of planar triangulations as contact graphs
of a set of internally disjoint homothetic pentagons. Surprisingly such a
representation exists for every triangulation whose outer face is a 5-gon. We
relate these representations to five color forests. These combinatorial
structures resemble Schnyder woods and transversal structures, respectively. In
particular there is a bijection to certain alpha-orientations and consequently
a lattice structure on the set of five color forests of a given graph. This
lattice structure plays a role in an algorithm that is supposed to compute a
contact representation with pentagons for a given graph. Based on a five color
forest the algorithm builds a system of linear equations and solves it, if the
solution is non-negative, it encodes distances between corners of a pentagon
representation. In this case the representation is constructed and the
algorithm terminates. Otherwise negative variables guide a change of the five
color forest and the procedure is restarted with the new five color forest.
Similar algorithms have been proposed for contact representations with
homothetic triangles and with squares.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05942"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05935">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05935">First Stretch then Shrink and Bulk: A Two Phase Approach for Enumeration of Maximal $(\Delta, \gamma)$\mbox{-}Cliques of a Temporal Network</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Suman.html">Suman Banerjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pal:Bithika.html">Bithika Pal</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05935">PDF</a><br /><b>Abstract: </b>A \emph{Temporal Network} (also known as \emph{Link Stream} or
\emph{Time-Varying Graph}) is often used to model a time-varying relationship
among a group of agents. It is typically represented as a collection of
triplets of the form $(u,v,t)$ that denotes the interaction between the agents
$u$ and $v$ at time $t$. For analyzing the contact patterns of the agents
forming a temporal network, recently the notion of classical \textit{clique} of
a \textit{static graph} has been generalized as \textit{$\Delta$\mbox{-}Clique}
of a Temporal Network. In the same direction, one of our previous studies
introduces the notion of \textit{$(\Delta, \gamma)$\mbox{-}Clique}, which is
basically a \textit{vertex set}, \textit{time interval} pair, in which every
pair of the clique vertices are linked at least $\gamma$ times in every
$\Delta$ duration of the time interval. In this paper, we propose a different
methodology for enumerating all the maximal $(\Delta, \gamma)$\mbox{-}Cliques
of a given temporal network. The proposed methodology is broadly divided into
two phases. In the first phase, each temporal link is processed for
constructing $(\Delta, \gamma)$\mbox{-}Clique(s) with maximum duration. In the
second phase, these initial cliques are expanded by vertex addition to form the
maximal cliques. From the experimentation carried out on $5$ real\mbox{-}world
temporal network datasets, we observe that the proposed methodology enumerates
all the maximal $(\Delta,\gamma)$\mbox{-}Cliques efficiently, particularly when
the dataset is sparse. As a special case ($\gamma=1$), the proposed methodology
is also able to enumerate $(\Delta,1) \equiv \Delta$\mbox{-}cliques with much
less time compared to the existing methods.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05935"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05883">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05883">A Simple Randomized $O(n \log n)$--Time Closest-Pair Algorithm in Doubling Metrics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maheshwari:Anil.html">Anil Maheshwari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a>, Michiel Smid <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05883">PDF</a><br /><b>Abstract: </b>Consider a metric space $(P,dist)$ with $N$ points whose doubling dimension
is a constant. We present a simple, randomized, and recursive algorithm that
computes, in $O(N \log N)$ expected time, the closest-pair distance in $P$. To
generate recursive calls, we use previous results of Har-Peled and Mendel, and
Abam and Har-Peled for computing a sparse annulus that separates the points in
a balanced way.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05883"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05875">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05875">Optimizing Reachability Sets in Temporal Graphs by Delaying</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deligkas:Argyrios.html">Argyrios Deligkas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Potapov:Igor.html">Igor Potapov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05875">PDF</a><br /><b>Abstract: </b>A temporal graph is a dynamic graph where every edge is assigned a set of
integer time labels that indicate at which discrete time step the edge is
available. In this paper, we study how changes of the time labels,
corresponding to delays on the availability of the edges, affect the
reachability sets from given sources. The questions about reachability sets are
motivated by numerous applications of temporal graphs in network epidemiology,
which aim to minimise the spread of infection, and scheduling problems in
supply networks in manufacturing with the opposite objectives of maximising
coverage and productivity. We introduce control mechanisms for reachability
sets that are based on two natural operations of delaying time events which
significantly affecting the chains of these events. The first operation, termed
merging, is global and batches together consecutive time labels in the whole
network simultaneously. This corresponds to postponing all events until a
particular time. The second, imposes independent delays on the time labels of
every edge of the graph.cWe provide a thorough investigation of the
computational complexity of different objectives related to reachability sets
when these operations are used. For the merging operation, i.e. global lockdown
effect, we prove NP-hardness results for several minimization and maximization
reachability objectives, even for very simple graph structures. For the second
operation, independent delays, we prove that the minimization problems are
NP-hard when the number of allowed delays is bounded. We complement this with a
polynomial-time algorithm for minimising the reachability set in case of
unbounded delays.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05875"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05813">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05813">Learning Mixtures of Spherical Gaussians via Fourier Analysis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Somnath.html">Somnath Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Narayanan:Hariharan.html">Hariharan Narayanan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05813">PDF</a><br /><b>Abstract: </b>Suppose that we are given independent, identically distributed samples $x_l$
from a mixture $\mu$ of no more than $k$ of $d$-dimensional spherical gaussian
distributions $\mu_i$ with variance $1$, such that the minimum $\ell_2$
distance between two distinct centers $y_l$ and $y_j$ is greater than $\sqrt{d}
\Delta$ for some $c \leq \Delta $, where $c\in (0,1)$ is a small positive
universal constant. We develop a randomized algorithm that learns the centers
$y_l$ of the gaussians, to within an $\ell_2$ distance of $\delta &lt;
\frac{\Delta\sqrt{d}}{2}$ and the weights $w_l$ to within $cw_{min}$ with
probability greater than $1 - \exp(-k/c)$. The number of samples and the
computational time is bounded above by $poly(k, d, \frac{1}{\delta})$. Such a
bound on the sample and computational complexity was previously unknown when
$\omega(1) \leq d \leq O(\log k)$. When $d = O(1)$, this follows from work of
Regev and Vijayaraghavan. These authors also show that the sample complexity of
learning a random mixture of gaussians in a ball of radius $\Theta(\sqrt{d})$
in $d$ dimensions, when $d$ is $\Theta( \log k)$ is at least $poly(k,
\frac{1}{\delta})$, showing that our result is tight in this case.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05813"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05738">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05738">Lower Bound for Succinct Range Minimum Query</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Mingmou.html">Mingmou Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05738">PDF</a><br /><b>Abstract: </b>Given an integer array $A[1..n]$, the Range Minimum Query problem (RMQ) asks
to preprocess $A$ into a data structure, supporting RMQ queries: given $a,b\in
[1,n]$, return the index $i\in[a,b]$ that minimizes $A[i]$, i.e.,
$\mathrm{argmin}_{i\in[a,b]} A[i]$. This problem has a classic solution using
$O(n)$ space and $O(1)$ query time by Gabow, Bentley, Tarjan (STOC, 1984) and
Harel, Tarjan (SICOMP, 1984). The best known data structure by Fischer, Heun
(SICOMP, 2011) and Navarro, Sadakane (TALG, 2014) uses $2n+n/(\frac{\log
n}{t})^t+\tilde{O}(n^{3/4})$ bits and answers queries in $O(t)$ time, assuming
the word-size is $w=\Theta(\log n)$. In particular, it uses
$2n+n/\mathrm{poly}\log n$ bits of space as long as the query time is a
constant.
</p>
<p>In this paper, we prove the first lower bound for this problem, showing that
$2n+n/\mathrm{poly}\log n$ space is necessary for constant query time. In
general, we show that if the data structure has query time $O(t)$, then it must
use at least $2n+n/(\log n)^{\tilde{O}(t^2)}$ space, in the cell-probe model
with word-size $w=\Theta(\log n)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05738"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05721">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05721">A Fast Algorithm for Source-Wise Round-Trip Spanners</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Chun_Jiang.html">Chun Jiang Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Han:Song.html">Song Han</a>, Kam-Yiu Lam <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05721">PDF</a><br /><b>Abstract: </b>In this paper, we study the problem of efficiently constructing source-wise
round-trip spanners in weighted directed graphs. For a source vertex set
$S\subseteq V$ in a digraph $G(V,E)$, an $S$-source-wise round-trip spanner of
$G$ of stretch $k$ is a subgraph $H$ of $G$ such that for every $u\in S,v\in
V$, the round-trip distance between $u$ and $v$ in $H$ is at most $k$ times of
the original distance in $G$. We show that, for a digraph $G(V,E)$ with $n$
vertices, $m$ edges and nonnegative edge weights, an $s$-sized source vertex
set $S\subseteq V$ and a positive integer $k$, there exists an algorithm, in
time $O(ms^{1/k}\log^5n)$, with high probability constructing an
$S$-source-wise round-trip spanner of stretch $O(k\log n)$ and size
$O(ns^{1/k}\log^2n)$. Compared with the state of the art for constructing
source-wise round-trip spanners, our algorithm significantly improves their
construction time $\Omega(\min\{ms,n^\omega\})$ (where $\omega \in [2,2.373)$
and 2.373 is the matrix multiplication exponent) to nearly linear
$O(ms^{1/k}\log^5n)$, while still keeping a spanner stretch $O(k\log n)$ and
size $O(ns^{1/k}\log^2n)$, asymptotically similar to their stretch
$2k+\epsilon$ and size $O((k^2/\epsilon)ns^{1/k}\log(nw))$, respectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05721"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05692">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05692">Measuring spatial uniformity with the hypersphere chord length distribution</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidiropoulos:Panagiotis.html">Panagiotis Sidiropoulos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05692">PDF</a><br /><b>Abstract: </b>Data uniformity is a concept associated with several semantic data
characteristics such as lack of features, correlation and sample bias. This
article introduces a novel measure to assess data uniformity and detect uniform
pointsets on high-dimensional Euclidean spaces. Spatial uniformity measure
builds upon the isomorphism between hyperspherical chords and L2-normalised
data Euclidean distances, which is implied by the fact that, in Euclidean
spaces, L2-normalised data can be geometrically defined as points on a
hypersphere. The imposed connection between the distance distribution of
uniformly selected points and the hyperspherical chord length distribution is
employed to quantify uniformity. More specifically,, the closed-form expression
of hypersphere chord length distribution is revisited extended, before
examining a few qualitative and quantitative characteristics of this
distribution that can be rather straightforwardly linked to data uniformity.
The experimental section includes validation in four distinct setups, thus
substantiating the potential of the new uniformity measure on practical
data-science applications.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05692"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05672">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05672">Linear-time Algorithms for Eliminating Claws in Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonomo=Braberman:Flavia.html">Flavia Bonomo-Braberman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nascimento:Julliano_R=.html">Julliano R. Nascimento</a>, Fabiano S. Oliveira, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Souza:U=eacute=verton_S=.html">Uéverton S. Souza</a>, Jayme L. Szwarcfiter <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05672">PDF</a><br /><b>Abstract: </b>Since many NP-complete graph problems have been shown polynomial-time
solvable when restricted to claw-free graphs, we study the problem of
determining the distance of a given graph to a claw-free graph, considering
vertex elimination as measure. CLAW-FREE VERTEX DELETION (CFVD) consists of
determining the minimum number of vertices to be removed from a graph such that
the resulting graph is claw-free. Although CFVD is NP-complete in general and
recognizing claw-free graphs is still a challenge, where the current best
algorithm for a graph $G$ has the same running time of the best algorithm for
matrix multiplication, we present linear-time algorithms for CFVD on weighted
block graphs and weighted graphs with bounded treewidth. Furthermore, we show
that this problem can be solved in linear time by a simpler algorithm on
forests, and we determine the exact values for full $k$-ary trees. On the other
hand, we show that CLAW-FREE VERTEX DELETION is NP-complete even when the input
graph is a split graph. We also show that the problem is hard to approximate
within any constant factor better than $2$, assuming the Unique Games
Conjecture.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05672"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05548">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05548">Multiparty Selection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Ke.html">Ke Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dumitrescu:Adrian.html">Adrian Dumitrescu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05548">PDF</a><br /><b>Abstract: </b>Given a sequence $A$ of $n$ numbers and an integer (target) parameter $1\leq
i\leq n$, the (exact) selection problem asks to find the $i$-th smallest
element in $A$. An element is said to be $(i,j)$-mediocre if it is neither
among the top $i$ nor among the bottom $j$ elements of $S$. The approximate
selection problem asks to find a $(i,j)$-mediocre element for some given $i,j$;
as such, this variant allows the algorithm to return any element in a
prescribed range. In the first part, we revisit the selection problem in the
two-party model introduced by Andrew Yao (1979) and then extend our study of
exact selection to the multiparty model. In the second part, we deduce some
communication complexity benefits that arise in approximate selection.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05548"><span class="datestr">at April 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05494">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05494">Submodular Clustering in Low Dimensions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Backurs:Arturs.html">Arturs Backurs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Har=Peled:Sariel.html">Sariel Har-Peled</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05494">PDF</a><br /><b>Abstract: </b>We study a clustering problem where the goal is to maximize the coverage of
the input points by $k$ chosen centers. Specifically, given a set of $n$ points
$P \subseteq \mathbb{R}^d$, the goal is to pick $k$ centers $C \subseteq
\mathbb{R}^d$ that maximize the service $ \sum_{p \in P}\mathsf{\varphi}\bigl(
\mathsf{d}(p,C) \bigr) $ to the points $P$, where $\mathsf{d}(p,C)$ is the
distance of $p$ to its nearest center in $C$, and $\mathsf{\varphi}$ is a
non-increasing service function $\mathsf{\varphi} : \mathbb{R}^+ \to
\mathbb{R}^+$. This includes problems of placing $k$ base stations as to
maximize the total bandwidth to the clients -- indeed, the closer the client is
to its nearest base station, the more data it can send/receive, and the target
is to place $k$ base stations so that the total bandwidth is maximized. We
provide an $n^{\varepsilon^{-O(d)}}$ time algorithm for this problem that
achieves a $(1-\varepsilon)$-approximation. Notably, the runtime does not
depend on the parameter $k$ and it works for an arbitrary non-increasing
service function $\mathsf{\varphi} : \mathbb{R}^+ \to \mathbb{R}^+$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05494"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05429">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05429">Construction and Random Generation of Hypergraphs with Prescribed Degree and Dimension Sequences</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arafat:Naheed_Anjum.html">Naheed Anjum Arafat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basu:Debabrota.html">Debabrota Basu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Decreusefond:Laurent.html">Laurent Decreusefond</a>, Stephane Bressan <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05429">PDF</a><br /><b>Abstract: </b>We propose algorithms for construction and random generation of hypergraphs
without loops and with prescribed degree and dimension sequences. The objective
is to provide a starting point for as well as an alternative to Markov chain
Monte Carlo approaches. Our algorithms leverage the transposition of properties
and algorithms devised for matrices constituted of zeros and ones with
prescribed row- and column-sums to hypergraphs. The construction algorithm
extends the applicability of Markov chain Monte Carlo approaches when the
initial hypergraph is not provided. The random generation algorithm allows the
development of a self-normalised importance sampling estimator for hypergraph
properties such as the average clustering coefficient.We prove the correctness
of the proposed algorithms. We also prove that the random generation algorithm
generates any hypergraph following the prescribed degree and dimension
sequences with a non-zero probability. We empirically and comparatively
evaluate the effectiveness and efficiency of the random generation algorithm.
Experiments show that the random generation algorithm provides stable and
accurate estimates of average clustering coefficient, and also demonstrates a
better effective sample size in comparison with the Markov chain Monte Carlo
approaches.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05429"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05345">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05345">Locality-Sensitive Hashing Scheme based on Longest Circular Co-Substring</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lei:Yifan.html">Yifan Lei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Qiang.html">Qiang Huang</a>, Mohan Kankanhalli, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tung:Anthony_K=_H=.html">Anthony K. H. Tung</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05345">PDF</a><br /><b>Abstract: </b>Locality-Sensitive Hashing (LSH) is one of the most popular methods for
$c$-Approximate Nearest Neighbor Search ($c$-ANNS) in high-dimensional spaces.
In this paper, we propose a novel LSH scheme based on the Longest Circular
Co-Substring (LCCS) search framework (LCCS-LSH) with a theoretical guarantee.
We introduce a novel concept of LCCS and a new data structure named Circular
Shift Array (CSA) for $k$-LCCS search. The insight of LCCS search framework is
that close data objects will have a longer LCCS than the far-apart ones with
high probability. LCCS-LSH is \emph{LSH-family-independent}, and it supports
$c$-ANNS with different kinds of distance metrics. We also introduce a
multi-probe version of LCCS-LSH and conduct extensive experiments over five
real-life datasets. The experimental results demonstrate that LCCS-LSH
outperforms state-of-the-art LSH schemes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05345"><span class="datestr">at April 15, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05309">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05309">Grammar-compressed Self-index with Lyndon Words</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsuruta:Kazuya.html">Kazuya Tsuruta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=ouml=ppl:Dominik.html">Dominik Köppl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Yuto.html">Yuto Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannai:Hideo.html">Hideo Bannai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Takeda:Masayuki.html">Masayuki Takeda</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05309">PDF</a><br /><b>Abstract: </b>We introduce a new class of straight-line programs (SLPs), named the Lyndon
SLP, inspired by the Lyndon trees (Barcelo, 1990). Based on this SLP, we
propose a self-index data structure of $O(g)$ words of space that can be built
from a string $T$ in $O(n + g \lg g)$ time, retrieving the starting positions
of all occurrences of a pattern $P$ of length $m$ in $O(m + \lg m \lg n + occ
\lg g)$ time, where $n$ is the length of $T$, $g$ is the size of the Lyndon SLP
for $T$, and $occ$ is the number of occurrences of $P$ in $T$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05309"><span class="datestr">at April 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16931">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/">John Horton Conway 1937–2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>An appreciation</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg"><img width="192" alt="" src="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg?w=192&amp;h=240" class="alignright wp-image-16933" height="240" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Names for large numbers <a href="https://sites.google.com/site/largenumbers/home/2-4/6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Horton Conway just passed away from complications of COVID-19. We are all saddened by this news, and we hope you all are doing your best to stay safe and help others cope.</p>
<p>
Today Ken and I thought we would reflect on some of Conway’s many contributions and emphasize three in which we see connections to computational complexity. </p>
<p>
Conway was a Fellow of the Royal Society, and was the first recipient of the London Mathematical Society’s Pólya Prize. His nomination to the Royal Society reads:</p>
<blockquote><p><b> </b> <em> A versatile mathematician who combines a deep combinatorial insight with algebraic virtuosity, particularly in the construction and manipulation of “off-beat” algebraic structures which illuminate a wide variety of problems in completely unexpected ways. He has made distinguished contributions to the theory of finite groups, to the theory of knots, to mathematical logic (both set theory and automata theory) and to the theory of games (as also to its practice). </em>
</p></blockquote>
<p>
</p><p></p><h2> A Life Force </h2><p></p>
<p></p><p>
Conway may be most noted for his game of <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Life</a>. This is a two-dimensional cellular automaton. Conway invented it in 1970, which he rounded up from 1969. The game—and Martin Gardner’s 1970 column on it in <em>Scientific American</em>—made him famous in the wider community. The website <a href="https://www.conwaylife.com/">conwaylife.com</a> and <a href="https://catagolue.appspot.com/home">several</a> <a href="https://tebs-game-of-life.com/">others</a> link to more information than we could digest in a lifetime.</p>
<p>
We want to emphasize instead how Conway was a special force in mathematics. He applied an almost elementary approach to deep hard problems of mathematics. This is a unique combination. There have been mathematicians who worked on deep problems and also on recreational math, but few who established integral flows across the boundary between them. Conway infused both with magic in a way conveyed by an iconic photograph of his Princeton office in 1993:</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg"><img width="450" alt="" src="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg?w=450&amp;h=270" class="aligncenter wp-image-16934" height="270" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><i>Guardian<i> via Dith Pran, <i>NY Times</i> <a href="https://www.theguardian.com/science/2015/jul/23/john-horton-conway-the-most-charismatic-mathematician-in-the-world">source</a> </i></i></font>
</td>
</tr>
</tbody></table>
<p>
What Ken remembers is how accessible Conway was <em>outside</em> his office. “I know I met him at least once while I was an undergraduate at Princeton in 1979 or 1980, though this is overlaid by a memory of finding just him and a few others in the Fine Hall tea room when I was there for my tenth reunion in 1991. My most evocative memory is when Conway gave an evening talk to the undergraduate mathematics club at Oxford when I was there sometime after 1981. It was relatively sparsely attended, perhaps because it was literally a dark and stormy winter night. But after his lecture we all got to huddle around him for another hour in the tea room as he regaled us with stories and mathematical problems.” </p>
<p>
We also remember that Conway was one of Andrew Wiles’s main confidants during the months before Wiles announced his proof of Fermat’s Last Theorem in June 1993. Here is a <a href="https://www.pbs.org/wgbh/nova/transcripts/2414proof.html">transcript</a> of a PBS Nova documentary on the proof in which Conway appears prominently. Ken has picked out two of Conway’s other contributions that we feel may have untapped use for research in complexity theory.</p>
<p>
</p><p></p><h2> Conway’s Numbers </h2><p></p>
<p></p><p>
One of this blog’s “invariants” is first-name last-name style, thus “Godfrey Hardy” not “G.H. Hardy.” But we make an exception in Conway’s case. Partly this owes to how his initials were amplified by Donald Knuth in his novella <em>Surreal Numbers</em>:</p>
<blockquote><p><b> </b> <em> In the beginning, everything was void, and J.H.W.H. Conway began to create numbers. </em>
</p></blockquote>
<p></p><p>
Besides the void (that is, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset}" class="latex" title="{\emptyset}" />), the creation uses the idea of a <em>left set</em> <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and a <em>right set</em> <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. Every number has the form <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L~|~R \rangle}" class="latex" title="{\langle L~|~R \rangle}" />. The initial number is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. " class="latex" title="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. " /></p>
<p>
Once a number is generated, it can be in the <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> of other numbers. Thus, next come </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Clangle+0+%7E%7C%7E+%5Cemptyset+%5Crangle+%26%3D%26+1%5C%5C+%5Clangle+%5Cemptyset+%7E%7C%7E+0+%5Crangle+%26%3D%26+-1.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} " /></p>
<p>
You might think of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle 0 ~|~ 0 \rangle}" class="latex" title="{\langle 0 ~|~ 0 \rangle}" /> next, but it violates the invariant </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cforall+%5Cell+%5Cin+L%29%28%5Cforall+r+%5Cin+R%29%5Cneg+%28r+%5Cleq+%5Cell%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). " class="latex" title="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). " /></p>
<p>which defines an <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L~|~R \rangle}" class="latex" title="{\langle L~|~R \rangle}" /> <em>form</em> to be a <em>number</em>. </p>
<p>
The relation <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\leq}" class="latex" title="{\leq}" /> is inductively defined for <img src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+%5Clangle+L_a+%7E%7C%7E+R_a+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a = \langle L_a ~|~ R_a \rangle}" class="latex" title="{a = \langle L_a ~|~ R_a \rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb+%3D+%5Clangle+L_b+%7E%7C%7E+R_b+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b = \langle L_b ~|~ R_b \rangle}" class="latex" title="{b = \langle L_b ~|~ R_b \rangle}" /> by </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Cleq+b+%5Cquad%5Cequiv%5Cquad+%28%5Cforall+%5Cell_a+%5Cin+L_a%29%28%5Cforall+r_b+%5Cin+R_b%29%5Cneg%28b+%5Cleq+%5Cell_a+%5C%3B%5Clor%5C%3B+r_b+%5Cleq+a%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). " class="latex" title="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). " /></p>
<p>
That is, no member of the left-set of <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> “bumps” <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> (in the sense of rowing races) and <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> does not bump any member of the right-set of <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />.  Note that <img src="https://s0.wp.com/latex.php?latex=%7BR_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R_a}" class="latex" title="{R_a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BL_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_b}" class="latex" title="{L_b}" /> are not involved—they already behave correctly owing to the invariant. The numbers <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b}" class="latex" title="{a,b}" /> are equal if <img src="https://s0.wp.com/latex.php?latex=%7Ba+%5Cleq+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a \leq b}" class="latex" title="{a \leq b}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb+%5Cleq+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b \leq a}" class="latex" title="{b \leq a}" /> both hold. The rule for addition is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%2B+b+%3D+%5Clangle+%28L_a+%5Cboxplus+b%29+%5Ccup+%28a+%5Cboxplus+L_b%29+%7E%7C%7E+%28a+%5Cboxplus+R_b%29+%5Ccup+%28R_a+%5Cboxplus+b%29+%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, " class="latex" title="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, " /></p>
<p>
where <img src="https://s0.wp.com/latex.php?latex=%7BL_a+%5Cboxplus+b+%3D+%5C%7B%5Cell_a+%2B+b%3A+%5Cell_a+%5Cin+L_a%5C%7D+%3D+b+%5Cboxplus+L_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}" class="latex" title="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}" /> and so on. The logical rule <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset+%5Cboxplus+a+%3D+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset \boxplus a = \emptyset}" class="latex" title="{\emptyset \boxplus a = \emptyset}" /> for any <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> makes the definition of addition well-founded. This yields the numerical fact </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%2B+0+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%7E%7C%7E+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%5Crangle+%3D+%5Clangle%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. " class="latex" title="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. " /></p>
<p>
It is immediate that <img src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+}" class="latex" title="{+}" /> is commutative. There is also a rule for multiplication but addition gives us enough to talk about here.</p>
<p>
</p><p></p><h2> Redundancy and Simplicity </h2><p></p>
<p></p><p>
It is straightforward to compute that <img src="https://s0.wp.com/latex.php?latex=%7B0+%2B+1+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 + 1 = 1}" class="latex" title="{0 + 1 = 1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B-1+%2B+0+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1 + 0 = -1}" class="latex" title="{-1 + 0 = -1}" />. Now consider: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++-1+%2B+1+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+1%29+%5Ccup+%28-1+%5Cboxplus+%5C%7B0%5C%7D%29+%7E%7C%7E+%28-1+%5Cboxplus+%5Cemptyset+%29+%5Ccup+%28%5C%7B0%5C%7D+%5Cboxplus+1%29%5Crangle+%3D+%5Clangle+-1+%7E%7C%7E+1%5Crangle.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. " class="latex" title="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. " /></p>
<p>This is a legal number. You can check that the relations <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle -1 ~|~ 1\rangle \leq 0}" class="latex" title="{\langle -1 ~|~ 1\rangle \leq 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 \leq \langle -1 ~|~ 1\rangle}" class="latex" title="{0 \leq \langle -1 ~|~ 1\rangle}" /> both hold. Thus—as a number rather than a “form”—the number <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle -1 ~|~ 1\rangle}" class="latex" title="{\langle -1 ~|~ 1\rangle}" /> equals <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />. </p>
<p>
That seems to make sense since <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> is the average of <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, but now compute <img src="https://s0.wp.com/latex.php?latex=%7B2+%3D+1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2 = 1 + 1}" class="latex" title="{2 = 1 + 1}" /> as a formal Conway number and consider <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3D+%5Clangle+-1+%7E%7C%7E+2%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c = \langle -1 ~|~ 2\rangle}" class="latex" title="{c = \langle -1 ~|~ 2\rangle}" />. This also satisfies the relations <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c \leq 0}" class="latex" title="{c \leq 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 \leq c}" class="latex" title="{0 \leq c}" />, so <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> must likewise equal <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />. Thus <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L ~|~ R \rangle}" class="latex" title="{\langle L ~|~ R \rangle}" /> is not some kind of numerical interpolation between <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. The interpretation that grabbed my imagination as a teenager in 1976 is that:</p>
<blockquote><p><b> </b> <em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\langle L ~|~ R \rangle}" class="latex" title="{\langle L ~|~ R \rangle}" /> equals the <b>simplest</b> number that is between <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. </em>
</p></blockquote>
<p></p><p>
This is especially evocative in cases like <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+1+%7E%7C%7E+%5Cemptyset+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle 1 ~|~ \emptyset \rangle}" class="latex" title="{\langle 1 ~|~ \emptyset \rangle}" />, which is what one gets by computing <img src="https://s0.wp.com/latex.php?latex=%7B1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 + 1}" class="latex" title="{1 + 1}" />. In general, <img src="https://s0.wp.com/latex.php?latex=%7Bm%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m+1}" class="latex" title="{m+1}" /> is the simplest number between <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset}" class="latex" title="{\emptyset}" />. Conway made this a theorem by giving each number a set-theoretic ordinal for its “time of generation” and proved that <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L ~|~ R \rangle}" class="latex" title="{\langle L ~|~ R \rangle}" /> always equals a (the) least-ordinal number <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cleq+c+%5Cleq+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell \leq c \leq r}" class="latex" title="{\ell \leq c \leq r}" /> for every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cin+L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell \in L}" class="latex" title="{\ell \in L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \in R}" class="latex" title="{r \in R}" />. </p>
<p>
Conway’s rules allow <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> to be infinite sets—any sets of numbers built by the rules of set theory. Then not only do all real numbers emerge at ordinal times, so do infinitesimals and further richness of structure. We should remember that Conway began as a set theorist with a dissertation under Harold Davenport titled <em>Homogeneous ordered sets</em>. All Conway numbers with finite creation times are dyadic rational numbers, which may seem trivial from the standpoint of set theory, but those are akin to binary strings. </p>
<p>
What became magic was how Conway’s rules characterize <em>games</em>. Through games we can also interpret forms like <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle 0 ~|~ 0 \rangle}" class="latex" title="{\langle 0 ~|~ 0 \rangle}" /> that are not numbers. I did not know about complexity when I purchased Conway’s <a href="https://en.wikipedia.org/wiki/On_Numbers_and_Games">book</a> <em>On Numbers and Games</em> around 1980, let alone the connections between games and complexity. The book has a lot of depth that might be useful to complexity theory. To quote Peter Sarnak, per this <a href="https://www.ias.edu/ideas/2015/roberts-john-horton-conway">article</a> by Conway’s biographer Siobhan Roberts on Conway’s meeting with Kurt Gödel:</p>
<blockquote><p><b> </b> <em> The surreal numbers will be applied. It’s just a question of how and when. </em>
</p></blockquote>
<p>
</p><p>
</p><p>
</p><p></p><h2> Modular Programming </h2><p></p>
<p></p><p>
Most of us know that the conditional-jump instruction</p>
<p>
<font size="+1"><tt><b><br />
if (x == 0) goto k<br />
</b></tt></font></p>
<p></p><p><br />
where <tt><b>k</b></tt> is the label of another instruction, creates a universal programming language when added to the usual programming primitives of assignment, sequencing, and simple arithmetic. Conway was a maven of the “modular-jump”:</p>
<p>
<font size="+1"><tt><b><br />
if (x == 0 mod m) goto k.<br />
</b></tt></font></p>
<p></p><p><br />
In complexity theory we know that mod-<img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> gates having 0-1 inputs define the idea of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}}" class="latex" title="{\mathsf{ACC}}" /> circuits, with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}^0}" class="latex" title="{\mathsf{ACC}^0}" /> denoting problems solved by families of these circuits having fixed depth and polynomial size. If we don’t insist on fixed depth and unary inputs, we get modular programs. They are more complex than <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}^0}" class="latex" title="{\mathsf{ACC}^0}" /> circuits, but we can learn from what can be done <em>concretely</em> with them.</p>
<p>
Conway created a particular form of modular programs in a language he called <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4808-8_2">FRACTRAN</a>. A program is just a list of positive fractions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Ba_r%7D%7Bb_r%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{a_r}{b_r}}" class="latex" title="{\frac{a_r}{b_r}}" /> in lowest terms. The input is an integer <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> held in a separate register. Each fraction represents the code line</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7Bif+%7D+%28n%2Aa_r+%5Cequiv+0+%5Cpmod%7Bb_r%7D%29+%5C%7B+n+%3D+n%5Cfrac%7Ba_r%7D%7Bb_r%7D%3B+%5Ctext%7Bgoto+start%7D+%5C%7D%3B+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; " class="latex" title="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; " /></p>
<p>
In other words, each iteration takes the first fraction <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{nf}" class="latex" title="{nf}" /> is an integer and updates <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{nf}" class="latex" title="{nf}" />; if there is no such fraction then the program exits and outputs <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />.</p>
<p>
For example, the following FRACTRAN program given in Wikipedia’s <a href="https://en.wikipedia.org/wiki/FRACTRAN">article</a> implicitly computes integer division: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B91%7D%7B66%7D%2C%7E%5Cfrac%7B11%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B33%7D%2C%7E%5Cfrac%7B85%7D%7B11%7D%2C%7E%5Cfrac%7B57%7D%7B119%7D%2C%7E%5Cfrac%7B17%7D%7B19%7D%2C%7E%5Cfrac%7B11%7D%7B17%7D%2C%7E%5Cfrac%7B1%7D%7B3%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. " class="latex" title="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. " /></p>
<p>The notation is unary: The input <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> has the form <img src="https://s0.wp.com/latex.php?latex=%7B2%5En+3%5Ed+11%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n 3^d 11}" class="latex" title="{2^n 3^d 11}" /> and the ouput is <img src="https://s0.wp.com/latex.php?latex=%7B5%5Eq+7%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5^q 7^r}" class="latex" title="{5^q 7^r}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+qd+%2B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = qd + r}" class="latex" title="{n = qd + r}" /> with remainder <img src="https://s0.wp.com/latex.php?latex=%7Br+%3C+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r &lt; d}" class="latex" title="{r &lt; d}" />. This already hints the fact that FRACTRAN is a universal programming language. Powers of primes serve as memory registers. The following program computes the Hamming weight <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> of the binary expansion of a natural number <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> encoded as <img src="https://s0.wp.com/latex.php?latex=%7B2%5Ex%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^x}" class="latex" title="{2^x}" />, returning the value <img src="https://s0.wp.com/latex.php?latex=%7B13%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{13^k}" class="latex" title="{13^k}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B33%7D%7B20%7D%2C%7E%5Cfrac%7B5%7D%7B11%7D%2C%7E%5Cfrac%7B13%7D%7B10%7D%2C%7E%5Cfrac%7B1%7D%7B5%7D%2C%7E%5Cfrac%7B2%7D%7B3%7D%2C%7E%5Cfrac%7B10%7D%7B7%7D%2C%7E%5Cfrac%7B7%7D%7B2%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. " class="latex" title="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. " /></p>
<p>This might help bridge to our notions of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}}" class="latex" title="{\mathsf{ACC}}" />. The Wikipedia article does a good job of de-mystifying the fractions in terms of their actions on the prime-power registers under the unary-style encoding. We wonder what happens when we try to work directly with binary encodings. </p>
<p>
</p><p></p><h2> The Collatz Example </h2><p></p>
<p></p><p>
The famous “<img src="https://s0.wp.com/latex.php?latex=%7B3n%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3n+1}" class="latex" title="{3n+1}" />” problem of Lothar Collatz is a case in point. It iterates the function </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++T%28n%29+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B3n%2B1%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+odd%7D+%5C%5C+%5Cfrac%7Bn%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+even%7D+%5Cend%7Bcases%7D++&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  " class="latex" title="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  " /></p>
<p>The following FRACTRAN program <a href="https://hal.inria.fr/hal-00958971/document">given</a> by Kenneth Monks iterates <img src="https://s0.wp.com/latex.php?latex=%7BT%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T(n)}" class="latex" title="{T(n)}" /> under the unary encoding <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n}" class="latex" title="{2^n}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B1%7D%7B11%7D%2C%7E%5Cfrac%7B136%7D%7B15%7D%2C%7E%5Cfrac%7B5%7D%7B17%7D%2C%7E%5Cfrac%7B4%7D%7B5%7D%2C%7E%5Cfrac%7B26%7D%7B21%7D%2C%7E%5Cfrac%7B7%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B7%7D%2C%7E%5Cfrac%7B33%7D%7B4%7D%2C%7E%5Cfrac%7B5%7D%7B2%7D%2C%7E%5Cfrac%7B7%7D%7B1%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. " class="latex" title="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. " /></p>
<p>Note that since the last fraction is an integer the program runs forever. If <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 1}" class="latex" title="{n = 1}" /> so that the input is <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />, it would go <img src="https://s0.wp.com/latex.php?latex=%7B2+%5Crightarrow+5+%5Crightarrow+4+%5Crightarrow+33+%5Crightarrow+3+%5Crightarrow+21+%5Crightarrow+26+%5Crightarrow+14+%5Crightarrow+2+%5Ccdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}" class="latex" title="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}" /> and thus cycle, unless we stop it. The powers of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> that appear in its output give the desired sequence. </p>
<p>
More natural to us, however, is the following modular program—which can use binary or any notation:</p>
<p>
<font size="+1"><tt><b><br />
start: if (n == 1) { halt; }<br />
if (n == 0 mod 2) { goto div; }<br />
n = 3*n + 1;<br />
div: n = n/2;<br />
goto start;<br />
</b></tt></font></p>
<p></p><p><br />
One can generalize the Collatz problem to moduli <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m &gt; 2}" class="latex" title="{m &gt; 2}" />. For each <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3C+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k &lt; m}" class="latex" title="{k &lt; m}" /> we have a linear transformation <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cmapsto+c_k+n+%2B+d_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \mapsto c_k n + d_k}" class="latex" title="{n \mapsto c_k n + d_k}" /> that always gives an integer value when <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cequiv+k+%5Cpmod%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \equiv k \pmod{m}}" class="latex" title="{n \equiv k \pmod{m}}" />. We want to know about the orbits of numbers <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> under this iteration.</p>
<p>
In fact, this is exactly what FRACTRAN does. Take <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> to be the least common multiple of the denominators <img src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_r}" class="latex" title="{b_r}" /> in a FRACTRAN program <img src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cfrac%7Ba_r%7D%7Bb_r%7D%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[\frac{a_r}{b_r}]}" class="latex" title="{[\frac{a_r}{b_r}]}" />. Then for each <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> we can list the remainders <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> that are multiples of <img src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_r}" class="latex" title="{b_r}" /> and we get <img src="https://s0.wp.com/latex.php?latex=%7Bc_k+%3D+%5Cfrac%7Ba_r%7D%7B%5Cgcd%28k%2Cm%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_k = \frac{a_r}{\gcd(k,m)}}" class="latex" title="{c_k = \frac{a_r}{\gcd(k,m)}}" />, with <img src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_k = 0}" class="latex" title="{d_k = 0}" />. The Turing-universality of FRACTRAN then proves a general theorem Conway stated in 1972:</p>
<blockquote><p><b>Theorem 1</b> <em> Generalized Collatz-type problems for moduli <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{m &gt; 2}" class="latex" title="{m &gt; 2}" /> are undecidable. </em>
</p></blockquote>
<p></p><p>
<a href="https://link.springer.com/chapter/10.1007/978-3-540-72504-6_49">Several</a> <a href="http://julienmalka.me/collatz.pdf">followup</a> <a href="https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/Lagarias3-23.pdf">papers</a> have proved stronger and more particular forms of the undecidability. The paper by Monks linked above leverages the unary encoding to show that having <img src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_k = 0}" class="latex" title="{d_k = 0}" /> is essentially without loss of generality for universality; it is titled “<img src="https://s0.wp.com/latex.php?latex=%7B3x%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3x+1}" class="latex" title="{3x+1}" /> Minus the <img src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+}" class="latex" title="{+}" />.” </p>
<p>
Having digested universality, it is natural to wonder about complexity. Can we use modular programming to achieve stronger connections between number theory and complexity classes—classes above the level of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}^0}" class="latex" title="{\mathsf{ACC}^0}" />, say? One possible mode of connection is exemplified by this <a href="https://www.researchgate.net/publication/220994869_One_Binary_Horn_Clause_is_Enough">paper</a> from STACS 1994, which both Dick and I attended. We wonder whether the kind of connection noted by Terry Tao in his <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">tribute</a> to Conway can also smooth the way to understanding <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{MIP^* = RE}}" class="latex" title="{\mathsf{MIP^* = RE}}" />.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Conway posed many open problems himself. Here is a <a href="https://oeis.org/A248380/a248380.pdf">list</a> of five for which he posted cash rewards in the manner of Paul Erdős. The fifth was recently solved. The fourth can be stated in one sentence:</p>
<blockquote><p><b> </b> <em> If a set of points in the plane intersects every convex region of area 1, then must it have pairs of points at arbitrarily small distances? </em>
</p></blockquote>
<p></p><p>
Our condolences go out to his family and all who were enthralled by him in the mathematical world. We could talk endlessly about his impact on mathematics education—even about simple things like how to <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=3111964">prove</a> that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{2}}" class="latex" title="{\sqrt{2}}" /> is irrational—or try to tangle with his <a href="https://en.wikipedia.org/wiki/Monstrous_moonshine">applications</a> of the “Monster” group to modular forms, but those must be for another time. Also see Scott Aaronson’s <a href="https://www.scottaaronson.com/blog/?p=4732">tribute</a> and its comments section for many more stories and items.</p>
<p></p><p><br />
[some small word and format changes, added link to Scott and may add others as time allows]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/"><span class="datestr">at April 14, 2020 08:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=49">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">A Primer on Private Statistics – Part I</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>Differentially private statistics is a very lively research area, and has seen a lot of activity in the last couple years. While the phrasing is a slight departure from previous work which focused on estimation with worst-case datasets, it turns out that the differences are often superficial. In a short series of blog posts, we hope to educate readers on some of the recent advancements in this area, as well as shed light on some of the connections between the old and the new. We’ll describe the settings, cover a couple of technical examples, and give pointers to some other directions in the area. Thanks to <a href="https://cs-people.bu.edu/ads22/">Adam Smith</a> for helping kick off this project, <a href="http://www.cs.columbia.edu/~ccanonne/">Clément Canonne</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, and <a href="http://www.thomas-steinke.net/">Thomas Steinke</a> for helpful comments, and <a href="https://lucatrevisan.github.io/">Luca Trevisan</a> for his <a href="https://lucatrevisan.wordpress.com/latex-to-wordpress/">LaTeX2WP script</a>.</p>
<p><b>1. Introduction </b></p>
<p>Statistics and machine learning are now ubiquitous in data analysis. Given a dataset, one immediately wonders what it allows us to infer about the underlying population. However, modern datasets don’t exist in a vacuum: they often contain sensitive information about the individuals they represent. Without proper care, statistical procedures will result in gross violations of privacy. Motivated by the shortcomings of ad hoc methods for data anonymization, Dwork, McSherry, Nissim, and Smith introduced the celebrated notion of differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>].</p>
<p>From its inception, some of the driving motivations for differential privacy were applications in statistics and the social sciences, notably disclosure limitation for the US Census. And yet, the lion’s share of differential privacy research has taken place within the computer science community. As a result, the specific applications being studied are often not formulated using statistical terminology, or even as statistical problems. Perhaps most significantly, much of the early work in computer science (though definitely not all) focus on estimating some property <em>of a dataset</em> rather than estimating some property <em>of an underlying population</em>.</p>
<p>Although the earliest works exploring the interaction between differential privacy and classical statistics go back to at least 2009 [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>,<a href="https://kamathematics.wordpress.com/feed/#FRY10">FRY10</a>], the emphasis on differentially private statistical inference in the computer science literature is somewhat more recent. However, while earlier results on differential privacy did not always formulate problems in a statistical language, statistical inference was a key motivation for most of this work. As a result many of the techniques that were developed have direct applications in statistics, for example establishing minimax rates for estimation problems.</p>
<p>The purpose of this series of blog posts is to highlight some of those results in the computer science literature, and present them in a more statistical language. Specifically, we will discuss:</p>
<ul>
<li>Tight minimax lower bounds for privately estimating the mean of a multivariate distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" />, using the technique of <em>tracing attacks</em> developed in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>,<a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>].
<p> </p>
</li>
<li>Upper bounds for estimating a distribution in Kolmogorov distance, using the ubiquitous <em>binary-tree mechanism</em> introduced in [<a href="https://kamathematics.wordpress.com/feed/#DNPR10">DNPR10</a>,<a href="https://kamathematics.wordpress.com/feed/#CSS11">CSS11</a>].</li>
</ul>
<p>In particular, we hope to encourage computer scientists working on differential privacy to pay more attention to the applications of their methods in statistics, and share with statisticians many of the powerful techniques that have been developed in the computer science literature.</p>
<p> </p>
<p><b> 1.1. Formulating Private Statistical Inference </b></p>
<p>Essentially every differentially private statistical estimation task can be phrased using the following setup. We are given a dataset <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C+%5Cdots%2C+X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1, \dots, X_n)}" class="latex" title="{X = (X_1, \dots, X_n)}" /> of size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, and we wish to design an algorithm <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Cin+%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \in \mathcal{M}}" class="latex" title="{M \in \mathcal{M}}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}}" class="latex" title="{\mathcal{M}}" /> is the class of mechanisms that are both:</p>
<ol>
<li>differentially private, and</li>
<li>accurate, either in expectation or with high probability, according to some task-specific measure.</li>
</ol>
<p>A few comments about this framework are in order. First, although the accuracy requirement is stochastic in nature (i.e., an algorithm might not be accurate depending on the randomness of the algorithm and the data generation process), the privacy requirement is worst-case in nature. That is, the algorithm must protect privacy for every dataset <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, even those we believe are very unlikely.</p>
<p>Second, the accuracy requirement is stated rather vaguely. This is because the notion of accuracy of an algorithm is slightly more nuanced, depending on whether we are concerned with <em>empirical</em> or <em>population</em> statistics. A particular emphasis of these blog posts is to explore the difference (or, as we will see, the lack of a difference) between these two notions of accuracy. The former estimates a quantity of the observed dataset, while the latter estimates a quantity of an unobserved distribution which is assumed to have generated the dataset.</p>
<p>More precisely, the former can be phrased in terms of empirical loss, of the form:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BX+%5Cin+%5Cmathcal%7BX%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_M%28%5Cell%28M%28X%29%2C+f%28X%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " class="latex" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}}" class="latex" title="{\mathcal{M}}" /> is some class of <em>randomized estimators</em> (e.g., differentially private estimators), <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{X}}" class="latex" title="{\mathcal{X}}" /> is some class of <em>datasets</em>, <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is some quantity of interest, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> is some <em>loss function</em>. That is, we’re looking to find an estimator that has small expected loss on <em>any dataset</em> in some class.</p>
<p>In contrast, statistical minimax theory looks at statements about population loss, of the form:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_%7BX+%5Csim+P%2C+M%7D%28%5Cell%28M%28X%29%2Cf%28P%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " class="latex" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> is some family of <em>distributions</em> over datasets (typically consisting of i.i.d. samples). That is, we’re looking to find an estimator that has small expected loss on random data from <em>any distribution</em> in some class. In particular, note that the randomness in this objective additionally includes the data generating procedure <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim P}" class="latex" title="{X \sim P}" />.</p>
<p>These two formulations are formally very different in several ways. First, the empirical formulation requires an estimator to have small loss on <em>worst-case</em> datasets, whereas the statistical formulation only requires the estimator to have small loss <em>on average</em> over datasets drawn from certain distributions. Second, the statistical formulation requires that we estimate the unknown quantity <img src="https://s0.wp.com/latex.php?latex=%7Bf%28P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(P)}" class="latex" title="{f(P)}" />, and thus necessitates a solution to the non-private estimation problem. On the other hand, the empirical formulation only asks us to estimate the known quantity <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" />, and thus if there were no privacy constraint it would always be possible to compute <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" /> exactly. Third, typically in the statistical formulation, we require that the dataset is drawn i.i.d., which means that we are more constrained when proving lower bounds for estimation than we are in the empirical problem.</p>
<p>However, in practice (more precisely, in the practice of doing theoretical research), these two formulations are more alike than they are different, and results about one formulation often imply results about the other formulation. On the algorithmic side, classical statistical results will often tell us that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f(X),f(P))}" class="latex" title="{\ell(f(X),f(P))}" /> is small, in which case algorithms that guarantee <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(M(X),f(X))}" class="latex" title="{\ell(M(X),f(X))}" /> is small also guarantee <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(M(X),f(P))}" class="latex" title="{\ell(M(X),f(P))}" /> is small.</p>
<p>Moreover, typical lower bound arguments for empirical quantities are often statistical in nature. These typically involving constructing some simple “hard distribution” over datasets such that no private algorithm can estimate well on average for this distribution, and thus these lower bound arguments also apply to estimating population statistics for some simple family of distributions. We will proceed to give some examples of estimation problems that were originally studied by computer scientists with the empirical formulation in mind. These results either implicitly or explicitly provide solutions to the corresponding population versions of the same problems—our goal is to spell out and illustrate these connections.</p>
<p><b>2. DP Background </b></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2CX_2%2C%5Cdots%2CX_n%29+%5Cin+%5Cmathcal%7BX%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" class="latex" title="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" /> be a collection of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> samples where each individual sample comes from the domain <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{X}}" class="latex" title="{\mathcal{X}}" />. We say that two samples <img src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27+%5Cin+%5Cmathcal%7BX%7D%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,X' \in \mathcal{X}^*}" class="latex" title="{X,X' \in \mathcal{X}^*}" /> are <em>adjacent</em>, denoted <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim X'}" class="latex" title="{X \sim X'}" />, if they differ on at most one individual sample. Intuitively, a randomized algorithm <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, which is often called a <em>mechanism</em> for historical reasons, is <em>differentially private</em> if the distribution of <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X')}" class="latex" title="{M(X')}" /> are similar for every pair of adjacent samples <img src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,X'}" class="latex" title="{X,X'}" />.</p>
<blockquote>
<p><b>Definition 1 ([<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> A mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" /> is <em><img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private</em> if for every pair of adjacent datasets <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim X'}" class="latex" title="{X \sim X'}" />, and every (measurable) <img src="https://s0.wp.com/latex.php?latex=%7BR+%5Csubseteq+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R \subseteq R}" class="latex" title="{R \subseteq R}" /> </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%29+%5Cin+R%29+%5Cleq+e%5E%7B%5Cepsilon%7D+%5Ccdot+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%27%29+%5Cin+R%29+%2B+%5Cdelta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " class="latex" title="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " /></p>
<p> </p>
</blockquote>
<p>We let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}_{\epsilon,\delta}}" class="latex" title="{\mathcal{M}_{\epsilon,\delta}}" /> denote the set of mechanisms that satisfy <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy.</p>
<blockquote>
<p><b>Remark 1</b> <em> To simplify notation, and to maintain consistency with the literature, we adopt the convention of defining the mechanism only for a fixed sample size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. What this means in practice is that the mechanisms we describe treat the sample size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is <em>public information</em> that need not be kept private. While one could define a more general model where <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is not fixed, it wouldn’t add anything to this discussion other than additional complexity. </em></p>
</blockquote>
<blockquote>
<p><b>Remark 2</b> <em> In these blog posts, we stick to the most general formulation of differential privacy, so-called <em>approximate differential privacy</em>, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" /> essentially because this is the notion that captures the widest variety of private mechanisms. Almost all of what follows would apply equally well, with minor technical modifications, to slightly stricter notions of <em>concentrated differential privacy [</em><a href="https://kamathematics.wordpress.com/feed/#DR16">DR16</a>, <a href="https://kamathematics.wordpress.com/feed/#BS16">BS16</a>, <a href="https://kamathematics.wordpress.com/feed/#BDRS18">BDRS18</a>], Rényi differential privacy [<a href="https://kamathematics.wordpress.com/feed/#Mir17">Mir17</a>], or <em>Gaussian differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DRS19">DRS19</a>]</em>. While so-called <em>pure differential privacy</em>, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,0)}" class="latex" title="{(\epsilon,0)}" />-differential privacy has also been studied extensively, this notion is artificially restrictive and excludes many differentially private mechanisms. </em></p>
</blockquote>
<p>A key property of differential privacy that helps when desinging efficient estimators is <em>closure under postprocessing</em>:</p>
<blockquote>
<p><b>Lemma 2 (Post-Processing [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> <a name="lempost-processing"></a> If <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private and <img src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccolon+%5Cmathcal%7BR%7D+%5Crightarrow+%5Cmathcal%7BR%7D%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" class="latex" title="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" /> is any randomized algorithm, then <img src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccirc+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M' \circ M}" class="latex" title="{M' \circ M}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private. </em></p>
</blockquote>
<p>The estimators we present in this work will use only one tool for achieving differential privacy, the <em>Gaussian Mechanism</em>.</p>
<blockquote>
<p><b>Lemma 3 (Gaussian Mechanism)</b> <em> <a name="lemgauss-mech"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" class="latex" title="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" /> be a function and let </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CDelta_%7Bf%7D+%3D+%5Csup_%7BX%5Csim+X%27%7D+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " class="latex" title="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " /></p>
<p>denote its <em><img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2}" class="latex" title="{\ell_2}" />-sensitivity</em>. The <em>Gaussian mechanism</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X%29+%3D+f%28X%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280+%2C+%5Cfrac%7B2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2%7D+%5Ccdot+%5CDelta_%7Bf%7D%5E2+%5Ccdot+%7B%5Cmathbb+I%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " class="latex" title="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " /></p>
<p><em> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy. </em></p>
</blockquote>
<p><b>3. Mean Estimation in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" /> </b></p>
<p>Let’s take a dive into the problem of <em>private mean estimation</em> for some family <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> of multivariate distributions over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" />. This problem has been studied for various families <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> and various choices of loss function. Here we focus on perhaps the simplest variant of the problem, in which <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> contains distributions of bounded support <img src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[\pm 1]^d}" class="latex" title="{[\pm 1]^d}" /> and the loss is the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2^2}" class="latex" title="{\ell_2^2}" /> error. We emphasize, however, that the methods we discuss here are quite versatile and can be used to derive minimax bounds for other variants of the mean-estimation problem.</p>
<p>Note that, by a simple argument, the non-private minimax rate for this class is achieved by the empirical mean, and is</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" /></p>
<p>The main goal of this section is to derive the minimax bound <a name="eqRd-minimax"></a></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Ctilde%5CTheta%5Cleft%28%5Cfrac%7Bd%5E2%7D%7B%5Cepsilon%5E2+n%5E2%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" class="latex" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" /></p>
<p><a name="eqRd-minimax"></a> Recall that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+%5CTheta%28f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde \Theta(f(n))}" class="latex" title="{\tilde \Theta(f(n))}" /> refers to a function which is both <img src="https://s0.wp.com/latex.php?latex=%7BO%28f%28n%29+%5Clog%5E%7Bc_1%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(f(n) \log^{c_1} f(n))}" class="latex" title="{O(f(n) \log^{c_1} f(n))}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28f%28n%29+%5Clog%5E%7Bc_2%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(f(n) \log^{c_2} f(n))}" class="latex" title="{\Omega(f(n) \log^{c_2} f(n))}" /> for some constants <img src="https://s0.wp.com/latex.php?latex=%7Bc_1%2C+c_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_1, c_2}" class="latex" title="{c_1, c_2}" />. The proof of this lower bound is based on <em>robust tracing attacks</em>, also called <em>membership inference attacks</em>, which were developed in a chain of papers [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. We remark that this lower bound is almost identical to the minimax bound for mean estimation proven in the much more recent work of Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>], but it lacks tight dependence on the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, which we discuss in the following remark.</p>
<blockquote>
<p><b>Remark 3</b> <em> The choice of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3D+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta = 1/n}" class="latex" title="{\delta = 1/n}" /> in <a href="https://kamathematics.wordpress.com/feed/#eqRd-minimax">(2)</a> may look strange at first. For the upper bound this choice is arbitrary—as we will see, we can upper bound the rate for any <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" /> at a cost of a factor of <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog%281%2F%5Cdelta%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log(1/\delta))}" class="latex" title="{O(\log(1/\delta))}" />. The lower bound applies only when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cleq+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \leq 1/n}" class="latex" title="{\delta \leq 1/n}" />. Note that the rate is qualitatively different when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \gg 1/n}" class="latex" title="{\delta \gg 1/n}" />. However, we emphasize that <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy is not a meaningful privacy notion unless <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \ll 1/n}" class="latex" title="{\delta \ll 1/n}" />. In particular, the mechanism that randomly outputs <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta n}" class="latex" title="{\delta n}" /> elements of the sample satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%280%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(0,\delta)}" class="latex" title="{(0,\delta)}" />-differential privacy. However, when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \gg 1/n}" class="latex" title="{\delta \gg 1/n}" />, this mechanism completely violates the privacy of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\gg 1}" class="latex" title="{\gg 1}" /> person in the dataset. Moreover, taking the empirical mean of these <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta n}" class="latex" title="{\delta n}" /> samples gives rate <img src="https://s0.wp.com/latex.php?latex=%7Bd%2F%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d/\delta n}" class="latex" title="{d/\delta n}" />, which would violate our lower bound when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> is large enough. On the other hand, we would expect the minimax rate to become slower when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \ll 1/n}" class="latex" title="{\delta \ll 1/n}" />. This expectation is, in fact, correct, however the proof we present does not give the tight dependence on the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />. See [<a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>] for a refinement that can obtain the right dependence on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, and [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] for the details of how to apply this refinement in the i.i.d. setting. </em></p>
</blockquote>
<p><b> 3.1. A Simple Upper Bound </b></p>
<blockquote>
<p><b>Theorem 4</b> <em> For every <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \in {\mathbb N}}" class="latex" title="{n \in {\mathbb N}}" />, and every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon,\delta &gt; 0}" class="latex" title="{\epsilon,\delta &gt; 0}" />, there exists an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private private mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> such that <a name="eqmean-est-ub"></a></em></p>
<p><em><em><a name="eqmean-est-ub"></a></em></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%5Cleq+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" /></p>
<p><em><a name="eqmean-est-ub"></a></em></p>
<p><em><a name="eqmean-est-ub"></a> </em></p>
</blockquote>
<p><em>Proof:</em> Define the mechanism</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Coverline%7BX%7D+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" class="latex" title="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" /></p>
<p>This mechanism satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy by Lemma <a href="https://kamathematics.wordpress.com/feed/#lemgauss-mech">3</a>, noting that for any pair of adjacent samples <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1 \cdots n}}" class="latex" title="{X_{1 \cdots n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX%27_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'_{1 \cdots n}}" class="latex" title="{X'_{1 \cdots n}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C+%5Coverline%7BX%7D+-+%5Coverline%7BX%7D%27%5C%7C_2%5E2+%5Cleq+%5Cfrac%7Bd%7D%7Bn%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" class="latex" title="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%5E2+%3D+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" class="latex" title="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" />. Note that since the Gaussian noise has mean <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and is independent of <img src="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7BX%7D+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\overline{X} - \mu}" class="latex" title="{\overline{X} - \mu}" />, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu+%5C%7C_2%5E2%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%5Cleq%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D%29+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Csigma%5E2+d+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p> </p>
<p><b> 3.2. Minimax Lower Bounds via Tracing </b></p>
<blockquote>
<p><b>Theorem 5</b> <em> <a name="thmmean-lb"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bn%2C+d+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n, d \in {\mathbb N}}" class="latex" title="{n, d \in {\mathbb N}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0}" class="latex" title="{\epsilon &gt; 0}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3C+1%2F96n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &lt; 1/96n}" class="latex" title="{\delta &lt; 1/96n}" />, if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> is the class of all product distributions on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}^{d}}" class="latex" title="{\{\pm 1\}^{d}}" />, then for some constant <img src="https://s0.wp.com/latex.php?latex=%7BC+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C &gt; 0}" class="latex" title="{C &gt; 0}" />, </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%2CM%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5COmega%5Cleft%28%5Cmin+%5Cleft%5C%7B+%5Cfrac%7Bd%5E2%7D%7B+%5Cepsilon%5E2+n%5E2%7D%2C+d+%5Cright%5C%7D%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " class="latex" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " /></p>
<p> </p>
</blockquote>
<p>Note that it is trivial to achieve error <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> for any distribution using the mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%5Cequiv+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{1 \cdots n}) \equiv 0}" class="latex" title="{M(X_{1 \cdots n}) \equiv 0}" />, so the result says that the error must be <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28d%5E2%2F%5Cepsilon%5E2+n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(d^2/\epsilon^2 n^2)}" class="latex" title="{\Omega(d^2/\epsilon^2 n^2)}" /> whenever this error is significantly smaller than the trivial error of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />.</p>
<p><b>Tracing Attacks.</b></p>
<p>Before giving the formal proof, we will try to give some intuition for the high-level proof strategy. The proof can be viewed as constructing a <em>tracing attack </em>[<a href="https://kamathematics.wordpress.com/feed/#DSSU17">DSSU17</a>] (sometimes called a <em>membership inference attack</em>) of the following form. There is an attacker who has the data of some individual <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> chosen in one of the two ways: either <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a random element of the sample <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, or <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is an independent random sample from the population <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" />. The attacker is given access to the true distribution <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> and the outcome of the mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" />, and wants to determine which of the two is the case. If the attacker can succeed, then <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> cannot be differentially private. To understand why this is the case, if <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a member of the dataset, then the attacker should say <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is in the dataset, but if we consider the adjacent dataset <img src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'}" class="latex" title="{X'}" /> where we replace <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> with some independent sample from <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" />, then the attacker will now say <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is independent of the dataset. Thus, <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X')}" class="latex" title="{M(X')}" /> cannot be close in the sense required by differential privacy.</p>
<p>Thus, the proof works by constructing a test statistic <img src="https://s0.wp.com/latex.php?latex=%7BZ+%3D+Z%28M%28X%29%2CY%2CP%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z = Z(M(X),Y,P),}" class="latex" title="{Z = Z(M(X),Y,P),}" /> that the attacker can use to distinguish the two possibilities for <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />. In particular, we show that there is a distribution over populations <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z)}" class="latex" title="{\mathop{\mathbb E}(Z)}" /> is small when <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is independent of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, but for <em>every</em> sufficiently accurate mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z)}" class="latex" title="{\mathop{\mathbb E}(Z)}" /> is large when <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a random element of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />.</p>
<p><b>Proof of Theorem <a href="https://kamathematics.wordpress.com/feed/#thmmean-lb">5</a>.</b></p>
<p>We start by constructing a “hard distribution” over the family of product distributions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%3D+%28%5Cmu%5E1%2C%5Cdots%2C%5Cmu%5Ed%29+%5Cin+%5B-1%2C1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" class="latex" title="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" /> consist of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> independent draws from the uniform distribution on <img src="https://s0.wp.com/latex.php?latex=%7B%5B-1%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[-1,1]}" class="latex" title="{[-1,1]}" /> and let <img src="https://s0.wp.com/latex.php?latex=%7BP_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_{\mu}}" class="latex" title="{P_{\mu}}" /> be the product distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}^{d}}" class="latex" title="{\{\pm 1\}^{d}}" /> with mean <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Csim+P_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_1,\dots,X_n \sim P_{\mu}}" class="latex" title="{X_1,\dots,X_n \sim P_{\mu}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1,\dots,X_n)}" class="latex" title="{X = (X_1,\dots,X_n)}" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5E%7Bn+%5Ctimes+d%7D+%5Crightarrow+%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" class="latex" title="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" /> be any <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private mechanism and let</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5C%7C+M%28X%29+-+%5Cmu%5C%7C_2%5E2+%29+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" class="latex" title="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" /></p>
<p>be its expected loss. We will prove the desired lower bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" />.</p>
<p>For every element <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, we define the random variables</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+Z_i+%3D+Z_i%28M%28X%29%2CX_i%2C%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle+%5C%5C+Z%27_%7Bi%7D+%3D+Z%27_i%28M%28X_%7B%5Csim+i%7D%29%2C+X_i%2C+%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " class="latex" title="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B%5Csim+i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{\sim i}}" class="latex" title="{X_{\sim i}}" /> denotes <img src="https://s0.wp.com/latex.php?latex=%7B%28X_1%2C%5Cdots%2CX%27_i%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X_1,\dots,X'_i,\dots,X_n)}" class="latex" title="{(X_1,\dots,X'_i,\dots,X_n)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BX%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'_i}" class="latex" title="{X'_i}" /> is an independent sample from <img src="https://s0.wp.com/latex.php?latex=%7BP_%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_\mu}" class="latex" title="{P_\mu}" />. Our goal will be to show that, privacy and accuracy imply both upper and lower bounds on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_i+Z_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_i Z_i)}" class="latex" title="{\mathop{\mathbb E}(\sum_i Z_i)}" /> that depend on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />, and thereby obtain a bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" />.</p>
<p>The first claim says that, when <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> is <em>not</em> in the sample, then the likelihood random variable has mean <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and variance controlled by the expected <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2^2}" class="latex" title="{\ell_2^2}" /> error of the mechanism.</p>
<blockquote>
<p><b>Claim 1</b> <em> <a name="clmmean-lb-1"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z'_i) = 0}" class="latex" title="{\mathop{\mathbb E}(Z'_i) = 0}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" class="latex" title="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7CZ%27_i%5C%7C_%5Cinfty+%5Cleq+4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|Z'_i\|_\infty \leq 4d}" class="latex" title="{\|Z'_i\|_\infty \leq 4d}" />. </em></p>
</blockquote>
<p><em>Proof:</em> Conditioned on any value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />, <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{\sim i})}" class="latex" title="{M(X_{\sim i})}" /> is independent from <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" />. Moreover, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28X_i+-+%5Cmu%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(X_i - \mu) = 0}" class="latex" title="{\mathop{\mathbb E}(X_i - \mu) = 0}" />, so we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28X_i+-+%5Cmu%29+%5Cright+%5Crangle+%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+0+%5Cright+%5Crangle+%29+%5C%5C+%3D+%260.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " /></p>
<p>For the second part of the claim, since <img src="https://s0.wp.com/latex.php?latex=%7B%28X_i+-+%5Cmu%29%5E2+%5Cleq+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X_i - \mu)^2 \leq 4}" class="latex" title="{(X_i - \mu)^2 \leq 4}" />, we have <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4+%5Ccdot+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" class="latex" title="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" />. The final part of the claim follows from the fact that every entry of <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{\sim i}) - \mu}" class="latex" title="{M(X_{\sim i}) - \mu}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX_i+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i - \mu}" class="latex" title="{X_i - \mu}" /> is bounded by <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> in absolute value, and <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_i}" class="latex" title="{Z'_i}" /> is a sum of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> such entries, so its absolute value is always at most <img src="https://s0.wp.com/latex.php?latex=%7B4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4d}" class="latex" title="{4d}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>The next claim says that, because <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is differentially private, <img src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_i}" class="latex" title="{Z_i}" /> has similar expectation to <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_i}" class="latex" title="{Z'_i}" />, and thus its expectation is also small.</p>
<blockquote>
<p><b>Claim 2</b> <em><a name="clmmean-lb-2"></a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" class="latex" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" /> </em></p>
</blockquote>
<p><em>Proof:</em> The proof is a direct calculation using the following inequality, whose proof is relatively simple using the definition of differential privacy:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%2B+2%5Cepsilon+%5Csqrt%7B%5Cmathrm%7BVar%7D%28Z%27_i%29%7D+%2B+2%5Cdelta+%5C%7C+Z%27_i+%5C%7C_%5Cinfty.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " class="latex" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " /></p>
<p>Given the inequality and Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-1">1</a>, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+0+%2B+%282%5Cepsilon%29%282%5Calpha%29+%2B+%282%5Cdelta%29%282d%29+%3D+4%5Cepsilon+%5Calpha+%2B+8+%5Cdelta+d+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " class="latex" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " /></p>
<p>The claim now follows by summing over all <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>The final claim says that, because <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is accurate, the expected sum of the random variables <img src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_i}" class="latex" title="{Z_i}" /> is large.</p>
<blockquote>
<p><b>Claim 3</b> <em> <a name="clmmean-lb-3"></a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cgeq+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" class="latex" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" /> </em></p>
</blockquote>
<p>The proof relies on the following key lemma, whose proof we omit.</p>
<blockquote>
<p><b>Lemma 6 (Fingerprinting Lemma [<a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>])</b><em> <a name="lemfp"></a> If <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%5Cin+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu \in [\pm 1]}" class="latex" title="{\mu \in [\pm 1]}" /> is sampled uniformly, <img src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Cin+%5C%7B%5Cpm+1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" class="latex" title="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" /> are sampled independently with mean <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />, and <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5En+%5Crightarrow+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" class="latex" title="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" /> is any function, then </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i+-+%5Cmu%29%29+%5Cgeq+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29%5E2%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " class="latex" title="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " /></p>
<p> </p>
</blockquote>
<p>The lemma is somewhat technical, but for intuition, consider the case where <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%7D+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X) = \frac{1}{n}\sum_{i} X_i}" class="latex" title="{f(X) = \frac{1}{n}\sum_{i} X_i}" /> is the empirical mean. In this case we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5En+%28X_i+-+%5Cmu%29%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cfrac%7B1%7D%7Bn%7D+%5Csum_i+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%7D%28+%28X_i+-+%5Cmu%29%5E2%29+%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathrm%7BVar%7D%28X_i%29%29+%3D+%5Cfrac%7B1%7D%7B3%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " /></p>
<p>The lemma says that, when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" /> is sampled this way, then any modification of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> that reduces the correlation between <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_i X_i}" class="latex" title="{\sum_i X_i}" /> will increase the mean-squared-error of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> proportionally.</p>
<p>We now prove Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a>.</p>
<p><em>Proof:</em> We can apply the lemma to each coordinate of the estimate <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" />.</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%29+%5C%5C+%3D%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i%5Ej+-+%5Cmu%5Ej%29%29+%5C%5C+%5Cgeq%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cleft%28+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5E2%29+%5Cright%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " /></p>
<p>The inequality is Lemma <a href="https://kamathematics.wordpress.com/feed/#lemfp">6</a>. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>Combining Claims <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-2">2</a> and <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a> gives</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" class="latex" title="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" /></p>
<p>Now, if <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \geq \frac{d}{6}}" class="latex" title="{\alpha^2 \geq \frac{d}{6}}" /> then we’re done, so we’ll assume that <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cleq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \leq \frac{d}{6}}" class="latex" title="{\alpha^2 \leq \frac{d}{6}}" />. Further, by our assumption on the value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, <img src="https://s0.wp.com/latex.php?latex=%7B8n+%5Cdelta+d+%5Cleq+%5Cfrac%7Bd%7D%7B12%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{8n \delta d \leq \frac{d}{12}}" class="latex" title="{8n \delta d \leq \frac{d}{12}}" />. In this case we can rearrange terms and square both sides to obtain</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%5Cgeq%7B%7D+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+-+8+n%5Cdelta+d%5Cright%29%5E2+%5Cgeq+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B12%7D%5Cright%29%5E2+%3D+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" class="latex" title="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" /></p>
<p>Combining the two cases for <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" /> gives <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cmin%5C%7B+%5Cfrac%7Bd%7D%7B6%7D%2C+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" class="latex" title="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" />, as desired.</p>
<p><b>Bibliography</b></p>
<p>[BDRS18]<a name="BDRS18"></a> Mark Bun, Cynthia Dwork, Guy N. Rothblum, and Thomas Steinke. Composable and versatile privacy via truncated CDP. STOC ’18.</p>
<p>[BS16]<a name="BS16"></a> Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. TCC ’16-B.</p>
<p>[BSU17]<a name="BSU17"></a> Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p>[BUV14]<a name="BUV14"></a> Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p>[CSS11]<a name="CSS11"></a> T-H Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. ACM Transactions on Information and System Security, 14(3):26, 2011.</p>
<p>[CWZ19]<a name="CWZ19"></a> T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p>[DMNS06]<a name="DMNS06"></a> Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p>[DNPR10]<a name="DNPR10"></a> Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. STOC ’10.</p>
<p>[DR16]<a name="DR16"></a> Cynthia Dwork and Guy N. Rothblum. Concentrated differential privacy. arXiv, 1603.01887, 2016.</p>
<p>[DRS19]<a name="DRS19"></a> Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy. arXiv, 1905.02383, 2019.</p>
<p>[DSSU17]<a name="DSSU17"></a> Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p>[DSSUV15]<a name="DSSUV15"></a> Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. Exposed! a survey of attacks on private data. Annual Review of Statistics and Its Application, 4:61–84, 2017.</p>
<p>[FRY10]<a name="FRY10"></a> Stephen E. Fienberg, Alessandro Rinaldo, and Xiaolin Yang. Differential privacy and the risk-utility tradeoff for multi-dimensional contingency tables. PSD ’10.</p>
<p>[KLSU19]<a name="KLSU19"></a> Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p>[Mir17]<a name="Mir17"></a> Ilya Mironov. Rényi differential privacy. CSF ’17.</p>
<p>[SU17a]<a name="SU17a"></a> Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p>[SU17b]<a name="SU17b"></a> Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p>[VS09]<a name="VS09"></a> Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>


<p></p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/"><span class="datestr">at April 14, 2020 02:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05922">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05922">Lecture Note on LCSSX's Lower Bounds for Non-Adaptive Distribution-free Property Testing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bshouty:Nader_H=.html">Nader H. Bshouty</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05922">PDF</a><br /><b>Abstract: </b>In this lecture note we give Liu-Chen-Servedio-Sheng-Xie's (LCSSX) lower
bound for property testing in the non-adaptive distribution-free.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05922"><span class="datestr">at April 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.05706">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.05706">From Holant to Quantum Entanglement and Back</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:Jin=Yi.html">Jin-Yi Cai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fu:Zhiguo.html">Zhiguo Fu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shao:Shuai.html">Shuai Shao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.05706">PDF</a><br /><b>Abstract: </b>Holant problems are intimately connected with quantum theory as tensor
networks. We first use techniques from Holant theory to derive new and improved
results for quantum entanglement theory. We discover two particular entangled
states $|{\Psi_6}\rangle$ of 6 qubits and $|{\Psi_8}\rangle$ of 8 qubits
respectively, that have extraordinary and unique closure properties in terms of
the Bell property. Then we use entanglement properties of constraint functions
to derive a new complexity dichotomy for all real-valued Holant problems
containing an odd-arity signature. The signatures need not be symmetric, and no
auxiliary signatures are assumed.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.05706"><span class="datestr">at April 14, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-612436836431644422">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/04/john-conway-dies-of-coronvirus.html">John Conway Dies of Coronvirus</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
John Conway passed away on April 11, 2020 of the Coronovirus. He is the first person I knew (for some definition of `know') who has died of it. I suspect this is true of many readers of this blog.<br />
(Fellow bloggers Scott Aaronson and Terry Tao have already posted about John Conway,<br />
<a href="https://www.scottaaronson.com/blog/">here</a> and <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">here</a>. I suspect there will be others and when they do I will add it here.<br />
ADDED LATER: nice xkcd <a href="https://xkcd.com/2293/">here</a><br />
<br />
John Conway is a great example of how the line between recreational math and serious math is .... non-existent? not important? Take our pick.<br />
<br />
Examples<br />
<br />
1) Conway invented Surreal Numbers. These can be used to express infinitely big and infinitely small numbers. One can even make sense of things like square root of infinity.  Conway's book is called On Numbers and Games (see <a href="https://en.wikipedia.org/wiki/On_Numbers_and_Games">here</a> and <a href="https://www.amazon.com/Numbers-Games-John-H-Conway/dp/1568811276">here</a>) Two free sources: <a href="https://thatsmaths.com/2012/11/22/the-root-of-infinity-its-surreal/">here</a> and <a href="https://www.whitman.edu/Documents/Academics/Mathematics/Grimm.pdf">here</a>.<br />
<br />
<div>
Note that Conway defined surreals in terms of games. Are they fun games? Probably not, but they are games!</div>
<div>
<br /></div>
<div>
2)  Conway's Game of Life (you really do need to use his name, note the contrast between <i>The game</i> <i>of life <a href="https://en.wikipedia.org/wiki/The_Game_of_Life">here</a> </i>and <i>Conway's Game of Life <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">here</a></i></div>
<div>
<i><br /></i></div>
<div>
<div>
The game is simple (and this one IS fun). You begin with some set of dots placed at lattice points, and a set of rules to tell how they live, die, or reproduce.  The rules are always the same. Different initial patterns form all kinds of patterns.  Sounds fun! Is it easy to tell, given pattern P1 and P2 whether, starting with P1 you can get to P2. No. Its undecidable.</div>
<div>
<br /></div>
<div>
So this simple fun game leads to very complicated patterns.</div>
<div>
<br /></div>
<div>
And nice to have an undecidable problem that does not mention Turing Machines. (I will tell the students it is undecidable this semester, though I won't be proving it.)</div>
<div>
<br /></div>
<div>
3)  Berlekamp, Conway, and Guy wrote <i>Winning Ways for your Mathematical Plays  </i>See <a href="https://en.wikipedia.org/wiki/Winning_Ways_for_your_Mathematical_Plays">here</a> and <a href="http://www.amazon.com/Winning-Ways-Your-Mathematical-Plays/dp/1568811446">here</a></div>
</div>
<div>
<br /></div>
<div>
This is the ultimate book on NIM games.</div>
<div>
<br /></div>
<div>
4) The above is probably what the readers of this blog are familiar with; however, according to his Wikipedia page (see <a href="https://en.wikipedia.org/wiki/John_Horton_Conway">here</a>) he worked in Combinatorial Game Theory, Geometry, Geometric Topology, Group Theory, Number Theory, Algebra, Analysis, Algorithmics and Theoretical Physics.</div>
<div>
<br /></div>
<div>
He will be missed.</div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/04/john-conway-dies-of-coronvirus.html"><span class="datestr">at April 13, 2020 02:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4732">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4732">John Horton Conway (1937-2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong><span class="has-inline-color has-vivid-red-color">Update (4/13):</span></strong> Check out the comments on this post for some wonderful firsthand Conway stories.  Or for the finest tribute I’ve seen so far, see a MathOverflow thread entitled <a href="https://mathoverflow.net/questions/357197/conways-lesser-known-results">Conway’s lesser known results</a>.  Virtually everything there is a gem to be enjoyed by amateurs and experts alike.  And if you actually click through to any of Conway’s papers … oh my god, what a rebuke to the way most of us write papers!</p>



<p><a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Horton Conway</a>, one of the great mathematicians and math communicators of the past half-century, has died at age 82.</p>



<blockquote class="wp-block-quote"><p><strong><span class="has-inline-color has-vivid-red-color">Update:</span></strong> John’s widow, Diana Conway, left a <a href="https://www.scottaaronson.com/blog/?p=4732#comment-1836789">nice note</a> in the comments section of this post.  I wish to express my condolences to her and to all of the Conway children and grandchildren.</p></blockquote>



<p>Just a week ago, as part of her quarantine homeschooling, I introduced my seven-year-old daughter Lily to the famous <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Conway’s Game of Life</a>.  Compared to the other stuff we’ve been doing, like fractions and right triangles and the distributive property of multiplication, the Game of Life was a <em>huge</em> hit: Lily spent a full hour glued to the screen, watching the patterns evolve, trying to guess when they’d finally die out.  So this first-grader knew who John Conway was, when I told her the sad news of his passing.</p>



<p>“Did he die from the coronavirus?” Lily immediately asked.</p>



<p>“I doubt it, but I’ll check,” I said.</p>



<p>Apparently it <em>was</em> the coronavirus.  Yes, the self-replicating snippet of math that’s now terrorizing the whole human race, in part because those in power couldn’t or wouldn’t understand exponential growth.  Conway is perhaps the nasty bugger’s most distinguished casualty so far.</p>



<p>I regrettably never knew Conway, although I did attend a few of his wildly popular and entertaining lectures.  His <a href="https://www.amazon.com/Book-Numbers-John-H-Conway/dp/038797993X">The Book of Numbers</a> (coauthored with Richard Guy, who himself recently passed away at age 103) made a huge impression on me as a teenager.  I worked through every page, gasping at gems like e<sup>π√163</sup> (“no, you can’t be serious…”), embarrassed to be learning so much from a “fun, popular” book but grateful that my ignorance of such basic matters was finally being remedied.</p>



<p>A little like Pascal with his triangle or Möbius with his strip, Conway was fated to become best-known to the public not for his deepest ideas but for his most accessible—although for Conway, a principal puzzle-supplier to Martin Gardner for decades, the boundary between the serious and the recreational may have been more blurred than for any other contemporary mathematician.  Conway invented the <a href="https://en.wikipedia.org/wiki/Surreal_number">surreal number system</a>, discovered three of the 26 <a href="https://en.wikipedia.org/wiki/Sporadic_group">sporadic simple groups</a>, was instrumental in the discovery of <a href="https://en.wikipedia.org/wiki/Monstrous_moonshine">monstrous moonshine</a>, and did many other things that bloggers more qualified than I will explain in the coming days.</p>



<p>Closest to my wheelhouse, Conway together with Simon Kochen waded into the foundations of quantum mechanics in 2006, with their <a href="https://en.wikipedia.org/wiki/Free_will_theorem">“Free Will Theorem”</a>—a result Conway liked to summarize provocatively as “if human experimenters have free will, then so do the elementary particles they measure.”  I confess that I wasn’t a fan at the time—partly because Conway and Kochen’s theorem was really about “freshly-generated randomness,” rather than free will in any sense related to agency, but also partly because I’d already known the conceptual point at issue, but had considered it folklore (see, e.g., my <a href="https://arxiv.org/abs/quant-ph/0206089">2002 review</a> of Stephen Wolfram’s <em>A New Kind of Science</em>).  Over time, though, the “Free Will Theorem” packaging grew on me.  Much like with the <a href="https://en.wikipedia.org/wiki/No-cloning_theorem">No-Cloning Theorem</a> and other simple enormities, sometimes it’s worth making a bit of folklore so memorable and compelling that it will never be folklore again.</p>



<p>At a lecture of Conway’s that I attended, someone challenged him that his proposed classification of knots worked only in special cases.  “Oh, of course, this only classifies 0% of knots—but 0% is a start!” he immediately replied, to roars from the audience.  That’s just one line that I remember, but nearly everything out of his mouth was of a similar flavor.  I noted that part of it was in the delivery.</p>



<p>As a mathematical jokester and puzzler who could delight and educate anyone from a Fields Medalist to a first-grader, Conway had no equal.  For no one else who I can think of, even going back centuries and millennia, were entertainment and mathematical depth so closely marbled together.  Here’s to a well-lived Life.</p>



<p>Feel free to share your own Conway memories in the comments.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4732"><span class="datestr">at April 12, 2020 07:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
