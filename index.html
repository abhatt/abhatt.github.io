<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at May 06, 2020 02:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02369">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02369">The Expander Hierarchy and its Applications to Dynamic Graph Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goranci:Gramoz.html">Gramoz Goranci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/R=auml=cke:Harald.html">Harald Räcke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Zihan.html">Zihan Tan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02369">PDF</a><br /><b>Abstract: </b>We introduce a notion for hierarchical graph clustering which we call the
expander hierarchy and show a fully dynamic algorithm for maintaining such a
hierarchy on a graph with $n$ vertices undergoing edge insertions and deletions
using $n^{o(1)}$ update time. An expander hierarchy is a tree representation of
graphs that faithfully captures the cut-flow structure and consequently our
dynamic algorithm almost immediately implies several results including:
</p>
<p>(1) The first fully dynamic algorithm with $n^{o(1)}$ worst-case update time
that allows querying $n^{o(1)}$-approximate conductance, $s$-$t$ maximum flows,
and $s$-$t$ minimum cuts for any given $(s,t)$ in $O(\log^{1/6} n)$ time. Our
results are deterministic and extend to multi-commodity cuts and flows. The key
idea behind these results is a fully dynamic algorithm for maintaining a tree
flow sparsifier, a notion introduced by R\"acke [FOCS'02] for constructing
competitive oblivious routing schemes.
</p>
<p>(2) A deterministic fully dynamic connectivity algorithm with $n^{o(1)}$
worst-case update time. This significantly simplifies the recent algorithm by
Chuzhoy et al.~that uses the framework of Nanongkai et al. [FOCS'17].
</p>
<p>(3) The first non-trivial deterministic fully dynamic treewidth decomposition
algorithm on constant-degree graphs with $n^{o(1)}$ worst-case update time that
maintains a treewidth decomposition of width $\text{tw}(G)\cdot n^{o(1)}$ where
$\text{tw}(G)$ denotes the treewidth of the current graph.
</p>
<p>Our technique is based on a new stronger notion of the expander
decomposition, called the boundary-linked expander decomposition. This
decomposition is more robust against updates and better captures the clustering
structure of graphs. Given that the expander decomposition has proved extremely
useful in many fields, we expect that our new notion will find more future
applications.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02369"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02368">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02368">Fast Dynamic Cuts, Distances and Effective Resistances via Vertex Sparsifiers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Li.html">Li Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goranci:Gramoz.html">Gramoz Goranci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Henzinger:Monika.html">Monika Henzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Richard.html">Richard Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02368">PDF</a><br /><b>Abstract: </b>We present a general framework of designing efficient dynamic approximate
algorithms for optimization on undirected graphs. In particular, we develop a
technique that, given any problem that admits a certain notion of vertex
sparsifiers, gives data structures that maintain approximate solutions in
sub-linear update and query time. We illustrate the applicability of our
paradigm to the following problems.
</p>
<p>(1) A fully-dynamic algorithm that approximates all-pair
maximum-flows/minimum-cuts up to a nearly logarithmic factor in
$\tilde{O}(n^{2/3})$ amortized time against an oblivious adversary, and
$\tilde{O}(m^{3/4})$ time against an adaptive adversary.
</p>
<p>(2) An incremental data structure that maintains $O(1)$-approximate shortest
path in $n^{o(1)}$ time per operation, as well as fully dynamic approximate
all-pair shortest path and transshipment in $\tilde{O}(n^{2/3+o(1)})$ amortized
time per operation.
</p>
<p>(3) A fully-dynamic algorithm that approximates all-pair effective resistance
up to an $(1+\epsilon)$ factor in $\tilde{O}(n^{2/3+o(1)} \epsilon^{-O(1)})$
amortized update time per operation.
</p>
<p>The key tool behind result (1) is the dynamic maintenance of an algorithmic
construction due to Madry [FOCS' 10], which partitions a graph into a
collection of simpler graph structures (known as j-trees) and approximately
captures the cut-flow and metric structure of the graph. The
$O(1)$-approximation guarantee of (2) is by adapting the distance oracles by
[Thorup-Zwick JACM `05]. Result (3) is obtained by invoking the random-walk
based spectral vertex sparsifier by [Durfee et al. STOC `19] in a hierarchical
manner, while carefully keeping track of the recourse among levels in the
hierarchy.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02368"><span class="datestr">at May 06, 2020 01:27 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02329">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02329">Many visits TSP revisited</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Łukasz Kowalik, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Shaohua.html">Shaohua Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nadara:Wojciech.html">Wojciech Nadara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smulewicz:Marcin.html">Marcin Smulewicz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wahlstr=ouml=m:Magnus.html">Magnus Wahlström</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02329">PDF</a><br /><b>Abstract: </b>We study the Many Visits TSP problem, where given a number $k(v)$ for each of
$n$ cities and pairwise (possibly asymmetric) integer distances, one has to
find an optimal tour that visits each city $v$ exactly $k(v)$ times. The
currently fastest algorithm is due to Berger, Kozma, Mnich and Vincze [SODA
2019, TALG 2020] and runs in time and space $\mathcal{O}^*(5^n)$. They also
show a polynomial space algorithm running in time $\mathcal{O}^*(16^{n+o(n)})$.
</p>
<p>In this work, we show three main results: (i) A randomized polynomial space
algorithm in time $\mathcal{O}^*(2^nD)$, where $D$ is the maximum distance
between two cities. By using standard methods, this results in
$(1+\epsilon)$-approximation in time $\mathcal{O}^*(2^n\epsilon^{-1})$.
Improving the constant $2$ in these results would be a major breakthrough, as
it would result in improving the $\mathcal{O}^*(2^n)$-time algorithm for
Directed Hamiltonian Cycle, which is a 50 years old open problem. (ii) A tight
analysis of Berger et al.'s exponential space algorithm, resulting in
$\mathcal{O}^*(4^n)$ running time bound. (iii) A new polynomial space
algorithm, running in time $\mathcal{O}(7.88^n)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02329"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02300">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02300">Multistage Committee Election</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bredereck:Robert.html">Robert Bredereck</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fluschnik:Till.html">Till Fluschnik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaczmarczyk:Andrzej.html">Andrzej Kaczmarczyk</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02300">PDF</a><br /><b>Abstract: </b>Electing a single committee of a small size is a classical and
well-understood voting situation. Being interested in a sequence of committees,
we introduce and study two time-dependent multistage models based on simple
Plurality voting. Therein, we are given a sequence of voting profiles (stages)
over the same set of agents and candidates, and our task is to find a small
committee for each stage of high score. In the conservative model we
additionally require that any two consecutive committees have a small symmetric
difference. Analogously, in the revolutionary model we require large symmetric
differences. We prove both models to be NP-hard even for a constant number of
agents, and, based on this, initiate a parameterized complexity analysis for
the most natural parameters and combinations thereof. Among other results, we
prove both models to be in XP yet W[1]-hard regarding the number of stages, and
that being revolutionary seems to be "easier" than being conservative: If the
(upper- resp. lower-) bound on the size of symmetric differences is constant,
the conservative model remains NP-hard while the revolutionary model becomes
polynomial-time solvable.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02300"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02238">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02238">Lower Bounds for Semi-adaptive Data Structures via Corruption</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Pavel Dvořák, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Loff:Bruno.html">Bruno Loff</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02238">PDF</a><br /><b>Abstract: </b>In a dynamic data structure problem we wish to maintain an encoding of some
data in memory, in such a way that we may efficiently carry out a sequence of
queries and updates to the data. A long-standing open problem in this area is
to prove an unconditional polynomial lower bound of a trade-off between the
update time and the query time of an adaptive dynamic data structure computing
some explicit function. Ko and Weinstein provided such lower bound for a
restricted class of {\em semi-adaptive\/} data structures, which compute the
Disjointness function. There, the data are subsets $x_1,\dots,x_k$ and $y$ of
$\{1,\dots,n\}$, the updates can modify $y$ (by inserting and removing
elements), and the queries are an index $i \in \{1,\dots,k\}$ (query $i$ should
answer whether $x_i$ and $y$ are disjoint, i.e., it should compute the
Disjointness function applied to $(x_i, y)$). The semi-adaptiveness places a
restriction in how the data structure can be accessed in order to answer a
query. We generalize the lower bound of Ko and Weinstein to work not just for
the Disjointness, but for any function having high complexity under the smooth
corruption bound.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02238"><span class="datestr">at May 06, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02218">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02218">On Reachable Assignments in Cycles and Cliques</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Luis Müller, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bentert:Matthias.html">Matthias Bentert</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02218">PDF</a><br /><b>Abstract: </b>The efficient and fair distribution of indivisible resources among agents is
a common problem in the field of \emph{Multi-Agent-Systems}. We consider a
graph-based version of this problem called Reachable Assignments, introduced by
Gourves, Lesca, and Wilczynski [AAAI, 2017]. The input for this problem
consists of a set of agents, a set of objects, the agent's preferences over the
objects, a graph with the agents as vertices and edges encoding which agents
can trade resources with each other, and an initial and a target distribution
of the objects, where each agent owns exactly one object in each distribution.
The question is then whether the target distribution is reachable via a
sequence of rational trades. A trade is rational when the two participating
agents are neighbors in the graph and both obtain an object they prefer over
the object they previously held. We show that Reachable Assignments is NP-hard
even when restricting the input graph to be a clique and develop an
$O(n^3)$-time algorithm for the case where the input graph is a cycle with $n$
vertices.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02218"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02143">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02143">A Space-Efficient Dynamic Dictionary for Multisets with Constant Time Operations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bercea:Ioana_Oriana.html">Ioana Oriana Bercea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Even:Guy.html">Guy Even</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02143">PDF</a><br /><b>Abstract: </b>We consider the dynamic dictionary problem for multisets. Given an upper
bound $n$ on the total cardinality of the multiset (i.e., including
multiplicities) at any point in time, the goal is to design a data structure
that supports multiplicity queries and allows insertions and deletions to the
multiset (i.e., the dynamic setting). The data structure must be
space-efficient (the space is $1+o(1)$ times the information-theoretic lower
bound) and support all operations in constant time with high probability.
</p>
<p>In this paper, we present the first dynamic dictionary for multisets that
achieves these performance guarantees. This answers an open problem of
Arbitman, Naor and Segev (FOCS 2010). The previously best-known construction of
Pagh, Pagh and Rao (SODA 2005) supports membership in constant time,
multiplicity queries in $O(\log n)$ time in the worst case, and insertions and
deletions in constant expected amortized time. The main technical component of
our solution is a strategy for efficiently storing variable-length binary
counters using weighted balls-into-bins experiments in which balls have
logarithmic weights.
</p>
<p>We also obtain a counting filter that approximates multiplicity queries with
a one sided error, using the reduction of Carter et al. (STOC 1978). Counting
filters have received significant attention over the years due to their
applicability in practice.We present the first counting filter with constant
time operations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02143"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.02082">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.02082">Grid Drawings of Graphs with Constant Edge-Vertex Resolution</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bekos:Michael_A=.html">Michael A. Bekos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gronemann:Martin.html">Martin Gronemann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montecchiani:Fabrizio.html">Fabrizio Montecchiani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Symvonis:Antonios.html">Antonios Symvonis</a>, Leonidas Theocharous <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.02082">PDF</a><br /><b>Abstract: </b>We study the algorithmic problem of computing drawings of graphs in which (i)
each vertex is a disk with constant radius r, (ii) each edge is a straight-line
segment connecting the centers of the two disks representing its end-vertices,
(iii) no two disks intersect, and (iv) the edge-vertex resolution is at least
r, that is, no edge segment intersects a non-adjacent disk. We call such
drawings disk-link drawings. This model is motivated by the fact that common
graph editors represent vertices as geometric features (usually either as disks
or as squares) of fixed size. In this scenario, vertex-vertex and edge-vertex
overlaps cause visual clutter and may generate ambiguities. Since such issues
can be solved by scaling up the drawing by a suitable factor, we present
constructive techniques that yield more compact upper bounds for the area
requirements of disk-link drawings for several (planar and nonplanar) graph
classes, including proper level, bounded bandwidth, complete, planar and
outerplanar graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.02082"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01982">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01982">Envy-free cake cutting: A polynomial number of queries with high probability</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Ch=egrave=ze:Guillaume.html">Guillaume Chèze</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01982">PDF</a><br /><b>Abstract: </b>In this article we propose a probabilistic framework in order to study the
fair division of a divisible good, e.g. a cake, between n players. Our
framework follows the same idea than the ''Full independence model'' used in
the study of fair division of indivisible goods. We show that, in this
framework, there exists an envy-free division algorithm satisfying the
following probability estimate:$$\mathbb{P}\big( C(\mu_1, \ldots,\mu_n) \geq
n^{7+b}\big) = \mathcal{O}\Big(n^{-\frac{b-1}{3}+1+o(1)}\Big),$$where
$\mu_1,\ldots, \mu_n$ correspond to the preferences of the $n$
players,$C(\mu_1, \ldots,\mu_n)$ is the number of queries used by the algorithm
and $b&gt;4$.In particular, this gives$$\lim_{n \rightarrow +
\infty}\mathbb{P}\big( C(\mu_1, \ldots,\mu_n) \geq n^{12}\big) = 0.$$It must be
noticed that nowadays few things are known about the complexity of envy-free
division algorithms. Indeed, Procaccia has given a lower bound in $\Omega(n^2)$
and Aziz and Mackenzie have given an upper bound in $n^{n^{n^{n^{n^{n}}}}}$. As
our estimate means that we have $C(\mu_1, \ldots, \mu_n)&lt;n^{12}$ with a high
probability, this gives a new insight on the complexity of envy-free cake
cutting algorithms.\\Our result follows from a study of Webb's algorithm and a
theorem of Tao and Vu about the smallest singular value of a random matrix.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01982"><span class="datestr">at May 06, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01929">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01929">Edge-Weighted Online Bipartite Matching</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fahrbach:Matthew.html">Matthew Fahrbach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Zhiyi.html">Zhiyi Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Runzhou.html">Runzhou Tao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zadimoghaddam:Morteza.html">Morteza Zadimoghaddam</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01929">PDF</a><br /><b>Abstract: </b>Online bipartite matching and its variants are among the most fundamental
problems in the online algorithms literature. Karp, Vazirani, and Vazirani
(STOC 1990) introduced an elegant algorithm for the unweighted problem that
achieves an optimal competitive ratio of $1-1/e$. Later, Aggarwal et al. (SODA
2011) generalized their algorithm and analysis to the vertex-weighted case.
Little is known, however, about the most general edge-weighted problem aside
from the trivial $1/2$-competitive greedy algorithm. In this paper, we present
the first online algorithm that breaks the long-standing $1/2$ barrier and
achieves a competitive ratio of at least $0.5086$. In light of the hardness
result of Kapralov, Post, and Vondr\'ak (SODA 2013) that restricts beating a
$1/2$ competitive ratio for the more general problem of monotone submodular
welfare maximization, our result can be seen as strong evidence that
edge-weighted bipartite matching is strictly easier than submodular welfare
maximization in the online setting.
</p>
<p>The main ingredient in our online matching algorithm is a novel subroutine
called online correlated selection (OCS), which takes a sequence of pairs of
vertices as input and selects one vertex from each pair. Instead of using a
fresh random bit to choose a vertex from each pair, the OCS negatively
correlates decisions across different pairs and provides a quantitative measure
on the level of correlation. We believe our OCS technique is of independent
interest and will find further applications in other online optimization
problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01929"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01921">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01921">Helly-gap of a graph and vertex eccentricities</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dragan:Feodor_F=.html">Feodor F. Dragan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guarnera:Heather_M=.html">Heather M. Guarnera</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01921">PDF</a><br /><b>Abstract: </b>A new metric parameter for a graph, Helly-gap, is introduced. A graph $G$ is
called $\alpha$-weakly-Helly if any system of pairwise intersecting disks in
$G$ has a nonempty common intersection when the radius of each disk is
increased by an additive value $\alpha$. The minimum $\alpha$ for which a graph
$G$ is $\alpha$-weakly-Helly is called the Helly-gap of $G$ and denoted by
$\alpha(G)$. The Helly-gap of a graph $G$ is characterized by distances in the
injective hull $\mathcal{H}(G)$, which is a (unique) minimal Helly graph which
contains $G$ as an isometric subgraph. This characterization is used as a tool
to generalize many eccentricity related results known for Helly graphs
($\alpha(G)=0$), as well as for chordal graphs ($\alpha(G)\le 1$),
distance-hereditary graphs ($\alpha(G)\le 1$) and $\delta$-hyperbolic graphs
($\alpha(G)\le 2\delta$), to all graphs, parameterized by their Helly-gap
$\alpha(G)$. Several additional graph classes are shown to have a bounded
Helly-gap, including AT-free graphs and graphs with bounded tree-length,
bounded chordality or bounded $\alpha_i$-metric.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01921"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01867">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01867">Advice for Online Knapsack With Removable Items</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/B=ouml=ckenhauer:Hans=Joachim.html">Hans-Joachim Böckenhauer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dreier:Jan.html">Jan Dreier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frei:Fabian.html">Fabian Frei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rossmanith:Peter.html">Peter Rossmanith</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01867">PDF</a><br /><b>Abstract: </b>In the proportional knapsack problem, we are given a knapsack of some
capacity and a set of variably sized items. The goal is to pack some of these
items such that they fill the knapsack as much as possible without ever
exceeding the capacity. The online version of this problem reveals the items
and their sizes not all at once but one by one. For each item, the algorithm
has to decide immediately whether to pack it or not. We consider a natural
variant of this online knapsack problem, which has been coined removable
knapsack and we denote by RemKnap. It differs from the classical variant by
allowing the removal of any packed item from the knapsack. Repacking is
impossible, however: Once an item is removed, it is gone for good.
</p>
<p>We analyze the advice complexity of this problem. It measures how many advice
bits an omniscient oracle needs to provide for an online algorithm to reach any
given competitive ratio, which is--understood in its strict sense--just the
algorithm's approximation factor. The online knapsack problem without
removability is known for its peculiar advice behavior involving three jumps in
competitivity. We show that the advice complexity of RemKnap is quite different
but just as interesting. The competitivity starts from the golden ratio when no
advice is given. It then drops down in small increments to (1 + epsilon) for a
constant amount of advice already, which requires logarithmic advice in the
classical version. Removability comes as no relief to the perfectionist,
however: Optimality still requires one full advice bit for every single item in
the instance as before.
</p>
<p>These results are particularly noteworthy from a structural viewpoint for the
exceptionally slow transition from near-optimality to optimality; such a steep
jump up from constant to full linear advice for just an infinitesimally small
improvement is unique among the online problems examined so far.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01867"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01861">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01861">Sampling Arbitrary Subgraphs Exactly Uniformly in Sublinear Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fichtenberger:Hendrik.html">Hendrik Fichtenberger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Mingze.html">Mingze Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Pan.html">Pan Peng</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01861">PDF</a><br /><b>Abstract: </b>We present a simple sublinear-time algorithm for sampling an arbitrary
subgraph $H$ \emph{exactly uniformly} from a graph $G$, to which the algorithm
has access by performing the following types of queries: (1) uniform vertex
queries, (2) degree queries, (3) neighbor queries, (4) pair queries and (5)
edge sampling queries. The query complexity and running time of our algorithm
are $\tilde{O}(\min\{m, \frac{m^{\rho(H)}}{\# H}\})$ and
$\tilde{O}(\frac{m^{\rho(H)}}{\# H})$, respectively, where $\rho(H)$ is the
fractional edge-cover of $H$ and $\# H$ is the number of copies of $H$ in $G$.
For any clique on $r$ vertices, i.e., $H=K_r$, our algorithm is almost optimal
as any algorithm that samples an $H$ from any distribution that has $\Omega(1)$
total probability mass on the set of all copies of $H$ must perform
$\Omega(\min\{m, \frac{m^{\rho(H)}}{\# H\cdot (cr)^r}\})$ queries.
</p>
<p>Together with the query and time complexities of the $(1\pm
\varepsilon)$-approximation algorithm for the number of subgraphs $H$ by
Assadi, Kapralov and Khanna [ITCS 2018] and the lower bound by Eden and
Rosenbaum [APPROX 2018] for approximately counting cliques, our results suggest
that in our query model, approximately counting cliques is ``equivalent to''
exactly uniformly sampling cliques, in the sense that the query and time
complexities of exactly uniform sampling and randomized approximate counting
are within a polylogarithmic factor of each other. This stands in interesting
contrast to an analogous relation between approximate counting and almost
uniformly sampling for self-reducible problems in the polynomial-time regime by
Jerrum, Valiant and Vazirani [TCS 1986].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01861"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01824">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01824">Complexity of $C_k$-coloring in hereditary classes of graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chudnovsky:Maria.html">Maria Chudnovsky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Shenwei.html">Shenwei Huang</a>, Paweł Rzążewski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Spirkl:Sophie.html">Sophie Spirkl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Mingxian.html">Mingxian Zhong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01824">PDF</a><br /><b>Abstract: </b>For a graph $F$, a graph $G$ is \emph{$F$-free} if it does not contain an
induced subgraph isomorphic to $F$. For two graphs $G$ and $H$, an
\emph{$H$-coloring} of $G$ is a mapping $f:V(G)\rightarrow V(H)$ such that for
every edge $uv\in E(G)$ it holds that $f(u)f(v)\in E(H)$. We are interested in
the complexity of the problem $H$-{\sc Coloring}, which asks for the existence
of an $H$-coloring of an input graph $G$. In particular, we consider $H$-{\sc
Coloring} of $F$-free graphs, where $F$ is a fixed graph and $H$ is an odd
cycle of length at least 5. This problem is closely related to the well known
open problem of determining the complexity of 3-{\sc Coloring} of $P_t$-free
graphs.
</p>
<p>We show that for every odd $k \geq 5$ the $C_k$-{\sc Coloring} problem, even
in the list variant, can be solved in polynomial time in $P_9$-free graphs. The
algorithm extends for the case of list version of $C_k$-{\sc Coloring}, where
$k$ is an even number of length at least 10.
</p>
<p>On the other hand, we prove that if some component of $F$ is not a subgraph
of a subdividecd claw, then the following problems are NP-complete in $F$-free
graphs: a)extension version of $C_k$-{\sc Coloring} for every odd $k \geq 5$,
b) list version of $C_k$-{\sc Coloring} for every even $k \geq 6$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01824"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01778">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01778">Determining the Multiplicative Complexity of Boolean Functions using SAT</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Soeken:Mathias.html">Mathias Soeken</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01778">PDF</a><br /><b>Abstract: </b>We present a constructive SAT-based algorithm to determine the multiplicative
complexity of a Boolean function, i.e., the smallest number of AND gates in any
logic network that consists of 2-input AND gates, 2-input XOR gates, and
inverters. In order to speed-up solving time, we make use of several symmetry
breaking constraints; these exploit properties of XAGs that may be useful
beyond the proposed SAT-based algorithm. We further propose a heuristic
post-optimization algorithm to reduce the number of XOR gates once the optimum
number of AND gates has been obtained, which also makes use of SAT solvers. Our
algorithm is capable to find all optimum XAGs for representatives of all
5-input affine-equivalent classes, and for a set of frequently occurring
6-input functions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01778"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01757">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01757">Sample Complexity of Uniform Convergence for Multicalibration</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Eliran Shabat, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Lee.html">Lee Cohen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mansour:Yishay.html">Yishay Mansour</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01757">PDF</a><br /><b>Abstract: </b>There is a growing interest in societal concerns in machine learning systems,
especially in fairness. Multicalibration gives a comprehensive methodology to
address group fairness. In this work, we address the multicalibration error and
decouple it from the prediction error. The importance of decoupling the
fairness metric (multicalibration) and the accuracy (prediction error) is due
to the inherent trade-off between the two, and the societal decision regarding
the "right tradeoff" (as imposed many times by regulators). Our work gives
sample complexity bounds for uniform convergence guarantees of multicalibration
error, which implies that regardless of the accuracy, we can guarantee that the
empirical and (true) multicalibration errors are close. We emphasize that our
results: (1) are more general than previous bounds, as they apply to both
agnostic and realizable settings, and do not rely on a specific type of
algorithm (such as deferentially private), (2) improve over previous
multicalibration sample complexity bounds and (3) implies uniform convergence
guarantees for the classical calibration error.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01757"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00575">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00575">Approximating maximum integral multiflows on bounded genus graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Chien-chung Huang, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mari:Mathieu.html">Mathieu Mari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mathieu:Claire.html">Claire Mathieu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vygen:Jens.html">Jens Vygen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00575">PDF</a><br /><b>Abstract: </b>We devise the first constant-factor approximation algorithm for finding an
integral multi-commodity flow of maximum total value for instances where the
supply graph together with the demand edges can be embedded on an orientable
surface of bounded genus. This extends recent results for planar instances.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00575"><span class="datestr">at May 06, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/073">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/073">TR20-073 |  Lower Bounds on OBDD Proofs with Several Orders | 

	Dmitry Itsykson, 

	Sam Buss, 

	Dmitry Sokolov, 

	Alexander Knop, 

	Artur Riazanov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
This paper is motivated by seeking lower bounds on OBDD($\land$, weakening, reordering) refutations, namely OBDD refutations that allow weakening and arbitrary reorderings. We first work with 1-NBP($\land$) refutations based on read-once nondeterministic branching programs. These generalize OBDD($\land$, reordering) refutations. There are polynomial size 1-NBP($\land$) refutations of the pigeonhole principle, hence 1-NBP($\land$) is strictly stronger than OBDD($\land$, reordering). There are also formulas that have polynomial size tree-like resolution refutations but require exponential size 1-NBP($\land$) refutations. As a corollary, OBDD($\land$, reordering) does not simulate tree-like resolution, answering a previously open question.

The system 1-NBP($\land$, $\exists$) uses projection inferences instead of weakening. 1-NBP($\land$, $\exists_k$) is the system restricted to projection on at most $k$ distinct variables. We construct explicit constant degree graphs $G_n$ on $n$ vertices and an $\epsilon &gt; 0$, such that 1-NBP($\land$, $\exists_{\epsilon n}$) refutations of the Tseitin formula for $G_n$ require exponential size.

Second, we study the proof system OBDD($\land$, weakening, reordering$_\ell$) which allows $\ell$ different variable orders in a refutation. We prove an exponential lower bound on the complexity of tree-like OBDD($\land$, weakening, reordering$_\ell$) refutations for $\ell = \epsilon \log n$, where $n$ is the number of variables and $\epsilon &gt; 0$ is a constant. The lower bound is based on multiparty communication complexity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/073"><span class="datestr">at May 05, 2020 06:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5609460581142399437">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html">Why is there no (d,n) grid for Hilbert's Tenth Problem?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
Hilbert's 10th problem, in modern language is:<br />
<br />
Find an algorithm that will, given a poly over Z in many variables, determine if it has a solution in Z.<br />
<br />
This problem was proven undecidable through the work of Davis, Putnam, Robinson and then<br />
Matiyasevich supplied the last crucial part of the proof.<br />
<br />
Let H10(d,n) be the problem with degree d and n variables.<br />
<br />
I had assumed that somewhere on the web would be a grid where the dth row, nth col has<br />
<br />
U if  H10(d,n) is undecidable<br />
<br />
D if H10(d,n) is decidable<br />
<br />
? if the status of H10(d,n) was unknown.<br />
<br />
I found no grid. I then collected up all the results I could find <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/h10.pdf">here</a><br />
<br />
This lead to the (non-math) question: Why is there no grid out there? Here are my speculations.<br />
<br />
1) Logicians worked on proving particular (d,n) are undecidable. They sought solutions in N. By contrast number theorists worked on proving particular (d,n) decidable. They sought solutions in Z.. Hence a grid would need to reconcile these two related problems.<br />
<br />
<div>
<div>
2) Logicians and number theorists didn't talk to each other. Websites and books on Hilbert's Tenth problem do not mention any solvable cases of it.</div>
</div>
<div>
<br /></div>
<div>
<div>
3) There is a real dearth of positive results, so a grid would not be that interesting. Note that we do not even know if the following is decidable: given k in Z does there exists x,y,z in Z such that</div>
<div>
<br /></div>
<div>
x^3 +y^3+ z^3 = k. I blogged about that <a href="https://blog.computationalcomplexity.org/2019/04/x-3-y-3-z-3-33-has-solution-in-z-and.html">here</a></div>
</div>
<div>
<br /></div>
<div>
4) For an undecidable result for (d,n) if you make n small then all of the results make d very large.</div>
<div>
<br /></div>
<div>
For example</div>
<div>
<br /></div>
<div>
n=9, d= 1.6 x 10^{45}  is undecidable. The status of n=9, d=1.6 x 10^{45} -1 is unknown.</div>
<div>
<br /></div>
<div>
Hence the grid would be hard to draw.</div>
<div>
<br /></div>
<div>
Frankly I don't really want a grid. I really want a sense of what open problems might be solved. I think progress has gone in other directions- H10 over other domains. Oh well, I want to know about</div>
<div>
<br /></div>
<div>
n=9 and d=1.6 x 10^{45}-1. (parenthesis ambiguous but either way would be an advance.)</div>
<div>
<br /></div>
<div>
<br /></div>
<div>
<br /></div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/05/why-is-there-no-dn-grid-for-hilberts.html"><span class="datestr">at May 05, 2020 04:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=48">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/">Friday, May 15 — Amin Karbasi from Yale University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The fourth Foundations of Data Science virtual talk will take place on Friday, May 15th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Amin Karbasi </strong>from Yale University will speak about “<em>User-Friendly Submodular Maximization</em>”.</p>



<p class="has-text-align-left"><strong>Abstract</strong>: Submodular functions model the intuitive notion of diminishing returns. Due to their far-reaching applications, they have been rediscovered in many fields such as information theory, operations research, statistical physics, economics, and machine learning. They also enjoy computational tractability as they can be minimized exactly or maximized approximately.</p>



<p>The goal of this talk is simple. We see how a little bit of randomness, a little bit of greediness, and the right combination can lead to pretty good methods for offline, streaming, and distributed solutions. I do not assume any background on submodularity and try to explain all the required details during the talk.</p>



<p><a href="https://sites.google.com/view/dstheory" target="_blank" rel="noreferrer noopener">Please register here to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/05/05/friday-may-15-amin-karbasi-from-yale-university/"><span class="datestr">at May 05, 2020 01:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/072">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/072">TR20-072 |  Locally testable codes via high-dimensional expanders | 

	Irit Dinur, 

	Prahladh Harsha, 

	Yotam Dikstein, 

	Noga Ron-Zewi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Locally testable codes (LTC) are error-correcting codes that have a local tester which can distinguish valid codewords from words that are far from all codewords, by probing a given word only at a very small (sublinear, typically constant) number of locations. Such codes form the combinatorial backbone of PCPs. A major open problem is whether there exist LTCs with positive rate, constant relative distance and testable with a constant number of queries. 

In this paper, we present a new approach towards constructing such LTCs using the machinery of high-dimensional expanders. 
To this end, we consider the Tanner representation of a code, which is specified by a graph and a base code. Informally, our result states that if this graph is part of an {\em agreement expander} then the local testability of the code follows from the local testability of the base code. Agreement expanders allow one to stitch together many mostly-consistent local functions into a single global function. High-dimensional expanders are known to yield agreement expanders with constant degree. 

This work unifies and generalizes the known results on testability of the Hadamard, Reed-Muller and lifted codes, all of which are proved via a single round of local self-correction: the corrected value at a vertex v depends on the values of all vertices that share a constraint with v. In the above codes this set includes all of the vertices. In contrast, in our setting the degree of a vertex might be a constant, so we cannot hope for one-round self-correction. We overcome this technical hurdle by performing iterative self correction with logarithmically many rounds and tightly controlling the error in each iteration using properties of the agreement expander.

Given this result, the missing ingredient towards constructing a constant-query LTC with positive rate and constant relative distance is an instantiation of a base code and a constant-degree agreement expander that interact well with each other.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/072"><span class="datestr">at May 05, 2020 12:09 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01242">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01242">Probabilistic Analysis of RRT Trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Konrad Anand, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Devroye:Luc.html">Luc Devroye</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01242">PDF</a><br /><b>Abstract: </b>This thesis presents analysis of the properties and run-time of the
Rapidly-exploring Random Tree (RRT) algorithm. It is shown that the time for
the RRT with stepsize $\epsilon$ to grow close to every point in the
$d$-dimensional unit cube is $\Theta\left(\frac1{\epsilon^d} \log
\left(\frac1\epsilon\right)\right)$. Also, the time it takes for the tree to
reach a region of positive probability is $O\left(\epsilon^{-\frac32}\right)$.
Finally, a relationship is shown to the Nearest Neighbour Tree (NNT). This
relationship shows that the total Euclidean path length after $n$ steps is
$O(\sqrt n)$ and the expected height of the tree is bounded above by $(e +
o(1)) \log n$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01242"><span class="datestr">at May 05, 2020 10:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01182">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01182">A Study of Performance of Optimal Transport</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dong:Yihe.html">Yihe Dong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Yu.html">Yu Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Richard.html">Richard Peng</a>, Ilya Razenshteyn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sawlani:Saurabh.html">Saurabh Sawlani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01182">PDF</a><br /><b>Abstract: </b>We investigate the problem of efficiently computing optimal transport (OT)
distances, which is equivalent to the node-capacitated minimum cost maximum
flow problem in a bipartite graph. We compare runtimes in computing OT
distances on data from several domains, such as synthetic data of geometric
shapes, embeddings of tokens in documents, and pixels in images. We show that
in practice, combinatorial methods such as network simplex and augmenting path
based algorithms can consistently outperform numerical matrix-scaling based
methods such as Sinkhorn [Cuturi'13] and Greenkhorn [Altschuler et al'17], even
in low accuracy regimes, with up to orders of magnitude speedups. Lastly, we
present a new combinatorial algorithm that improves upon the classical
Kuhn-Munkres algorithm.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01182"><span class="datestr">at May 05, 2020 10:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01112">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01112">Efficiently Testing Simon's Congruence</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gawrychowski:Pawel.html">Pawel Gawrychowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kosche:Maria.html">Maria Kosche</a>, Tore Koss, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manea:Florin.html">Florin Manea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Siemer:Stefan.html">Stefan Siemer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01112">PDF</a><br /><b>Abstract: </b>Simon's congruence $\sim_k$ is defined as follows: two words are
$\sim_k$-equivalent if they have the same set of subsequences of length at most
$k$. We propose an algorithm which computes, given two words $s$ and $t$, the
largest $k$ for which $s\sim_k t$. Our algorithm runs in linear time
$O(|s|+|t|)$ when the input words are over the integer alphabet
$\{1,\ldots,|s|+|t|\}$ (or other alphabets which can be sorted in linear time).
This approach leads to an optimal algorithm in the case of general alphabets as
well. Our results are based on a novel combinatorial approach and a series of
efficient data structures.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01112"><span class="datestr">at May 05, 2020 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01098">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01098">A Dynamic Space-Efficient Filter with Constant Time Operations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bercea:Ioana_Oriana.html">Ioana Oriana Bercea</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Even:Guy.html">Guy Even</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01098">PDF</a><br /><b>Abstract: </b>A dynamic dictionary is a data structure that maintains sets of cardinality
at most $n$ from a given universe and supports insertions, deletions, and
membership queries. A filter approximates membership queries with a one-sided
error that occurs with probability at most $\epsilon$. The goal is to obtain
dynamic filters that are space-efficient (the space is $1+o(1)$ times the
information-theoretic lower bound) and support all operations in constant time
with high probability. One approach to designing filters is to reduce to the
retrieval problem. When the size of the universe is polynomial in $n$, this
approach yields a space-efficient dynamic filter as long as the error parameter
$\epsilon$ satisfies $\log(1/\epsilon) = \omega(\log\log n)$.
</p>
<p>For the case that $\log(1/\epsilon) = O(\log\log n)$, we present the first
space-efficient dynamic filter with constant time operations in the worst case
(whp). In contrast, the space-efficient dynamic filter of Pagh, Pagh, Rao (SODA
2005) supports insertions and deletions in amortized expected constant time.
Our approach employs the classic reduction of Carter et al. (STOC 1978) on a
new type of dictionary construction that supports random multisets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01098"><span class="datestr">at May 05, 2020 10:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01045">Locally testable codes via high-dimensional expanders</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dikstein:Yotam.html">Yotam Dikstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dinur:Irit.html">Irit Dinur</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harsha:Prahladh.html">Prahladh Harsha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ron=Zewi:Noga.html">Noga Ron-Zewi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01045">PDF</a><br /><b>Abstract: </b>Locally testable codes (LTC) are error-correcting codes that have a local
tester which can distinguish valid codewords from words that are "far" from all
codewords by probing a given word only at a very few (sublinear, typically
constant) number of locations. Such codes form the combinatorial backbone of
PCPs. A major open problem is whether there exist LTCs with positive rate,
constant relative distance and testable with a constant number of queries.
</p>
<p>In this paper, we present a new approach towards constructing such LTCs using
the machinery of high-dimensional expanders. To this end, we consider the
Tanner representation of a code, which is specified by a graph and a base code.
Informally, our result states that if this graph is part of a high-dimensional
expander then the local testability of the code follows from the local
testability of the base code.
</p>
<p>This work unifies and generalizes the known results on testability of the
Hadamard, Reed-Muller and lifted codes on the Subspace Complex, all of which
are proved via local self correction. However, unlike previous results,
constant rounds of self correction do not suffice as the diameter of the
underlying test graph can be logarithmically large in a high-dimensional
expander and not constant as in all known earlier results. We overcome this
technical hurdle by performing iterative self correction with logarithmically
many rounds and tightly controlling the error in each iteration using
properties of the high-dimensional expander.
</p>
<p>Given this result, the missing ingredient towards constructing a
constant-query LTC with positive rate and constant relative distance is an
instantiation of a base code that interacts well with a constant-degree
high-dimensional expander.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01045"><span class="datestr">at May 05, 2020 10:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.01003">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.01003">Variational Shape Approximation of Point Set Surfaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skrodzki:Martin.html">Martin Skrodzki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zimmermann:Eric.html">Eric Zimmermann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Polthier:Konrad.html">Konrad Polthier</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.01003">PDF</a><br /><b>Abstract: </b>In this work, we present a translation of the complete pipeline for
variational shape approximation (VSA) to the setting of point sets. First, we
describe an explicit example for the theoretically known non-convergence of the
currently available VSA approaches. The example motivates us to introduce an
alternate version of VSA based on a switch operation for which we prove
convergence. Second, we discuss how two operations - split and merge - can be
included in a fully automatic pipeline that is in turn independent of the
placement and number of initial seeds. Third and finally, we present two
approaches how to obtain a simplified mesh from the output of the VSA
procedure. This simplification is either based on simple plane intersection or
based on a variational optimization problem. Several qualitative and
quantitative results prove the relevance of our approach.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.01003"><span class="datestr">at May 05, 2020 10:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00947">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00947">Online Learning and Optimization for Revenue Management Problems with Add-on Discounts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simchi=Levi:David.html">David Simchi-Levi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Rui.html">Rui Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Huanan.html">Huanan Zhang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00947">PDF</a><br /><b>Abstract: </b>We study in this paper a revenue management problem with add-on discounts.
The problem is motivated by the practice in the video game industry, where a
retailer offers discounts on selected supportive products (e.g. video games) to
customers who have also purchased the core products (e.g. video game consoles).
We formulate this problem as an optimization problem to determine the prices of
different products and the selection of products with add-on discounts. To
overcome the computational challenge of this optimization problem, we propose
an efficient FPTAS algorithm that can solve the problem approximately to any
desired accuracy. Moreover, we consider the revenue management problem in the
setting where the retailer has no prior knowledge of the demand functions of
different products. To resolve this problem, we propose a UCB-based learning
algorithm that uses the FPTAS optimization algorithm as a subroutine. We show
that our learning algorithm can converge to the optimal algorithm that has
access to the true demand functions, and we prove that the convergence rate is
tight up to a certain logarithmic term. In addition, we conduct numerical
experiments with the real-world transaction data we collect from a popular
video gaming brand's online store on Tmall.com. The experiment results
illustrate our learning algorithm's robust performance and fast convergence in
various scenarios. We also compare our algorithm with the optimal policy that
does not use any add-on discount, and the results show the advantages of using
the add-on discount strategy in practice.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00947"><span class="datestr">at May 05, 2020 10:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00937">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00937">Simultaneous Visibility Representations of Undirected Pairs of Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chugg:Ben.html">Ben Chugg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Evans:William_S=.html">William S. Evans</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wong:Kelvin.html">Kelvin Wong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00937">PDF</a><br /><b>Abstract: </b>We consider the problem of determining if a pair of undirected graphs
$\langle G_\mathsf{V}, G_\mathsf{H} \rangle$, which share the same vertex set,
has a representation using opaque geometric shapes for vertices, and
vertical/horizontal visibility between shapes to determine the edges of
$G_\mathsf{V}$/$G_\mathsf{H}$. While such a simultaneous visibility
representation of two graphs can be determined efficiently if the direction of
the required visibility for each edge is provided (and the vertex shapes are
sufficiently simple), it was unclear if edge direction is critical for
efficiency. We show that the problem is $\mathsf{NP}$-complete without that
information, even for graphs that are only slightly more complex than paths. In
addition, we characterize which pairs of paths have simultaneous visibility
representations using fixed orientation L-shapes. This narrows the range of
possible graph families for which determining simultaneous visibility
representation is non-trivial yet not $\mathsf{NP}$-hard.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00937"><span class="datestr">at May 05, 2020 10:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00880">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00880">Almost Universal Anonymous Rendezvous in the Plane</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bouchard:S=eacute=bastien.html">Sébastien Bouchard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dieudonn=eacute=:Yoann.html">Yoann Dieudonné</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pelc:Andrzej.html">Andrzej Pelc</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petit:Franck.html">Franck Petit</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00880">PDF</a><br /><b>Abstract: </b>Two mobile agents represented by points freely moving in the plane and
starting at two distinct positions, have to meet. The meeting, called
rendezvous, occurs when agents are at distance at most $r$ of each other and
never move after this time, where $r$ is a positive real unknown to them,
called the visibility radius. Agents are anonymous and execute the same
deterministic algorithm. Each agent has a set of private attributes, some or
all of which can differ between agents. These attributes are: the initial
position of the agent, its system of coordinates (orientation and chirality),
the rate of its clock, its speed when it moves, and the time of its wake-up. If
all attributes (except the initial positions) are identical and agents start at
distance larger than $r$ then they can never meet. However, differences between
attributes make it sometimes possible to break the symmetry and accomplish
rendezvous. Such instances of the rendezvous problem (formalized as lists of
attributes), are called feasible.
</p>
<p>Our contribution is three-fold. We first give an exact characterization of
feasible instances. Thus it is natural to ask whether there exists a single
algorithm that guarantees rendezvous for all these instances. We give a strong
negative answer to this question: we show two sets $S_1$ and $S_2$ of feasible
instances such that none of them admits a single rendezvous algorithm valid for
all instances of the set. On the other hand, we construct a single algorithm
that guarantees rendezvous for all feasible instances outside of sets $S_1$ and
$S_2$. We observe that these exception sets $S_1$ and $S_2$ are geometrically
very small, compared to the set of all feasible instances: they are included in
low-dimension subspaces of the latter. Thus, our rendezvous algorithm handling
all feasible instances other than these small sets of exceptions can be justly
called almost universal.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00880"><span class="datestr">at May 05, 2020 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00875">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00875">Deterministic Treasure Hunt in the Plane with Angular Hints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bouchard:S=eacute=bastien.html">Sébastien Bouchard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dieudonn=eacute=:Yoann.html">Yoann Dieudonné</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pelc:Andrzej.html">Andrzej Pelc</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Petit:Franck.html">Franck Petit</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00875">PDF</a><br /><b>Abstract: </b>A mobile agent equipped with a compass and a measure of length has to find an
inert treasure in the Euclidean plane. Both the agent and the treasure are
modeled as points. In the beginning, the agent is at a distance at most $D&gt;0$
from the treasure, but knows neither the distance nor any bound on it. Finding
the treasure means getting at distance at most 1 from it. The agent makes a
series of moves. Each of them consists in moving straight in a chosen direction
at a chosen distance. In the beginning and after each move the agent gets a
hint consisting of a positive angle smaller than $2\pi$ whose vertex is at the
current position of the agent and within which the treasure is contained. We
investigate the problem of how these hints permit the agent to lower the cost
of finding the treasure, using a deterministic algorithm, where the cost is the
worst-case total length of the agent's trajectory. It is well known that
without any hint the optimal (worst case) cost is $\Theta(D^2)$. We show that
if all angles given as hints are at most $\pi$, then the cost can be lowered to
$O(D)$, which is optimal. If all angles are at most $\beta$, where $\beta&lt;2\pi$
is a constant unknown to the agent, then the cost is at most
$O(D^{2-\epsilon})$, for some $\epsilon&gt;0$. For both these positive results we
present deterministic algorithms achieving the above costs. Finally, if angles
given as hints can be arbitrary, smaller than $2\pi$, then we show that cost
$\Theta(D^2)$ cannot be beaten.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00875"><span class="datestr">at May 05, 2020 10:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00858">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00858">Minimum Cuts in Geometric Intersection Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cabello:Sergio.html">Sergio Cabello</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00858">PDF</a><br /><b>Abstract: </b>Let $\mathcal{D}$ be a set of $n$ disks in the plane. The \emph{disk graph}
$G_\mathcal{D}$ for $\mathcal{D}$ is the undirected graph with vertex set
$\mathcal{D}$ in which two disks are joined by an edge if and only if they
intersect. The \emph{directed transmission graph} $G^{\rightarrow}_\mathcal{D}$
for $\mathcal{D}$ is the directed graph with vertex set $\mathcal{D}$ in which
there is an edge from a disk $D_1 \in \mathcal{D}$ to a disk $D_2 \in
\mathcal{D}$ if and only if $D_1$ contains the center of $D_2$.
</p>
<p>Given $\mathcal{D}$ and two non-intersecting disks $s, t \in \mathcal{D}$, we
show that a minimum $s$-$t$ vertex cut in $G_\mathcal{D}$ or in
$G^{\rightarrow}_\mathcal{D}$ can be found in $O(n^{3/2}\operatorname{polylog}
n)$ expected time. To obtain our result, we combine an algorithm for the
maximum flow problem in general graphs with dynamic geometric data structures
to manipulate the disks.
</p>
<p>As an application, we consider the \emph{barrier resilience problem} in a
rectangular domain. In this problem, we have a vertical strip $S$ bounded by
two vertical lines, $L_\ell$ and $L_r$, and a collection $\mathcal{D}$ of
disks. Let $a$ be a point in $S$ above all disks of \mathcal{D}, and let $b$ a
point in $S$ below all disks of $\mathcal{D}$. The task is to find a curve from
$a$ to $b$ that lies in $S$ and that intersects as few disks of $\mathcal{D}$
as possible. Using our improved algorithm for minimum cuts in disk graphs, we
can solve the barrier resilience problem in $O(n^{3/2}\operatorname{polylog}
n)$ expected time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00858"><span class="datestr">at May 05, 2020 10:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00853">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00853">Lower Bounds for Non-Elitist Evolutionary Algorithms Via Negative Multiplicative Drift</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doerr:Benjamin.html">Benjamin Doerr</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00853">PDF</a><br /><b>Abstract: </b>A decent number of lower bounds for non-elitist population-based evolutionary
algorithms has been shown by now. Most of them are technically demanding due to
the (hard to avoid) use of negative drift theorems -- general results which
translate an expected progress away from the target into a high hitting time.
</p>
<p>We propose a simple negative drift theorem for multiplicative drift scenarios
and show that it simplifies many existing results. We discuss in more detail
Lehre's (PPSN 2010) \emph{negative drift in populations} method, one of the
most general tools to prove lower bounds on the runtime of non-elitist
evolutionary algorithms. Together with other arguments, we obtain an
alternative and simpler proof, which also strengthens and simplifies this
method. In particular, now only three of the five technical conditions of the
previous result have to be verified. The lower bounds we obtain are explicit
instead of only asymptotic. This allows to compute concrete lower bounds for
concrete algorithms, but also enables us to show that super-polynomial runtimes
appear already when the reproduction rate is only a $(1 - \omega(n^{-1/2}))$
factor below the threshold. As one particular result, we apply this method, for
the first time, to an algorithm using fitness-proportionate selection.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00853"><span class="datestr">at May 05, 2020 10:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00690">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00690">Independent Set on P$_k$-Free Graphs in Quasi-Polynomial Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Peter Gartland, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00690">PDF</a><br /><b>Abstract: </b>We present an algorithm that takes as input a graph $G$ with weights on the
vertices, and computes a maximum weight independent set $S$ of $G$. If the
input graph $G$ excludes a path $P_k$ on $k$ vertices as an induced subgraph,
the algorithm runs in time $n^{O(k^2 \log^3 n)}$. Hence, for every fixed $k$
our algorithm runs in quasi-polynomial time. This resolves in the affirmative
an open problem of [Thomass\'{e}, SODA'20 invited presentation]. Previous to
this work, polynomial time algorithms were only known for $P_4$-free graphs
[Corneil et al., DAM'81], $P_5$-free graphs [Lokshtanov et al., SODA'14], and
$P_6$-free graphs [Grzesik et al., SODA'19]. For larger values of $t$, only
$2^{O(\sqrt{kn\log n})}$ time algorithms [Basc\'{o} et al., Algorithmica'19]
and quasi-polynomial time approximation schemes [Chudnovsky et al., SODA'20]
were known. Thus, our work is the first to offer conclusive evidence that
Independent Set on $P_k$-free graphs is not NP-complete for any integer $k$.
</p>
<p>Additionally we show that for every graph $H$, if there exists a
quasi-polynomial time algorithm for Independent Set on $C$-free graphs for
every connected component $C$ of $H$, then there also exists a quasi-polynomial
time algorithm for {\sc Independent Set} on $H$-free graphs. This lifts our
quasi-polynomial time algorithm to $T_k$-free graphs, where $T_k$ has one
component that is a $P_k$, and $k-1$ components isomorphic to a fork (the
unique $5$-vertex tree with a degree $3$ vertex).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00690"><span class="datestr">at May 05, 2020 10:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2005.00681">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2005.00681">Pointer-Machine Algorithms for Fully-Online Construction of Suffix Trees and DAWGs on Multiple Strings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2005.00681">PDF</a><br /><b>Abstract: </b>We deal with the problem of maintaining the suffix tree indexing structure
for a fully-online collection of multiple strings, where a new character can be
prepended to any string in the collection at any time. The only previously
known algorithm for the problem, recently proposed by Takagi et al.
[Algorithmica 82(5): 1346-1377 (2020)], runs in $O(N \log \sigma)$ time and
$O(N)$ space on the word RAM model, where $N$ denotes the total length of the
strings and $\sigma$ denotes the alphabet size. Their algorithm makes heavy use
of the nearest marked ancestor (NMA) data structure on semi-dynamic trees, that
can answer queries and supports insertion of nodes in $O(1)$ amortized time on
the word RAM model. In this paper, we present a simpler fully-online
right-to-left algorithm that builds the suffix tree for a given string
collection in $O(N (\log \sigma + \log d))$ time and $O(N)$ space, where $d$ is
the maximum number of in-coming Weiner links to a node of the suffix tree. We
note that $d$ is bounded by the height of the suffix tree, which is further
bounded by the length of the longest string in the collection. The advantage of
this new algorithm is that it works on the pointer machine model, namely, it
does not use the complicated NMA data structures that involve table look-ups.
As a byproduct, we also obtain a pointer-machine algorithm for building the
directed acyclic word graph (DAWG) for a fully-online left-to-right collection
of multiple strings, which runs in $O(N (\log \sigma + \log d))$ time and
$O(N)$ space again without the aid of the NMA data structures.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2005.00681"><span class="datestr">at May 05, 2020 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/">postdoc position at University of Alberta (apply by December 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Theory Group in the Dept. of Computing Science at U. of Alberta invites applications for TWO postdoc positions. The successful applicants are expected to work closely with Zachary Friggstad and Mohammad Salavatipour in the areas of: approx algorithms, hardness of approximation, combinatorial optimization. For details see <a href="https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf">https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf</a><br />
Email: mrs@ualberta.ca</p>
<p>Website: <a href="http://www.cs.ualberta.ca">http://www.cs.ualberta.ca</a><br />
Email: mrs@ualberta.ca</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/05/04/postdoc-position-at-university-of-alberta-apply-by-december-31-2020/"><span class="datestr">at May 04, 2020 06:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/071">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/071">TR20-071 |  A Tight Lower Bound on Adaptively Secure Full-Information Coin Flip | 

	Iftach Haitner, 

	Yonatan Karidi-Heller</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a distributed coin-flipping protocol, Blum [ACM Transactions on Computer Systems '83],
the parties try to output a common (close to) uniform bit, even when some adversarially chosen parties try to bias the common output. In an adaptively secure full-information coin flip, Ben-Or and Linial [FOCS '85], the parties communicate over a broadcast channel and a computationally unbounded adversary can choose which parties to corrupt during the protocol execution. Ben-Or and Linial proved that the $n$-party majority protocol is resilient to $o(\sqrt{n})$ corruptions (ignoring log factors), and conjectured this is a tight upper bound for any $n$-party protocol (of any round complexity). Their conjecture was proved to be correct for single-turn (each party sends a single message) single-bit (a message is one bit) protocols, Lichtenstein, Linial, and Saks [Combinatorica '89], symmetric protocols Goldwasser, Kalai, and Park [ICALP '15], and recently for (arbitrary message length) single-turn protocols Tauman Kalai, Komargodski, and Raz [DISC '18]. Yet, the question for many-turn (even single-bit) protocols was left completely open.

In this work we close the above gap, proving that no $n$-party protocol (of any round complexity) is resilient to $O(\sqrt{n})$ (adaptive) corruptions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/071"><span class="datestr">at May 04, 2020 02:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/070">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/070">TR20-070 |  On the list recoverability of randomly punctured codes | 

	Ben Lund, 

	Aditya Potukuchi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that a random puncturing of a code with good distance is list recoverable beyond the Johnson bound.
In particular, this implies that there are Reed-Solomon codes that are list recoverable beyond the Johnson bound.
It was previously known that there are Reed-Solomon codes that do not have this property. 
As an immediate corollary to our main theorem, we obtain better degree bounds on unbalanced expanders that come from Reed-Solomon codes.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/070"><span class="datestr">at May 04, 2020 09:06 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1297">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1297">News for April 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>April is now behind us, and we hope you and your families are all staying safe and healthy. We saw <s>six</s> seven property papers appear online last month, so at least there is some reading ahead of us! A mixture of privacy, quantum, high-dimensional distributions, and juntas (juntæ?). A lot of distribution testing, overall.</p>



<p><strong>Connecting Robust Shuffle Privacy and Pan-Privacy</strong>, by Victor Balcer, Albert Cheu, Matthew Joseph, and Jieming Mao (<a href="https://arxiv.org/abs/2004.09481">arXiv</a>). This paper considers a recent notion of differential privacy called<em> shuffle privacy</em>, where users have sensitive data, a central untrusted server wants to do something with that data (for instance, say… testing its distribution), and a trusted middle-man/entity shuffles the users’ messages u.a.r. to bring in a bit more anonymity. As it turns out, testing uniformity (or identity) of distributions in the shuffle privacy model is (i) much harder than without privacy constraints; (ii) much harder than with ‘usual’ (weaker) differential privacy (iii) much easier than with local privacy; (iv) related to the sample complexity under another privacy notion, <em>pan-privacy</em>. It’s a brand exciting new world out there!</p>



<p><em>(Note: for the reader interested in keeping track of identity/uniformity testing of probability distributions under various privacy models, I wrote a very short summary of the current results <a href="https://github.com/ccanonne/probabilitydistributiontoolbox/blob/master/private-goodness-of-fit.pdf">here</a>.)</em></p>



<p><strong>Entanglement is Necessary for Optimal Quantum Property Testing, </strong>by Sebastien Bubeck, Sitan Chen, and Jerry Li (<a href="https://arxiv.org/abs/2004.07869">arXiv</a>). The analogue of uniformity testing, in the quantum world, is testing whether a quantum state is equal (or far from) the maximally mixed state. It’s known that this task  has “quantum sample complexity” (number of measurements) \(\Theta(d/\varepsilon^2)\) (i.e., square root dependence on  the dimension of the state, \(d^2\)). But this requires <em>entangled</em> measurements, which may be tricky to get (or, in my case, understand): what happens if the measurements can be adaptive, but not entangled? In this work, the authors show that, under this weaker access model \(\Omega(d^{4/3}/\varepsilon^2)\) measurements are necessary: adaptivity alone won’t cut it. It may still help though: without either entanglement <em>nor</em> adaptivity, the authors also show a \(\Omega(d^{3/2}/\varepsilon^2)\) measurements lower bound.</p>



<p><strong>Testing Data Binnings</strong>, by Clément Canonne and Karl Wimmer (<a href="https://eccc.weizmann.ac.il/report/2020/062/">ECCC</a>). More identity testing! Not private and not quantum for this one, but… not <em>quite</em> identity testing either. To paraphrase the abstract: this paper introduces (and gives near matching bounds for)  the related question of <em>identity up to binning</em>, where the reference distribution \(q\) is over \(k \ll n\) elements: the question is then whether there exists a suitable binning of the domain \([n]\) into \(k\) intervals such that, <em>once binned</em>, \(p\) is equal to \(q\).” </p>



<p><strong>Hardness of Identity Testing for Restricted Boltzmann Machines and Potts models</strong>, by Antonio Blanca, Zongchen Chen, Daniel Štefankovič, and Eric Vigoda (<a href="https://arxiv.org/abs/2004.10805">arXiv</a>). Back to identity testing of distributions, but for high-dimensional structured ones this one. Specifically, this paper focuses on the undirected graphical models known as <em>restricted Boltzmann machines, </em>and provides efficient algorithms for identity testing and conditional hardness lower bounds depending on the type of correlations allowed in the graphical models.</p>



<p><strong>Robust testing of low-dimensional functions</strong>, by Anindya De, Elchanan Mossel, and Joe Neeman (<a href="https://arxiv.org/abs/2004.11642">arXiv</a>). Junta testing is a classical, central problem in property testing, with motivations and applications in machine learning and complexity. The related (and equally well-motivated) question of junta testing of functions on \(\mathbb{R}^d\) (instead of the Boolean hypercube) was recently studied by the same authors; and the related (and, again, equally well-motivated) question of <em>tolerant</em> junta testing on the Boolean hypercube was also recently studied (among other works) by the same authors. Well, this paper does it all, and tackles the challenging (and, for a change, equally well-motivated!) question of <em>tolerant</em> testing of juntas  on \(\mathbb{R}^d\).</p>



<p><strong>Differentially Private Assouad, Fano, and Le Cam</strong>, by Jayadev Acharya, Ziteng Sun, and Huanyu Zhang (<a href="https://arxiv.org/abs/2004.06830">arXiv</a>). Back to probability distributions and privacy. This paper provides differentially private analogues of the classical eponymous statistical inference results (Assouad’s lemma, Fano’s inequality, and Le Cam’s method). In particular, it gives ready-to-use, blackbox tools to prove testing and learning lower bounds for distributions in the differentially private setting, and shows how to use them to easily derive, and rederive, several lower bounds.</p>



<p><strong>Edit: </strong>We missed one!</p>



<p><strong>Learning and Testing Junta Distributions with Subcube Conditioning</strong>, by Xi Chen, Rajesh Jayaram, Amit Levi, Erik Waingarten (<a href="https://arxiv.org/abs/2004.12496">arXiv</a>). This paper focuses on the <em>subcube conditioning</em> model of (high-dimensional) distribution testing, where the algorithm can fix some variables to values of its choosing and get samples conditioned on those variables. Extending and refining techniques from <a href="https://ptreview.sublinear.info/?p=1227">a previous work by a (sub+super)set of the authors</a>, the paper shows how to optimally learn and test <a href="http://proceedings.mlr.press/v49/aliakbarpour16.html">junta distributions</a> in this framework—with exponential savings with respect to the usual i.i.d. sampling model.</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1297"><span class="datestr">at May 04, 2020 01:52 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blog.simons.berkeley.edu/?p=164">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/simons.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/">Fine-grained hardness of lattice problems: Open questions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<h1>1 Introduction</h1>
<h2>1.1 Lattices and lattice-based cryptography</h2>
<p>Lattices are classically-studied geometric objects that in the past few decades have found a multitude of applications in computer science. The most important application area is <em>lattice-based cryptography</em>, the design of cryptosystems whose security is based on the apparent intractability of computational problems on lattices, even for quantum computers. Indeed, lattice-based cryptography has revolutionized the field because of its apparent quantum resistance and its other attractive security, functionality, and efficiency properties.</p>
<p>Intuitively, a lattice is a regular ordering of points in some (typically high-dimensional) space. More precisely, a <em>lattice</em> \( {{\cal{L}}}\) of rank \( {n}\) is the set of all integer linear combinations of some linearly independent vectors \( {\mathbf{b}_1, \ldots, \mathbf{b}_n}\), which are called a <em>basis</em> of \( {{\cal{L}}}\). We will be primarily interested in analyzing the running times of lattice algorithms as functions of the lattice’s rank \( {n}\).</p>
<h2>1.2. Computational lattice problems</h2>
<p>The two most important computational problems on lattices are the Shortest Vector Problem (SVP) and the Closest Vector Problem (CVP). SVP asks, given a basis of a lattice \( {{\cal{L}}}\) as input, to find a shortest non-zero vector in \( {{\cal{L}}}\). CVP, which can be viewed as an inhomogeneous version of SVP, asks, given a basis of a lattice \( {{\cal{L}}}\) and a target point \( {\mathbf{t}}\) as input, to find a closest vector in \( {{\cal{L}}}\) to \( {\mathbf{t}}\).</p>
<p>Algorithms for solving SVP form the core of the best known attacks on lattice-based cryptography both in theory and in practice. Accordingly, it is critical to understand the precise complexity of SVP as well as possible. The best provably correct algorithms for both SVP and CVP run in \( {2^{n + o(n)}}\)-time [<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>, <a href="https://arxiv.org/abs/1504.01995">ADS15</a>, <a href="https://arxiv.org/abs/1709.01535">AS18a</a>]. The best heuristic algorithms for SVP run in \( {2^{cn + o(n)}}\)-time for \( {c = 0.292}\) classically [<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] and \( {c = 0.265}\) using quantum speedups [<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] (see also [<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>]), and most real-world lattice-based cryptosystems assume that these algorithms are close to optimal. Indeed, many of these cryptosystems assume what Albrecht et al. [<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>] call a “paranoid” worst-case estimate of \( {c = 0.2075}\) (based on the kissing number and assuming that sieving algorithms are optimal) as the fastest hypothetical running time for SVP algorithms when choosing parameters. Accordingly, the difference in being able to solve SVP in \( {2^{0.2075n}}\) versus \( {2^{n/20}}\) versus \( {2^{\sqrt{n}}}\) time may mean the difference between lattice-based cryptosystems being secure, insecure with current parameters, or effectively broken in practice.</p>
<p>There is a rank-preserving reduction from SVP to CVP [<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>], so any algorithm for CVP immediately gives an essentially equally fast algorithm for SVP. In other words, CVP is at least as hard as SVP (and probably a bit harder). Indeed, historically, almost all lower bounds for SVP are proven via reduction from CVP (and nearly all algorithmic progress on CVP uses ideas originally developed for SVP).</p>
<h2>1.3. Fine-grained hardness</h2>
<p>The field of fine-grained complexity works to give strong, quantitative lower bounds on computational problems assuming standard complexity-theoretic assumptions. Proving such a (conditional) lower bound for an \( {{\mathsf{NP}}}\)-hard problem generally works by (1) assuming a stronger hardness assumption than \( {{\mathsf{P}} \neq {\mathsf{NP}}}\) about the complexity of \( {k}\)-SAT (such as ETH or SETH, defined below), and (2) giving a highly efficient reduction from \( {k}\)-SAT to the problem. The most important hardness assumptions for giving lower bounds on \( {{\mathsf{NP}}}\)-hard problems are the Exponential Time Hypothesis (ETH) and the Strong Exponential Time Hypothesis (SETH) of Impagliazzo and Paturi [<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>]. ETH asserts that there is no \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT, and SETH asserts that for every \( {\epsilon &gt; 0}\) there exists \( {k \in {\mathbb Z}^+}\) such that there is no \( {2^{(1 – \epsilon)n}}\)-time algorithm for \( {k}\)-SAT, where \( {n}\) denotes the number of variables in the SAT instance.</p>
<p>Here by “highly efficient” reductions we mean linear ones, i.e., reductions that map a \( {3}\)-SAT or \( {k}\)-SAT formula on \( {n}\) variables to an SVP or CVP instance of rank \( {C n + o(n)}\) for some absolute constant \( {C &gt; 0}\). Indeed, by giving a reduction from \( {3}\)-SAT (respectively, \( {k}\)-SAT for any \( {k \in {\mathbb Z}^+}\)) instances on \( {n}\) variables to SVP or CVP instances of rank \( {C n + o(n)}\), we can conclude that there is no \( {2^{o(n)}}\)-time (resp., \( {2^{(1-\epsilon)n/C}}\)-time for any \( {\epsilon &gt; 0}\)) algorithm for the corresponding problem assuming ETH (resp., SETH). Note that the smaller the value of \( {C}\) for which one can show such a reduction, the stronger the conclusion. In particular, a reduction mapping \( {k}\)-SAT instances on \( {n}\) variables to SVP or CVP instances of rank \( {n + o(n)}\) would imply an essentially tight lower bound on the corresponding problem assuming SETH — as mentioned above, the best provably correct algorithms for both SVP and CVP run in time \( {2^{n + o(n)}}\).</p>
<h2>1.4. Fine-grained hardness of CVP (and SVP)</h2>
<p>It is relatively easy to show that CVP is “ETH-hard,” i.e., to show that a \( {2^{o(n)}}\)-time algorithm for CVP would imply a \( {2^{o(n)}}\)-time algorithm for \( {3}\)-SAT instances with \( {n}\) variables. This would falsify ETH. (It’s a nice exercise to show that the Subset Sum problem on a set of size \( {n}\) reduces to CVP on a lattice of rank \( {n}\), which implies the result.)</p>
<p>With some work, Divesh Aggarwal and Noah extended this to SVP [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>]. In particular, we showed a reduction from CVP to SVP that only increases the rank of the lattice by some constant multiplicative factor. (Formally, the reduction only works with certain minor constraints on the CVP instance. The reduction originally relied on a geometric conjecture, which was open for decades. But, Serge Vlăduţ proved the conjecture [<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] shortly after we published!)</p>
<p>So, unless ETH is false, there is no \( {2^{o(n)}}\)-time algorithm for CVP or SVP. But, for cryptographic applications, even, say, a \( {2^{n/20}}\)-time algorithm would be completely devastating. If such an algorithm were found, cryptographic schemes that we currently think are secure against absurdly powerful attackers straight out of science fiction (say, one with a computer the size of the sun running until the heat death of the universe) would turn out to be easily broken (e.g., in seconds on our laptops).</p>
<p>In [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we <em>almost</em> showed that CVP is “SETH-hard,” i.e., that a \( {2^{(1-\epsilon)n}}\)-time algorithm for CVP would imply such an algorithm for \( {k}\)-SAT for <em>any</em> constant \( {k}\). This would falsify SETH. So, we <em>almost</em> showed that the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm is optimal. The “almost” is because our proof works with \( {\ell_p}\) norms, that is, we show hardness for the version of CVP in which the distance from the target to a lattice vector is defined in terms of the \( {\ell_p}\) norm,</p>
<p align="center">\( \displaystyle \|\mathbf{x}\|_p := (|x_1|^p + \cdots + |x_d|^p)^{1/p} \; . \)</p>
<p>We call the corresponding problem \( {{\mathrm{CVP}}_p}\). In fact, our proof works for all \( {\ell_p}\) norms <em>except</em> when \( {p}\) is an even integer. (To see why this might happen, notice \( {\|\mathbf{x}\|_p^p}\) is a polynomial in the \( {x_i}\) if and only if \( {p}\) is an even integer. In fact, there’s some sense in which “\( {\ell_2}\) is the easiest norm,” because for any \( {p}\), there is a linear map \( {A \in {\mathbb R}^{d \times m}}\) such that \( {m}\) is not too large and \( {\|\mathbf{x}\|_2 \approx \|A \mathbf{x}\|_p}\).) Of course, we are most interested in the case \( {p= 2}\) (the only case for which the [<a href="https://arxiv.org/abs/1504.01995">ADS15</a>] algorithm works), which is an even integer! Indeed, for all \( {p \neq 2}\), the fastest known algorithm for CVP is still Ravi Kannan’s \( {n^{O(n)}}\)-time algorithm from 1987 [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>]. (For SVP and for constant-factor approximate CVP, \(2^{O(n)}\)-time algorithms are known [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>].)</p>
<p>In fact, we showed that for \( {p = 2}\), no “natural” reduction can rule out a \( {2^{3n/4}}\)-time algorithm for CVP under SETH. A “natural” reduction is one with a fixed bijection between witnesses. In particular, any “natural” reduction from \( {3}\)-SAT to CVP must reduce to a lattice with rank at least roughly \( {4n/3}\). So, new ideas will be needed to prove stronger hardness of CVP in the \( {\ell_2}\) norm.</p>
<h1>2. Open problems</h1>
<p>We now discuss some of the problems that we left open in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]. For simplicity, we ask for specific results (e.g., “prove that problem \( {A}\) is \( {T}\)-hard under hypothesis \( {B}\)“), but of course any similar results would be very interesting (e.g., “\( {A}\) is \( {T’}\)-hard under hypothesis \( {B’}\)“).</p>
<h2>2.1. Hardness in the \(\ell_2\) norm</h2>
<p>The most obvious question that we left open is, of course, to prove similar \( {2^n}\)-time hardness results for \( {{\mathrm{CVP}}_2}\) (and more generally for \( {{\mathrm{CVP}}_p}\) for even integers \( {p}\)).</p>
<blockquote>
<p><b>Open problem 1.</b> Show that there is no \( {2^{0.99 n}}\)-time algorithm for \( {{\mathrm{CVP}}_2}\) assuming SETH.</p>
</blockquote>
<p>Remember that we showed that any proof of such a strong result would have to use an “unnatural” reduction. So, a fundamentally different approach is needed. One potentially promising direction would be to find a Cook reduction, as our limitations only apply to Karp reductions.</p>
<p>Alternatively, one might try for a different result that gets around this “natural” reduction limitations. E.g., even the following much weaker result would be very interesting.</p>
<blockquote>
<p><b>Open problem 2.</b> Show an efficient reduction from \( {3}\)-SAT on \( {n}\) variables to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {\approx 10n}\).</p>
</blockquote>
<p>Such a reduction to \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {Cn}\) for some large constant \( {C}\) is known by applying the Sparsification Lemma [<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] to \( {3}\)-SAT, but showing such a reduction for any reasonably small \( {C}\) or even any explicit \( {C}\) using a different proof technique would be interesting.</p>
<p>Also, our limitations only apply to reductions that map satisfying assignments to <em>exact</em> closest vectors. So, one might try to get around our limitation by working directly with approximate versions of \( {3}\)-SAT and \( {{\mathrm{CVP}}_2}\). (In [<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>], we show such reductions from Gap-\( {k}\)-SAT to constant-factor approximate \( {{\mathrm{CVP}}_p}\) for all \( {p \notin 2{\mathbb Z}}\) as well as all \( {k \leq p}\). We also show reductions from Gap-\( {k}\)-Parity that achieve relatively large approximation factors.)</p>
<blockquote>
<p><b>Open problem 3.</b> Show an efficient reduction from Gap-\( {3}\)-SAT on \( {n}\) variables to approximate \( {{\mathrm{CVP}}_2}\) on a lattice of rank \( {n}\).</p>
</blockquote>
<h2>2.2. Hardness in \(\ell_p\) norms</h2>
<p>Intuitively, one reason that we are able to prove such strong results for \( {\ell_p}\) norms for \( {p \neq 2}\) is because we can use lattices with large ambient dimension \( {d}\) but low rank \( {n}\). In other words, while our reductions produce lattices \( {{\cal{L}}}\) that live in some \( {n}\)-dimensional subspace of \( {\ell_p}\)-space, the ambient space itself has large dimension \( {d}\) relative to \( {n}\). Of course, any subspace of the \( {\ell_2}\) norm is an \( {\ell_2}\) subspace (i.e., every slice of a ball is a lower-dimensional ball), so in the \( {\ell_2}\) norm, one can assume without loss of generality that \( {d = n}\). In particular, if we were able to prove \( {2^n}\)-hardness for the \( {\ell_2}\) norm, then we would actually prove \( {2^d}\)-hardness for free. However, a potentially easier problem would be to improve the \( {2^n}\)-hardness of \( {{\mathrm{CVP}}_p}\) shown in [<a href="https://arxiv.org/abs/1704.03928">BGS17</a>, <a href="https://arxiv.org/abs/1911.02440">ABGS20</a>]  to \( {2^d}\)-hardness for some \( p \neq 2 \).</p>
<blockquote>
<p><b>Open problem 4.</b> Show that there is no \( {2^{0.99 d}}\)-time algorithm for \( {{\mathrm{CVP}}_p}\) (for some \( {p}\)) assuming SETH.</p>
</blockquote>
<p>More generally, it would be very interesting to settle the fine-grained complexity of \( {{\mathrm{CVP}}_p}\) for some \( {p \neq 2}\) (either in terms of rank \( {n} \) or dimension \( {d} \)). This could take the form either of showing improved algorithms (currently the fastest algorithms for \( {{\mathrm{CVP}}_p}\) for general \( {p}\) run in \( {n^{O(n)}}\)-time [<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>], and \( {2^{O(n)}}\)-time for a constant approximation factor [<a href="https://arxiv.org/abs/1011.5666">DPV11</a>]), or showing super-\( {2^n}\) hardness, or both.</p>
<blockquote>
<p><b>Open problem 5.</b> Show matching upper bounds and lower bounds (under SETH) for \( {{\mathrm{CVP}}_p}\) for some \( {p}\) (possibly with a constant approximation factor).</p>
</blockquote>
<p>The case where \( {p = \infty}\) is especially interesting. Indeed, because the kissing number in the \( {\ell_\infty}\) norm is \( {3^n-1}\), one might guess that the fastest algorithms for \( {{\mathrm{CVP}}_\infty}\) and \( {{\mathrm{SVP}}_\infty}\) actually run in time \( {3^{n + o(n)}}\) or perhaps \( {3^{d + o(d)}}\). (See [<a href="https://arxiv.org/pdf/1801.02358">AM18</a>], which essentially achieves this.) We therefore ask whether stronger lower bounds can be proven in this special case.</p>
<blockquote>
<p><b>Open problem 6.</b> Show that \( {{\mathrm{CVP}}_\infty}\) cannot be solved in time \( {3^{0.99n}}\) (under SETH).</p>
</blockquote>
<h2>2.3. Hardness closer to crypto</h2>
<p>The most relevant problem to cryptography is approximate \( {{\mathrm{SVP}}_2}\) with an approximation factor that is polynomial in the rank \( {n}\). Our fastest algorithms to solve this problem work via a reduction to exact (or near exact) \( {{\mathrm{SVP}}_2}\) with some lower rank \( {n’ = \Theta(n)}\), so that even for these polynomial approximation factors, our fastest algorithms run in time \( {2^{\Omega(n)}}\) (where the hidden constant depends on the polynomial; see <a href="https://blog.simons.berkeley.edu/2020/04/lattice-blog-reduction-part-i-bkz/">Michael’s post</a> for more on this topic). And, hardness results for exact SVP rule out attacks on cryptography that use such reductions. We currently only know how to rule out \( {2^{o(n)}}\)-time algorithms for \( {{\mathrm{SVP}}_2}\) (under the Gap-ETH assumption). We ask whether we can do better. (In [<a href="https://arxiv.org/abs/1712.00942">AS18b</a>], we proved the stronger result below for \( {\ell_p}\) norms for large enough \( {p \notin 2{\mathbb Z}}\).)</p>
<blockquote>
<p><b>Open problem 7.</b> Prove that there is no \( {2^{n/10}}\)-time algorithm for \( {{\mathrm{SVP}}_2}\) (under SETH).</p>
</blockquote>
<p>Of course, we would ideally like to directly rule out faster algorithms for approximate \( {{\mathrm{SVP}}_2}\) with the approximation factors that are most directly relevant to cryptography. There are serious complexity-theoretic barriers to overcome to get all the way there (e.g., \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) are known to be in \( {{\mathsf{NP}}} \cap {{\mathsf{coNP}}}\) for large enough polynomial approximation factors. But, we can still hope to get as close as possible, by proving stronger hardness results for approximate \( {{\mathrm{CVP}}_p}\) and approximate \( {{\mathrm{SVP}}_p}\). Indeed, a beautiful sequence of works showed hardness for approximation factors up to \( {n^{c/\log \log n}}\) (so “nearly polynomial) [<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>, <a href="https://arxiv.org/abs/1806.04087">HR12</a>], but these results are not fine grained.</p>
<p>The best <em>fine-grained</em> hardness of approximation results known rule out algorithms for small constant-factor approximations for \( {{\mathrm{CVP}}_p}\) with \( {p \notin 2{\mathbb Z}}\) in time \( {2^{0.99n}}\) for \( {{\mathrm{CVP}}_p}\) and \( {{\mathrm{SVP}}_p}\) for any \( {p}\) in time \( {2^{o(n)}}\). We ask whether we can do better.</p>
<blockquote>
<p><b>Open problem 8.</b> Prove that there is no \( {2^{0.99 n}}\)-time algorithm for \( {2}\)-approximate \( {{\mathrm{CVP}}_p}\) (under some form of Gap-SETH, see below).</p>
</blockquote>
<blockquote>
<p><b>Open problem 9.</b> Prove that there is no \( {2^{o(n)}}\)-time algorithm for \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for superconstant \( {\gamma = \omega(1)}\) (under Gap-ETH).</p>
</blockquote>
<h2>2.4. Gap-SETH?</h2>
<p>One issue that arose in our attempts to prove fine-grained hardness of approximation results is that we don’t even know the “right” complexity-theoretic assumption about approximate CSPs to use as a starting point. For fine-grained hardness of exact problems, ETH and SETH are very well established hypotheses, and they are in some sense “the weakest possible” assumptions of their form. E.g., it is easy to see that \( {k}\)-SAT is \( {2^{Cn}}\) hard if any \( {k}\)-CSP is. But, for hardness of approximation, the situation is less clear.</p>
<p>The analogue of ETH in the regime of hardness of approximation is the beautiful Gap-ETH assumption, which was defined independently by Irit Dinur [<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] and Pasin Manurangsi and Prasad Raghavendra [<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>]. This assumption says that there exists some constant approximation factor \( {\delta \neq 1}\) such that \( {\delta}\)-Gap-\( {3}\)-SAT cannot be solved in time \( {2^{o(n)}}\). (Formally, both Dinur and Manurangsi and Raghavendra say that there is no \( {2^{o(n)}}\)-time algorithm that distinguishes a satisfiable formula from a formula for which no assignment satisfies more than a \( {(1-\epsilon)}\) fraction of the clauses, but we ignore this requirement of perfect completeness here.) It is easy to see that this hypothesis is equivalent to a similar hypothesis about any \( {3}\)-CSP (or, indeed, any \( {k}\)-CSP for any constant\( {k}\)).</p>
<p>However, to prove hardness of approximation with the finest of grains, we need some “gap” analogue of SETH, i.e., we would like to assume that for large enough \( {k}\), some Gap-\( {k}\)-CSP is hard to approximate up to some constant factor \( {\delta \neq 1}\) in better than \( {2^{0.99n}}\)-time. (Formally, we should add an additional variable \( {\epsilon &gt; 0}\) and have such a hypothesis for every running time \( {2^{(1-\epsilon)n}}\), but we set \( {\epsilon = 0.01}\) here to keep things relatively simple.)</p>
<p>An issue arises here concerning the dependence of the approximation factor \( {\delta}\) on the arity \( {k}\). In particular, recall that \( {k}\)-SAT can be trivially approximated up to a factor of \( {1-2^{-k}}\) (since a random assignment satisfies a \( {1-2^{-k}}\) fraction of the clauses in expectation). So, if we define Gap-SETH in terms of Gap-\( {k}\)-SAT, then we must choose \( {\delta = \delta(k) \geq 1-2^{-k}}\) that converges to one as \(k\) increases. Manurangsi proposed such a version of Gap-SETH in his thesis [<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>, Conjecture 12.1], specifically that for every large enough constant \( {k}\) there exists a constant \( {\delta = \delta(k) \neq 1}\) such that Gap-\( {k}\)-SAT cannot be approximated up to a factor of \( {\delta}\) in time \( {2^{0.99n}}\). (Again, we are leaving out an additional variable, \( {\epsilon}\).)</p>
<p>If we rely on this version of Gap-SETH, then our current techniques seem to get stuck at proving hardness of approximation for, say, \( {\gamma}\)-approximate \( {{\mathrm{CVP}}_p}\) for some non-explicit constant \( {\gamma_p &gt; 1}\) (and, if one works out the numbers, one can see immediately that \( {\gamma_p}\) must be really quite close to one). However, other Gap-\(k\)-CSPs are known to be (\(\mathsf{NP}\)-)hard to approximate up to much better approximation factors. E.g., for any \( {k}\), Gap-\(k\)-Parity is \( {{\mathsf{NP}}}\)-hard to approximate up to any constant approximation factor \( {1/2 &lt; \delta \leq 1}\) [<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>], and Gap-\( {k}\)-AND is \( {{\mathsf{NP}}}\)-hard to approximate for any constant approximation factor \( {\Omega(k/2^k) \leq \delta \leq 1}\) [<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>]. Indeed, Gap-\( {k}\)-AND is a quite natural problem to consider in this context since there is a fine-grained, approximation-factor preserving reduction from any Gap-\( {k}\)-CSP to Gap-\( {k}\)-AND. This generality motivates understanding the precise complexity of Gap-\( {k}\)-AND.</p>
<blockquote>
<p><b>Open problem 10.</b> What is the fine-grained complexity of the \( {\delta}\)-Gap-\( {k}\)-AND problem in terms of \( {n}\), \( {k}\), and \( {\delta}\)? In particular, if</p>
<p align="center">\( \displaystyle C_{k,\delta} := \inf \{ C &gt; 0 \ : \ \text{there is a $2^{C_{k,\delta}}$-time algorithm for algorithm for $\delta$-Gap-$k$-AND}\}\)</p>
<p>then what is the behavior of \( {C_{k,\delta}}\) as \( {k \rightarrow \infty}\) (for various functions \( {\delta = \delta(k)}\) of \( {k}\))?</p>
</blockquote>
<p>In particular, if one were to hypothesize sufficiently strong hardness of \( {\delta}\)-Gap-\( {k}\)-AND — i.e., to define an appropriate variant of Gap-SETH based on Gap-\( {k}\)-AND — then one might be able to use this hypothesis to prove very strong fine-grained hardness of approximation results. There is a fine-grained (but non-approximation preserving) reduction from Gap-\( {k}\)-AND to Gap-\( {k}\)-SAT, and so Manurangsi’s Gap-SETH is equivalent to the conjecture that there exists some non-explicit \( {\delta(k)}\) such that \( {\lim_{k \rightarrow \infty} C_{k,\delta} = 1}\).</p>


<ul><li>[<a href="https://arxiv.org/abs/1911.02440">ABGS20</a>] Aggarwal, Bennett, Golovnev, Stephens-Davidowitz. Fine-grained hardness of CVP(P)— Everything that we can prove (and nothing else)</li><li>[<a href="https://estimate-all-the-lwe-ntru-schemes.github.io/paper.pdf">A+18</a>] Albrecht, Curtis, Deo, Davidson, Player, Postlethwaite, Virdia, Wunderer. Estimate all the {LWE, NTRU} schemes! <em>SCN</em>, 2019.</li><li>[<a href="https://arxiv.org/abs/1412.7994">ADRS15</a>] Aggarwal, Dadush, Regev, Stephens-Davidowitz. Solving the Shortest Vector Problem in \(2^n\) time via discrete Gaussian sampling. <em>STOC</em>, 2015.</li><li>[<a href="https://arxiv.org/abs/1504.01995">ADS15</a>]  Aggarwal, Dadush, Stephens-Davidowitz. Solving the Closest Vector Problem in \(2^n\) time–The discrete Gaussian strikes again! <em>FOCS</em>, 2015.</li><li>[<a href="https://arxiv.org/pdf/1801.02358">AM18</a>] Aggarwal, Mukhopadhyay. Faster algorithms for SVP and CVP in the \(\ell_\infty\) norm. <em>ISAAC</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1709.01535">AS18a</a>] Aggarwal, Stephens-Davidowitz. Just take the average! An embarrassingly simple \(2^n\)-time algorithm for SVP (and CVP). <em>SOSA</em>, 2018.</li><li>[<a href="https://arxiv.org/abs/1712.00942">AS18b</a>] Aggarwal, Stephens-Davidowitz. (Gap/S)ETH hardness of SVP. In <em>STOC</em>, 2018.</li><li>[<a href="https://eprint.iacr.org/2015/1128">BDGL16</a>] Becker, Ducas, Gama, Laarhoven. New directions in nearest neighbor searching with applications to lattice sieving. <em>SODA</em>, 2016.</li><li>[<a href="https://arxiv.org/abs/1704.03928">BGS17</a>] Bennett, Golovnev, Stephens-Davidowitz. On the quantitative hardness of CVP. <em>FOCS</em>, 2017.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2012/110/">Cha16</a>] Chan. Approximation resistance from pairwise-independent subgroups. <em>J. ACM</em>, 2016.</li><li>[<a href="https://eccc.weizmann.ac.il/report/2016/128/">Din16</a>] Dinur. Mildly exponential reduction from gap 3SAT to polynomial-gap label-cover.</li><li>[<a href="http://www.wisdom.weizmann.ac.il/~dinuri/mypapers/cvpjournal.pdf">DKRS03</a>] Dinur, Kindler, Raz, Safra. Approximating CVP to within almost-polynomial factors is NP-hard. <em>Combinatorica</em>, 2003.</li><li>[<a href="https://arxiv.org/abs/1011.5666">DPV11</a>] Dadush, Peikert, Vempala. Enumerative lattice algorithms in any norm via \(M\)-ellipsoid coverings. <em>FOCS</em>, 2011.</li><li>[<a href="https://cseweb.ucsd.edu/~daniele/papers/GMSS.pdf">GMSS99</a>] Goldreich, Micciancio, Safra, Seifert. Approximating shortest lattice vectors is not harder than approximating closest lattice vectors. <em>IPL</em>, 1999.</li><li>[<a href="http://kiosk.nada.kth.se/theory/projects/publications/optimaljh.pdf">Hås01</a>] Håstad. Some optimal inapproximability results. <em>J. ACM</em>, 2001.</li><li>[<a href="https://arxiv.org/abs/1806.04087">HR12</a>] Haviv, Regev. Tensor-based hardness of the Shortest Vector Problem to within almost polynomial factors. <em>TOC</em>, 2012.</li><li>[<a href="https://cseweb.ucsd.edu/~paturi/myPapers/pubs/ImpagliazzoPaturi_2001_jcss.pdf">IP01</a>] Impagliazzo, Paturi. On the complexity of \(k\)-SAT. <em>JCSS</em>, 2001.</li><li>[<a href="https://cseweb.ucsd.edu/~russell/ipz.pdf">IPZ01</a>] Impagliazzo, Paturi, Zane. Which problems have strongly exponential complexity? <em>JCSS</em>, 2001.</li><li>[<a href="http://www.thijs.com/docs/phd-final.pdf">Laa15</a>] Laarhoven. Search problems in cryptography. Ph.D thesis, 2015.</li><li>[<a href="https://kilthub.cmu.edu/articles/Minkowski_s_convex_body_theorem_and_integer_programming/6607328/files/12097865.pdf">Kan87</a>] Kannan. Minkowski’s convex body theorem and Integer Programming. <em>MOR</em>, 1987.</li><li>[<a href="https://eprint.iacr.org/2019/1016">KMPR19</a>] Kirshanova, Mårtensson, Postlethwaite, Roy Moulik. Quantum algorithms for the approximate \(k\)-list problem and their application to lattice sieving. <em>Asiacrypt</em>, 2019.</li><li>[<a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2019/EECS-2019-49.html">Man19</a>] Manurangsi. Approximation and Hardness: Beyond P and NP.</li><li>[<a href="https://arxiv.org/pdf/1607.02986.pdf">MR17</a>] Manurangsi, Raghavendra. A Birthday Repetition Theorem and Complexity of Approximating Dense CSPs. <em>ICALP</em>, 17.</li><li>[<a href="https://arxiv.org/abs/1802.00886">Vlă19</a>] Vlăduţ. Lattices with exponentially large kissing numbers. <em>Moscow J. of Combinatorics and Number Theory</em>, 2019<em>.</em></li></ul></div>







<p class="date">
by Huck Bennett <a href="https://blog.simons.berkeley.edu/2020/05/fine-grained-hardness-of-lattice-problems-open-questions/"><span class="datestr">at May 04, 2020 01:07 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
