<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at August 24, 2020 04:21 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/">IDEAL Special Quarter (Theory of Deep Learning)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
September 21 – December 12, 2020 Online (https://www.ideal.northwestern.edu/special-quarters/fall-2020/) https://www.ideal.northwestern.edu/special-quarters/fall-2020/registration There will be a Special Quarter on Theory of Deep Learning this Fall as a part of IDEAL – The Institute for Data, Econometrics, Algorithms, and Learning, runs jointly with TTIC and the University of Chicago. The Special Quarter will be entirely online, and take place … <a href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/" class="more-link">Continue reading <span class="screen-reader-text">IDEAL Special Quarter (Theory of Deep Learning)</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2020/08/24/ideal-special-quarter-theory-of-deep-learning/"><span class="datestr">at August 24, 2020 04:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1663724076500583508">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/08/sharp-p-and-issue-of-natural-problems.html">Sharp P and the issue of `natural problems'</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> #P was defined by Valiant as a way to pin down that the PERMANENT of a matrix is hard to compute.</p><p>The definition I give is equivalent to the one Valiant gave.</p><p>g is in #P if there exists p a poly and B in P such that</p><p>g(x) = | { y : |y| = p(|x|) and (x,y) \in B } |</p><p>A function f is #P-complete if g is in #P and for all g in #P,  f is poly-Turing reducible to g.</p><p>#SAT is the function that, given a formula, returns the number of satisfying assignments. It is #P-complete by looking at the proof the Cook-Levin Theorem. The reduction of f to #SAT only makes one query to #SAT. A common way to show that #A is #P-complete is to show that SAT \le A with a reduction that preserves the number of solutions. </p><p>Valiant proved that PERM was #P-complete (his reduction only used 1 call to PERM).</p><p>There are problems in P whose #-version is #-P complete: Matching and DNF-SAT are two of them.</p><p>Notice that I defined #SAT directly, not in terms of a poly p and a set B as above. Here is why: if you use poly p and set B one can do obnoxious things like: </p><p>SAT = { phi : exists yz 2n-bits long such that phi(y)=T and z is prime }</p><p>The # version of this definition is not really what I want (though I am sure its #P-complete).</p><p>Valiant (see <a href="https://www.math.cmu.edu/~af1p/Teaching/MCC17/Papers/enumerate.pdf">here</a> and <a href="http://www.math.cmu.edu/~af1p/Teaching/MCC17/Papers/permanent.pdf">here</a>) and Simon (see <a href="https://link.springer.com/content/pdf/10.1007%2F3-540-08342-1_37.pdf">here</a>) showed that  for many known NPC-problems A, #A is #P-complete. They meant NATURAL problems. Is it true for all natural NP-complete problems?</p><p>Unfortunately the statement `All NATURAL NPC problems give rise to #P-complete functions' is hard (impossible?) to state rigorously and hence hard (impossible?) to prove. </p><p>1) Is there a natural A in NP such that #A is NOT #P-complete (under assumptions)?</p><p>2) Are there any theorems that show a large set of NPC problems have #P counterparts? Or are we doomed to, when we want to show some #A is #P-complete, come up with a new proof?</p><p>3) Can one PROVE there are NPC problems A such that #A is NOT #P-complete? (under assumptions).</p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/08/sharp-p-and-issue-of-natural-problems.html"><span class="datestr">at August 24, 2020 01:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09607">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09607">Optimal Metric Search Is Equivalent to the Minimum Dominating Set Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hetland:Magnus_Lie.html">Magnus Lie Hetland</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09607">PDF</a><br /><b>Abstract: </b>In metric search, worst-case analysis is of little value, as the search
invariably degenerates to a linear scan for ill-behaved data. Consequently,
much effort has been expended on more nuanced descriptions of what performance
might in fact be attainable, including heuristic baselines like the AESA
family, as well as statistical proxies such as intrinsic dimensionality. This
paper gets to the heart of the matter with an exact characterization of the
best performance actually achievable for any given data set and query.
Specifically, linear-time objective-preserving reductions are established in
both directions between optimal metric search and the minimum dominating set
problem, whose greedy approximation becomes the equivalent of an oracle-based
AESA, repeatedly selecting the pivot that eliminates the most of the remaining
points. As an illustration, the AESA heuristic is adapted to downplay the role
of previously eliminated points, yielding some modest performance improvements
over the original, as well as its younger relative iAESA2.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09607"><span class="datestr">at August 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09465">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09465">Comparison of Algorithms for Simple Stochastic Games</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretinsky:Jan.html">Jan Kretinsky</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramneantu:Emanuel.html">Emanuel Ramneantu</a>, Alexander Slivinskiy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weininger:Maximilian.html">Maximilian Weininger</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09465">PDF</a><br /><b>Abstract: </b>Simple stochastic games are turn-based 2.5-player zero-sum graph games with a
reachability objective. The problem is to compute the winning probability as
well as the optimal strategies of both players. In this paper, we compare the
three known classes of algorithms -- value iteration, strategy iteration and
quadratic programming -- both theoretically and practically. Further, we
suggest several improvements for all algorithms, including the first approach
based on quadratic programming that avoids transforming the stochastic game to
a stopping one. Our extensive experiments show that these improvements can lead
to significant speed-ups. We implemented all algorithms in PRISM-games 3.0,
thereby providing the first implementation of quadratic programming for solving
simple stochastic games.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09465"><span class="datestr">at August 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09414">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09414">Schematic Representation of Large Biconnected Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Battista:Giuseppe_Di.html">Giuseppe Di Battista</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frati:Fabrizio.html">Fabrizio Frati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patrignani:Maurizio.html">Maurizio Patrignani</a>, Marco Tais <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09414">PDF</a><br /><b>Abstract: </b>Suppose that a biconnected graph is given, consisting of a large component
plus several other smaller components, each separated from the main component
by a separation pair. We investigate the existence and the computation time of
schematic representations of the structure of such a graph where the main
component is drawn as a disk, the vertices that take part in separation pairs
are points on the boundary of the disk, and the small components are placed
outside the disk and are represented as non-intersecting lunes connecting their
separation~pairs. We consider several drawing conventions for such schematic
representations, according to different ways to account for the size of the
small components. We map the problem of testing the existence of such
representations to the one of testing the existence of suitably constrained
1-page book-embeddings and propose several polynomial-time or
pseudo-polynomial-time algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09414"><span class="datestr">at August 24, 2020 01:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09406">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09406">$(2+\epsilon)$-ANN for time series under the Fr\'echet distance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Driemel:Anne.html">Anne Driemel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Psarros:Ioannis.html">Ioannis Psarros</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09406">PDF</a><br /><b>Abstract: </b>We give the first ANN-data structure for time series under the continuous
Fr\'echet distance, where ANN stands for approximate near neighbor. Given a
parameter $\epsilon \in (0,1]$, the data structure can be used to preprocess
$n$ curves in Euclidean $\mathbb{R}$ (aka time series), each of complexity $m$,
to answer queries with a curve of complexity $k$ by either returning a curve
that lies within Fr\'echet distance $2+\epsilon$, or answering that there
exists no curve in the input within distance $1$. In both cases, the answer is
correct.
</p>
<p>Our data structure uses space in $n\cdot
\mathcal{O}\left({\epsilon^{-1}}\right)^{k} + \mathcal{O}(nm)$ and query time
in $\mathcal{O}\left(k\right)$. The data structure is therefore especially
useful in the asymmetric setting, where $k \ll m$. This is well-motivated for
the continuous Fr\'echet distance as the distance measure takes into account
the interior points along the edges of the curve.
</p>
<p>We show that the approximation factor achieved by our data structure is
optimal in the cell-probe model of computation. Concretely, we show that for
any data structure which achieves an approximation factor less than $2$ and
which supports curves of arclength at most $L$, uses a word size bounded by
$O(L^{1-\epsilon})$ for some constant $\epsilon&gt;0$, and answers the query using
only a constant number of probes, the number of words used to store the data
structure must be at least $L^{\Omega(k)}$. Our data structure uses only a
constant number of probes per query and does not have any dependency on $L$.
</p>
<p>We apply similar techniques for proving cell-probe lower bounds for the
discrete Fr\'echet distance matching known upper bounds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09406"><span class="datestr">at August 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09329">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09329">$2$-Layer $k$-Planar Graphs: Density, Crossing Lemma, Relationships, and Pathwidth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angelini:Patrizio.html">Patrizio Angelini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lozzo:Giordano_Da.html">Giordano Da Lozzo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/F=ouml=rster:Henry.html">Henry Förster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schneck:Thomas.html">Thomas Schneck</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09329">PDF</a><br /><b>Abstract: </b>The $2$-layer drawing model is a well-established paradigm to visualize
bipartite graphs. Several beyond-planar graph classes have been studied under
this model. Surprisingly, however, the fundamental class of $k$-planar graphs
has been considered only for $k=1$ in this context. We provide several
contributions that address this gap in the literature. First, we show tight
density bounds for the classes of $2$-layer $k$-planar graphs with
$k\in\{2,3,4,5\}$. Based on these results, we provide a Crossing Lemma for
$2$-layer $k$-planar graphs, which then implies a general density bound for
$2$-layer $k$-planar graphs. We prove this bound to be almost optimal with a
corresponding lower bound construction. Finally, we study relationships between
$k$-planarity and $h$-quasiplanarity in the $2$-layer model and show that
$2$-layer $k$-planar graphs have pathwidth at most $k+1$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09329"><span class="datestr">at August 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09317">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09317">Indistinguishability Obfuscation from Well-Founded Assumptions</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Aayush.html">Aayush Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lin:Huijia.html">Huijia Lin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sahai:Amit.html">Amit Sahai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09317">PDF</a><br /><b>Abstract: </b>In this work, we show how to construct indistinguishability obfuscation from
subexponential hardness of four well-founded assumptions. We prove:
</p>
<p>Let $\tau \in (0,\infty), \delta \in (0,1), \epsilon \in (0,1)$ be arbitrary
constants. Assume sub-exponential security of the following assumptions, where
$\lambda$ is a security parameter, and the parameters $\ell,k,n$ below are
large enough polynomials in $\lambda$:
</p>
<p>- The SXDH assumption on asymmetric bilinear groups of a prime order $p =
O(2^\lambda)$,
</p>
<p>- The LWE assumption over $\mathbb{Z}_{p}$ with subexponential
modulus-to-noise ratio $2^{k^\epsilon}$, where $k$ is the dimension of the LWE
secret,
</p>
<p>- The LPN assumption over $\mathbb{Z}_p$ with polynomially many LPN samples
and error rate $1/\ell^\delta$, where $\ell$ is the dimension of the LPN
secret,
</p>
<p>- The existence of a Boolean PRG in $\mathsf{NC}^0$ with stretch
$n^{1+\tau}$,
</p>
<p>Then, (subexponentially secure) indistinguishability obfuscation for all
polynomial-size circuits exists.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09317"><span class="datestr">at August 24, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09299">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09299">Optimal algorithm for computing Steiner 3-eccentricities of trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ilic:Aleksandar.html">Aleksandar Ilic</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09299">PDF</a><br /><b>Abstract: </b>The Steiner $k$-eccentricity of a vertex $v$ of a graph $G$ is the maximum
Steiner distance over all $k$-subsets of $V (G)$ which contain $v$. In this
note, we design a linear algorithm for computing the Steiner $3$-eccentricities
and the connective Steiner $3$-eccentricity index on a tree and thus improving
a quadratic algorithm presented in [G. Yu, X. Li, \emph{Connective Steiner
3-eccentricity index and network similarity measure}, Appl. Math. Comput. 386
(2020), 125446.]
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09299"><span class="datestr">at August 24, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09260">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09260">Greedy Approaches to Online Stochastic Matching</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Borodin:Allan.html">Allan Borodin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/MacRury:Calum.html">Calum MacRury</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rakheja:Akash.html">Akash Rakheja</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09260">PDF</a><br /><b>Abstract: </b>Within the context of stochastic probing with commitment, we consider the
online stochastic matching problem; that is, the one-sided online bipartite
matching problem where edges adjacent to an online node must be probed to
determine if they exist based on edge probabilities that become known when an
online vertex arrives. If a probed edge exists, it must be used in the matching
(if possible). We consider the competitiveness of online algorithms in the
random order input model (ROM), when the offline vertices are weighted. More
specifically, we consider a bipartite stochastic graph $G = (U,V,E)$ where $U$
is the set of offline vertices, $V$ is the set of online vertices and $G$ has
edge probabilities $(p_{e})_{e \in E}$ and vertex weights $(w_{u})_{u \in U}$.
Additionally, $G$ has patience values $(\ell_{v})_{v \in V}$, where $\ell_v$
indicates the maximum number of edges adjacent to an online vertex $v$ which
can be probed. We assume that $U$ and $(w_{u})_{u \in U}$ are known in advance,
and that the patience, adjacent edges and edge probabilities for each online
vertex are only revealed when the online vertex arrives. If any one of the
following three conditions is satisfied, then there is a conceptually simple
deterministic greedy algorithm whose competitive ratio is $1-\frac{1}{e}$.
</p>
<p>(1) When the offline vertices are unweighted. $\\$
</p>
<p>(2) When the online vertex probabilities are "vertex uniform"; i.e., $p_{u,v}
= p_v$ for all $(u,v) \in E$. $\\$
</p>
<p>(3) When the patience constraint $\ell_v$ satisfies $\ell_v \in \{[1,|U|\}$
for every online vertex; i.e., every online vertex either has unit or full
patience.
</p>
<p>Setting the probability $p_e = 1$ for all $e \in E$, the stochastic problem
becomes the classical online bipartite matching problem. Our competitive ratios
thus generalize corresponding results for the classical ROM bipartite matching
setting.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09260"><span class="datestr">at August 24, 2020 01:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09052">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09052">On transversality of bent hyperplane arrangements and the topological expressiveness of ReLU neural networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grigsby:J=_Elisenda.html">J. Elisenda Grigsby</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lindsey:Kathryn.html">Kathryn Lindsey</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09052">PDF</a><br /><b>Abstract: </b>Let F:R^n -&gt; R be a feedforward ReLU neural network. It is well-known that
for any choice of parameters, F is continuous and piecewise (affine) linear. We
lay some foundations for a systematic investigation of how the architecture of
F impacts the geometry and topology of its possible decision regions for binary
classification tasks. Following the classical progression for smooth functions
in differential topology, we first define the notion of a generic, transversal
ReLU neural network and show that almost all ReLU networks are generic and
transversal. We then define a partially-oriented linear 1-complex in the domain
of F and identify properties of this complex that yield an obstruction to the
existence of bounded connected components of a decision region. We use this
obstruction to prove that a decision region of a generic, transversal ReLU
network F: R^n -&gt; R with a single hidden layer of dimension (n + 1) can have no
more than one bounded connected component.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09052"><span class="datestr">at August 23, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09008">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09008">On Fine-Grained Exact Computation in Regular Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Amiri:Saeed_Akhoondian.html">Saeed Akhoondian Amiri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09008">PDF</a><br /><b>Abstract: </b>We show that there is no subexponential time algorithm for computing the
exact solution of the maximum independent set problem in $d$-regular graphs,
for any constant $d&gt;2$, unless ETH fails. We also discuss the extensions of our
construction to other problems and other classes of graphs, including
$5$-regular planar graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09008"><span class="datestr">at August 23, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09004">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09004">Solving problems on generalized convex graphs via mim-width</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brettell:Nick.html">Nick Brettell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munaro:Andrea.html">Andrea Munaro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paulusma:Dani=euml=l.html">Daniël Paulusma</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09004">PDF</a><br /><b>Abstract: </b>A bipartite graph $G=(A,B,E)$ is ${\cal H}$-convex, for some family of graphs
${\cal H}$, if there exists a graph $H\in {\cal H}$ with $V(H)=A$ such that the
set of neighbours in $A$ of each $b\in B$ induces a connected subgraph of $H$.
A variety of well-known $\mathsf{NP}$-complete problems, including
\textsc{Dominating Set}, \textsc{Feedback Vertex Set}, \textsc{Induced
Matching} and \textsc{List $k$-Colouring}, become polynomial-time solvable for
${\mathcal H}$-convex graphs when ${\mathcal H}$ is the set of paths. In this
case, the class of ${\mathcal H}$-convex graphs is known as the class of convex
graphs. The underlying reason is that the class of convex graphs has bounded
mim-width. We extend the latter result to families of ${\mathcal H}$-convex
graphs where
</p>
<p>(i) ${\mathcal H}$ is the set of cycles, or
</p>
<p>(ii) ${\mathcal H}$ is the set of trees with bounded maximum degree and a
bounded number of vertices of degree at least $3$.
</p>
<p>As a consequence, we can re-prove and strengthen a large number of results on
generalized convex graphs known in the literature. To complement result (ii),
we show that the mim-width of ${\mathcal H}$-convex graphs is unbounded if
${\mathcal H}$ is the set of trees with arbitrarily large maximum degree or
arbitrarily large number of vertices of degree at least $3$. In this way we are
able to determine complexity dichotomies for the aforementioned graph problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09004"><span class="datestr">at August 23, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.09002">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.09002">On Turn-Regular Orthogonal Representations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bekos:Michael_A=.html">Michael A. Bekos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Binucci:Carla.html">Carla Binucci</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Battista:Giuseppe_Di.html">Giuseppe Di Battista</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Didimo:Walter.html">Walter Didimo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gronemann:Martin.html">Martin Gronemann</a>, Karsten Klein, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patrignani:Maurizio.html">Maurizio Patrignani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rutter:Ignaz.html">Ignaz Rutter</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.09002">PDF</a><br /><b>Abstract: </b>An interesting class of orthogonal representations consists of the so-called
turn-regular ones, i.e., those that do not contain any pair of reflex corners
that "point to each other" inside a face. For such a representation H it is
possible to compute in linear time a minimum-area drawing, i.e., a drawing of
minimum area over all possible assignments of vertex and bend coordinates of H.
In contrast, finding a minimum-area drawing of H is NP-hard if H is
non-turn-regular. This scenario naturally motivates the study of which graphs
admit turn-regular orthogonal representations. In this paper we identify
notable classes of biconnected planar graphs that always admit such
representations, which can be computed in linear time. We also describe a
linear-time testing algorithm for trees and provide a polynomial-time algorithm
that tests whether a biconnected plane graph with "small" faces has a
turn-regular orthogonal representation without bends.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.09002"><span class="datestr">at August 23, 2020 11:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08970">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08970">A Simple Proof of Optimal Approximations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Csik=oacute=s:M=oacute=nika.html">Mónika Csikós</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mustafa:Nabil_H=.html">Nabil H. Mustafa</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08970">PDF</a><br /><b>Abstract: </b>The fundamental result of Li, Long, and Srinivasan on approximations of set
systems has become a key tool across several communities such as learning
theory, algorithms, combinatorics and data analysis (described as `the pinnacle
of a long sequence of papers'). The goal of this paper is to give a simpler,
self-contained, modular proof of this result for finite set systems. The only
ingredient we assume is the standard Chernoff's concentration bound. This makes
the proof accessible to a wider audience, readers not familiar with techniques
from statistical learning theory, and makes it possible to be covered in a
single self-contained lecture in an algorithms course.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08970"><span class="datestr">at August 23, 2020 11:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08963">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08963">A Direct Product Theorem for One-Way Quantum Communication</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Rahul.html">Rahul Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kundu:Srijita.html">Srijita Kundu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08963">PDF</a><br /><b>Abstract: </b>We prove a direct product theorem for the one-way entanglement-assisted
quantum communication complexity of a general relation
$f\subseteq\mathcal{X}\times\mathcal{Y}\times\mathcal{Z}$. For any
$\varepsilon, \zeta &gt; 0$ and any $k\geq1$, we show that \[
\mathrm{Q}^1_{1-(1-\varepsilon)^{\Omega(\zeta^6k/\log|\mathcal{Z}|)}}(f^k) =
\Omega\left(k\left(\zeta^5\cdot\mathrm{Q}^1_{\varepsilon + 12\zeta}(f) -
\log\log(1/\zeta)\right)\right),\] where $\mathrm{Q}^1_{\varepsilon}(f)$
represents the one-way entanglement-assisted quantum communication complexity
of $f$ with worst-case error $\varepsilon$ and $f^k$ denotes $k$ parallel
instances of $f$.
</p>
<p>As far as we are aware, this is the first direct product theorem for quantum
communication. Our techniques are inspired by the parallel repetition theorems
for the entangled value of two-player non-local games, under product
distributions due to Jain, Pereszl\'{e}nyi and Yao, and under anchored
distributions due to Bavarian, Vidick and Yuen, as well as message-compression
for quantum protocols due to Jain, Radhakrishnan and Sen.
</p>
<p>Our techniques also work for entangled non-local games which have input
distributions anchored on any one side. In particular, we show that for any
game $G = (q, \mathcal{X}\times\mathcal{Y}, \mathcal{A}\times\mathcal{B},
\mathsf{V})$ where $q$ is a distribution on $\mathcal{X}\times\mathcal{Y}$
anchored on any one side with anchoring probability $\zeta$, then \[
\omega^*(G^k) = \left(1 - (1-\omega^*(G))^5\right)^{\Omega\left(\frac{\zeta^2
k}{\log(|\mathcal{A}|\cdot|\mathcal{B}|)}\right)}\] where $\omega^*(G)$
represents the entangled value of the game $G$. This is a generalization of the
result of Bavarian, Vidick and Yuen, who proved a parallel repetition theorem
for games anchored on both sides, and potentially a simplification of their
proof.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08963"><span class="datestr">at August 23, 2020 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08827">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08827">Plane Spanning Trees in Edge-Colored Simple Drawings of $K_n$</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aichholzer:Oswin.html">Oswin Aichholzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoffmann:Michael.html">Michael Hoffmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Obenaus:Johannes.html">Johannes Obenaus</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paul:Rosna.html">Rosna Paul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Perz:Daniel.html">Daniel Perz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seiferth:Nadja.html">Nadja Seiferth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vogtenhuber:Birgit.html">Birgit Vogtenhuber</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weinberger:Alexandra.html">Alexandra Weinberger</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08827">PDF</a><br /><b>Abstract: </b>K\'{a}rolyi, Pach, and T\'{o}th proved that every 2-edge-colored
straight-line drawing of the complete graph contains a monochromatic plane
spanning tree. It is open if this statement generalizes to other classes of
drawings, specifically, to simple drawings of the complete graph. These are
drawings where edges are represented by Jordan arcs, any two of which intersect
at most once. We present two partial results towards such a generalization.
First, we show that the statement holds for cylindrical simple drawings. (In a
cylindrical drawing, all vertices are placed on two concentric circles and no
edge crosses either circle.) Second, we introduce a relaxation of the problem
in which the graph is $k$-edge-colored, and the target structure must be
hypochromatic, that is, avoid (at least) one color class. In this setting, we
show that every $\lceil (n+5)/6\rceil$-edge-colored monotone simple drawing of
$K_n$ contains a hypochromatic plane spanning tree. (In a monotone drawing,
every edge is represented as an $x$-monotone curve.)
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08827"><span class="datestr">at August 23, 2020 11:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08811">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08811">Faster Heuristics for Graph Burning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gautam:Rahul_Kumar.html">Rahul Kumar Gautam</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kare:Anjeneya_Swami.html">Anjeneya Swami Kare</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhavani:S=_Durga.html">S. Durga Bhavani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08811">PDF</a><br /><b>Abstract: </b>Graph burning is a process of information spreading through the network by an
agent in discrete steps. The problem is to find an optimal sequence of nodes
which have to be given information so that the network is covered in least
number of steps. Graph burning problem is NP-Hard for which two approximation
algorithms and a few heuristics have been proposed in the literature. In this
work, we propose three heuristics, namely, Backbone Based Greedy Heuristic
(BBGH), Improved Cutting Corners Heuristic (ICCH) and Component Based Recursive
Heuristic (CBRH). These are mainly based on Eigenvector centrality measure.
BBGH finds a backbone of the network and picks vertex to be burned greedily
from the vertices of the backbone. ICCH is a shortest path based heuristic and
picks vertex to burn greedily from best central nodes. The burning number
problem on disconnected graphs is harder than on the connected graphs. For
example, burning number problem is easy on a path where as it is NP-Hard on
disjoint paths. In practice, large networks are generally disconnected and
moreover even if the input graph is connected, during the burning process the
graph among the unburned vertices may be disconnected. For disconnected graphs,
ordering of the components is crucial. Our CBRH works well on disconnected
graphs as it prioritizes the components. All the heuristics have been
implemented and tested on several bench-mark networks including large networks
of size more than $50$K nodes. The experimentation also includes comparison to
the approximation algorithms. The advantages of our algorithms are that they
are much simpler to implement and also several orders faster than the
heuristics proposed in the literature.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08811"><span class="datestr">at August 23, 2020 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08748">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08748">DPMC: Weighted Model Counting by Dynamic Programming on Project-Join Trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudek:Jeffrey_M=.html">Jeffrey M. Dudek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phan:Vu_H=_N=.html">Vu H. N. Phan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08748">PDF</a><br /><b>Abstract: </b>We propose a unifying dynamic-programming framework to compute exact
literal-weighted model counts of formulas in conjunctive normal form. At the
center of our framework are project-join trees, which specify efficient
project-join orders to apply additive projections (variable eliminations) and
joins (clause multiplications). In this framework, model counting is performed
in two phases. First, the planning phase constructs a project-join tree from a
formula. Second, the execution phase computes the model count of the formula,
employing dynamic programming as guided by the project-join tree. We
empirically evaluate various methods for the planning phase and compare
constraint-satisfaction heuristics with tree-decomposition tools. We also
investigate the performance of different data structures for the execution
phase and compare algebraic decision diagrams with tensors. We show that our
dynamic-programming model-counting framework DPMC is competitive with the
state-of-the-art exact weighted model counters cachet, c2d, d4, and miniC2D.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08748"><span class="datestr">at August 23, 2020 11:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08739">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08739">Simple and Efficient Cardinality Estimation in Data Streams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pettie:Seth.html">Seth Pettie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Dingyu.html">Dingyu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yin:Longhui.html">Longhui Yin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08739">PDF</a><br /><b>Abstract: </b>We study sketching schemes for the cardinality estimation problem in data
streams, and advocate for measuring the efficiency of such a scheme in terms of
its MVP: Memory-Variance Product, i.e., the product of its space, in bits, and
the relative variance of its estimates.
</p>
<p>Under this natural metric, the celebrated HyperLogLog sketch of Flajolet et
al. (2007) has an MVP approaching $6(3\ln 2-1)\approx 6.48$ for estimating
cardinalities up to $2^{64}$. Applying the Cohen/Ting (2014) martingale
transformation results in a sketch Martingale HyperLogLog with MVP $ \approx
4.16$, though it is not composable. Recently Pettie and Wang (2020) proved that
it is possible to achieve MVP approaching $\approx 1.98$ with a composable
sketch called Fishmonger, though the time required to update this sketch is not
constant.
</p>
<p>Our aim in this paper is to strike a nice balance between extreme simplicity
(exemplified by (Martingale) (Hyper)LogLog) and extreme information-theoretic
efficiency exemplified by Fishmonger). We develop a new class of "curtain"
sketches that are a bit more complex than Martingale LogLog but with
substantially better $\MVP$s, e.g., Martingale Curtain has MVP $ \approx 2.31$.
We also prove that Martingale Fishmonger has an MVP of around $1.63$, and
conjecture this to be an information-theoretic lower bound on the problem,
independent of update time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08739"><span class="datestr">at August 23, 2020 11:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08721">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08721">The Quantum Supremacy Tsirelson Inequality</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretschmer:William.html">William Kretschmer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08721">PDF</a><br /><b>Abstract: </b>A leading proposal for verifying near-term quantum supremacy experiments on
noisy random quantum circuits is linear cross-entropy benchmarking. For a
quantum circuit $C$ on $n$ qubits and a sample $z \in \{0,1\}^n$, the benchmark
involves computing $|\langle z|C|0^n \rangle|^2$, i.e. the probability of
measuring $z$ from the output distribution of $C$ on the all zeros input. Under
a strong conjecture about the classical hardness of estimating output
probabilities of quantum circuits, no polynomial-time classical algorithm given
$C$ can output a string $z$ such that $|\langle z|C|0^n\rangle|^2$ is
substantially larger than $\frac{1}{2^n}$ (Aaronson and Gunn, 2019). On the
other hand, for a random quantum circuit $C$, sampling $z$ from the output
distribution of $C$ achieves $|\langle z|C|0^n\rangle|^2 \approx \frac{2}{2^n}$
on average (Arute et al., 2019).
</p>
<p>In analogy with the Tsirelson inequality from quantum nonlocal correlations,
we ask: can a polynomial-time quantum algorithm do substantially better than
$\frac{2}{2^n}$? We study this question in the query (or black box) model,
where the quantum algorithm is given oracle access to $C$. We show that, for
any $\varepsilon \ge \frac{1}{\mathrm{poly}(n)}$, outputting a sample $z$ such
that $|\langle z|C|0^n\rangle|^2 \ge \frac{2 + \varepsilon}{2^n}$ on average
requires at least $\Omega\left(\frac{2^{n/4}}{\mathrm{poly}(n)}\right)$ queries
to $C$, but not more than $O\left(2^{n/3}\right)$ queries to $C$, if $C$ is
either a Haar-random $n$-qubit unitary, or a canonical state preparation oracle
for a Haar-random $n$-qubit state. We also show that when $C$ samples from the
Fourier distribution of a random Boolean function, the naive algorithm that
samples from $C$ is the optimal 1-query algorithm for maximizing $|\langle
z|C|0^n\rangle|^2$ on average.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08721"><span class="datestr">at August 23, 2020 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08680">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08680">On directed analogues of expander and hyperfinite graph sequences</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cs=oacute=ka:Endre.html">Endre Csóka</a>, Łukasz Grabowski <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08680">PDF</a><br /><b>Abstract: </b>We introduce and study analogues of expander and hyperfinite graph sequences
in the context of directed acyclic graphs, which we call "extender" and
"hypershallow" graph sequences, respectively. Our main result is a
probabilistic construction of non-hypershallow graph sequences.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08680"><span class="datestr">at August 23, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08654">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08654">The Power of Hashing with Mersenne Primes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahle:Thomas_Dybdahl.html">Thomas Dybdahl Ahle</a>, Jakob Tejs Bæk Knudsen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thorup:Mikkel.html">Mikkel Thorup</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08654">PDF</a><br /><b>Abstract: </b>The classic way of computing a $k$-universal hash function is to use a random
degree-$(k-1)$ polynomial over a prime field $\mathbb Z_p$. For a fast
computation of the polynomial, the prime $p$ is often chosen as a Mersenne
prime $p=2^b-1$.
</p>
<p>In this paper, we show that there are other nice advantages to using Mersenne
primes. Our view is that the output of the hash function is a $b$-bit integer
that is uniformly distributed in $[2^b]$, except that $p$ (the all \texttt1s
value) is missing. Uniform bit strings have many nice properties, such as
splitting into substrings which gives us two or more hash functions for the
cost of one, while preserving strong theoretical qualities. We call this trick
"Two for one" hashing, and we demonstrate it on 4-universal hashing in the
classic Count Sketch algorithm for second moment estimation.
</p>
<p>We also provide a new fast branch-free code for division and modulus with
Mersenne primes. Contrasting our analytic work, this code generalizes to
Pseudo-Mersenne primes $p=2^b-c$ for small $c$, improving upon a classical
algorithm of Crandall.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08654"><span class="datestr">at August 23, 2020 11:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08506">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08506">Novel Results on the Number of Runs of the Burrows-Wheeler-Transform</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giuliani:Sara.html">Sara Giuliani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lipt=aacute=k:Zsuzsanna.html">Zsuzsanna Lipták</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Prezza:Nicola.html">Nicola Prezza</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sciortino:Marinella.html">Marinella Sciortino</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Toffanello:Anna.html">Anna Toffanello</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08506">PDF</a><br /><b>Abstract: </b>The Burrows-Wheeler-Transform (BWT), a reversible string transformation, is
one of the fundamental components of many current data structures in string
processing. It is central in data compression, as well as in efficient query
algorithms for sequence data, such as webpages, genomic and other biological
sequences, or indeed any textual data. The BWT lends itself well to compression
because its number of equal-letter-runs (usually referred to as $r$) is often
considerably lower than that of the original string; in particular, it is well
suited for strings with many repeated factors. In fact, much attention has been
paid to the $r$ parameter as measure of repetitiveness, especially to evaluate
the performance in terms of both space and time of compressed indexing data
structures.
</p>
<p>In this paper, we investigate $\rho(v)$, the ratio of $r$ and of the number
of runs of the BWT of the reverse of $v$. Kempa and Kociumaka [FOCS 2020] gave
the first non-trivial upper bound as $\rho(v) = O(\log^2(n))$, for any string
$v$ of length $n$. However, nothing is known about the tightness of this upper
bound. We present infinite families of binary strings for which $\rho(v) =
\Theta(\log n)$ holds, thus giving the first non-trivial lower bound on
$\rho(n)$, the maximum over all strings of length $n$.
</p>
<p>Our results suggest that $r$ is not an ideal measure of the repetitiveness of
the string, since the number of repeated factors is invariant between the
string and its reverse. We believe that there is a more intricate relationship
between the number of runs of the BWT and the string's combinatorial
properties.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08506"><span class="datestr">at August 23, 2020 11:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron.html">Bricard’s jumping octahedron</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The <a href="https://en.wikipedia.org/wiki/Sch%C3%B6nhardt_polyhedron">Schönhardt polyhedron</a> is a non-convex octahedron that can be formed from a convex regular octahedron by twisting two opposite faces, stretching and deforming the other faces as you twist. It’s well known for not having any interior diagonals, and for being impossible to subdivide into tetrahedra without introducing new vertices. But long before Erich Schönhardt described it in 1928 in connection with these properties, Raoul Bricard was investigating <a href="https://en.wikipedia.org/wiki/Bricard_octahedron">flexible octahedra</a>, in connection with <a href="https://en.wikipedia.org/wiki/Cauchy%27s_theorem_(geometry)">Cauchy’s theorem on the rigidity of polyhedra</a>. The Schönhardt polyhedron forms an interesting example of flexibility, as I learned from a 1975 collection of lecture notes by Branko Grünbaum on “<a href="https://digital.lib.washington.edu/researchworks/bitstream/handle/1773/15700/Lost%20Mathematics.pdf?fterence=1">Lost Mathematics</a>”). I’m not entirely sure that it was known to Bricard (it’s not clear from Bricard’s paper and Grünbaum doesn’t really say so) but it wouldn’t surprise me if it was.</p>

<p>Cauchy’s theorem states that the shape of every convex polyhedron is uniquely determined by the shapes and connectivity of its faces. There can be no other convex polyhedron that has faces of the same shape, connected in the same way. But in some cases (like the regular icosahedron) you can dent some of the faces in to make a different, non-convex polyhedron with the same face shapes and connectivity. So Cauchy’s theorem doesn’t immediately extend to non-convex polyhedra. In fact, certain non-convex “<a href="https://en.wikipedia.org/wiki/Flexible_polyhedron">flexible polyhedra</a>” can deform continuously into an infinite range of shapes, without changing the shape or connectivity of their faces. Bricard’s octahedra are self-crossing examples and later investigators found examples without self-crossings.</p>

<p>But Grünbaum describes a different, non-self-crossing non-convex octahedron, the “jumping octahedron”. Rather than having a continuous range of rigid shapes, it has exactly two shapes, both of which have faces of the same shapes and connectivity. Unlike the example of the regular icosahedron and dented icosahedron, the two shapes have dihedral angles that are convex and concave in the same places. If you make this polyhedron out of perfectly rigid faces, with hinged connections at their edges, it could only be in one or the other of its two shapes: you wouldn’t be able to get it to the other shape without taking it apart and rebuilding it. But if you make it out of a material that’s stiff enough to hold its shape but flexible enough to deform a little, you can make a model that jumps or snaps from one shape to the other when you twist it. If you deform it a little out of shape, it will snap back to the nearest of its two valid shapes. Here’s one I made very roughly from some light cardstock and transparent tape, in its two shapes, one with only slightly-concave long diagonals down its sides and the other much more twisted and folded up:</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img width="315" style="border-style: solid; border-color: black;" alt="Jumping octahedron" src="http://www.ics.uci.edu/~eppstein/pix/jumping-octahedron/1-m.jpg" /></td>
<td style="padding: 10px;"><img width="315" style="border-style: solid; border-color: black;" alt="Jumping octahedron" src="http://www.ics.uci.edu/~eppstein/pix/jumping-octahedron/2-m.jpg" /></td>
</tr></tbody></table></div>

<p>My model makes an interesting squelchy sound when I twist it from the more upright shape to the more twisted one, because these two shapes have different volumes and the air has to get out through the cracks between the faces. If I had perfectly sealed all these cracks, the pressure change would prevent it from changing shape. This change in volume is a big contrast from the Bricard octahedra and other continuously-flexible polyhedra, which must maintain constant volume as they flex.</p>

<p>The net I folded it from looks like this:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/jumping-octahedron-net.svg" alt="Net for jumping octahedron" /></p>

<p>It’s in two parts in order to make the seams of my model be symmetric, but also that way it fits better onto a single sheet of paper or card. It consists of two equilateral-triangle faces (the faces at the top and bottom of the model shown above) and six identical obtuse triangles on the sides. In my net and model, these triangles are isosceles, but that’s not important. The important part is that, if one of these triangles is projected onto the line between it and the equilateral triangle, its projected length is slightly more than the length of the connecting edge (because it’s an obtuse triangle) but not too long: longer by a factor strictly between one and</p>

\[\frac{1}{2}+\frac{1}{\sqrt{3}}\approx 1.07735.\]

<p>If you make the projection too short (with a right or acute side triangle shape) then it will not have two different shapes that maintain the same faces and convex-concave relation at each dihedral. If you make the projection too long, then you won’t be able to put it together at all while keeping all the faces flat. An explanation for some of this behavior can be seen from the diagram below, which shows the bottom equilateral triangle and one of the obtuse side triangles of the polyhedron, flattened out into a single plane, from a top view.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/jumping-octahedron-overhead.svg" alt="Overhead view of two faces of the jumping octahedron" /></p>

<p>If you fold these two triangles on their connecting edge, keeping the bottom equilateral triangle fixed but lifting the obtuse triangle into space, then the outer vertex of the obtuse triangle will rotate through a semicircle, but the plane of this semicircle is perpendicular to the plane of view of the diagram, so in top view it just looks like a line, the red line in the diagram. The edge along which the two triangles are attached is the axis of rotation, so it’s perpendicular to the semicircle of rotation and to the projected red line. If you fold all three edges of the bottom equilateral triangle at equal angles, then by symmetry the tips of the three folded obtuse triangles will form another equilateral triangle, and the size of this equilateral triangle will depend on the fold angle. If the vertices of this second equilateral triangle project to points on the yellow circle (the circumcircle of the bottom equilateral triangle) then this triangle will have exactly the correct size to attach the top face. This is only possible when the vertex of the obtuse triangle in the drawing is folded to a point that projects to of the two crossings of the red line and the yellow circle. The two fold angles for which this happens give the two shapes of the jumping octahedron.</p>

<p>The constraint that the side triangles be obtuse is what is needed to make the two crossing points of the red line and the circle be in the same arc of the circle relative to the vertices of the bottom equilateral triangle. The constraint that their projected length should be only a little bit longer than the side length of the equilateral triangle is what is needed to make the red line cross the circle at all. So these two constraints are necessary to make the jumping octahedron work. There’s one more necessary constraint: the height of the obtuse triangle above the edge connecting it to the equilateral triangle has to be large enough to reach both of the crossing points of the red line. When I started to make the model I was worried about a different geometric constraint: maybe the twisted state of the model is so twisted that its inner folded parts cross each other near the center of the model? But that can’t happen. If it did happen, the projected view of the model would have the side triangles folded into a position where they cover the center of the yellow circle. But that would mean that the top triangle’s vertices are too far around the yellow circle, past the point where the farthest point of the red line can cross.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104737012685827990">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/08/22/bricards-jumping-octahedron.html"><span class="datestr">at August 22, 2020 05:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=20013">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/08/22/quantum-matters/">Quantum Matters</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2020/08/fig_2.jpeg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2020/08/fig_2.jpeg?w=640&amp;h=472" class="alignnone size-full wp-image-20101" height="472" /></a></p>
<p><span style="color: #ff0000;">A comparison between the Google estimator U for the fidelity and two improved estimators that we studied  MLE (maximum likelihood estimator) and V (a variant of U). (More figures at the end of the post.)</span></p>
<p>Here are some links on quantum matters. I hope to return to them in more detail in some future posts.</p>
<h2>1. A <a href="https://gilkalai.files.wordpress.com/2019/11/stat-quantum2.pdf">paper</a> with Yosi Rinott and Tomer Shoham on the Statistics of Google’s experiment</h2>
<p>Yosef Rinott, Tomer Shoham and Gil Kalai:  <a href="https://gilkalai.files.wordpress.com/2019/11/stat-quantum2.pdf">Statistical aspects of the quantum supremacy demonstration</a>, (<a href="https://arxiv.org/abs/2008.05177">arXive</a>)</p>
<p><strong>Abstract:</strong></p>
<blockquote><p><span style="color: #0000ff;"><em>The notable claim of quantum supremacy presented by Google’s team in 2019 consists of demonstrating the ability of a quantum circuit to generate, albeit with considerable noise, bitstrings from a distribution that is considered hard to simulate on classical computers. Verifying that the generated data is indeed from the claimed distribution and assessing the circuit’s noise level and its fidelity is a purely statistical undertaking.</em></span></p>
<p><span style="color: #0000ff;"><em>The objective of this paper is to explain the relations between quantum computing and some of the statistical aspects involved in demonstrating quantum supremacy in terms that are accessible to statisticians, computer scientists, and mathematicians.</em></span></p>
<p><span style="color: #0000ff;"><em>Starting with the statistical analysis in Google’s demonstration, which we explain, we study various estimators of the fidelity, and different approaches to testing the distributions generated by the quantum computer. We propose different noise models, and discuss their implications. A preliminary study of the Google data, focusing mostly on circuits of 12 and 14 qubits is discussed throughout the paper.</em></span></p></blockquote>
<p>I am greatly enjoying working with Yosi and Tomer, and I hope to devote a special post to the very interesting statistics of the Google supremacy experiment.</p>
<h2></h2>
<h2>2. My paper <a href="https://gilkalai.files.wordpress.com/2020/08/laws-blog2.pdf">The Argument against Quantum Computers, the Quantum Laws of Nature, and Google’s Supremacy Claims</a></h2>
<p>Here is how the paper concludes</p>
<blockquote><p><span style="color: #0000ff;"><em>Over the past four decades, the very idea of quantum computation has led to many advances in several areas of physics, engineering, computer science, and mathematics. I expect that the most important application will eventually be the understanding of the impossibility of quantum error-correction and quantum computation. Overall, the debate over quantum computing is a fascinating one, and I can see a clear silver lining: major advances in human ability to simulate quantum physics and quantum chemistry are expected to emerge if quantum computational supremacy can be demonstrated and quantum computers can be built, but also if quantum computational supremacy cannot be demonstrated and quantum computers cannot be built.</em></span></p>
<p><span style="color: #0000ff;"><em>Some of the insights and methods characteristic of the area of quantum computation might be useful for classical computation of realistic quantum systems – which is, apparently, what nature does.</em></span></p></blockquote>
<p> </p>
<p>The link above is the most recent version that will be updated; Here is the <a href="https://arxiv.org/abs/2008.05188">arXive version</a>. A discussion on <a href="https://news.ycombinator.com/item?id=23291071">Hacker News</a>.</p>
<h2></h2>
<h2>3. My Dec 2019 surprise lecture and the panel discussion</h2>
<p>My Dec  19 2019 (B.C.) surprise lecture at the mathematics of quantum computing school and the afternoon panel on the same day. It turned out that the lecture was videotaped. The slides can be seen in <a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/">this post</a>. Remarkably, social distancing was pioneered by the session chair toward the end of the lecture (while not justified in that case).</p>
<p></p>
<p>Here once again again is <a href="https://youtu.be/_Yb7uIGBynU">the link for the panel discussion on quantum supremacy</a> of the same day (<a href="https://gilkalai.wordpress.com/2019/12/27/the-google-quantum-supremacy-demo/">reviewed here</a>) . Here is a quote of mine from the panel.</p>
<blockquote><p><em><span style="color: #0000ff;">Of course, it is important to think what are the implications of quantum supremacy, is it useful? what does it say on the extended Church-Turing thesis? on prospects for quantum error-correction and universal quantum computers? etc. but I think that in the next few years one thing that we need to also concentrate on is the following question: Is the Google experiment correct? Is this a correct scientific verification of quantum supremacy?</span></em></p></blockquote>
<h2></h2>
<h2>4. My July 15 USTLC lecture</h2>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/4slides.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2020/08/4slides.png?w=640&amp;h=364" class="alignnone size-full wp-image-20091" height="364" /></a></p>
<p><span style="color: #ff0000;">Four slides from my USTLC zoom lecture</span><span style="color: #ff0000;">. (Click to enlarge.)<br />
</span></p>
<p>Here is the <a href="https://idc-il.zoom.us/rec/share/4v58MpbZ-CBJG7OO1E3SYYN-P426aaa82ndLr_cMyEgOuIwdOStnnIw18Xsg0dUr?fbclid=IwAR31ShatGHJ1bWpVCdBPUoWhG3VjqmhfD1kQBFVLGzmvtNlWNMW-T58_0dw">videotaped Zoom presentation</a> and <a href="https://gilkalai.files.wordpress.com/2019/11/july1.pptx">here are the slides</a>.</p>
<h2></h2>
<h2>5. A small taste of quantum poetry for the skeptics. (A full post is coming.)</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/12/dslide16.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/12/dslide16.png?w=640&amp;h=362" class="alignnone size-large wp-image-19013" height="362" /></a></p>
<p><span style="color: #ff0000;">Poems by Peter Shor and Renan Gross (click to enlarge)</span></p>
<p>Peter Shor <a href="https://twitter.com/PeterShor1/status/1199299777743204354">pioneered</a> quantum poetry for the skeptics over Twitter. There were many very nice contributions all over social media by <a href="https://gilkalai.files.wordpress.com/2019/12/dslide16.png">Renan Gross</a>, John Dowling, Nidit Nanda, ⟨dl|yonge|mallo⟩, Alfred Marcel Bruckstein, Kenneth Regan, and others. <strong>Keep the quantum poems coming!</strong> Of course, the poems should be taken with humor. Here is a small taste.</p>
<h3><span style="color: #993366;">My short response to Peter’s poem</span></h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>Understanding nature and ourselves is a worthy dream</em></span><br />
<span style="color: #0000ff;"><em>Requiring no interaction with the supreme</em></span></h3>
</blockquote>
<h3><span style="color: #993366;">Limericks</span></h3>
<h3>Jon Dowling</h3>
<p><span id="more-20013"></span></p>
<blockquote><p><em>A quantum computer from Google,</em><br />
<em>Turned the Church-Turing thesis to strudel.</em><br />
<em>And yet there remain,</em><br />
<em>Many doubting this claim,</em><br />
<em>And we lash all of them with wet noodles.</em></p></blockquote>
<h3>Avi Wigderson</h3>
<blockquote><p><em>“There once was a quantum computer</em><br />
<em>Whose pet was a five-legged hamster …”</em><br />
<em>So Peter and Gil</em><br />
<em>Their grandchildren will</em><br />
<em>Tell “…happy they lived ever after”</em></p></blockquote>
<p>Avi suggests a kids’ chorus saying “yeah, right” or “sure, sure”, after each line</p>
<h3><span style="color: #993366;">Six-word stories</span></h3>
<h3>Ehud Friedgut</h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>For sale: <span class="il">quantum</span> computer. Never used.</em></span></h3>
</blockquote>
<h3>Another 6-word story (mine) with a rhyme (of some sort)</h3>
<blockquote>
<h3><span style="color: #0000ff;"><em>Michelson and Morley weren’t </em></span><em><strong><span style="color: #0000ff;">G</span><span style="color: #ff0000;">o</span><span style="color: #ffcc00;">o</span><span style="color: #0000ff;">g</span><span style="color: #339966;">l</span><span style="color: #ff0000;">e</span></strong></em><span style="color: #0000ff;"><em> employees.</em></span></h3>
</blockquote>
<h2></h2>
<h2>6. More figures from my paper with Yosi and Tomer.</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/plot_3.jpeg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2020/08/plot_3.jpeg?w=640&amp;h=350" class="alignnone size-full wp-image-20102" height="350" /></a></p>
<p><span style="color: #ff0000;">Various estimators for the fidelity for the Google data compared to simulations. </span></p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/fig_8.jpeg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2020/08/fig_8.jpeg?w=640&amp;h=519" class="alignnone size-full wp-image-20103" height="519" /></a></p>
<p><span style="color: #ff0000;">The model expected values compared to the empirical distribution. On the left for the real data and on the right for simulated data.  As it turned out the Google noise model does not fit for the sample data. (Our readout model provides only a small improvement.)  </span></p>
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2020/08/hists.jpeg"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2020/08/hists.jpeg?w=640&amp;h=249" class="alignnone size-full wp-image-20104" height="249" /></a></p>
<p><span style="color: #ff0000;">The size biased distribution fits the model very well.</span></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/08/22/quantum-matters/"><span class="datestr">at August 22, 2020 05:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/127">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/127">TR20-127 |  $k$-Forrelation Optimally Separates Quantum and Classical Query Complexity | 

	Nikhil Bansal, 

	Makrand Sinha</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Aaronson and Ambainis (SICOMP '18) showed that any partial function on $N$ bits that can be computed with an advantage $\delta$ over a random guess by making $q$ quantum queries, can also be computed classically with an advantage $\delta/2$ by a randomized decision tree making ${O}_q(N^{1-\frac{1}{2q}}\delta^{-2})$ queries. Moreover, they conjectured the $k$-Forrelation problem --- a partial function that can be computed with $q = \lceil k/2 \rceil$ quantum queries --- to be a suitable candidate for exhibiting such an extremal separation. 
    
     We prove their conjecture by showing a tight lower bound of $\widetilde{\Omega}_k(N^{1-1/k})$ for the randomized query complexity of $k$-Forrelation, where the advantage $\delta = 1/\mathrm{polylog}^k(N)$ and $\widetilde{\Omega}_k$ hides $\mathrm{polylog}^k(N)$ factors. Our proof relies on classical Gaussian tools, in particular, Gaussian interpolation and Gaussian integration by parts, and in fact, shows a more general statement, that to prove lower bounds for $k$-Forrelation against a family of functions, it suffices to bound the $\ell_1$-weight of the Fourier coefficients at levels $k, 2k, 3k, \ldots, (k-1)k$ for functions in the family.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/127"><span class="datestr">at August 21, 2020 07:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/08/21/phd-or-postdoc-at-goethe-university-frankfurt-apply-by-august-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/08/21/phd-or-postdoc-at-goethe-university-frankfurt-apply-by-august-31-2020/">PhD or Postdoc at Goethe University Frankfurt (apply by August 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The research group by Holger Dell at Goethe University Frankfurt is inviting applications for a three-year PhD or Postdoc position, starting at the earliest possible date. Potential topics include the algorithmic theory of network science, algebraic graph algorithms, fine-grained and parameterized complexity, “classical” complexity theory, as well as adjacent areas.</p>
<p>Website: <a href="https://www.t.cs.uni-frankfurt.de/positions/">https://www.t.cs.uni-frankfurt.de/positions/</a><br />
Email: recruiting2020@holgerdell.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/08/21/phd-or-postdoc-at-goethe-university-frankfurt-apply-by-august-31-2020/"><span class="datestr">at August 21, 2020 02:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17421">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/">Logical Complexity of Proofs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>If you cannot find proofs, talk about them.</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/rr/" rel="attachment wp-att-17427"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/rr.png?w=300&amp;h=119" class="alignright size-medium wp-image-17427" height="119" /></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Robert Reckhow with his advsior Stephen Cook famously started the formal study of the complexity of proofs with their 1979 <a href="https://www.cs.toronto.edu/~sacook/homepage/cook_reckhow.pdf">paper</a>. They were interested in the length of the shortest <a href="https://en.wikipedia.org/wiki/Proof_complexity">proofs</a> of propositional statements. Georg Kreisel and others may have looked at proof length earlier, but one of the key insights of Reckhow and Cook is that low level propositional logic is important.</p>
<p>
Today I thought we might look at the complexity of proofs.</p>
<p>
Cook and Reckhow were motivated by issues like: How hard is it to prove that a graph has no clique of a certain size? Or how hard to prove that some program halts on all inputs of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />? All of these questions ask about the length of proofs in a precise sense. Proofs have been around forever, back to Euclid at least, but Cook and Reckhow were the first to formally study the lengths of proofs. </p>
<p>
They were not directly interested in actual proofs. The kind you can find in the <a href="https://arxiv.org/archive/math">arXiv</a> or in a math journal, or at a conference—online or not. The kind that are in their paper.<br />
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/paper-5/" rel="attachment wp-att-17432"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/paper.png?w=300&amp;h=60" class="aligncenter size-medium wp-image-17432" height="60" /></a></p>
<p>We are talking today about these types of proofs. Not proofs that graphs have cliques. But proofs that a no planar graph can have a <img src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5}" class="latex" title="{5}" /> clique. </p>
<p><a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/unknown-144/" rel="attachment wp-att-17430"><img src="https://rjlipton.files.wordpress.com/2020/08/unknown.png?w=600" alt="" class="aligncenter size-full wp-image-17430" /></a></p>
<p>
</p><p></p><h2> Proofs </h2><p></p>
<p></p><p>
Proofs are what we strive to find ever day. They the coin that measures progress in a mathematical field like complexity theory. We do sometimes work out examples, sometimes do computations to confirm conjectures on small examples, sometimes consider analogies to other proofs. But mostly we want to understand proofs. We want to create new ones and understand others proofs. </p>
<p>
Years ago when studying the graph isomorphism problem, I did some extensive computations for the random case. That is for the case of isomorphism for a random dense graphs against a worst case other graph. The computations helped me improve my result. It did not yield a proof, of course, but helped me realize that a certain lemma could be improved from a bound <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log n}" class="latex" title="{\log n}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" />. My results were dominated by <a href="https://www.researchgate.net/profile/Stanley_Selkow/publication/220618511_Random_Graph_Isomorphism/links/00463537d337e6a35d000000/Random-Graph-Isomorphism.pdf">paper</a> of Laszlo Babai, Paul Erdös, and Stanley Selkow. Oh well. </p>
<p>
</p><p></p><h2> Proofs Complexity </h2><p></p>
<p></p><p>
There are several measures of complexity for proofs. One is the length. Long proofs are difficult to find, difficult to write up, difficult to read, and difficult to check. Another less obvious measure is the logical structure of a proof. What does this mean?</p>
<p>
Our idea is that a proof can be modeled by a formula from propositional logic. The <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> is what we are trying to prove and the letters <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and so on are for statements we already know.  </p>
<li>
<img src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(A \rightarrow P)}" class="latex" title="{(A \rightarrow P)}" />  This is a direct proof. <p></p>
</li><li>
<img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cneg+P+%5Crightarrow+%5Cneg+A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\neg P \rightarrow \neg A)}" class="latex" title="{(\neg P \rightarrow \neg A)}" />  This is a proof by contradiction. <p></p>
</li><li>
<img src="https://s0.wp.com/latex.php?latex=%7B%28+A+%5Cvee+%5Cneg+A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{( A \vee \neg A \rightarrow P)}" class="latex" title="{( A \vee \neg A \rightarrow P)}" />  This is proof that uses a statement <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> that may be true or false. <p></p>
<p>
The last is a slight cheat, we use <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Cvee+%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \vee \neg A}" class="latex" title="{A \vee \neg A}" /> to stand for a kind of axiom. A perfect example is from number theory. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi(X)}" class="latex" title="{\pi(X)}" /> be the number of primes less than <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and the function <img src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{li(x)}" class="latex" title="{li(x)}" /> the <a href="https://en.wikipedia.org/w/index.php?title=Logarithmic_integral_function&amp;action=edit&amp;section=1">logarithmic function</a>. 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%3D+%5Cint_0%5Ex+%5Cfrac%7Bdt%7D%7B%5Cln+t%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. " class="latex" title="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. " /></p>
<p>The prime number <a href="https://en.wikipedia.org/wiki/Prime_number_theorem">theorem</a> says that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+%3D+li%28x%29+%2B+E%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) = li(x) + E(x), " class="latex" title="\displaystyle  \pi(x) = li(x) + E(x), " /></p>
<p>an error term. </p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/graph/" rel="attachment wp-att-17425"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/graph.png?w=300&amp;h=171" class="aligncenter size-medium wp-image-17425" height="171" /></a>
</td>
</tr>
<tr>
</tr>
</tbody></table>
<p>
It was noted that <img src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{li(x)}" class="latex" title="{li(x)}" /> is larger than <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi(x)}" class="latex" title="{\pi(x)}" /> for known values. The obvious question was that could 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%5Cge+%5Cpi%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  li(x) \ge \pi(x), " class="latex" title="\displaystyle  li(x) \ge \pi(x), " /></p>
<p>be always true? If so this would be an interesting inequality. In 1914 John Littlewood famously <a href="https://www.google.com/books/edition/_/2SUrpE8NK6sC?hl=en&amp;gbpv=1&amp;pg=PA33&amp;dq=John+Littlewood+pi+nd+li">proved</a> that this was not true: </p>
<blockquote><p><b>Theorem 1</b> <em> If the Riemann Hypothesis is true: 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) - li(x) " class="latex" title="\displaystyle  \pi(x) - li(x) " /></p>
<p>is infinitely often positive and negative. If the Riemann Hypothesis is false: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) - li(x) " class="latex" title="\displaystyle  \pi(x) - li(x) " /></p>
</em><p><em>is infinitely often positive and negative. </em>
</p></blockquote>
<p></p><p>
Thus he proved that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) - li(x) " class="latex" title="\displaystyle  \pi(x) - li(x) " /></p>
<p>is infinitely often positive and negative whether the the Riemann is true or not. </p>
<p>
</p><p></p><h2> Proofs in Trouble </h2><p></p>
<p></p><p>
A sign of a proof in danger is, in my opinion, is not just the length. A better measure I think is the logical flow of proof. I know of no actual proof that uses this structure: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28A+%5Crightarrow+B%29+%5Crightarrow+%28%28A+%5Cvee+C%29+%5Crightarrow+%28B+%5Cvee+C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) " class="latex" title="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) " /></p>
<p>Do you? Even if your proof is only a few lines or even pages, if the high level flow was the above tautology I would be worried. </p>
<p>
Another example is <img src="https://s0.wp.com/latex.php?latex=%7BP+%5Crightarrow+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P \rightarrow P}" class="latex" title="{P \rightarrow P}" />. This of course is a circular proof. It seems hard to believe we would actually do this, but it has happen. The key is that no one says: I will assume the theorem to prove it. The flaw is disguised better than that.</p>
<p>
I cannot formally define this measure. Perhaps it is known, but I do think that it would be an additional measure. For actual proofs, ones we use every day, perhaps it would be valuable. I know I have looked at an attempted proof of X and noticed the logical flow in this sense was too complex. So complex that it was wrong. The author of the potential proof was me. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Is this measure, the logical flow of a proof, of any interest? </p>
<p></p></li></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/"><span class="datestr">at August 19, 2020 01:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-25562705.post-41257542542066199">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/roth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://aaronsadventures.blogspot.com/2020/08/moment-multicalibration-for-uncertainty.html">Moment Multicalibration for Uncertainty Estimation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
This blog post is about<a href="https://arxiv.org/abs/2008.08037" target="_blank"> a new paper</a> that I'm excited about, which is joint work with <a href="https://www.cis.upenn.edu/~chrjung/" target="_blank">Chris Jung</a>,<a href="https://economics.sas.upenn.edu/people/changhwa-lee" target="_blank"> Changhwa Lee</a>, <a href="https://sites.google.com/view/malleshpai/">Mallesh Pai</a>, and <a href="https://sites.google.com/site/quaerereverum9/">Ricky Vohra</a>. <div><br /></div><div>Suppose you are diagnosed with hypertension, and your doctor recommends that you take a certain drug to lower your blood pressure. The latest research, she tells you, finds that the drug lowers diastolic blood pressure by an average of 10 mm Hg. You remember your statistics class from college, and so you ask about confidence intervals. She looks up the paper, and tells you that it reports a 95% confidence interval of [5, 15]. How should you interpret this? </div><div><br /></div><div>What you might naively hope is that [5, 15] represents a <i>conditional prediction interval</i>. If you have some set of observable features $x$, and a label $y$ (in this case corresponding to your decrease in diastolic blood pressure after taking the drug), a 95% conditional prediction interval would promise that:</div><div>$$\Pr_y [y \in [5, 15] | x] \geq 0.95$$</div><div><br /></div><div>In other words, a conditional prediction interval would promise that given all of your observed features, <i>over the unrealized/unmeasured randomness of the world</i>, there is a 95% chance that your diastolic blood pressure will decrease by between 5 and 15 points. </div><div><br /></div><div>But if you think about it, coming up with a conditional prediction interval is essentially impossible in a rich feature space. If $x$ contains lots of information about you, then probably there was nobody in the original study population that exactly matched your set of features $x$, and so we have no information at all about the conditional distribution on $y$ given $x$ --- i.e. no samples at all from the distribution over which our coverage probability supposedly holds! So how can you expect any sort of promise at all? There are two typical ways around this difficulty. </div><div><br /></div><div>The first is to make heroic assumptions about the data generation process. For example, if we assume that the world looks like an ordinary least squares model, and that there is a linear relationship between $y$ and $x$, then we can form a confidence region around the parameters of the model, and from that derive prediction intervals. But these prediction intervals are not valid if the model fails to hold, which it inevitably will. </div><div><br /></div><div>The second is to give up on conditional prediction intervals, and instead give <i>marginal prediction intervals</i>. This is what the <a href="https://arxiv.org/abs/0706.3188" target="_blank">conformal prediction</a> literature aims to do. A marginal prediction interval looks quite similar to a conditional prediction interval (at least syntactically), and promises:</div><div>$$\Pr_{(x,y)} [y \in [5, 15] ] \geq 0.95$$</div><div><br /></div><div>Rather than conditioning on your features $x$, a marginal prediction interval averages over all people, and promises that 95% of people who take the drug have their diastolic blood pressure lowered by between 5 and 15 points. But the semantics of this promise are quite different than that of a conditional prediction interval. Because the average is now taken over a large, heterogeneous population, very little is promised to <i>you</i>. For example, it might be that for patients in your demographic group (e.g. middle aged women with Sephardic Jewish ancestry and a family history of diabetes) that the drug is actually expected to raise blood pressure rather than lower it. Because this subgroup represents less than 5% of the population, it is entirely consistent with the marginal prediction interval being correct. Of course, if you are lucky, then perhaps someone has conducted a study of people from this demographic group and has computed marginal prediction intervals over it! But what if there are multiple different groups that you are a member of, over which the results seem to conflict? For example, you might also have a low BMI value and have unusually good cholesterol readings --- features of a group for which the drug works unusually well. Which uncertainty estimate should you trust, if you are a member of both groups? </div><div><br /></div><div>These concerns actually arise already when we think about the semantics of mean estimations ("the expected drop in blood pressure amongst patients who take this drug is 10 mm Hg"). Ideally, if you were a patient with features $x$, then 10 would be an estimate of $\mathbb{E}[y | x]$. But just as with uncertainty estimation, in a large feature space, we typically have no information about the distribution on $y$ conditional on $x$ (because we have never met anyone exactly like <i>you</i> before), and so instead what we have is just an estimate of $\mathbb{E}[y]$ --- i.e. averaging over people. If you have a method of making predictions $f(x)$ as a function of features $x$, then a standard performance metric is <i>calibration</i> --- which informally asks that for every prediction $p$, amongst all people for whom we predicted $f(x) = p$, the average of the realized labels $y$ should be $p$. Again, estimates of this form promise little to individuals, because they are averages over a large and heterogeneous population.   </div><div><br /></div><div>Several years ago, <a href="https://arxiv.org/abs/1711.08513" target="_blank">Hebert-Johnson et al.</a> proposed a nice way to interpolate between the (impossible) ideal of offering conditional mean predictions  $f(x) = \mathbb{E}[y | x]$, and the weak guarantee of merely offering calibrated predictions $f$. Roughly speaking, they proposed to specify a very large collection of potentially intersecting groups $G$ (representing e.g. demographic groups like Sephardic Jewish women with a family history of diabetes, and hypertensive patients with low cholesterol and BMI values, etc) and to ask that a trained predictor be <i>simultaniously</i> calibrated on each sufficiently large group in $G$. They showed how to accomplish this using a polynomially sized sample from the underlying distribution, with polynomial running time overhead, on top of the cost of solving learning problems over $G$. </div><div><br /></div><div>In our paper, we --- roughly speaking --- show how to accomplish the same thing, but for variances and other higher moments, in addition to just means. And our "multicalibrated moment estimates" can be used to construct prediction intervals in exactly the same way that real moments of the conditional label distribution could be used. If you used the real (unknown) label distribution moments, you would have gotten conditional prediction intervals. If you use our multi-calibrated moments, you get marginal prediction intervals that are simultaneously valid as averaged over each of the groups in $G$. So, for example, our hypertensive patient above could interpret her prediction interval --- if it was constructed from multicalibrated moment estimates computed from her features --- as an average over each of the demographic groups that she is a member of (so long as they are contained within $G$), and all of those interpretations would be simultaneously valid. </div><div><br /></div><div>I'll leave the details to the paper --- including what exactly we mean by "moment multicalibration". I'll just note that a major difficulty is that variances and higher moments --- unlike expectations --- do not combine linearly, so it is no longer sensible to ask that "amongst all people for whom we predicted variance v, the true variance should be v" --- because even the true conditional label variances do not satisfy this property. But it <i>is </i>sensible to ask that a pair of mean and moment predictions be calibrated in this way: "amongst all people for whom we predicted mean $\mu$ and variance v, the true mean should be $\mu$ and the true variance should be $v$." This is what we call "mean-conditioned moment calibration", and it is satisfied by the true distributional moments. </div><div><br /></div><div>The paper is here: <a href="https://arxiv.org/abs/2008.08037">Moment Multicalibration for Uncertainty Estimation</a>.</div><div><br /></div></div>







<p class="date">
by Aaron (noreply@blogger.com) <a href="http://aaronsadventures.blogspot.com/2020/08/moment-multicalibration-for-uncertainty.html"><span class="datestr">at August 19, 2020 11:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/126">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/126">TR20-126 |  Indistinguishability Obfuscation from Well-Founded Assumptions | 

	Aayush  Jain, 

	Huijia Lin, 

	Amit Sahai</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work, we show how to construct indistinguishability obfuscation from subexponential hardness of four well-founded assumptions. We prove:

Let $\tau \in (0,\infty), \delta \in (0,1), \epsilon \in (0,1)$ be arbitrary constants. Assume sub-exponential security of the following assumptions, where $\lambda$ is a security parameter, and the parameters $\ell,k,n$ below are large enough polynomials in $\lambda$:

- The SXDH assumption on asymmetric bilinear groups of a prime order $p = O(2^\lambda)$,

- The LWE assumption over $\mathbb{Z}_{p}$ with subexponential modulus-to-noise ratio $2^{k^\epsilon}$, where $k$ is the dimension of the LWE secret,

- The LPN assumption over $\mathbb{Z}_p$ with polynomially many LPN samples and error rate $1/\ell^\delta$, where $\ell$ is the dimension of the LPN secret,

- The existence of a Boolean PRG in $\mathsf{NC}^0$ with stretch $n^{1+\tau}$,
 
Then, (subexponentially secure) indistinguishability obfuscation for all polynomial-size circuits exists.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/126"><span class="datestr">at August 19, 2020 11:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/125">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/125">TR20-125 |  Efficient reconstruction of depth three circuits with top fan-in two | 

	Gaurav  Sinha</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper we develop efficient randomized algorithms to solve the black-box reconstruction problem for polynomials(over finite fields) computable by depth three arithmetic circuits with alternating addition/multiplication gates, such that top(output) gate is an addition gate with in-degree $2$. Such circuits naturally compute polynomials of the form $G\times(T_1 + T_2)$, where $G,T_1,T_2$ are product of affine forms computed at the first(addition) layer in the circuit, and polynomials $T_1,T_2$ have no common factors. Rank of such a circuit is defined to be the dimension of vector space spanned by all affine factors of $T_1$ and $T_2$. For any polynomial $f$ computable by such a circuit, $rank(f)$ is defined to be the minimum rank of any such circuit computing it. Our work develops randomized algorithms, which take as input a black-box computing polynomial $f$, with coefficients in a finite field $\mathbb{F}$, exhibiting such a circuit. Here are the results. 

$[$Low rank$]:$ When $5\leq r = rank(f) = O(\log^3 d)$, it runs in time $(nd^{\log^3d}\log |\mathbb{F}|)^{O(1)}$ and outputs a depth three circuit computing $f$ (with high probability), with top addition gate having in-degree $\leq d^{rank(f)}$.

$[$High rank$]:$ When $rank(f) = \Omega(\log^3 d)$, it runs in time $(nd\log |\mathbb{F}|)^{O(1)}$, and with high probability outputs a depth three circuit computing $f$, with top addition gate having in-degree $2$.

Prior to our work, black-box reconstruction for this circuit class was addressed in [Shp07, KS09, Sin16b]. Reconstruction algorithm in [Shp07] runs in time quasi-polynomial in $n,d,|\mathbb{F}|$ and that in [KS09] is quasi-polynomial in $d,|\mathbb{F}|$. Algorithm in [Sin16b] works only for polynomials over characteristic zero fields. Thus ours is the first blackbox reconstruction algorithm for this class of circuits that runs in time polynomial in $\log |\mathbb{F}|$. This problem has been mentioned as an open problem in [GKL12] (STOC 2012). In the high rank case, our algorithm runs in $(nd\log|\mathbb{F}|)^{O(1)}$ time, thereby significantly improving the existing algorithms in [Shp07, KS09].</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/125"><span class="datestr">at August 17, 2020 07:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/124">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/124">TR20-124 |  A Strong XOR Lemma for Randomized Query Complexity | 

	Joshua Brody, 

	JaeTak Kim, 

	Peem Lerdputtipongporn, 

	Hariharan Srinivasulu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give a strong direct sum theorem for computing $XOR \circ g$.  Specifically, we show that the randomized query complexity of computing the XOR of $k$ instances of $g$ satisfies $\bar{R}_\varepsilon(XOR \circ g)=\Theta(\bar{R}_{\varepsilon/k}(g))$.  This matches the naive success amplification bound and answers a question of Blais and Brody.

As a consequence of our strong direct sum theorem, we give a total function $g$ for which $R(XOR \circ g) = \Theta(k\log(k)R(g))$, answering an open question from Ben-David et al.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/124"><span class="datestr">at August 17, 2020 01:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/123">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/123">TR20-123 |  An Optimal Tester for k-Linear | 

	Nader Bshouty</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A Boolean function $f:\{0,1\}^n\to \{0,1\}$ is $k$-linear if it returns the sum (over the binary field $F_2$) of $k$ coordinates of the input. In this paper, we study property testing of the classes $k$-Linear, the class of all $k$-linear functions, and $k$-Linear$^*$, the class $\cup_{j=0}^kj$-Linear.
We give a non-adaptive distribution-free two-sided $\epsilon$-tester for $k$-Linear that makes
$$O\left(k\log k+\frac{1}{\epsilon}\right)$$ queries.
This matches the lower bound known from the literature.

We then give a non-adaptive distribution-free one-sided $\epsilon$-tester for $k$-Linear$^*$ that makes the same number of queries and show that any non-adaptive uniform-distribution one-sided $\epsilon$-tester for $k$-Linear must make at least $ \tilde\Omega(k)\log n+\Omega(1/\epsilon)$ queries. The latter bound, almost matches the upper bound $O(k\log n+1/\epsilon)$ known from the literature. We then show that any adaptive uniform-distribution one-sided $\epsilon$-tester for $k$-Linear must make at least $\tilde\Omega(\sqrt{k})\log n+\Omega(1/\epsilon)$ queries.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/123"><span class="datestr">at August 17, 2020 01:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6748297921609096715">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/04/what-if-history-of-science-factoring.html">Mathematics is not commutative</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In my poll of P vs NP and other issues, one of the questions was<br />
<br />
<br />
                             <i>Is factoring in P?</i><br />
<i><br /></i>
One of the most interesting answers was<br />
<br />
<br />
                            <i> I don't really see why it shouldn't be. - Peter Shor</i><br />
<i><br /></i>
Recall that Peter Shor proved Factoring is in Quantum-P which lead to intense interest in Quantum Computing.<br />
<br />
1) What if factoring was in P and this was shown before Shor's algorithm? Would Shor or someone else have ever proven factoring in quantum P? Would there be as much intense interest in quantum computing as there is now? Perhaps by physicists more than CS people?<br />
<br />
2) What if factoring was in P and this was shown before RSA? Where would crypto be now? Zip drives with a googleplex random (or nearly random) bits and more 1-time pads? More lattice based crypto? Or RSA but with larger numbers? This may depend on how good the factoring algorithm is.<br />
<br />
3) More generally, how much does the order of events matter for science?<br />
<br />
a) If the Banach-Tarski paradox was discovered early on, would we have just tossed out the Axiom of Choice before so much more was build on it? Darling thinks we should toss out AC NOW because of Banach-Tarski.<br />
<br />
b) In the model of set theory L you can do ALL of math except some parts of set theory and maybe a few other things (note quite: Harvey Friedman has found some combinatorial statements that need large cardinals to prove). Had L been discovered earlier then could we all now be working in L (except a few people who look at other models, but they are not in the mainstream)? We might know more about L and less about forcing. We would KNOW that AC and CH are true. Or we would think we know.<br />
<br />
c) If  Engineers were the first ones to look at SAT and reductions, might they have been content to know that  if SAT \le A then A is probably hard? No need for the Cook-Levin Theorem! And then when someone proved Cook-Levin would the Engineers not really cares since they already knew SAT was hard?<br />
<br />d) I can imagine Ramsey's Theorem being discovered much later for some application, or perhaps never being discovered at all.<div><br /></div><div>e) VDW's theorem has so few application, I can imagine it never being discovered. </div><div><br /></div><div>4) There are cases where if A was discovered before B then B has an easy proof, whereas if B was discovered before A, then B has a hard proof. I'll give one example:</div><div><br /></div><div>Given HALT is undecidable, Godel's theorem is easy.</div><div><br /></div><div>Assume HALT is undecidable. </div><div><br /></div><div>Let STAT(e) be the statement M_e(0) does not  halt.</div><div><br /></div><div>There is some e such that M_e(0) does not halt  but ZFC cannot prove this.</div><div><br /></div><div>PROOF: Assume, By Way of Contradiction that for all e such that M_e(0) does not halt,</div><div>ZFC could prove this. Then HALT is DECIDABLE:</div><div><br />Given e, run M_e(0) and at the same time enumerate all proofs in ZFC. It is guaranteed that</div><div>you will either find M_e(0) halts or a proof that M_e(0) does not halt. Hence you will,</div><div>in finite time, know if M_e(0) halts OR NOT.</div><div><br /></div><div>END OF PROOF</div><div><br /></div><div>Is the sequence of events where HALT is proven undecidable  before Godel's theorem plausible.</div><div>I  think so</div><div><br /></div><div>I INVITE my readers to give there own examples of when Math is not commutative- meaning that</div><div>the order of events matters.</div><div>
<br /></div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/04/what-if-history-of-science-factoring.html"><span class="datestr">at August 17, 2020 12:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/122">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/122">TR20-122 |  Size Bounds on Low Depth Circuits for Promise Majority | 

	Joshua Cook</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give two results on the size of AC0 circuits computing promise majority. $\epsilon$-promise majority is majority promised that either at most an $\epsilon$ fraction of the input bits are 1, or at most $\epsilon$ are 0.

First, we show super quadratic lower bounds on both monotone and general depth 3 circuits for promise majority.

For any $\epsilon \in (0, 1/2)$, monotone depth 3 AC0 circuits for $\epsilon$-promise majority have size 
$\tilde{\Omega}\left(\epsilon^3 n^{2 + \frac{\ln(1 - \epsilon)}{\ln(\epsilon)}}\right)$
         
For any $\epsilon \in (0, 1/2)$, general depth 3 AC0 circuits for $\epsilon$-promise majority have size
$\tilde{\Omega}\left(\epsilon^3 n^{2 + \frac{\ln(1 - \epsilon^2)}{2\ln(\epsilon)}}\right)$

These are the first nontrivial size lower bounds on depth 3 promise majority circuits for $\epsilon &lt; 0.45$.
        
Second, we give both uniform and non-uniform sub-quadratic size constant depth circuits for promise majority.

For integer $k \geq 1$, constant $\epsilon \in (0, 1/2)$, there exists monotone non uniform AC0 circuits of depth $2 + 2 \cdot k$ computing $\epsilon$-promise majority with size
$\tilde{O}\left(n^{\frac{1}{1 - 2^{-k}}}\right)$

For integer $k \geq 1$, constant $\epsilon \in (0, 1/2)$, there exists monotone uniform AC0 circuit of depth $2 + 2 \cdot k$ computing $\epsilon$-promise majority with size
$n^{\frac{1}{1 - \left(\frac{2}{3}\right)^k} + o(1)}$

These circuits are based on incremental improvements to existing depth 3 circuits for promise majority given by Ajtai and Viola combined with a divide and conquer strategy.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/122"><span class="datestr">at August 16, 2020 02:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/121">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/121">TR20-121 |  Fractional Pseudorandom Generators from the $k$th Fourier Level | 

	Eshan Chattopadhyay, 

	Jason Gaitonde, 

	Abhishek Shetty</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In recent work by Chattopadhyay et al.[CHHL19,CHLT19], the authors exhibit a simple and flexible construction of pseudorandom generators for classes of Boolean functions that satisfy $L_1$ Fourier bounds. [CHHL19] show that if a class satisfies such tail bounds at all levels, this implies a PRG whose seed length depends on the quality of these bounds through their innovative random walk framework that composes together fractional PRGs that polarize quickly to the Boolean hypercube. On the other hand, [CHLT19] show that, by derandomizing the analysis of [RT19], just level-two Fourier bounds suffice to construct a pseudorandom generator using their framework; as this is a much weaker assumption on the class, [CHLT19] naturally obtain exponentially worse dependence on the error in the seed length compared to [CHHL19]. Moreover, this derandomization relies on simulating nearly independent Gaussians for the fractional pseudorandom generator, which necessitates the  polynomial dependence on $1/\epsilon$ in each fractional step.
    
    In this work, we attempt to bridge the gap between these two results. Namely, we partially answer an open question by [CHLT19] that nearly interpolates between them. In particular, we show that if one has bounds up to the level-$k$ $L_1$ Fourier mass of a closely related class of functions, where $k&gt;2$, one can obtain improved seed length, the degree to which is determined by how high $k$ can be taken. Our analysis shows that for error $\epsilon=1/\text{poly}(n)$, one needs control at just level $O(\log n)$ to recover the seed length of [CHHL19], without assumptions on the entire tail. We avoid this by providing a simple, alternate analysis of their fractional PRG that instead relies on Taylor's theorem and $p$-biased Fourier analysis to avoid assumptions on the weights of the higher-order terms. This further allows us to show that this framework can handle the class of low-degree polynomials over $\mathbb{F}_2$, with slightly worse dependence than the current state-of-the-art, which was not previously known. We hope that this alternate analysis will be fruitful in improving the understanding of this new and powerful framework.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/121"><span class="datestr">at August 16, 2020 02:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/privacy-composition/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/privacy-composition/">Why Privacy Needs Composition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>We’re back!  In our last <a href="https://differentialprivacy.org/\average-case-dp">post</a> we discussed some of the subtle pitfalls of formulating the assumptions underlying average-case relaxations of differential privacy.  This time we’re going to look at the composition property of differential privacy—that is, the fact that running two independent differentially private algorithms on your data and combining their outputs is still differentially private. This is a key property of differential privacy and is actually closely related to the worst-case nature of differential privacy.</p>

<p>Composition is really the crucial property that has made differential privacy successful. Data analysis doesn’t happen in a vacuum, and the greatest threat to privacy comes from combining multiple pieces of information. These pieces of information can come from a single source that releases detailed statistics, or they could come from separate sources. So it’s critical to understand how the composition of multiple pieces of information can affect privacy.</p>

<p>In this post we’ll give some examples to illustrate why we need composition, and why composition is challenging for average-case relaxations of differential privacy.  Composition is what allows you to design sophisticated differentially private algorithms out of simple building blocks, and it’s what allows one organization to release differentially private statistics without having to understand the entire ecosystem of related information that has been or will be released.  As we’ll see, the challenges of composing average-case privacy guarantees are also very closely related to the subtleties that arise in thinking about the adversary’s beliefs.</p>

<h3 id="differencing-attacks">Differencing Attacks</h3>

<p>Let’s start with a simple example of composition that was alluded to in our last post.</p>

<p>You’ve just started a new job and signed up for the health insurance provided by your employer. Thus, your employer is able to obtain aggregated data from the insurance provider. In particular, your employer can ask “How many of our employees have submitted claims for condition X?”  However, your employer should not be able to find out whether or not <em>you</em> have condition X. 
For concreteness, condition X could be a mental health condition, drug addiction, being pregnant, terminal cancer, or an expensive chronic illness. Each of these could result in some kind of employment discrimination.</p>

<p>The employer may find out that 417 employees have condition X.  That’s OK; on its own, this number reveals very little about whether or not <em>you</em> have condition X, as long as your employer is uncertain about how many employees <em>other than you</em> have condition X.  We can formalize this as some kind of average-case or Bayesian privacy guarantee. Thus the health-insurance company is comfortable releasing this number exactly.  But, yesterday, before you started your job, it also seemed reasonable to allow your employer to ask the exact same question, and yesterday the answer was 416. Thus your employer concludes that you have condition X.</p>

<p>In this example, we see how two pieces of information—the count before you started and the count after you started—each of which seems innocuous on its own can be combined to reveal private information. This is a simple example of a <em>differencing attack</em> and composition is important in part because it prevents these attacks.</p>

<p>This example involves only two pieces of information. However, an attack could combine many pieces of information. For example, the counts could be broken down by sex, race/ethnicity, age, location, and tobacco use.<sup id="fnref:1"><a href="https://differentialprivacy.org/feed.xml#fn:1" class="footnote">1</a></sup> Additional data may also be obtained from other sources, such as public records, social media, voluntary disclosures, healthcare providers, financial records, employment records, or even illicit sources. The possibilities for attacks grow rapidly as more information is made available. And an employer is only one example of a potential privacy adversary.</p>

<p>The point of this example is that it’s easy to argue that one piece of information is harmless to privacy by making plausible-looking assumptions about the adversary. But this intuition rapidly breaks down once you consider the bigger picture where there are many pieces of information that can complete the puzzle. That’s why we need rigorous methods for understanding privacy and its composition.</p>

<h3 id="quantifying-composition">Quantifying Composition</h3>

<p>How does differential privacy prevent a differencing attack like the one we just discussed? The simplest way is to add a little bit of random noise to each answer. On the first day, instead of releasing the exact count 416, we could release a noisy count, say, 420. Then on the second day, instead of releasing the true count 417, we release another noisy count, say, 415. More precisely, it is common to add noise to counts drawn from a Laplace or Gaussian distribution.  These figures are still close enough to the true values to be useful, but the difference of 1 is now obscured by the noise, so your privacy is protected.</p>

<p>Since the noise is unknown to <em>any</em> potential adversary, it introduces uncertainty that protects the contribution that an individual makes to the count. Taking the difference of two independent noisy counts results in something that is still noisy. However, we must be careful to quantify this privacy guarantee, particularly when it comes to composition.</p>

<p>So, how much noise do we need to add? Let’s go back to the example and suppose the insurance company provides noisy answers where the noise has mean zero and some fixed variance. Your employer could simply ask the same question again and again and each time receive a different noisy answer. Averaging these noisy answers will effectively reduce the variance of the added noise and allow the true answer to be discerned. That leaves us back where we started.</p>

<p>The moral of this revised example is that the scale of the noise must increase if we allow more access to the data, so more questions means more noise in each answer.<sup id="fnref:2"><a href="https://differentialprivacy.org/feed.xml#fn:2" class="footnote">2</a></sup> 
Asking the same question again and again may seem silly. There are easy ways to defend against this and some similar attacks. (E.g., by returning the same answer each time instead of generating fresh noise.) But, unfortunately, the underlying phenomenon cannot be circumvented. One of the seminal works that led to differential privacy <a href="https://dl.acm.org/doi/10.1145/773153.773173" title="Irit Dinur, Kobbi Nissim. Revealing Information While Preserving Privacy. PODS 2003"><strong>[DN03]</strong></a> showed that there is an inherent tradeoff between the number of questions to be answered and the amount of noise that needs to be added to protect privacy. The general attack is simple: Instead of asking the same query again and again, the attacker asks “random” queries.<sup id="fnref:3"><a href="https://differentialprivacy.org/feed.xml#fn:3" class="footnote">3</a></sup> This attack only requires basic linear algebra and, importantly, has been demonstrated on real systems <a href="https://arxiv.org/abs/1810.05692" title="Aloni Cohen, Kobbi Nissim. Linear Program Reconstruction in Practice. 2018."><strong>[CN18]</strong></a>.</p>

<h3 id="adaptive-composition">Adaptive Composition</h3>

<p>There are actually two kinds of composition to consider. There is <strong>non-adaptive composition</strong>, where the questions to be asked are pre-specified and thus independent of the data, and there is <strong>adaptive composition</strong>, where the questions may themselves depend on the results of prior access to the data. Adaptive composition arises in an interactive system where queries are submitted one-by-one and each answer is returned before the next query is submitted. So far, we have really only considered non-adaptive composition.</p>

<p>Any interactive system must take adaptive composition into account.  A natural algorithm which asks adaptive questions is gradient descent for minimizing a function that is determined by private data (e.g., for logistic regression on medical records). At each step, the algorithm asks for a gradient of the function, which depends on the private data, at the current point. Then the point is updated according to the reported gradient and the process repeats. Since the updated point depends on the previous answer, the next gradient computation is adaptive.</p>

<p>The good news is that differential privacy can handle adaptive composition just fine.  However, to handle adaptive composition, it’s really important that you have a worst-case privacy definition like differential privacy. As we will see below, average-case variants of differential privacy cannot handle adaptive composition. Intuitively, the problem is that whatever distributional assumption you might make about the data or query a priori is unlikely to hold when you condition on past interactions with the same data or related data.</p>

<p>Here’s a technical example that shows the difficulty of adaptive composition. Our data \(x \in \{-1,+1\}^n\) is a vector of \(n\) bits, one bit per person.<sup id="fnref:4"><a href="https://differentialprivacy.org/feed.xml#fn:4" class="footnote">4</a></sup>  Because we’re considering average-case differential privacy, we’ll model this vector as uniformly random.  Consider the following slightly odd algorithm \(M_2(x,v)\)—it takes a vector \(v \in \{-1,+1\}^n\) from the user, and, if the correlation \(\langle x, v \rangle / n\) between \(v\) and \(x\) is smaller than \(\varepsilon/2\), the query returns \(\emptyset\), but, if the correlation between \(v\) and \(x\) is larger than \(\varepsilon/2\), the query returns the dataset \(x\).  In isolation this algorithm satisfies an average-case version of differential privacy, because if \(n\) is large enough and \(x\) is uniformly random, then it’s very unlikely that the user can guess a vector \(v\) that causes this algorithm to output anything other than \(\emptyset\).  This algorithm may seem contrived; it is a simple stand-in for any algorithm that behaves very well most of the time, but fails completely on some rare inputs.</p>

<p>Now, consider another, more familiar differentially private algorithm called randomized response <a href="https://www.jstor.org/stable/2283137?seq=1" title="Stanley Warner. Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias. Journal of the American Statistical Association 1965."><strong>[W65]</strong></a>.  For those not familiar, this algorithm \(M_1(x)\) outputs a vector \(y \in \{-1,+1\}^n\), where \(y_i\) is slightly more likely to be \(x_i\) than \(-x_i\).  Specifically, we set \(y_i = x_i\) with probability \((1+\varepsilon)/2\) and \(y_i = - x_i\) otherwise. This satisfies \(\log(\frac{1+\varepsilon}{1-\varepsilon})\)-differential privacy or, roughly, \(2\varepsilon\)-differential privacy. The upshot is that we obtain a vector \(y\) where the correlation between \(x\) and \(y\) is about \(\varepsilon\), i.e. \(\langle x , y \rangle / n \approx \varepsilon\).</p>

<p>OK, so \(M_1\) and \(M_2\) both satisfy strong average-case versions of differential privacy when the data is uniform, but what about their composition?  Well, the bad news is that running \(y = M_1(x)\) followed by \(M_2(x,y)\) is going to return the dataset \(x\) with probability approaching 100%!  That’s because \(y\) was designed precisely to be a vector with correlation about \(\varepsilon\) with \(x\), and this is exactly the key that gets \(M_2\) to unlock the dataset.</p>

<p>What went wrong here is that, even if \(x\) really is uniformly random, it’s very far from it when conditioned on the output \(y=M_1(x)\). To analyze \(M_2(x,y)\) we must look at the distribution of \(x\) conditioned on \(y\). This distribution is going to be messy and may as well be a worst-case distribution, which means we must leave the realm of average-case privacy.</p>

<h3 id="conclusion">Conclusion</h3>
<p>Composition guarantees that, as long as each part of your system is differentially private, then the overall system is too. It would be difficult to build sophisticated systems without this property. And it’s what allows one organization to release differentially private statistics without having to worry about what other information might be out there. In short, composition is what allows differential privacy to deal with the complexities of the real world.</p>

<p>It is unlikely that differential privacy would have taken off as a field of research without this composition property. Any proposal for an alternative approach to privacy-preserving data analysis should first be evaluated in terms of how it handles composition.</p>

<p>This post only scratches the surface. In particular, we haven’t talked about the quantitative aspects of composition; that’s where the fun really begins. We will leave you with some pointers to further reading on the topic:</p>

<ul>
  <li><a href="http://www.annualreviews.org/eprint/E84vbD3Yzw4ff7YPAjnv/full/10.1146/annurev-statistics-060116-054123" title="Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman. Exposed! A Survey of Attacks on Private Data. Annual Review of Statistics and its Applications 2017."><strong>[DSSU17]</strong></a> This is a survey of attacks which explains quantitatively the relationship between noise, number of questions, and privacy risks.</li>
  <li><a href="https://arxiv.org/abs/1311.0776" title="Peter Kairouz, Sewoong Oh, Pramod Viswanath. The Composition Theorem for Differential Privacy. ICML 2015."><strong>[KOV15]</strong></a> <a href="https://arxiv.org/abs/1507.03113" title="Jack Murtagh, Salil Vadhan. The Complexity of Computing the Optimal Composition of Differential Privacy. TCC 2016"><strong>[MV15]</strong></a> <a href="https://arxiv.org/abs/1603.01887" title="Cynthia Dwork, Guy Rothbum. Concentrated Differential Privacy. 2016."><strong>[DR16]</strong></a> <a href="https://arxiv.org/abs/1605.02065" title="Mark Bun, Thomas Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. TCC 2016."><strong>[BS16]</strong></a> <a href="https://arxiv.org/abs/1702.07476" title="Ilya Mironov. Renyi Differential Privacy. CSF 2017."><strong>[M17]</strong></a> <a href="https://arxiv.org/abs/1905.02383" title="Jinshuo Dong, Aaron Roth, Weijie Su. Gaussian Differential Privacy. Journal of the Royal Statistical Society: Series B. 2020"><strong>[DRS19]</strong></a> On the positive side, these papers analyze how differential privacy composes, yielding sharp quantitative bounds.</li>
</ul>

<hr />

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>A good rule of thumb is that, if the number of released values is much larger than the number of people, then a privacy attack is probably possible. This is analogous to the rule from algebra that, if the number of constraints (released values) is greater than the number of unknown variables (people’s data), then the unknowns can be worked out. <a href="https://differentialprivacy.org/feed.xml#fnref:1" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:2">
      <p>Exactly quantifying how much noise is needed as the number of questions grows leads to the concept of a “privacy budget.” That is, we must precisely quantify how differential privacy degrades under composition. This is a very deep topic and is something we hope to discuss in future posts. <a href="https://differentialprivacy.org/feed.xml#fnref:2" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:3">
      <p>The queries do not need to be random <strong><a href="https://iacr.org/archive/crypto2008/51570469/51570469.pdf" title="Cynthia Dwork, Sergey Yekhanin. New Efficient Attacks on Statistical Disclosure Control Mechanisms. CRYPTO 2008">[DY08]</a></strong>. The queries simply need to be “sufficiently distinct”, which can be formulated precisely as being nearly orthogonal vectors. Random, or even pseudorandom queries (e.g., hash functions), will almost certainly satisfy this property. In general, it is fairly likely that a set of queries will have this property and allow a reconstruction attack; that is, it is hard to <em>avoid</em> this phenomenon. <a href="https://differentialprivacy.org/feed.xml#fnref:3" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:4">
      <p>This representation of the dataset as a vector of bits \(x \in \{-1,+1\}^n \) is an abstraction. The entries in the dataset would actually be something like a set of pairs \( ( u_i, x_i ) \) for \(i = 1, \cdots, n \), where \(u_i\) is various information that identifies the individual concerned (name, address, race, date of birth, etc.). <a href="https://differentialprivacy.org/feed.xml#fnref:4" class="reversefootnote">↩</a></p>
    </li>
  </ol>
</div></div>







<p class="date">
by Jonathan Ullman <a href="https://differentialprivacy.org/privacy-composition/"><span class="datestr">at August 16, 2020 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/08/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/08/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p>Two sites on toroidal polyhedra: <a href="https://www.spektrum.de/alias/raeumliche-geometrie/bonnie-stewarts-hohlkoerper/681891">Bonnie Stewarts Hohlkörper</a> and <a href="http://polyhedra.doskey.com/Stewart00.html">Alex Doskey’s virtual reality models of Stewart’s polyhedra</a> (<a href="https://mathstodon.xyz/@11011110/104618649607830730">\(\mathbb{M}\)</a>). Found while researching a new WP article on Stewart’s book <em><a href="https://en.wikipedia.org/wiki/Adventures_Among_the_Toroids">Adventures Among the Toroids</a></em>. The first link is in German but readable through Google translate and has lots of pretty pictures. The second needs VR software to be usable.</p>
  </li>
  <li>
    <p><a href="https://www.robertdickau.com/mapfolding.html">The map folding problem, illustrated by Robert Dickau</a> (<a href="https://mathstodon.xyz/@11011110/104630030819531499">\(\mathbb{M}\)</a>). See <a href="https://www.robertdickau.com/default.html#math">Dickau’s home page</a> for many more mathematical illustrations, mostly of combinatorial enumeration problems and fractals.</p>
  </li>
  <li>
    <p>For some reason I wanted the name of a surface of revolution of a circular arc less than \(\pi\) around its chord (<a href="https://mathstodon.xyz/@11011110/104635297508909080">\(\mathbb{M}\)</a>). <a href="https://en.wikipedia.org/wiki/Lemon_(geometry)">Wikipedia said “lemon”</a> but sourced to MathWorld so I thought maybe MathWorld had made it up. Not so. Better sources say the same. And the surface for the complementary arc is an “apple”. It looks like a North American football but <a href="http://modellsammlung.uni-goettingen.de/index.php?lang=en&amp;r=5&amp;sr=17&amp;m=182">a “football” is a different surface of revolution, of constant positive Gaussian curvature</a>.</p>
  </li>
  <li>
    <p><a href="https://link.springer.com/journal/454/64/2">Special issue of <em>Discrete &amp; Computational Geometry</em> in memory of Branko Grünbaum</a> (<a href="https://mathstodon.xyz/@11011110/104643955543481823">\(\mathbb{M}\)</a>). I think many of the research papers in it are interesting but I want to draw particular attention to <a href="https://link.springer.com/article/10.1007/s00454-020-00214-y">the preface by Gil Kalai, Bojan Mohar, and Isabella Novik</a>, which provides a nice brief survey both of Grünbaum’s many contributions to discrete geometry and of the lines of active research they have led to.</p>
  </li>
  <li>
    <p><a href="http://gallery.bridgesmathart.org/exhibitions/2020-Bridges-Conference">2020 Bridges Conference Mathematical Art Gallery</a> (<a href="https://mathstodon.xyz/@11011110/104646771923669610">\(\mathbb{M}\)</a>). Many are great but a couple of my favorites are <a href="http://gallery.bridgesmathart.org/exhibitions/2020-bridges-conference/conan-chadbourne">Conan Chadbourne’s grid partition enumeration</a> and <a href="http://gallery.bridgesmathart.org/exhibitions/2020-bridges-conference/mdlevin_publicmsncom">Martin Levin’s ten-tetrahedron tensegrity</a>. I didn’t participate but apparently the Bridges conference itself was held virtually a few days ago; see <a href="https://2020.bridgesmathart.org/">the conference site</a> for more including papers and videos.</p>
  </li>
  <li>
    <p><a href="https://felixboiii.github.io/paper-plotter/">Paper plotter</a> (<a href="https://mathstodon.xyz/@11011110/104655233453519187">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24091297">via</a>): tool to make 3d paper cut-and-assemble models of the graphs of bivariate functions.</p>
  </li>
  <li>
    <p>Kowhaiwhai (<a href="https://mathstodon.xyz/@11011110/104663925881930344">\(\mathbb{M}\)</a>).  are repeating decorative patterns used in New Zealand on Maori buildings. <a href="https://natlib.govt.nz/photos?text=kowhaiwhai&amp;commit=Search">The National Library of NZ has a number of good examples</a>, including the <a href="https://natlib.govt.nz/records/23146518">sketches of patterns by Tamati Ngakoho (top) and of a traditional Arawa pattern (bottom)</a> shown below. There’s also <a href="http://www.maori.org.nz/whakairo/default.php?pid=sp55&amp;parent=52">a brief guide to their interpretation online</a>. I can’t find much analysis of their structure, though, beyond pointing to frieze groups for their symmetries. The part that interests me more is their fractal-like swooping structure, reminiscent of (and in some cases directly modeled on) fern fronds.</p>
  </li>
</ul>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/Kowhaiwhai.jpg" alt="Godber, Albert Percy, 1875-1949. Godber, Albert Percy, 1876-1949. Drawings of Maori rafter patterns or kowhaiwhai. 16. 22W. MA22; 17. 21W. MA21; and, 18. 25W. MA25. Puhoro. [1939-1947]. Ref: E-302-q-1-016/018. Alexander Turnbull Library, Wellington, New Zealand. From https://natlib.govt.nz/records/23146518" /></p>

<ul>
  <li>
    <p><a href="https://www.wired.com/story/why-wikipedia-decided-to-stop-calling-fox-a-reliable-source/">Why Wikipedia decided to stop calling Fox a reliable source</a> (<a href="https://mathstodon.xyz/@11011110/104666160845673755">\(\mathbb{M}\)</a>). Note however that Fox has not actually been deemed unreliable, in general. <a href="https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources/Noticeboard/Archive_303#RfC:_Fox_News">The discussion had a no-consensus close</a>.</p>
  </li>
  <li>
    <p><a href="https://sinews.siam.org/Details-Page/untangling-random-polygons-and-other-things">Untangling random polygons</a> (<a href="https://mathstodon.xyz/@11011110/104677553383067578">\(\mathbb{M}\)</a>): repeatedly rescaling midpoint polygons always leads to an ellipse.</p>
  </li>
  <li>
    <p><a href="https://www.atlasobscura.com/articles/kek-lapis-sarawak">The mesmerizing geometry of Malaysia’s most complex cakes:
Bold colors and designs set kek lapis Sarawak apart</a> (<a href="https://mathstodon.xyz/@11011110/104680812259935603">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24116775">via</a>). As seen on The Great British Bake Off. These cakes have many parallel layers in bright colors, cut and rearranged to form complex designs. Mostly they involve 45 and 90-degree angles but at least one of the examples uses hexagonal symmetry instead.</p>
  </li>
  <li>
    <p>My Google Scholar profile has mildly broken down (<a href="https://mathstodon.xyz/@11011110/104683176033821672">\(\mathbb{M}\)</a>). When I go there, it offers me two new profiles to link as my coauthors: Man-Kwun Chiu and Matí Korman. They are indeed coauthors, from my new CCCG papers. But when I click to accept them as listed coauthors, it tells me I have too many coauthors, refuses to add them, and returns to offering me new profiles to link. I can see no way out of this other than to not accept my coauthors, which would be wrong. Google, fix this limitation!</p>
  </li>
  <li>
    <p>A use for old CDs: <a href="https://momath.org/home/math-monday-those-circles-are-great/">cut them up and glue the pieces together to make visualizations of great circle arrangements on the sphere</a> (<a href="https://mathstodon.xyz/@11011110/104690896919723051">\(\mathbb{M}\)</a>). The mathematical question posed by this is: for which numbers of great circles is it possible to make an arrangement in which all the arcs between pairs of neighbors have equal lengths?</p>
  </li>
  <li>
    <p><a href="https://thonyc.wordpress.com/">The Renaissance Mathematicus</a> (<a href="https://mathstodon.xyz/@pkra/104694183591138626">\(\mathbb{M}\)</a>), an interesting blogger on the history of science. See also the <a href="https://thonyc.wordpress.com/2020/08/15/keep-the-renaissance-mathematicus-online/">crowdfunding drive to replace their old creaky iMac</a>, from which I found this.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/08/15/linkage.html"><span class="datestr">at August 15, 2020 05:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=20069">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/">To cheer you up in difficult times 9: Alexey Pokrovskiy proved that Rota’s Basis Conjecture holds asymptotically</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h2><a href="https://gilkalai.files.wordpress.com/2020/08/alexeypokrovskiy.jpg"><img width="209" alt="" src="https://gilkalai.files.wordpress.com/2020/08/alexeypokrovskiy.jpg?w=209&amp;h=300" class="alignnone size-medium wp-image-20075" height="300" /></a></h2>
<h2>Pokrovskiy’s startling morning  <strong><span style="color: #ff0000;">r</span><span style="color: #0000ff;">ai</span><span style="color: #ff6600;">n</span><span style="color: #ff9900;">b</span><span style="color: #ff00ff;">o</span><span style="color: #800080;">w</span></strong></h2>
<p><a href="https://arxiv.org/abs/2008.06045">Rota’s Basis Conjecture holds asymptotically</a>, by Alexey <span style="color: #000000;">Pokrovskiy</span></p>
<p><strong>Abstract:</strong> Rota’s Basis Conjecture is a well known problem from matroid theory, that states that for any collection of n bases in a rank n matroid, it is possible to decompose all the elements into n disjoint rainbow bases. Here an asymptotic version of this is proved. We show that it is possible to find <em>n − o(n)</em> disjoint rainbow independent sets of size <em>n − o(n)</em>.</p>
<p>A <strong><span style="color: #ff0000;">r</span><span style="color: #0000ff;">ai</span><span style="color: #ff6600;">n</span><span style="color: #ff9900;">b</span><span style="color: #ff00ff;">o</span><span style="color: #800080;">w </span></strong><span style="color: #800080;"><span style="color: #000000;">basis is a basis with one element from each collection.</span></span></p>
<p>(I thank Nati Linial for telling me about it.)</p>
<p>Another way to formulate Rota’s basis conjecture (for representable matroids) is that if <em>B</em><sub>1</sub>, <em>B</em><sub>2</sub>, …, <em>B<sub>n</sub></em> are <em>n</em> bases of an <em>n</em>-dimensional vector space <em>V</em> (not necessarily distinct or disjoint), then there exists an <em>n</em> × <em>n</em> grid of vectors (<em>v<sub>ij</sub></em>) such that</p>
<p>1. the <em>n</em> vectors in row <em>i</em> are the members of the <em>i</em>th basis <em>B<sub>i</sub></em> (in some order), and</p>
<p>2. in each column of the matrix, the <em>n</em> vectors in that column form a basis of <em>V</em>.</p>
<p>If all the bases are the standard basis then this reduces to the existence of <a href="https://en.wikipedia.org/wiki/Latin_square">Latin squares</a>.</p>
<p><strong>Unrelated trivia question:</strong>  AGC-GTC-TGC-GTC-TGC-GAC-GATC-? what comes next in the sequence?</p>
<p>We mentioned Rota’s basis conjecture in various earlier posts.  A classic paper on the subject is the <a href="https://gilkalai.files.wordpress.com/2017/02/huang-rota.pdf">1989 paper by Rosa Huang and Gian Carlo-Rota</a>. Three and a half years ago Timothy Chow lunched a polymath project (Polymath 12) to solve it. (Here is my<a href="https://gilkalai.wordpress.com/2017/02/26/timothy-chow-launched-polymath12-on-rota-basis-conjecture-and-other-news/"> post on the project with various variants of the conjecture</a>, the <a href="https://polymathprojects.org/2017/02/23/rotas-basis-conjecture-polymath-12/">first post on the polymath blog</a>, and the <a href="https://asone.ai/polymath/index.php?title=Rota%27s_conjecture">wiki</a>). See <a href="https://gilkalai.wordpress.com/2014/08/08/jim-geelen-bert-gerards-and-geo%ef%ac%80-whittle-solved-rotas-conjecture-on-matroids/">this post</a> for several famous conjectures by Rota, and this post about the related <a href="https://gilkalai.wordpress.com/2017/03/15/test-your-intuition-about-the-alon-tarsi-conjecture/">Alon-Tarsi conjecture</a>.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/"><span class="datestr">at August 14, 2020 10:09 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
