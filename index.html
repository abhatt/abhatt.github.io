<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/27705661/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at February 10, 2019 03:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html">Big convex polyhedra in grids</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I recently wrote here about <a href="https://11011110.github.io/blog/2018/09/05/big-convex-polygons.html">big convex polygons in grids</a>, a problem for which we know very precise answers. This naturally raises the question: what about higher dimensions? How many vertices can be part of a convex polyhedron in an  grid, or more generally a convex polytope in a -dimensional grid of side length ? Here we do still know some pretty good answers, at least up to constant factors in spaces of constant dimension.</p>

<p>The problem is included in a 2008 survey by Imre Bárány,<sup id="fnref:bar"><a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bar" class="footnote">1</a></sup> according to whom the maximum number of vertices is</p>



<p>For instance, in three dimensional  grids the maximum number of vertices is .</p>

<p>One way to find polyhedra with this many vertices is to take the convex hull of the points in a ball,<sup id="fnref:bl"><a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bl" class="footnote">2</a></sup> <sup id="fnref:bd"><a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:bd" class="footnote">3</a></sup> or in scaled copies of any fixed smooth convex body. Another way, which should generate polyhedra with a somewhat less irregular appearance and (up to constant factors) the same number of vertices, is to take the <a href="https://en.wikipedia.org/wiki/Minkowski_addition">Minkowski sum</a> of all line segments (up to scaling and translation) that will fit into a smaller grid, of side length . For instance, the <a href="https://en.wikipedia.org/wiki/Truncated_rhombicuboctahedron">truncated rhombicuboctahedron</a> below<sup id="fnref:ruen"><a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:ruen" class="footnote">4</a></sup> is the Minkowski sum of all the line segments that fit into a unit cube. Its 96 vertices lie in a  grid. In general, this method produces a <a href="https://en.wikipedia.org/wiki/Zonohedron">zonohedron</a> whose complexity can be analyzed in terms of a -dimensional arrangement of  hyperplanes. As long as this arrangement is not too degenerate (which it appears not to be, but I haven’t worked out the details carefully) this should give
a number of vertices within a constant factor of the number coming from the convex hull construction.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/truncated-rhombicuboctahedron2.png" alt="Truncated rhombicuboctahedron" /></p>

<p>A matching upper bound comes from a 1963 paper by G. K. Andrews,<sup id="fnref:and"><a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:and" class="footnote">5</a></sup> and Bárány writes that although several more proofs have been published none of them is easy. I’m not sure whether the difficulty is in getting the exact bound or in the fact that Andrews and the later proofs allow more general shapes with volume  that don’t fit into a grid, but it’s not hard to get close to the right bound simply by counting the number of possible facets of a given volume . By using <a href="https://en.wikipedia.org/wiki/Lenstra%E2%80%93Lenstra%E2%80%93Lov%C3%A1sz_lattice_basis_reduction_algorithm">lattice basis reduction</a> the integer vectors in the hyperplane through any facet have a nearly-orthogonal basis whose product of lengths is proportional to . By considering how this product of lengths can be broken down into factors of different scales, and counting how many integer vectors of those lengths exist, it follows that the number of possible facets of volume  is . Combining this with the  surface area of a grid polytope gives the correct upper bound on the number of vertices up to a polylog factor.</p>

<p>What about when the dimension is not constant? The best general construction I know for high dimensions is to take all points with a fixed distance  from the grid center. There are  possible values for the distance, so this construction produces a convex polytope with  vertices. It comes from a 1946 paper by Behrend, who uses this idea to find <a href="https://en.wikipedia.org/wiki/Salem%E2%80%93Spencer_set">dense sets of integers with no arithmetic progressions</a>.<sup id="fnref:beh"><a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:beh" class="footnote">6</a></sup> It is never worse to use the convex hull of the ball than the points on a sphere,
and it is tempting to guess that (at least when  is singly exponential in  so that  becomes constant) the convex hull technique will produce slightly more vertices, , but I don’t know whether this is true or if so how to prove it. A celebrated paper by Elkin from 2011 produces exactly this factor of  improvement in Behrend’s progression-free sets,<sup id="fnref:elk"><a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fn:elk" class="footnote">7</a></sup> but appears to be doing it some other way than by finding larger convex polytopes.</p>

<div class="footnotes">
  <ol>
    <li id="fn:bar">
      <p>Bárány, Imre (2008), “Extremal problems for convex lattice polytopes: a survey”, <em>Surveys on Discrete and Computational Geometry</em>, Contemporary Mathematics 453, Amer. Math. Soc., pp. 87–103, <a href="https://doi.org/10.1090/conm/453/08796">doi:10.1090/conm/453/08796</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=2405678">MR2405678</a>. <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bar" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:bl">
      <p>Bárány, Imre and Larman, David (1998), “The convex hull of the integer points in a large ball”, <em>Math. Ann.</em> 312 (1), pp. 167–181, <a href="https://doi.org/10.1007/s002080050217">doi:10.1007/s002080050217</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1645957">MR1645957</a>. <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bl" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:bd">
      <p>Balog, Antal and Deshouillers, Jean-Marc (1999), “On some convex lattice polytopes”. <em>Number Theory in Progress</em>, Vol. 2 (Zakopane-Kościelisko, 1997), de Gruyter, pp. 591–606, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=1689533">MR1689533</a>. <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:bd" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:ruen">
      <p>Ruen, Tom (2014), “Truncated rhombicuboctahedron”, CC-BY-SA 4.0, <a href="https://commons.wikimedia.org/wiki/File:Truncated_rhombicuboctahedron2.png">File:Truncated rhombicuboctahedron2.png</a> on Wikimedia commons. <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:ruen" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:and">
      <p>Andrews, George E. (1963), “A lower bound for the volume of strictly convex bodies with many boundary lattice points”, <em>Trans. Amer. Math. Soc.</em> 106, pp. 270–279, <a href="https://doi.org/10.2307/1993769">doi:10.2307/1993769</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0143105">MR0143105</a>. <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:and" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:beh">
      <p>Behrend, F. A. (1946), “On sets of integers which contain no three terms in arithmetical progression”, <em>Proc. Nat. Acad. Sci.</em> 32 (12), pp. 331–332, <a href="https://doi.org/10.1073/pnas.32.12.331">doi:10.1073/pnas.32.12.331</a>, <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=0018694">MR0018694</a>. <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:beh" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:elk">
      <p>Elkin, Michael (2011), “An improved construction of progression-free sets”, <em>Israel J. Math.</em> 184, pp. 93–128, <a href="https://arxiv.org/abs/0801.4310">arXiv:0801.4310</a>, <a href="https://doi.org/10.1007%2Fs11856-011-0061-1">doi:10.1007/s11856-011-0061-1</a>, <a href="https://www.ams.org/mathscinet-getitem?mr=2823971">MR2823971</a>. <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html#fnref:elk" class="reversefootnote">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101564963348879092">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/02/09/big-convex-polyhedra.html"><span class="datestr">at February 09, 2019 03:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02755">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02755">Significance of Episodes Based on Minimal Windows</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02755">PDF</a><br /><b>Abstract: </b>Discovering episodes, frequent sets of events from a sequence has been an
active field in pattern mining. Traditionally, a level-wise approach is used to
discover all frequent episodes. While this technique is computationally
feasible it may result in a vast number of patterns, especially when low
thresholds are used.
</p>
<p>In this paper we propose a new quality measure for episodes. We say that an
episode is significant if the average length of its minimal windows deviates
greatly when compared to the expected length according to the independence
model. We can apply this measure as a post-pruning step to test whether the
discovered frequent episodes are truly interesting and consequently to reduce
the number of output.
</p>
<p>As a main contribution we introduce a technique that allows us to compute the
distribution of lengths of minimal windows using the independence model. Such a
computation task is surpisingly complex and in order to solve it we compute the
distribution iteratively starting from simple episodes and progressively moving
towards the more complex ones. In our experiments we discover candidate
episodes that have a sufficient amount of minimal windows and test each
candidate for significance. The experimental results demonstrate that our
approach finds significant episodes while ignoring uninteresting ones.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02755"><span class="datestr">at February 09, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02526">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02526">Going Far From Degeneracy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fomin:Fedor_V=.html">Fedor V. Fomin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovach:Petr_A=.html">Petr A. Golovach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lokshtanov:Daniel.html">Daniel Lokshtanov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Panolan:Fahad.html">Fahad Panolan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saurabh:Saket.html">Saket Saurabh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zehavi:Meirav.html">Meirav Zehavi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02526">PDF</a><br /><b>Abstract: </b>An undirected graph G is d-degenerate if every subgraph of G has a vertex of
degree at most d. By the classical theorem of Erd\H{o}s and Gallai from 1959,
every graph of degeneracy d&gt;1 contains a cycle of length at least d+1. The
proof of Erd\H{o}s and Gallai is constructive and can be turned into a
polynomial time algorithm constructing a cycle of length at least d+1. But can
we decide in polynomial time whether a graph contains a cycle of length at
least d+2? An easy reduction from Hamiltonian Cycle provides a negative answer
to this question: deciding whether a graph has a cycle of length at least d+2
is NP-complete. Surprisingly, the complexity of the problem changes drastically
when the input graph is 2-connected. In this case we prove that deciding
whether G contains a cycle of length at least d+k can be done in time
2^{O(k)}|V(G)|^{O(1)}. In other words, deciding whether a 2-connected n-vertex
G contains a cycle of length at least d+log n can be done in polynomial time.
</p>
<p>Similar algorithmic results hold for long paths in graphs. We observe that
deciding whether a graph has a path of length at least d+1 is NP-complete.
However, we prove that if graph G is connected, then deciding whether G
contains a path of length at least d+k can be done in time 2^{O(k)}n^{O(1)}. We
complement these results by showing that the choice of degeneracy as the `above
guarantee parameterization' is optimal in the following sense: For any
\epsilon&gt;0 it is NP-complete to decide whether a connected (2-connected) graph
of degeneracy d has a path (cycle) of length at least (1+\epsilon)d.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02526"><span class="datestr">at February 09, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02499">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02499">A fast algorithm for constructing balanced binary search trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ruzankin:Pavel_S=.html">Pavel S. Ruzankin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02499">PDF</a><br /><b>Abstract: </b>We suggest a new non-recursive algorithm for constructing a binary search
tree given an array of numbers. The algorithm has $O(N)$ time and $O(1)$ memory
complexities if the given array of $N$ numbers is sorted. The resulting tree is
of minimal height and can be transformed to a complete binary search tree
(retaining minimal height) with $O(\log N)$ time and $O(1)$ memory.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02499"><span class="datestr">at February 09, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02459">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02459">On Mean Estimation for General Norms with Statistical Queries</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jerry.html">Jerry Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nikolov:Aleksandar.html">Aleksandar Nikolov</a>, Ilya Razenshteyn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02459">PDF</a><br /><b>Abstract: </b>We study the problem of mean estimation for high-dimensional distributions,
assuming access to a statistical query oracle for the distribution. For a
normed space $X = (\mathbb{R}^d, \|\cdot\|_X)$ and a distribution supported on
vectors $x \in \mathbb{R}^d$ with $\|x\|_{X} \leq 1$, the task is to output an
estimate $\hat{\mu} \in \mathbb{R}^d$ which is $\epsilon$-close in the distance
induced by $\|\cdot\|_X$ to the true mean of the distribution. We obtain sharp
upper and lower bounds for the statistical query complexity of this problem
when the the underlying norm is symmetric as well as for Schatten-$p$ norms,
answering two questions raised by Feldman, Guzm\'{a}n, and Vempala (SODA 2017).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02459"><span class="datestr">at February 09, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02428">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02428">Fourier bounds and pseudorandom generators for product tests</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lee:Chin_Ho.html">Chin Ho Lee</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02428">PDF</a><br /><b>Abstract: </b>We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to
\{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on
disjoint $m$-bit inputs. We prove that for every positive integer $d$, \[
</p>
<p>\sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d . \] Our upper bound is
tight up to a constant factor in the $O(\cdot)$. Our proof builds on a new
`level-$d$ inequality' that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any
$[0,1]$-valued function $f$ in terms of its expectation, which may be of
independent interest.
</p>
<p>As a result, we construct pseudorandom generators for such functions with
seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to
polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$. Our
generator in particular works for the well-studied class of combinatorial
rectangles, where in addition we allow the bits to be read in any order. Even
for this special case, previous generators have an extra $\tilde
O(\log(1/\varepsilon))$ factor in their seed lengths.
</p>
<p>Using Schur-convexity, we also extend our results to functions $f_i$ whose
range is $[-1,1]$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02428"><span class="datestr">at February 09, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02398">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02398">$\mathsf{QMA}$ Lower Bounds for Approximate Counting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kretschmer:William.html">William Kretschmer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02398">PDF</a><br /><b>Abstract: </b>We prove a query complexity lower bound for $\mathsf{QMA}$ protocols that
solve approximate counting: estimating the size of a set given a membership
oracle. This gives rise to an oracle $A$ such that $\mathsf{SBP}^A \not\subset
\mathsf{QMA}^A$, resolving an open problem of Aaronson [2]. Our proof uses the
polynomial method to derive a lower bound for the $\mathsf{SBQP}$ query
complexity of the $\mathsf{AND}$ of two approximate counting instances. We use
Laurent polynomials as a tool in our proof, showing that the "Laurent
polynomial method" can be useful even for problems involving ordinary
polynomials.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02398"><span class="datestr">at February 09, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02392">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02392">Finding Good Itemsets by Packing Data</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tatti:Nikolaj.html">Nikolaj Tatti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vreeken:Jilles.html">Jilles Vreeken</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02392">PDF</a><br /><b>Abstract: </b>The problem of selecting small groups of itemsets that represent the data
well has recently gained a lot of attention. We approach the problem by
searching for the itemsets that compress the data efficiently. As a compression
technique we use decision trees combined with a refined version of MDL. More
formally, assuming that the items are ordered, we create a decision tree for
each item that may only depend on the previous items. Our approach allows us to
find complex interactions between the attributes, not just co-occurrences of
1s. Further, we present a link between the itemsets and the decision trees and
use this link to export the itemsets from the decision trees. In this paper we
present two algorithms. The first one is a simple greedy approach that builds a
family of itemsets directly from data. The second one, given a collection of
candidate itemsets, selects a small subset of these itemsets. Our experiments
show that these approaches result in compact and high quality descriptions of
the data.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02392"><span class="datestr">at February 09, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.02371">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.02371">Diffeomorphic Medial Modeling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yushkevich:Paul_A=.html">Paul A. Yushkevich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aly:Ahmed.html">Ahmed Aly</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jiancong.html">Jiancong Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xie:Long.html">Long Xie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorman:Robert_C=.html">Robert C. Gorman</a>, Alison Pouch, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Younes:Laurent.html">Laurent Younes</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.02371">PDF</a><br /><b>Abstract: </b>Deformable shape modeling approaches that describe objects in terms of their
medial axis geometry (e.g., m-reps [Pizer et al., 2003]) yield rich geometrical
features that can be useful for analyzing the shape of sheet-like biological
structures, such as the myocardium. We present a novel shape analysis approach
that combines the benefits of medial shape modeling and diffeomorphometry. Our
algorithm is formulated as a problem of matching shapes using diffeomorphic
flows under constraints that approximately preserve medial axis geometry during
deformation. As the result, correspondence between the medial axes of similar
shapes is maintained. The approach is evaluated in the context of modeling the
shape of the left ventricular wall from 3D echocardiography images.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.02371"><span class="datestr">at February 09, 2019 11:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1087">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1087">News for January 2019</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong>Minimax Testing of Identity to a Reference Ergodic Markov Chain</strong>, by Geoffrey Wolfer and Aryeh Kontorovich (<a href="https://arxiv.org/abs/1902.00080">arXiv</a>). This work studies distributional identity testing on Markov chains from a single trajectory, as recently introduced by <a href="https://arxiv.org/abs/1704.06850">Daskalakis, Dikkala, and Gravin</a>: we wish to test whether a Markov chain is equal to some reference chain, or far from it. This improves on previous work by considering a stronger distance measure than before, and showing that the sample complexity only depends on properties of the reference chain (which we are trying to test identity to). It additionally proves instance-by-instance bounds (where the sample complexity depends on properties of the specific chain we wish to test identity to).</p>



<p><strong>Almost Optimal Distribution-free Junta Testing</strong>, by Nader H. Bshouty (<a href="https://arxiv.org/abs/1901.00717">arXiv</a>). This paper provides a \(\tilde O(k/\varepsilon)\)-query algorithm with two-sided error for testing if a Boolean function is a \(k\)-junta (that is, its value depends only on \(k\) of its variables) in the distribution-free model (where distance is measured with respect to an unknown distribution from which we can sample). This complexity is a quadratic improvement over the \(\tilde O(k^2)/\varepsilon\)-query algorithm of <a href="https://arxiv.org/abs/1802.04859">Chen, Liu, Servedio, Sheng, and Xie</a>. This complexity is also near-optimal, as shown in a lower bound by Saglam (which we covered back in <a href="https://ptreview.sublinear.info/?p=1030">August</a>).</p>



<p><strong>Exponentially Faster Massively Parallel Maximal Matching</strong>, by Soheil Behnezhad, MohammadTaghi Hajiaghayi, and David G. Harris (<a href="https://arxiv.org/abs/1901.03744">arXiv</a>). The authors consider maximal matching in the Massively Parallel Computation (MPC) model. They show that one can compute a maximal matching in \(O(\log \log \Delta)\)-rounds, with \(O(n)\) space per machine. This is an exponential improvement over the previous works, which required either \(\Omega(\log n)\) rounds or \(n^{1 + \Omega(1)}\) space per machine. Corollaries of their result include approximation algorithms for vertex cover, maximum matching, and weighted maximum matching. </p></div>







<p class="date">
by Gautam Kamath <a href="https://ptreview.sublinear.info/?p=1087"><span class="datestr">at February 08, 2019 06:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3379">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/">ACM SIGecom Elections</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><span style="font-weight: 400;">The following message just went out to ACM SIGecom members:</span></p>
<blockquote><p>———- Forwarded message ———<br />
From: <strong>Monique Chang</strong> &lt;<a href="mailto:chang@hq.acm.org">chang@hq.acm.org</a>&gt;<br />
Date: Mon, Feb 4, 2019 at 2:20 PM<br />
Subject: 2019 ACM SIGecom Election: Candidate Slate Announcement<br />
To: &lt;<a href="mailto:SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org">SIG-ELECTION-ANNOUNCEMENT@listserv.acm.org</a>&gt;</p>
<p>Dear ACM SIGecom Member,</p>
<p>The ACM SIGecom Nominating Committee has proposed the following candidates for the 2019 ACM SIGecom election.</p>
<p><strong><u>Chair</u></strong><br />
(Running Unopposed)</p>
<p>Nicole Immorlica</p>
<p><strong><u>Vice-Chair</u></strong></p>
<p>Scott Kominers</p>
<p>Ariel Procaccia</p>
<p><strong><u>Secretary-Treasurer</u></strong></p>
<p>Hu Fu</p>
<p>Katrina Ligett</p>
<p>In accordance with the ACM SIG Bylaws, additional candidates may be placed on the ballot by petition. All candidates must be ACM Professional Members, as well as members of the SIG. Anyone interested in petitioning must inform ACM Headquarters, Pat Ryan (<a href="mailto:ryanp@hq.acm.org">ryanp@hq.acm.org</a>), and SIGecom’s Secretary-Treasurer, Jenn Wortman Vaughan (<a href="mailto:jenn@microsoft.com">jenn@microsoft.com</a>), of their intent to petition by <strong>15 March 2019</strong>. Petitions must be submitted to ACM Headquarters for verification by <strong>2 April 2019</strong>.</p>
<p>Monique Chang</p>
<p>ACM SIG Elections Coordinator</p>
<p>Office of Policy and Administration</p></blockquote>
<p><span style="font-weight: 400;">Three things for members of our community to note:</span></p>
<ol>
<li style="font-weight: 400;">It’s important vote (once the link goes out; note that the current email is just an announcement and an invitation for additional candidates to petition to be included on the ballot). The SIG leadership is very important for the ongoing direction of our organization. Your vote makes a difference, because our elections are often decided by small margins.</li>
</ol>
<ol start="2">
<li style="font-weight: 400;">If you didn’t get this email, you’re likely not registered as a member of our SIG. Membership costs only $5 for students and $10 for others; AFAIK, you don’t have to be an ACM member to be a SIG member. Our number of members is an important signal to the ACM about the strength of our community (which is why we have set our fees so low). Votes like this one are also restricted to members! If your membership has lapsed, or if you’ve never taken the plunge, this might be a good occasion to do so, by clicking on the link below:</li>
</ol>
<p style="font-weight: 400;"><a href="https://www.acm.org/special-interest-groups/sigs/sigecom">https://www.acm.org/special-interest-groups/sigs/sigecom</a></p>
<ol start="3">
<li style="font-weight: 400;">Thanks to our nominations chair, David Parkes, who put together the slate of candidates just listed, and also to all of the candidates who agreed to serve. Our community is really lucky to have such a strong and deep pool of volunteers, and this is one more example. Indeed, in advance, I’d particularly like to thank those candidates who *don’t* win, whoever they turn out to be: it’s thankless to stick one’s neck out for an election only to see someone else get chosen (often by a small margin; see #1), but your willingness to serve is much appreciated.</li>
</ol></div>







<p class="date">
by Kevin Leyton-Brown <a href="https://agtb.wordpress.com/2019/02/08/acm-sigecom-elections/"><span class="datestr">at February 08, 2019 02:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/017">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/017">TR19-017 |  Fourier bounds and pseudorandom generators for product tests | 

	Chin Ho Lee</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the Fourier spectrum of functions $f\colon \{0,1\}^{mk} \to \{-1,0,1\}$ which can be written as a product of $k$ Boolean functions $f_i$ on disjoint $m$-bit inputs.  We prove that for every positive integer $d$,
\[
  \sum_{S \subseteq [mk]: |S|=d} |\hat{f_S}| = O(m)^d .
\]
Our upper bound is tight up to a constant factor in the $O(\cdot)$.  Our proof builds on a new "level-$d$ inequality" that bounds above $\sum_{|S|=d} \hat{f_S}^2$ for any $[0,1]$-valued function $f$ in terms of its expectation, which may be of independent interest.

As a result, we construct pseudorandom generators for such functions with seed length $\tilde O(m + \log(k/\varepsilon))$, which is optimal up to polynomial factors in $\log m$, $\log\log k$ and $\log\log(1/\varepsilon)$.  Our generator in particular works for the well-studied class of combinatorial rectangles, where in addition we allow the bits to be read in any order.  Even for this special case, previous generators have an extra $\tilde O(\log(1/\varepsilon))$ factor in their seed lengths. 

Using Schur-convexity, we also extend our results to functions $f_i$ whose range is $[-1,1]$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/017"><span class="datestr">at February 07, 2019 02:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/016">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/016">TR19-016 |  The hardest halfspace | 

	Alexander A. Sherstov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the approximation of halfspaces $h:\{0,1\}^n\to\{0,1\}$ in the infinity norm by polynomials and rational functions of any given degree.  Our main result is an explicit construction of the "hardest" halfspace, for which we prove polynomial and rational approximation lower bounds that match the trivial upper bounds achievable for all halfspaces.  This completes a lengthy line of work started by Myhill and Kautz (1961).

As an application, we construct a communication problem with essentially the largest possible gap, of $n$ versus $2^{-\Omega(n)},$ between the sign-rank and discrepancy. Equivalently, our problem exhibits a gap of $\log n$ versus $\Omega(n)$ between the communication complexity with unbounded versus weakly unbounded error, improving quadratically on previous constructions and completing a line of work started by Babai, Frankl, and Simon (FOCS 1986). Our results further generalize to the $k$-party number-on-the-forehead model, where we obtain an explicit separation of $\log n$ versus $\Omega(n/4^{n})$ for communication with unbounded versus weakly unbounded error. This gap is a quadratic improvement on previous work and matches the state of the art for number-on-the-forehead lower bounds.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/016"><span class="datestr">at February 07, 2019 02:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-971154734717743655">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html">An Immerman-Szelepcsényi Story</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
As a grad student in the late 80's I had the opportunity to witness many great and often surprising theorems in computational complexity. Let me tell you about one of them, the Immerman-Szelepcsényi result that <a href="https://blog.computationalcomplexity.org/2003/06/foundations-of-complexity-lesson-19.html">nondeterministic space is closed under complement</a>. I wish I had the original emails for this story but instead I'm working from memory and apologies if I get some of the details wrong. I'm expanding from a <a href="https://blog.computationalcomplexity.org/2002/08/last-spring-i-saw-copenhagen-great.html">short version</a> from the early days of this blog.<br />
<br />
I started my graduate work at UC Berkeley in 1985 and then moved to MIT in the summer of '86, following my advisor Michael Sipser. In the summer of 1987, Neil Immerman, then at Yale, proved his famous result building on his work in <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> In those days you didn't email papers, he made copies and sent them by US postal mail to several major researchers in complexity including Sipser. But Sipser was away for the summer, I believe in Russia, and the paper sat in his office.<br />
<br />
Immerman also sent the paper to a Berkeley professor, probably Manuel Blum, who gave it to one of his students who decided to speak about the result in a student-led seminar. I forgot who was the student, maybe Moni Naor. I was still on the Berkeley email list so I got the talk announcement and went into complexity ecstasy over the news. I asked Moni (or whomever was giving the talk) if he could tell me details and he sent me a nice write-up of the proof. Given the importance of the result, I sent the proof write-up out to the MIT theory email list.<br />
<br />
Guess who was on the MIT theory list? Neil Immerman. Neil wrote back with his own explanation of the proof. Neil explained how it came out of descriptive complexity but as a pure write-up of a proof of the theorem, Moni did an excellent job.<br />
<br />
We found out about Robert Szelepcsényi when his paper showed up a few months later in the Bulletin of the European Association for Theoretical Computer Science. Szelepcsényi came to the problem from formal languages, whether context-sensitive languages (nondeterministic linear space) was closed under complement. Szelepcsényi, an undergrad in Slovakia at the time, heard about the problem in a class he took. Szelepcsényi's proof was very similar to Immerman. Szelepcsényi's paper took longer to get to US researchers but likely was proven and written about the same time as Immerman.<br />
<br />
Even though both papers were <a href="https://doi.org/10.1137/0217058">published</a> <a href="https://doi.org/10.1007/BF00299636">separately</a> we refer to the result as Immerman-Szelepcsényi and is now just some old important theorem you see in introductory theory classes.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/02/an-immerman-szelepcsenyi-story.html"><span class="datestr">at February 07, 2019 12:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/015">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/015">TR19-015 |  QMA Lower Bounds for Approximate Counting | 

	William Kretschmer</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove a query complexity lower bound for $QMA$ protocols that solve approximate counting: estimating the size of a set given a membership oracle. This gives rise to an oracle $A$ such that $SBP^A \not\subset QMA^A$, resolving an open problem of Aaronson [2]. Our proof uses the polynomial method to derive a lower bound for the $SBQP$ query complexity of the $AND$ of two approximate counting instances. We use Laurent polynomials as a tool in our proof, showing that the "Laurent polynomial method" can be useful even for problems involving ordinary polynomials.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/015"><span class="datestr">at February 07, 2019 08:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15634">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/">An Old But Cool Result</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p></p><p>
<font color="#0044cc"><br />
<em>Solving a type of Fermat Equation</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/unknown-117/" rel="attachment wp-att-15639"><img src="https://rjlipton.files.wordpress.com/2019/02/unknown.jpeg?w=600" alt="" class="alignright size-full wp-image-15639" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"></font></td>
</tr>
</tbody>
</table>
<p>
Leo Moser was a <a href="https://en.wikipedia.org/wiki/Leo_Moser">mathematician</a> who worked on a very varied set of problems. He for example raised a question about “worms,” and invented a notation for huge <a href="https://en.wikipedia.org/wiki/Steinhaus-Moser_notation">numbers</a>.</p>
<p>
Today I want to talk about one of his results with a very short proof.</p>
<p>
No, it is not about worms. That is a <a href="https://en.wikipedia.org/wiki/Moser%27s_worm_problem">question</a> in discrete geometry that is still open I believe: “What is the region of smallest area which can accommodate every planar arc of length one?” The region must be able to hold the arc inside but the curve can be moved and rotated to allow it to fit. A disk of diameter <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> works and has area about <img src="https://s0.wp.com/latex.php?latex=%7B+0.78%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0.78}" class="latex" title="{ 0.78}" />. It is possible to do much better and get around <img src="https://s0.wp.com/latex.php?latex=%7B+0.27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ 0.27}" class="latex" title="{ 0.27}" />. </p>
<p><a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/worm3/" rel="attachment wp-att-15636"><img src="https://rjlipton.files.wordpress.com/2019/02/worm3.png?w=300&amp;h=143" alt="" width="300" class="aligncenter size-medium wp-image-15636" height="143" /></a></p>
<p>See this <a href="https://www.nada.kth.se/~johanh/snakes.pdf">paper</a> for some additional details.</p>
<p>
No, it is not about a conjecture of Paul Erdős See <a href="https://arxiv.org/pdf/1011.2956.pdf">this</a> for a great paper on this result: </p>
<blockquote><p><b>Theorem 1</b> <em> Suppose that 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1%5E%7Bk%7D+%2B+2%5E%7Bk%7D+%2B+%5Ccdots+%2B+%28m-1%29%5E%7Bk%7D+%3D+m%5E%7Bk%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. " class="latex" title="\displaystyle  1^{k} + 2^{k} + \cdots + (m-1)^{k} = m^{k}. " /></p>
<p>Then any <img src="https://s0.wp.com/latex.php?latex=%7B%28m%2Ck%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{(m,k)}" class="latex" title="{(m,k)}" /> solution in integers with <img src="https://s0.wp.com/latex.php?latex=%7Bk+%5Cge+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{k \ge 2}" class="latex" title="{k \ge 2}" /> must have 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++m+%3E+10%5E%7B10%5E%7B6%7D%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  m &gt; 10^{10^{6}}. " class="latex" title="\displaystyle  m &gt; 10^{10^{6}}. " /></p>
</em><p><em></em>
</p></blockquote>
<p>Erdős conjectured there are no solutions at all. It is easy to check that for <img src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k=1}" class="latex" title="{k=1}" /> the unique solution is a bit smaller: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%2B+2+%3D+3.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  1 + 2 = 3." class="latex" title="\displaystyle  1 + 2 = 3." /></p>
<p>
</p><p></p><h2> The Result </h2><p></p>
<p></p><p>
Yes, it is about the solution to a natural family of Diophantine equations. This result of Moser comes from an old paper of his. The result can be found on the wonderful blog called <a href="https://www.cut-the-knot.org/arithmetic/algebra/TwoParameterFermat.shtml">cut-the-knot</a> written by Alexander Bogomolny.</p>
<p>
The question considered by Moser is simple to state: </p>
<blockquote><p><b> </b> <em> Consider the equation over the integers <img src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x^{a} + y^{b} = z^{c}}" class="latex" title="{x^{a} + y^{b} = z^{c}}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Ba%2C+b%2C+c%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{a, b, c}" class="latex" title="{a, b, c}" /> are fixed values that are relatively prime. Show that there are infinitely many integer solutions. </em>
</p></blockquote>
<p></p><p>
The surprise, to me, is that this equation always has integer solutions. I thought about it for a bit and had no idea how to even start.</p>
<p>
The solution is as follows. The initial insight is that the restriction on the exponents implies that there are integers <img src="https://s0.wp.com/latex.php?latex=%7Bm%2C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m, n}" class="latex" title="{m, n}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7Babm+%2B+1+%3D+cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{abm + 1 = cn}" class="latex" title="{abm + 1 = cn}" />. </p>
<p>
Wait a minute. We must be careful by what we mean by “the values of <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b,c}" class="latex" title="{a,b,c}" /> are relatively prime.” We need more than the greatest common divisor (GCD) of <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b,c}" class="latex" title="{a,b,c}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. We need that <img src="https://s0.wp.com/latex.php?latex=%7Bab%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ab}" class="latex" title="{ab}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> are relatively prime. Note that <img src="https://s0.wp.com/latex.php?latex=%7B6%2C10%2C15%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{6,10,15}" class="latex" title="{6,10,15}" /> have GCD equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> but no matter which of the triple is “<img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" />” we cannot find the needed <img src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m,n}" class="latex" title="{m,n}" />: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%286%5Ccdot+10%2C15%29+%3E+1%2C+%2810%5Ccdot+15%2C+6%29%3E1%2C+%2815%2C6+%5Ccdot+10%29+%3E+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. " class="latex" title="\displaystyle  (6\cdot 10,15) &gt; 1, (10\cdot 15, 6)&gt;1, (15,6 \cdot 10) &gt; 1. " /></p>
<p>I thank Subrahmanyam Kalyanasundaram for catching this.</p>
<p>
The next idea is not to look for a single set of solutions but rather to find a parametrized solution. That is try to find expressions for <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y,z}" class="latex" title="{x,y,z}" /> that depend on some variables <img src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u,v}" class="latex" title="{u,v}" /> so that for all <img src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u,v}" class="latex" title="{u,v}" /> the equation is satisfied. </p>
<p>
Then set 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. " class="latex" title="\displaystyle  x = u^{bm}(u^{abm} + v^{abm})^{bm}. " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. " class="latex" title="\displaystyle  y = v^{am}(u^{abm} + v^{abm})^{am}. " /></p>
<p>Note as <img src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u,v}" class="latex" title="{u,v}" /> vary over integers the values of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> vary over integers too. The claim is that this is a parameterization of the equation. Let’s see why. We need to figure out what <img src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^{a} + y^{b}}" class="latex" title="{x^{a} + y^{b}}" /> is equal to. It looks a bit nasty but it is not. Let <img src="https://s0.wp.com/latex.php?latex=%7BW+%3D+u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{W = u^{abm} + v^{abm}}" class="latex" title="{W = u^{abm} + v^{abm}}" />. Then 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x+%3D+u%5E%7Bbm%7DW%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x = u^{bm}W^{bm}. " class="latex" title="\displaystyle  x = u^{bm}W^{bm}. " /></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++y+%3D+v%5E%7Bam%7DW%5E%7Bam%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  y = v^{am}W^{am}. " class="latex" title="\displaystyle  y = v^{am}W^{am}. " /></p>
<p>So <img src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^{a} + y^{b} }" class="latex" title="{x^{a} + y^{b} }" /> is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++u%5E%7Babm%7D+W%5E%7Babm%7D+%2B+v%5E%7Babm%7DW%5E%7Babm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. " class="latex" title="\displaystyle  u^{abm} W^{abm} + v^{abm}W^{abm}. " /></p>
<p>Which magically is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++W%5E%7Babm%7D%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29+%3D+W%5E%7Babm%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. " class="latex" title="\displaystyle  W^{abm}(u^{abm} + v^{abm}) = W^{abm+1}. " /></p>
<p>Thus setting 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++z+%3D+W%5E%7Bn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  z = W^{n} " class="latex" title="\displaystyle  z = W^{n} " /></p>
<p>implies that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+W%5E%7Babm%2B1%7D+%3D+W%5E%7Bcn%7D+%3D+%28W%5E%7Bn%7D%29%5E%7Bc%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. " class="latex" title="\displaystyle  x^{a} + y^{b} = W^{abm+1} = W^{cn} = (W^{n})^{c} = z^{c}. " /></p>
<p>Very neat. By the way we do need to note that as <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> run through integers the values of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> vary enough to get an infinite number of solutions. A simple growth argument shows that this is true.</p>
<p>
The key trick was to <b>not</b> use a standard idea and apply the binomial theorem and expand 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28u%5E%7Babm%7D+%2B+v%5E%7Babm%7D%29%5E%7Bbm%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (u^{abm} + v^{abm})^{bm}. " class="latex" title="\displaystyle  (u^{abm} + v^{abm})^{bm}. " /></p>
<p>My algebra DNA suggests that expanding such an expression is often a good idea. Here it would lead to a mess. This is a case where using the binomial expansion does not work.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
I really like Moser’s clever solution to the diophantine equation 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Ba%7D+%2B+y%5E%7Bb%7D+%3D+z%5E%7Bc%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^{a} + y^{b} = z^{c}. " class="latex" title="\displaystyle  x^{a} + y^{b} = z^{c}. " /></p>
<p>Note that it must fail when <img src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a=b=c=p}" class="latex" title="{a=b=c=p}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bp%3E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p&gt;2}" class="latex" title="{p&gt;2}" /> by the famous solution to the original Fermat equation. </p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/02/06/an-old-but-cool-result/"><span class="datestr">at February 06, 2019 12:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://corner.mimuw.edu.pl/?p=1062">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/banach.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://corner.mimuw.edu.pl/?p=1062">HALG 2019 - Call For Submissions of Short Contributed Presentations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>The HALG 2019 conference seeks submissions for contributed presentations. Each presentation is expected to consist of a poster and a short talk (an invitation to the poster). There will be no conference proceedings, hence presenting work already published at a different venue or journal (or to be submitted there) is welcome.</p>
<p>If you would like to present your results at HALG 2019, please submit their details the abstract of the talk or the contribution of the poster via EasyChair: <a href="https://easychair.org/conferences/?conf=halg2019" target="_blank" rel="noopener noreferrer">https://easychair.org/conferences/?conf=halg2019</a></p>
<p>The abstract should include (when relevant) information where the results have been published/accepted (e.g., conference), and where they are publicly available (e.g., arXiv). All submissions will be reviewed by the program committee, giving priority to new work not formally published yet, and to papers published in 2018 or later.</p>
<p>Submissions deadline: March 15th, 2019.<br />
Late submissions will be accepted subject to space constraints.</p></div>







<p class="date">
by sank <a href="http://corner.mimuw.edu.pl/?p=1062"><span class="datestr">at February 06, 2019 11:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=92">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/">Extremal Combinatorics V: POSETS</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>This is the remaining post V on partially ordered sets of my series on extremal combinatorics (<a href="https://gilkalai.wordpress.com/2008/05/01/extremal-combinatorics-i/">I</a>,<a href="https://gilkalai.wordpress.com/2008/07/17/extermal-combinatorics-ii-some-geometry-and-number-theory/">II</a>,<a href="https://gilkalai.wordpress.com/2008/09/28/extremal-combinatorics-iii-some-basic-theorems/">III</a>,<a href="https://gilkalai.wordpress.com/2008/10/06/extremal-combinatorics-iv-shifting/">IV</a>,<a href="https://gilkalai.wordpress.com/2009/05/21/extremal-combinatorics-vi-the-frankl-wilson-theorem/">VI</a>). </em></p>
<p>We will talk here about POSETS – partially ordered sets. The study of order is very important in many areas of mathematics starting with the order relation on the integers and reals in algebra and in Euclidean geometry. The set of all subsets of a set can be partially ordered by inclusion and this is a very basic example of posets. While the study of order and posets is a separate area on its own, parts of it are very important in extremal combinatorics and we will give a little taste here.</p>
<p style="text-align: center;"><span style="color: #0000ff;"><strong>Dear readers, please contribute your favorite result or problem on partially ordered sets (or Sorting) in the comment session.</strong></span></p>
<p>A chain <img src="https://s0.wp.com/latex.php?latex=C+%5Csubset+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C \subset P" class="latex" title="C \subset P" /> in a POSET is a set of elements so that every two of them are comparable. An antichain $A \subset P$ is a set of elements so that every two distinct elemenאs in <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> are incomparable.  (Antichains are also called independent sets.) An immediate but important Lemma is:</p>
<p><strong>The immediate lemma:</strong> The intersection of a chain <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> and an antichain <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> contains at most one element. <strong><span style="color: #993366;">Walla!</span></strong></p>
<h3>Dilworth’s theorem</h3>
<p>Dilworth’s theorem (DT): Every finite partially ordered <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> set can be covered by <img src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a(P)" class="latex" title="a(P)" /> chains.</p>
<p>(By the immediate lemma, at least <img src="https://s0.wp.com/latex.php?latex=a%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a(P)" class="latex" title="a(P)" /> chains are needed.)</p>
<p>Dual Dilworth theorem: Every partially ordered sets can be covered by <img src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c(P)" class="latex" title="c(P)" /> antichains.</p>
<p>(By the immediate lemma, at least <img src="https://s0.wp.com/latex.php?latex=c%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c(P)" class="latex" title="c(P)" /> antichains are needed.)</p>
<p>The proof of the dual Dilworth theorem is easy. Note that the set <img src="https://s0.wp.com/latex.php?latex=A_1%3DMIN%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_1=MIN(P)" class="latex" title="A_1=MIN(P)" /> of minimal elements of <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> is an antichain. Let <img src="https://s0.wp.com/latex.php?latex=A_k+%3D+MIN+%28P%5Cbackslash+%28A_1+%5Ccup+A_2+%5Ccup+%5Cdots+A_%7Bk-1%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))" class="latex" title="A_k = MIN (P\backslash (A_1 \cup A_2 \cup \dots A_{k-1}))" />. We need two easy observations. First, <img src="https://s0.wp.com/latex.php?latex=A_k+is+an+antichain&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_k is an antichain" class="latex" title="A_k is an antichain" /> and second: If <img src="https://s0.wp.com/latex.php?latex=A_k+%5Cne+%5Cemptyset&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_k \ne \emptyset" class="latex" title="A_k \ne \emptyset" /> then there is a chain with one element from <img src="https://s0.wp.com/latex.php?latex=A_i%3A+1+%5Cle+i%5Cle+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A_i: 1 \le i\le k" class="latex" title="A_i: 1 \le i\le k" />. <strong><span style="color: #0000ff;">Walla!</span></strong></p>
<p>The proof of Dilworth’s theorem is by induction on $|P|$. For the induction step you first consider the case where every antichain of maximal size is either <img src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="MAX(P)" class="latex" title="MAX(P)" /> or <img src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="MIN (P)" class="latex" title="MIN (P)" />. In this case you consider a chain with one element in <img src="https://s0.wp.com/latex.php?latex=MAX%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="MAX(P)" class="latex" title="MAX(P)" /> and one element in <img src="https://s0.wp.com/latex.php?latex=MIN+%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="MIN (P)" class="latex" title="MIN (P)" /> and delete these elements from <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />. For the resulting post <img src="https://s0.wp.com/latex.php?latex=Q&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Q" class="latex" title="Q" />, <img src="https://s0.wp.com/latex.php?latex=a%28Q%29%3Da%28P%29-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a(Q)=a(P)-1" class="latex" title="a(Q)=a(P)-1" /> and we can use the induction hypothesis.</p>
<p>Otherwise there is an antichain <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> of maximum size <img src="https://s0.wp.com/latex.php?latex=t%3Da%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t=a(P)" class="latex" title="t=a(P)" /> which is not <em>MAX(P)</em> or <em>MIN(P)</em>.  Put <img src="https://s0.wp.com/latex.php?latex=A%3D%5C%7Ba_1%2Ca_2%2C%5Cdots%2Ca_t%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A=\{a_1,a_2,\dots,a_t\}" class="latex" title="A=\{a_1,a_2,\dots,a_t\}" />. Let <img src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P^+" class="latex" title="P^+" /> be the set of elements in <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> which are larger or equal some element in <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />, and let <img src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P^-" class="latex" title="P^-" /> be the set of elements in <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> which are smaller or equal some element in <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />.</p>
<p>Now,</p>
<ol>
<li><img src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccup+P%5E-%3DP&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P^+ \cup P^-=P" class="latex" title="P^+ \cup P^-=P" />. Otherwise we could add an element to <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> to form a larger antichain.</li>
<li><img src="https://s0.wp.com/latex.php?latex=P%5E%2B+%5Ccap+P%5E-+%3D+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P^+ \cap P^- = A" class="latex" title="P^+ \cap P^- = A" />. Otherwise, there will be two elements of <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> which are comparable.</li>
</ol>
<p>So by the induction hypothesis <img src="https://s0.wp.com/latex.php?latex=P%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P^+" class="latex" title="P^+" /> can be covered by <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> chains <img src="https://s0.wp.com/latex.php?latex=C_1%5E%2B%2C+C_2%5E%2B%2C+%5Cdots%2C+C_t%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1^+, C_2^+, \dots, C_t^+" class="latex" title="C_1^+, C_2^+, \dots, C_t^+" /> and <img src="https://s0.wp.com/latex.php?latex=P%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P^-" class="latex" title="P^-" /> can be covered by <img src="https://s0.wp.com/latex.php?latex=a%28P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a(P" class="latex" title="a(P" />$ chains <img src="https://s0.wp.com/latex.php?latex=C_1%5E-%2C+C_2%5E-%2C+%5Cdots%2C+C_t%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1^-, C_2^-, \dots, C_t^-" class="latex" title="C_1^-, C_2^-, \dots, C_t^-" />. Bu re-indexing we can assume that both <img src="https://s0.wp.com/latex.php?latex=C_i%5E%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_i^+" class="latex" title="C_i^+" /> and <img src="https://s0.wp.com/latex.php?latex=C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_i^-" class="latex" title="C_i^-" /> contains <img src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_i" class="latex" title="a_i" />. It follows that <img src="https://s0.wp.com/latex.php?latex=a_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_i" class="latex" title="a_i" /> is the minimal element in $C_i^+$ and the maximal element in $C_i^-$ and hence <img src="https://s0.wp.com/latex.php?latex=C_i%3D%3AC_i%5E%2B+%5Ccup+C_i%5E-&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_i=:C_i^+ \cup C_i^-" class="latex" title="C_i=:C_i^+ \cup C_i^-" /> is a chain. The <img src="https://s0.wp.com/latex.php?latex=t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="t" class="latex" title="t" /> chains <img src="https://s0.wp.com/latex.php?latex=C_1%2C+C_2%2C+%5Cdots%2C+C_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1, C_2, \dots, C_t" class="latex" title="C_1, C_2, \dots, C_t" /> cover <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />. <span style="color: #993366;"><strong>Sababa!</strong></span></p>
<p>An <strong>important Corollary</strong> both from Dilworth’s theorem and its dual is that</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=a%28P%29+c%28P%29+%5Cge+%7CP%7C.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a(P) c(P) \ge |P|." class="latex" title="a(P) c(P) \ge |P|." /></p>
<h3>Erdos-Szekeres theorem</h3>
<p>The fundamental Erdos Szekeres theorem asserts that if <img src="https://s0.wp.com/latex.php?latex=n%3Dab%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n=ab+1" class="latex" title="n=ab+1" /> then every sequence <img src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C%5Cdots+%2Ca_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_1,a_2,\dots ,a_n" class="latex" title="a_1,a_2,\dots ,a_n" /> of different real numbers contains a monotone increasing sequence of length <img src="https://s0.wp.com/latex.php?latex=a%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a+1" class="latex" title="a+1" /> or a monotone decreasing sequence of length <img src="https://s0.wp.com/latex.php?latex=b%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="b+1" class="latex" title="b+1" />.</p>
<p>There are simple proofs. For example, associate to every <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> a pair <img src="https://s0.wp.com/latex.php?latex=%28I_k%2CD_k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(I_k,D_k)" class="latex" title="(I_k,D_k)" /> of integers where  <img src="https://s0.wp.com/latex.php?latex=I_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I_k" class="latex" title="I_k" /> is the maximum length of the increasing subsequence starting with <img src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_k" class="latex" title="a_k" /> and <img src="https://s0.wp.com/latex.php?latex=D_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D_k" class="latex" title="D_k" /> is the maximum length of the deccreasing subsequence starting with <img src="https://s0.wp.com/latex.php?latex=a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_k" class="latex" title="a_k" />. The result follows from the easy observation that all these pairs are different.</p>
<p>Both Dilworth’ theorem and its easy dual imply easily (in fact we need only the important corollary) the Erdos Szekeres theorem when we define the following partial order: <img src="https://s0.wp.com/latex.php?latex=i+%3C+k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i &lt; k" class="latex" title="i &lt; k" /> if both <img src="https://s0.wp.com/latex.php?latex=i%3Ck&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i&lt;k" class="latex" title="i&lt;k" /> and <img src="https://s0.wp.com/latex.php?latex=a_i+%3C+a_k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_i &lt; a_k" class="latex" title="a_i &lt; a_k" />.</p>
<h3>Looking at Sperner’s theorem again</h3>
<p>Sperner’s theorem asserts that the maximal size of an antichain of subsets of an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> elements set is <img src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{{n} \choose {[n/2]}}" class="latex" title="{{n} \choose {[n/2]}}" />. By Dilworth’s theorem it follows that we can cover all sets by <img src="https://s0.wp.com/latex.php?latex=%7B%7Bn%7D+%5Cchoose+%7B%5Bn%2F2%5D%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{{n} \choose {[n/2]}}" class="latex" title="{{n} \choose {[n/2]}}" /> chains (and, of course when we exhibit such a covering it reproves Sperner’s theorem). A symmetric saturated chain decomposition is a partition of <img src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(n)" class="latex" title="P(n)" /> (=all subsets of <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[n]" class="latex" title="[n]" />) to saturated chains where each chain has, for some <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />, sets of sizes $k,k+1,\dots,d-k$. You can build such a decomposition inductively.</p>
<p>Start with a decomposition for <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> for each chain <img src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_i" class="latex" title="C_i" /> create a new chain <img src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C'_i" class="latex" title="C'_i" /> by adding the element <img src="https://s0.wp.com/latex.php?latex=n%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n+1" class="latex" title="n+1" /> to every set. And then move the top set in <img src="https://s0.wp.com/latex.php?latex=C%27_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C'_i" class="latex" title="C'_i" /> to <img src="https://s0.wp.com/latex.php?latex=C_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_i" class="latex" title="C_i" />.  <strong>Walla!</strong></p>
<p>This is the beginning of a very beautiful story related also to the Dedekind Problem about  number of antichains in <img src="https://s0.wp.com/latex.php?latex=P%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P(n)" class="latex" title="P(n)" />.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png"><img src="https://gilkalai.files.wordpress.com/2019/02/untitledgreene-kleitman2.png?w=640&amp;h=489" alt="" width="640" class="alignnone size-full wp-image-16834" height="489" /></a></p>
<p><strong><span style="color: #ff0000;">Curtis Greene and Danny Kleitman</span></strong></p>
<h3>The Greene-Kleitman theorem</h3>
<p>Let <img src="https://s0.wp.com/latex.php?latex=a_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_k(P)" class="latex" title="a_k(P)" /> be the maximum size of the union <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> antichains in a poset <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />. For every chain For every chain <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> we have <img src="https://s0.wp.com/latex.php?latex=%7CC+%5Ccap+X%7C+%5Cle+%5Cmin%5C%7B%7CC%7C%2Ck%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|C \cap X| \le \min\{|C|,k\}" class="latex" title="|C \cap X| \le \min\{|C|,k\}" />. Therefore for a partition of <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> to chains <img src="https://s0.wp.com/latex.php?latex=C_1%2CC_2%2C%5Cdots%2CC_t&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_1,C_2,\dots,C_t" class="latex" title="C_1,C_2,\dots,C_t" /> we   have <img src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5Cge+%7CX%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum\min\{|C_i|,k\ge |X|" class="latex" title="\sum\min\{|C_i|,k\ge |X|" />. The <a href="https://www.encyclopediaofmath.org/index.php/Greene-Kleitman_theorem">Greene-Kleitman theorem</a> asserts that there is always  a decomposition into chains with <img src="https://s0.wp.com/latex.php?latex=%5Csum%5Cmin%5C%7B%7CC_i%7C%2Ck%5C%7D%3Da_k%28P%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum\min\{|C_i|,k\}=a_k(P)" class="latex" title="\sum\min\{|C_i|,k\}=a_k(P)" />.</p>
<h3>The perfect graph theorem.</h3>
<p>What is the relation between the very easy dual Dilworth theorem and the harder Dilworth theorem? As it turns out there is a very general theorem, Lovasz’ perfect graph theorem, that shows that these two theorems are equivalent.</p>
<p>A graph G is perfect if for every induced subgraph H, the chromatic number equals the clique number. Lovasz’ theorem  (conjectured by Claude Berge) asserts that complements of perfect graphs are perfect. The perfectness of the comparability graph of a poset amounts to the dual Dilworth theorem, and for its complement it is the Dilworth theorem. Lovasz in fact proved that perfectness is equivalent to the relation $\latex \omega(H)\cdot \alpha (H) \ge |H|$ for every induced subgraph H. (For posets this is our important corollary above.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png"><img src="https://gilkalai.files.wordpress.com/2019/02/kahn-linial-saks.png?w=640&amp;h=239" alt="" width="640" class="alignnone size-full wp-image-16832" height="239" /></a></p>
<p><strong><span style="color: #ff0000;">Jeff Kahn and Jake Baron </span></strong><span style="color: #ff0000;">(</span><span style="color: #ff0000;"><a href="http://archive.dimacs.rutgers.edu/DIMACS_highlights/tuza/tuza.html">see here on their 2016 asymptotic solution to Tusza’s conjecture</a></span><span style="color: #ff0000;">),</span><strong><span style="color: #ff0000;"> Mike Saks, and Nati Linial</span></strong></p>
<h3>Startling theorems on POSETS: Kahn-Saks,  Linial-Saks, Linial-Kahn, and Kahn-Saks</h3>
<p>Here  are some beautiful and important theorems on posets. An order ideas <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" /> of a post is a set of elements so that if <img src="https://s0.wp.com/latex.php?latex=x+in+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x in I" class="latex" title="x in I" /> and <img src="https://s0.wp.com/latex.php?latex=y+%3C+x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y &lt; x" class="latex" title="y &lt; x" /> then <img src="https://s0.wp.com/latex.php?latex=y+%5Cin+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="y \in I" class="latex" title="y \in I" />.</p>
<p><strong>Theorem (Linial-Saks, 1985):</strong> In every poset <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> there is an element which is contained in more than δ and less than 1-δ order ideas of <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />.  (<a href="http://www.cs.huji.ac.il/~nati/PAPERS/central_element.pdf">Paper</a>)</p>
<p><strong>Theorem (Kahn-Saks, 1984):</strong> For every Poset <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> which is not a chain there are two incomparable elements <img src="https://s0.wp.com/latex.php?latex=x%2Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x,y" class="latex" title="x,y" /> such that the number of linear extensions of <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> for which <img src="https://s0.wp.com/latex.php?latex=x%3Cy&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x&lt;y" class="latex" title="x&lt;y" /> is between 3/11 and 8/11. (<a href="https://link.springer.com/article/10.1007/BF00565647">Paper</a>)</p>
<p>A <a href="http://www.cs.huji.ac.il/~nati/PAPERS/brunn_minkowski.pdf">simpler proof</a> was found in the late 80s by Kahn and Linial and by Karzanov and Khachiyan. It  is  based on the Brunn Minkowski theorem and gives a weaker constant <img src="https://s0.wp.com/latex.php?latex=1%2F2e&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1/2e" class="latex" title="1/2e" /> .</p>
<p><strong>Theorem (Kahn-Saks, 1987)</strong>: For every finite distributive lattice <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="L" class="latex" title="L" /> the maximum antichain is of size <img src="https://s0.wp.com/latex.php?latex=o%28%7CL%7C%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="o(|L|)" class="latex" title="o(|L|)" />. (<a href="https://core.ac.uk/download/pdf/82629369.pdf">Paper</a>)</p>
<p>Lattices are special types of posets with the property that for every set of elements (pairs <img src="https://s0.wp.com/latex.php?latex=%5C%7Bx%2Cy%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{x,y\}" class="latex" title="\{x,y\}" /> suffice in the finite case), there is a unique minimal elements above them all (denoted for pairs by <i>x</i> ∧ <i>y</i>) and a unique maximal element (denoted for pairs by <i>x</i> ∨ <i>y</i>) below them all.</p>
<p>A <a href="https://en.wikipedia.org/wiki/Distributive_lattice">distributive lattice</a> is a lattice that satisfies for every <em>x, y</em> and <em>z</em>, the relation</p>
<p style="text-align: center;"><i>x</i> ∧ (<i>y</i> ∨ <i>z</i>) = (<i>x</i> ∧ <i>y</i>) ∨ (<i>x</i> ∧ <i>z</i>)</p>
<p>Birkhoff’s representation theorem asserts that finite distributive lattices can be represented as order ideals of posets (ordered by inclusion).</p>
<p> </p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/02/05/extremal-combinatorics-v-posets/"><span class="datestr">at February 05, 2019 11:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-8542550481798271953">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2019/02/two-awards-at-hicss19-for-csgssi.html">Two awards at HICSS’19 for CS@GSSI student Roberto Verdecchia</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div><div><a href="https://robertoverdecchia.github.io/" target="_blank">Roberto Verdecchia</a>, a third-year Ph.D. student of the Gran Sasso Science Institute (GSSI) and the Vrije Universiteit Amsterdam (VU) has received two distinct prizes at the 52nd Hawaii International Conference on System Sciences (HICSS’19;<span> </span><a style="color: #1155cc;" href="http://hicss.hawaii.edu/" target="_blank">http://hicss.hawaii.edu/</a>) for his research paper “<a style="color: #1155cc;" href="https://robertoverdecchia.github.io/papers/HICSS_2019.pdf" target="_blank">DecidArch: Playing Cards as Software Architects</a>”, which is <span style="font-family: Helvetica; font-size: 12px;">co-authored with</span><i style="font-family: Helvetica; font-size: 12px;"> </i>Patricia Lago, Jia F. Cai (both at VU Amsterdam), Remco C. de Boer (ArchiXL) and Philippe Kruchten (University of British Columbia). Out of over 780 papers presented at HICCS within 11 different research tracks, the study was presented with the “Best Paper award” of the Software Education and Training track. Additionally, the article was also selected as one of the five “ISSIP-IBM-CBA Student Paper Award for Best Industry Studies Paper” of HICCS’19.</div><div><br />The study presents a novel educational game conceived to train students and practitioners in concepts related to software architecture and decision making. The game is currently used as an interactive session of the course “Software Architecture”, taught at the Vrije Universiteit Amsterdam.<br /><br />The two prizes were adjudicated independently by two distinct committees.</div><div> </div><div>Congratulations to Roberto!</div><div><br /></div><div>Let me close by adding that I expect that Roberto will deliver his PhD thesis in the autumn 2019 and will soon be on the job market. If you have a postdoc or tenure-track  position in SE, keep him mind. </div></div></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2019/02/two-awards-at-hicss19-for-csgssi.html"><span class="datestr">at February 05, 2019 08:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4206">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2019/02/04/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-11/">恭喜发财!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><img src="https://lucatrevisan.files.wordpress.com/2019/02/8cxnlmgdi.png?w=584" alt="8cxnLMGdi" class="alignnone size-full wp-image-4207" /></p>
<p>新年快乐！</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2019/02/04/%e6%81%ad%e5%96%9c%e5%8f%91%e8%b4%a2-11/"><span class="datestr">at February 05, 2019 06:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4122">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4122">Sabineblogging</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I’ve of course been following the recent public debate about whether to build a circular collider to succeed the LHC—notably including <a href="https://www.nytimes.com/2019/01/23/opinion/particle-physics-large-hadron-collider.html">Sabine Hossenfelder’s <em>New York Times</em> column</a> arguing that we shouldn’t.  (See also the <a href="https://www.nytimes.com/2019/02/01/opinion/letters/physics-research-collider-cern.html">responses</a> by Jeremy Bernstein and Lisa Randall, and the <a href="http://www.math.columbia.edu/~woit/wordpress/?p=10768">discussion on Peter Woit’s blog</a>, and <a href="https://www.facebook.com/daniel.harlow.31/posts/10104284984149212">Daniel Harlow’s Facebook thread</a>, and <a href="https://www.vox.com/future-perfect/2019/1/22/18192281/cern-large-hadron-collider-future-circular-collider-physics">this <em>Vox</em> piece</a> by Kelsey Piper.)  Let me blog about this as a way of cracking my knuckles or tuning my violin, just getting back into blog-shape after a long hiatus for travel and family and the beginning of the semester.</p>
<p>Regardless of whether this opinion is widely shared among my colleagues, I like Sabine.  I’ve often found her <a href="http://backreaction.blogspot.com/">blogging</a> funny and insightful, and I wish more non-Lubos physicists would articulate their thoughts for the public the way she does, rather than just standing on the sidelines and criticizing the ones who do. I find it unfortunate that some of the replies to Sabine’s arguments dwelled on her competence and “standing” in physics (even if we set aside—as we should—Lubos’s misogynistic rants, whose predictability could be used to calibrate atomic clocks). It’s like this: if high-energy physics <em>had</em> reached a pathological state of building bigger and bigger colliders for no good reason, then we’d <em>expect</em> that it would take a semi-outsider to say so in public, so then it wouldn’t be a further surprise to find precisely such a person doing it.</p>
<p>Not for the first time, though, I find myself coming down on the opposite side as Sabine. Basically, <em>if</em> civilization could get its act together and find the money, I think it would be pretty awesome to build a new collider to push forward the energy frontier in our understanding of the universe.<br /></p>


<p>Note that I’m not making the much stronger claim that this is the <em>best possible</em> use of $20 billion for science.  Plausibly a thousand $20-million projects could be found that would advance our understanding of reality by more than a new collider would.  But it’s also important to realize that that’s not the question at stake here.  When, for example, the US Congress cancelled the <a href="https://en.wikipedia.org/wiki/Superconducting_Super_Collider">Superconducting Supercollider</a> midway through construction—partly, it’s believed, on the basis of opposition from eminent physicists in other subfields, who argued that they could do equally important science for much cheaper—none of the SSC budget, as in 0% of it, ever <em>did</em> end up redirected to those other subfields.  In practice, then, the question of “whether a new collider is worth it” is probably best considered in absolute terms, rather than relative to other science projects.</p>



<p>What I found most puzzling, in Sabine’s writings on this subject, was the leap in logic from</p>



<ol><li>many theorists expected that superpartners, or other new particles besides the Higgs boson, had a good chance of being discovered at the LHC, based on statistical arguments about “natural” parameter values, and</li><li>the basic soundness of naturalness arguments was always open to doubt, and indeed the LHC results to date offer zero support for them, and</li><li>many of the same theorists now want an even bigger collider, and continue to expect new particles to be found, and haven’t sufficiently reckoned with their previous failed predictions, to …</li><li><strong>therefore</strong> we shouldn’t build the bigger collider.</li></ol>



<p>How do we get from 1-3 to 4: is the idea that we should <em>punish</em> the errant theorists, by withholding an experiment that they want, in order to deter future wrong predictions?  After step 3, it seems to me that Sabine could equally well have gone to: and therefore it’s all the more important that we <em>do</em> build a new collider, in order to establish all the more conclusively that there’s just an energy desert up there—and that I, Sabine, was right to emphasize that possibility, and those other theorists were wrong to downplay it!</p>



<p>Like, I gather that there are independently motivated scenarios where there <em>would</em> be only the Higgs at the LHC scale, and then new stuff at the next energy scale beyond it.  And as an unqualified outsider who enjoys talking to friends in particle physics and binge-reading about it, I’d find it hard to assign the totality of those scenarios less than ~20% credence or more than ~80%—certainly if the actual experts don’t either.</p>



<p>And crucially, it’s not as if <em>raising the collision energy</em> is just one arbitrary direction in which to look for new fundamental physics, among a hundred a-priori equally promising directions.  Basically, there’s raising the collision energy and then there’s everything else.  By raising the energy, you’re not testing one specific idea for physics beyond Standard Model, but a hundred or a thousand ideas in one swoop.</p>



<p>The situation reminds me a little of the quantum computing skeptics who say: scalable QC can never work, in practice and probably even in principle; the mainstream physics community only <em>thinks</em> it can work because of groupthink and hype; therefore, we shouldn’t waste more funds trying to make it work.  With the sole, very interesting exception of Gil Kalai, none of the skeptics ever seem to draw what strikes me as an equally logical conclusion: whoa, let’s go <em>full speed ahead</em> with trying to build a scalable QC, because there’s an epochal revolution in physics to be had here—once the experimenters finally see that I was right and the mainstream was wrong, and they start to unravel the reasons why!</p>



<p>Of course, $20 billion is a significant chunk of change, by the standards of science even if not by the standards of random government wastages (like our recent $11 billion shutdown).  And ultimately, decisions do need to be made about which experiments are most interesting to pursue with limited resources.  And if a future circular collider <em>were</em> built, and if it indeed just found a desert, I think the balance would tilt pretty strongly toward Sabine’s position—that is, toward declining to build an even bigger and more expensive collider after that.  If the Patriots drearily won every Superbowl 13-3, year after year after year, eventually no one would watch anymore and the Superbowl would get cancelled (well, maybe that will happen for other reasons…).</p>



<p>But it’s worth remembering that—correct me if I’m wrong—so far there have been <em>no</em> cases in the history of particle physics of massively expanding the energy frontier and finding absolutely nothing new there (i.e., nothing that at least conveyed multiple bits of information, as the Higgs mass did).  And while my opinion should count for less than a neutrino mass, just thinking it over a-priori, I keep coming back to the question: before we close the energy frontier for good, shouldn’t there have been at least <em>one</em> unmitigated null result, rather than zero?</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4122"><span class="datestr">at February 04, 2019 12:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-9219479121065296157">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html">Don't know Football but still want bet on the Superb Owl?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>
(Superb Owl is not a typo. I've heard (and it could be wrong) that the  NFL guards their copyright so you can't even say `Buy Beer here for the YOU KNOW WHATl' but instead `Buy Beer here for the big game''. Stephen Colbert a long time ago go around this by calling the game Superb Owl.)</div>
<div>
<br /></div>
<div>
<br /></div>
<div>
If I knew more about football  I might place a bet related to the Superb Owl. What kind of bets can I place?</div>
<div>
<br /></div>
<div>
1) Bet the point spread: Last time I looked the Patriots were a 2.5 point favorite. So either bet that Patriots will win by more than  2.5 or the Rams will lose by less than 2.5 or just win.</div>
<div>
<br /></div>
<div>
2) Over-Under: bet that either the total score will be over 56.5 or under it.</div>
<div>
<br /></div>
<div>
 There are prop-bets-- bets that are ABOUT the game but not related to the final score.</div>
<div>
<br /></div>
<div>
I've seen the following</div>
<div>
<br /></div>
<div>
1) Tom Brady will retire after the game. I wonder if Tom Brady (or a friend of his) could bet on this one knowing some inside information. Not i any state in America, but off-shore...</div>
<div>
<br /></div>
<div>
2) Jamie White will score the first touchdown.</div>
<div>
<br /></div>
<div>
3) Will Gladys Knight's   National Anthem go longer than 1 minute, 50 seconds (it was 1:47 seconds a few days ago but it shifted to 1:50).</div>
<div>
<br /></div>
<div>
Amazingly, this last one is what Josh Hermsmeyer (on Nate Silver's Webpage)  chose to focus on: <a href="https://fivethirtyeight.com/features/the-super-bowls-best-matchup-is-gladys-knight-vs-the-clock/">here</a>. Note that:</div>
<div>
<br /></div>
<div>
1) The people who picked 1 minute 50 seconds as the over-under probably didn't do much research. They might have set it to get the same number of people on both sides, which may explain the shift; however, I can't imagine this bet got that much action. Then again, I'm not that imaginative.</div>
<div>
<br /></div>
<div>
2) Josh DID. He did an  analysis of what is likely (he thinks it will go longer)</div>
<div>
<br /></div>
<div>
3) So- can Josh bet on this an clean up? Can you bet on this and clean up?</div>
<div>
<br /></div>
<div>
4) There is an issue: Some kinds of bets are legal in some places (betting who will WIN or beat a point-spread is legal in Las Vegas-- the Supreme court struck down a federal anti-betting rule). Some prop bets are legal. The Gladys Knight one is not.  Why not? Someone could have inside information! Gladys Knight would!</div>
<div>
<br /></div>
<div>
So you CAN bet  Rams+2.5 beats the Patriots LEGALLY</div>
<div>
<br /></div>
<div>
but to bet Gladys Knight's National Anthem will take more than 1 minute 50 seconds you might need to use  BITCOIN, and go to some offshore account. Too much sugar for a <a href="https://en.bitcoin.it/wiki/Satoshi_(unit)">satoshi</a>.</div>
<div>
<br /></div>
<div>
5) There is another issue- there is no such thing as a sure thing (I blogged on that <a href="https://blog.computationalcomplexity.org/2008/02/there-is-no-such-thing-as-sure-thing.html">here</a>). People who bet on sports for a living (I know one such person and will blog about that later) play THE LONG GAME. So to say</div>
<div>
<br /></div>
<div>
          <i> I will withdraw X dollars (for large X)  from my investments and bet it on </i></div>
<div>
<i>          Gladys Knight's</i><i>  Star Spangled Banner to go more than 1 minute 50 seconds</i></div>
<div>
<i>          because its a sure thing</i></div>
<div>
<br /></div>
<div>
Would be... a very bad idea.<br />
<br />
The above was all written the day before Superb Owl. Now its the next day and Gladys Knight has sung the National Anthem. So who won the Gladys Knight Bowl? The answer is not as straightforward as it could be, see <a href="https://www.usatoday.com/story/sports/nfl/super-bowl/2019/02/03/super-bowl-2019-gladys-knight-causes-prop-bet-controversy-anthem/2764778002/">here</a>.</div>
<div>
<br /></div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/02/dont-know-football-but-still-want-bet.html"><span class="datestr">at February 04, 2019 02:36 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/014">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/014">TR19-014 |  A New Proof of Nonsignalling Multiprover Parallel Repetition Theorem | 

	Himanshu Tyagi, 

	Shun Watanabe</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We present an information theoretic proof of the nonsignalling multiprover parallel repetition theorem, a recent extension of its two-prover variant that underlies many hardness of approximation results. The original proofs used de Finetti type decomposition for strategies. We present a new proof that is based on a technique we introduced recently for proving strong converse results in multiuser information theory and entails a change of measure after replacing hard information constraints with soft ones.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/014"><span class="datestr">at February 03, 2019 12:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15616">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/">A Strange Horizon</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Data science of many things including citations</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/allisonamazon/" rel="attachment wp-att-15619"><img src="https://rjlipton.files.wordpress.com/2019/02/allisonamazon.jpg?w=133&amp;h=200" alt="" width="133" class="alignright wp-image-15619" height="200" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Amazon India <a href="https://www.amazon.in/l/B001H6KWN6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Paul Allison is an emeritus professor of sociology at the University of Pennsylvania and the founder and president of the company <a href="https://statisticalhorizons.com/">Statistical Horizons</a>. They provides short courses and seminars for statistical training. </p>
<p>
Today we have a short seminar on statistics and horizons of effectiveness. <span id="more-15616"></span></p>
<p>
Our first topic is about citations. Did we say citations? What are we in research more interested in than citations? Allison co-wrote a paper on a <a href="https://en.wikipedia.org/wiki/Lotka's_law">“law”</a> claimed by Alfred Lotka about how the number of citations behaves. Full details in a moment, but two upshots are: </p>
<ul>
<li>
Over half of the papers are contributed by a few highly prolific authors. <p></p>
</li><li>
One-shot authors are roughly <img src="https://s0.wp.com/latex.php?latex=%7B61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{61\%}" class="latex" title="{61\%}" /> of the population but account for only a tiny proportion of the literature.
</li></ul>
<p>
</p><p></p><h2> Allison’s Paper </h2><p></p>
<p>Allison co-wrote his <a href="https://statisticalhorizons.com/wp-content/uploads/AllisonEtAl.SSS76.pdf">paper</a>, “Lotka’s Law: A Problem in Its Interpretation and Application,” with Derek de Solla Price, Belver Griffith, Michael Moravcsik, and John Stewart in 1976. Lotka’s law, which is related to George Zipf’s famous <a href="https://en.wikipedia.org/wiki/Zipf's_law">law</a>, alleges that over any time period in any scientific or literary field, the number <img src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a(n)}" class="latex" title="{a(n)}" /> of authors with <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> contributions obeys </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%28n%29+%3D+%5Cfrac%7BC%7D%7Bn%5E2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  a(n) = \frac{C}{n^2}, " class="latex" title="\displaystyle  a(n) = \frac{C}{n^2}, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> is independent of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. This suggests a maximum of <img src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D+%3D+%5Csqrt%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n_{max} = \sqrt{C}}" class="latex" title="{n_{max} = \sqrt{C}}" /> on the range of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, since higher <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> give <img src="https://s0.wp.com/latex.php?latex=%7Ba%28n%29+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a(n) &lt; 1}" class="latex" title="{a(n) &lt; 1}" />, but there is also a probabilistic interpretation: The law says that the total number of papers at <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is <img src="https://s0.wp.com/latex.php?latex=%7BC%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C/n}" class="latex" title="{C/n}" />, and that gives a positive constant expectation even when <img src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n_{max}}" class="latex" title="{n_{max}}" /> varies as <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. Both cases yield that out of the total number <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> of papers, which has <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5CTheta%28C%5Clog%28C%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = \Theta(C\log(C))}" class="latex" title="{T = \Theta(C\log(C))}" />, over half of them are contributed by a vanishing percentage of highly prolific authors. Meanwhile, one-shot authors are roughly <img src="https://s0.wp.com/latex.php?latex=%7B6%2F%5Cpi%5E2+%5Capprox+61%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{6/\pi^2 \approx 61\%}" class="latex" title="{6/\pi^2 \approx 61\%}" /> of the population but account for only a <img src="https://s0.wp.com/latex.php?latex=%7B1%2F%5Clog%28T%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/\log(T)}" class="latex" title="{1/\log(T)}" /> proportion of the literature.</p>
<p>
However, the paper also remarks on a third case, namely making <img src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n_{max}}" class="latex" title="{n_{max}}" /> a fixed constant—since human time is finite in any field. This puts a sharper <em>horizon</em> on Lotka’s Law and changes the inferences made as the horizon is approached. The paper shows how the <img src="https://s0.wp.com/latex.php?latex=%7Bn_%7Bmax%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n_{max}}" class="latex" title="{n_{max}}" /> factor intrudes on other inferences they would like to draw, even between the former two cases. And never mind <a href="http://www.revistadestatistica.ro/index.php/the-power-of-lotkas-law-through-the-eyes-of-r/">more</a>–<a href="https://rjlipton.wordpress.com/feed/www.fosareh.net/fa/files/pdf/Osareh-mostafavi-collnet[1].doc">recent</a> <a href="http://www.collnet.de/Berlin-2008/LarsenWIS2008llc.pdf">evidence</a> of <a href="http://www.librarywaves.com/index.php/lw/article/download/51/45/">breakdowns</a> in Lotka’s law. </p>
<p>
</p><p></p><h2> Horizons </h2><p></p>
<p></p><p>
We have mentioned de Solla Price <a href="https://rjlipton.wordpress.com/2012/09/29/why-we-lose-sleep-some-nights/">before</a> in regard to his founding <a href="https://en.wikipedia.org/wiki/Scientometrics">scientometrics</a>. In practice this is mainly concerned with citation analysis and other productivity metrics, but its widely-quoted definition, “the science of measuring and analyzing science,” strikes us as broader. We feel there should be a component for measuring limitations of the effectiveness of the science one is practicing.</p>
<p>
Now of course in statistics there are longstanding measures of statistical <a href="https://en.wikipedia.org/wiki/Power_(statistics)">power</a> and experiment acuity and of <em>noise</em> in general. Nevertheless, the cascading “(non-)reproducibility crisis” argues that more needs to be addressed. The development of software tools to counter “<a href="https://en.wikipedia.org/wiki/Data_dredging">p-hacking</a>” exemplifies a new layer of scientific modeling to do so—which could be called introspective modeling. </p>
<p>
I will exemplify with two “horizons” that are apparent in my own statistical chess research. One involves estimating the Elo rating of “perfect play.” The other involves the level of skill at which my data may cease to be effective. The former has captured popular imagination—it was among the first questions posed to me by Judit Polgar in a broadcast during the 2016 world championship match—but the latter is my concern in practice. We will see that these may be the same horizon, approached either by looking down from the stars or up from the road. </p>
<p>
I am not the first to do this kind of work or face the issue of its resolving power. Matej Guid, Artiz Perez, and Ivan Bratko made it the sole topic of a 2008 followup <a href="https://pdfs.semanticscholar.org/fcdc/9fb1e88c40de12ad9481f0d580f803bc1582.pdf">paper</a> to their 2006 <a href="https://en.chessbase.com/news/2006/world_champions2006.pdf">study</a> of all games in world championship matches. But their indicators strike me as weak. Most simply, they do not try to estimate where their horizon <em>is</em>, just argue that their results are not wholly beyond it. We will try to do more—but speculatively. The first step is rock-solid—it is a big surprise I found last month.</p>
<p>
</p><p></p><h2> More Data, More Resolution </h2><p></p>
<p></p><p>
I use strong chess programs to take two main kinds of data. My full model uses programs in an analysis mode that evaluates all available moves to the same degree of thoroughness and takes roughly 4–6 hours per game. My quicker “screening” tests use programs in their normal playing mode, which gives full shrift only to what’s considered the best move, but shaves the time down to 10–15 minutes. For my AAAI 2011 <a href="https://cse.buffalo.edu/~regan/papers/pdf/ReHa11c.pdf">paper</a> with Guy Haworth, I used over 400,000 positions from 5,700 games at rating levels from Elo 1600 to 2700 only, all run on my office and home PCs. Below Elo 2000 the available data was so scant that noise is evident in the paper’s table.</p>
<p>
Since then, many more games by lower-rated players are being archived—much thanks to the greater availability of chessboards that automatically record moves in the standard <a href="https://en.wikipedia.org/wiki/Portable_Game_Notation">PGN</a> format, and to an upswell in tournaments, for youth in particular. Last year, thanks to the great free bandwidth granted by my university’s Center for Computational Research (<a href="http://www.buffalo.edu/ccr.html">CCR</a>), I took data in the quicker mode from over 10,600,000 moves from just over 400,000 game-sides (counting White and Black separately) in every tournament compiled by <a href="https://en.chessbase.com/">ChessBase</a> as well as some posted only by The Week in Chess (<a href="http://theweekinchess.com/">TWIC</a>) or provided directly by the World Chess Federation (FIDE). My two main test quantities are:</p>
<ul>
<li>
The percentage of the computer’s best move being the one the player chose (“MM%”). <p></p>
</li><li>
The average error judged by the computer per move, scaling down large differences (“ASD”).
</li></ul>
<p>
My 2011 paper found strong linear relations of these quantities to the players’ rating, and great ASD fits on a 3-million-move data set are shown graphically in this <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a>. With MM% and my new 2018 data, here is what I see when I limit to the 1600–2700 range, grouping in “buckets” of 25 Elo points. All screenshots are taken with Andrew Que’s Polynomial Regression <a href="http://polynomialregression.drque.net/online.php">applet</a>. They all show data taken with Stockfish 9 run to search depth at least 20 and breadth at least 200 million nodes; the similar data for the chess program Komodo 11.3 gives similar results.</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfitpart/" rel="attachment wp-att-15620"><img src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfitpart.png?w=450&amp;h=285" alt="" width="450" class="aligncenter wp-image-15620" height="285" /></a></p>
<p>
Even with vastly more data, there still does not appear any reason to reject the simple hypothesis that the relation to rating is linear. Not only is <img src="https://s0.wp.com/latex.php?latex=%7BR%5E2+%3E+0.99%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R^2 &gt; 0.99}" class="latex" title="{R^2 &gt; 0.99}" />, the quality of fit is terrific. The noise under Elo 2000 is minimal.</p>
<p>
But now I have over 14,000 moves in individual buckets clear down to the FIDE minimum 1000 rating; only the 2750 bucket with 11,923 moves and the 2800-level bucket with 6,340 (from just a handful of the world’s elite players) lag behind. When those buckets are added, here is what we see:</p>
<p><a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearmmpfita/" rel="attachment wp-att-15622"><img src="https://rjlipton.files.wordpress.com/2019/02/linearmmpfita.png?w=450&amp;h=285" alt="" width="450" class="aligncenter wp-image-15622" height="285" /></a></p>
<p>
The linear hypothesis is notably less tenable. Instead, a quadratic polynomial fits supremely well:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfita/" rel="attachment wp-att-15623"><img src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfita.png?w=450&amp;h=285" alt="" width="450" class="aligncenter wp-image-15623" height="285" /></a></p>
<p>
Thus it seems I must admit a <em>nonlinearity</em> into my chess model. This may not be just about slightly improving my model’s application to players at the ends of the rating spectrum. Philosophically, nonlinearity can be a game-changer: the way Newtonian physics is fine for flying jets all around the globe but finding your neighbor’s house via <a href="http://physicscentral.com/explore/writers/will.cfm">GPS</a> absolutely requires Einstein. </p>
<p>
</p><p></p><h2> The Horizon Issue </h2><p></p>
<p></p><p>
Let us flip the axes so that <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is MM% and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is rating. Then the intercept of <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+100%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = 100\%}" class="latex" title="{X = 100\%}" /> would give the rating of perfect agreement with the computer. Well, here is what we see:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticmmpfitflipext/" rel="attachment wp-att-15624"><img src="https://rjlipton.files.wordpress.com/2019/02/quadraticmmpfitflipext.png?w=450&amp;h=285" alt="" width="450" class="aligncenter wp-image-15624" height="285" /></a></p>
<p>
Having the rating of perfect agreement be about 1950—which is a amateur A-level in the US—is ludicrous. The greater import is how the increase stops at Elo 3000 with matching just under 75%. The serious implication I draw is that this helps locate the horizon of effectiveness of the data and my methods based on it. Meanwhile, I’ve had the sense from applications that my full model based on smaller higher-quality data is coherent up to about 3100 but cannot tell differences above that. </p>
<p>
Indeed, there is a corroborating indicator of this horizon: The top chess programs, or even different (major) versions of the same program, don’t even match <em>each other</em> over 75% with regularity. Moreover, the <em>same program</em> will fairly often change to a different move when left running for more time or to a greater search depth. If it didn’t change, it wouldn’t improve. Thus my tests, which have no foreknowledge of how long a program used to cheat was running and on how powerful hardware, cannot expect to register positives at a higher rate. The natural agreement rates for human players range from about 35% for novices to upwards of 60% for world champions. </p>
<p>
</p><p></p><h2> The Average-Error Case </h2><p></p>
<p></p><p>
The fit to average scaled error-per-move (ASD) shows the other side of the horizon issue. The ASD measure is more tightly correlated to rating—as the graphs in the above-mentioned <a href="https://rjlipton.wordpress.com/2016/11/30/when-data-serves-turkey/">post</a> suffice to indicate. Here is the corresponding graph on the new data, again with flipped axes:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/linearasdfit/" rel="attachment wp-att-15625"><img src="https://rjlipton.files.wordpress.com/2019/02/linearasdfit.png?w=450&amp;h=285" alt="" width="450" class="aligncenter wp-image-15625" height="285" /></a></p>
<p>
Only under 1250 Elo does perfect linearity seem to be countermanded. The issue, however, is at the other end. Committing asymptotically zero error seems to be a more acute indicator of perfection than 100% agreement with a strong program. However, the <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />-intercept there is given as a rating under 3300, whereas computer programs have been reliably <a href="http://www.computerchess.org.uk/ccrl/404/">rated</a> above 3400, and very recently over 3500. Thus we’d appear to have computers rated higher than perfection.</p>
<p>
One can move from the above indication of my setup losing mojo before 3000 to allege that it is insufficient for fair judgment of human players above 2500, say, so that the intercept is not valid. My counter-argument is that the same intercept is also a robust extrapolation from the range 1500 to 2500 where the linear fit is nearly perfect and the computer’s sufficiency for authoritative judgment of the players is beyond doubt. </p>
<p>
Nevertheless, the above “game-changer” for the move-matching percentage suggests the same for ASD. A quadratic fit to ASD produces the following results:</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/quadraticasdfitnw/" rel="attachment wp-att-15626"><img src="https://rjlipton.files.wordpress.com/2019/02/quadraticasdfitnw.png?w=450&amp;h=285" alt="" width="450" class="aligncenter wp-image-15626" height="285" /></a></p>
<p>
Now the <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />-intercept at <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = 0}" class="latex" title="{X = 0}" /> is within error bars of 3500, in agreement with the 3475 figure currently used in my full model and less starkly under the measured ratings.</p>
<p>
</p><p></p><h2> One More Riff </h2><p></p>
<p></p><p>
Let us think of move-matching for a given rating <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> as a flip of a biased coin with heads probability <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+p_R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p = p_R}" class="latex" title="{p = p_R}" />. If we plot <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> not against <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> but against <img src="https://s0.wp.com/latex.php?latex=%7Bp%5Ccdot+p%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p\cdot p(1-p)}" class="latex" title="{p\cdot p(1-p)}" />, we recover a nearly perfect linear fit (the plot shows <img src="https://s0.wp.com/latex.php?latex=%7B4p%5E2+%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4p^2 (1-p)}" class="latex" title="{4p^2 (1-p)}" />):</p>
<p>
<a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/ppqfit/" rel="attachment wp-att-15627"><img src="https://rjlipton.files.wordpress.com/2019/02/ppqfit.png?w=450&amp;h=285" alt="" width="450" class="aligncenter wp-image-15627" height="285" /></a></p>
<p>
Well, <img src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p(1-p)}" class="latex" title="{p(1-p)}" /> is the variance of one coin flip. Why should multiplying <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> by this variance recover a linear fit in the <em>mean</em>? Only multiplying <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> by the square root of <img src="https://s0.wp.com/latex.php?latex=%7Bp%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p(1-p)}" class="latex" title="{p(1-p)}" /> still leaves a significantly non-linear plot. </p>
<p>
Recovering <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> from <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%281-p%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^2(1-p)}" class="latex" title="{p^2(1-p)}" /> needs solving a cubic equation. The maximum value is at <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Cfrac%7B2%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p = \frac{2}{3}}" class="latex" title="{p = \frac{2}{3}}" /> and is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B4%7D%7B27%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{4}{27}.}" class="latex" title="{\frac{4}{27}.}" /> Multiplying by <img src="https://s0.wp.com/latex.php?latex=%7B4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4}" class="latex" title="{4}" /> as in the plot makes <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B16%7D%7B27%7D+%5Capprox+0.592593%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{16}{27} \approx 0.592593}" class="latex" title="{\frac{16}{27} \approx 0.592593}" /> the maximum solvable value. This regression line associates this to a rating of only 2860. This suggests a tangibly lower horizon. It also seems contradicted by the fact of Magnus Carlsen maintaining a rating over 2860 from January 2013 through June 2015, yet his engine agreement did not approach 66.7%.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We’ve connected the horizon of perfect play to whether the fundamental relationship of rating to agreement with strong computer programs is linear, quadratic, or indirectly cubic. Which relationship is true? What further tests may best ascertain the range of effectiveness of inferences from these data?</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2019/02/03/a-strange-horizon/"><span class="datestr">at February 03, 2019 06:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1490">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/02/02/stoca-workshop/">STOCA workshop</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>For the past few months, we, the STOC 2019 PC, have enjoyed the privilege of reading and discussing a lot of exciting submissions. On Sunday and Monday we will reject most of them. After that, on <strong>Tuesday February 5th</strong>, we will celebrate with a 1-day workshop hosted at Google.</p>
<p>Here is the official website for registration (free!) and other useful infromation:<br />
<a href="https://sites.google.com/view/stoca19/home">https://sites.google.com/view/stoca19/home</a></p></div>







<p class="date">
by aviad.rubinstein <a href="https://theorydish.blog/2019/02/02/stoca-workshop/"><span class="datestr">at February 03, 2019 05:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16779">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/">Konstantin Tikhomirov: The Probability that a Bernoulli Matrix is Singular</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg"><img src="https://gilkalai.files.wordpress.com/2019/02/tikhomirov.jpg?w=640" alt="" class="alignnone size-full wp-image-16826" /></a></p>
<p><span style="color: #ff0000;"><strong>Konstantin Tikhomirov</strong></span></p>
<p>An old problem in combinatorial random matrix theory is cracked!</p>
<p><a href="https://arxiv.org/abs/1812.09016"><strong>Singularity of random Bernoulli matrices</strong></a> by <strong>Konstantin Tikhomirov</strong></p>
<p><strong>Abstract</strong>: For each <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, let <img src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_n" class="latex" title="M_n" /> be an <em>n</em>×<em>n</em> random matrix with independent ±1 entries. We show that</p>
<p style="text-align: center;">P(<img src="https://s0.wp.com/latex.php?latex=M_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="M_n" class="latex" title="M_n" /> is singular}=<img src="https://s0.wp.com/latex.php?latex=%281%2F2%2Bo_n%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(1/2+o_n(1))^n" class="latex" title="(1/2+o_n(1))^n" />,</p>
<p>which settles an old problem. Some generalizations are considered.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg"><img src="https://gilkalai.files.wordpress.com/2019/02/komlos.jpg?w=640" alt="" class="alignnone size-full wp-image-16821" /></a></p>
<p><span style="color: #ff0000;"><b>János Komlós</b></span></p>
<h3>Background and discussion</h3>
<p>What is the probability <img src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n)" class="latex" title="s(n)" /> that a random n by n matrix with <img src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pm 1" class="latex" title="\pm 1" /> entries is singular? Well, it can be singular if either two rows are identical, or if two columns are identical. This happens with probability</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=n%28n-1%29%281%2B0%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n(n-1)(1+0(1)) \cdot 2^{-n}" class="latex" title="n(n-1)(1+0(1)) \cdot 2^{-n}" />.</p>
<p>Are there other more dominant reasons for singularity? Are most <img src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pm 1" class="latex" title="\pm 1" /> matrices nonsingular as <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> tends to infinity? The first results in this direction are by Janos Komlos who first proved in 1968 that <img src="https://s0.wp.com/latex.php?latex=s%28n%29%3Do%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n)=o(1)" class="latex" title="s(n)=o(1)" /> and later that <img src="https://s0.wp.com/latex.php?latex=s%28n%29%3DO%281%2F%5Csqrt+n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n)=O(1/\sqrt n)" class="latex" title="s(n)=O(1/\sqrt n)" />. A major breakthrough came in 1995 when  <a href="http://www.ams.org/journals/jams/1995-08-01/S0894-0347-1995-1260107-2/home.html">Kahn , Komlos, and Szemeredi proved</a> that <img src="https://s0.wp.com/latex.php?latex=s%28n%29+%5Cle+0.999%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n) \le 0.999^n" class="latex" title="s(n) \le 0.999^n" />. Terry Tao and Van Vu improved in 2006 the constant to 0.939 and then to (3/4+o(1)) and the, now broken, world record from 2010 was <img src="https://s0.wp.com/latex.php?latex=%281%2F%5Csqrt+2%29%2Bo%281%29%29%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(1/\sqrt 2)+o(1))^n" class="latex" title="(1/\sqrt 2)+o(1))^n" />  by Jean Bourgain, Van Vu and Philip Wood. Congratulations Konstantin!</p>
<p>If you want to tease the Gods of Mathematics you can try to prove that <img src="https://s0.wp.com/latex.php?latex=s%28n%29+%3Dn%28n-1%29%281%2Bo%281%29%29+%5Ccdot+2%5E%7B-n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}" class="latex" title="s(n) =n(n-1)(1+o(1)) \cdot 2^{-n}" />? and, as suggested in the Kahn-Komlós-Szemerédi paper,  even prove an expansion  <img src="https://s0.wp.com/latex.php?latex=s%28n%29+%3D+2%7B%7Bn%7D+%5Cchoose+%7B2%7D%7D%28%5Cfrac%7B1%7D%7B2%7D%29%5E%7Bn%7D%2B2%7B%7Bn%7D%5Cchoose+%7B4%7D%7D+%28%5Cfrac%7B3%7D%7B8%7D%29%5En%5Ccdots&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots" class="latex" title="s(n) = 2{{n} \choose {2}}(\frac{1}{2})^{n}+2{{n}\choose {4}} (\frac{3}{8})^n\cdots" /> based on dependencies between <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-tuples of rows and columns.</p>
<p>Let me mention that  <a href="https://arxiv.org/abs/math/0505156">Kevin Costello, Tao, and Vu, proved in 2005</a> that  random symmetric matrices are almost surely non-singular.  This is related to beautiful mathematics. <a href="https://arxiv.org/abs/0804.2362"> Tao and Vu also proved</a> that the probability for vanishing of the permanent of a Bernoulli matrix is <img src="https://s0.wp.com/latex.php?latex=o%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="o(1)" class="latex" title="o(1)" />. I am not sure what is the proven behavior for permanents and one may expect that vanishing of the permanent occurs in probability which is super exponentially small. (Perhaps <img src="https://s0.wp.com/latex.php?latex=C%2F%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C/\sqrt {n!}" class="latex" title="C/\sqrt {n!}" />.)</p>
<p>Here are related posts on Tao’s blog What’s New. <a href="https://terrytao.wordpress.com/2007/12/05/milliman-lecture-ii-additive-combinatorics-and-random-matrices/">A post on Tao’s Milliman’s lecture on the additive combinatorics and random matrices</a>; <a href="https://terrytao.wordpress.com/2008/04/16/on-the-permanent-of-a-random-bernoulli-matrix/">On the permamnent of random Bernoulli matrix</a>;</p>
<h3>Determinants and the guaranteed cancellation phenomenon</h3>
<p>The value of the determinant of a Bernoulli matrix is the sum of <em>n!</em> ±1 terms. So we can guess that the expected value will be around <img src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sqrt {n!}" class="latex" title="\sqrt {n!}" />, and with high probability it is near the expected value. There is something special about the determinant which we can call the <strong>Guaranteed Cancellation Phenomenon (GCP)</strong>. The value of the determinant of a Bernoulli  matrix is at most <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n^{n/2}" class="latex" title="n^{n/2}" /> which is not that much larger than <img src="https://s0.wp.com/latex.php?latex=%5Csqrt+%7Bn%21%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sqrt {n!}" class="latex" title="\sqrt {n!}" />. (GCP applies to matrices with real or complex variables with rows with prescribed  <img src="https://s0.wp.com/latex.php?latex=%5Cell_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_2" class="latex" title="\ell_2" /> norms.)  Guaranteed cancellation is a very interesting mathematical phenomenon in various contexts. (For example, the prime number theorem and the Riemann hypothesis are about guaranteed cancellation.) The determinant itself is a polynomial of degree <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> with <img src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n^2" class="latex" title="n^2" /> variables , and GCP for determinants was one of the starting points in a paper that I wrote with Leonard Schulman on <a href="https://arxiv.org/abs/1804.04828">quasi-random multilinear polynomials</a>. (For other examples of GCP see also this <a href="https://mathoverflow.net/questions/59530/horst-kn%C3%B6rrers-permutation-cancellation-problem">MO question</a> and various posts  on Mobius randomness.) Maybe it is time to ask on MathOverflow for a list of places were GCP  is expected or proven.)</p>
<p>Sperner, the Littlewood-Offord problem, and additive combinatorics</p>
<p>The determinant of a <img src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\pm 1" class="latex" title="\pm 1" /> matrix is the signed sum of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> minors. It follows from Sperner’s theorem that if <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> of these minors are non-zero then the probability that the sum vanishes is <img src="https://s0.wp.com/latex.php?latex=O%281%2F%5Csqrt+m%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(1/\sqrt m)" class="latex" title="O(1/\sqrt m)" />. This is the idea behind Komlos’ second proof. The relevant general question (backward <a href="https://en.wikipedia.org/wiki/Littlewood%E2%80%93Offord_problem">Littlewood Offord</a>  problem) which is of much independent interest is “Under which conditions on a sequence <img src="https://s0.wp.com/latex.php?latex=a_1%2Ca_2%2C+%5Cdots%2C+a_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a_1,a_2, \dots, a_n" class="latex" title="a_1,a_2, \dots, a_n" /> we can guarantee that the probability that a signed sum of the sequence vanished (or has a small absolute value) is small.” The famous Erdos-Moser conjecture (solved on the nose by Stanley using the Hard Lefschetz theorem, sharpening a result by Sárközy and Szemerédi) asserts that if the elements of the sequence are distinct then the larger vanishing probability is attained by the sequence of integers between <em>-[n/2]</em> and +<em>[n/2]</em>. In this case (like for any arithmetic progression) the vanishing probability is <img src="https://s0.wp.com/latex.php?latex=n%5E%7B-3%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n^{-3/2}" class="latex" title="n^{-3/2}" />.  Kahn, Komlos and Szemeredi relied on (and extended)  a theory by  Gábor Halász for guaranteeing that the vanishing probability is small (exponentially small) and, of course, much work is needed to prove that Halász-type conditions are satisfied.</p>
<p>I was excited by the 2005 solution for symmetric matrices also because it involved a quadratic version of Littlewood-Offord type results which are of much independent interest. I think that there are many interesting remaining open problems.</p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/02/02/konstantin-tikhomrov-the-probability-that-a-bernoulli-matrix-is-singular/"><span class="datestr">at February 02, 2019 06:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-6555947.post-2316741109895040253">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/suresh.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://feedproxy.google.com/~r/TheGeomblog/~3/SO5XVo9kvXw/more-fat-blogging.html">More FAT* blogging</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Session 3: <a href="https://algorithmicfairness.wordpress.com/2019/01/30/fat-papers-profiling-and-representation/">Representation and Profiling</a><br /><br />Session 4: <a href="https://algorithmicfairness.wordpress.com/2019/02/01/fat-papers-fairness-methods/">Fairness methods. </a><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=SO5XVo9kvXw:HrNVfBPMlIM:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=yIl2AUoC8zA" border="0" /></a> <a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=SO5XVo9kvXw:HrNVfBPMlIM:63t7Ie-LG7Y"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=63t7Ie-LG7Y" border="0" /></a>
</div><img width="1" alt="" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/SO5XVo9kvXw" height="1" /></div>







<p class="date">
by Suresh Venkatasubramanian (noreply@blogger.com) <a href="http://feedproxy.google.com/~r/TheGeomblog/~3/SO5XVo9kvXw/more-fat-blogging.html"><span class="datestr">at February 02, 2019 07:46 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7467">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/02/01/black-holes-a-complexity-theory-perspective/">Black Holes, a Complexity Theory perspective</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Guest post by Chi-Ning Chou and Parth Mehta from <a href="https://www.boazbarak.org/fall18seminar/">the physics and computation seminar</a>.</p>
<h3>Abstract</h3>
<p>The firewall paradox (introduced <em>here</em>) is a bewitching thought experiment that mandates a deeper understanding of our reality. As luck would have it, QFT predictions seem sound, GR calculations appear valid, and semi-classical approximations look reasonable: no one is willing to budge! To save Alice from burning in the miserable firewall, therefore, we must come up with a radically new proposal. This blog post aims to map what seems to be a hard, physics dilemma into a Computer Science problem that we can, using the grace of a lazy programmer, show to be hard to solve. In particular, we present an overview of the Harlow-Hayden decoding task and show how it maps the Firewall Paradox to a hard computation on a quantum computer. We end by rigorously defining quantum circuit complexity, Aaronson’s improved proof, AdS/CFT correspondence, and some fascinating homework (open) problems.</p>
<h2>Why all the fuss?</h2>
<p>Have you ever confessed to yourself that you don’t quite understand Black Hole complementarity well? In the past decade or so, physicists realized they did not grasp the concept thoroughly either. The firewall paradox is a natural result of bewildered physicists trying to make sense of reality. Thus far, no satisfying physical explanation reaches people’s consensus. Nevertheless, Daniel Harlow and Patrick Hayden [HH13] proposed a tempting solution to the firewall paradox using Computational Complexity (CC). Concretely, they showed the following.</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Ctext%7BA+conjecture+in+CC+is+true%7D%5CRightarrow%5Ctext%7BFirewalls+do+not+exist%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}." class="latex" title="\text{A conjecture in CC is true}\Rightarrow\text{Firewalls do not exist}." /></p>
<p>We elaborate on this deep connection throughout this post.</p>
<h3>Problem Solving: Physics v.s. Computer Science</h3>
<p>The notion of a `conjecture’ has different implications for either field. In Physics, a wrong conjecture often delights physicists since there is more work left to do and better theory required to explain the physical phenomenon under study. For complexity theorists, however, if, say, the famous <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Cneq%5Cmathbf%7BNP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P}\neq\mathbf{NP}" class="latex" title="\mathbf{P}\neq\mathbf{NP}" /> is proved to be false, a few consequences follow. First, the authors of the proof win a million dollars (See the <a href="http://www.claymath.org/millennium-problems/p-vs-np-problem" target="_blank" rel="noopener">Millennium problems</a>.). Second, such a result would break almost all the foundations of computational complexity and cryptography. That is, refuting an (important) conjecture in computational complexity is tantamount to resulting in real-world catastrophes! Below in Table 1 is a short summary.</p>
<table style="border: 1px solid black; border-collapse: collapse;">
<tbody>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;"></td>
<td style="border: 1px solid black;">Theoretical Physics</td>
<td style="border: 1px solid black;">Theoretical Computer Science</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Object</td>
<td style="border: 1px solid black;">Are the mathematical models for our physical world correct?</td>
<td style="border: 1px solid black;">Is our intuition about the mathematical models we defined correct?</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">Consequences of disproving</td>
<td style="border: 1px solid black;">After few days/months/years, physicists will come up with a new model and try to falsify it.</td>
<td style="border: 1px solid black;">The belief system of complexity theorists collapses. Some super algorithms might show up and shake the world.</td>
</tr>
<tr style="border: 1px solid black;">
<td style="border: 1px solid black;">How to prove/disprove</td>
<td style="border: 1px solid black;">Checking mathematical consistency, doing both thought and empirical experiments.</td>
<td style="border: 1px solid black;">Using fancy mathematics or designing super algorithms.</td>
</tr>
</tbody>
</table>
<p style="text-align: center;">Table 1: “Conjecture”, as used in Physics and Computer Science.</p>
<p>We labour above to convince the reader about these differences because the Harlow-Hayden decoding task has vital implications for both, Physics and Computer Science. The connections between Black Holes and Computational Complexity can be thought of as a new <em>testbench</em> for physical models.</p>
<h2>Reckless review: Quantum Information</h2>
<h3>Gates</h3>
<p>In Quantum Computation, gates are unitary operators. Some common gates used in the Quantum Information literature are as follows:</p>
<ul>
<li>
<div>Single-qubit: Pauli matrices (<em>i.e.,</em> <img src="https://s0.wp.com/latex.php?latex=X%2CY%2CZ&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X,Y,Z" class="latex" title="X,Y,Z" />), phase operator <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />, Hadamard matrix <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />.</div>
</li>
<li>
<div>Two-qubit: CNOT, Toffoli, CZ.</div>
</li>
</ul>
<p>For more details, please refer to [NC02]. Interestingly enough, singe-qubit and two-qubit gates are sufficient to construct any <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit gates! Such a set of operators is said to be <em>universal</em>. For example, <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{\text{Toffoli},H,P\}" class="latex" title="\{\text{Toffoli},H,P\}" /> and <img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BCNOT%7D%2CG%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{\text{CNOT},G\}" class="latex" title="\{\text{CNOT},G\}" /> are universal for almost every single-qubit operator. Furthermore, Kitaev and Solovay gave a <em>qualitative</em> version of the universality theorem by showing that getting an <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> approximation to an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit operator in trace norm, only <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog%5E21%2F%5Cepsilon%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\log^21/\epsilon)" class="latex" title="O(\log^21/\epsilon)" /> gates are needed. A final remark on unitary operators: an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit operator is actually a matrix of size <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" /> by <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" />. Namely, it requires <img src="https://s0.wp.com/latex.php?latex=2%5E%7B2n%7D-2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2n}-2^n" class="latex" title="2^{2n}-2^n" /> complex numbers to describe an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit operator. (Note the difference between <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> and <img src="https://s0.wp.com/latex.php?latex=2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n" class="latex" title="2^n" />.)</p>
<h3>Quantum circuits</h3>
<p>A quantum circuit <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}" class="latex" title="\mathcal{C}" /> has inputs consisting of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubits, potentially with <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> <em><a href="https://en.wikipedia.org/wiki/Ancilla_bit" target="_blank" rel="noopener">ancilla bits</a></em>. The computation is done by interior gates from some universal gate set, <em>e.g., </em><img src="https://s0.wp.com/latex.php?latex=%5C%7B%5Ctext%7BToffoli%7D%2CH%2CP%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{\text{Toffoli},H,P\}" class="latex" title="\{\text{Toffoli},H,P\}" />. The outputs are <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits with potentially <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> bits of garbage. See the following example of quantum circuit for the <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-qubit Hadamard operator <img src="https://s0.wp.com/latex.php?latex=H_n%7C+x%5Crangle%3D%5Csum_%7By%5Cin%5C%7B0%2C1%5C%7D%5En%7D%28-1%29%5E%7B%5Clangle+x%2Cy%5Crangle%7D%7Cy%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle" class="latex" title="H_n| x\rangle=\sum_{y\in\{0,1\}^n}(-1)^{\langle x,y\rangle}|y\rangle" /> in Figure 1.</p>
<div style="width: 413px;" class="wp-caption aligncenter" id="attachment_7472"><img src="https://windowsontheory.files.wordpress.com/2019/02/hadamard-e1549002349573.png?w=403&amp;h=266" alt="hadamard" width="403" class="alignnone  wp-image-7472" height="266" /><p class="wp-caption-text">Figure 1: A quantum circuit for the n-qubit Hadamard operator.</p></div>
<p>Similarly, the size of a quantum circuit is defined as the number of interior gates. In Figure 1 for example, the size of the circuit is <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />.</p>
<h3>Quantum circuit complexity: <strong>BQP/poly</strong></h3>
<p>Let <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" title="f:\{0,1\}^n\rightarrow\{0,1\}" /> be a boolean function. Define its quantum circuit complexity as the size of the smallest quantum circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> such that for any <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in\{0,1\}^n" class="latex" title="x\in\{0,1\}^n" /></p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." /></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQSIZE}[s(n)]" class="latex" title="\mathbf{BQSIZE}[s(n)]" /> denote the class of boolean functions of quantum circuit complexity at most <img src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n)" class="latex" title="s(n)" />. The complexity class <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP/poly}" class="latex" title="\mathbf{BQP/poly}" /> is defined as <img src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQSIZE%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]" class="latex" title="\cup_{c\in\mathbb{N}}\mathbf{BQSIZE}[n^c]" />. It immediately follows from definition that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}" class="latex" title="\mathbf{P/poly}\subseteq\mathbf{BQP/poly}" />. As proving lower bound for <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P/poly}" class="latex" title="\mathbf{P/poly}" /> (<em>i.e.,</em> finding a problem that is not in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P/poly}" class="latex" title="\mathbf{P/poly}" />) is a long-standing extremely difficult problem, it is believed to be hard to prove lower bound against <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP/poly}" class="latex" title="\mathbf{BQP/poly}" />.</p>
<h3>Uniform quantum circuit complexity: BQP</h3>
<p>As <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP/poly}" class="latex" title="\mathbf{BQP/poly}" /> is too powerful to work with, one might want to define a weaker version of the quantum complexity measure. A natural choice is considering a <em>uniform</em> computational model.</p>
<p>In the classical setting, a uniform computational model is defined using a Turing machine. However, it is not clear how to define the corresponding version, a quantum Turing machine. One way to do so is via <em>uniform circuits</em>, defined as follows. We say a circuit family <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3D%5C%7BC_n%5C%7D_%7Bn%5Cin%5Cmathbb%7BN%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}" class="latex" title="\mathcal{C}=\{C_n\}_{n\in\mathbb{N}}" /> is <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P}" class="latex" title="\mathbf{P}" />-uniform if there exists a polynomial time Turing machine such that on input <img src="https://s0.wp.com/latex.php?latex=1%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1^n" class="latex" title="1^n" />, it outputs <img src="https://s0.wp.com/latex.php?latex=C_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C_n" class="latex" title="C_n" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:\{0,1\}^n\rightarrow\{0,1\}" class="latex" title="f:\{0,1\}^n\rightarrow\{0,1\}" /> be a boolean function. Define its uniform quantum circuit complexity as the size of the smallest <strong>uniform</strong> quantum circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> such that for any <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in\{0,1\}^n" class="latex" title="x\in\{0,1\}^n" /></p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5CPr%5Cleft%5B%5Cmathcal%7BM%7D_1%28C%7Cx%5Crangle%29%3Df%28x%29%5Cright%5D%5Cgeq%5Cfrac%7B2%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." class="latex" title="\Pr\left[\mathcal{M}_1(C|x\rangle)=f(x)\right]\geq\frac{2}{3}." /></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQTIME%7D%5Bs%28n%29%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQTIME}[s(n)]" class="latex" title="\mathbf{BQTIME}[s(n)]" /> denote the class of boolean functions of quantum circuit complexity at most <img src="https://s0.wp.com/latex.php?latex=s%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="s(n)" class="latex" title="s(n)" />. The complexity class <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP}" class="latex" title="\mathbf{BQP}" /> is defined as <img src="https://s0.wp.com/latex.php?latex=%5Ccup_%7Bc%5Cin%5Cmathbb%7BN%7D%7D%5Cmathbf%7BBQTIME%7D%5Bn%5Ec%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]" class="latex" title="\cup_{c\in\mathbb{N}}\mathbf{BQTIME}[n^c]" />. It immediately follows from definition that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%5Csubseteq%5Cmathbf%7BBPP%7D%5Csubseteq%5Cmathbf%7BBQP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}" class="latex" title="\mathbf{P}\subseteq\mathbf{BPP}\subseteq\mathbf{BQP}" />.</p>
<h3>Unitary complexity: C(U)</h3>
<p>Let <img src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" title="U\in\mathbb{C}^{2^n\times2^n}" /> be an unitary matrix. Define <img src="https://s0.wp.com/latex.php?latex=C%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C(U)" class="latex" title="C(U)" /> be the smallest quantum circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> such that</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5C%7CC-U%5C%7C_%7B%5Cinfty%7D%5Cleq%5Cfrac%7B1%7D%7B3%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\|C-U\|_{\infty}\leq\frac{1}{3}." class="latex" title="\|C-U\|_{\infty}\leq\frac{1}{3}." /></p>
<p>This unitary complexity can be thought of as a relaxation of the quantum circuit complexity. The reason is that here a unitary matrix <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> might not compute a boolean function. Thus, proving a lower bound for <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQSIZE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQSIZE}" class="latex" title="\mathbf{BQSIZE}" /> implies a lower bound for unitary complexity while the converse is not clear. Namely, proving a super-polynomial lower bound for the unitary complexity might be an easier task.</p>
<p>However, no non-trivial<sup>1</sup> lower bound for the unitary complexity is known and there is, unfortunately, no formal <em>barrier result</em> explaining why this is difficult to prove.</p>
<h3>Warm-up: Gottesman-Knill</h3>
<p>We defined quantum circuits above, and we hope you find them exotic – at least start-up investors do. But given how fundamental quantum circuits are to the Harlow-Hayden decoding task, we ask: is it possible to efficiently (classically) simulate a quantum circuit made up of a restricted but non-trivial set of quantum gates? We show below a restricted variant of the popular Gottesman-Knill Theorem:</p>
<blockquote><p><strong>Theorem (Gottesman-Knill).<br />
</strong><span style="color: #4b4f53; background-color: #ffffff;">1. Given: Clifford circuit <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%3A+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle+%5Crightarrow+%5C%7B%7C0%5Crangle%2C%7C1%5Crangle%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}" class="latex" title="\mathcal{C}: |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle \rightarrow \{|0\rangle,|1\rangle\}" /> made up of gates <img src="https://s0.wp.com/latex.php?latex=%5C%7BCNOT%2C+P%2C+H%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{CNOT, P, H\}" class="latex" title="\{CNOT, P, H\}" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}" class="latex" title="\mathcal{C}" /> is measured on its first output line.<br />
</span><span style="color: #4b4f53; background-color: #ffffff;">2.Task: Show that it is possible to (classically) efficiently sample the output distribution of <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}" class="latex" title="\mathcal{C}" />.</span></p></blockquote>
<p><em>Proof:</em></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%7B%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%7C0%5Crangle%7D%5Clangle0%7C%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle" class="latex" title="\Pr(0) = \langle{\psi_0|\mathcal{C}^{\dag}(|0\rangle}\langle0|)\mathcal{C}|\psi_0\rangle" /> where <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi_0%5Crangle+%3D+%7C%5Calpha_1%5Crangle%5Cotimes+%5Ccdots+%5Cotimes+%7C%5Calpha_n%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle" class="latex" title="|\psi_0\rangle = |\alpha_1\rangle\otimes \cdots \otimes |\alpha_n\rangle" />. Since the projector can be written as <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5Clangle0%7C%3D+%5Cfrac%7BI+%2B+Z%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle\langle0|= \frac{I + Z}{2}" class="latex" title="|0\rangle\langle0|= \frac{I + Z}{2}" />, we get</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5CPr%280%29+%3D+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7D%28%5Cfrac%7BI+%2B+Z%7D%7B2%7D%29%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D%5Cfrac%7B1%7D%7B2%7D%5B1+%2B+%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]" class="latex" title="\Pr(0) = \langle\psi_0|\mathcal{C}^{\dag}(\frac{I + Z}{2})\mathcal{C}|\psi_0\rangle =\frac{1}{2}[1 + \langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle]" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=Z_1+%3D+Z+%5Cotimes+I%5Ccdots+%5Cotimes+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Z_1 = Z \otimes I\cdots \otimes I" class="latex" title="Z_1 = Z \otimes I\cdots \otimes I" /> since we only measure the first output line of <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}" class="latex" title="\mathcal{C}" />. At first glance, <img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle" class="latex" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle" /> might look like a monstrous computation to perform since, in general, the operator in the middle is a <img src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n\times 2^n" class="latex" title="2^n\times 2^n" /> matrix, so the calculating the inner product would require exponential time classically. However, recognizing that Clifford gates are normalizers of the Pauli Group on <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits, note that <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D+%3D+P_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n" class="latex" title="\mathcal{C}^{\dag}Z_1\mathcal{C} = P_1 \otimes \cdots \otimes P_n" /> where <img src="https://s0.wp.com/latex.php?latex=P_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P_i" class="latex" title="P_i" /> is some Pauli matrix. It is straightforward to show that these update rules can be computed efficiently. We thus have</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Clangle%5Cpsi_0%7C%5Cmathcal%7BC%7D%5E%7B%5Cdag%7DZ_1%5Cmathcal%7BC%7D%7C%5Cpsi_0%5Crangle+%3D+%5Clangle%5Cpsi_0%7CP_1+%5Cotimes+%5Ccdots+%5Cotimes+P_n%7C%5Cpsi_0%5Crangle+%3D+%5Cprod_%7Bi+%3D+1%7D%5E%7Bn%7D+%5Clangle%5Calpha_i%7CP_i%7C%5Calpha_i%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle" class="latex" title="\langle\psi_0|\mathcal{C}^{\dag}Z_1\mathcal{C}|\psi_0\rangle = \langle\psi_0|P_1 \otimes \cdots \otimes P_n|\psi_0\rangle = \prod_{i = 1}^{n} \langle\alpha_i|P_i|\alpha_i\rangle" /></p>
<p>which is a product of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> terms. We have thus reduced the (exponentially large) burden of computing a giant <img src="https://s0.wp.com/latex.php?latex=2%5En%5Ctimes+2%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^n\times 2^n" class="latex" title="2^n\times 2^n" /> matrix<br />
to computing <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> matrices size <img src="https://s0.wp.com/latex.php?latex=2%5Ctimes+2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2\times 2" class="latex" title="2\times 2" />, so we can sample the output distribution efficiently.</p>
<h2>The Firewall paradox and the Harlow-Hayden decoding task</h2>
<h3>Physics to CS</h3>
<div style="width: 411px;" class="wp-caption aligncenter" id="attachment_7468"><img src="https://windowsontheory.files.wordpress.com/2019/02/bh.png?w=401&amp;h=417" alt="bh" width="401" class="alignnone  wp-image-7468" height="417" /><p class="wp-caption-text">Figure 2: A cartoon representing drama (no pun intended) near the Black Hole.</p></div>
<p>All of the black hole physics covered in the previous blog post leads to the moment (we hope) you have been waiting for: a charming resolution of the firewall paradox. Consider the interior of an old, rusty black hole <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> that has radiated away more than half of its matter. Let <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> be the old Hawking radiation, and let <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> represent the fresh Hawking radiation coming right out of the boundary of the Black Hole. Alice is our canonical Ph.D. student who is brave enough to risk her life for physics. Since <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is a giant information scrambler, we expect to find entanglement between <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> with overwhelming probability. We know from QFT that there are bell pairs straddling the event horizon of the black hole, so <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> and <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> should be maximally entangled. But this is a problem because <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> cannot be entangled with both <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />! The AMPS argument shows that if Alice is able to distill a bell pair between <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" />, then we should see a firewall of photons at the event horizon, thus violating the no-drama postulate. See Figure 2 for more intuition about the set up. (Note that the <img src="https://s0.wp.com/latex.php?latex=%5Ccup&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\cup" class="latex" title="\cup" />‘s represent Bell Pairs, as consistent with the 3D-Quon Language) If we take Black Hole complimentary seriously, then we have an answer! If Alice does not distill a Bell pair between <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" />, then nothing really happens. However, if Alice does manage to distill the entanglement between <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and <img src="https://s0.wp.com/latex.php?latex=B+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B " class="latex" title="B " />, then we witness a firewall. Is not this answer so very unsatisfactory? Why should the existence of a firewall depend on Alice’s ability to distill entanglement? What is so special about this decoding task?<br />
The H-H decoding task answers precisely this question. Intuitively, it says that if Alice manages to distill a Bell pair between <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />, she could also invert a one-way function, a task we believe is very hard to perform! We conjecture that Alice would take exponential time to decode the entanglement, so the Black Hole would disappear long before Alice even makes a dent in the problem! Before we provide an in depth resolution of the paradox through the H-H decoding, let us (as good philosophers do) briefly review assumptions:</p>
<ol>
<li>The Black Hole <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> can be modelled by a finite collection of qubits, say <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits.</li>
<li>Alice is told that the initial state of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is the product basis <img src="https://s0.wp.com/latex.php?latex=%7C0%5Crangle%5E%7B%5Cotimes+n%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0\rangle^{\otimes n}" class="latex" title="|0\rangle^{\otimes n}" />.</li>
<li>Black Hole dynamics are assumed to be unitary, so Alice need not worry about some spooky M-theory that may claim to evolve <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> in a non-unitary fashion.</li>
<li><img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is a giant information scrambler, represented by some random circuit <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}" class="latex" title="\mathcal{C}" />.</li>
<li>Fresh radiation <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> is a single qubit, w.l.o.g., since any additional qubits could be made a part of <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" />.</li>
<li><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_{RBH}" class="latex" title="|\psi\rangle_{RBH}" /> is not Haar-Random. Mini-exercise: prove that if <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_{RBH}" class="latex" title="|\psi\rangle_{RBH}" /> is Haar-Random, our job becomes easy because the circuit complexity of the H-H decoding task grows exponentially with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />, the size of <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />.</li>
<li>Alice has access only to circuit <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}" class="latex" title="\mathcal{C}" /> and <img src="https://s0.wp.com/latex.php?latex=R%2C+B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R, B" class="latex" title="R, B" /> but not <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />. Trivial Mini-exercise: prove that if Alice has access to <img src="https://s0.wp.com/latex.php?latex=R%2CB%2CH%2C+%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R,B,H, \mathcal{C}" class="latex" title="R,B,H, \mathcal{C}" />, then it is easy to distill the entanglement between <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" />.</li>
<li>Alice may be an intellectual Goddess who just knows which unitary to apply, or, more realistically, someone who has exponential time to prepare before the Black Hole forms. Of crucial importance therefore is the circuit complexity of the unitary Alice applies to distill the Bell pair, not so much the process of finding the unitary.</li>
</ol>
<h3>Distilling the B-R Bell pair</h3>
<p>Let us jump into the definition of the <em>Harlow-Hayden decoding task</em>.</p>
<p><strong>Definition (Harlow-Hayden decoding task).</strong><br />
Given a (polynomial-size) quantum circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> as input such that <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_%7BRBH%7D%3DC%7C0%5En%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_{RBH}=C|0^n\rangle" class="latex" title="|\psi\rangle_{RBH}=C|0^n\rangle" /> where <img src="https://s0.wp.com/latex.php?latex=R%2CB%2CH&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R,B,H" class="latex" title="R,B,H" /> are three disjoint part of the <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> qubits. Furthermore, it is guaranteed that there exists a unitary operator <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> acting only on the qubits in <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> such that after applying <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" />, the rightmost bit of <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> and the leftmost bit of <img src="https://s0.wp.com/latex.php?latex=B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="B" class="latex" title="B" /> forms a bell pair <img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B%7C00%5Crangle%2B%7C11%5Crangle%7D%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{|00\rangle+|11\rangle}{\sqrt{2}}" class="latex" title="\frac{|00\rangle+|11\rangle}{\sqrt{2}}" />. The goal of the Harlow-Hayden decoding task is then to find a quantum circuit for such U on the qubits in <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" />. See Figure 3.</p>
<div style="width: 410px;" class="wp-caption aligncenter" id="attachment_7474"><img src="https://windowsontheory.files.wordpress.com/2019/02/hhd.png?w=400&amp;h=238" alt="hhd" width="400" class="alignnone  wp-image-7474" height="238" /><p class="wp-caption-text">Figure 3: The Harlow-Hayden decoding task.</p></div>
<p>A necessary condition for the firewall paradox to make sense is that the Harlow-Hayden decoding task should be <em>easy</em>. If Alice cannot distill the entanglement efficiently, the black hole will evaporate before Alice is ready to witness the firewall!</p>
<p>To refute the firewall paradox, Harlow and Hayden proved the following theorem.</p>
<blockquote><p><strong>Theorem 1.<br />
</strong>If the Harlow-Hayden decoding task can be done in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP/poly}" class="latex" title="\mathbf{BQP/poly}" />, then <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" />.<strong><br />
</strong></p></blockquote>
<p>We won’t formally define the complexity class <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{SZK}" class="latex" title="\mathbf{SZK}" />. However, it is important to know that the foundation of the lattice-based cryptography, a promising <em>quantum-secure</em> crypto framework, is based on the hardness of some problem in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{SZK}" class="latex" title="\mathbf{SZK}" />. If <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BSZK%7D%5Csubseteq%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" class="latex" title="\mathbf{SZK}\subseteq\mathbf{BQP/poly}" />, then all lattice-based cryptosystems can be broken by polynomial time quantum algorithm!</p>
<p>Instead of a proof for Theorem 1, which is more involved, we give a proof for an improvement of the Harlow-Hayden theorem due to Scott Aaronson. (Aaronson also showed that there might not even exist quantum-secure cryptography if the Harlow-Hayden decoding task can be efficiently solved!)</p>
<h2>Aaronson’s improvement</h2>
<p>In Aaronson’s lecture notes [Aar16], he showed the following improvement on Theorem 1.</p>
<blockquote><p><strong>Theorem 2.</strong><br />
If the Harlow-Hayden decoding task can be done in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP/poly}" class="latex" title="\mathbf{BQP/poly}" />, then quantum-secure injective one-way function does not exist.</p></blockquote>
<p>Before formally defining a one way function, it is paramount to understand its impact: modern cryptosystems are built from some variant of a one-way function. Intuitively, primitives that have the one-way property are (i) easy to implement (<em>e.g.,</em> encrypt) but (ii) hard to invert (<em>e.g.,</em> be attacked). As a result, if there is no quantum-secure injective one-way function, then that is strong evidence that quantum-secure cryptography might not exist.</p>
<p>Now, let us formally define what quantum-secure injective one-way function is and give a formal proof for Theorem 2.</p>
<blockquote><p><strong>Definition 1 (Quantum-secure injective one-way function).<br />
</strong>A boolean function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" title="f:\{0,1\}^n\rightarrow\{0,1\}^m" /> is a quantum-secure injective one-way function if</p>
<ul>
<li><img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> is injective,</li>
<li><img src="https://s0.wp.com/latex.php?latex=f%5Cin%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f\in\mathbf{BQP/poly}" class="latex" title="f\in\mathbf{BQP/poly}" />, and</li>
<li>for any polynomial time quantum algorithm <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /></li>
</ul>
<div style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5CPr_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Bf%28x%29%3Df%28A%28f%28x%29%29%29%5D%5Cleq%5Cfrac%7B1%7D%7B%5Ctext%7Bpoly%7D%28n%29%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}." class="latex" title="\Pr_{x\in\{0,1\}^n}[f(x)=f(A(f(x)))]\leq\frac{1}{\text{poly}(n)}." /></div>
</blockquote>
<p>Note that since <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> is injective, the last condition can actually be phrased as <img src="https://s0.wp.com/latex.php?latex=x%3DA%28f%28x%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x=A(f(x))" class="latex" title="x=A(f(x))" />. Also, the condition should be read as “on input <img src="https://s0.wp.com/latex.php?latex=f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f(x)" class="latex" title="f(x)" />, the quantum algorithm <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> outputs <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />”, namely, <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> inverts <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" />.</p>
<div><em>Proof:</em></div>
<div></div>
<p>Suppose the Harlow-Hayden decoding task is in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP/poly}" class="latex" title="\mathbf{BQP/poly}" />, we are going to show that for any injective <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%5Crightarrow%5C%7B0%2C1%5C%7D%5Em&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:\{0,1\}^n\rightarrow\{0,1\}^m" class="latex" title="f:\{0,1\}^n\rightarrow\{0,1\}^m" /> computable by some polynomial size quantum circuit, there is a polynomial time quantum algorithm that inverts <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" />. Namely, <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> is not a quantum-secure injective one-way function.To get an efficient inverting algorithm for <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" />, let us first prepare a special circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> from <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> and treat it as an input to the Harlow-Hayden decoding task. The circuit <img src="https://s0.wp.com/latex.php?latex=C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C" class="latex" title="C" /> will simply map the <img src="https://s0.wp.com/latex.php?latex=%7C0%5E%7Bm%2B2%2Bn%7D%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|0^{m+2+n}\rangle" class="latex" title="|0^{m+2+n}\rangle" /> to the following state</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5E%7Bm%2B2%2Bn%7D%7D%7D%5Csum_%7Bx%5Cin%5C%7B0%2C1%5C%7D%5En%7D%5Cleft%28%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%7C0%5Crangle_B%2B%7Cf%28x%29%2C1%5Crangle_R%7C1%5Crangle_B%5Cright%29%7Cx%5Crangle_H.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H." class="latex" title="\frac{1}{\sqrt{2^{m+2+n}}}\sum_{x\in\{0,1\}^n}\left(|x,0^{m-n},0\rangle_R|0\rangle_B+|f(x),1\rangle_R|1\rangle_B\right)|x\rangle_H." /></p>
<p>Note that as <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> has a polynomial size quantum circuit, the circuit <img src="https://s0.wp.com/latex.php?latex=%5Cmathcal%7BC%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathcal{C}" class="latex" title="\mathcal{C}" /> can also be implemented in polynomial size.Next, the easiness of the Harlow-Hayden decoding task guarantees us the existence of a unitary operation <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> on the qubits in <img src="https://s0.wp.com/latex.php?latex=R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R" class="latex" title="R" /> such that for any <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in\{0,1\}^n" class="latex" title="x\in\{0,1\}^n" /></p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=U%5Cleft%28%5Cfrac%7B%7Cx%2C0%5E%7Bm-n%7D%2C0%5Crangle_R%2B%7Cf%28x%29%2C1%5Crangle_R%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29+%3D+%7C%5Cphi_x%5Crangle_R%5Cleft%28%5Cfrac%7B%7C0%5Crangle%2B%7C1%5Crangle%7D%7B%5Csqrt%7B2%7D%7D%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)" class="latex" title="U\left(\frac{|x,0^{m-n},0\rangle_R+|f(x),1\rangle_R}{\sqrt{2}}\right) = |\phi_x\rangle_R\left(\frac{|0\rangle+|1\rangle}{\sqrt{2}}\right)" /></p>
<p>for some state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cphi_x%5Crangle_R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\phi_x\rangle_R" class="latex" title="|\phi_x\rangle_R" />. By restricting <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> on the first <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> qubits, one can get unitary operators <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> such that for all <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in\{0,1\}^n" class="latex" title="x\in\{0,1\}^n" />,</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=V%7Cx%2C0%5E%7Bm-n%7D%5Crangle%3D%7C%5Cphi_x%5Crangle%5Ctext%7B+and+%7DW%7Cf%28x%29%5Crangle%3D%7C%5Cphi_x%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle." class="latex" title="V|x,0^{m-n}\rangle=|\phi_x\rangle\text{ and }W|f(x)\rangle=|\phi_x\rangle." /></p>
<p>Thus, <img src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V^\dagger W" class="latex" title="V^\dagger W" /> inverts <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> because for any <img src="https://s0.wp.com/latex.php?latex=x%5Cin%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x\in\{0,1\}^n" class="latex" title="x\in\{0,1\}^n" />,</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=V%5E%5Cdagger+W%7Cf%28x%29%5Crangle%3D%7Cx%2C0%5E%7Bm-n%7D%5Crangle.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle." class="latex" title="V^\dagger W|f(x)\rangle=|x,0^{m-n}\rangle." /></p>
<p>Furthermore, as we are guaranteed that the Harlow-Hayden decoding task is in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BBQP%2Fpoly%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{BQP/poly}" class="latex" title="\mathbf{BQP/poly}" />, <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> as well as <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> and <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W" class="latex" title="W" /> all have polynomial size quantum circuits! Namely, <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> can be efficiently inverted by a quantum algorithm and thus <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> is not a quantum-secure injective one-way function.</p>
<h2>What’s next?</h2>
<p>The Harlow-Hayden decoding task as well as the Aaronson’s improvement can be interpreted as (strong) evidence that distilling the B-R Bell pair is hard (in the worst-case<sup>2</sup>). One might hope for an <em>average-case</em> hardness for the Harlow-Hayden decoding task and thus infer that <em>most</em> black holes are difficult to distill. However, even if such average-case hardness results existed, physicists would still remain dissatisfied! The foremost grievance a physicist may have is the lack of a coherent causal framework to model reality. That is, what happens if, in the<br />
very small but non-zero chance, a black hole is easy to distill? Does that mean that a firewall exists in such black hole? How can a unifying theory explain such situation coherently? An ideal theory for theoretical physicists should work for <em>every</em> black hole instead of for <em>most</em> black holes! Second, physicists seem to dislike the abstract, process-theoretic approach undertaken by computer scientists. Here, we have completely ignored talking about the internal dynamics of a black hole or even a full description of its evolving Hilbert space. They would, for instance, like to see a <em>differential equation</em> that captures the difficulty of distilling a black hole throughout its evolution. Resolutions to the firewall paradox or effort towards building a theory of quantum gravity should be somewhat <em>explicit</em> in the sense that one can really instantiate some (toy) examples from the theory and see how the system evolves and examine whether this fits the real experience from the world. In other words, a theory with a black box (<em>i.e.,</em> a complexity conjecture) might not be regarded as a resolution.</p>
<h3>Homework</h3>
<ol>
<li>What powers would Alice need to ensure that she can efficiently distill the B-R bell pair. What if we assume <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP+%3D+PSPACE%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P = PSPACE}" class="latex" title="\mathbf{P = PSPACE}" />?</li>
<li>Can we show that the decoding is hard on average, rather than for the worst case?</li>
<li>What are some similar deep connections between black holes and complexity theory?</li>
<li>For people interested in the quantum complexity theory, there are many open problems regarding the quantum circuit complexity: consider the <em>unitary synthesis problem</em><sup>3</sup> proposed by Scott Aaronson [Aar16].</li>
<li>Another interesting problem is connecting the difficulty of proving quantum circuit lower bounds to other complexity problem such as classical circuit lower bounds or cryptographic assumptions.</li>
</ol>
<h2>Footnotes</h2>
<p><sup>1</sup>Non-trivial here means the unitary matrix <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> is explicit in the sense that given <img src="https://s0.wp.com/latex.php?latex=i%2Cj%5Cin%5B2%5En%5D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i,j\in[2^n]]" class="latex" title="i,j\in[2^n]]" />, one can efficiently compute <img src="https://s0.wp.com/latex.php?latex=U_%7Bij%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U_{ij}" class="latex" title="U_{ij}" />.<br />
<sup>2</sup>Hard in worst-case means that there does not exist efficient algorithm that works on <em>every</em> input. Another hardness notion is hard on <em>average</em>, by which we mean there does not exist efficient algorithm the works for <em>most</em> of the input. Showing average-case hardness is in general a more difficult task than proving worst-case hardness.<br />
<sup>3</sup>Does the following hold: for any unitary matrix <img src="https://s0.wp.com/latex.php?latex=U%5Cin%5Cmathbb%7BC%7D%5E%7B2%5En%5Ctimes2%5En%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U\in\mathbb{C}^{2^n\times2^n}" class="latex" title="U\in\mathbb{C}^{2^n\times2^n}" />, there exists a classical oracle <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> such that <img src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29%3Dn%5E%7BO%281%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C^A(U)=n^{O(1)}" class="latex" title="C^A(U)=n^{O(1)}" /> where <img src="https://s0.wp.com/latex.php?latex=C%5EA%28U%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C^A(U)" class="latex" title="C^A(U)" /> is the minimum size of quantum circuit that approximates <img src="https://s0.wp.com/latex.php?latex=U&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U" class="latex" title="U" /> with oracle access to <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />.</p>
<h2>References</h2>
<div>[Aar16] Scott Aaronson. The complexity of quantum states and transformations: from quantum money to black holes. <em>arXiv preprint arXiv:1607.05256</em>, 2016.</div>
<div></div>
<div>[HH13] Daniel Harlow and Patrick Hayden. Quantum computation vs. firewalls.</div>
<div><em>Journal of High Energy Physics</em>, 2013(6):85, 2013.</div>
<div></div>
<div>[NC02] Michael A Nielsen and Isaac Chuang. Quantum computation and quantum information, 2002.</div></div>







<p class="date">
by Chi-Ning Chou <a href="https://windowsontheory.org/2019/02/01/black-holes-a-complexity-theory-perspective/"><span class="datestr">at February 01, 2019 05:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/01/31/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/01/31/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>As usual, follow <a href="https://mathstodon.xyz/@11011110">me</a> on <a href="https://mathstodon.xyz">Mathstodon</a> to see these as I post them rather than two weeks later.</p>

<ul>
  <li>
    <p><a href="https://montrealgazette.com/news/organizers-fear-visa-issues-may-push-ai-conferences-to-avoid-canada">Half of the 200 people who needed visas to attend one of the satellite workshops of NeurIPS 2018 in Montreal were unable to get them in time</a> (<a href="https://mathstodon.xyz/@11011110/101429260698057077"></a>, <a href="https://www.wired.com/story/canada-welcome">see also</a>), making it more likely that future conferences depending on international attendance will avoid Canada.</p>
  </li>
  <li>
    <p>This is not a cinnamon bun (<a href="https://mathstodon.xyz/@11011110/101438594980314031"></a>). It’s actually a 160 million year old fossil snail shell from Madagascar, roughly the size of a large fist (or cinnamon bun). I don’t think it’s particularly rare or valuable; I picked it up because I liked its shape.</p>

    <p style="text-align: center;"><img src="https://www.ics.uci.edu/~eppstein/pix/gastropod/gastropod-m.jpg" alt="Fossil gastropod" style="border-style: solid; border-color: black;" /></p>
  </li>
  <li>
    <p><a href="https://www.ics.uci.edu/~nmamano/knightstour.html">Web site for generating knight’s tours of oversized chessboards with approximately-minimum numbers of bends and crossings</a> (<a href="https://mathstodon.xyz/@11011110/101445919833908876"></a>). For background on how it works, see the short paper by Besa, Johnson, Mamano, and Osegueda (all UCI students) in <a href="https://doi.org/10.1007/978-3-030-04414-5"><em>Graph Drawing 2018</em></a> pp. 661–663 – unfortunately I don’t know of a non-paywalled link.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Besse_Day">Besse Beulah Day</a> (<a href="https://mathstodon.xyz/@11011110/101451632049375948"></a>), in the 1940s, was one of the first to apply the design of experiments to engineering, after previously having learned to use the technique in forestry. Jacqueline Telford wrote about her briefly in <a href="https://www.jhuapl.edu/techdigest/TD/td2703/telford.pdf">a 2007 survey</a>. Searching for the phrase “Besse Day, working at” finds that Telford’s account of Day’s work has been plagiarized by at least six other works. It’s a form of fame, I guess, to be copied so much.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/how-one-german-city-developed-and-then-lost-generations-of-math-geniuses-106750">The slow rise and rapid fall of Göttingen as the world capital of mathematics</a> (<a href="https://mathstodon.xyz/@11011110/101457036274744941"></a>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/carolina-araujo-is-building-a-network-of-women-in-mathematics-20190122/">An interview with Brazilian mathematician Carolina Araujo</a> (<a href="https://mathstodon.xyz/@11011110/101464602401203371"></a>) on the gender gap in mathematics and what still needs to be done to close it.</p>
  </li>
  <li>
    <p><a href="https://doi.org/10.1038/s42256-018-0002-3">If you sample enough times from an unknown distribution over an unknown finite subset of , can you (with high probability) produce a finite set of measure at least ?</a> (<a href="https://mathstodon.xyz/@11011110/101470101768702252"></a>, <a href="https://twitter.com/johncarlosbaez/status/1083055024119308288">via</a>, <a href="https://www.metafilter.com/178941/Learnability-can-be-undecidable">via2</a>). Your set does not need to consist only of the points you’ve sampled! You can do it if   for finite  but not otherwise.</p>
  </li>
  <li>
    <p><a href="https://agtb.wordpress.com/2019/01/22/guest-post-like-a-swarm-of-locusts-vijay-vazirani/">Vijay Vazirani on the flocking behavior of theoretical computer scientists</a> (<a href="https://mathstodon.xyz/@11011110/101472666044751626"></a>). Vijay’s post also includes an announcement for a semester-long <a href="https://simons.berkeley.edu/programs/market2019">program on online and matching-based market design</a> at the Simons Institute in Berkeley.</p>
  </li>
  <li>
    <p>The view from my desk (<a href="https://mathstodon.xyz/@11011110/101478744747251421"></a>). Actually my office has lots of windows with a nice view of a well-used plaza, outdoor coffee shop, trees, and distant mountains. But to see that, I have to get up and go over to one of the windows. If I stay at my desk and look up at the window, I see this interesting geometric pattern instead.</p>

    <p style="text-align: center;"><img src="https://www.ics.uci.edu/~eppstein/pix/deskview/deskview-m.jpg" alt="UC Irvine's CalIT2 building from Donald Bren Hall, room 4082" style="border-style: solid; border-color: black;" /></p>
  </li>
  <li>
    <p><a href="https://scholar.social/@GerardWestendorp/101478161346333486">Gerard Westendorp made a snowdecahedron</a> but <a href="https://scholar.social/@GerardWestendorp/101483814063002454">global warming melted it</a>.</p>
  </li>
  <li>
    <p><a href="http://homepages.gac.edu/~jsiehler/games/blocks-start.html">Online sliding block puzzles</a> (<a href="https://mathstodon.xyz/@jsiehler/101472426764291238"></a>) by
Jacob Siehler. The goal is to swap the positions of two colored blocks. Even the easy ones are non-obvious.</p>
  </li>
  <li>
    <p>Cute proof of <a href="https://en.wikipedia.org/wiki/Sperner%27s_theorem">Sperner’s theorem</a> (<a href="https://mathstodon.xyz/@11011110/101495343260074941"></a>) from a talk by R. P. Stanley: represent subsets of  by strings of<br />
 parentheses, “)” in position  if  is in the set, “(” otherwise. In each string, flip the first unmatched “(”, grouping the subsets into chains like (()(( – )()(( – )())( – )())). Each chain touches the middle level once, and any other antichain at most once, so the middle level is the biggest antichain.</p>
  </li>
  <li>
    <p>Two triangles in a convex point set can cross or overlap in eight configurations, colorfully named the taco, mariposa, bat, nested, crossing, ears, swords, and david by “<a href="https://www.combinatorics.org/ojs/index.php/eljc/article/view/v26i1p8">More Turán-Type Theorems for Triangles in Convex Point Sets</a>”, a new paper in <em>Elect. J. Comb.</em> by Aronov, Dujmović, Morin, Ooms, and Schultz (<a href="https://mathstodon.xyz/@11011110/101507914773539844"></a>). For 246 of the 256 subsets of configurations, they find near-max families of triangles avoiding the subset. The remaining 8 subsets are equivalent to “tripod packing”, which is less well-understood but the subject of another newly published paper, “<a href="https://doi.org/10.1007/s00454-018-0012-2">New Results on Tripod Packings</a>” (<em>Discrete Comput. Geom.</em>, by Östergård and Pöllänen). The tripod problem has a complicated history of independent rediscovery, not all of which was known to Östergård and Pöllänen, so see the <em>EJC</em> paper for a more thorough survey.</p>
  </li>
  <li>
    <p><a href="https://mathvis.academic.wlu.edu/2017/07/13/creating-a-3d-printable-lorenz-attractor/">Creating a 3D-printable Lorenz attractor</a> (<a href="https://mathstodon.xyz/@11011110/101514403573957983"></a>). From Elizabeth Denne’s <a href="https://mathvis.academic.wlu.edu">“Visions in Math” blog</a> which, sadly, seems to have gone on hiatus after publishing this in 2017.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/01/31/linkage.html"><span class="datestr">at January 31, 2019 09:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5538403199779655367">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html">Phish Before Turkey</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The Chronicle of Higher Education recently published a story <a href="https://www.chronicle.com/article/Phishing-Scheme-Targets/245535">Phishing Scheme Targets Professors’ Desire to Please Their Deans — All for $500 in Gift Cards</a>. The same thing happened to me last fall.<br />
<br />
Twas the day before Thanksgiving and an email went out to most of the faculty in my department.<br />
<blockquote class="tr_bq">
<b>From: </b>Lance Fortnow &lt;lancefortnow@yahoo.com&gt;<br />
<b>Sent: </b>Wednesday, November 21, 2018 1:45 PM<br />
<b>To: </b>[name deleted]<br />
<b>Subject:</b> </blockquote>
<blockquote class="tr_bq">
Hello,are you available?</blockquote>
At the time I was in New Jersey visiting family. lancefortnow@yahoo.com is not my email. I do own fortnow@yahoo.com but don't email there, I rarely check it.<br />
<br />
Some faculty checked with me to see if this is real. One faculty called me to see what I wanted. Once I found out what was happening I sent a message to my entire faculty to ignore those emails.<br />
<br />
Some faculty did reply to see what I want. The response:<br />
<blockquote class="tr_bq">
i need you to help me get an Amazon gifts card from the store,i will reimburse you back when i get to the office.</blockquote>
One of our security faculty decided to follow up and replied "Sure! Let me get them for you. Could you provide more more information? e.g., amount and #cards. I can bring them on Monday." The reply:<br />
<blockquote class="tr_bq">
The amount i want is $100 each in two (2) piece so that will make it a total of $200 l'll be reimbursing back to you.i need physical cards which you are going to get from the store. When you get them,just scratch it and take a picture of them and attach it to the email then send it to me here ok</blockquote>
<div>
He went a few more rounds before the phisher just stopped responding.</div>
<div>
<br /></div>
<div>
A week later, a different faculty member came to my office and said I wanted to see him but he's been out of town. I said it was nice to see him but I didn't ask to talk to him and we figured out the confusion was the phishing email.</div>
<div>
<br /></div>
<div>
Someone went through the trouble of creating a fake email address in my name, looking up the email addresses of the faculty in the department and individually emailing each of them, without realizing computer science professors won't fall for a gift card phishing attack. Or at least none of them admitted falling for it.</div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/01/phish-before-turkey.html"><span class="datestr">at January 31, 2019 04:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/013">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/013">TR19-013 |  CSPs with Global Modular Constraints: Algorithms and Hardness via Polynomial Representations | 

	Joshua Brakensiek, 

	Sivakanth Gopi, 

	Venkatesan Guruswami</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the complexity of Boolean constraint satisfaction problems (CSPs) when the assignment must have Hamming weight in some congruence class modulo $M$, for various choices of the modulus $M$. Due to the known classification of tractable Boolean CSPs, this mainly reduces to the study of three cases: 2SAT, HornSAT, and LIN-MOD2 (linear equations mod $2$). We classify the moduli $M$ for which these respective problems are polynomial time solvable, and when they are not (assuming the ETH). Our study reveals that this modular constraint lends a surprising richness to these classic, well-studied problems, with interesting broader connections to complexity theory and coding theory. The HornSAT case is connected to the covering complexity of polynomials representing the NAND function mod $M$. The LIN-MOD2 case is tied to the sparsity of polynomials representing the OR function mod $M$, which in turn has connections to modular weight distribution properties of linear codes and locally decodable codes. In both cases, the analysis of our algorithm as well as the hardness reduction rely on these polynomial representations, highlighting an interesting algebraic common ground between hard cases for our algorithms and the gadgets which show hardness. These new complexity measures of polynomial representations merit further study.

The inspiration for our study comes from a recent work by Nägele, Sudakov, and Zenklusen on submodular minimization with a global congruence constraint. Our algorithm for HornSAT has strong similarities to their algorithm, and in particular identical kind of set systems arise in both cases. Our connection to polynomial representations leads to a simpler analysis of such set systems, and also sheds light on (but does not resolve) the complexity of submodular minimization with a congruency requirement modulo a composite $M$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/013"><span class="datestr">at January 31, 2019 03:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7426">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/01/30/black-hole-paradoxes-a-conservative-yet-radical-journey/">Black hole paradoxes: A conservative yet radical journey</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Guest post by Abhishek Anand and Noah Miller from <a href="https://www.boazbarak.org/fall18seminar/">the physics and computation seminar</a>.</p>



<p>In 2013, Harlow and Hayden drew an unexpected connection between theoretical computer science and theoretical physics as they proposed a potential resolution to the famous black hole Firewall paradox using computational complexity arguments. This blog post attempts to lay out the Firewall paradox and other peculiar (at first) properties associated with black holes that make them such intriguing objects to study. This post is inspired by Scott Aaronson’s [1] and Daniel Harlow’s [2] excellent notes on the same topic. The notes accompanying <a href="https://windowsontheory.org/2019/01/20/the-firewall-paradox-in-context/">this post</a> provides a thorough and self-contained introduction to theoretical physics from a CS perspective. Furthermore, for a quick and intuitive summary of the Firewall paradox and it’s link to computational complexity, refer to <a href="https://windowsontheory.org/2018/08/22/black-holes-paradoxes-and-computational-complexity/">this</a> blog post by Professor Barak last summer.</p>



<h2>Black holes and conservative radicalism</h2>



<p>Black holes are fascinating objects. Very briefly, they are regions of spacetime where the matter-energy density is so high and hence, where the gravitational effects are so strong that no particle (not even light!) can escape from it. More specifically, we define a particular distance called the “Schwarzschild radius” and anything that enters within the Schwarzschild radius, (also known as the “event horizon,”) cannot ever escape from the black hole. General relativity predicts that this particle is bound to hit the “singularity,” where spacetime curvature becomes infinite. In the truest sense of the word, they represent the “edge cases” of our Universe. Hence, perhaps, it is fitting that physicists believe that through thought experiments at these edges cases, they can investigate the true behavior of the laws that govern our Universe.</p>



<p>Once you know that such an object exists, many questions arise: what would it look it from the outside? Could we already be within the event horizon of a future black hole? How much information does it store? Would something special be happening at the Schwarzschild radius? How would the singularity manifest physically?</p>



<p>The journey of trying to answer these questions can aptly be described by the term “radical conservatism.” This is a phrase that has become quite popular in the physics community. A “radical conservative” would be someone that tries to modify as few laws of physics as possible (that’s the conservative part) and through their dogmatic refusal to modify these laws and go wherever their reasoning leads (that’s the radical part) is able to derive amazing things. We radically use the given system of beliefs to lead to certain conclusions (sometimes paradoxes!) and then conservatively update the system of beliefs to resolve the created paradox and iterate. We shall go through a few such cycles and end at the Firewall paradox. Let’s begin with the first problem: how much information does a black hole store?</p>



<h2>Entropy of a black hole</h2>



<p>A black hole is a physical object. Hence, it could be able to store some information. But how much? In other words, what should the entropy of a black hole be? There are two simple ways of looking at this problem:</p>



<ul><li><strong>0:</strong> The no-hair theorem postulates that an outside observer can measure a small number of quantities which completely characterize the black hole. There’s the mass of the black hole, which is its most important quantity. Interestingly, if the star was spinning before it collapsed, the black hole will also have some angular momentum, and its equator will bulge out a bit. Hence, the black hole is also characterized by an angular momentum vector. Also, if the object had some net charge, the black hole would also have that net charge. This means that if two black holes were created due to a book and a pizza, respectively, with the same mass, charge and angular momentum, there would settle down to the “same” black hole with no observable difference. If an outside observer knows these quantities, they will now know everything about the black hole. So, in this view, we should expect for the entropy of a black hole to be 0.</li><li><strong>Unbounded:</strong> But maybe that’s not entirely fair. After all, the contents of the star should somehow be contained in the singularity, hidden behind the horizon. As we saw above, all of the specific details of the star from before the collapse do not have any effect on the properties of the resulting black hole. The only stuff that matters it the total mass, total angular momentum, and the total charge. That leaves an infinite number of possible objects that could all have produced the same black hole: a pizza or a book or a PlayStation and so on. So actually, perhaps, we should expect the entropy of a black hole to be unbounded.</li></ul>



<p>The first answer troubled Jacob Bekenstein. He was a firm believer in the Second Law of Thermodynamics: the total entropy of an isolated system can never decrease over time. However, if the entropy of a black hole is 0, it provides with a way to reduce the entropy of any system: just dump objects with non-zero entropy into the black hole. </p>



<p>Bekenstein drew connections between the area of the black hole and its entropy. For example, the way in which a black hole’s area could only increase (according to classical general relativity) seemed reminiscent of entropy. Moreover, when two black holes merge, the area of the final black hole will always exceed the sum of the areas of the two original black holes This is surprising as for two spheres, the area/radius of the merged sphere, is always less than the sum of the areas/radii of two individual spheres: </p>



<p><img src="https://s0.wp.com/latex.php?latex=%28r_1%5E3+%2B+r_2%5E3%29%5E%7B%5Cfrac%7B1%7D%7B3%7D%7D+%3C+r_1+%2B+r_2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(r_1^3 + r_2^3)^{\frac{1}{3}} &lt; r_1 + r_2" class="latex" title="(r_1^3 + r_2^3)^{\frac{1}{3}} &lt; r_1 + r_2" /></p>



<p> Most things we’re used to, like a box of gas, have an entropy that scales linearly with its volume. However, black holes are not like most things. He predicted that entropy of a black hole should be proportional to its area, A and not its volume. We now believe that Bekenstein was right and it turns out that the entropy of the black hole can be written as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=S%3D%5Cfrac%7BkA%7D%7B4l%5E2_p%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S=\frac{kA}{4l^2_p}" class="latex" title="S=\frac{kA}{4l^2_p}" /></p>



<p>where <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is Boltzmann constant and <img src="https://s0.wp.com/latex.php?latex=l_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="l_p" class="latex" title="l_p" /> is the Planck-length, a length scale where physicists believe quantum mechanics breaks down and a quantum theory of gravity will be required. Interestingly, it seems as though the entropy of the black hole is (one-fourth times) the number of Planck-length-sized squares it would take to tile the horizon area. (Perhaps, the microstates of the black hole are “stored” on the horizon?) Using “natural units” where we set all constants to 1, we can write this as<br /> </p>



<p><img src="https://s0.wp.com/latex.php?latex=S%3D%5Cfrac%7BA%7D%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S=\frac{A}{4}" class="latex" title="S=\frac{A}{4}" /></p>



<p>which is very pretty. Even though this number of not infinite, it is very large. Here are some numerical estimates from [2]. The entropy of the universe (minus all the black holes) mostly comes from cosmic microwave background radiation and is about <img src="https://s0.wp.com/latex.php?latex=10%5E%7B87%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="10^{87}" class="latex" title="10^{87}" /> in some units. Meanwhile, in the same units, the entropy of a solar mass black hole is <img src="https://s0.wp.com/latex.php?latex=10%5E%7B78%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="10^{78}" class="latex" title="10^{78}" />. The entropy of our sun, as it is now, is a much smaller <img src="https://s0.wp.com/latex.php?latex=10%5E%7B60%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="10^{60}" class="latex" title="10^{60}" />. The entropy of the supermassive black hole in the center of our galaxy is <img src="https://s0.wp.com/latex.php?latex=10%5E%7B88%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="10^{88}" class="latex" title="10^{88}" />, <strong>larger than the rest of the universe combined </strong>(minus black holes). The entropy of any of the largest known supermassive black holes would be <img src="https://s0.wp.com/latex.php?latex=10%5E%7B96%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="10^{96}" class="latex" title="10^{96}" />. Hence, there is a simple “argument” which suggests that black holes are the most efficient information storage devices in the universe: if you wanted to store a lot of information in a region smaller than a black hole horizon, it would probably have to be so dense that it would just be a black hole anyway.</p>



<p>However, this resolution to “maintain” the second law of thermodynamics leads to a radical conclusion: if a black hole has non-zero entropy, it must have a non-zero temperature and hence, must emit thermal radiation. This troubled Hawking.</p>



<h2>Hawking radiation and black hole evaporation</h2>



<p>Hawking did a semi-classical computation looking at energy fluctuations near the horizon and actually found that black holes do radiate! They emit energy in the form of very low-energy particles. This is a unique feature of what happens to black holes when you take quantum field theory into account and is very surprising. However, the Hawking radiation from any actually existing black hole is far too weak to have been detected experimentally.</p>



<p>One simplified way to understand the Hawking radiation is by thinking about highly coupled modes (think “particles”) being formed continuously near the horizon. As this formation must conserve the conservation of energy, one of these particles has negative energy and one of the particles has the same energy but with a positive sign and hence, they are maximally entangled (if you know the energy of one of the particles, you know the energy of the other one): we will be referring to this as short-range entanglement. The one with negative energy falls into the black hole while the one with positive energy comes out as Hawking radiation. The maximally-entangled state of the modes looks like:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Csum_%7B%5Cmathbf%7Bk%7D%7D+f%28%5Cmathbf%7Bk%7D%29+%7C%5Cmathbf%7Bk%7D%5Crangle_%7B%5Crm+in%7D+%7C%5Cmathbf%7Bk%7D%5Crangle_%7B%5Crm+out%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\sum_{\mathbf{k}} f(\mathbf{k}) |\mathbf{k}\rangle_{\rm in} |\mathbf{k}\rangle_{\rm out} " class="latex" title="\sum_{\mathbf{k}} f(\mathbf{k}) |\mathbf{k}\rangle_{\rm in} |\mathbf{k}\rangle_{\rm out} " /></p>



<p>Here is a cartoon that represents the process:</p>



<ul class="wp-block-gallery columns-1 is-cropped"><li class="blocks-gallery-item"><figure><img src="https://windowsontheory.files.wordpress.com/2019/01/partnermode2.png?w=600" alt="" class="wp-image-7431" />A cartoon of the Hawking partner modes. The shaded region shows the width of the Gaussian wavepackets. The outgoing mode redshifts and spreads.</figure></li></ul>



<p>Because energetic particles are leaving the black hole and negative energy particles are adding to it, the black hole itself will actually shrink, which would never happen classically! And, eventually a black-hole will disappear. In fact, the time of evaporation of the black hole scales polynomially in the radius of the black hole, as <img src="https://s0.wp.com/latex.php?latex=R%5E3&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="R^3" class="latex" title="R^3" />. The black holes that we know about are simply too big and would be shrinking too slowly. A stellar-mass black hole would take <img src="https://s0.wp.com/latex.php?latex=10%5E%7B67%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="10^{67}" class="latex" title="10^{67}" /> years to disappear from Hawking radiation.</p>



<p>However, the fact that black holes disappear does not play nicely with another core belief in physics: reversibility.</p>



<h2>Unitary evolution and thermal radiation</h2>



<p>A core tenet of quantum mechanics is <em>unitary evolution</em>: every operation that happens to a quantum state must be reversible (invertible). That is: if we know the final state and the set and order of operations performed, we should be able to invert the operations and get back the initial state. No information is lost. However, something weird happens with an evaporating black hole. First, let us quickly review pure and mixed quantum states. A <em>pure state</em> is a quantum state that can be described by a single ket vector while a mixed state represents a classical (probabilistic) mixture of pure states and can be expressed using density matrices. For example, in both, the pure state <img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Clangle+%3D+%7C1%5Crangle+%2B+%7C0%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\langle = |1\rangle + |0\rangle" class="latex" title="|\psi\langle = |1\rangle + |0\rangle" /> and mixed state <img src="https://s0.wp.com/latex.php?latex=%5Crho+%3D+%7C1%5Crangle%5Clangle1%7C+%2B++%7C0%5Crangle%5Clangle0%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho = |1\rangle\langle1| +  |0\rangle\langle0|" class="latex" title="\rho = |1\rangle\langle1| +  |0\rangle\langle0|" /> would one measure <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> half the time and <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> 50% half the time. However, in the later one would not observe any quantum effects (think interference patterns of the double-slit experiment).</p>



<p>People outside of the black hole will not be able to measure the objects (quantum degrees of freedom) that are inside the black hole. They will only be able to perform measurements on a subset of the information: the one available outside of the event horizon. So, the state they would measure would be a mixed state. A simple example to explain what this means is that if the state of the particles near the horizon is:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle_%7Binit%7D+%3D+%5Cfrac%7B%7C0%5Crangle_A%7C0%5Crangle_B+%2B%7C1%5Crangle_A%7C1%5Crangle_B%7D+%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle_{init} = \frac{|0\rangle_A|0\rangle_B +|1\rangle_A|1\rangle_B} {\sqrt{2}}" class="latex" title="|\Psi\rangle_{init} = \frac{|0\rangle_A|0\rangle_B +|1\rangle_A|1\rangle_B} {\sqrt{2}}" /></p>



<p>tracing over the qubit A leaves us with the state and density matrix:</p>



<p><br /> <img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle_%7Bobs%7D+%3D+%5Cfrac%7B%7C0%5Crangle_%7BB%7D%5Clangle0%7C+%2B+%7C1%5Crangle_%7BB%7D%5Clangle1%7C%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle_{obs} = \frac{|0\rangle_{B}\langle0| + |1\rangle_{B}\langle1|}{2}" class="latex" title="|\Psi\rangle_{obs} = \frac{|0\rangle_{B}\langle0| + |1\rangle_{B}\langle1|}{2}" />,</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D+%5Cfrac%7B1%7D%7B2%7D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%5C%5C+0+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{obs} = \frac{1}{2} \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}" class="latex" title="\rho_{obs} = \frac{1}{2} \begin{pmatrix} 1 &amp; 0 \\ 0 &amp; 1 \end{pmatrix}" /></p>



<p>which is a classical mixed state (50% of times results in 1 and 50% of times results in 0). The non-diagonal entries of the density matrix encode the “quantum inference” of the quantum state. Here, are they are, in some sense we have lost the “quantum” aspect of the information.</p>



<p>In fact, Hawking went and traced over the field degrees of freedom that were hidden behind the event horizon, and found something surprising: the mixed state was thermal! It acted “as if” it is being emitted by some object with temperature “T” which does not depend on what formed the black hole and solely depends on the mass of the black hole. Now, we have the information paradox:</p>



<ul><li><strong>Physics perspective</strong>: Now, once the black hole evaporates, we are left with this mixed thermal there is no way to precisely reconstruct the initial state that formed the black hole: the black hole has taken away information! Once the black hole is gone, the information of what went into the black hole is gone for good. Nobody living in the post-black-hole universe could figure out exactly what went into the black hole, even if they had full knowledge of the radiation. Another way to derive a contradiction is that the process of black hole evaporation when combined with the disappearance of the black hole, imply that a pure state has evolved into a mixed state, something which is impossible via unitary time evolution! Pure states only become mixed states whenever we decide to perform a partial trace; they never become mixed because of Schrodinger’s equation which governs the evolution of quantum states.</li><li><strong>CS perspective: </strong>We live in a world where only invertible functions are allowed. However, we are given this exotic function – the black hole – which seems to be a genuine random one-to-many function. There is no way to determine the input deterministically given the output of the function.</li></ul>



<p>What gives? If the process of black hole evaporation is truly “non-unitary,” it would be a first for physics. We have no way to make sense of quantum mechanics without the assumption of unitary operations and reversibility; hence, it does not seem very conservative to get ride of it. </p>



<p>Physicists don’t know exactly how information is conserved, but they think that if they assume that it does, it will help them figure out something about quantum gravity. Most physicists believe that the process of black hole evaporation should indeed be unitary. The information of what went into the black hole is being released via the radiation in way too subtle for us to currently understand. What does this mean?</p>



<ul><li><strong>Physics perspective</strong>: Somehow, after the black hole is gone, the final state we observe, after tracing over the degrees of freedom taken away by the black hole, is pure and encodes all information about what went inside the black hole. That is: <img src="https://s0.wp.com/latex.php?latex=Tr_%7Binside%7D+%28%7C%5CPsi%5Crangle_%7Binit%7D%5Clangle%5CPsi%7C%29+%3D+pure&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Tr_{inside} (|\Psi\rangle_{init}\langle\Psi|) = pure" class="latex" title="Tr_{inside} (|\Psi\rangle_{init}\langle\Psi|) = pure" /></li><li><strong>CS perspective</strong>: Somehow, the exotic black hole function seems random but actually is pseudo-random as well as injective and given the output and enough time, we can decode it and determine the input (think hash functions!).</li></ul>



<p>However, this causes yet another unwanted consequence: the violation of the no-cloning theorem!</p>



<h2>Xeroxing problem and black hole complementarity</h2>



<p>The no-cloning theorem simply states that an arbitrary quantum state cannot be copied. In other words, if you have one qubit representing some initial state, no matter what operations you do, you cannot end up with two qubits with the same state you started with. How do our assumptions violate this?</p>



<p>Say you are outside the black hole and send in a qubit with some information (input to the function). You collect the radiation corresponding to the qubit (output of the function) that came out. Now you decode this radiation (output) to determine the state of infalling matter (input). Aha! You have violated the no-cloning theorem as you have two copies of the same state: one inside and one outside the black hole.</p>



<p>So wait, again, what gives?</p>



<p>One possible resolution is to postulate that the inside of the black hole just does not exist. However, that doesn’t seem very conservative. According to Einstein’s theory of relativity, locally speaking, there is nothing particularly special about the horizon: hence, one should be able to cross the horizon and move towards the singularity peacefully.</p>



<p>The crucial observation is that for the person who jumped into the black hole, the outside universe may as well not exist; they can not escape. Extending this further, perhaps, somebody on the outside does not believe the interior of the black hole exists and somebody on the inside does not believe the exterior exists and they are both right. This hypothesis, formulated in the early 1990s, has been given the name of <em>Black Hole Complementarity.</em> The word “complementarity” comes from the fact that two observers give different yet complementary views of the world.</p>



<p>In this view, according to someone on the outside, instead of entering the black hole at some finite time, the infalling observer will instead be stopped at some region very close to the horizon, which is quite hot when you get up close. Then, the Hawking radiation coming off of the horizon will hit the observer on its way out, carrying the information about them which has been plastered on the horizon. So the outside observer, who is free to collect this radiation, should be able to reconstruct all the information about the person who went in. Of course, that person will have burned up near the horizon and will be dead.</p>



<p>And from the infalling observer’s perspective, however, they were able to pass peacefully through the black hole and sail on to the singularity. So from their perspective, they live, while from the outside it looks like they died. However, no contradiction can be reached, because nobody has access to both realities.</p>



<p>But why is that? Couldn’t the outside observer see the infalling observer die and then rocket themselves straight into the black hole themselves to meet the alive person once again before they hit the singularity, thus producing a contradiction?</p>



<p>The core idea is that it must take some time for the infalling observer to “thermalize” (equilibriate) on the horizon: enough time for the infalling observer to reach the singularity and hence become completely inaccessible. Calculations do show this to be true. In fact, we can already sense a taste of complexity theory even in this argument: we are assuming that some process is slower than some other process.</p>



<p>In summary, according to the BHC worldview, the information outside the horizon is redundant with the information inside the horizon.</p>



<p>But, in 2012, a new paradox, the Firewall paradox, was introduced by AMPS [3]. This paradox seems to be immune to BHC: the paradox exists even if we assume everything we have discussed till now. The physics principle we violate, in this case, is the monogamy of entanglement.</p>



<h2>Monogamy of entanglement and Page time</h2>



<p>Before we state the Firewall paradox, we must introduce two key concepts.</p>



<h3>Monogamy of entanglement</h3>



<p>Monogamy of entanglement is a statement about the maximum entanglement a particle can share with other particles. More precisely, if two particles A and B are maximally entangled with each other, they cannot be at all entanglement with a third particle C. Two maximally entangled particles have saturated both of their “entanglement quotas\”. In order for them to have correlations with other particles, they must decrease their entanglement with each other.</p>



<p>Monogamy of entanglement can be understood as a static version of the no-cloning theorem. Here is a short proof sketch of why polygamy of entanglement implies the violation of no-cloning theorem.</p>



<p>Let’s take a short detour to explain quantum teleportation:</p>



<p>Say you have three particles A, B, and C with A and B maximally entangled (Bell pair), and C is an arbitrary quantum state:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%7C%5CPhi%5E%2B%5Crangle_%7BAB%7D+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D+%28%7C0%5Crangle_A+%5Cotimes+%7C0%5Crangle_%7BB%7D+%2B+%7C1%5Crangle_A+%5Cotimes+%7C1%5Crangle_%7BB%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Phi^+\rangle_{AB} = \frac{1}{\sqrt{2}} (|0\rangle_A \otimes |0\rangle_{B} + |1\rangle_A \otimes |1\rangle_{B})" class="latex" title="|\Phi^+\rangle_{AB} = \frac{1}{\sqrt{2}} (|0\rangle_A \otimes |0\rangle_{B} + |1\rangle_A \otimes |1\rangle_{B})" /></p>



<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi%5Crangle_C+%3D+%5Calpha+%7C0%5Crangle_C+%2B+%5Cbeta%7C1%5Crangle_C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi\rangle_C = \alpha |0\rangle_C + \beta|1\rangle_C" class="latex" title="|\psi\rangle_C = \alpha |0\rangle_C + \beta|1\rangle_C" /></p>



<p>We can write their total state as:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi+%5Crangle_%7BC%7D%5Cotimes+%7C%5CPhi+%5E%7B%2B%7D%5Crangle_%7BAB%7D%3D%28%5Calpha+%7C0%5Crangle_%7BC%7D%2B%5Cbeta+%7C1%5Crangle_%7BC%7D%29%5Cotimes+%7B%5Cfrac+%7B1%7D%7B%5Csqrt+%7B2%7D%7D%7D%28%7C0%5Crangle_%7BA%7D%5Cotimes+%7C0%5Crangle_%7BB%7D%2B%7C1%5Crangle_%7BA%7D%5Cotimes+%7C1%5Crangle_%7BB%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi \rangle_{C}\otimes |\Phi ^{+}\rangle_{AB}=(\alpha |0\rangle_{C}+\beta |1\rangle_{C})\otimes {\frac {1}{\sqrt {2}}}(|0\rangle_{A}\otimes |0\rangle_{B}+|1\rangle_{A}\otimes |1\rangle_{B})" class="latex" title="|\psi \rangle_{C}\otimes |\Phi ^{+}\rangle_{AB}=(\alpha |0\rangle_{C}+\beta |1\rangle_{C})\otimes {\frac {1}{\sqrt {2}}}(|0\rangle_{A}\otimes |0\rangle_{B}+|1\rangle_{A}\otimes |1\rangle_{B})" /></p>



<p>Re-arranging and pairing A and C, the state simplifies to:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%7C%5Cpsi+%5Crangle+%7BC%7D%5Cotimes+%5C+%7C%5CPhi+%5E%7B%2B%7D%5Crangle+%7BAB%7D%5C+%3D+%5Cfrac+%7B1%7D%7B2%7D%7B%5CBig+%5Clbrack+%7D%5C+%7C%5CPhi+%5E%7B%2B%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Calpha+%7C0%5Crangle+%7BB%7D%2B%5Cbeta+%7C1%5Crangle+%7BB%7D%29%5C+%2B%5C+%7C%5CPhi+%5E%7B-%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Calpha+%7C0%5Crangle+%7BB%7D-%5Cbeta+%7C1%5Crangle+%7BB%7D%29%5C+%2B%5C+%7C%5CPsi+%5E%7B%2B%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Cbeta+%7C0%5Crangle+%7BB%7D%2B%5Calpha+%7C1%5Crangle+%7BB%7D%29%5C+%2B%5C+%7C%5CPsi+%5E%7B-%7D%5Crangle+%7BAC%7D%5Cotimes+%28%5Cbeta+%7C0%5Crangle+%7BB%7D-%5Calpha+%7C1%5Crangle+%7BB%7D%29%7B%5CBig+%5Crbrack+%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\psi \rangle {C}\otimes \ |\Phi ^{+}\rangle {AB}\ = \frac {1}{2}{\Big \lbrack }\ |\Phi ^{+}\rangle {AC}\otimes (\alpha |0\rangle {B}+\beta |1\rangle {B})\ +\ |\Phi ^{-}\rangle {AC}\otimes (\alpha |0\rangle {B}-\beta |1\rangle {B})\ +\ |\Psi ^{+}\rangle {AC}\otimes (\beta |0\rangle {B}+\alpha |1\rangle {B})\ +\ |\Psi ^{-}\rangle {AC}\otimes (\beta |0\rangle {B}-\alpha |1\rangle {B}){\Big \rbrack }" class="latex" title="|\psi \rangle {C}\otimes \ |\Phi ^{+}\rangle {AB}\ = \frac {1}{2}{\Big \lbrack }\ |\Phi ^{+}\rangle {AC}\otimes (\alpha |0\rangle {B}+\beta |1\rangle {B})\ +\ |\Phi ^{-}\rangle {AC}\otimes (\alpha |0\rangle {B}-\beta |1\rangle {B})\ +\ |\Psi ^{+}\rangle {AC}\otimes (\beta |0\rangle {B}+\alpha |1\rangle {B})\ +\ |\Psi ^{-}\rangle {AC}\otimes (\beta |0\rangle {B}-\alpha |1\rangle {B}){\Big \rbrack }" /></p>



<p>which means that if one does a Bell pair measurement on A and C, based on the measurement outcome, we know exactly which state B is projected to and by using rotations can make the state of B equal to the initial state of C. Hence, we teleported quantum information from C to B.</p>



<p>Now, assume that A was maximally entangled to both B and D. Then by doing the same procedure, we could teleport quantum information from C to both B and D and hence, violate the no-cloning theorem!</p>



<h3>Page time</h3>



<p>Named after Don Page, the “Page time” refers to the time when the black hole has emitted enough of its energy in the form of Hawking radiation that its entropy has (approximately) halved. Now the question is, what’s so special about the Page time?</p>



<p>First note that the rank of the density matrix is closely related to its purity (or mixedness). For example, a completely mixed state is the diagonal matrix:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D+%5Cfrac%7B1%7D%7B4%7D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0%5C%5C+0+%26+1+%26+0+%26+0+%5C%5C+0+%26+0+%26+1+%26+0+%5C%5C+0+%26+0+%26+0+%26+1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{obs} = \frac{1}{4} \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix}" class="latex" title="\rho_{obs} = \frac{1}{4} \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 1 \end{pmatrix}" /></p>



<p>which has maximal rank (<img src="https://s0.wp.com/latex.php?latex=2%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{2}" class="latex" title="2^{2}" />). Furthermore, a completely pure state <img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle+%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle \langle\Psi|" class="latex" title="|\Psi\rangle \langle\Psi|" /> can always be represented as (if we just change the basis and make the first column/row represent <img src="https://s0.wp.com/latex.php?latex=%7C%5CPsi%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="|\Psi\rangle" class="latex" title="|\Psi\rangle" />):</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D++%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0+%5C%5C+0+%26+0+%26+0+%26+0++%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{obs} =  \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0  \end{pmatrix}" class="latex" title="\rho_{obs} =  \begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 0 &amp; 0  \end{pmatrix}" /><br /></p>



<p>which has rank 1.</p>



<p>Imagine we have watched a black hole form and begin emitting Hawking radiation. Say we start collecting this radiation. The density matrix of the radiation will have the form:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Crho_%7Bobs%7D+%3D+%5Csum_%7Bi%3D1%7D%5E%7B2%5E%7Bn-k%7D%7D+p_i+%7C%5CPsi%5Crangle_%7Bi%7D%5Clangle%5CPsi%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho_{obs} = \sum_{i=1}^{2^{n-k}} p_i |\Psi\rangle_{i}\langle\Psi|" class="latex" title="\rho_{obs} = \sum_{i=1}^{2^{n-k}} p_i |\Psi\rangle_{i}\langle\Psi|" /></p>



<p>where <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> is the total number of qubits in our initial state, <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" /> is the number of qubits outside (in form of radiation), and <img src="https://s0.wp.com/latex.php?latex=p_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_i" class="latex" title="p_i" /> is the probability of each state. We are simply tracing over the degrees of freedom inside the black hole (as there are <img src="https://s0.wp.com/latex.php?latex=n-k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n-k" class="latex" title="n-k" /> degrees inside the black hole, dimensionality of this space is <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-k%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{n-k}" class="latex" title="2^{n-k}" />).</p>



<p>Don Page proposed the following graph of what he thought entanglement entropy of this density matrix should look like. It is fittingly called the “Page curve.”</p>



<figure class="wp-block-image"><img src="https://windowsontheory.files.wordpress.com/2019/01/pagecurve.png?w=600" alt="" class="wp-image-7432" />The Page Curve</figure>



<ul><li>If <img src="https://s0.wp.com/latex.php?latex=k%3C%5Cfrac%7Bn%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k&lt;\frac{n}{2}" class="latex" title="k&lt;\frac{n}{2}" />, rank(<img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />) = <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{k}" class="latex" title="2^{k}" />, as there are enough terms in the sum to get a maximally ranked matrix. And hence, we get maximally mixed states. In the beginning, the radiation we collect at early times will still remain heavily entangled with the degrees of freedom near the black hole, and as such the state will look mixed to us because we can not yet observe all the complicated entanglement. As more and more information leaves the black hole in the form of Hawking radiation, we are “tracing out” fewer and fewer of the near-horizon degrees of freedom. The dimension of our density matrix grows bigger and bigger, and because the outgoing radiation is still so entangled with the near-horizon degrees of freedom, the density matrix will still have off-diagonal terms which are essentially zero. Hence, the state entropy increases linearly.</li><li>But if <img src="https://s0.wp.com/latex.php?latex=k%3E%5Cfrac%7Bn%7D%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k&gt;\frac{n}{2}" class="latex" title="k&gt;\frac{n}{2}" />, by the same argument, rank(<img src="https://s0.wp.com/latex.php?latex=%5Crho&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\rho" class="latex" title="\rho" />) = <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bn-k%7D+%3C+2%5E%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{n-k} &lt; 2^{k}" class="latex" title="2^{n-k} &lt; 2^{k}" />. Hence, the density matrix becomes more and more pure. Once the black hole’s entropy has reduced by half, the dimension of the Hilbert space we are tracing out finally becomes smaller than the dimension of the Hilbert space we are not tracing out. The off-diagonal terms spring into our density matrix, growing in size and number as the black hole continues to shrink. Finally, once the black hole is gone, we can easily see that all the resulting radiation is in a pure state.</li></ul>



<p>The entanglement entropy of the outgoing radiation finally starts decreasing, as we are finally able to start seeing entanglements between all this seemingly random radiation we have painstakingly collected. Some people like to say that if one could calculate the Page curve from first principles, the information paradox would be solved. Now we are ready to state the firewall paradox.</p>



<h2>The Firewall Paradox</h2>



<p>Say Alice collects all the Hawking radiation coming out of a black hole. At maybe, about <img src="https://s0.wp.com/latex.php?latex=1.5&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1.5" class="latex" title="1.5" /> times the Page time, Alice is now able to see significant entanglement in all the radiation she has collected. Alice then dives into the black hole and sees an outgoing Hawking mode escaping. Given the Page curve, we know that knowing this outgoing mode must decrease the entropy of our observed mixed state. In other words, it must make our observed density matrix purer. And hence, be entangled with the particles we have already collected.</p>



<p>(Another way to think about this: let’s say that a random quantum circuit at the horizon scrambles the information in a non-trivial yet injective way in order for radiation particles to encode the information regarding what went inside the black hole. The output qubits of the circuit must be highly entangled due to the random circuit.)</p>



<ul class="wp-block-gallery columns-1 is-cropped"><li class="blocks-gallery-item"><figure><img src="https://windowsontheory.files.wordpress.com/2019/01/alice2-1.png?w=796" class="wp-image-7455" />Alice diving into the black hole after the Page time to see the outgoing mode emerge.</figure></li></ul>



<p>However, given our discussion on Hawking radiation about short-range entanglement, the outgoing mode must be maximally entangled with an in-falling partner mode. This contradicts monogamy of entanglement! The outgoing mode cannot be entangled both with the radiation Alice has already collected and also maximally entangled with the nearby infalling mode!</p>



<p>So, to summarize, what did we do? We started with the existence of black holes and through our game of conservative radicalism, modified how physics works around them in order to make sure the following dear Physics principles are not violated by these special objects:</p>



<ul><li>Second Law of Thermodynamics</li><li>Objects with entropy emit thermal radiation</li><li>Unitary evolution and reversibility</li><li>No-cloning theorem</li><li>Monogamy of entanglement</li></ul>



<p>And finally, ended with the Firewall paradox.</p>



<p>So, for the last time in this blog post, what gives?</p>



<ul><li><strong>Firewall solution:</strong> The first solution to the paradox is the existence of a <em>firewall</em> at the horizon. The only way to not have the short-range entanglement discussed is if there is very high energy density at the horizon. However, this violates the “no-drama” theorem and Einstein’s equivalence principle of general relativity which states that locally there should be nothing special about the horizon. If firewalls did exist, an actual wall of fire could randomly appear out of nowhere in front of us right now if a future black hole would have its horizon near us. Hence, this solution is not very popular.</li><li><strong>Remnant solution:</strong> One possible resolution would be that the black hole never “poofs” but some quantum gravity effect we do not yet understand stabilizes it instead, allowing for some Planck-sized object to stick around? Such an object would be called a “remnant.” The so-called “remnant solution” to the information paradox is not a very popular one. People don’t like the idea of a very tiny, low-mass object holding an absurdly large amount of information.</li><li><strong>No unitary evolution:</strong> Perhaps, black holes are special objects which actually lose information! This would mean that black hole physics (the quantum theory of gravity) would be considerably different compared to quantum field theory.</li><li><strong>Computational complexity solution?</strong>: Can anyone ever observe this violation? And if not, does that resolve the paradox? This will be covered in our next blog post by Parth and Chi-Ning.</li></ul>



<h2>References</h2>



<ol><li>Scott Aaronson. The complexity of quantum states and transformations: from quantum money to black holes.arXiv preprintarXiv:1607.05256, 2016.</li><li>Daniel Harlow. Jerusalem lectures on black holes and quantum information. Reviews of Modern Physics, 88(1):015002, 2016.</li><li>Ahmed Almheiri, Donald Marolf, Joseph Polchinski, and JamesSully. Black holes: complementarity or firewalls? Journal of HighEnergy Physics, 2013(2):62, 2013.</li></ol></div>







<p class="date">
by bishk97 <a href="https://windowsontheory.org/2019/01/30/black-hole-paradoxes-a-conservative-yet-radical-journey/"><span class="datestr">at January 30, 2019 05:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1483">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/01/29/deadline-approaching-2019-godel-prize/">Deadline approaching – 2019 Gödel Prize</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A reminder that the February 15th deadline is approaching (see <a href="https://theorydish.blog/2018/12/18/2019-godel-prize/" rel="nofollow">https://theorydish.blog/2018/12/18/2019-godel-prize/</a>). It is safe to assume that the paper you are excited about was not nominated by others. Also, from personal experience, it is a great feeling to know that your nomination succeeded. Worse case, your (moderately) hard work you will earn you the privilege to complain about the committee’s stupidity (which, again from personal experience, could be satisfying as well <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f609.png" alt="😉" style="height: 1em;" class="wp-smiley" /> )</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2019/01/29/deadline-approaching-2019-godel-prize/"><span class="datestr">at January 29, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15603">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/01/29/primes-and-polynomials/">Primes And Polynomials</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>A result on the prime divisors of polynomial values</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/01/issaischur.jpg"><img src="https://rjlipton.files.wordpress.com/2019/01/issaischur.jpg?w=120&amp;h=180" alt="" width="120" class="alignright wp-image-15604" height="180" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://books.google.com/books?id=XLNJDylP53QC&amp;pg=PA89&amp;lpg=PA89&amp;dq=Issai+Schur:+Ramanujan%E2%80%99s+German+Contemporary&amp;source=bl&amp;ots=JwM2fktiyS&amp;sig=ACfU3U0kPjUEsHm3z5xtZTpLYjEW89mc5Q&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiG5pftg5TgAhWCiOAKHZTXAlEQ6AEwC3oECAQQAQ#v=onepage&amp;q=Issai%20Schur%3A%20Ramanujan%E2%80%99s%20German%20Contemporary&amp;f=false">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Issai Schur was a mathematician who obtained his doctorate over a hundred years ago. He was a student of the great group theorist Ferdinand Frobenius. Schur worked in various areas and proved many deep results, including some theorems in basic number theory.</p>
<p>
Today we discuss a nice lemma due to Schur. Actually, it’s a theorem.<br />
<span id="more-15603"></span></p>
<p>
There are many things named after Schur. Wikipedia has compiled a <a href="https://en.wikipedia.org/wiki/List_of_things_named_after_Issai_Schur">list</a> of them:</p>
<blockquote><p><b> </b> <em> <i>Frobenius-Schur indicator Herz-Schur multiplier Jordan-Schur theorem Lehmer-Schur algorithm Schur algebra Schur class Schur complement method Schur complement Schur decomposition Schur functor Schur index Schur multiplier Schur number Schur orthogonality relations Schur polynomial Schur product theorem Schur test Schur-convex function Schur-Horn theorem Schur-Weyl duality Schur-Zassenhaus theorem Schur’s inequality Schur’s lemma (from Riemannian geometry) Schur’s lemma Schur’s property Schur’s theorem</i> </em>
</p></blockquote>
<p></p><p>
This lists two Schur lemmas. But when you click on Wikipedia’s “Schur’s lemma” <a href="https://en.wikipedia.org/wiki/Schur's_lemma_(disambiguation)">page</a>, there are three Schur lemmas. No, wait—there are four, including one called “Schur’s test.” But the result we are interested in is classed as a <em>theorem</em>. Wikipedia’s single <a href="https://en.wikipedia.org/wiki/Schur's_theorem">page</a> for “Schur’s theorem” lists not just <em>five</em> but <em>six</em> Schur’s theorems. This is one higher than the count eventually reached in Monty Python’s famous “Spanish Inquisition” <a href="http://www.montypython.net/scripts/spanish.php">skit</a>. We want the sixth one, which is quite useful—like a lemma.</p>
<p>
</p><p></p><h2> The Result </h2><p></p>
<p></p><p>
Here is Schur’s lemma—no, theorem—published in 1912.</p>
<blockquote><p><b>Theorem 1</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> be a non-constant polynomial with integer coefficients. Then <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has infinitely many prime divisors. </em>
</p></blockquote>
<p></p><p>
Here <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has infinitely many prime divisors means that the number of primes that arise as divisors of the values <img src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(n)}" class="latex" title="{f(n)}" /> as <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D0%2C1%2C2%2C3%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=0,1,2,3,\dots}" class="latex" title="{n=0,1,2,3,\dots}" /> is infinite. Note, this works even if the polynomial is reducible or contains some trivial factors. Thus 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%29+%3D+10x%5E%7B3%7D+%2B+100%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(x) = 10x^{3} + 100, " class="latex" title="\displaystyle  f(x) = 10x^{3} + 100, " /></p>
<p>is fine. As is <img src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7B2%7D-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^{2}-1}" class="latex" title="{x^{2}-1}" />.</p>
<p>
Schur’s theorem is quite fun, even just to prove. Here is a nice version from a <a href="https://pdfs.semanticscholar.org/5eb7/4363199754164fdf7bbc77925a98c1eb435b.pdf">paper</a> by Ram Murty, whose work on extensions of Euclid’s famous proof of the infinitude of primes we <a href="https://rjlipton.wordpress.com/2018/07/11/you-cannot-do-that/">covered</a> last summer. We follow Murty’s proof.</p>
<p>
<em>Proof:</em>  Suppose <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> is an integral polynomial of least degree for which the statement fails, 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%29+%3D+a_%7Bn%7Dx%5E%7Bn%7D+%2B+a_%7Bn-1%7Dx%5E%7Bn-1%7D+%2B+%5Ccdots+%2B+a_%7B1%7Dx+%2B+a_%7B0%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(x) = a_{n}x^{n} + a_{n-1}x^{n-1} + \cdots + a_{1}x + a_{0}, " class="latex" title="\displaystyle  f(x) = a_{n}x^{n} + a_{n-1}x^{n-1} + \cdots + a_{1}x + a_{0}, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7Ba_n+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_n &gt; 0}" class="latex" title="{a_n &gt; 0}" />. If <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B0%7D%3D0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_{0}=0}" class="latex" title="{a_{0}=0}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%2Fx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)/x}" class="latex" title="{f(x)/x}" /> is an integral polynomial of lower degree for which it must fail, so we have <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B0%7D%5Cneq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_{0}\neq 0}" class="latex" title="{a_{0}\neq 0}" />. By hypothesis, <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has only finitely many prime divisors, which we can represent as <img src="https://s0.wp.com/latex.php?latex=%7Bp_%7B1%7D%2C+%5Cdots%2C+p_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_{1}, \dots, p_{r}}" class="latex" title="{p_{1}, \dots, p_{r}}" />. For each natural number <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" />, define <img src="https://s0.wp.com/latex.php?latex=%7BP+%3D+a_0+%5Ccdot+p_1+%5Ccdots+p_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P = a_0 \cdot p_1 \cdots p_r}" class="latex" title="{P = a_0 \cdot p_1 \cdots p_r}" /> and </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++Q_%7Bm%7D+%3D+f%28P%5E%7Bm%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  Q_{m} = f(P^{m}). " class="latex" title="\displaystyle  Q_{m} = f(P^{m}). " /></p>
<p>Now <img src="https://s0.wp.com/latex.php?latex=%7BP+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P &gt; 1}" class="latex" title="{P &gt; 1}" /> because <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> can take the value <img src="https://s0.wp.com/latex.php?latex=%7B%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+1}" class="latex" title="{+1}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> only finitely often, and all sufficiently large <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> give <img src="https://s0.wp.com/latex.php?latex=%7BQ_m+%3E+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_m &gt; 1}" class="latex" title="{Q_m &gt; 1}" /> for the same reason. Because <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> includes <img src="https://s0.wp.com/latex.php?latex=%7Ba_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_0}" class="latex" title="{a_0}" /> as a factor, <img src="https://s0.wp.com/latex.php?latex=%7BQ_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_m}" class="latex" title="{Q_m}" /> is divisible by <img src="https://s0.wp.com/latex.php?latex=%7Ba_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_0}" class="latex" title="{a_0}" />, giving </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28P%5Em%29+%3D+a_0%28K+%2B+1%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(P^m) = a_0(K + 1) " class="latex" title="\displaystyle  f(P^m) = a_0(K + 1) " /></p>
<p>for some integer <img src="https://s0.wp.com/latex.php?latex=%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K}" class="latex" title="{K}" /> that by choice of <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> is divisible by all of <img src="https://s0.wp.com/latex.php?latex=%7Bp_1%2C%5Cdots%2Cp_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_1,\dots,p_r}" class="latex" title="{p_1,\dots,p_r}" />. But then as in Euclid’s proof, <img src="https://s0.wp.com/latex.php?latex=%7BK%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{K+1}" class="latex" title="{K+1}" /> is co-prime to all those primes, so it must furnish a prime divisor of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> that is not among them. This is a contradiction. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
This proof was simple but clever. Here is a concrete version for the polynomial <img src="https://s0.wp.com/latex.php?latex=%7Bx%5E%7B2%7D+%2B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^{2} + a}" class="latex" title="{x^{2} + a}" />, which may help in understanding the proof: Say <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3Dx%5E%7B2%7D+%2B+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)=x^{2} + a}" class="latex" title="{f(x)=x^{2} + a}" /> is divisible by only <img src="https://s0.wp.com/latex.php?latex=%7Bp_%7B1%7D%2C%5Cdots%2Cp_%7Br%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_{1},\dots,p_{r}}" class="latex" title="{p_{1},\dots,p_{r}}" /> say. Let <img src="https://s0.wp.com/latex.php?latex=%7BP%3Dp_%7B1%7D+%5Ccdots+p_%7Br%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P=p_{1} \cdots p_{r}.}" class="latex" title="{P=p_{1} \cdots p_{r}.}" /> The trick is to look at 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28aPt%29+%3D+%28aPt%29%5E%7B2%7D+%2B+a+%3D+ag%28t%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(aPt) = (aPt)^{2} + a = ag(t), " class="latex" title="\displaystyle  f(aPt) = (aPt)^{2} + a = ag(t), " /></p>
<p>where 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++g%28t%29+%3D+a%28Pt%29%5E%7B2%7D+%2B+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  g(t) = a(Pt)^{2} + 1. " class="latex" title="\displaystyle  g(t) = a(Pt)^{2} + 1. " /></p>
<p>For some <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> large enough there exists a prime <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> that divides <img src="https://s0.wp.com/latex.php?latex=%7Bg%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(n)}" class="latex" title="{g(n)}" />. But this prime divides <img src="https://s0.wp.com/latex.php?latex=%7Bf%28aPn%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(aPn)}" class="latex" title="{f(aPn)}" /> and so <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+p_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p = p_{i}}" class="latex" title="{p = p_{i}}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. But then <img src="https://s0.wp.com/latex.php?latex=%7Bg%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(n)}" class="latex" title="{g(n)}" /> modulo <img src="https://s0.wp.com/latex.php?latex=%7Bp_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_{i}}" class="latex" title="{p_{i}}" /> is equal to <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> which is a contradiction.</p>
<p>
</p><p></p><h2> An Application </h2><p></p>
<p></p><p>
As the proof hints, Schur’s theorem is a proper extension of Euclid’s, which is just the case <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29+%3D+x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x) = x}" class="latex" title="{f(x) = x}" />. Here is a less-obvious application:</p>
<blockquote><p><b>Theorem 2</b> <em> Suppose that <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> is a polynomial with integer coefficients. Assume that <img src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f(n)}" class="latex" title="{f(n)}" /> is a perfect square for all integers <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> large enough. Then <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3Dg%28x%29%5E%7B2%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f(x)=g(x)^{2}}" class="latex" title="{f(x)=g(x)^{2}}" /> for some polynomial <img src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{g(x)}" class="latex" title="{g(x)}" />. </em>
</p></blockquote>
<p></p><p>
There are many proofs of this theorem. One uses the famous Hilbert Irreducibility theorem, which we also <a href="https://rjlipton.wordpress.com/2018/06/08/hilberts-irreducibility-theorem/">discussed</a> last summer. Another proof uses Schur’s lemma and the fact that if <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(x)}" class="latex" title="{g(x)}" /> are products of irreducible integer polynomials that are collectively distinct then the ideal generated by <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> contains a positive integer—namely, their <a href="https://en.wikipedia.org/wiki/Resultant">resultant</a> <img src="https://s0.wp.com/latex.php?latex=%7BR%28f%2Cg%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R(f,g)}" class="latex" title="{R(f,g)}" />. Again following Murty’s paper: </p>
<p>
<em>Proof:</em>  We can factor <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%3Dg%28x%29%5E%7B2%7Dh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)=g(x)^{2}h(x)}" class="latex" title="{f(x)=g(x)^{2}h(x)}" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(x)}" class="latex" title="{h(x)}" /> is a product of irreducible integer polynomials, and the goal is to show that <img src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(x) = 1}" class="latex" title="{h(x) = 1}" />. If <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> has positive degree, then by Schur’s theorem, there are infinitely many prime divisors <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" />. The square-freeness of <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> implies that it shares no factors with its derivative <img src="https://s0.wp.com/latex.php?latex=%7Bh%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h'}" class="latex" title="{h'}" />, so <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+R%28h%2Ch%27%29+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = R(h,h') &gt; 0}" class="latex" title="{r = R(h,h') &gt; 0}" />. We need only take <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> dividing <img src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(n)}" class="latex" title="{h(n)}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> large enough that <img src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(n)}" class="latex" title="{f(n)}" /> is a perfect square but such that <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> does not divide <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />. Then the order of <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> dividing <img src="https://s0.wp.com/latex.php?latex=%7Bf%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(n)}" class="latex" title="{f(n)}" /> must be even, which implies that the order of <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> dividing <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> must be even. So <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^2}" class="latex" title="{p^2}" /> divides <img src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(n)}" class="latex" title="{h(n)}" />.</p>
<p>
By a similar token, since <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> divides <img src="https://s0.wp.com/latex.php?latex=%7Bh%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(n+p)}" class="latex" title="{h(n+p)}" /> as well and <img src="https://s0.wp.com/latex.php?latex=%7Bf%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(n+p)}" class="latex" title="{f(n+p)}" /> is a perfect square, we get that <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^2}" class="latex" title="{p^2}" /> divides <img src="https://s0.wp.com/latex.php?latex=%7Bh%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(n+p)}" class="latex" title="{h(n+p)}" />.  Now <img src="https://s0.wp.com/latex.php?latex=%7Bh%28n%2Bp%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(n+p)}" class="latex" title="{h(n+p)}" /> is congruent to <img src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29+%2B+ph%27%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(n) + ph'(n)}" class="latex" title="{h(n) + ph'(n)}" /> modulo <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^2}" class="latex" title="{p^2}" />, and since <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^2}" class="latex" title="{p^2}" /> divides <img src="https://s0.wp.com/latex.php?latex=%7Bh%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(n)}" class="latex" title="{h(n)}" /> from before, it follows that <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> divides <img src="https://s0.wp.com/latex.php?latex=%7Bh%27%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h'(n)}" class="latex" title="{h'(n)}" />. Since <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> belongs to the ideal generated by <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bh%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h'}" class="latex" title="{h'}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}[x]}" class="latex" title="{\mathbb{Z}[x]}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> divides <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> too, but this contradicts the choice of <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />. So <img src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(x)}" class="latex" title="{h(x)}" /> must be a constant. Since the notion of “irreducible” with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%5Bx%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}[x]}" class="latex" title="{\mathbb{Z}[x]}" /> applies to constants, any square dividing <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> is already part of <img src="https://s0.wp.com/latex.php?latex=%7Bg%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(x)}" class="latex" title="{g(x)}" />, so <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> must be a product of distinct primes. This forestalls <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^2}" class="latex" title="{p^2}" /> dividing <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> in the above, so we must have <img src="https://s0.wp.com/latex.php?latex=%7Bh+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h = 1}" class="latex" title="{h = 1}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We did mention Schur’s long list of things named after him. Did people name things after others more often years ago? Or is naming them still common-place?</p>
<p>
[fixed last proof]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/01/29/primes-and-polynomials/"><span class="datestr">at January 29, 2019 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/01/29/simplifying-task-milestone">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/01/29/simplifying-task-milestone.html">Simplifying task-milestone diagrams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In my graph algorithms class last week, I covered critical path scheduling, as motivation for the linear-time algorithms for computing shortest and longest paths in directed acyclic graphs. In this scheduling problem, you are given a system of tasks, each with a predicted time to perform it, and constraints that some tasks should be done before others. Assuming that you have enough people working together to perform tasks in parallel, how quickly can you get everything done?</p>

<p>An optimal solution can be found by scheduling each task to start at a time given by the longest sequence of tasks leading up to it such that each consecutive pair in the sequence must be performed sequentially. The total length of the resulting schedule equals the length of the <a href="https://en.wikipedia.org/wiki/Critical_path_method">critical path</a>, the longest sequence of sequential tasks in the whole system. The example below could represent subtasks of a software project: design, implement, and test the software (A, B, and C), develop test cases (D), and document the results (E). Its critical path could be one of ABC, DE, AE, or DC, depending on the lengths of each task.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/pert1.svg" alt="Five tasks with ordering constraints" /></p>

<p>It’s easy enough to solve this problem directly, but to convert it to a path problem we need to have lengths on edges rather than times on vertices. It’s also convenient to have a single starting vertex for all the paths.
Therefore, <a href="https://en.wikipedia.org/wiki/Critical_path_method">Wikipedia’s article on the critical path method</a> uses a different kind of graph, which I’ll call a “task-milestone diagram” to distinguish it from the one above.
In this diagram, the vertices represent milestones, single points in time. The tasks to be performed are represented by edges, and the time to perform a task becomes the length of its edge. The goal of the scheduling problem now becomes one of choosing a time for each milestone, with enough time between pairs of milestones to perform each task.
The longest-path schedule, in which we place each milestone at a time given by the longest path to it from the start milestone, solves this problem optimally.</p>

<p>To convert a system of tasks and ordering constraints (without milestones) into an equivalent task-milestone diagram, make two new milestones for each task, one for when it starts and one for when it ends. Turn each task into an edge between its two milestones. Transform each ordering constraint (saying that task X should be performed earlier than task Y) into a length-zero edge from the end of task X to the beginning of task Y. Add two more milestones, for the start and end of the whole project. And add more length-zero edges from the project start to the start of each task that has no predecessors, and from the end of each task that has no successors to the project end milestone.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/pert2.svg" alt="Expanding each task vertex into two milestone vertices connected by a task edge" /></p>

<p>In the resulting graph, the paths from the start to the end milestone consist of the same sequences of tasks as we had before: ABC, DE, AE, or DC, separated by length-zero edges.
And for computational purposes the expansion doesn’t blow up the input size enough to cause any problems. But if we want to use this diagram for visualizing the resulting schedule, it’s a little confusing because of all of those extra length-zero edges. They don’t really represent tasks; they’re just there to make sure that the paths connect the tasks in the correct order. Do we really need so many of them?</p>

<p>There are a couple of simple rules that can be used to reduce the number of length-zero edges:</p>

<ul>
  <li>If two vertices both have only zero-length edges going out of them, and both have the same set of outgoing neighbors, they can be merged into a single vertex. Symmetrically, if two vertices both have only zero-length edges coming into them, and both have the same set of incoming neighbors, they can be merged.</li>
  <li>If a vertex has only one edge going out of it, of length zero, it can be merged with its outgoing neighbor. Symmetrically, if a vertex has only one edge coming into it, of length zero, it can be merged with its incoming neighbor.</li>
</ul>

<p>For instance, the first rule will merge the milestones for the starts of tasks A and D, and the second rule will merge the resulting vertex into the start vertex. Repeatedly applying these rules produces the following simplified graph. Note that its start-to-end paths, ABC, DE, AE, and DC, are exactly the same as the potential critical paths that we started with.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/pert3.svg" alt="Path-preserving simplification of the task-milestone diagram" /></p>

<p>If we assume that the task edges all have non-negative length (as they do in the scheduling application) and that we only care about longest paths, there are even more simplifications that we can perform. These ones might change the set of all paths in the graph (as identified by their sequences of tasks) but they preserve the identities of the longest paths:</p>

<ul>
  <li>
    <p>If a zero-length edge goes from task X to task Y, and the graph contains another path between the same two tasks, remove the edge.</p>
  </li>
  <li>
    <p>If a zero-length edge goes from task X to Y, every other edge into Y or out of X has length zero, and every incoming neighbor of task Y has a path to every outgoing neighbor of task X, then merge X and Y into a single vertex.</p>
  </li>
</ul>

<p>In our example, the bottom edge meets the conditions of the second rule. Applying that rule produces an even simpler task-milestone diagram:</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/pert4.svg" alt="Additional simplification preserving longest paths" /></p>

<p>Our example has no instances of the first rule, but when it is used it removes paths from the graph. The removed paths can never be longest paths, because any path through the removed edge can be made longer by replacing that edge by a different path from X to Y.
When we perform the second rule, we may introduce new paths that were not already present, from a predecessor of Y, through the merged vertex, to a successor of X. For instance, the new graph has a path through only the two tasks AC, which was not one of the four paths we started with. But because these new paths replace portions of existing paths by two length-zero edges, they can never be the longest path, and the resulting compacted diagram can safely be used for scheduling.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/101502692118389818">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/01/29/simplifying-task-milestone.html"><span class="datestr">at January 29, 2019 04:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-6555947.post-6062056358171439265">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/suresh.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://feedproxy.google.com/~r/TheGeomblog/~3/G-UqSGr3bSg/fat-session-2-systems-and-measurement.html">FAT* Session 2: Systems and Measurement.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Building systems that have fairness properties and monitoring systems that do A/B testing on us.<br /><br /><a href="https://algorithmicfairness.wordpress.com/2019/01/28/fat-papers-systems-and-measurement/">Session 2 of FAT*</a>: my opinionated summary.<div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=G-UqSGr3bSg:UU9jYzynrL0:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=yIl2AUoC8zA" border="0" /></a> <a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=G-UqSGr3bSg:UU9jYzynrL0:63t7Ie-LG7Y"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=63t7Ie-LG7Y" border="0" /></a>
</div><img width="1" alt="" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/G-UqSGr3bSg" height="1" /></div>







<p class="date">
by Suresh Venkatasubramanian (noreply@blogger.com) <a href="http://feedproxy.google.com/~r/TheGeomblog/~3/G-UqSGr3bSg/fat-session-2-systems-and-measurement.html"><span class="datestr">at January 29, 2019 06:48 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=334">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/01/28/tcs-talk-wednesday-february-6-ran-canetti-bu-and-tau/">TCS+ talk: Wednesday, February 6 — Ran Canetti, BU and TAU</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The new season of TCS+ is about to start! Our first talk for Spring will take place next Wednesday, February 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Ran Canetti</strong> from BU and TAU will speak about “<em>Fully Bideniable Interactive Encryption</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: While standard encryption guarantees secrecy of the encrypted plaintext only against an attacker that has no knowledge of the communicating parties’ keys and randomness of encryption, deniable encryption [Canetti et al., Crypto’96] provides the additional guarantee that the plaintext remains secret even in face of entities that attempt to coerce (or bribe) the communicating parties to expose their internal states, including the plaintexts, keys and randomness. To achieve this guarantee, deniable encryption equips the parties with faking algorithms which allow them to generate fake keys and randomness that make the ciphertext appear consistent with any plaintext of the parties’ choice. To date, however, only partial results were known: Either deniability against coercing only the sender, or against coercing only the receiver [Sahai-Waters, STOC ‘14] or schemes satisfying weaker notions of deniability [O’Neil et al., Crypto ‘11].</p>
<p>In this paper we present the first fully bideniable interactive encryption scheme, thus resolving the 20-years-old open problem. Our scheme also provides an additional and new guarantee: Even if the sender claims that one plaintext was used and the receiver claims a different one, the adversary has no way of figuring out who is lying – the sender, the receiver, or both. This property, which we call off-the-record deniability, is useful when the parties don’t have means to agree on what fake plaintext to claim, or when one party defects against the other. Our protocol has three messages, which is optimal [Bendlin et al., Asiacrypt’11], and needs a globally available reference string. We assume subexponential indistinguishability obfuscation (IO) and one-way functions.</p>
<p>Joint work with Sunoo Park and Oxana Poburinnaya.</p></blockquote>
<p> </p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/01/28/tcs-talk-wednesday-february-6-ran-canetti-bu-and-tau/"><span class="datestr">at January 28, 2019 04:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/01/28/first-airoyoung-phd-school/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/01/28/first-airoyoung-phd-school/">First AIROYoung PhD School</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
March 26-29, 2019 Rome, Italy https://workshop.airoyoung.org/2019#phd-school This is a three-days PhD School with theoretical classes and lab sessions on cutting-edge topics arising in Optimization and Simulation</div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/01/28/first-airoyoung-phd-school/"><span class="datestr">at January 28, 2019 11:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-6555947.post-8169216749697822290">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/suresh.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://feedproxy.google.com/~r/TheGeomblog/~3/TROyy-Os39k/fat-blogging.html">FAT* blogging</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I'll be blogging about each session of papers from the FAT* Conference. So as not to clutter your feed, the posts will be housed at the fairness blog that I co-write along with Sorelle Friedler and Carlos Scheidegger.<br /><br />The first post is on <a href="https://algorithmicfairness.wordpress.com/2019/01/27/fat-papers-framing-and-abstraction/">Session 1: Framing and Abstraction</a>.<div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=TROyy-Os39k:gYq646_XYaU:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=yIl2AUoC8zA" border="0" /></a> <a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=TROyy-Os39k:gYq646_XYaU:63t7Ie-LG7Y"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=63t7Ie-LG7Y" border="0" /></a>
</div><img width="1" alt="" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/TROyy-Os39k" height="1" /></div>







<p class="date">
by Suresh Venkatasubramanian (noreply@blogger.com) <a href="http://feedproxy.google.com/~r/TheGeomblog/~3/TROyy-Os39k/fat-blogging.html"><span class="datestr">at January 28, 2019 04:09 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=600">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/01/27/selling-your-town-to-the-marijuana-industry/">Selling your town to the marijuana industry</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p style="text-align: justify;">I vowed to quit with marijuana, but I just can’t.  It’s addictive.</p>
<p style="text-align: justify;">We can go back to 2016, when voters were hit with legalese that can only be described as a trap.  Basically, under the mask of legalizing the consumption of marijuana, the ballot question was really about opening recreational pot shops around the corner.  No doubt many, many people voted for legalization without knowledge of this and with no desire to have pot shops in their town.  What exultation must have come from the lawyers working for the industry, when their masterstroke made it to the fine print:</p>
<h3 style="text-align: justify;">A town voting to legalize marijuana <del>may</del> MUST open pot shops.</h3>
<p style="text-align: justify;">At the same time, the administration of Newton changed.  Councilors who liked the place the way it is and wanted to protect it lost to others who wanted it more vibrant.  The new councilors and the new mayor sided with the marijuana industry.</p>
<p style="text-align: justify;">The way in which they eventually won is sinister.  The context was that everybody in Newton wants at least some restriction on the number of marijuana stores.  But don’t take my word for this claim: even the pro-pot councilors believe so, and in fact almost unanimously they put a question on the ballot about restricting the number of stores.  At the same time, many people in Newton wanted zero stores.  In another masterstroke of the saga, the councilors were able to put one group against the other.  They added another question about having zero stores, following a massive, grassroots petition which however should have put the question at a different time. Then they forced the people who wanted zero stores to vote against restricting the number of stores. This is genius.  Also, if it isn’t illegal I believe it should be.  And in perfect coup style, media outlets censored several pieces explaining the situation to the voters. The end result was what the administration had always wanted: no restriction on the number of stores. Ignore the alarms of the doctors, the police officers, and the people.  What do they know about what’s best for Newton? The bottom line is that the revenue will do good things for the city! Oh yes, the revenue.  Newton has 1 billion dollars in deficit.  You read well, 1 billion.  For decades we will have a fraction of the city budget wiped out to repay that. I guess they can say we are so desperately in debt that we should rake in every penny we can zone in town.  But I think a more accurate perspective is that even in their wildest dreams, cannabis sales won’t make a dent in that.  And maybe they should spend a couple of minutes thinking about the dozens of other ways we can bring money to the city without bringing the drugs.</p>
<p style="text-align: justify;">Executing their sophisticated plan cost in the neighborhood of $100k, mostly spent on a political strategy group which helped win the election.  To add insult to injury, key members of this marijuana combine, including the political strategists and those who funded them, don’t live in Newton but in towns where recreational pot stores are banned.  The marijuana combine is effectively carving out suburban Boston in areas where it’s good to live and areas where it’s good to sell pot.</p>
<p style="text-align: justify;">As is well known, nobody has any problem with legalizing marijuana consumption.  Moreover, there is absolutely no problem with buying this stuff over the internet, or stocking up at out-of-the-way stores.  Well, absolutely no problem except one.  The money wouldn’t go into the pockets of X, Y, and Z.</p></div>







<p class="date">
by Emanuele <a href="https://emanueleviola.wordpress.com/2019/01/27/selling-your-town-to-the-marijuana-industry/"><span class="datestr">at January 28, 2019 01:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
