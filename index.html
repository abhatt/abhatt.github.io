<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://www.blogger.com/feeds/25562705/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://benjamin-recht.github.io/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://www.blogger.com/feeds/21224994/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/27705661/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at July 29, 2020 11:55 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/">Junior Fellowship / Andvanced Fellowship at ETH Institute for Theoretical Studies in Zurich (apply by September 23, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Junior and Advanced Fellows of the ETH Institute for Theoretical Studies are independent postdocs of exceptional talent and promise, having achieved significant results in mathematics, theoretical computer science or the theoretical natural sciences. Junior Fellows stay at the Institute for up to three years, Advanced Fellows up to five years.</p>
<p>Website: <a href="https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html">https://eth-its.ethz.ch/fellows/nomination-of-junior-fellows1.html</a><br />
Email: nominations@eth-its.ethz.ch</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/07/29/junior-fellowship-andvanced-fellowship-at-eth-institute-for-theoretical-studies-in-zurich-apply-by-september-23-2020/"><span class="datestr">at July 29, 2020 02:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/114">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/114">TR20-114 |  Disjointness through the Lens of Vapnik–Chervonenkis Dimension: Sparsity and Beyond | 

	Anup Bhattacharya, 

	Sourav Chakraborty, 

	Arijit Ghosh, 

	Gopinath Mishra, 

	Manaswi Paraashar</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The disjointness problem - where Alice and Bob are given two subsets of $\{1, \dots, n\}$ and they have to check if their sets intersect - is a central problem in the world of communication complexity. While both deterministic and randomized communication complexities for this problem are known to be $\Theta(n)$, it is also known that if the sets are assumed to be drawn from some restricted set systems then the communication complexity can be much lower. In this work, we explore how communication complexity measures change with respect to the complexity of the underlying set system. The complexity measure for the set system that we use in this work is the Vapnik–Chervonenkis (VC) dimension. More precisely, on any set system with VC dimension bounded by $d$, we analyze how large can the deterministic and randomized communication complexities be, as a function of $d$ and $n$.  The $d$-sparse set disjointness problem, where the sets have size at most $d$, is one such set system with VC dimension $d$. The deterministic and the randomized communication complexities of the $d$-sparse set disjointness problem have been well studied and is known to be $\Theta \left( d \log \left({n}/{d}\right)\right)$ and $\Theta(d)$, respectively, in the multi-round communication setting. In this paper, we address the question of whether the randomized communication complexity is always upper bounded by a function of the VC dimension of the set system, and does there always exist a gap between the deterministic and randomized communication complexity for set systems with small VC dimension. 

In this paper, we construct two natural set systems of VC dimension $d$, motivated from geometry. Using these set systems we show that the deterministic and randomized communication complexity can be $\widetilde{\Theta}\left(d\log \left( n/d \right)\right)$ for set systems of VC dimension $d$ and this matches the deterministic upper bound for all set systems of VC dimension $d$. We also study the deterministic and randomized communication complexities of the set intersection problem when sets belong to a set system of bounded VC dimension. We show that there exists set systems of VC dimension $d$ such that both deterministic and randomized (one-way and multi-round) complexities for the set intersection problem can be as high as $\Theta\left( d\log \left( n/d \right) \right)$, and this is tight among all set systems of VC dimension $d$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/114"><span class="datestr">at July 29, 2020 02:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14368">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14368">A Simple Sublinear Algorithm for Gap Edit Distance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brakensiek:Joshua.html">Joshua Brakensiek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charikar:Moses.html">Moses Charikar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinstein:Aviad.html">Aviad Rubinstein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14368">PDF</a><br /><b>Abstract: </b>We study the problem of estimating the edit distance between two
$n$-character strings. While exact computation in the worst case is believed to
require near-quadratic time, previous work showed that in certain regimes it is
possible to solve the following {\em gap edit distance} problem in sub-linear
time: distinguish between inputs of distance $\le k$ and $&gt;k^2$. Our main
result is a very simple algorithm for this benchmark that runs in time $\tilde
O(n/\sqrt{k})$, and in particular settles the open problem of obtaining a truly
sublinear time for the entire range of relevant $k$.
</p>
<p>Building on the same framework, we also obtain a $k$-vs-$k^2$ algorithm for
the one-sided preprocessing model with $\tilde O(n)$ preprocessing time and
$\tilde O(n/k)$ query time (improving over a recent $\tilde O(n/k+k^2)$-query
time algorithm for the same problem [GRS'20].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14368"><span class="datestr">at July 29, 2020 11:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14346">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14346">Algorithmic Fractal Dimensions in Geometric Measure Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lutz:Jack_H=.html">Jack H. Lutz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mayordomo:Elvira.html">Elvira Mayordomo</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14346">PDF</a><br /><b>Abstract: </b>The development of algorithmic fractal dimensions in this century has had
many fruitful interactions with geometric measure theory, especially fractal
geometry in Euclidean spaces. We survey these developments, with emphasis on
connections with computable functions on the reals, recent uses of algorithmic
dimensions in proving new theorems in classical (non-algorithmic) fractal
geometry, and directions for future research.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14346"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14339">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14339">The Satisfactory Partition Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Ajinkya Gaikwad, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maity:Soumen.html">Soumen Maity</a>, Shuvam Kant Tripathi <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14339">PDF</a><br /><b>Abstract: </b>The Satisfactory Partition problem consists in deciding if the set of
vertices of a given undirected graph can be partitioned into two nonempty parts
such that each vertex has at least as many neighbours in its part as in the
other part. This problem was introduced by Gerber and Kobler [European J. Oper.
Res. 125 (2000) 283-291] and further studied by other authors, but its
parameterized complexity remains open until now. It is known that the
Satisfactory Partition problem, as well as a variant where the parts are
required to be of the same cardinality, are NP-complete. We enhance our
understanding of the problem from the viewpoint of parameterized complexity by
showing that (1) the problem is FPT when parameterized by the neighbourhood
diversity of the input graph, (2) it can be solved in $O(n^{8 {\tt cw}})$ where
${\tt cw}$ is the clique-width,(3) a generalized version of the problem is
W[1]-hard when parameterized by the treewidth.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14339"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14307">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14307">Twenty-Two New Approximate Proof Labeling Schemes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emek:Yuval.html">Yuval Emek</a>, Yuval Gil <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14307">PDF</a><br /><b>Abstract: </b>Introduced by Korman, Kutten, and Peleg (Distributed Computing 2005), a
\emph{proof labeling scheme (PLS)} is a system dedicated to verifying that a
given configuration graph satisfies a certain property.
</p>
<p>It is composed of a centralized \emph{prover}, whose role is to generate a
proof for yes-instances in the form of an assignment of labels to the nodes,
and a distributed \emph{verifier}, whose role is to verify the validity of the
proof by local means and accept it if and only if the property is satisfied.
</p>
<p>To overcome lower bounds on the label size of PLSs for certain graph
properties, Censor-Hillel, Paz, and Perry (SIROCCO 2017) introduced the notion
of an \emph{approximate proof labeling scheme (APLS)} that allows the verifier
to accept also some no-instances as long as they are not "too far" from
satisfying the property.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14307"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14225">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14225">The Complexity of the Partition Coloring Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Zhenyu.html">Zhenyu Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xiao:Mingyu.html">Mingyu Xiao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Yi.html">Yi Zhou</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14225">PDF</a><br /><b>Abstract: </b>Given a simple undirected graph $G=(V,E)$ and a partition of the vertex set
$V$ into $p$ parts, the \textsc{Partition Coloring Problem} asks if we can
select one vertex from each part of the partition such that the chromatic
number of the subgraph induced on the $p$ selected vertices is bounded by $k$.
PCP is a generalized problem of the classical \textsc{Vertex Coloring Problem}
and has applications in many areas, such as scheduling and encoding etc.
</p>
<p>In this paper, we show the complexity status of the \textsc{Partition
Coloring Problem} with three parameters: the number of colors, the number of
parts of the partition, and the maximum size of each part of the partition.
</p>
<p>Furthermore, we give a new exact algorithm for this problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14225"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14204">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14204">Graph Spanners by Sketching in Dynamic Streams and the Simultaneous Communication Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Filtser:Arnold.html">Arnold Filtser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nouri:Navid.html">Navid Nouri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14204">PDF</a><br /><b>Abstract: </b>Graph sketching is a powerful technique introduced by the seminal work of
Ahn, Guha and McGregor'12 on connectivity in dynamic graph streams that has
enjoyed considerable attention in the literature since then, and has led to
near optimal dynamic streaming algorithms for many fundamental problems such as
connectivity, cut and spectral sparsifiers and matchings. Interestingly,
however, the sketching and dynamic streaming complexity of approximating the
shortest path metric of a graph is still far from well-understood. Besides a
direct $k$-pass implementation of classical spanner constructions, the state of
the art amounts to a $O(\log k)$-pass algorithm of Ahn, Guha and McGregor'12,
and a $2$-pass algorithm of Kapralov and Woodruff'14. In particular, no single
pass algorithm is known, and the optimal tradeoff between the number of passes,
stretch and space complexity is open.
</p>
<p>In this paper we introduce several new graph sketching techniques for
approximating the shortest path metric of the input graph. We give the first
{\em single pass} sketching algorithm for constructing graph spanners: we show
how to obtain a $\widetilde{O}(n^{\frac{2}{3}})$-spanner using
$\widetilde{O}(n)$ space, and in general a
$\widetilde{O}(n^{\frac{2}{3}(1-\alpha)})$-spanner using
$\widetilde{O}(n^{1+\alpha})$ space for every $\alpha\in [0, 1]$, a tradeoff
that we think may be close optimal. We also give new spanner construction
algorithms for any number of passes, simultaneously improving upon all prior
work on this problem. Finally, we note that unlike the original sketching
approach of Ahn, Guha and McGregor'12, none of the existing spanner
constructions yield {\em simultaneous communication} protocols with low per
player information. We give the first such protocols for the spanner problem
that use a small number of rounds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14204"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14179">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14179">Close relatives of Feedback Vertex Set without single-exponential algorithms parameterized by treewidth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bergougnoux:Benjamin.html">Benjamin Bergougnoux</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brettell:Nick.html">Nick Brettell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwon:O=joung.html">O-joung Kwon</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14179">PDF</a><br /><b>Abstract: </b>The Cut &amp; Count technique and the rank-based approach have lead to
single-exponential FPT algorithms parameterized by treewidth, that is, running
in time $2^{O(tw)}n^{O(1)}$, for Feedback Vertex Set and connected versions of
the classical graph problems (such as Vertex Cover and Dominating Set). We show
that Subset Feedback Vertex Set, Subset Odd Cycle Transversal, Restricted
Edge-Subset Feedback Edge Set, Node Multiway Cut, and Multiway Cut are unlikely
to have such running times. More precisely, we match algorithms running in time
$2^{O(tw \log tw)}n^{O(1)}$ with tight lower bounds under the Exponential-Time
Hypothesis (ETH), ruling out $2^{o(tw \log tw)}n^{O(1)}$, where $n$ is the
number of vertices and $tw$ is the treewidth of the input graph. Our algorithms
extend to the weighted case, while our lower bounds also hold for the larger
parameter pathwidth and do not require weights. We also show that, in contrast
to Odd Cycle Transversal, there is no $2^{o(tw \log tw)}n^{O(1)}$-time
algorithm for Even Cycle Transversal under the ETH.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14179"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14169">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14169">Semantic Width and the Fixed-Parameter Tractability of Constraint Satisfaction Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Hubie.html">Hubie Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gottlob:Georg.html">Georg Gottlob</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lanzinger:Matthias.html">Matthias Lanzinger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pichler:Reinhard.html">Reinhard Pichler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14169">PDF</a><br /><b>Abstract: </b>Constraint satisfaction problems (CSPs) are an important formal framework for
the uniform treatment of various prominent AI tasks, e.g., coloring or
scheduling problems. Solving CSPs is, in general, known to be NP-complete and
fixed-parameter intractable when parameterized by their constraint scopes. We
give a characterization of those classes of CSPs for which the problem becomes
fixed-parameter tractable.
</p>
<p>Our characterization significantly increases the utility of the CSP framework
by making it possible to decide the fixed-parameter tractability of problems
via their CSP formulations.
</p>
<p>We further extend our characterization to the evaluation of unions of
conjunctive queries, a fundamental problem in databases. Furthermore, we
provide some new insight on the frontier of PTIME solvability of CSPs.
</p>
<p>In particular, we observe that bounded fractional hypertree width is more
general than bounded hypertree width only for classes that exhibit a certain
type of exponential growth.
</p>
<p>The presented work resolves a long-standing open problem and yields powerful
new tools for complexity research in AI and database theory.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14169"><span class="datestr">at July 29, 2020 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14161">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14161">Twin-width III: Max Independent Set and Coloring</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Geniet:Colin.html">Colin Geniet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Eun_Jung.html">Eun Jung Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomass=eacute=:St=eacute=phan.html">Stéphan Thomassé</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrigant:R=eacute=mi.html">Rémi Watrigant</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14161">PDF</a><br /><b>Abstract: </b>We recently introduced the graph invariant twin-width, and showed that
first-order model checking can be solved in time $f(d,k)n$ for $n$-vertex
graphs given with a witness that the twin-width is at most $d$, called
$d$-contraction sequence or $d$-sequence, and formulas of size $k$ [Bonnet et
al., FOCS '20]. The inevitable price to pay for such a general result is that
$f$ is a tower of exponentials of height roughly $k$. In this paper, we show
that algorithms based on twin-width need not be impractical. We present
$2^{O(k)}n$-time algorithms for $k$-Independent Set, $r$-Scattered Set,
$k$-Clique, and $k$-Dominating Set when an $O(1)$-sequence is provided. We
further show how to solve weighted $k$-Independent Set, Subgraph Isomorphism,
and Induced Subgraph Isomorphism, in time $2^{O(k \log k)}n$. These algorithms
are based on a dynamic programming scheme following the sequence of
contractions forward. We then show a second algorithmic use of the contraction
sequence, by starting at its end and rewinding it. As an example of this
reverse scheme, we present a polynomial-time algorithm that properly colors the
vertices of a graph with relatively few colors, establishing that bounded
twin-width classes are $\chi$-bounded. This significantly extends the
$\chi$-boundedness of bounded rank-width classes, and does so with a very
concise proof. The third algorithmic use of twin-width builds on the second
one. Playing the contraction sequence backward, we show that bounded twin-width
graphs can be edge-partitioned into a linear number of bicliques, such that
both sides of the bicliques are on consecutive vertices, in a fixed vertex
ordering. Given that biclique edge-partition, we show how to solve the
unweighted Single-Source Shortest Paths and hence All-Pairs Shortest Paths in
sublinear time $O(n \log n)$ and time $O(n^2 \log n)$, respectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14161"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14156">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14156">Dual Half-integrality for Uncrossable Cut Cover and its Application to Maximum Half-Integral Flow</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Naveen.html">Naveen Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Nikhil.html">Nikhil Kumar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14156">PDF</a><br /><b>Abstract: </b>Given an edge weighted graph and a forest $F$, the $\textit{2-edge
connectivity augmentation problem}$ is to pick a minimum weighted set of edges,
$E'$, such that every connected component of $E'\cup F$ is 2-edge connected.
Williamson et al. gave a 2-approximation algorithm (WGMV) for this problem
using the primal-dual schema. We show that when edge weights are integral, the
WGMV procedure can be modified to obtain a half-integral dual. The 2-edge
connectivity augmentation problem has an interesting connection to routing flow
in graphs where the union of supply and demand is planar. The half-integrality
of the dual leads to a tight 2-approximate max-half-integral-flow min-multicut
theorem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14156"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14142">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14142">Rectangle Tiling Binary Arrays</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghosal:Pratik.html">Pratik Ghosal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meesum:Syed_Mohammad.html">Syed Mohammad Meesum</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paluch:Katarzyna.html">Katarzyna Paluch</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14142">PDF</a><br /><b>Abstract: </b>The problem of rectangle tiling binary arrays is defined as follows. Given an
$n \times n$ array $A$ of zeros and ones and a natural number $p$, our task is
to partition $A$ into at most $p$ rectangular tiles, so that the maximal weight
of a tile is minimized. A tile is any rectangular subarray of $A$. The weight
of a tile is the sum of elements that fall within it. We present a linear
$(O(n^2))$ time $(\frac{3}{2}+\frac{p^2}{w(A)})$-approximation algorithm for
this problem, where $w(A)$ denotes the weight of the whole array $A$.
</p>
<p>The algorithm employs the lower bound of $L=\lceil \frac{w(A)}{p} \rceil$,
which is the same lower bound on the optimum that was used in all algorithms
for rectangle tiling. We prove that a better approximation factor for the
binary \RTILE cannot be achieved using the same lower bound $L$, because there
exist arrays, whose every partition contains a tile of weight at least
$(\frac{3}{2}+\frac{p^2}{w(A)})L$. The previously known approximation algorithm
for rectangle tiling binary arrays achieved the ratio of $2$. We also consider
the dual problem of rectangle tiling for binary arrays, where we are given an
upper bound on the weight of the tiles, and we have to cover the array $A$ with
the minimum number of non-overlapping tiles. Both problems have natural
extensions to $d$-dimensional versions, for which we provide analogous results.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14142"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14092">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14092">Counting Short Vector Pairs by Inner Product and Relations to the Permanent</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bj=ouml=rklund:Andreas.html">Andreas Björklund</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaski:Petteri.html">Petteri Kaski</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14092">PDF</a><br /><b>Abstract: </b>Given as input two $n$-element sets $\mathcal A,\mathcal B\subseteq\{0,1\}^d$
with $d=c\log n\leq(\log n)^2/(\log\log n)^4$ and a target $t\in
\{0,1,\ldots,d\}$, we show how to count the number of pairs $(x,y)\in \mathcal
A\times \mathcal B$ with integer inner product $\langle x,y \rangle=t$
deterministically, in $n^2/2^{\Omega\bigl(\!\sqrt{\log n\log \log n/(c\log^2
c)}\bigr)}$ time. This demonstrates that one can solve this problem in
deterministic subquadratic time almost up to $\log^2 n$ dimensions, nearly
matching the dimension bound of a subquadratic randomized detection algorithm
of Alman and Williams [FOCS 2015]. We also show how to modify their randomized
algorithm to count the pairs w.h.p., to obtain a fast randomized algorithm. Our
deterministic algorithm builds on a novel technique of reconstructing a
function from sum-aggregates by prime residues, which can be seen as an {\em
additive} analog of the Chinese Remainder Theorem. As our second contribution,
we relate the fine-grained complexity of the task of counting of vector pairs
by inner product to the task of computing a zero-one matrix permanent over the
integers.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14092"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14045">The Tractability of SHAP-scores over Deterministic and Decomposable Boolean Circuits</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arenas:Marcelo.html">Marcelo Arenas</a>, Pablo Barceló Leopoldo Bertossi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Monet:Mika=euml=l.html">Mikaël Monet</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14045">PDF</a><br /><b>Abstract: </b>Scores based on Shapley values are currently widely used for providing
explanations to classification results over machine learning models. A prime
example of this corresponds to the influential SHAP-score, a version of the
Shapley value in which the contribution of a set $S$ of features from a given
entity $\mathbf{e}$ over a model $M$ is defined as the expected value in $M$ of
the set of entities $\mathbf{e}'$ that coincide with $\mathbf{e}$ over all
features in $S$. While in general computing Shapley values is a computationally
intractable problem, it has recently been claimed that the SHAP-score can be
computed in polynomial time over the class of decision trees. In this paper, we
provide a proof of a stronger result over Boolean models: the SHAP-score can be
computed in polynomial time over deterministic and decomposable Boolean
circuits, also known as tractable probabilistic circuits. Such circuits
encompass a wide range of Boolean circuits and binary decision diagrams
classes, including binary decision trees and Ordered Binary Decision Diagrams
(OBDDs). Moreover, we establish the computational limits of the notion of
SHAP-score by showing that computing it over a class of Boolean models is
always (polynomially) as hard as the model counting problem for this class
(under some mild condition). This implies, for instance, that computing the
SHAP-score for DNF propositional formulae is a #P-hard problem, and, thus, that
determinism is essential for the circuits that we consider.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14045"><span class="datestr">at July 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2007.14028">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2007.14028">Efficient Sampling Algorithms for Approximate Temporal Motif Counting (Extended Version)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Jingjing.html">Jingjing Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yanhao.html">Yanhao Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jiang:Wenjun.html">Wenjun Jiang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yuchen.html">Yuchen Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tan:Kian=Lee.html">Kian-Lee Tan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2007.14028">PDF</a><br /><b>Abstract: </b>A great variety of complex systems ranging from user interactions in
communication networks to transactions in financial markets can be modeled as
temporal graphs, which consist of a set of vertices and a series of timestamped
and directed edges. Temporal motifs in temporal graphs are generalized from
subgraph patterns in static graphs which take into account edge orderings and
durations in addition to structures. Counting the number of occurrences of
temporal motifs is a fundamental problem for temporal network analysis.
However, existing methods either cannot support temporal motifs or suffer from
performance issues. In this paper, we focus on approximate temporal motif
counting via random sampling. We first propose a generic edge sampling (ES)
algorithm for estimating the number of instances of any temporal motif.
Furthermore, we devise an improved EWS algorithm that hybridizes edge sampling
with wedge sampling for counting temporal motifs with 3 vertices and 3 edges.
We provide comprehensive analyses of the theoretical bounds and complexities of
our proposed algorithms. Finally, we conduct extensive experiments on several
real-world datasets, and the results show that our ES and EWS algorithms have
higher efficiency, better accuracy, and greater scalability than the
state-of-the-art sampling method for temporal motif counting.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2007.14028"><span class="datestr">at July 29, 2020 11:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/113">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/113">TR20-113 |  Relaxed Locally Correctable Codes with Nearly-Linear Block Length and Constant Query Complexity | 

	Tom Gur, 

	Igor Shinkar, 

	Alessandro Chiesa</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Locally correctable codes (LCCs) are error correcting codes C : \Sigma^k \to \Sigma^n which admit local algorithms that correct any individual symbol of a corrupted codeword via a minuscule number of queries. This notion is stronger than that of locally decodable codes (LDCs), where the goal is to only recover individual symbols of the message. One of the central problems in algorithmic coding theory is to construct O(1)-query LCCs and LDCs with minimal block length. Alas, state-of-the-art of such codes requires super-polynomial block length to admit O(1)-query algorithms for local correction and decoding, despite much attention during the last two decades.

This lack of progress prompted the study of relaxed LCCs and LDCs, which allow the correction algorithm to abort (but not err) on a small fraction of the locations. This relaxation turned out to allow constant-query correcting and decoding algorithms for codes with polynomial block length. Focusing on local correction, Gur, Ramnarayan, and Rothblum (ITCS~2018) showed that there exist O(1)-query relaxed LCCs that achieve nearly-quartic block length n = k^{4+\alpha}, for an arbitrarily small constant \alpha&gt;0.

We construct an O(1)-query relaxed LCC with nearly-linear block length n = k^{1+\alpha}, for an arbitrarily small constant \alpha&gt;0. This significantly narrows the gap between the lower bound which states that there are no O(1)-query relaxed LCCs with block length n = k^{1+o(1)}. In particular, our construction matches the parameters achieved by Ben-Sasson et al. (SIAM J. Comput. 2006), who constructed relaxed LDCs with the same parameters. This resolves an open problem raised by Gur, Ramnarayan, and Rothblum (ITCS 2018).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/113"><span class="datestr">at July 27, 2020 08:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/112">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/112">TR20-112 |  Simulating DQBF Preprocessing Techniques with Resolution Asymmetric Tautologies | 

	Joshua Blinkhorn</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Dependency quantified Boolean formulas (DQBF) describe an NEXPTIME-complete generalisation of QBF, which in turn generalises SAT. QRAT is a recently proposed proof system for quantified Boolean formulas (QBF), which simulates the full suite of QBF preprocessing techniques and thus forms a uniform proof checking format for solver verification.

In this work, we study QRAT in the more general DQBF context, obtaining a sound and complete refutational DQBF proof system that we call DQRAT. We show that DQRAT can simulate the full suite of dedicated DQBF preprocessing techniques, except those relying on defined variables, which we cover with the introduction of a new form of prefix modification. Our work enables generalisations of further QBF preprocessing techniques (e.g. blocked literal elimination) that were not previously considered for DQBF.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/112"><span class="datestr">at July 27, 2020 07:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17349">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/07/27/a-brilliant-book-on-combinatorics/">A Brilliant Book on Combinatorics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>And Razborov’s brilliant proof method</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.files.wordpress.com/2020/07/jukna1.png"><img src="https://rjlipton.files.wordpress.com/2020/07/jukna1.png?w=600" alt="" class="alignright size-full wp-image-17351" /></a></p>
<p>
Stasys Jukna is the author of the <a href="https://www.google.com/books/edition/Extremal_Combinatorics/NV3Y8vjWo8kC?hl=en&amp;gbpv=1">book</a> <em>Extremal Combinatorics With Applications in Computer Science</em>. </p>
<p>
Today we talk about Jukna’s book on extremal combinatorics.</p>
<p>
The structure of his book is great. The material is useful and well presented. Rather than add more general comments about his book, we thought we might highlight one tiny part—the part on monotone circuit lower bounds. Here goes. All below is based directly on his discussion. Any errors or misguided comments are ours.</p>
<p>
</p><p></p><h2> Monotone Boolean Functions </h2><p></p>
<p></p><p>
Fix an input size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> and consider some property of subsets <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[n]}" class="latex" title="{[n]}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(S)=1}" class="latex" title="{f(S)=1}" /> exactly when <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> has the property. We can think of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> as a Boolean function. You believe that this property is hard to compute—how do you go about proving that? </p>
<p>
In general we have no tools, but if the property is monotone, then there are some powerful methods. Recall <em>monotone</em> means that if <img src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(S)=1}" class="latex" title="{f(S)=1}" /> then any set <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7BS+%5Csubset+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S \subset T}" class="latex" title="{S \subset T}" /> still has the property. For example, <img src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(S)}" class="latex" title="{f(S)}" /> could be that <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> includes at least half of the elements of <img src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[n]}" class="latex" title="{[n]}" />. It cannot be that <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> has an even number of elements. Another example is when <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is given in <em>disjunctive normal form</em> (DNF), </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+T_1+%5Cvee+T_2+%5Cvee+%5Ccdots+T_m%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, " class="latex" title="\displaystyle  f \equiv T_1 \vee T_2 \vee \cdots T_m, " /></p>
<p>where each <b>term</b> <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> is a conjunction of variables. Each <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> can be regarded as a subset of <img src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[n]}" class="latex" title="{[n]}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(S) = 1}" class="latex" title="{f(S) = 1}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%7BS+%5Csupseteq+T_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S \supseteq T_k}" class="latex" title="{S \supseteq T_k}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />. Every monotone function also has a <em>conjunctive normal form</em> (CNF) </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cequiv+C_f+%3D+C_1+%5Cwedge+C_2+%5Cwedge+%5Ccdots+%5Cwedge+C_%5Cell%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, " class="latex" title="\displaystyle  f \equiv C_f = C_1 \wedge C_2 \wedge \cdots \wedge C_\ell, " /></p>
<p>where each <b>clause</b> <img src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_k}" class="latex" title="{C_k}" /> is a disjunction of variables. Then <img src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(S) = 1}" class="latex" title="{f(S) = 1}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%7BS+%5Ccap+C_k+%5Cneq+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S \cap C_k \neq \emptyset}" class="latex" title="{S \cap C_k \neq \emptyset}" /> for <em>all</em> <img src="https://s0.wp.com/latex.php?latex=%7Bk.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k.}" class="latex" title="{k.}" /> The problem is that the numbers <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> of terms and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> of clauses involved may be huge. The clauses may have different sizes. Given a CNF <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> of maximum clause size <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" />, we write <img src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^s}" class="latex" title="{C^s}" /> for the conjunction of clauses of size exactly <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^{&lt;s}}" class="latex" title="{C^{&lt;s}}" /> for the rest. We similarly write <img src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^r}" class="latex" title="{D^r}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^{&lt;r}}" class="latex" title="{D^{&lt;r}}" /> for DNFs <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />.</p>
<p>
The lower bound methods are on the size of a monotone circuit for <img src="https://s0.wp.com/latex.php?latex=%7Bf%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(S)}" class="latex" title="{f(S)}" />. That is the circuit can only use gates <img src="https://s0.wp.com/latex.php?latex=%7BAND%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{AND}" class="latex" title="{AND}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BOR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{OR}" class="latex" title="{OR}" />, but no other types of gates, especially not <img src="https://s0.wp.com/latex.php?latex=%7BNOT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{NOT}" class="latex" title="{NOT}" /> gates. Of course, if <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has no small monotone circuits, then it has no small DNF or CNF formulas either. </p>
<p>
The neat fact on which the lower-bound technique builds is that if <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> <b>does</b> have small monotone circuits, then we can “wrap” it between a CNF and a DNF in various customizable ways:</p>
<blockquote><p><b>Theorem 1 (informal)</b> <em><a name="informal"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> with small monotone circuits and <img src="https://s0.wp.com/latex.php?latex=%7Br%2Cs+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r,s &gt; 0}" class="latex" title="{r,s &gt; 0}" /> we can find a CNF <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> of maximum clause size <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> and a DNF <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> of maximum term size <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> such that </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cleq+f+%5Cleq+D+%5Cqquad%5Ctext%7Band+also%7D%5Cqquad+D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. " class="latex" title="\displaystyle  C \leq f \leq D \qquad\text{and also}\qquad D^{&lt;r} \leq C^{&lt;s}. " /></p>
</em><p><em>Moreover, <img src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{C^s}" class="latex" title="{C^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{D^r}" class="latex" title="{D^r}" /> are small. </em>
</p></blockquote>
<p></p><p>
We have said “wrap” not “sandwich” because although <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> is the “upper slice,” the part of <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> with smaller terms—but there could be many of them—wraps around to be under the corresponding part of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. This fact will enable us to throw away the smaller clauses and terms. How small is “small”? We will say later. We are trying to solve problems of exposition by keeping a high-level view at the start. </p>
<p>
</p><p></p><h2> Exposition Problems </h2><p></p>
<p></p><p>
Tim Gowers has written an <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.587.8986&amp;rep=rep1&amp;type=pdf">article</a> about the lower method for monotone functions. The method is due to Alexander Razborov in his seminal 1985 <a href="http://people.cs.uchicago.edu/~razborov/files/clique.pdf">paper</a> and extended by Noga Alon and Ravi Boppana in their <a href="https://core.ac.uk/download/pdf/191378189.pdf">paper</a> right afterward, and by Benjamin Rossman in his 2009 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.156.5526&amp;rep=rep1&amp;type=pdf">paper</a>, to name a few. </p>
<p>
Gowers says right away that the original papers on this method are clear and well written. But he believes that there is need for more exposition. The method is so important that it must be made easy for all to understand. He says his article is an attempt to solve an <i>open exposition problem</i>. The notion of an exposition problem is due to Timothy Chow who <a href="https://arxiv.org/pdf/0712.1320.pdf">wrote</a>:</p>
<blockquote><p><b> </b> <em> All mathematicians are familiar with the concept of an open research problem. I propose the less familiar concept of an open exposition problem. </em>
</p></blockquote>
<p></p><p>
Chow raised this issue with respect to the forcing method in set theory due to Paul Cohen. A modest suggestion: Read Chow on forcing, a great exposition; read Gowers on the monotone lower bound method, another great one. Both are much better than anything we can do. But we will put our own spin on the lower bound method. And hope to add to the quest to solve the exposition problem. </p>
<p></p><h2> The Method—High Level </h2><p></p>
<p></p><p>
Suppose that <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> is a monotone boolean circuit that has <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> inputs and computes <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" /> at the last gate. The method is called the <i>approximation method</i> because the idea is that it builds two other boolean functions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{lower}}" class="latex" title="{\mathsf{lower}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{upper}}" class="latex" title="{\mathsf{upper}}" />: for all <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0,1\}^{n}}" class="latex" title="{\{0,1\}^{n}}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathsf%7Blower%7D%28x%29+%5Cle+f%28x%29+%5Cle+%5Cmathsf%7Bupper%7D%28x%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). " class="latex" title="\displaystyle  \mathsf{lower}(x) \le f(x) \le \mathsf{upper}(x). " /></p>
<p>This follows a tradition in math that we often replace a complex function, <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x)}" class="latex" title="{f(x)}" />, with simpler upper and lower bounds. Standard stuff. </p>
<p>
Usually the point is that the approximators are not only easier to understand but also simpler in some objective sense. For example, Christophe Chesneau and Yogesh Bagul give a nice short <a href="https://hal.archives-ouvertes.fr/hal-01934571/document">compendium</a> of approximating formulas involving trigonometric functions by formulas without them, including that for all <img src="https://s0.wp.com/latex.php?latex=%7B0%3Cx%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0&lt;x&lt;1}" class="latex" title="{0&lt;x&lt;1}" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cexp%28-bx%5E%7B2%7D%29+%3C+%5Csin%28x%29%2Fx+%3C+%5Cexp%28-x%5E%7B2%7D%2F6%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), " class="latex" title="\displaystyle  \exp(-bx^{2}) &lt; \sin(x)/x &lt; \exp(-x^{2}/6), " /></p>
<p>with <img src="https://s0.wp.com/latex.php?latex=%7Bb+%5Capprox+0.172604%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b \approx 0.172604}" class="latex" title="{b \approx 0.172604}" />. If you have to reason about the behavior of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csin%28x%29%2Fx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sin(x)/x}" class="latex" title="{\sin(x)/x}" />, it is nice to have these upper and lower bounds. Note that the upper bound kind-of wraps around because it is the same kind of function as the lower bound.</p>
<p>
What gives the monotone method a special twist is that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Blower%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{lower}}" class="latex" title="{\mathsf{lower}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7Bupper%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{upper}}" class="latex" title="{\mathsf{upper}}" /> are not necessarily simple in the sense of being small.  Rather, they <em>make simple errors</em>—ones that can be corrected with small effort. The correction process yields <img src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^s}" class="latex" title="{C^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%5Er.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^r.}" class="latex" title="{D^r.}" />  Isolating what is small, however, requires us to trade an “AND” of two inequalities for an “OR” of two economical ones. We know that at least one of the latter inequalities must be true. We arrange that either one gives us the kind of lower bound we seek. </p>
<p>
</p><p></p><h2> Some More Detail </h2><p></p>
<p></p><p>
Here is how the trade happens. From Theorem <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> we have: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cwedge+C%5E%7B%3Cs%7D+%5Cleq+f+%5Cleq+D%5E%7B%3Cr%7D+%5Cvee+D%5Er%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, " class="latex" title="\displaystyle  C^s \wedge C^{&lt;s} \leq f \leq D^{&lt;r} \vee D^r, " /></p>
<p>where: <img src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^s}" class="latex" title="{C^s}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^r}" class="latex" title="{D^r}" /> are small, and while <img src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^{&lt;s}}" class="latex" title="{C^{&lt;s}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^{&lt;r}}" class="latex" title="{D^{&lt;r}}" /> might be big, we have <img src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^{&lt;r} \leq C^{&lt;s}}" class="latex" title="{D^{&lt;r} \leq C^{&lt;s}}" />. The trick is to ask:</p>
<blockquote><p><b> </b> <em> Is <img src="https://s0.wp.com/latex.php?latex=%7BC%5E%7B%3Cs%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{C^{&lt;s}}" class="latex" title="{C^{&lt;s}}" /> empty—that is, is it the trivial <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> function? </em>
</p></blockquote>
<p>
</p><ul>
<li>
If <em>yes</em>, then it goes away on the left-hand side. We get: <p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C%5Es+%5Cleq+f.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C^s \leq f. " class="latex" title="\displaystyle  C^s \leq f. " /></p>
<p>Since <img src="https://s0.wp.com/latex.php?latex=%7BC%5Es%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^s}" class="latex" title="{C^s}" /> is small, this is something we want. We got a small lower bound on <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> that holds for <b>all</b> arguments <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. </p>
</li><li>
If <em>no</em>, then it has a nontrivial clause corresponding to a set <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> of size at most <img src="https://s0.wp.com/latex.php?latex=%7Bs-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s-1}" class="latex" title="{s-1}" />. This is where the wraparound comes in. We have: <p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++D%5E%7B%3Cr%7D+%5Cleq+C%5E%7B%3Cs%7D+%5Cleq+E%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, " class="latex" title="\displaystyle  D^{&lt;r} \leq C^{&lt;s} \leq E, " /></p>
<p>since we chose at least one clause. Substituting on the right-hand side thus gives us: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f+%5Cleq+E+%5Cvee+D%5Er.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f \leq E \vee D^r. " class="latex" title="\displaystyle  f \leq E \vee D^r. " /></p>
<p>Now <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> is small, since it is just one clause, and <img src="https://s0.wp.com/latex.php?latex=%7BD%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^r}" class="latex" title="{D^r}" /> is small. We got a small upper bound rather than lower bound, but the fact that it has a restricted form and holds for <b>all</b> cases we can input to <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> will give us a lower bound on <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" />.
</p></li></ul>
<p>
Finally we are ready to state the theorem, which quantifies “small.” To follow Jukna, we now need to replace “<img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />” by “<img src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r+1}" class="latex" title="{r+1}" />” and “<img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" />” by “<img src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s+1}" class="latex" title="{s+1}" />.” But the essence is the same.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="tsimple"></a> If <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has a monotone Boolean circuit of size <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />, then for any <img src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r,s}" class="latex" title="{r,s}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B1+%5Cleq+r%2Cs+%5Cleq+n-1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{1 \leq r,s \leq n-1}" class="latex" title="{1 \leq r,s \leq n-1}" />, we can build a conjunction <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> of at most <img src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+r%5E%7Bs%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{t \cdot r^{s+1}}" class="latex" title="{t \cdot r^{s+1}}" /> clauses of size exactly <img src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{s+1}" class="latex" title="{s+1}" />, a disjunction <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> of at most <img src="https://s0.wp.com/latex.php?latex=%7Bt+%5Ccdot+s%5E%7Br%2B1%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{t \cdot s^{r+1}}" class="latex" title="{t \cdot s^{r+1}}" /> terms of size exactly <img src="https://s0.wp.com/latex.php?latex=%7Br%2B1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{r+1}" class="latex" title="{r+1}" />, and a set <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> of size at most <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> such that either <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{C \leq f}" class="latex" title="{C \leq f}" /> or <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f \leq D \cup E}" class="latex" title="{f \leq D \cup E}" />. </em>
</p></blockquote>
<p></p><p>
Rather than re-prove this, we will continue the discussion with a concrete example. An exposition trick is: give examples before the general case and then abstract. Our example will involve graphs <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />—so the variables have the form <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i,j}}" class="latex" title="{x_{i,j}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i,j} = 1}" class="latex" title="{x_{i,j} = 1}" /> means there is an edge between vertex <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and vertex <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%2Cj%7D+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i,j} = 0}" class="latex" title="{x_{i,j} = 0}" /> otherwise. Putting <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> as the number of vertices, the number of possible edges is <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+%5Cbinom%7Bm%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = \binom{m}{2}}" class="latex" title="{n = \binom{m}{2}}" />. We think of <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> as a set of edges, so <img src="https://s0.wp.com/latex.php?latex=%7BG+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G \subseteq [n]}" class="latex" title="{G \subseteq [n]}" />.</p>
<p>
</p><p></p><h2> Checking for Triangles </h2><p></p>
<p></p><p>
Let <img src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(G)=1}" class="latex" title="{f(G)=1}" /> hold precisely when <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> has a triangle. This is clearly a monotone property. Our goal is to use the lower and upper bounds to prove that the monotone complexity of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(G)}" class="latex" title="{f(G)}" /> is almost of order <img src="https://s0.wp.com/latex.php?latex=%7Bm%5E%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m^{3}}" class="latex" title="{m^{3}}" />. A side note is that the general complexity is much less via <img src="https://s0.wp.com/latex.php?latex=%7Bm+%5Ctimes+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m \times m}" class="latex" title="{m \times m}" /> matrix products. </p>
<p>
The first beauty of using the method is that <em>you</em> get to choose the parameters <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> with a goal <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> in mind. The <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> must be in <img src="https://s0.wp.com/latex.php?latex=%7B%5B1%2Cn-1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[1,n-1]}" class="latex" title="{[1,n-1]}" />. The value of <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> will be a lower bound on the size of any monotone boolean circuit for <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" />. The parameters <img src="https://s0.wp.com/latex.php?latex=%7Br%2Cs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r,s}" class="latex" title="{r,s}" /> are bounds on the clause and term size of the DNF and the CNF. You can select them any way you wish. But of course choose them wisely.</p>
<p>
In this case we know that <img src="https://s0.wp.com/latex.php?latex=%7Br%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r=1}" class="latex" title="{r=1}" /> is a right choice. We will say what <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> is later but we will have <img src="https://s0.wp.com/latex.php?latex=%7Bs%3D%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s=(\log n)^{O(1)}}" class="latex" title="{s=(\log n)^{O(1)}}" />. Once you pick them, the CNF <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> and DNF <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> (and small set <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" />, a set of <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log n)}" class="latex" title="{O(\log n)}" /> edges in this case) are chosen for you. You have no control over the sets <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> that make up the terms of <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> and the sets <img src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_\ell}" class="latex" title="{C_\ell}" /> that correspond to the clauses of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. Well you do know something about them. Here is what you do know about how many sets there are and how big the sets are:</p>
<ol>
<li>
For <img src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%2C%5Cdots%2Ct+%5Ccdot+s%5E%7Br%2B1%7D+%3D+ts%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k=1,\dots,t \cdot s^{r+1} = ts^2}" class="latex" title="{k=1,\dots,t \cdot s^{r+1} = ts^2}" />, each <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> is of size <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />. <p></p>
</li><li>
For <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%3D1%2C%5Cdots%2C+t+%5Ccdot+r%5E%7Bs%2B1%7D+%3D+t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell=1,\dots, t \cdot r^{s+1} = t}" class="latex" title="{\ell=1,\dots, t \cdot r^{s+1} = t}" />, each <img src="https://s0.wp.com/latex.php?latex=%7BC_%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_\ell}" class="latex" title="{C_\ell}" /> is of size <img src="https://s0.wp.com/latex.php?latex=%7Bs%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s+1}" class="latex" title="{s+1}" />.
</li></ol>
<p>The goal in either case is to force <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> to be large. We’ve numbered the right-hand case first.</p>
<ol>
<li>
Case <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Cleq+D+%5Ccup+E%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f \leq D \cup E}" class="latex" title="{f \leq D \cup E}" />. Here we want to consider graphs <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> that <b>do</b> have a triangle—and nothing else. Because <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> includes at most <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> edges, hence touches at most <img src="https://s0.wp.com/latex.php?latex=%7B2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2s}" class="latex" title="{2s}" /> vertices, and <img src="https://s0.wp.com/latex.php?latex=%7B2s+%5Cll+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2s \ll m}" class="latex" title="{2s \ll m}" />, we can focus on triangles among the <img src="https://s0.wp.com/latex.php?latex=%7Bm%27+%3D+m+-+2s%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m' = m - 2s}" class="latex" title="{m' = m - 2s}" /> untouched vertices. There are <img src="https://s0.wp.com/latex.php?latex=%7BT+%3D+%5Cbinom%7Bm%27%7D%7B3%7D+%3D+%5CTheta%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T = \binom{m'}{3} = \Theta(m^3)}" class="latex" title="{T = \binom{m'}{3} = \Theta(m^3)}" /> such triangles, hence <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> graphs <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> to consider.<p></p>
<p>
Since these graphs <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> have no edges in <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> but make <img src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(G) = 1}" class="latex" title="{f(G) = 1}" />, there must be some <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BT_k%28G%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k(G) = 1}" class="latex" title="{T_k(G) = 1}" />. Since <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> has size <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />, this means <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> has two edges of the triangle. Now the point is:</p>
<blockquote><p><b> </b> <em> For each <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" />, there is at most <b>one</b> triangle that <img src="https://s0.wp.com/latex.php?latex=%7BT_k%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{T_k}" class="latex" title="{T_k}" /> can be two edges of. </em>
</p></blockquote>
<p></p><p>
Hence there must be at least as many terms as possible triangles. This means: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++ts%5E2+%5Cgeq+%5Cbinom%7Bm%27%7D%7B3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  ts^2 \geq \binom{m'}{3}. " class="latex" title="\displaystyle  ts^2 \geq \binom{m'}{3}. " /></p>
<p>Because <img src="https://s0.wp.com/latex.php?latex=%7Bs+%3D+%28%5Clog+n%29%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s = (\log n)^{O(1)}}" class="latex" title="{s = (\log n)^{O(1)}}" />, we finally get <img src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t = \tilde{\Omega}(m^3)}" class="latex" title="{t = \tilde{\Omega}(m^3)}" />, where the tilde means to ignore factors of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log n}" class="latex" title="{\log n}" />.</p>
<p></p></li><li>
Case <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C \leq f}" class="latex" title="{C \leq f}" />. Here we want to consider graphs <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bf%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(G) = 0}" class="latex" title="{f(G) = 0}" /> but <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is chock full of as many edges as one can have without creating a triangle. Such <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> include complete bipartite graphs. There are <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm-1%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{m-1} - 1}" class="latex" title="{2^{m-1} - 1}" /> such graph inputs, as can be realized from how any binary string <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> except <img src="https://s0.wp.com/latex.php?latex=%7B0%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0^m}" class="latex" title="{0^m}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B1%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1^m}" class="latex" title="{1^m}" /> encodes such a graph—and only its bit-complement <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> encodes the same labeled graph.<p></p>
<p>
In order to keep <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Cleq+f%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C \leq f}" class="latex" title="{C \leq f}" /> we need <img src="https://s0.wp.com/latex.php?latex=%7BC%28G%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C(G) = 0}" class="latex" title="{C(G) = 0}" /> for all such <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />, so we need (at least) one clause <img src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_k}" class="latex" title="{C_k}" /> to <em>fail</em> on <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" />. This means that all vertices touched by the edges in <img src="https://s0.wp.com/latex.php?latex=%7BC_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_k}" class="latex" title="{C_k}" /> must be in the same partition. The more vertices touched, the fewer strings <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> have all <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />s (or all <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />s) in the corresponding positions, which means the fewer graphs <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> “covered” by that clause. We want to know how many clauses we need to cover all these graphs, hence we try to minimize the number of vertices touched by each clause. That number is at least <img src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3D+%5Clceil+%5Csqrt%7B2s%7D%5Crceil%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s' = \lceil \sqrt{2s}\rceil}" class="latex" title="{s' = \lceil \sqrt{2s}\rceil}" />. The number of graphs we cover is at most <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bm+-+s%27%7D+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{m - s'} - 1}" class="latex" title="{2^{m - s'} - 1}" /> (the <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> excludes the empty graph). Thus the number <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> of clauses we need satisfies </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++t+%5Cgeq+%5Cfrac%7B2%5E%7Bm-1%7D+-+1%7D%7B2%5E%7Bm+-+s%27%7D+-+1%7D+%5Cgeq+2%5E%7Bs%27+-+1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. " class="latex" title="\displaystyle  t \geq \frac{2^{m-1} - 1}{2^{m - s'} - 1} \geq 2^{s' - 1}. " /></p>
<p>By taking <img src="https://s0.wp.com/latex.php?latex=%7Bs%27+%3E+4.5%5Clog%5E2+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s' &gt; 4.5\log^2 m}" class="latex" title="{s' &gt; 4.5\log^2 m}" /> we can make <img src="https://s0.wp.com/latex.php?latex=%7Bt+%5Cgeq+m%5E3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t \geq m^3}" class="latex" title="{t \geq m^3}" /> in this case. We can actually get bigger functions with bigger <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" />, but this balances against case 1 where <img src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+%5Ctilde%7B%5COmega%7D%28m%5E3%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t = \tilde{\Omega}(m^3)}" class="latex" title="{t = \tilde{\Omega}(m^3)}" /> was the best we could do, so that is our lower bound.
</p></li></ol>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Does this help in understanding the approximation method? Can you work out the concretely optimum choice of <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> in the triangle example?</p>
<p>
Would you prefer not changing <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> in the statement of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a>? Then we would have worded the triangle example with “<img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = 2}" class="latex" title="{r = 2}" />” rather than “<img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = 1}" class="latex" title="{r = 1}" />.” The former is a little more suggestive of the idea of having two edges of a triangle. Doing so, however, could make notation in the proof of Theorem <a href="https://rjlipton.wordpress.com/feed/#tsimple">2</a> somewhat messier. Another possibility was keeping Jukna’s usage throughout, so that the earlier version <a href="https://rjlipton.wordpress.com/feed/#informal">1</a> of the theorem would say <img src="https://s0.wp.com/latex.php?latex=%7BD%5E%7B%5Cleq+r%7D+%5Cleq+C%5E%7B%5Cleq+s%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^{\leq r} \leq C^{\leq s}}" class="latex" title="{D^{\leq r} \leq C^{\leq s}}" /> with <img src="https://s0.wp.com/latex.php?latex=%7BC%5E%7Bs%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C^{s+1}}" class="latex" title="{C^{s+1}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD%5E%7Br%2B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D^{r+1}}" class="latex" title="{D^{r+1}}" /> being small. We try to solve “exposition problems” in every post but feel a dilemma here. Comments might help us on a followup post. </p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2020/07/27/a-brilliant-book-on-combinatorics/"><span class="datestr">at July 27, 2020 06:39 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3389282706697250678">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html">Do computers make us more safe or less safe?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Norbert Weiner wrote a paper <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/moral.pdf">Some Moral and Technical Consequences of Automation</a> in 1960. It warns of the dangers of computers in two ways:<br />
<br />
1) If a chess program is only trained against expert chess players then it might get confused if its opponent makes a bad move. This is not dangerous. But imagine a nuclear missle system that assumes the opponent is rational. If the opponent is not rational then it might launch and have an accidental nuclear war. So <i>there must be a human component </i>so that this won't happen.<br />
<br />
I offer a story and a counter narrative. In the 5th season, 23rd episode of the TV show Castle,<br />
title <i>The Human Factor </i>a character had the following story to tell:<br />
<i><br />
The drone on its own was going to bomb a car. But the human noticed that there were red roses on the car, so it was a wedding couple, not a terrorist. If a human had not been involved the drone may have killed an innocent just married couple!</i><br />
<br />
This scene bothered me. It could EASILY be the other way around: the human wants to bomb and the drone (which has better vision) notices the roses. Or there may be many other ways that a computer could be BETTER than a human. I am not saying that a completely automated system is better, I am saying that its not obvious which way to go.  Both in some combination? What combination? Who has the final say? And in the drone scenario there may not be time for a human to consider the options.<br />
<br />
2) The Sorcerer's apprentice scenario. In The Sorcerer's Apprentice segment of the (original) movie Fantasia, Mickey mouse tells a broom to get him a glass of water. The broom keeps bringing him water and Mickey almost drowns. Computers may take orders to literally and not stop. I wonder if  automated stock-trading and automated auctions may have this problem. Is there a case known where this really did cause a problem?<div><br /></div><div>So what do you think?</div><div><br /></div><div>NOW- do computers (or, more generally technology) make us more safe or less safe?</div><div><br /></div><div>FUTURE- same question.</div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/07/do-computers-make-us-more-safe-or-less.html"><span class="datestr">at July 27, 2020 03:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2020/07/27/discrete-fragility/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2020/07/27/discrete-fragility/">Digital Witnesses</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Doyle derived his LQG counterexample in the time before the ubiquity of numerical computing. This meant that numerical examples did not carry the rhetorical weight of algebraic closed form instances. The need for clean, persuasive formulae also meant that controllers were idealized in continuous time. Continuous-time optimal control often produced policies that couldn’t be implemented because of the limits of physical reality: no system can act instantaneously with arbitrary power. These issues of infeasibility were <a href="https://ieeexplore.ieee.org/document/1099822/">certainly noted in the literature</a> during the hey day of optimal control, but continuous time models still often made it difficult to pinpoint these issues.</p>

<p>Discrete-time models don’t share many of these issues. In discrete time, we explicitly encode the sequential, computational nature of decision and control. Discrete-time formulae are unfortunately less elegant than their continuous-time counterparts, but, as I hope to show here, they are often more revealing. Indeed, constructing examples where discrete-time optimal control leads to fragile solutions seems to be surprisingly easy.</p>

<p>Here, I’ll highlight a few examples where relatively innocuous problem formulations lead to very fragile control policies. The examples are weirdly simple and almost comical to a point. But anyone who has played with discrete-time optimal control may have stumbled into similar control policies and had to step back and think about why.</p>

<p>Let’s revisit the discrete-time LQR problem:</p>



<p>We again assume $x_t$ is observed perfectly without noise. While such perfect state information is not realistic, even ideal state feedback ends up being fragile in discrete time. $w_t$ is assumed to be stochastic, but I don’t think much changes if we move to a more adversarial setting. Here, we need the decision variable $u_t$ to be <em>causal</em>. It must be a function of only the values $x_s$ and $u_s$ with $s\leq t$. For stochastic disturbances, the optimal $u$ can always be found by dynamic programming.</p>

<p>Consider the following innocuous dynamics:</p>



<p>This system is a simple, two-state shift register. I’ll write the state out with indexed components $x=[x^{(1)},x^{(2)}]^\top$. New states enter through the control $B$ into the second state. The first state, $x^{(1)}$ is simply whatever was in the second register at the previous time step. The open loop dynamics of this system are as stable as you could imagine. Both eigenvalues of $A$ are zero.</p>

<p>Let’s say our control objective aims to try to keep the two states equal to each other. We can model this with the quadratic cost:</p>



<p>I assume $R=0$ here for simplicity, as the formulae are particularly nice for this case. But, as I will discuss in a moment, the situation is not improved simply by having $R$ be positive. For the disturbance, assume that $w_t$ is zero mean, has bounded second moment, $\Sigma_t = \mathbb{E}[w_t w_t^\top]$, and is uncorrelated with $x_t$ and $u_t$.</p>

<p>The cost is asking to minimize</p>



<p>When $w_t=0$, $x_t^{(1)}+x_t^{(2)} = x_{t-1}^{(2)}+u_{t-1}$, so it seems like our best bet is to just set $u_{t}=x_t^{(2)}$. This turns out to be the optimal action, and you can prove this directly using standard dynamic programming computations. What this means is that the closed loop dynamics of the system are</p>



<p>This closed-loop system is <em>marginally stable</em>, meaning that while signals don’t blow up, some states will persist forever and not converge to $0$. Indeed, the state-transition matrix here has eigenvalues $0$ and $1$. The $1$ corresponds the state where the two components are equal, and such a state can persist forever.</p>

<p>If we learned an incorrect model of the dynamics, how would that influence the closed loop behavior? The simplest scenario is that we identified $B$ from some preliminary experiments. We can immediately see that if the true $B_\star=\alpha B $, then the closed loop dynamics are</p>



<p>This system is unstable for any $\alpha&gt;1$. That is, the system is arbitrarily sensitive to misidentification of the dynamics. Note that this lack of robustness has nothing to do with the noise sequence. The structure of the cost is what drives the system to fragility.</p>

<p>If $R&gt;0$, you will get a slightly different policy. Again, using elementary dynamic programming shows that the optimal control is $u_t=\beta_t(R) x_t^{(2)}$ for some $\beta_t(R) \in (1/2,1)$. The closed loop system will be a bit more stable, but this comes at the price of reduced performance. And, at best, the gain margin of this system approaches $2$ as $R$ goes to infinity. You can also check that if you add $\epsilon$ times the identity to $Q$, you again get a control policy proportional to $x_t^{(2)}$.</p>

<p>This behavior can occur in even simpler systems. Consider the one-state linear system</p>



<p>The open loop system is again as stable as it gets. Now let’s aim to minimize $\Vert x-u \Vert$. It doesn’t matter what norm you choose here or whether you treat the noise as stochastic or worst case with respect to $w$, the optimal control is going to be $u_t = x_t/b$. Once again, the closed loop system has a pole at $1$ and is arbitrary fragile to misspecification of $b$.</p>

<p>I could continue to construct nasty examples, but I hope these examples are sufficiently illustrative. They are certainly contrived and pathological, and it’s not at all clear that they reflect any optimal control problem you might have been hoping to solve. However, both examples involve systems that are robust and stable in open loop. It’s only when we close the feedback loop that we end up in a dangerous situation. That simple optimal control problems give some profoundly fragile solutions should be a clear warning: <em>You can’t just optimize and hope to be robust.</em> You have to consider uncertainty as a first class citizen when designing feedback systems.</p>

<p>In some sense, the core contribution of robust control is in raising awareness of fundamental tradeoffs in the design of feedback systems. Optimal control promises that you can roughly identify a system, model uncertainty as noise, solve an optimization problem,  and then ship your policy. Hopefully, the examples in the last two posts have shown why this particular approach is fraught with danger.</p>

<p>If failure of a feedback system has any consequences, then a more holistic robust approach is <em>necessary</em>. We have to work with experts at different levels of the engineering pipeline, worry about unmodeled behaviors, and understand hard limits and practical tradeoffs. That is, engineering has to be more concerned with <em>design</em> than with <em>optimization.</em></p>

<p>There are all sorts of questions that a robust, systems level engineering effort might ask. Where should you put that extra sensor? Which parts of the system are likely to create issues? Is it possible to avoid performance disruptions when updating a single component in a legacy system? These questions are important in all aspects of system engineering, and developing accessible tools for addressing them in machine learning systems remains a daunting but essential challenge.</p>

<p>I am emphatically not saying that the design of feedback systems is hopeless. It’s easy to walk away with the impression “Ben’s examples are pathologies and unlike what I see in practice” or the pessimistic feeling of “shoot, all of this ML stuff is hopeless, I’m going to go work on something tractable like vaccine development.” I’m not saying that engineering robust machine learning systems is hopeless. I’m just saying that our community has to work better to incorporate multiple levels of uncertainty in its thinking. What are the fundamental tradeoffs between performance and robustness in machine learning? What do we even want to be robust to? In the next post I want to describe some of these robustness tradeoffs without using the language of optimization, probing if that provides some possible paths forward.</p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2020/07/27/discrete-fragility/"><span class="datestr">at July 27, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2020-07-26-private-set-intersection-2/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2020-07-26-private-set-intersection-2/">Private Set Intersection #2</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In the first post on Private Set Intersection, I presented the problem of Private Set Intersection, its applications and the simple protocol of [KMRS14], that allows Alice and Bob to learn the intersection of their sets with the aid of an untrusted third party Steve who is assumed to not...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2020-07-26-private-set-intersection-2/"><span class="datestr">at July 26, 2020 11:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/111">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/111">TR20-111 |  Lifting: As Easy As 1,2,3 | 

	Ian Mertz, 

	Toniann Pitassi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Query-to-communication lifting theorems translate lower bounds on query complexity to lower bounds for the corresponding communication model. In this paper, we give a simplified proof of deterministic lifting (in both the tree-like and dag-like settings). Whereas previous proofs used sophisticated Fourier analytic techniques, our proof uses elementary counting together with the sunflower lemma.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/111"><span class="datestr">at July 25, 2020 05:05 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8081773524220393104">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/07/virtual-complexity.html">Virtual Complexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The <a href="https://computationalcomplexity.org/Archive/2020/fullsite/">Complexity Complexity Conference</a>, the conference that shares its name and URL with this blog, originally scheduled for Saarbrücken will be held virtually next week. Registration is free for non-authors. <a href="https://www.youtube.com/channel/UCXgNLnzWOP4bM2-xfHDHUrw">Talks</a> are already posted. Looking forward to seeing you at the business meeting and the social.<br />
<div>
<br /></div>
<div>
<div>
Award winners have already been announced: The Best Student Paper Award goes to Rahul Ilango for <a href="https://drops.dagstuhl.de/opus/volltexte/2020/12583/">Connecting Perebor Conjectures: Towards a Search to Decision Reduction for Minimizing Formulas</a> and the Best Paper Award goes to Daniel Dadush and Samarth Tiwari for <a href="https://drops.dagstuhl.de/opus/volltexte/2020/12586/">On the Complexity of Branching Proofs</a>.</div>
</div>
<div>
<br /></div>
<div>
Virtual conferences give an opportunity for far more people to attend since you don't have the expense and time needed to go to Germany. On the other hand it's hard to dedicate time for a conference when you aren't there. I missed STOC which would have been walking distance from where I live but I did attend parts of the <a href="http://ec20.sigecom.org/">Economics and Computation</a> conference which was supposed to be in Budapest. EC made great use of <a href="http://gather.town/">gather.town</a> where you can wander around virtual rooms bumping into and talking to people. I caught up with a few people there. Complexity plans to use gather for its social meeting next week. Looking forward to the virtual beer.</div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/07/virtual-complexity.html"><span class="datestr">at July 24, 2020 04:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19859">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/">Noam Lifshitz: A new hypercontractivity inequality — The proof!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>This is a guest post kindly contributed by Noam Lifshitz</em>. <em>Here is a <a href="https://gilkalai.files.wordpress.com/2020/07/proof-of-hypercontractivity.pdf">pdf version</a>.  This post is a continuation of the post  </em><a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/" rel="bookmark">To cheer you up in difficult times 3: A guest post by Noam Lifshitz on the new hypercontractivity inequality of Peter Keevash, Noam Lifshitz, Eoin Long and Dor Minzer</a>, <em>and it gives the proof of the new hypercontractive inequality. We plan a third post where various applications will be mentioned.</em></p>
<p>Before we get to the post I want to mention that there are a lot of activities on the web. I may devote a special post to links and discussion (and contributing links in the comment section is very welcome.) but meanwhile a few links:  1) <a href="https://simons.berkeley.edu/events/boolean">Advances in Boolean Function Analysis Lecture Series</a> (thanks to Avishay Tal and Prasad Raghavendra for letting me know); 2) <a href="https://math216.wordpress.com/agittoc-2020/">Online course in Foundations of Algebraic Geometry</a> Given by Ravi Vakil from Stanford. You can take the course at varying levels of involvement. (Thanks to Tami Ziegler for telling me) A very very interesting way of online teaching. 3) <a href="https://researchseminars.org/">A site with online mathematical lectures.</a></p>
<h2><img width="640" alt="Bonami" src="https://gilkalai.files.wordpress.com/2020/07/bonami.jpg?w=640&amp;h=480" class="alignnone size-full wp-image-19984" height="480" /></h2>
<p><span style="color: #ff0000;">Aline Bonami with Szilard Revesz and me (2006). Aline Bonami first proved the 2-point hypercontractive inequality which is very useful in the analysis of Boolean functions. (Leonard Gross proved it independently a few years later and William Beckner found important applications to harmonic analysis.)</span></p>
<h2>Proof of the new hypercontractivity inequality</h2>
<p>Our aim is to prove the hypercontractivity theorem for global functions. The proof here is taken from a joint paper with David Ellis and Guy Kindler that’ll soon be out on the Arxiv.</p>
<h3><strong>Theorem 1:</strong></h3>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B1%2F100%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5E%7BS%7D%7D%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|\mathrm{T}_{1/100}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\in\left\{ 1,\ldots,m\right\} ^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}, " class="latex" title="\displaystyle \|\mathrm{T}_{1/100}f\|_{4}^{4}\le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\in\left\{ 1,\ldots,m\right\} ^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}, " /></p>
<p>Here we use the notations given in the <a href="https://gilkalai.wordpress.com/2020/05/08/to-cheer-you-up-in-difficult-times-3-a-guest-post-by-noam-lifshitz-on-the-new-hypercontractivity-inequality-of-peter-keevash-noam-lifshitz-eoin-long-and-dor-minzer/">last blog post</a>. Let us first get a feel for our hypercontractivity theorem by proving the <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=1}" class="latex" title="{n=1}" /> case. Here the RHS is <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}.}" class="latex" title="{\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}.}" /></p>
<h3>1. Proof of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=1}" class="latex" title="{n=1}" /> case</h3>
<p>We will prove the following slightly stronger version of Theorem 1 for the <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=1}" class="latex" title="{n=1}" /> case.</p>
<p><strong>Proposition 2:</strong></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%5Crightarrow%5Cmathbb%7BC%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\colon\left\{ 1,\ldots,m\right\} \rightarrow\mathbb{C}.}" class="latex" title="{f\colon\left\{ 1,\ldots,m\right\} \rightarrow\mathbb{C}.}" /> Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho\le\frac{1}{10}.}" class="latex" title="{\rho\le\frac{1}{10}.}" /> Then<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " class="latex" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " /></p>
<p style="text-align: left;"><strong>Proof</strong>: Let us write <img src="https://s0.wp.com/latex.php?latex=%7BL%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L\left[f\right]}" class="latex" title="{L\left[f\right]}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BL_%7B1%7D%5Cleft%5Bf%5Cright%5D%3Df-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{1}\left[f\right]=f-\mathbb{E}\left[f\right].}" class="latex" title="{L_{1}\left[f\right]=f-\mathbb{E}\left[f\right].}" /> Rearranging, we have<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2BL%5Cleft%5Bf%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle f=\mathbb{E}\left[f\right]+L\left[f\right]. " class="latex" title="\displaystyle f=\mathbb{E}\left[f\right]+L\left[f\right]. " /><br />
The noise operator in the <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=1}" class="latex" title="{n=1}" /> case is by definition equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho+Id%2B%5Cleft%281-%5Crho%5Cright%29%5Cmathbb%7BE%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho Id+\left(1-\rho\right)\mathbb{E},}" class="latex" title="{\rho Id+\left(1-\rho\right)\mathbb{E},}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{E}}" class="latex" title="{\mathbb{E}}" /> is the expectation over <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7B%5Censuremath%7B%5Cleft%5C%7B+1%2C%5Cldots%2Cm%5Cright%5C%7D+%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{\ensuremath{\left\{ 1,\ldots,m\right\} }}}" class="latex" title="{\text{\ensuremath{\left\{ 1,\ldots,m\right\} }}}" /> operator, and <img src="https://s0.wp.com/latex.php?latex=%7BId%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Id}" class="latex" title="{Id}" /> is the identity operator. Hence,<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BT%7D_%7B%5Crho%7Df%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Crho+L%5Bf%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathrm{T}_{\rho}f=\mathbb{E}\left[f\right]+\rho L[f]. " class="latex" title="\displaystyle \mathrm{T}_{\rho}f=\mathbb{E}\left[f\right]+\rho L[f]. " /></p>
<p>Now when expanding the 4-norm of the function <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C%5Cmathrm%7BT%7D_%7B1%2F100%7Df%5C%7C_%7B4%7D%5E%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|\mathrm{T}_{1/100}f\|_{4}^{4}}" class="latex" title="{\|\mathrm{T}_{1/100}f\|_{4}^{4}}" />, we obtain</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%C2%A0+%5Cle%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}  \le\left|\mathbb{E}\left[f\right]\right|^{4}" class="latex" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}  \le\left|\mathbb{E}\left[f\right]\right|^{4}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B6%5Crho%5E%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5C%7CLf%5C%7C_%7B2%7D%5E%7B2%7D%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle +6\rho^{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|Lf\|_{2}^{2}+" class="latex" title="\displaystyle +6\rho^{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|Lf\|_{2}^{2}+" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%2B4%5Crho%5E%7B3%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D%2B&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle  +4\rho^{3}\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}+" class="latex" title="\displaystyle  +4\rho^{3}\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}+" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B+%5Crho%5E%7B4%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle + \rho^{4}\|L\left[f\right]\|_{4}^{4}," class="latex" title="\displaystyle + \rho^{4}\|L\left[f\right]\|_{4}^{4}," /></p>
<p>where we used the fact that the expectation of <img src="https://s0.wp.com/latex.php?latex=%7BL%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L\left[f\right]}" class="latex" title="{L\left[f\right]}" /> is 0. When looking at the right hand side of the global hypercontractivity theorem, we see most of the above terms except for the one involving the third norm of the Laplacian. Indeed we have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+RHS+%3D%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle RHS =\|f\|_{2}^{4}+\|L\left[f\right]\|_{4}^{4}" class="latex" title="\displaystyle RHS =\|f\|_{2}^{4}+\|L\left[f\right]\|_{4}^{4}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\left|\mathbb{E}\left[f\right]\right|^{4}" class="latex" title="\displaystyle =\left|\mathbb{E}\left[f\right]\right|^{4}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B2%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle +2\|L\left[f\right]\|_{2}^{2}\left|\mathbb{E}\left[f\right]\right|^{2}" class="latex" title="\displaystyle +2\|L\left[f\right]\|_{2}^{2}\left|\mathbb{E}\left[f\right]\right|^{2}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle +\|L\left[f\right]\|_{2}^{4}" class="latex" title="\displaystyle +\|L\left[f\right]\|_{2}^{4}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%2B%5C%7CL%5Ctext%7B%5Censuremath%7B%5Cleft%5Bf%5Cright%5D%5C%7C%7D%7D_%7B4%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle +\|L\text{\ensuremath{\left[f\right]\|}}_{4}^{4}." class="latex" title="\displaystyle +\|L\text{\ensuremath{\left[f\right]\|}}_{4}^{4}." /></p>
<p>Hence we see that the only term in the left hand side that doesn’t appear with a greater coefficient in the left hand side is the term <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3},}" class="latex" title="{\left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3},}" /> and by AM-GM we have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B3%7D%5E%7B3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}" class="latex" title="\displaystyle \left|\mathbb{E}\left[f\right]\right|\|L\left[f\right]\|_{3}^{3}" /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5Cleft%7CL%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B3%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\mathbb{E}\left[\left|\mathbb{E}\left[f\right]\right|\left|L\left[f\right]\right|^{3}\right]" class="latex" title="\displaystyle =\mathbb{E}\left[\left|\mathbb{E}\left[f\right]\right|\left|L\left[f\right]\right|^{3}\right]" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cle%5Cmathbb%7BE%7D%5Cleft%5B%5Cfrac%7B%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5Cleft%7CL%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%2B%5Cleft%7CL%5Ctext%7B%5Censuremath%7B%5Cleft%5Bf%5Cright%5D%7D%7D%5Cright%7C%5E%7B4%7D%7D%7B2%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \le\mathbb{E}\left[\frac{\left|\mathbb{E}\left[f\right]\right|^{2}\left|L\left[f\right]\right|^{2}+\left|L\text{\ensuremath{\left[f\right]}}\right|^{4}}{2}\right]" class="latex" title="\displaystyle \le\mathbb{E}\left[\frac{\left|\mathbb{E}\left[f\right]\right|^{2}\left|L\left[f\right]\right|^{2}+\left|L\text{\ensuremath{\left[f\right]}}\right|^{4}}{2}\right]" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cfrac%7B1%7D%7B2%7D%5Cleft%7C%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%7C%5E%7B2%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B2%7D%5E%7B2%7D%2B%5Cfrac%7B1%7D%7B2%7D%5C%7CL%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\frac{1}{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|L\left[f\right]\|_{2}^{2}+\frac{1}{2}\|L\left[f\right]\|_{4}^{4}, " class="latex" title="\displaystyle =\frac{1}{2}\left|\mathbb{E}\left[f\right]\right|^{2}\|L\left[f\right]\|_{2}^{2}+\frac{1}{2}\|L\left[f\right]\|_{4}^{4}, " /></p>
<p>which allows us to upper bound the only term appearing in the left hand side but not in the right hand side by corresponding terms that do appear in the right hand side. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<h3>2. Tensorisation lemma</h3>
<p>Next we are going to prove a theorem that doesn’t seem to fit to our setting, but we’re going to fit it in by force. Let <img src="https://s0.wp.com/latex.php?latex=%7BX%2CY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,Y}" class="latex" title="{X,Y}" /> be finite sets. Let us write <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}\left(X\right)}" class="latex" title="{\mathcal{F}\left(X\right)}" /> for the linear space of complex valued functions on <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. The space <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Ctimes+Y%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}\left(X\times Y\right)}" class="latex" title="{\mathcal{F}\left(X\times Y\right)}" /> can be identified with the space <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Cotimes%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}\left(X\right)\otimes\mathcal{F}\left(Y\right),}" class="latex" title="{\mathcal{F}\left(X\right)\otimes\mathcal{F}\left(Y\right),}" /> where a pair of function <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Cotimes+g%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\otimes g}" class="latex" title="{f\otimes g}" /> is identified with the function<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%28x%2Cy%5Cright%29%5Cmapsto+f%5Cleft%28x%5Cright%29g%5Cleft%28y%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \left(x,y\right)\mapsto f\left(x\right)g\left(y\right) " class="latex" title="\displaystyle \left(x,y\right)\mapsto f\left(x\right)g\left(y\right) " /><br />
in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BF%7D%5Cleft%28X%5Ctimes+Y%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{F}\left(X\times Y\right).}" class="latex" title="{\mathcal{F}\left(X\times Y\right).}" /></p>
<p>Given two operators <img src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B1%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B1%7D%5Cright%29%2CA_%7B2%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B2%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B2%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{1}\colon\mathcal{F}\left(X_{1}\right)\rightarrow\mathcal{F}\left(Y_{1}\right),A_{2}\colon\mathcal{F}\left(X_{2}\right)\rightarrow\mathcal{F}\left(Y_{2}\right)}" class="latex" title="{A_{1}\colon\mathcal{F}\left(X_{1}\right)\rightarrow\mathcal{F}\left(Y_{1}\right),A_{2}\colon\mathcal{F}\left(X_{2}\right)\rightarrow\mathcal{F}\left(Y_{2}\right)}" />, the operator <img src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X_%7B1%7D%5Ctimes+X_%7B2%7D%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y_%7B1%7D%5Ctimes+Y_%7B2%7D%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{1}\otimes A_{2}\colon\mathcal{F}\left(X_{1}\times X_{2}\right)\rightarrow\mathcal{F}\left(Y_{1}\times Y_{2}\right)}" class="latex" title="{A_{1}\otimes A_{2}\colon\mathcal{F}\left(X_{1}\times X_{2}\right)\rightarrow\mathcal{F}\left(Y_{1}\times Y_{2}\right)}" /> is the unique operator sending <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Cotimes+g%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\otimes g}" class="latex" title="{f\otimes g}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7Df%5Cotimes+A_%7B2%7Dg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{1}f\otimes A_{2}g}" class="latex" title="{A_{1}f\otimes A_{2}g}" />. We write <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%7B%5Cotimes+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^{\otimes n}}" class="latex" title="{A^{\otimes n}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes%5Ccdots%5Cotimes+A.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A\otimes\cdots\otimes A.}" class="latex" title="{A\otimes\cdots\otimes A.}" /> The operator <img src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{1}\otimes A_{2}}" class="latex" title="{A_{1}\otimes A_{2}}" /> can also be defined more explictly in terms of its values on functions. The operator <img src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+A_%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{1}\otimes A_{2}}" class="latex" title="{A_{1}\otimes A_{2}}" /> can be understood more explicitly by noting that it is the composition of the operators <img src="https://s0.wp.com/latex.php?latex=%7BA_%7B1%7D%5Cotimes+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_{1}\otimes I}" class="latex" title="{A_{1}\otimes I}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BI%5Cotimes+A_%7B2%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{I\otimes A_{2}.}" class="latex" title="{I\otimes A_{2}.}" /> Now the operator <img src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes+I%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A\otimes I}" class="latex" title="{A\otimes I}" /> is given by <img src="https://s0.wp.com/latex.php?latex=%7BA%5Cotimes+If%5Cleft%28x%2Cy%5Cright%29%3DAf_%7By%7D%5Cleft%28x%5Cright%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A\otimes If\left(x,y\right)=Af_{y}\left(x\right),}" class="latex" title="{A\otimes If\left(x,y\right)=Af_{y}\left(x\right),}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bf_%7By%7D%5Cleft%28x%5Cright%29%3Df%5Cleft%28x%2Cy%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_{y}\left(x\right)=f\left(x,y\right).}" class="latex" title="{f_{y}\left(x\right)=f\left(x,y\right).}" /></p>
<p><strong>Lemma 3:</strong> Let <img src="https://s0.wp.com/latex.php?latex=%7BX%2CY%2CZ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,Y,Z}" class="latex" title="{X,Y,Z}" /> be measure spaces with finite underlying sets. Let <img src="https://s0.wp.com/latex.php?latex=%7BA%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%2CB%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Z%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right),B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Z\right)}" class="latex" title="{A\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right),B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Z\right)}" /> be operators satisfying</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7CAf%5C%7C_%7B4%7D%5Cle%5C%7CBf%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|Af\|_{4}\le\|Bf\|_{4} " class="latex" title="\displaystyle \|Af\|_{4}\le\|Bf\|_{4} " /></p>
<p>for all functions <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\in\mathcal{F}\left(X\right).}" class="latex" title="{f\in\mathcal{F}\left(X\right).}" /><br />
Then</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7CA%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D%5Cle%5C%7CB%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|A^{\otimes n}f\|_{4}\le\|B^{\otimes n}f\|_{4} " class="latex" title="\displaystyle \|A^{\otimes n}f\|_{4}\le\|B^{\otimes n}f\|_{4} " /></p>
<p>for all <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Cin%5Cmathcal%7BF%7D%5Cleft%28X%5E%7Bn%7D%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\in\mathcal{F}\left(X^{n}\right).}" class="latex" title="{f\in\mathcal{F}\left(X^{n}\right).}" /></p>
<p>Here the spaces <img src="https://s0.wp.com/latex.php?latex=%7BX%5E%7Bn%7D%2CY%5E%7Bn%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X^{n},Y^{n},}" class="latex" title="{X^{n},Y^{n},}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z^{n}}" class="latex" title="{Z^{n}}" /> are equipped with the product measure, where the measure of an atom is the product of the measures of its coordiates.</p>
<p><strong>Proof:</strong> For each <img src="https://s0.wp.com/latex.php?latex=%7By%5Cin+X%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y\in X,}" class="latex" title="{y\in X,}" /> let <img src="https://s0.wp.com/latex.php?latex=%7Bg_%7By%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_{y}}" class="latex" title="{g_{y}}" /> be given by <img src="https://s0.wp.com/latex.php?latex=%7Bg_%7By%7D%3A%3DA%5E%7B%5Cotimes%5Cleft%28n-1%5Cright%29%7Df%5Cleft%28%5Ccdot%2Cy%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_{y}:=A^{\otimes\left(n-1\right)}f\left(\cdot,y\right).}" class="latex" title="{g_{y}:=A^{\otimes\left(n-1\right)}f\left(\cdot,y\right).}" /> As mentioned <img src="https://s0.wp.com/latex.php?latex=%7BA%5E%7B%5Cotimes+n%7Df%5Cleft%28x%2Cy%5Cright%29%3DAg_%7By%7D%5Cleft%28x%5Cright%29.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A^{\otimes n}f\left(x,y\right)=Ag_{y}\left(x\right).}" class="latex" title="{A^{\otimes n}f\left(x,y\right)=Ag_{y}\left(x\right).}" /> Hence by hypothesis, we have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathbb%7BE%7D%5Cleft%5B%5Cleft%7C%5Cmathrm%7BA%7D%5E%7B%5Cotimes+n%7Df%5Cright%7C%5E%7B4%7D%5Cright%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \mathbb{E}\left[\left|\mathrm{A}^{\otimes n}f\right|^{4}\right]" class="latex" title="\displaystyle \mathbb{E}\left[\left|\mathrm{A}^{\otimes n}f\right|^{4}\right]" /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Cmathbb%7BE%7D_%7By%7D%5Cmathbb%7BE%7D_%7Bx%7D%5Cleft%7CAg_%7By%7D%5Cleft%28x%5Cright%29%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\mathbb{E}_{y}\mathbb{E}_{x}\left|Ag_{y}\left(x\right)\right|^{4}" class="latex" title="\displaystyle =\mathbb{E}_{y}\mathbb{E}_{x}\left|Ag_{y}\left(x\right)\right|^{4}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%5Cle%5Cmathbb%7BE%7D_%7By%7D%5Cmathbb%7BE%7D_%7Bx%7D%5Cleft%7CBg_%7By%7D%5Cleft%28x%5Cright%29%5Cright%7C%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle  \le\mathbb{E}_{y}\mathbb{E}_{x}\left|Bg_{y}\left(x\right)\right|^{4}" class="latex" title="\displaystyle  \le\mathbb{E}_{y}\mathbb{E}_{x}\left|Bg_{y}\left(x\right)\right|^{4}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5C%7CA%5E%7B%5Cotimes+n-1%7D%5Cotimes+B%5C%7C_%7B4%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\|A^{\otimes n-1}\otimes B\|_{4}^{4}." class="latex" title="\displaystyle =\|A^{\otimes n-1}\otimes B\|_{4}^{4}." /> We may now repeat the same process on each of the other coordinates to replace the <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />s by <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" />s one by one. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<h3>3. The main idea: Fourifying the 2-norms.</h3>
<p>The strategy of our proof is to take the theorem</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5Cle%5C%7Cf%5C%7C_%7B2%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}, " class="latex" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}\le\|f\|_{2}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}, " /></p>
<p>which we established in the <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=1}" class="latex" title="{n=1}" /> case for <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho\le\frac{1}{10}}" class="latex" title="{\rho\le\frac{1}{10}}" />, and to turn it into an essentially equivalent statement about 4-norms. We will then get a tensorised statement for general <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, which we will be able to convert back into our hypercontractivity theorem for global functions. Our idea is to encode our function <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> as a function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5Cleft%28f%5Cright%29%5Ccolon%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{En}\left(f\right)\colon\left\{ -1,1\right\} ^{n\left(p-1\right)}\rightarrow\mathbb{R}}" class="latex" title="{\mathrm{En}\left(f\right)\colon\left\{ -1,1\right\} ^{n\left(p-1\right)}\rightarrow\mathbb{R}}" /> satisfying</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BEn%7D%5Ccirc+T_%7B%5Crho%7D%3D%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Ccirc%5Cmathrm%7BEn%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathrm{En}\circ T_{\rho}=\mathrm{T}_{\rho}\circ\mathrm{En} " class="latex" title="\displaystyle \mathrm{En}\circ T_{\rho}=\mathrm{T}_{\rho}\circ\mathrm{En} " /></p>
<p>and</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B2%7D%3D%5C%7Cf%5C%7C_%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|\mathrm{En}f\|_{2}=\|f\|_{2}. " class="latex" title="\displaystyle \|\mathrm{En}f\|_{2}=\|f\|_{2}. " /></p>
<p>The benefit of working with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7Df%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{En}f}" class="latex" title="{\mathrm{En}f}" /> rather than <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is that in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{ 0,1\right\} ^{n\left(p-1\right)}}" class="latex" title="{\left\{ 0,1\right\} ^{n\left(p-1\right)}}" /> one may move between 4-norms and 2-norms by appealing to the hypercontractivity theorem there, which gives</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%5Ccirc%5Cmathrm%7BEn%7Df%5C%7C_%7B4%7D%5Cle%5C%7C%5Cmathrm%7BE%7Dnf%5C%7C_%7B2%7D%5Cle%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B4%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}\circ\mathrm{En}f\|_{4}\le\|\mathrm{E}nf\|_{2}\le\|\mathrm{En}f\|_{4} " class="latex" title="\displaystyle \|\mathrm{T}_{\frac{1}{\sqrt{3}}}\circ\mathrm{En}f\|_{4}\le\|\mathrm{E}nf\|_{2}\le\|\mathrm{En}f\|_{4} " /></p>
<p>at the cost of some noise.</p>
<p>To define <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{En}}" class="latex" title="{\mathrm{En}}" /> we use Fourier analysis of Abelian groups. Let us briefly recall it. For simplicity let us assume that <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BC%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C},}" class="latex" title="{f\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C},}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> is a prime. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Comega%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\omega}" class="latex" title="{\omega}" /> be a <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />th root of unity. For any <img src="https://s0.wp.com/latex.php?latex=%7B%5Cgamma%5Cin%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\gamma\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}}" class="latex" title="{\gamma\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}}" /> we have a character <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%5Ccolon%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7Bn%7D%5Crightarrow%5Cmathbb%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{\gamma}\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C}}" class="latex" title="{\chi_{\gamma}\colon\left(\mathbb{Z}/p\mathbb{Z}\right)^{n}\rightarrow\mathbb{C}}" /> given by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%5Cleft%28x%5Cright%29%3D%5Comega%5E%7B%5Cleft%5Clangle+%5Cgamma%2Cx%5Cright%5Crangle+%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{\gamma}\left(x\right)=\omega^{\left\langle \gamma,x\right\rangle }.}" class="latex" title="{\chi_{\gamma}\left(x\right)=\omega^{\left\langle \gamma,x\right\rangle }.}" /> The <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{\gamma}}" class="latex" title="{\chi_{\gamma}}" /> are an orthonormal basis of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cright%29%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left(\mathbb{Z}/p\right)^{n}}" class="latex" title="{\left(\mathbb{Z}/p\right)^{n}}" /> and we write <img src="https://s0.wp.com/latex.php?latex=%7Bf%3D%5Csum%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f=\sum\hat{f}\left(\gamma\right)\chi_{\gamma}}" class="latex" title="{f=\sum\hat{f}\left(\gamma\right)\chi_{\gamma}}" />, where <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%3D%5Cleft%5Clangle+f%2C%5Cchi_%7B%5Cgamma%7D%5Cright%5Crangle+.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat{f}\left(\gamma\right)=\left\langle f,\chi_{\gamma}\right\rangle .}" class="latex" title="{\hat{f}\left(\gamma\right)=\left\langle f,\chi_{\gamma}\right\rangle .}" /> Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{0}}" class="latex" title="{\chi_{0}}" /> is the constant function, and so we have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Chat%7Bf%7D%5Cleft%280%5Cright%29%3D%5Cleft%5Clangle+f%2C%5Cchi_%7B0%7D%5Cright%5Crangle+%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \hat{f}\left(0\right)=\left\langle f,\chi_{0}\right\rangle =\mathbb{E}\left[f\right], " class="latex" title="\displaystyle \hat{f}\left(0\right)=\left\langle f,\chi_{0}\right\rangle =\mathbb{E}\left[f\right], " /></p>
<p>which gives</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Csum%5Chat%7Bf%7D%5Cleft%28i%5Cright%29%5Cchi_%7Bi%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle f=\mathbb{E}\left[f\right]+\sum\hat{f}\left(i\right)\chi_{i}. " class="latex" title="\displaystyle f=\mathbb{E}\left[f\right]+\sum\hat{f}\left(i\right)\chi_{i}. " /></p>
<p>Our mission will first be to convert the <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />-norm of a function <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Crightarrow%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\colon\mathbb{Z}/p\rightarrow\mathbb{R}}" class="latex" title="{f\colon\mathbb{Z}/p\rightarrow\mathbb{R}}" /> to the <img src="https://s0.wp.com/latex.php?latex=%7B4-%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4-}" class="latex" title="{4-}" />norm of a different function.</p>
<p>We define an encoding operator <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Crightarrow%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{En}\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\left\{ -1,1\right\} ^{p-1}}" class="latex" title="{\mathrm{En}\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\left\{ -1,1\right\} ^{p-1}}" /> by setting</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%5Cmapsto%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%2B%5Csum_%7Bi%5Cin%5Cleft%5C%7B+1%2C%5Cldots%2Cp-1%5Cright%5C%7D+%7D%5Chat%7Bf%7D%5Cleft%28i%5Cright%29x_%7Bi%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle f\mapsto\mathbb{E}\left[f\right]+\sum_{i\in\left\{ 1,\ldots,p-1\right\} }\hat{f}\left(i\right)x_{i}. " class="latex" title="\displaystyle f\mapsto\mathbb{E}\left[f\right]+\sum_{i\in\left\{ 1,\ldots,p-1\right\} }\hat{f}\left(i\right)x_{i}. " /></p>
<p>We have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7Cf%5C%7C_%7B2%7D%5E%7B2%7D%3D%5C%7C%5Cmathrm%7BEn%7Df%5C%7C_%7B2%7D%5E%7B2%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|f\|_{2}^{2}=\|\mathrm{En}f\|_{2}^{2}, " class="latex" title="\displaystyle \|f\|_{2}^{2}=\|\mathrm{En}f\|_{2}^{2}, " /></p>
<p>as the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{i}}" class="latex" title="{\chi_{i}}" /> are orthonormal and so are the <img src="https://s0.wp.com/latex.php?latex=%7Bx_%7Bi%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_{i}.}" class="latex" title="{x_{i}.}" /> Moreover, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%5Ccirc%5Cmathrm%7BEn%7D%3D%5Cmathrm%7BEn%7D%5Ccirc+T_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{T}_{\rho}\circ\mathrm{En}=\mathrm{En}\circ T_{\rho}}" class="latex" title="{\mathrm{T}_{\rho}\circ\mathrm{En}=\mathrm{En}\circ T_{\rho}}" /> by the Fourier formula for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{T}_{\rho}.}" class="latex" title="{\mathrm{T}_{\rho}.}" /> Since <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />-norms are always smaller than 4-norms on probability spaces, we’ve got the following corollary of Proposition 2.</p>
<p><strong>Lemma 4.</strong> For all <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho\le\frac{1}{10}}" class="latex" title="{\rho\le\frac{1}{10}}" /> and all <img src="https://s0.wp.com/latex.php?latex=%7Bf%5Ccolon%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Crightarrow%5Cmathbb%7BC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\mathbb{C}}" class="latex" title="{f\colon\mathbb{Z}/p\mathbb{Z}\rightarrow\mathbb{C}}" /> we have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%5Cle%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28f%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2B%5C%7Cf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5C%7C_%7B4%7D%5E%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|\mathrm{En}\left(f\right)\|_{4}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " class="latex" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}\le\|\mathrm{En}\left(f\right)\|_{4}^{4}+\|f-\mathbb{E}\left[f\right]\|_{4}^{4}. " /></p>
<p>We now reach the final little trick. We define a measure space <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> whose underlying set is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Csqcup%5Cleft%5C%7B+0%2C1%5Cright%5C%7D+%5E%7B%5Cleft%5C%7B+p-1%5Cright%5C%7D+%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}/p\mathbb{Z}\sqcup\left\{ 0,1\right\} ^{\left\{ p-1\right\} },}" class="latex" title="{\mathbb{Z}/p\mathbb{Z}\sqcup\left\{ 0,1\right\} ^{\left\{ p-1\right\} },}" /> and where the measure is given by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%5Cleft%28i%5Cright%29%3D%5Cfrac%7B1%7D%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu\left(i\right)=\frac{1}{p}}" class="latex" title="{\mu\left(i\right)=\frac{1}{p}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bi%5Cin%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i\in\mathbb{Z}/p\mathbb{Z}}" class="latex" title="{i\in\mathbb{Z}/p\mathbb{Z}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%5Cleft%28x%5Cright%29%3D%5Cfrac%7B1%7D%7B2%7D%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu\left(x\right)=\frac{1}{2}^{p-1}}" class="latex" title="{\mu\left(x\right)=\frac{1}{2}^{p-1}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bx%5Cin%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x\in\left\{ -1,1\right\} ^{p-1}.}" class="latex" title="{x\in\left\{ -1,1\right\} ^{p-1}.}" /> We let <img src="https://s0.wp.com/latex.php?latex=%7BB%5Ccolon%5Cmathcal%7BF%7D%5Cleft%28X%5Cright%29%5Crightarrow%5Cmathcal%7BF%7D%5Cleft%28Y%5Cright%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right)}" class="latex" title="{B\colon\mathcal{F}\left(X\right)\rightarrow\mathcal{F}\left(Y\right)}" /> be given by <img src="https://s0.wp.com/latex.php?latex=%7BBf%3D%5Cmathrm%7BEn%7Df%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Bf=\mathrm{En}f}" class="latex" title="{Bf=\mathrm{En}f}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{ -1,1\right\} ^{p-1}}" class="latex" title="{\left\{ -1,1\right\} ^{p-1}}" /> and letting it be <img src="https://s0.wp.com/latex.php?latex=%7Bf-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f-\mathbb{E}\left[f\right]}" class="latex" title="{f-\mathbb{E}\left[f\right]}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}/p\mathbb{Z}.}" class="latex" title="{\mathbb{Z}/p\mathbb{Z}.}" /> This way Lemma 4 takes the form <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5Cle%5C%7CBf%5C%7C_%7B4%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|\mathrm{T}_{\rho}f\|_{4}\le\|Bf\|_{4}.}" class="latex" title="{\|\mathrm{T}_{\rho}f\|_{4}\le\|Bf\|_{4}.}" /></p>
<h3>4. Tensorised operators</h3>
<p>The operator <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{T}_{\rho}}" class="latex" title="{\mathrm{T}_{\rho}}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}/p\mathbb{Z}^{n}}" class="latex" title="{\mathbb{Z}/p\mathbb{Z}^{n}}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%3D%5Cmathrm%7BT%7D_%7B%5Crho%7D%5E%7B%5Cotimes+n%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{T}_{\rho}=\mathrm{T}_{\rho}^{\otimes n},}" class="latex" title="{\mathrm{T}_{\rho}=\mathrm{T}_{\rho}^{\otimes n},}" /> where the latter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT%7D_%7B%5Crho%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{T}_{\rho}}" class="latex" title="{\mathrm{T}_{\rho}}" /> refers to the noise operator on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D%2Fp.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Z}/p.}" class="latex" title="{\mathbb{Z}/p.}" /> The characters <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{\gamma}}" class="latex" title="{\chi_{\gamma}}" /> satisfy <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi_%7B%5Cgamma%7D%3D%5Cbigotimes%5Cchi_%7B%5Cgamma_%7Bi%7D%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\chi_{\gamma}=\bigotimes\chi_{\gamma_{i}},}" class="latex" title="{\chi_{\gamma}=\bigotimes\chi_{\gamma_{i}},}" /> and so we have the Fourier formula</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathrm%7BT%7D_%7B%5Crho%7Df%C2%A0+%3D%5Csum_%7B%5Cgamma%7D%5Crho%5E%7B%5C%23%5Cleft%5C%7B+i%3A%5Cgamma_%7Bi%7D%5Cne0%5Cright%5C%7D+%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D.+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \mathrm{T}_{\rho}f  =\sum_{\gamma}\rho^{\#\left\{ i:\gamma_{i}\ne0\right\} }\hat{f}\left(\gamma\right)\chi_{\gamma}. " class="latex" title="\displaystyle \mathrm{T}_{\rho}f  =\sum_{\gamma}\rho^{\#\left\{ i:\gamma_{i}\ne0\right\} }\hat{f}\left(\gamma\right)\chi_{\gamma}. " /></p>
<p>We also have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5Bf%5Cright%5D%3D%5Cbigotimes_%7Bi%5Cin+S%7D%5Cleft%28f%5Cmapsto+f-%5Cmathbb%7BE%7D%5Cleft%5Bf%5Cright%5D%5Cright%29%5Cotimes%5Cbigotimes_%7Bi%5Cnotin+S%7DId%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle L_{S}\left[f\right]=\bigotimes_{i\in S}\left(f\mapsto f-\mathbb{E}\left[f\right]\right)\otimes\bigotimes_{i\notin S}Id, " class="latex" title="\displaystyle L_{S}\left[f\right]=\bigotimes_{i\in S}\left(f\mapsto f-\mathbb{E}\left[f\right]\right)\otimes\bigotimes_{i\notin S}Id, " /></p>
<p>and so</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5Bf%5Cright%5D%3D%5Csum_%7B%5Cgamma%3A%5Cgamma_%7Bi%7D%5Cne0%5Ctext%7B+for+all+%7Di%5Cin+S%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle L_{S}\left[f\right]=\sum_{\gamma:\gamma_{i}\ne0\text{ for all }i\in S}\hat{f}\left(\gamma\right)\chi_{\gamma}. " class="latex" title="\displaystyle L_{S}\left[f\right]=\sum_{\gamma:\gamma_{i}\ne0\text{ for all }i\in S}\hat{f}\left(\gamma\right)\chi_{\gamma}. " /></p>
<p>This will allow us to conclude that</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L_%7BS%7D%5Cleft%5B%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5Cright%5D_%7BS%5Crightarrow+x%7D%3D%5Crho%5E%7B%5Cleft%7CS%5Cright%7C%7DT_%7B%5Crho%7DL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}T_{\rho}L_{S}[f]_{S\rightarrow x}. " class="latex" title="\displaystyle L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}T_{\rho}L_{S}[f]_{S\rightarrow x}. " /></p>
<p>We will also encounter the operator <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%5E%7B%5Cotimes+n%7D%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{En}^{\otimes n},}" class="latex" title="{\mathrm{En}^{\otimes n},}" /> which by abusing notation we also call <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{En}}" class="latex" title="{\mathrm{En}}" /> encodes</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f%3D%5Csum_%7B%5Cgamma%7D%5Chat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cchi_%7B%5Cgamma%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle f=\sum_{\gamma}\hat{f}\left(\gamma\right)\chi_{\gamma} " class="latex" title="\displaystyle f=\sum_{\gamma}\hat{f}\left(\gamma\right)\chi_{\gamma} " /></p>
<p>as the function <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_%7B%5Cgamma%7D%5Cwidehat%7Bf%7D%5Cleft%28%5Cgamma%5Cright%29%5Cprod_%7Bi%3D1%7D%5E%7Bn%7Dx_%7Bpi%2B%5Cgamma_%7Bi%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_{\gamma}\widehat{f}\left(\gamma\right)\prod_{i=1}^{n}x_{pi+\gamma_{i}}}" class="latex" title="{\sum_{\gamma}\widehat{f}\left(\gamma\right)\prod_{i=1}^{n}x_{pi+\gamma_{i}}}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%5Cleft%28p-1%5Cright%29%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\left\{ -1,1\right\} ^{n\left(p-1\right)}.}" class="latex" title="{\left\{ -1,1\right\} ^{n\left(p-1\right)}.}" /><br />
Now finally we can get to the understanding of the operator <img src="https://s0.wp.com/latex.php?latex=%7BB%5E%7B%5Cotimes+n%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B^{\otimes n}.}" class="latex" title="{B^{\otimes n}.}" /> The space <img src="https://s0.wp.com/latex.php?latex=%7BY%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y^{n}}" class="latex" title="{Y^{n}}" /> is the disjoint union of <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{n}}" class="latex" title="{2^{n}}" /> spaces of the form</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7BS%7D%5Ctimes%5Cleft%28%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%5Cright%29%5E%7B%5Cleft%5Bn%5Cright%5D%5Csetminus+S%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}. " class="latex" title="\displaystyle \left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}. " /></p>
<p>By definition of the tensor product, for <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%5Cin%5Cleft%28%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5Cright%29%5E%7BS%7D%5Ctimes%5Cleft%28%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bp-1%7D%5Cright%29%5E%7B%5Cleft%5Bn%5Cright%5D%5Csetminus+S%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}}" class="latex" title="{x,y\in\left(\mathbb{Z}/p\mathbb{Z}\right)^{S}\times\left(\left\{ -1,1\right\} ^{p-1}\right)^{\left[n\right]\setminus S}}" /> is the function</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+B%5E%7Bn%7Df%5Cleft%28x%2Cy%5Cright%29%3D%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5Cleft%28y%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle B^{n}f\left(x,y\right)=\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\left(y\right). " class="latex" title="\displaystyle B^{n}f\left(x,y\right)=\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\left(y\right). " /></p>
<h3>5. Finishing the proof</h3>
<p><strong>Proof:</strong> Lemmas 3 and 4 yield:</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5C%7C_%7B4%7D%5E%7B4%7D%C2%A0+%5Cle%5C%7CB%5E%7B%5Cotimes+n%7Df%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}  \le\|B^{\otimes n}f\|_{4}^{4}" class="latex" title="\displaystyle \|\mathrm{T}_{\rho}f\|_{4}^{4}  \le\|B^{\otimes n}f\|_{4}^{4}" /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{4}^{4}," class="latex" title="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{4}^{4}," /></p>
<p>for any <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho%5Cle%5Cfrac%7B1%7D%7B10%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho\le\frac{1}{10}.}" class="latex" title="{\rho\le\frac{1}{10}.}" /> We now have</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B%5Crho%7D%7B%5Csqrt%7B3%7D%7D%7Df%5C%7C_%7B4%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \|\mathrm{T}_{\frac{\rho}{\sqrt{3}}}f\|_{4}^{4}" class="latex" title="\displaystyle \|\mathrm{T}_{\frac{\rho}{\sqrt{3}}}f\|_{4}^{4}" /> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%28%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%29%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BT%7D_%7B%5Cfrac%7B1%7D%7B%5Csqrt%7B3%7D%7D%7D%5Cleft%28%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5Cright%29%5C%7C_%7B4%7D%5E%7B4%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\sum_{S\subseteq\left[n\right]}(\frac{1}{\sqrt{3}})^{\left|S\right|}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{T}_{\frac{1}{\sqrt{3}}}\left(\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\right)\|_{4}^{4}," class="latex" title="\displaystyle =\sum_{S\subseteq\left[n\right]}(\frac{1}{\sqrt{3}})^{\left|S\right|}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{T}_{\frac{1}{\sqrt{3}}}\left(\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\right)\|_{4}^{4}," /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%C2%A0+%5Cle%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7C%5Cmathrm%7BEn%7D%5Cleft%28L_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5Cright%29%5C%7C_%7B2%7D%5E%7B4%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle  \le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{2}^{4}" class="latex" title="\displaystyle  \le\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|\mathrm{En}\left(L_{S}[f]_{S\rightarrow x}\right)\|_{2}^{4}" /><br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%3D%5Csum_%7BS%5Csubseteq%5Cleft%5Bn%5Cright%5D%7D%5Cmathbb%7BE%7D_%7Bx%5Csim%5Cmathbb%7BZ%7D%2Fp%5Cmathbb%7BZ%7D%5E%7BS%7D%7D%5C%7CL_%7BS%7D%5Bf%5D_%7BS%5Crightarrow+x%7D%5C%7C_%7B2%7D%5E%7B4%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}." class="latex" title="\displaystyle =\sum_{S\subseteq\left[n\right]}\mathbb{E}_{x\sim\mathbb{Z}/p\mathbb{Z}^{S}}\|L_{S}[f]_{S\rightarrow x}\|_{2}^{4}." /></p>
<p>The first equality follows from the formula <img src="https://s0.wp.com/latex.php?latex=%7BL_%7BS%7D%5Cleft%5B%5Cmathrm%7BT%7D_%7B%5Crho%7Df%5Cright%5D_%7BS%5Crightarrow+x%7D%3D%5Crho%5E%7B%5Cleft%7CS%5Cright%7C%7D%5Cmathrm%7BT%7D_%7B%5Crho%7DL_%7BS%7D%5Cleft%5Bf%5Cright%5D_%7BS%5Crightarrow+x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}\mathrm{T}_{\rho}L_{S}\left[f\right]_{S\rightarrow x}}" class="latex" title="{L_{S}\left[\mathrm{T}_{\rho}f\right]_{S\rightarrow x}=\rho^{\left|S\right|}\mathrm{T}_{\rho}L_{S}\left[f\right]_{S\rightarrow x}}" /> and the fact that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BT_%7B%5Crho%7D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{T_{\rho}}}" class="latex" title="{\mathrm{T_{\rho}}}" /> commutes with the encoding. The inequality used hypercontractivity on the discrete cube. The last equality follows from the fact that the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BEn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{En}}" class="latex" title="{\mathrm{En}}" /> operator preserves 2-norms. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/07/24/noam-lifshitz-a-new-hypercontractivity-inequality-the-proof/"><span class="datestr">at July 24, 2020 03:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7779">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/07/24/ryan-odonnels-tcs-toolkit-and-other-resources/">Ryan O’Donnell’s “TCS Toolkit” and other resources</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>When I was in grad school a common advice for beginning grad students was to leaf through the (paper) STOC or FOCS proceedings to see papers that you are interested in. This is still a decent advice (and requires less physical strength these days <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /> ) but papers are not always the best source for people starting out. More often than we’d like to, the author of the 10th paper on a topic writes it to the audience of people that read (in fact probably wrote) the previous 9 papers.</p>



<p>Talks often do a better job of giving an overview of the field, and one great resource is the <a href="https://simons.berkeley.edu/videos">videos</a> from the Simons Institute. If you want to get more in-depth information about a particular topic, it’s hard to beat the extended surveys in <a href="https://www.nowpublishers.com/TCS">Foundations and Trends in TCS</a>, as well as the related areas such as <a href="https://www.nowpublishers.com/MAL">Machine Learning</a> and <a href="https://www.nowpublishers.com/CIT">Information Theory</a>. </p>



<p>But if you are not yet sure what topic you’re interested in, or perhaps not even sure if you want to go to grad school, but you just know that you are interested in theory, there is now a new great resource. As I learned from <a href="https://twitter.com/BooleanAnalysis/status/1286658578049359873">Twitter</a>, Ryan O’Donnell has just finished his <a href="https://www.diderot.one/course/28/">TCS Toolkit course</a>. All 99(!) lectures are on <a href="https://www.youtube.com/watch?v=prI35GmCon4&amp;list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX">YouTube</a>.</p>



<p>The topics are the following (these links are to the handwritten notes, for the lecture videos see <a href="https://www.youtube.com/watch?v=prI35GmCon4&amp;list=PLm3J0oaFux3ZYpFLwwrlv_EHH9wtH6pnX">YouTube channel</a>):</p>



<p><a href="https://www.diderot.one/course/28/chapters/1824/">1.   Course Overview, and How to TCS</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1881/">2.   Basic Asymptotics</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1889/">3.   Factorials and Binomial Coefficients</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1923/">4.   Central Limit Theorem</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1956/">5.   Chernoff Bounds</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1973/">6.   Computational Models</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1981/">7.   Fast Multiplication with the DFT</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/1990/">8.   Analysis of Boolean Functions</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2003/">9.   Quantum Computation</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2037/">10.   Fields and Polynomials</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2038/">11.   Error-Correcting Codes</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2064/">12.   Derandomization</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2065/">13.   Spectral Graph Theory I</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2094/">14.   Spectral Graph Theory II</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2099/">15.   Spectral Graph Theory III</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2101/">15.1.   Cheeger’s Inequality (Spectral Graph Theory bonus)</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2112/">16.   Expander Graphs</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2149/">17.   Linear Programming I</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2162/">18.   Linear Programming II</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2173/">19.   The Ellipsoid Algorithm</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2190/">20.   CSPs and Approximation</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2197/">21.   LP Hierarchies and Proof Systems</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2209/">22.   Treewidth</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2227/">23.   Communication Complexity</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2250/">24.   Information Theory</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2251/">25.   Cryptography</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2290/">26.   Hardness Assumptions</a></p>



<p><a href="https://www.diderot.one/course/28/chapters/2291/">27.   The PCP Theorem</a></p>



<p>p.s. For giving a high level taste of theory to beginning undergraduates, a great resource is Aaronson’s <a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing since Democritus</a> or <a href="https://www.math.ias.edu/avi/book">Wigderson’s Math and Computation</a> if they’re more math inclined. </p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/07/24/ryan-odonnels-tcs-toolkit-and-other-resources/"><span class="datestr">at July 24, 2020 02:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4916">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4916">The Busy Beaver Frontier</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong><span class="has-inline-color has-vivid-red-color">Update (July 27):</span></strong> I now have a <a href="https://www.scottaaronson.com/papers/bb.pdf">substantially revised and expanded version</a>, which incorporates (among other things) the extensive feedback that I got from this blog post.  There are new philosophical remarks, some lovely new open problems, and an <em>even-faster-growing</em> (!) integer sequence.  Check it out!</p>



<p></p><hr /><p></p>



<p>A life that was all covid, cancellations, and Trump, all desperate rearguard defense of the beleaguered ideals of the Enlightenment, would hardly be worth living.  So it was an exquisite delight, these past two weeks, to forget current events and write an <a href="https://www.scottaaronson.com/papers/bb.pdf">18-page survey article</a> about the <a href="https://en.wikipedia.org/wiki/Busy_beaver">Busy Beaver function</a>: the staggeringly quickly-growing function that probably encodes a huge portion of all interesting mathematical truth in its first hundred values, if only we could know those values or exploit them if we did.</p>



<p>Without further ado, here’s the title, abstract, and link:</p>



<blockquote class="wp-block-quote"><p><a href="https://www.scottaaronson.com/papers/bb.pdf"><strong>The Busy Beaver Frontier</strong></a><br />by Scott Aaronson</p><p>The Busy Beaver function, with its incomprehensibly rapid growth, has captivated generations of computer scientists, mathematicians, and hobbyists.  In this survey, I offer a personal view of the BB function 58 years after its introduction, emphasizing lesser-known insights, recent progress, and especially favorite open problems.  Examples of such problems include: when does the BB function first exceed the Ackermann function?  Is the value of BB(20) independent of set theory?  Can we prove that BB(n+1)&gt;2<sup>BB(n)</sup> for large enough n?  Given BB(n), how many advice bits are needed to compute BB(n+1)?  Do all Busy Beavers halt on all inputs, not just the 0 input?  Is it decidable whether BB(n) is even or odd?</p></blockquote>



<p>The article is slated to appear soon in <em>SIGACT News</em>.  I’m grateful to Bill Gasarch for suggesting it—even with everything else going on, this was a commission I felt I couldn’t turn down!</p>



<p>Besides Bill, I’m grateful to the various Busy Beaver experts who answered my inquiries, to Marijn Heule and Andy Drucker for suggesting some of the open problems, to Marijn for creating a figure, and to Lily, my 7-year-old daughter, for raising the question about the first value of n at which the Busy Beaver function exceeds the Ackermann function.  (Yes, Lily’s covid homeschooling has included multiple lessons on very large positive integers.)</p>



<p>There are still a few days until I have to deliver the final version. So if you spot anything wrong or in need of improvement, don’t hesitate to leave a comment or send an email.  Thanks in advance!</p>



<p>Of course Busy Beaver has been an obsession that I’ve returned to many times in my life: for example, in that <a href="https://www.scottaaronson.com/writings/bignumbers.html">Who Can Name the Bigger Number?</a> essay that I wrote way back when I was 18, in <em><a href="https://www.amazon.com/Quantum-Computing-since-Democritus-Aaronson/dp/0521199565">Quantum Computing Since Democritus</a></em>, in my <a href="https://www.scottaaronson.com/blog/?p=3445">public lecture at Festivaletteratura</a>, and in my <a href="https://www.scottaaronson.com/blog/?p=2725">2016 paper with Adam Yedidia</a> that showed that the values of all Busy Beaver numbers beyond the 7910<sup>th</sup> are independent of the axioms of set theory (Stefan O’Rear has since shown that independence starts at the 748<sup>th</sup> value or sooner).  This survey, however, represents the first time I’ve tried to take stock of BusyBeaverology <em>as a research topic</em>—collecting in one place all the lesser-known theorems and empirical observations and open problems that I found the most striking, in the hope of inspiring not just contemplation or wonderment but actual progress.</p>



<p>Within the last few months, the world of <em>deep mathematics that you can actually explain to a child</em> lost two of its greatest giants: <a href="https://en.wikipedia.org/wiki/John_Horton_Conway">John Conway</a> (who died of covid, and who I <a href="https://www.scottaaronson.com/blog/?p=4732">eulogized here</a>) and <a href="https://en.wikipedia.org/wiki/Ronald_Graham">Ron Graham</a>.  One thing I found poignant, and that I didn’t know before I started writing, is that Conway and Graham <em>both</em> play significant roles in the story of the Busy Beaver function.  Conway, because most of the best known candidates for Busy Beaver Turing machines turn out, when you analyze them, to be testing variants of the notorious <a href="https://en.wikipedia.org/wiki/Collatz_conjecture">Collatz Conjecture</a>—and Conway is the one who proved, in 1972, that the set of “Collatz-like questions” is Turing-undecidable.  And Graham because of <a href="https://en.wikipedia.org/wiki/Graham%27s_number">Graham’s number</a> from <a href="https://en.wikipedia.org/wiki/Ramsey_theory">Ramsey theory</a>—a candidate for the biggest number that’s ever played a role in mathematical research—and because of the <a href="https://googology.wikia.org/wiki/User_blog:Wythagoras/The_nineteenth_Busy_Beaver_number_is_greater_than_Graham%27s_Number!">discovery</a>, four years ago, that the 18<sup>th</sup> Busy Beaver number exceeds Graham’s number.</p>



<p>(“Just how big is Graham’s number?  So big that the <em>17<sup>th</sup> Busy Beaver number</em> is not yet known to exceed it!”)</p>



<p>Anyway, I tried to make the survey pretty accessible, while still providing enough technical content to sink one’s two overgrown front teeth into (don’t worry, there are no such puns in the piece itself).  I hope you like reading it at least 1/BB(10) as much as I liked writing it.</p>



<p><strong><span class="has-inline-color has-vivid-red-color">Update (July 24):</span></strong> Longtime commenter Joshua Zelinsky gently reminded me that one of the main questions discussed in the survey—namely, whether we can prove BB(n+1)&gt;2<sup>BB(n)</sup> for all large enough n—was <a href="https://www.scottaaronson.com/blog/?p=1385#comment-73298">first brought to my attention</a> by him, Joshua, in a 2013 Ask-Me-Anything session on this blog!  I apologize to Joshua for the major oversight, which has now been corrected.  On the positive side, we just got a powerful demonstration <em>both</em> of the intellectual benefits of blogging, and of the benefits of sharing paper drafts on one’s blog before sending them to the editor!</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4916"><span class="datestr">at July 23, 2020 06:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/07/23/tenure-track-or-tenured-faculty-positions-at-center-on-frontiers-of-computing-studies-peking-university-apply-by-september-30-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/07/23/tenure-track-or-tenured-faculty-positions-at-center-on-frontiers-of-computing-studies-peking-university-apply-by-september-30-2020/">Tenure-track or Tenured Faculty Positions at Center on Frontiers of Computing Studies, Peking University (apply by September 30, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Center on Frontiers of Computing Studies (CFCS), Peking University (PKU), China, is a university new initiative co-founded by Professors John Hopcroft and Wen Gao.</p>
<p>We are seeking applicants from all areas of Computer Science, spanning theoretical foundations, systems, software, and applications, with special interests in artificial intelligence and machine learning.</p>
<p>Website: <a href="https://cfcs.pku.edu.cn/english/people/joinus/236979.htm">https://cfcs.pku.edu.cn/english/people/joinus/236979.htm</a><br />
Email: cfcs_recruiting@pku.edu.cn</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/07/23/tenure-track-or-tenured-faculty-positions-at-center-on-frontiers-of-computing-studies-peking-university-apply-by-september-30-2020/"><span class="datestr">at July 23, 2020 02:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/07/22/three-cccg-videos">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html">Three CCCG videos</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Three new ten-minute research talk videos by me are now up on YouTube as part of the collection of videos to be presented in the 2020 Canadian Conference on Computational Geometry. The <a href="http://vga.usask.ca/cccg2020/program.pdf">pdf conference program</a> has links to all the videos. The conference includes an opportunity to interact with the speakers online, on the August 5–7 dates of the actual conference, with free registration at <a href="http://vga.usask.ca/cccg2020/">the CCCG web site</a>.</p>

<p>My three videos are on <a href="https://11011110.github.io/blog/2020/07/16/comparing-multi-sport.html">dynamic products of ranks, discussed in my previous post</a>, polyhedra that are difficult to unfold, and mathematics inspired by <a href="https://en.wikipedia.org/wiki/Lusona">the sona drawings of southwest Africa</a>. For your convenience here they are more directly:</p>

<div style="text-align: center;">

<p> </p>

<p> </p>

<p> </p>
</div>

<p>(Apologies for the weird aspect ratio. I should probably aim for a more standard 16x9 format in future.)</p>

<p>I also have a fourth CCCG paper, on unfolding orthogonal polyhedra, with a video produced by Joe O’Rourke. I posted about its preprint version, “<a href="https://11011110.github.io/blog/2019/07/29/zipless-polycube.html">Some polycubes have no edge-unzipping</a>”, a year ago. Here’s Joe’s talk:</p>

<div style="text-align: center;">
<p> </p>

</div></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/07/22/three-cccg-videos.html"><span class="datestr">at July 22, 2020 02:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/average-case-dp/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/average-case-dp/">The Pitfalls of Average-Case Differential Privacy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Differential privacy protects against extremely strong adversaries—even ones who know the entire dataset except for one bit of information about one individual.  Since its inception, people have considered ways to relax the definition to assume a more realistic adversary.  A natural way to do so is to incorporate some distributional assumptions. That is, rather than considering a worst-case dataset, assume the dataset is drawn from some distribution and provide some form of “average-case” or “Bayesian” privacy guarantee with respect to this distribution. This is especially tempting as it is common for statistical analysis to work under distributional assumptions.</p>

<p>In this post and in a planned follow-up post, we will discuss some pitfalls of average-case or Bayesian versions of differential privacy.  To avoid keeping you in suspense:</p>

<ul>
  <li>The average-case assumptions in relaxations of differential privacy are qualitatively different to and much more brittle than the typical assumptions made about how the data is generated.</li>
  <li>Average-case relaxations do not satisfy the strong composition properties that have made differential privacy so successful.</li>
  <li>It is safer to use distributional assumptions in the accuracy analysis instead of the privacy analysis. That is, we can provide average-case utility and worst-case privacy. Recent work has shown that this model can capture most of the advantages of distributional assumptions.</li>
</ul>

<p>We will show some illustrative examples for each of these points, but we will be purposefully vague as to exactly which alternative definition we are considering, as these issues arise in a wide variety of definitions.  Our hope is not to shut down discussion of these relaxations, or to single out specific definitions as flawed.  There are specific concrete applications where average-case differential privacy might be useful, and our goal is to highlight some issues that must be carefully considered in each application.</p>

<h3 id="assumptions-about-nature-vs-assumptions-about-the-adversary">Assumptions about nature vs. assumptions about the adversary?</h3>

<p>In any reasonable definition of privacy, we have to think about whom we are hiding sensitive information from.  This person—“the adversary”—could be a stranger, a close friend, a relative, a corporation we do business with, or the government, and who they are affects what information they have access to and what defenses are appropriate.   How the adversary can access the private system defines the <a href="https://differentialprivacy.org/\trustmodels">trust model</a>. Distributional assumptions correspond to the adversary’s side information.  Our key point is:</p>

<blockquote>
  <p>Assumptions incorporated into the definition of privacy are assumptions about the adversary and these are qualitatively different from assumptions about “nature,” which is the process that generates the data.</p>
</blockquote>

<p>For example, suppose an employer learns that two of its employees have expensive medical conditions. On its own, this information does not identify those employees and this privacy intuition could be formalized via distributional assumptions. But these distributional assumptions will break if the employer later receives some side information. For example, the other healthy employees may voluntarily disclose their medical status or the employer may find out that, before you were hired, that number was only one. (Incidentally, this is an example of a failure of composition, which we will discuss in another post.)</p>

<p>This example illustrates how assumptions about the adversary that might seem reasonable in a vacuum can be invalidated by context. Plus, assumptions about the adversary can be invalidated by <em>future</em> side information, and you can’t retract a privacy leak once it happens the way you can a medical study. So assumptions about the adversary are much less future-proof than assumptions about nature.</p>

<h3 id="all-models-are-wrong-but-some-are-useful">All models are wrong, but some are useful</h3>

<p>One justification for incorporating distributional assumptions into the privacy definition is that the person using the data is often making these assumptions anyway—for example, that the data is i.i.d. Gaussian, or that two variables have some underlying linear relationship to be discovered.  So, if the assumption were false, wouldn’t we already be in trouble?  Not really.</p>

<blockquote>
  <p>It’s important to remember the old saw “all models are wrong, but some are useful.”  Some models have proven themselves useful for statistical purposes, but that does not mean they are useful as a basis for privacy.</p>
</blockquote>

<p>For example, our methods may be robust to the relatively friendly ways that nature deviates from the model, but we can’t trust adversaries to be as friendly.</p>

<p>For a toy example, suppose we model our data as coming from a normal distribution \( N(\mu,\sigma^2) \), but actually the data is collected at two different testing centers, one of which rounds its measurements to the nearest integer and the other of which provides two decimal places of precision.  This rounding makes the model wrong, but won’t significantly affect our estimate of the mean.  However, just looking at the estimate of the mean might reveal that someone in the dataset went to the second testing center, potentially compromising that person’s privacy.</p>

<p>A more natural setting where this issue arises is in dealing with <em>outliers</em> or other extreme examples, which we will discuss in the next section.</p>

<h3 id="privacy-for-outliers">Privacy for outliers</h3>

<p>The usual worst-case definition of differential privacy provides privacy for everyone, including outliers.  Although there are lots of ways to achieve differential privacy, in order to compare definitions, it will help to restrict attention to the basic approach based on calibrating noise to sensitivity:</p>

<p>Suppose we have a private dataset \( x \in \mathcal{X}^n \) containing the data of \( n \) individuals, and some real-valued query \( q : \mathcal{X}^n \to \mathbb{R} \).  The standard way to release an estimate of \( q(x) \) is to compute
\[
M(x) = q(x) + Z \cdot \sup_{\textrm{neighboring}~x’,x”} |q(x’) - q(x”)|
\]
where 
\(
\sup_{\textrm{neighboring}~x’,x”} |q(x’) - q(x”)|
\)
is called the “worst-case sensitivity” of \( q \) and \( Z \) is some noise, commonly drawn from a Laplace or Gaussian distribution.</p>

<p>Unfortunately, the worst-case sensitivity may be large or even infinite for basic statistics of interest, such as the mean \( q(x) = \frac{1}{n} \sum_{i} x_i \) of unbounded real values.  There are a variety of differentially private algorithms for addressing this problem,<sup id="fnref:1"><a href="https://differentialprivacy.org/feed.xml#fn:1" class="footnote">1</a></sup> but that is not what this post is about.  It’s tempting to, instead, try to scale the noise to some notion of “average-case sensitivity,” with the goal of satisfying some average-case version of differential privacy.  For example, suppose the data is drawn from some normal distribution \( N(\mu,\sigma^2) \) and the neighboring datasets \( x', x'' \) are each \( n \) i.i.d. samples from this distribution, but differing on exactly one random sample.  Then the worst-case sensitivity of the mean is infinite:
\[
\sup_{\textrm{neighboring}~x’,x”} |q(x’) - q(x”)| = \infty,
\]
but the average-sensitivity is proportional to \(1/n\):
\[
\mathbb{E}_{\textrm{neighboring}~x’, x”}(|q(x’) - q(x”)|) \approx \frac{\sigma}{n}.
\]
Thus, under an average-case privacy guarantee, we can estimate the mean with very little noise.</p>

<p>But what happens to privacy if this assumption fails, perhaps because of outliers?  Imagine computing the average wealth of a subset of one hundred Amazon employees who test positive for COVID-19, and discovering that it’s over one billion dollars.  Maybe Jeff Bezos isn’t feeling well?<sup id="fnref:2"><a href="https://differentialprivacy.org/feed.xml#fn:2" class="footnote">2</a></sup></p>

<p>Yes, this example is a little contrived, since you probably shouldn’t have computed the empirical mean of such skewed data anyway. But, if this fact leaks out, you can’t just go back in time and truncate the data or compute the median instead. Privacy tends to be high-stakes both because of the potential consequences of a breach and the inability to retract or correct a privacy violation after it is discovered.</p>

<p>In the next section we’ll see a slightly more complex example where average-case privacy / average-case sensitivity fails to protect privacy even when the distributional assumptions hold.</p>

<h3 id="example-pairwise-correlations-and-linear-regression">Example: pairwise correlations and linear regression</h3>

<p>Suppose our dataset \( X \) is a matrix \( \{-1,+1\}^{n \times (d+1)} \) where each row \( X_i \) corresponds to one person’s data and each column corresponds to one feature.  For simplicity, let’s suppose our distributional assumption is that the dataset is completely uniform—each bit is sampled independently and uniformly from \( \{-1,+1\} \).  We’ll think of the first \( d \) columns as “features” and the last column as a “secret label.”</p>

<p>First, consider the set of pairwise correlations between each feature and the secret label:
\[
q_j(X) = \sum_{i = 1}^{n} X_{i,j} X_{i,d+1}
\]
for \( j = 1,\dots,d \).  Note that \( q_j(X) \) has mean 0 and variance \( n \) under our distributional model of the data.</p>

<p>Now, suppose we have a weight vector \( w \in \mathbb{R}^{d} \) and want to estimate the weighted average of correlations
\[
q(X) = \sum_{j = 1}^{d} w_j q_j(X) = \sum_{i=1}^{n} \sum_{j=1}^{d} w_{j} X_{i,j} X_{i,d+1}
\]
This statistic may look a little odd, but it’s pretty close to computing the average squared error of the linear predictor \( \hat X_{i,d+1} = \sum_{j=1}^{d} w_j X_{i,j} \) given by the weight vector \( w \), which is a natural thing to estimate.</p>

<p>The worst-case sensitivity of \(q\) is proportional to \( \|w\|_1 \).<br />
However, it’s not too hard to show that, under our distributional model, the average-case sensitivity is much lower; it is proportional to \( \| w \|_2 \).  Thus, using average-case privacy may allow us to add significantly less noise.</p>

<p>What could go wrong here?  Well, we’ve implicitly assumed that the weights \( w \) are independent of the data \( X \).  That is, the person specifying the weights has no knowledge of the data itself, only its distribution.  Suppose the weights are specified by an adversary who has learned the \( d \) features of the first individual (although there is nothing special about considering the first individual), who sets the weights to \(w = (X_{1,1},\dots,X_{1,d}) \).  Another calculation shows that, in this case, <em>even when our model of the data is exactly correct</em>, the query \( q(X) \) has mean \( d \cdot X_{1,d+1} \) and standard deviation approximately \( \sqrt{nd} \).  Thus, if \( d \gg n \) we can confidently determine the secret label \( X_{1,d+1} \)  of the first individual from the value \( q(X) \).  Moreover, adding noise of standard deviation \( \ll d \) will not significantly affect the adversary’s ability to learn the secret label.  But, earlier, we argued that average-case sensitivity is proportional to \( \|w \|_2 = \sqrt{d} \), so this form of average-case privacy fails to protect a user’s data in this scenario!  Note that adding noise proportional to \( \|w\|_1 = d \) would satisfy (worst-case) differential privacy and would thwart this adversary.</p>

<blockquote>
  <p>What went wrong is that the data satisfied our assumptions, but the adversary’s beliefs about the data did not!</p>
</blockquote>

<p>The set of reasonable distributions to consider for the adversary’s beliefs may look very different from the set of reasonable distributions to consider for your analysis of the data.  You may think that it’s not reasonable for the attacker to choose this weight vector \( w \) containing a lot of prior information about an individual, but assuming that the attacker cannot obtain or specify such a vector is very different from assuming that the data is uniform, and requires its own justification.</p>

<p>Before wrapping up, let’s just make a couple more observations about this example:</p>

<ul>
  <li>This attack is pretty robust. The assumption that the data is uniform with independent features can be relaxed significantly.  It’s also not necessary for the adversary to exactly know all the features of the first user, all we need is for the weights to have correlation \( \gg \sqrt{nd} \) with the features.  For example, if the dataset is genomic data, having the data of a relative might suffice.</li>
  <li>This problem isn’t specific to high-dimensional data with \( d \gg n \).  If we allow more general types of “queries”, then a similar attack is possible when there are only \( d \approx \log n \) features.</li>
  <li>To make this example as crisp as possible, we allowed an adversarial data analyst to specify the weight vector \( w \).  You might think examples like this can’t arise if the algorithm designer specifies all of the queries internally, but ensuring that requires great care (as we’ll see in our upcoming post about composition).</li>
</ul>

<h3 id="conclusion">Conclusion</h3>
<p>As we have discussed, the main issue that arises in average-case or Bayesian versions of differential privacy is that we must make strong assumptions about the adversary. A simple distributional assumption about the data, which may be entirely reasonable for statistical analysis, entails assuming a naïve adversary with essentially no side information, which is not reasonable from a privacy perspective.</p>

<p>In a future post, we will discuss <em>composition</em>, which is a key robustness property and really the secret to differential privacy’s success.  As we’ll see, average-case versions of differential privacy do not enjoy strong composition properties the way worst-case differential privacy does, which makes them much harder to deploy.</p>

<p>Incorporating assumptions about the adversary into the privacy guarantee requires great care; and it is safest to make fewer assumptions, which quickly pushes us towards the worst-case definition of differential privacy. Nevertheless, assumptions about the adversary are often made implicitly and it is worth studying how to make these explicit.</p>

<p>So, is there are role for distributional assumptions in differential privacy? Yes! Although we’ve discussed the pitfalls of making the <em>privacy guarantee</em> contingent on distributional assumptions, none of these pitfalls apply to making the <em>utility guarantee</em> contingent on distributional assumptions, as is normally done in statistical analysis.  In recent years, this combination—worst-case privacy, average-case utility—has been fruitful, and seems to allow many of the benefits that average-case privacy definitions seek to capture.  For example, recent work has shown that worst-case differential privacy permits accurate mean and covariance estimation of unbounded data under natural modeling assumptions <a href="https://arxiv.org/abs/1711.03908" title="Vishesh Karwa, Salil Vadhan. Finite Sample Differentially Private Confidence Intervals. ITCS 2018."><strong>[KV18]</strong></a>, <a href="https://arxiv.org/abs/1805.00216" title="Gautam Kamath, Jerry Li, Vikrant Singhal, Jonathan Ullman. Privately Learning High-Dimensional Distributions. COLT 2019."><strong>[KLSU19]</strong></a>, <a href="https://arxiv.org/abs/1906.02830" title="Mark Bun, Thomas Steinke. Average-Case Averages: Private Algorithms for Smooth Sensitivity and Mean Estimation. NeurIPS 2019."><strong>[BS19]</strong></a>, <a href="https://arxiv.org/abs/2001.02285" title="Wenxin Du, Canyon Foot, Monica Moniot, Andrew Bray, Adam Groce. Differentially Private Confidence Intervals. 2020."><strong>[DFMBG20]</strong></a>, <a href="https://arxiv.org/abs/2002.09464" title="Gautam Kamath, Vikrant Singhal, Jonathan Ullman.  Private Mean Estimation of Heavy-Tailed Distributions. COLT 2020."><strong>[KSU20]</strong></a>, <a href="https://arxiv.org/abs/2006.06618" title="Sourav Biswas, Yihe Dong, Gautam Kamath, Jonathan Ullman. CoinPress: Practical Private Mean and Covariance Estimation. 2020."><strong>[BDKU20]</strong></a>, but this remains an active area of research.</p>

<hr />

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>For example, there are approaches based on various paradigms like Smooth Sensitivity <a href="http://www.cse.psu.edu/~ads22/pubs/NRS07/NRS07-full-draft-v1.pdf" title="Kobbi Nissim, Sofya Raskhodnikova, Adam Smith. Smooth Sensitivity and Sampling in Private Data Analysis. STOC 2007."><strong>[NRS07]</strong></a> <a href="https://arxiv.org/abs/1906.02830" title="Mark Bun, Thomas Steinke. Average-Case Averages: Private Algorithms for Smooth Sensitivity and Mean Estimation. NeurIPS 2019."><strong>[BS19]</strong></a>, Propose-Test-Release <a href="http://www.stat.cmu.edu/~jinglei/dl09.pdf" title="Cynthia Dwork, Jing Lei. Differential Privacy and Robust Statistics. STOC 2009."><strong>[DL09]</strong></a>, or Truncation/Winsorization <a href="http://www.cse.psu.edu/~ads22/pubs/2011/stoc194-smith.pdf" title="Adam Smith. Privacy-preserving Statistical Estimation with Optimal Convergence Rates. STOC 2011."><strong>[S11]</strong></a> <a href="https://arxiv.org/abs/1711.03908" title="Vishesh Karwa, Salil Vadhan. Finite Sample Differentially Private Confidence Intervals. ITCS 2018."><strong>[KV18]</strong></a> <a href="https://arxiv.org/abs/1805.00216" title="Gautam Kamath, Jerry Li, Vikrant Singhal, Jonathan Ullman. Privately Learning High-Dimensional Distributions. COLT 2019."><strong>[KLSU19]</strong></a> <a href="https://arxiv.org/abs/2002.09464" title="Gautam Kamath, Vikrant Singhal, Jonathan Ullman.  Private Mean Estimation of Heavy-Tailed Distributions. COLT 2020."><strong>[KSU20]</strong></a> to name a few. <a href="https://differentialprivacy.org/feed.xml#fnref:1" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:2">
      <p>If you are confident that Jeff Bezos or other extremely high-wealth individuals are not in the sample, then you could <em>truncate</em> each sample and compute the mean of the truncated samples.  This would give worst-case privacy, and, if you are correct in your assumption, would not affect the mean. <a href="https://differentialprivacy.org/feed.xml#fnref:2" class="reversefootnote">↩</a></p>
    </li>
  </ol>
</div></div>







<p class="date">
by Jonathan Ullman <a href="https://differentialprivacy.org/average-case-dp/"><span class="datestr">at July 22, 2020 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/110">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/110">TR20-110 |  Capacity Lower Bounds via Productization | 

	Leonid Gurvits, 

	Jonathan Leake</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The purpose of this note is to state and prove a lower bound on the capacity of a real stable polynomial $p(x)$ which is based only on its value and gradient at $x=1$. This result implies a sharp improvement to a similar inequality proved by Linial-Samorodnitsky-Wigderson in 2000. Such inequalities have played an important role in the recent work on operator scaling and its generalizations and applications.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/110"><span class="datestr">at July 22, 2020 04:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4912">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4912">Is this blog obsolete?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Longtime friend-of-the-blog <a href="http://michaelnielsen.org/">Michael Nielsen</a>, formerly a quantum computing theorist and now an independent thinker about science and AI and learning, posted the following <a href="https://twitter.com/michael_nielsen/status/1284988349418098688">exchange</a> with the astounding <a href="https://www.technologyreview.com/2020/07/20/1005454/openai-machine-learning-language-generator-gpt-3-nlp/">GPT-3</a> text generator / chatbot:</p>



<blockquote class="wp-block-quote"><p>Q: Is it possible to use quantum computers to solve NP-complete problems in polynomial time?<br />A: It is not possible to use quantum computers to solve NP-complete problems in polynomial time.</p><p>Q: Why not?<br />A: Because NP-complete problems are not in BQP.</p><p>Q: You’ve just restated your earlier assertion!  What I’d like is to understand the underlying reason why not!<br />A: I’m sorry, but I don’t have time to explain the underlying reason why not.</p><p>Q: No offence, but this seems really bogus.  I don’t believe you understand the reason why!<br />A: I’m sorry, but I don’t have time to explain the underlying reason why not.</p></blockquote>



<p>(And then there are a few more rounds of the AI not having time to “explain the underlying reason why not.”)</p>



<p>This is, like, 80% of the way to replacing <em>Shtetl-Optimized</em>!</p>



<p>For much more discussion of GPT-3 and its implications, and samples of its output, see for example the <a href="https://www.reddit.com/r/slatestarcodex/">SSC subreddit</a>.  At the moment, as far as I can tell, the closest a person off the street can easily come to experimenting with GPT-3 themselves is using a website called <a href="https://play.aidungeon.io/">AI Dungeon</a>.</p>



<p>And yes, as many have already remarked, this is clearly the <a href="https://en.wikipedia.org/wiki/Altair_8800">MITS Altair</a> of text-generating AI, an amusing toy that’s also the start of something that will change the world.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4912"><span class="datestr">at July 21, 2020 12:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/stoc2020/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/stoc2020/">Conference Digest - STOC 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a href="http://acm-stoc.org/stoc2020/">STOC 2020</a> was recently held online, as one of the first major theory conferences during the COVID-19 era.
It featured four papers on differential privacy, which we list and link below.
Each one is accompanied by a video from the conference, as well as a longer video if available.
Please let us know if we missed any papers on differential privacy, either in the comments below or by email.</p>

<ul>
  <li>
    <p><a href="https://arxiv.org/abs/1911.08339">The Power of Factorization Mechanisms in Local and Central Differential Privacy</a> (<a href="https://www.youtube.com/watch?v=hSenRTxhZhM">video</a>)<br />
<a href="https://dblp.uni-trier.de/pers/hd/e/Edmonds:Alexander">Alexander Edmonds</a>, <a href="http://www.cs.toronto.edu/~anikolov/">Aleksandar Nikolov</a>, <a href="https://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2005.04763">Private Stochastic Convex Optimization: Optimal Rates in Linear Time</a> (<a href="https://www.youtube.com/watch?v=Tlc-z-MFAmM">video</a>)<br />
<a href="http://vtaly.net/">Vitaly Feldman</a>, <a href="https://tomerkoren.github.io/">Tomer Koren</a>, <a href="http://kunaltalwar.org/">Kunal Talwar</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1911.04014">Interaction is necessary for distributed learning with privacy or communication constraints</a> (<a href="https://www.youtube.com/watch?v=AWgzaFOU_HM">video</a>)<br />
<a href="https://yuvaldagan.wordpress.com/">Yuval Dagan</a>, <a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/1906.05271">Does Learning Require Memorization? A Short Tale about a Long Tail</a> (<a href="https://www.youtube.com/watch?v=sV59uoWJRnk">video</a>, <a href="https://www.youtube.com/watch?v=Fp7cgHRl8Yc">longer video</a>)<br />
<a href="http://vtaly.net/">Vitaly Feldman</a></p>
  </li>
</ul></div>







<p class="date">
by Gautam Kamath <a href="https://differentialprivacy.org/stoc2020/"><span class="datestr">at July 20, 2020 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://gradientscience.org/transfer-learning/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/madry.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://gradientscience.org/transfer-learning/">Transfer Learning with Adversarially Robust Models</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a style="float: left; width: 45%;" href="https://arxiv.org/abs/2007.08489" class="bbutton">
<i class="fas fa-file-pdf"></i>
    Paper
</a>
<a style="float: left; width: 45%;" href="https://github.com/Microsoft/robust-models-transfer" class="bbutton">
<i class="fab fa-github"></i>
   Models and Code
</a>
<br /></p>

<p><i>In our <a href="https://arxiv.org/abs/2007.08489">latest paper</a>, in collaboration with <a href="https://www.microsoft.com/en-us/research/">Microsoft Research</a>, we explore adversarial
robustness as an avenue for training computer vision models with more transferrable
features. We find that robust models outperform their standard counterparts on
a variety of transfer learning tasks.</i></p>

<h2 id="what-is-transfer-learning">What is transfer learning?</h2>

<p>Transfer learning is a paradigm where one leverages information
from a “source” task to better solve another “target” task. Particularly when there is little training data or compute available for solving the target
task, transfer learning provides a simple and efficient way to obtain performant
machine learning models.</p>

<p>Transfer learning has already proven its utility in many ML contexts. In natural language processing, for example, one can leverage language models pre-trained on large
text corpora to beat state-of-the-art performance on
tasks like query answering, entity recognition or part-of-speech classification.</p>

<p>In our work we focus on computer vision; in this context, a standard—and
remarkably successful—transfer learning pipeline is “ImageNet pre-training.”
This pipeline starts with a deep neural network trained on the <a href="http://image-net.org">ImageNet-1K</a>
dataset, and then refines this pre-trained model for a target task. The target task can range
from classification of smaller datasets (e.g., <a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR</a>) to more complex
tasks like object detection (e.g., <a href="http://host.robots.ox.ac.uk/pascal/VOC/">VOC</a>).</p>

<p>Although there are many ways in which one can refine a pre-trained model, we
will restrict our attention to the two most popular methods:</p>

<ul>
  <li><strong>Fixed-feature</strong>: In fixed-feature transfer learning, we replace the final
(linear) layer of the neural network with a new layer that has the correct
number of outputs for the target task. Then, keeping the rest of the layers
<em>fixed</em>, we train the newly replaced layer on the target task.</li>
  <li><strong>Full-network</strong>: In full-network transfer learning, we also replace the last
layer but do not freeze any layers afterwards. Instead, we use the pre-trained
network
as a sort of “initialization,” and continue training <em>all</em> the layers on the
target task.</li>
</ul>

<p>When at least a moderate amount of data is available, full-network transfer
learning typically outperforms the fixed-feature strategy.</p>

<h2 id="how-can-we-improve-transfer-learning">How can we improve transfer learning?</h2>

<p>Although we don’t have a comprehensive understanding of what makes transfer
learning algorithms tick, there has been a long line of work focused on identifying 
factors that improve (or worsen) performance (examples include
<a href="https://arxiv.org/abs/1406.5774">[1]</a>,
<a href="https://arxiv.org/abs/1608.08614">[2]</a>,
<a href="https://arxiv.org/abs/1805.08974">[3]</a>,
<a href="https://arxiv.org/abs/1804.08328">[4]</a>,
<a href="https://arxiv.org/abs/1411.1792">[5]</a>).</p>

<p>By design, the pre-trained ImageNet model itself plays a major role here:
indeed, a recent study by <a href="https://arxiv.org/abs/1805.08974">Kornblith, Shlens, and Le</a> finds that
pre-trained models which achieve a higher ImageNet accuracy also perform better when
transferred to downstream classification tasks, with a tight linear
correspondence between ImageNet accuracy and the accuracy on the target task:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/ksl.png" alt="A scatter plot of ImageNet accuracy versus downstream     transfer accuracy showing the linear relation." class="bigimg" /></p>
<div class="footnote">
Reproduced from <a href="https://arxiv.org/abs/1805.08974">[KSL19]</a>. 
Each dot is a pre-trained model whose $x$ coordinate is given by its 
ImageNet accuracy and $y$ coordinate is given by its downstream 
accuracy on the target task (after the corresponding refinement on that task).
</div>

<p>But is improving ImageNet accuracy of the pre-trained model the <em>only</em> way to improve transfer learning performance?</p>

<p>After all, we want to obtain models that have learned broadly applicable features from the
source dataset. ImageNet accuracy likely correlates with the quality of
features that a model has learned, but may not fully describe the downstream
utility of these features.
Ultimately, the nature of learned features stems from the <em>priors</em> placed on
them during training. For example, there have been studies of the (sometimes
implicit) priors imposed by architectural components (e.g., <a href="https://dmitryulyanov.github.io/deep_image_prior">convolutional layers</a>),
<a href="https://www.tandfonline.com/doi/abs/10.1198/10618600152418584">data</a>
<a href="https://arxiv.org/abs/1911.09071">augmentation</a>, 
<a href="https://arxiv.org/abs/1811.00401">loss functions</a> and even
<a href="https://stats385.github.io/assets/lectures/Stanford_Donoho_class_Nov_19.pdf">gradient descent</a> on neural network training.</p>

<p>In <a href="https://arxiv.org/abs/2007.08489">our paper</a>, we study another prior: <em>adversarial robustness</em>.
Adversarial robustness—a rather frequent subject on this blog—refers to
model’s invariance to small (often imperceptible) perturbations of natural
inputs, called <a href="https://gradientscience.org/intro_adversarial">adversarial examples</a>.</p>

<p>Standard neural networks (i.e., trained with the goal of maximizing
accuracy) are extremely vulnerable to such adversarial examples. For example,
with just a tiny perturbation to the pig image below, a pre-trained ImageNet
classifier will predict it as an “airliner” with 99% confidence:</p>

<p><img src="https://gradientscience.org/images/piggie.png" alt="An adversarial example: a pig on the left which is imperceptibly perturbed to be classified as an airliner on the right." /></p>
<div class="footnote">
A "pigs-can-fly" adversarial example: The "pig" image on the left is correctly classified by a standard ML model, but its imperceptibly perturbed counterpart on the right is classified as an "airliner" with 99% confidence.
</div>

<p>Adversarial robustness is thus typically induced at training time by replacing
the standard loss minimization objective with a <em>robust optimization</em> objective
(see our <a href="https://gradientscience.org/robust_opt_pt1">post on robust optimization</a> for more background):</p>



<p>The above objective trains models to be robust to image perturbations that are
small in (pixel-wise) $\ell_2$ (Euclidean) normIn reality, an $\ell_2$ ball doesn't perfectly capture the
set of imperceptible perturbations we want models to be robust to—but robustness with respect to this fairly rudimentary notion of perturbations turns out to be already non-trivial and very helpful.. 
The parameter $\varepsilon$ is a hyperparameter
governing the intended degree of invariance of the resulting models to the
corresponding perturbations. Setting 
$\varepsilon = 0$ corresponds to standard training, and increasing $\varepsilon$
asks the model to be robust to increasingly large perturbations.
In short, the objective asks the model to minimize risk on not only the 
training datapoints but also the entire radius-$\varepsilon$
neighbourhood around them.</p>

<p><em>[A quick plug: Our <a href="https://github.com/MadryLab/robustness"><code class="language-plaintext highlighter-rouge">robustness</code> Python library</a>, used for the code release of this paper, enables one to easily train and manipulate both standard and adversarially robust models.]</em></p>

<p>Although adversarial robustness has been initially studied solely through the lens of machine learning security, a line
of recent work (including some that’s been <a href="https://gradientscience.org/adv">previously</a> 
<a href="https://gradientscience.org/robust_apps">covered</a> on this blog) has begun to study
adversarially robust models in their own right, framing adversarial robustness
as a prior that forces models to learn features that are locally stable.
These works have found that on the one hand, adversarially robust models tend
to attain lower accuracy than their standardly-trained
counterparts.</p>

<p>On the other hand, recent work suggests that the feature
representations of robust models carry several advantages over those of
standard models, such as <a href="https://arxiv.org/abs/1805.12152">better-behaved</a>
<a href="https://arxiv.org/abs/1905.09797">gradients</a>, <a href="https://arxiv.org/abs/1910.08640">representation
invertibility</a>, and more <a href="https://arxiv.org/abs/2005.10190">specialized
features</a>.
We’ve actually discussed some of these observations in earlier posts on this
blog—see, e.g., our posts about 
<a href="https://gradientscience.org/robust_reps">representation learning</a> and 
<a href="https://gradientscience.org/robust_apps">image synthesis</a>.</p>

<p>These desirable properties
might suggest that robust neural networks are learning better feature
representations than standard networks, which could improve transfer
performance.</p>

<h3 id="adversarial-robustness-and-transfer-learning">Adversarial robustness and transfer learning</h3>

<p>So in summary, we have standard models with high accuracy on the source task but
little (or no) robustness; and we have adversarially robust models, which are
worse in terms of ImageNet accuracy, but have the “nice”
representational properties identified and discussed by prior works. Which
models are better for transfer learning?</p>

<p>To answer this question, we trained and examined a large collection
of standard and robust ImageNet models, while grid searching over a wide range of
hyperparameters and architectures to find the best model of each type. (All
models are available for download via our <a href="https://github.com/microsoft/robust-models-transfer">code/model
release</a> and more
details on our training procedure can be found there and in <a href="https://arxiv.org/abs/2007.08489">our
paper</a>). We then performed transfer
learning (using both fixed-feature and full-network refinement) from each
trained model to 12 downstream classification tasks.</p>

<p>It turns out that 
adversarially robust source models fairly consistently outperform their standard counterparts in
terms of downstream accuracy. In the table below, we compare the accuracies of
the best standard model (searching over hyperparameters and
architecture) and the best robust model (searching over the
previous factors as well as robustness level $\varepsilon$):</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/results-table.svg" style="width: 100%;" class="bigimg" alt="Table showing that robust models     perform better than their standard counterparts." /></p>
<div class="footnote">
    The main result: Adversarially robust models outperform their standard counterparts when transferred to downstream classification tasks.
</div>

<p>This difference in performance tends to be particularly striking in the context of fixed-feature transfer learning. The following graph shows, for each architecture and
downstream classification task, the best standard model compared to the best
robust model in that setting. As we can see, adversarially robust models
improve on the performance of their standard counterparts, and the gap tends to
<em>increase</em> as networks increase in width:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/LogisticRegression.svg" alt="A bar chart showing that robust models improve on     standard ones even without taking the maximum over architectures." class="bigimg" /></p>
<div class="footnote">
    Adversarially robust models tend to improve over standard networks for
    individual architectures too. (An analogous graph for full-network
    transfer learning is given in Figure 3 of <a href="https://arxiv.org/abs/2007.08489">our paper</a>.)
</div>

<p>Adversarial robustness improved downstream transfer
performance even when the target task was not a classification one. For example, the
following table compares standard and robust pre-training for use in downstream
object detection and instance segmentation:</p>

<p><img src="https://gradientscience.org/../assets/robust-transfer-learning/obj-det-results.svg" style="width: 80%;" class="bigimg" /></p>
<div class="footnote">
</div>

<h3 id="robustness-versus-accuracy">Robustness versus accuracy</h3>

<p>So it seems like robust models, despite being less accurate on the source task, are actually
better for transfer learning purposes. Indeed, the linear relation between
 ImageNet accuracy and transfer performance observed in prior work (see our discussion above) doesn’t seem
 to hold when the robustness parameter is varied. Compare the graphs below to the ones at the very start of this post:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/wide_resnet50_4_LogisticRegression.svg" class="bigimg" /></p>
<div class="footnote">
    Source-task (ImageNet) versus target (fixed-feature) accuracy for models with the same
    architecture while varying the robustness levels. Each dot is a
    WideResNet-50x4 model with $x$ coordinate given by source-task accuracy and
    $y$ coordinate given by fixed-feature transfer learning accuracy.
    Contrast the trends here with the "fixed-feature" trend in the first
    figure of this post—the linear trend depicted there largely disappears as less
    accurate but more robust models perform better in terms of transfer.
</div>

<p>How do we reconcile our observations with these trends observed by prior work?</p>

<p>We hypothesize that robustness and accuracy have <em>disentangled</em> effects on
transfer performance. That is, for a fixed level of robustness, higher
accuracy on the source task helps transfer, and for a fixed level of
accuracy, increased robustness helps transfer. Indeed, as shown below, for a
fixed level of robustness, the accuracy-transfer relation tends to hold
strongly:</p>

<p><img src="https://gradientscience.org/assets/robust-transfer-learning/fixed-robustness.svg" class="bigimg" /></p>
<div class="footnote">
Even though robust models appear to break the linear
accuracy-transfer trend, this trend is actually preserved for a fixed value of
robustness. Each dot in the graph is a different architecture, trained for the same level of robustness ($\varepsilon = 3.0$). The $x$ coordinate is source task (ImageNet) accuracy, and the $y$ coordinate is the downstream accuracy on each target dataset.
</div>

<p>In addition to reconciling our results with those of prior work, these findings suggest that ongoing work on developing more accurate robust models
may have the added benefit of further improving transfer learning performance.</p>

<h3 id="other-empirical-mysteries-and-future-work">Other empirical mysteries and future work</h3>

<p>This post discussed how adversarially robust models might constitute a promising
avenue for improving transfer learning, and already often outperform standard
models in terms of downstream accuracy. In <a href="https://arxiv.org/abs/2007.08489">our paper</a>, 
we study this phenomenon more closely: for example, we examine the effects of
model width, and we compare adversarial robustness to other notions of
robustness. We also uncover a few somewhat mysterious properties: for example,
resizing images seems to have a non-trivial effect on the relationship between
robustness and downstream accuracy.</p>

<p>Finally, while our work provides evidence that adversarially
robust computer vision models transfer better, understanding precisely <em>why</em> this is the case remains open. More broadly, the results we
observe indicate that we still do not yet fully understand (even empirically)
the ingredients that make transfer learning successful. We hope that our work
prompts an inquiry into the underpinnings of modern transfer learning.</p></div>







<p class="date">
<a href="https://gradientscience.org/transfer-learning/"><span class="datestr">at July 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2418581440113974615">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html">Erdos-Turan for k=3 is True!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
(All of the math in this post is summarized (without proofs) in a writeup by Erik Metz and myself which you can find <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/3apblog.pdf">here</a>. It is a pdf file so you can click on links in it to get to the papers it refers to. There have been posts on this topic by <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">Gil Kalai</a> and  <a href="https://lucatrevisan.wordpress.com/2020/07/08/silver-linings/">Luca Trevisan</a>. If you know of others then let me know so I can add them to this post.)<br />
<br />
<br />
<br />
This is a sequel to <a href="https://blog.computationalcomplexity.org/2010/12/breakthrough-result-on-density-and-3.html">A BREAKTHROUGH result on density and 3-AP's</a> and <a href="https://blog.computationalcomplexity.org/2017/06/big-news-on-w3r.html">Big news on W(3,r)!</a><br />
<br />
For this post N is large, and all inequalites have a big-O or a big-Omega.<br />
<br />
For this post [N] is {1,...,N}<br />
<br />
Let<br />
<br />
r(N) be the least w such that if A is a subset of [N] and |A|  &gt;  w, then A has a 3-AP.<br />
<br />
There has been a long sequence of results getting smaller and smaller upper bounds on r(N).<br />
<br />
The motivation for getting these results is that if r(N) is &lt; N/(log N)^{1+\delta} with delta&gt;0 then the following holds:<br />
<br />
If sum_{x\in A} 1/x diverges then A has a 3-AP.<br />
<br />
This is the k=3 case of one of the Erdos-Turan Conjectures.<br />
<br />
Bloom and Sisack HAVE gotten N/(log N)^{1+delta} so they HAVE gotten ET k=3. Wow!<br />
<br />
1) I am NOT surprised that its true.<br />
<br />
2) I am SHOCKED and DELIGHTED that it was proven.  Shocked because the results leading up to it (see the write up referenced at the beginning of this post) seemed Zeno-like, approaching the result needed got but not getting there. Delighted because... uh, as the kids say, just cause.<br />
<br />
I've heard that k=4 really is much harder (see my comments and Gil's response on his blog post, pointed to at the beginning of this post)  and it is true that there has been far less progress on that case (the write up I pointed to at the beginning of this post says what is known). Hence I will again be <i>shocked </i>if it is proven.  So, unlike The Who (see <a href="https://www.youtube.com/watch?v=UDfAdHBtK_Q">here</a>) I CAN be fooled again. That's okay--- I will  be <i>delighted</i>. (ADDED LATER- there are more comments no Gil's website, from Thomas Bloom and Ben Green about what is likely to happen in the next 10 years.)<br />
<br />
Erdos offered a prize of $3000 for a proof that A has, for all k, a k-AP.  The prize is now $5000. After Erdos passed away Ronald Graham became the Erdos-Bank and paid out the money when people solved a problem Erdos put a bounty on. What happens now? (If I have the facts wrong and/or if you know the answer, please leave a polite and enlightening comment.)<br />
<br />
<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/07/erdos-turan-for-k3-is-true.html"><span class="datestr">at July 19, 2020 07:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/109">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/109">TR20-109 |  On Testing Hamiltonicity in the Bounded Degree Graph Model | 

	Oded Goldreich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that testing Hamiltonicity in the bounded-degree graph model requires a linear number of queries. This refers to both the path and the cycle versions of the problem, and similar results hold also for the directed analogues.
In addition, we present an alternative proof for the known fact that testing Independent Set Size (in this model) requires a linear number of queries.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/109"><span class="datestr">at July 19, 2020 03:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/108">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/108">TR20-108 |  Query Complexity of Global Minimum Cut | 

	Arijit Bishnu, 

	Arijit Ghosh, 

	Gopinath Mishra, 

	Manaswi Paraashar</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work, we resolve the query complexity of global minimum cut problem for a graph by designing a randomized algorithm for approximating the size of minimum cut in a graph, where the graph can be accessed through local queries like \textsc{Degree}, \textsc{Neighbor}, and \textsc{Adjacency} queries.

Given $\epsilon \in (0,1)$, the algorithm with high probability outputs an estimate $\hat{t}$ satisfying the following $(1-\epsilon) t \leq \hat{t} \leq (1+\epsilon) t$, where $m$ is the number of edges in the graph and $t$ is the size of minimum cut in the graph. The expected number of local queries used by our algorithm is $\min\left\{m+n,\frac{m}{t}\right\}\mbox{poly}\left(\log n,\frac{1}{\epsilon}\right)$ where $n$ is the number of vertices in the graph. Eden and Rosenbaum showed that $\Omega(m/t)$ many local queries are required for approximating the size of minimum cut in graphs. These two results together resolve the query complexity of the problem of estimating the size of minimum cut in graphs using local queries.

Building on the lower bound of Eden and Rosenbaum, we show that, for all $t \in \mathbb{N}$, $\Omega(m)$ local queries are required to decide if the size of the minimum cut in the graph is $t$ or $t-2$. Also, we show that, for any $t \in \mathbb{N}$, $\Omega(m)$ local queries are required to find all the minimum cut edges even if it is promised that the input graph has a minimum cut of size $t$. Both of our lower bound results are randomized, and hold even if we can make \textsc{Random Edge} query apart from local queries.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/108"><span class="datestr">at July 19, 2020 01:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/107">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/107">TR20-107 |  Testing linear inequalities of subgraph statistics | 

	Lior Gishboliner, 

	Asaf Shapira, 

	Henrique Stagni</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Property testers are fast randomized algorithms whose task is to distinguish between inputs satisfying some predetermined property ${\cal P}$ and those that are far from satisfying it. Since these algorithms operate by inspecting a small randomly selected portion of the input, the most natural property one would like to be able to test is whether the input does not contain certain forbidden small substructures. In the setting of graphs, such a result was obtained by Alon et al., who proved that for any finite family of graphs ${\cal F}$, the property of being induced ${\cal F}$-free (i.e. not containing an induced copy of any $F \in {\cal F}$) is testable.

It is natural to ask if one can go one step further and prove that more elaborate properties involving induced subgraphs are also testable. One such generalization of the result of Alon et al. was formulated by Goldreich and Shinkar who conjectured that for any finite family of graphs ${\cal F}$, and any linear inequality involving the densities of the graphs $F \in {\cal F}$ in the input graph,
the property of satisfying this inequality can be tested in a certain restricted model of graph property testing. Our main result in this paper disproves this conjecture in the following strong form: some properties of this type are not testable even in the classical (i.e. unrestricted) model of graph property testing.

The proof deviates significantly from prior non-testability results in this area. The main idea is to use a linear inequality relating induced subgraph densities in order to encode the property of being a quasirandom graph.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/107"><span class="datestr">at July 19, 2020 01:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17307">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/">Mathematical Search</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>A flying start from nearby Rochester</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/agarwalzanibbi/" rel="attachment wp-att-17309"><img width="150" alt="" src="https://rjlipton.files.wordpress.com/2020/07/agarwalzanibbi.png?w=150&amp;h=142" class="alignright size-thumbnail wp-image-17309" height="142" /></a></p>
<p>
Anurag Agarwal and Richard Zanibbi are tenured faculty in Mathematics and Computer Science, respectively, at RIT. They partner with Clyde Lee Giles of Penn State and Douglas Oard of U.Md. on the <a href="https://www.cs.rit.edu/~dprl/mathseer/">MathSeer</a> project. If the name reminds you of <a href="http://citeseerx.ist.psu.edu/">CiteSeer<img src="https://s0.wp.com/latex.php?latex=%7B%7B%5C%2C%7D%5Ex%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\,}^x}" class="latex" title="{{\,}^x}" /></a>, no surprise: Giles co-originated that and still directs it.</p>
<p>
Today we note last month’s release of a major piece of MathSeer called <a href="https://mathdeck.cs.rit.edu/">MathDeck</a> and show how to have fun with it.</p>
<p><span id="more-17307"></span></p>
<p>
Agarwal is a PhD graduate from Buffalo. He did his thesis in the Mathematics Department under Thomas Cusick on cryptography, but often visited Computer Science. He took part in seminars on lattice-based cryptography led by Jin-Yi Cai when he was in Buffalo and in one of mine on related topics. I also knew him socially as a housemate of Pavan Aduri, whose joint work we’ve mentioned <a href="https://rjlipton.wordpress.com/2012/07/14/it-dont-come-easy/">here</a>. </p>
<p>
A long time ago, Dick wrote a <a href="https://rjlipton.wordpress.com/2010/12/20/some-mathematical-gifts/">post</a> on <a href="http://detexify.kirelabs.org/classify.html">Detexify</a>, which does optical character recognition (OCR) for mathematical symbols and finds corresponding (La)TeX commands. <em>MathDeck</em> does OCR as well, but what it is really trying to recognize is the <em>formula</em> you are trying to write. If it is a famous formula—or one you have already saved in your “deck”—it will find and complete it for you. It also takes input from LaTeX. <em>MathDeck</em> was created by Gavin Nishizawa, Jennifer Liu, Yancarlos Diaz, Abishai Dmello, and Wei Zhong along with Zanibbi. They are credited on a brief <a href="https://www.cs.rit.edu/~rlaz/files/ECIR2020_MathDeck_Demo.pdf">paper</a> and <a href="https://www.cs.rit.edu/~dprl/mathseer/demos.html">video</a>.</p>
<p>
</p><p></p><h2> Trying MathDeck </h2><p></p>
<p></p><p>
On first visit, the site shows a very brief tutorial which can be dismissed via a sometimes-invisible X in the upper-right corner. The first formula I thought to write was Leonhard Euler’s “mystic equation” <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Cpi%7D+%2B+1+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{i\pi} + 1 = 0}" class="latex" title="{e^{i\pi} + 1 = 0}" />. Its OCR sprang into action as I drew and converted my attempt to draw a curly <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi}" class="latex" title="{\pi}" /> as <img src="https://s0.wp.com/latex.php?latex=%7B7n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{7n}" class="latex" title="{7n}" /> with an extra crossbar.  (The website graphics are much sharper than our screenshots here.)</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/eulerformulamathdeck/" rel="attachment wp-att-17310"><img width="540" alt="" src="https://rjlipton.files.wordpress.com/2020/07/eulerformulamathdeck.jpg?w=540&amp;h=400" class="aligncenter wp-image-17310" height="400" /></a></p>
<p></p><p><br />
Nevertheless, its default deck of “WikiCards” recognizes the attempt and includes “Euler’s Identity” as an option. Selecting the card changes the display to an immaculately typeset version. I then decided to change it to the form <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7Bi%5Cpi%7D+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{i\pi} = -1}" class="latex" title="{e^{i\pi} = -1}" />. <em>MathDeck</em> does not have a pixel eraser like Microsoft Paint does but allows you to delete a region after selecting it:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/eulerformulatypeset/" rel="attachment wp-att-17312"><img width="360" alt="" src="https://rjlipton.files.wordpress.com/2020/07/eulerformulatypeset.jpg?w=360&amp;h=190" class="aligncenter wp-image-17312" height="190" /></a></p>
<p></p><p><br />
Selecting “trash” did not close up the space to the equals sign. I drew a minus bar at far right, but my attempts to follow with <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> kept being interpreted as “<img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />” or something worse, and the alternate form of Euler’s identity did not come up below. Finally, I restored the LaTeX-input box on the right and edited the source to read, <font size="+1"><tt>e^{i\pi} = -1</tt></font>:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/eulerformulatypeset2/" rel="attachment wp-att-17314"><img width="540" alt="" src="https://rjlipton.files.wordpress.com/2020/07/eulerformulatypeset2.jpg?w=540&amp;h=175" class="aligncenter wp-image-17314" height="175" /></a></p>
<p></p><p><br />
The artifact of my hand-drawn minus sign was still at far right. I could not select and trash it even after refreshing the page. What fixed the issue was drawing something else over the squiggle and having the OCR interpret the tandem into something else, which I could then select and delete. </p>
<p>
</p><p></p><h2> Superposing Forms and Associations </h2><p></p>
<p></p><p>
I next wondered how the system would react to my trying to write Schrödinger’s equation. One challenge is that it has many forms. I chose the form given uppermost in Wikipedia’s <a href="https://en.wikipedia.org/wiki/Schrodinger_equation#Equation">article</a>: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++i%5Chbar+%5Cfrac%7Bd+%7C%5CPsi%28t%29%5Crangle%7D%7Bd+t%7D+%3D+%5Chat%7BH%7D%7C%5CPsi%28t%29%5Crangle+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  i\hbar \frac{d |\Psi(t)\rangle}{d t} = \hat{H}|\Psi(t)\rangle " class="latex" title="\displaystyle  i\hbar \frac{d |\Psi(t)\rangle}{d t} = \hat{H}|\Psi(t)\rangle " /></p>
<p>To arrive at the challenge gradually, I first omitted the quantum <em>ket</em> notation, the hat on <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" />, and the dependence on <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />. I wrote partial derivatives and lowercase <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" />. Thus what I first tried to handwrite was: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++i%5Chbar+%5Cfrac%7B%5Cpartial+%5Cpsi%7D%7B%5Cpartial+t%7D+%3D+H%5Cpsi+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  i\hbar \frac{\partial \psi}{\partial t} = H\psi " class="latex" title="\displaystyle  i\hbar \frac{\partial \psi}{\partial t} = H\psi " /></p>
<p>The system jumped on my handwriting right away and I won’t report the results except to say it looked like Dada art with math symbols. One can, however, do a drawing in Paint or similar app and upload it. So I drew</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingerdrawing/" rel="attachment wp-att-17315"><img src="https://rjlipton.files.wordpress.com/2020/07/schrodingerdrawing.png?w=600" alt="" class="aligncenter size-full wp-image-17315" /></a></p>
<p></p><p><br />
and obtained</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingerrendered/" rel="attachment wp-att-17316"><img width="360" alt="" src="https://rjlipton.files.wordpress.com/2020/07/schrodingerrendered.jpg?w=360&amp;h=260" class="aligncenter wp-image-17316" height="260" /></a></p>
<p></p><p><br />
The ten cards returned (one is below the snip) have some wild but inspired associations. Handwriting Wikipedia’s form as given did not produce better results. However, I realized I could snip what appears on Wikipedia and upload that:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingersnip/" rel="attachment wp-att-17317"><img src="https://rjlipton.files.wordpress.com/2020/07/schrodingersnip.jpg?w=600" alt="" class="aligncenter size-full wp-image-17317" /></a></p>
<p></p><p><br />
The result was a ghostly evocation of the equation, with LaTeX to boot:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodingerdada/" rel="attachment wp-att-17318"><img width="540" alt="" src="https://rjlipton.files.wordpress.com/2020/07/schrodingerdada.jpg?w=540&amp;h=78" class="aligncenter wp-image-17318" height="78" /></a></p>
<p></p><p><br />
The LaTeX output reminded me that I could enter Schrödinger’s equation in LaTeX and remove all doubt. I did the short form first. Would the system recognize it?</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodinger1/" rel="attachment wp-att-17319"><img width="540" alt="" src="https://rjlipton.files.wordpress.com/2020/07/schrodinger1.jpg?w=540&amp;h=328" class="aligncenter wp-image-17319" height="328" /></a></p>
<p></p><p><br />
The name <em>Schrödinger</em> popped up in the eighth card at bottom center, but not the form I had typed. It has an integral and no equals sign. Of greater note, the center card called up another giant of quantum mechanics and began with exactly the left-hand side I had typed. To its left came Wolfgang Pauli with another occurrence of <img src="https://s0.wp.com/latex.php?latex=%7Bi%5Chbar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i\hbar}" class="latex" title="{i\hbar}" />. None of the output had the time variable <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />, however, so I put it in:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodinger2/" rel="attachment wp-att-17320"><img width="540" alt="" src="https://rjlipton.files.wordpress.com/2020/07/schrodinger2.jpg?w=540&amp;h=349" class="aligncenter wp-image-17320" height="349" /></a></p>
<p></p><p><br />
Bingo—the card labeled simply <em>Schrödinger Equation</em> appears at upper center. Unlike Wikipedia’s version, it includes <b>r</b> standing for other coordinates and—hence—properly uses partial derivatives. Otherwise it is exactly what my search intended to summon.</p>
<p>
I felt the real reward came in the other cards. I did not know that Hubble’s law had such a simple statement. I knew quantum mechanics takes glory in symmetries, of course, but did not know what equation would bear the definitive moniker, “Symmetry in Quantum Mechanics.” I remember as a child the fun of unstructured time in libraries where the physical card catalog was sorted by theme and one could browse adjacent ideas, as also on the shelves. </p>
<p>
Now I put in the ket notation, the hat to make <img src="https://s0.wp.com/latex.php?latex=%7B%5Chat%7BH%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\hat{H}}" class="latex" title="{\hat{H}}" />, and the uppercase <img src="https://s0.wp.com/latex.php?latex=%7B%5CPsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Psi}" class="latex" title="{\Psi}" />. The latter two changes evidently moved the <em>Schrödinger Equation</em> card to the top of the deck, with <em>Pauli Equation</em> moving up behind it, but other cards completely changed:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/schrodinger3/" rel="attachment wp-att-17321"><img width="540" alt="" src="https://rjlipton.files.wordpress.com/2020/07/schrodinger3.jpg?w=540&amp;h=349" class="aligncenter wp-image-17321" height="349" /></a></p>
<p></p><p><br />
I had not known the term <em>Einselection</em>. Finally, I decided to wipe the canvas and simply enter <img src="https://s0.wp.com/latex.php?latex=%7BH%5CPsi+%3D+E%5CPsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H\Psi = E\Psi}" class="latex" title="{H\Psi = E\Psi}" /> as the minimalist form of Schrödinger’s equation. I’ll leave you to see what the system comes up with on your own fresh canvas.</p>
<p>
</p><p></p><h2> Search and Research </h2><p></p>
<p></p><p>
The goal is to augment search that includes equations as well as text. For instance, right now I’d like to find sources that use a formula like </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Br%3D0%7D%5E%7B%5Cinfty%7D%5Cfrac%7Br%5E2%7D%7Be%5E%7Bar%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{r=0}^{\infty}\frac{r^2}{e^{ar}} " class="latex" title="\displaystyle  \sum_{r=0}^{\infty}\frac{r^2}{e^{ar}} " /></p>
<p>in the context of statistical tests for distinguishing between distributions. I’ve had success with Google on smaller pieces of TeX but this chunk yields nothing sensible. Changing the variable “<img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />” to “<img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />” changes some of the results but comes no closer; nor does changing to <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> or editing the sum to begin with <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> not <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />. The search should somehow recognize that <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> is a constant but is also the main parameter.</p>
<p>
The fact that I’ve typed a particular LaTeX form might be an impediment. I could have written <img src="https://s0.wp.com/latex.php?latex=%7Br%5E2+e%5E%7B-ar%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r^2 e^{-ar}}" class="latex" title="{r^2 e^{-ar}}" /> in the body of the sum without using a fraction. The <em>MathDeck</em> documentation focuses on enabling mathematical search for non-LaTeX users, but independence from syntax for all users is a commensurate goal. The idea is to make formulas “chunks” in their own right, chunks governed by semantics more than syntax, and promote saving and recombining them. For instance, I could save the body and replace the sum by an integral. </p>
<p>
The visual unit for this in <em>MathDeck</em> is the blue oval enclosing a formula. They can be created and edited at the top, imported to make a new <em>card</em>, and combined onto the canvas to build up larger formulas. The paper calls them “chips” but for me they evoke hieroglyphic <a href="https://en.wikipedia.org/wiki/Cartouche">cartouches</a> enclosing royal names. Cards can be marked as favorites and the collection added to. </p>
<p>
Here is an example where I made a cartouche and card out of the abstract form of the main equation in my chess model, as I expounded in a <a href="https://rjlipton.wordpress.com/2018/10/18/london-calling/">post</a> to mark the 2018 world chess championship match in London.</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/chessequation/" rel="attachment wp-att-17324"><img width="600" alt="" src="https://rjlipton.files.wordpress.com/2020/07/chessequation.jpg?w=600&amp;h=368" class="aligncenter wp-image-17324" height="368" /></a></p>
<p></p><p><br />
Once again the system pitches in with interesting associations. Some were expected but others are surprises. Logit and logarithmic loss are naturally associated but I had not heard of “Perplexity,” and what is Benford’s Law doing here? (Dick and I have been trying to find natural <em>exceptions</em> to Benford’s Law in Covid-19 statistics—we’ve not had time yet to tell whether we’ll succeed.)</p>
<p>
The searches at top are still “vanilla” Google search, and the search below the canvas is only within a deck or decks. We look forward to when a truly smart integration of mathematics into major search engines will be engendered by this project.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
How do you see <em>MathDeck</em> and the larger <em>MathSeer</em> project growing in the near future? We hope <em>MathDeck</em> stokes some immediate enjoyment and curiosity.</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/07/18/mathematical-search/"><span class="datestr">at July 18, 2020 04:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2020-07-17-polynomial-secret-sharing-and-the-lagrange-basis/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2020-07-17-polynomial-secret-sharing-and-the-lagrange-basis/">Polynomial Secret Sharing and the Lagrange Basis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this post, we highlight an amazing result: Shamir’s secret sharing scheme. This is one of the most powerful uses of polynomials over a finite field in distributed computing. Intuitively, this scheme allows a $Dealer$ to commit to a secret $s$ by splitting it into shares distributed to $n$ parties....</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2020-07-17-polynomial-secret-sharing-and-the-lagrange-basis/"><span class="datestr">at July 17, 2020 06:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
