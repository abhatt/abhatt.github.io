<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at July 22, 2019 04:23 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-7828284719883166611">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html">Answer to both Infinite Hats Problems from the last post</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
(This is a joint post with David Marcus. You'll see why later.)<br />
<br />
In a prior  I posed two infinite hat problems. Today I post the solutions. Actually this is a copy of my last post with the solutions added, so it is self contained.<br />
<br />
A Hat Problem that you have probably seen:<br />
<br />
1) There are an infinite number of people, numbered 1,2,3,...  There are 2 colors of hats. They can all see everyone's hat but their own. <br />
<br />
2) The adversary is going to put hats on all the people. They will guess their own hat color<i> at the same time</i>. <br />
<br />
3) The people can discuss strategy ahead of time, but must use a deterministic strategy and the adversary knows the strategy.<br />
<br />
4) The people want to minimize how many they get wrong. <br />
<br />
5) The adversary puts on hats to maximize how many they get wrong.<br />
<br />
I ask two questions (the answers are in a document I point to) and one meta-question:<br />
<br />
Q1: Is there a solution where they get all but a finite number of the guesses right? (If you have read my prior post on hat puzzles, <a href="https://blog.computationalcomplexity.org/2017/07/two-hat-problems-you-may-or-may-not.html">here</a> then you can do this one.) <br />
<br />
Q2: Is there a solution where they get all but at most (say) 18 wrong.<br />
<br />
<br />
Answers to Q1 and Q2 are <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/infinitehats.pdf">here</a>.<br />
<br />
How did I get into this problem? I was looking at hat problems a while back. Then  I began discussing Q1 and Q2 by email  (Does the term <i>discussing</i> have as a default that it is by email?) with David Marcus who had just read the chapter of <a href="https://www.amazon.com/Problems-Point-Exploring-Computer-Science/dp/9813279974">Problems with a Point</a> on hat puzzles. After a few emails back and fourth, he began looking on the web for answers. He found one. There is a website of hat puzzles! It was MY website papers on  Hat Puzzles! It is  <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/hats.html">here</a>. And on it was a relevant paper <a href="https://www.cs.umd.edu/users/gasarch/TOPICS/hats/infinite-hats-and-ac.pdf">here</a>. We did not find any other source of the problem or its solution. <br />
<br />
Q3: How well known is problem Q2 and the solution?  I've seen Q1 around but the only source on Q2 that I know of is that paper, and now this blog post. So, please leave a comment telling me if you have seen Q2 and/or the solution someplace else, and if so where.<br />
<br />
The responses to my last post indicated that YES the problem was out there, but the proof that you could not get all-but-18 was not well known. <br />
<br />
I THINK that all of the proofs that you can't do all-but-18 in the comment of the last post were essentially the same as the solution I pointed to in this blog. I would be interested if there is an alternative proof. <br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/07/answer-to-both-infinite-hats-problems.html"><span class="datestr">at July 22, 2019 03:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08579">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08579">On Approximate Range Mode and Range Selection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/El=Zein:Hicham.html">Hicham El-Zein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Meng.html">Meng He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Munro:J=_Ian.html">J. Ian Munro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nekrich:Yakov.html">Yakov Nekrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandlund:Bryce.html">Bryce Sandlund</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08579">PDF</a><br /><b>Abstract: </b>For any $\epsilon \in (0,1)$, a $(1+\epsilon)$-approximate range mode query
asks for the position of an element whose frequency in the query range is at
most a factor $(1+\epsilon)$ smaller than the true mode. For this problem, we
design an $O(n/\epsilon)$ bit data structure supporting queries in
$O(\lg(1/\epsilon))$ time. This is an encoding data structure which does not
require access to the input sequence; we prove the space cost is asymptotically
optimal for constant $\epsilon$. Our solution improves the previous best result
of Greve et al. (Cell Probe Lower Bounds and Approximations for Range Mode,
ICALP'10) by reducing the space cost by a factor of $\lg n$ while achieving the
same query time. We also design an $O(n)$-word dynamic data structure that
answers queries in $O(\lg n /\lg\lg n)$ time and supports insertions and
deletions in $O(\lg n)$ time, for any constant $\epsilon \in (0,1)$. This is
the first result on dynamic approximate range mode; it can also be used to
obtain the first static data structure for approximate 3-sided range mode
queries in two dimensions.
</p>
<p>We also consider approximate range selection. For any $\alpha \in (0,1/2)$,
an $\alpha$-approximate range selection query asks for the position of an
element whose rank in the query range is in $[k - \alpha s, k + \alpha s]$,
where $k$ is a rank given by the query and $s$ is the size of the query range.
When $\alpha$ is a constant, we design an $O(n)$-bit encoding data structure
that can answer queries in constant time and prove this space cost is
asymptotically optimal. The previous best result by Krizanc et al. (Range Mode
and Range Median Queries on Lists and Trees, Nordic Journal of Computing, 2005)
uses $O(n\lg n)$ bits, or $O(n)$ words, to achieve constant approximation for
range median only. Thus we not only improve the space cost, but also provide
support for any arbitrary $k$ given at query time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08579"><span class="datestr">at July 22, 2019 01:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08559">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08559">An Algorithm and Estimates for the Erd\H{o}s-Selfridge Function (work in progress)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Brianna Sorenson, Jonathan P Sorenson, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Webster:Jonathan.html">Jonathan Webster</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08559">PDF</a><br /><b>Abstract: </b>Let $p(n)$ denote the smallest prime divisor of the integer $n$. Define the
function $g(k)$ to be the smallest integer $&gt;k+1$ such that
$p(\binom{g(k)}{k})&gt;k$. So we have $g(2)=6$ and $g(3)=g(4)=7$. In this paper we
present the following new results on the Erd\H{o}s-Selfridge function $g(k)$:
We present a new algorithm to compute the value of $g(k)$, and use it to both
verify previous work and compute new values of $g(k)$, with our current limit
being $$ g(272)=57\ 61284\ 34192\ 78614\ 55093\ 37498. $$ We define a new
function $\hat{g}(k)$, and under the assumption of our Uniform Distribution
Heuristic we show that $$ \log g(k) = \log \hat{g}(k) + O(\log k) $$ with high
"probability". We also provide computational evidence to support our claim that
$\hat{g}(k)$ estimates $g(k)$ reasonably well in practice. There are several
open conjectures on the behavior of $g(k)$ which we are able to prove for
$\hat{g}(k)$, namely that $$ \frac{1-\log 2}{2}+o(1) \quad \le \quad \frac{\log
\hat{g}(k)}{k/\log k} \quad \le \quad 2+o(1), $$ and that $$
\limsup_{k\rightarrow\infty} \frac{\hat{g}(k+1)}{\hat{g}(k)}=\infty.$$ Let
$G(x,k)$ count the number of integers $n\le x$ such that $p(\binom{n}{k})&gt;k$.
Unconditionally, we prove that for large $x$, $G(x,k)$ is asymptotic to
$x/\hat{g}(k)$. And finally, we show that the running time of our new algorithm
is at most $g(k) \exp[ -c (k\log\log k) /(\log k)^2 (1+o(1))]$ for a constant
$c&gt;0$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08559"><span class="datestr">at July 22, 2019 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08433">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08433">Some Polycubes Have No Edge-Unzipping</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Joseph O'Rourke <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08433">PDF</a><br /><b>Abstract: </b>It is unknown whether or not every polycube has an edge-unfolding. A polycube
is an object constructed by gluing cubes face-to-face. An edge-unfolding cuts
edges on the surface and unfolds it to a net, a non-overlapping polygon in the
plane. Here we explore the more restricted edge-unzippings where the cut edges
form a path. We construct a polycube that has no edge-unzipping.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08433"><span class="datestr">at July 22, 2019 01:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08402">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08402">Favourite distances in 3-space</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Swanepoel:Konrad_J=.html">Konrad J. Swanepoel</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08402">PDF</a><br /><b>Abstract: </b>Let $S$ be a set of $n$ points in Euclidean $3$-space. Assign to each $x\in
S$ a distance $r(x)&gt;0$, and let $e_r(x,S)$ denote the number of points in $S$
at distance $r(x)$ from $x$. Avis, Erd\H{o}s and Pach (1988) introduced the
extremal quantity $f_3(n)=\max\sum_{x\in S}e_r(x,S)$, where the maximum is
taken over all $n$-point subsets $S$ of 3-space and all assignments $r\colon
S\to(0,\infty)$ of distances. We show that if the pair $(S,r)$ maximises
$f_3(n)$ and $n$ is sufficiently large, then, except for at most $2$ points,
$S$ is contained in a circle $\mathcal{C}$ and the axis of symmetry
$\mathcal{L}$ of $\mathcal{C}$, and $r(x)$ equals the distance from $x$ to $C$
for each $x\in S\cap\mathcal{L}$. This, together with a new construction,
implies that $f_3(n)=n^2/4 + 5n/2 + O(1)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08402"><span class="datestr">at July 22, 2019 01:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08399">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08399">Cluster deletion revisited</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsur:Dekel.html">Dekel Tsur</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08399">PDF</a><br /><b>Abstract: </b>In the Cluster Deletion problem the input is a graph $G$ and an integer $k$,
and the goal is to decide whether there is a set of at most $k$ edges whose
removal from $G$ results a graph in which every connected component is a
clique. In this paper we give an algorithm for Cluster Deletion whose running
time is $O^*(1.404^k)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08399"><span class="datestr">at July 22, 2019 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08362">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08362">Sparse Recovery for Orthogonal Polynomial Transforms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Anna Gilbert, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Albert.html">Albert Gu</a>, Christopher Re, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rudra:Atri.html">Atri Rudra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wootters:Mary.html">Mary Wootters</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08362">PDF</a><br /><b>Abstract: </b>In this paper we consider the following sparse recovery problem. We have
query access to a vector $\vx \in \R^N$ such that $\vhx = \vF \vx$ is
$k$-sparse (or nearly $k$-sparse) for some orthogonal transform $\vF$. The goal
is to output an approximation (in an $\ell_2$ sense) to $\vhx$ in sublinear
time. This problem has been well-studied in the special case that $\vF$ is the
Discrete Fourier Transform (DFT), and a long line of work has resulted in
sparse Fast Fourier Transforms that run in time $O(k \cdot \mathrm{polylog}
N)$. However, for transforms $\vF$ other than the DFT (or closely related
transforms like the Discrete Cosine Transform), the question is much less
settled.
</p>
<p>In this paper we give sublinear-time algorithms---running in time $\poly(k
\log(N))$---for solving the sparse recovery problem for orthogonal transforms
$\vF$ that arise from orthogonal polynomials. More precisely, our algorithm
works for any $\vF$ that is an orthogonal polynomial transform derived from
Jacobi polynomials. The Jacobi polynomials are a large class of classical
orthogonal polynomials (and include Chebyshev and Legendre polynomials as
special cases), and show up extensively in applications like numerical analysis
and signal processing. One caveat of our work is that we require an assumption
on the sparsity structure of the sparse vector, although we note that vectors
with random support have this property with high probability.
</p>
<p>Our approach is to give a very general reduction from the $k$-sparse sparse
recovery problem to the $1$-sparse sparse recovery problem that holds for any
flat orthogonal polynomial transform; then we solve this one-sparse recovery
problem for transforms derived from Jacobi polynomials.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08362"><span class="datestr">at July 22, 2019 01:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08355">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08355">3SUM with Preprocessing: Algorithms, Lower Bounds and Cryptographic Applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golovnev:Alexander.html">Alexander Golovnev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Siyao.html">Siyao Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Horel:Thibaut.html">Thibaut Horel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Park:Sunoo.html">Sunoo Park</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vaikuntanathan:Vinod.html">Vinod Vaikuntanathan</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08355">PDF</a><br /><b>Abstract: </b>Given a set of integers $\{a_1, \ldots, a_N\}$, the 3SUM problem requires
finding $a_i, a_j, a_k \in A$ such that $a_i + a_j = a_k$. A preprocessing
version of 3SUM, called 3SUM-Indexing, considers an initial offline phase where
a computationally unbounded algorithm receives $a_1,\ldots,a_N$ and produces a
data structure with $S$ words of $w$ bits each, followed by an online phase
where one is given the target $b$ and needs to find a pair $(i, j)$ such that
$a_i + a_j = b$ by probing only $T$ memory cells of the data structure. In this
paper, we study the 3SUM-Indexing problem and show the following.
</p>
<p>[New algorithms:] Goldstein et al. conjectured that there is no data
structure for 3SUM-Indexing with $S=N^{2-\varepsilon}$ and
$T=N^{1-\varepsilon}$ for any constant $\varepsilon&gt;0$. Our first contribution
is to disprove this conjecture by showing a suite of algorithms with $S^3 \cdot
T = \tilde{O}(N^6)$; for example, this achieves $S=\tilde{O}(N^{1.9})$ and
$T=\tilde{O}(N^{0.3})$.
</p>
<p>[New lower bounds:] Demaine and Vadhan in 2001 showed that every 1-query
algorithm for 3SUM-Indexing requires space $\tilde{\Omega}(N^2)$. Our second
result generalizes their bound to show that for every space-$S$ algorithm that
makes $T$ non-adaptive queries, $S = \tilde{\Omega}(N^{1+1/T})$. Any asymptotic
improvement to our result will result in a major breakthrough in static data
structure lower bounds.
</p>
<p>[New cryptographic applications:] A natural question in cryptography is
whether we can use a "backdoored" random oracle to build secure cryptography.
We provide a novel formulation of this problem, modeling a random oracle whose
truth table can be arbitrarily preprocessed by an unbounded adversary into an
exponentially large lookup table to which the online adversary has oracle
access. We construct one-way functions in this model assuming the hardness of a
natural average-case variant of 3SUM-Indexing.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08355"><span class="datestr">at July 22, 2019 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08306">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08306">A Polynomial Time Algorithm for Log-Concave Maximum Likelihood via Locally Exponential Families</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Axelrod:Brian.html">Brian Axelrod</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Diakonikolas:Ilias.html">Ilias Diakonikolas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sidiropoulos:Anastasios.html">Anastasios Sidiropoulos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stewart:Alistair.html">Alistair Stewart</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valiant:Gregory.html">Gregory Valiant</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08306">PDF</a><br /><b>Abstract: </b>We consider the problem of computing the maximum likelihood multivariate
log-concave distribution for a set of points. Specifically, we present an
algorithm which, given $n$ points in $\mathbb{R}^d$ and an accuracy parameter
$\epsilon&gt;0$, runs in time $poly(n,d,1/\epsilon),$ and returns a log-concave
distribution which, with high probability, has the property that the likelihood
of the $n$ points under the returned distribution is at most an additive
$\epsilon$ less than the maximum likelihood that could be achieved via any
log-concave distribution. This is the first computationally efficient
(polynomial time) algorithm for this fundamental and practically important
task. Our algorithm rests on a novel connection with exponential families: the
maximum likelihood log-concave distribution belongs to a class of structured
distributions which, while not an exponential family, "locally" possesses key
properties of exponential families. This connection then allows the problem of
computing the log-concave maximum likelihood distribution to be formulated as a
convex optimization problem, and solved via an approximate first-order method.
Efficiently approximating the (sub) gradients of the objective function of this
optimization problem is quite delicate, and is the main technical challenge in
this work.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08306"><span class="datestr">at July 22, 2019 01:27 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08304">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08304">A Constant Factor Approximation for Capacitated Min-Max Tree Cover</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Syamantak.html">Syamantak Das</a>, Lavina Jain, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Nikhil.html">Nikhil Kumar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08304">PDF</a><br /><b>Abstract: </b>Given a graph $G=(V,E)$ with non-negative real edge lengths and an integer
parameter $k$, the Min-Max k-Tree Cover problem seeks to find a set of at most
$k$ subtrees of $G$, such that the union of the trees is the vertex set $V$.
The objective is to minimize the maximum length among all the trees. We give
the first constant factor approximation for the hard uniform capacitated
version of this problem, where, an input parameter $\lambda$ upper bounds the
number of vertices that can be covered by any of the trees. Our result extends
to the rooted version of the problem, where we are given a set of $k$ root
vertices, $R$ and each of the covering trees is required to include a distinct
vertex in $R$ as the root. Prior to our work, the only result known was a
$(2k-1)$-approximation algorithm for the special case when the total number of
vertices in the graph is $k\lambda$ [Guttmann-Beck and Hassin, J. of
Algorithms, 1997].
</p>
<p>Our technique circumvents the difficulty of using the minimum spanning tree
of the graph as a lower bound, which is standard for the uncapacitated version
of the problem [Even et al., OR Letters 2004] [Khani et al., Algorithmica
2010}]. Instead, we use Steiner trees that cover $\lambda$ vertices along with
an iterative refinement procedure that ensures that the output trees have low
cost and the vertices are well distributed among the trees
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08304"><span class="datestr">at July 22, 2019 01:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08246">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08246">Finding First and Most-Beautiful Queens by Integer Programming</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischetti:Matteo.html">Matteo Fischetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salvagnin:Domenico.html">Domenico Salvagnin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08246">PDF</a><br /><b>Abstract: </b>The n-queens puzzle is a well-known combinatorial problem that requires to
place n queens on an n x n chessboard so that no two queens can attack each
other. Since the 19th century, this problem was studied by many mathematicians
and computer scientists. While finding any solution to the n-queens puzzle is
rather straightforward, it is very challenging to find the lexicographically
first (or smallest) feasible solution. Solutions for this type are known in the
literature for n &lt;= 55, while for some larger chessboards only partial
solutions are known. The present paper was motivated by the question of whether
Integer Linear Programming (ILP) can be used to compute solutions for some open
instances. We describe alternative ILP-based solution approaches, and show that
they are indeed able to compute (sometimes in unexpectedly-short computing
times) many new lexicographically optimal solutions for n ranging from 56 to
115. One of the proposed algorithms is a pure cutting plane method based on a
combinatorial variant of classical Gomory cuts. We also address an intriguing
"lexicographic bottleneck" (or min-max) variant of the problem that requires
finding a most beautiful (in a well defined sense) placement, and report its
solution for n up to 176.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08246"><span class="datestr">at July 22, 2019 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/095">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/095">TR19-095 |  Unambiguous Catalytic Computation | 

	Chetan Gupta, 

	Rahul Jain, 

	Vimal Raj Sharma, 

	Raghunath Tewari</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The catalytic Turing machine is a model of computation defined by Buhrman, Cleve,
Kouck, Loff, and Speelman (STOC 2014). Compared to the classical space-bounded Turing
machine, this model has an extra space which is filled with arbitrary content in addition
to the clean space. In such a model we study if this additional filled space can be used to
increase the power of computation or not, with the condition that the initial content of this
extra filled space must be restored at the end of the computation.
In this paper, we define the notion of unambiguous catalytic Turing machine and prove
that under a standard derandomization assumption, the class of problems solved by an
unambiguous catalytic Turing machine is same as the class of problems solved by a general
nondeterministic catalytic Turing machine in the logspace setting.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/095"><span class="datestr">at July 21, 2019 11:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08185">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08185">Imperfect Gaps in Gap-ETH and PCPs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bafna:Mitali.html">Mitali Bafna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vyas:Nikhil.html">Nikhil Vyas</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08185">PDF</a><br /><b>Abstract: </b>We study the role of perfect completeness in probabilistically checkable
proof systems (PCPs) and give a new way to transform a PCP with imperfect
completeness to a PCP with perfect completeness when the initial gap is a
constant. In particular, we show that $\text{PCP}_{c,s}[r,q] \subseteq
\text{PCP}_{1,1-\Omega(1)}[r+O(1),q+O(r)]$, for $c-s=\Omega(1)$. This implies
that one can convert imperfect completeness to perfect in linear-sized PCPs for
$NTIME[O(n)]$ with a $O(\log n)$ additive loss in the query complexity $q$. We
show our result by constructing a "robust circuit" using threshold gates. These
results are a gap amplification procedure for PCPs (when completeness is
imperfect), analogous to questions studied in parallel repetition and
pseudorandomness.
</p>
<p>We also investigate the time complexity of approximating perfectly
satisfiable instances of 3SAT versus those with imperfect completeness. We show
that the Gap-ETH conjecture without perfect completeness is equivalent to
Gap-ETH with perfect completeness, i.e. we show that Gap-3SAT, where the gap is
not around 1, has a subexponential algorithm, if and only if, Gap-3SAT with
perfect completeness has subexponential algorithms. We also relate the time
complexities of these two problems in a more fine-grained way, to show that
$T_2(n) \leq T_1(n(\log\log n)^{O(1)})$, where $T_1(n),T_2(n)$ denote the
randomized time-complexity of approximating MAX 3SAT with perfect and imperfect
completeness, respectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08185"><span class="datestr">at July 21, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08142">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08142">Stack sorting with restricted stacks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cerbai:Giulio.html">Giulio Cerbai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Claesson:Anders.html">Anders Claesson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferrari:Luca.html">Luca Ferrari</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08142">PDF</a><br /><b>Abstract: </b>The (classical) problem of characterizing and enumerating permutations that
can be sorted using two stacks connected in series is still largely open. In
the present paper we address a related problem, in which we impose restrictions
both on the procedure and on the stacks. More precisely, we consider a greedy
algorithm where we perform the rightmost legal operation (here "rightmost"
refers to the usual representation of stack sorting problems). Moreover, the
first stack is required to be $\sigma$-avoiding, for some permutation $\sigma$,
meaning that, at each step, the elements maintained in the stack avoid the
pattern $\sigma$ when read from top to bottom. Since the set of permutations
which can be sorted by such a device (which we call $\sigma$-machine) is not
always a class, it would be interesting to understand when it happens. We will
prove that the set of $\sigma$-machines whose associated sortable permutations
are not a class is counted by Catalan numbers. Moreover, we will analyze two
specific $\sigma$-machines in full details (namely when $\sigma=321$ and
$\sigma=123$), providing for each of them a complete characterization and
enumeration of sortable permutations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08142"><span class="datestr">at July 21, 2019 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08121">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08121">On Arrangements of Orthogonal Circles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/F=ouml=rster:Henry.html">Henry Förster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kryven:Myroslav.html">Myroslav Kryven</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wolff:Alexander.html">Alexander Wolff</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08121">PDF</a><br /><b>Abstract: </b>In this paper, we study arrangements of orthogonal circles, that is,
arrangements of circles where every pair of circles must either be disjoint or
intersect at a right angle. Using geometric arguments, we show that such
arrangements have only a linear number of faces. This implies that orthogonal
circle intersection graphs have only a linear number of edges. When we restrict
ourselves to orthogonal unit circles, the resulting class of intersection
graphs is a subclass of penny graphs (that is, contact graphs of unit circles).
We show that, similarly to penny graphs, it is NP-hard to recognize orthogonal
unit circle intersection graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08121"><span class="datestr">at July 21, 2019 11:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08111">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08111">Makespan Minimization with OR-Precedence Constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Happach:Felix.html">Felix Happach</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08111">PDF</a><br /><b>Abstract: </b>We consider a variant of the NP-hard problem of assigning jobs to machines to
minimize the completion time of the last job. Usually, precedence constraints
are given by a partial order on the set of jobs, and each job requires all its
predecessors to be completed before it can start. In his seminal paper, Graham
(1966) presented a simple 2-approximation algorithm, and, more than 40 years
later, Svensson (2010) proved that 2 is essentially the best approximation
ratio one can hope for in general. In this paper, we consider a different type
of precedence relation that has not been discussed as extensively and is called
OR-precedence. In order for a job to start, we require that at least one of its
predecessors is completed - in contrast to all its predecessors. Additionally,
we assume that each job has a release date before which it must not start. We
prove that Graham's algorithm has an approximation guarantee of 2 also in this
setting, and present a polynomial-time algorithm that solves the problem to
optimality, if preemptions are allowed. The latter result is in contrast to
classical precedence constraints, for which Ullman (1975) showed that the
preemptive variant is already NP-hard. Our algorithm generalizes a result of
Johannes (2005) who gave a polynomial-time algorithm for unit processing time
jobs subject to OR-precedence constraints, but without release dates. The
performance guarantees presented here match the best-known ones for special
cases where classical precedence constraints and OR-precedence constraints
coincide.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08111"><span class="datestr">at July 21, 2019 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08093">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08093">Metric Dimension Parameterized by Treewidth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Purohit:Nidhi.html">Nidhi Purohit</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08093">PDF</a><br /><b>Abstract: </b>A resolving set $S$ of a graph $G$ is a subset of its vertices such that no
two vertices of $G$ have the same distance vector to $S$. The Metric Dimension
problem asks for a resolving set of minimum size, and in its decision form, a
resolving set of size at most some specified integer. This problem is
NP-complete, and remains so in very restricted classes of graphs. It is also
W[2]-complete with respect to the size of the solution. Metric Dimension has
proven elusive on graphs of bounded treewidth. On the algorithmic side, a
polytime algorithm is known for trees, and even for outerplanar graphs, but the
general case of treewidth at most two is open. On the complexity side, no
parameterized hardness is known. This has led several papers on the topic to
ask for the parameterized complexity of Metric Dimension with respect to
treewidth. We provide a first answer to the question.
</p>
<p>We show that Metric Dimension parameterized by the treewidth of the input
graph is W[1]-hard. More refinedly we prove that, unless the Exponential Time
Hypothesis fails, there is no algorithm solving Metric Dimension in time
$f(\text{pw})n^{o(\text{pw})}$ on $n$-vertex graphs of constant degree, with
$\text{pw}$ the pathwidth of the input graph, and $f$ any computable function.
This is in stark contrast with an FPT algorithm of Belmonte et al. [SIAM J.
Discrete Math. '17] with respect to the combined parameter $\text{tl}+\Delta$,
where $\text{tl}$ is the tree-length and $\Delta$ the maximum-degree of the
input graph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08093"><span class="datestr">at July 21, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08024">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08024">Counting single-qubit Clifford equivalent graph states is #P-Complete</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dahlberg:Axel.html">Axel Dahlberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Helsen:Jonas.html">Jonas Helsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wehner:Stephanie.html">Stephanie Wehner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08024">PDF</a><br /><b>Abstract: </b>Graph states, which include for example Bell states, GHZ states and cluster
states, form a well-known class of quantum states with applications ranging
from quantum networks to error-correction. Deciding whether two graph states
are equivalent up to single-qubit Clifford operations is known to be decidable
in polynomial time and have been studied both in the context of producing
certain required states in a quantum network but also in relation to stabilizer
codes. The reason for the latter this is that single-qubit Clifford equivalent
graph states exactly corresponds to equivalent stabilizer codes. We here
consider the computational complexity of, given a graph state |G&gt;, counting the
number of graph states, single-qubit Clifford equivalent to |G&gt;. We show that
this problem is #P-Complete. To prove our main result we make use of the notion
of isotropic systems in graph theory. We review the definition of isotropic
systems and point out their strong relation to graph states. We believe that
these isotropic systems can be useful beyond the results presented in this
paper.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08024"><span class="datestr">at July 21, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.08019">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.08019">Transforming graph states to Bell-pairs is NP-Complete</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dahlberg:Axel.html">Axel Dahlberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Helsen:Jonas.html">Jonas Helsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wehner:Stephanie.html">Stephanie Wehner</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.08019">PDF</a><br /><b>Abstract: </b>Critical to the construction of large scale quantum networks, i.e. a quantum
internet, is the development of fast algorithms for managing entanglement
present in the network. One fundamental building block for a quantum internet
is the distribution of Bell pairs between distant nodes in the network. Here we
focus on the problem of transforming multipartite entangled states into the
tensor product of bipartite Bell pairs between specific nodes using only a
certain class of local operations and classical communication. In particular we
study the problem of deciding whether a given graph state, and in general a
stabilizer state, can be transformed into a set of Bell pairs on specific
vertices using only single-qubit Clifford operations, single-qubit Pauli
measurements and classical communication. We prove that this problem is
NP-Complete.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.08019"><span class="datestr">at July 21, 2019 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07982">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07982">Sensitive Distance and Reachability Oracles for Large Batch Updates</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brand:Jan_van_den.html">Jan van den Brand</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saranurak:Thatchaphol.html">Thatchaphol Saranurak</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07982">PDF</a><br /><b>Abstract: </b>In the sensitive distance oracle problem, there are three phases. We first
preprocess a given directed graph $G$ with $n$ nodes and integer weights from
$[-W,W]$. Second, given a single batch of $f$ edge insertions and deletions, we
update the data structure. Third, given a query pair of nodes $(u,v)$, return
the distance from $u$ to $v$. In the easier problem called sensitive
reachability oracle problem, we only ask if there exists a directed path from
$u$ to $v$.
</p>
<p>Our first result is a sensitive distance oracle with
$\tilde{O}(Wn^{\omega+(3-\omega)\mu})$ preprocessing time,
$\tilde{O}(Wn^{2-\mu}f^{2}+Wnf^{\omega})$ update time, and
$\tilde{O}(Wn^{2-\mu}f+Wnf^{2})$ query time where the parameter $\mu\in[0,1]$
can be chosen. The data-structure requires $O(Wn^{2+\mu} \log n)$ bits of
memory. This is the first algorithm that can handle $f\ge\log n$ updates.
Previous results (e.g. [Demetrescu et al. SICOMP'08; Bernstein and Karger
SODA'08 and FOCS'09; Duan and Pettie SODA'09; Grandoni and Williams FOCS'12])
can handle at most 2 updates. When $3\le f\le\log n$, the only non-trivial
algorithm was by [Weimann and Yuster FOCS'10]. When $W=\tilde{O}(1)$, our
algorithm simultaneously improves their preprocessing time, update time, and
query time. In particular, when $f=\omega(1)$, their update and query time is
$\Omega(n^{2-o(1)})$, while our update and query time are truly subquadratic in
$n$, i.e., ours is faster by a polynomial factor of $n$. To highlight the
technique, ours is the first graph algorithm that exploits the kernel basis
decomposition of polynomial matrices by [Jeannerod and Villard J.Comp'05; Zhou,
Labahn and Storjohann J.Comp'15] developed in the symbolic computation
community.
</p>
<p>[...]
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07982"><span class="datestr">at July 21, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07969">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07969">On the $\text{AC}^0[\oplus]$ complexity of Andreev's Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Potukuchi:Aditya.html">Aditya Potukuchi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07969">PDF</a><br /><b>Abstract: </b>Andreev's Problem states the following: Given an integer $d$ and a subset of
$S \subseteq \mathbb{F}_q \times \mathbb{F}_q$, is there a polynomial $y =
p(x)$ of degree at most $d$ such that for every $a \in \mathbb{F}_q$, $(a,p(a))
\in S$? We show an $\text{AC}^0[\oplus]$ lower bound for this problem.
</p>
<p>This problem appears to be similar to the list recovery problem for degree
$d$-Reed-Solomon codes over $\mathbb{F}_q$ which states the following: Given
subsets $A_1,\ldots,A_q$ of $\mathbb{F}_q$, output all (if any) the
Reed-Solomon codewords contained in $A_1\times \cdots \times A_q$. For our
purpose, we study this problem when $A_1, \ldots, A_q$ are random subsets of a
given size, which may be of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07969"><span class="datestr">at July 21, 2019 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07922">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07922">Approximate counting CSP seen from the other side</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zivny:Stanislav.html">Stanislav Zivny</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07922">PDF</a><br /><b>Abstract: </b>In this paper we study the complexity of counting Constraint Satisfaction
Problems (CSPs) of the form #CSP($\mathcal{C}$,-), in which the goal is, given
a relational structure $\mathbf{A}$ from a class $\mathcal{C}$ of structures
and an arbitrary structure $\mathbf{B}$, to find the number of homomorphisms
from $\mathbf{A}$ to $\mathbf{B}$. Flum and Grohe showed that
#CSP($\mathcal{C}$,-) is solvable in polynomial time if $\mathcal{C}$ has
bounded treewidth [FOCS'02]. Building on the work of Grohe [JACM'07] on
decision CSPs, Dalmau and Jonsson then showed that, if $\mathcal{C}$ is a
recursively enumerable class of relational structures of bounded arity, then
assuming FPT $\neq$ #W[1], there are no other cases of #CSP($\mathcal{C}$,-)
solvable exactly in polynomial time (or even fixed-parameter time) [TCS'04].
</p>
<p>We show that, assuming FPT $\neq$ W[1] (under randomised parametrised
reductions) and for $\mathcal{C}$ satisfying certain general conditions,
#CSP($\mathcal{C}$,-) is not solvable even approximately for $\mathcal{C}$ of
unbounded treewidth; that is, there is no fixed parameter tractable (and thus
also not fully polynomial) randomised approximation scheme for
#CSP($\mathcal{C}$,-). In particular, our condition generalises the case when
$\mathcal{C}$ is closed under taking minors.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07922"><span class="datestr">at July 21, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07910">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07910">On the m-eternal Domination Number of Cactus Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Václav Blažej, Jan Matyáš Křišťan, Tomáš Valla <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07910">PDF</a><br /><b>Abstract: </b>Given a graph $G$, guards are placed on vertices of $G$. Then vertices are
subject to an infinite sequence of attacks so that each attack must be defended
by a guard moving from a neighboring vertex. The m-eternal domination number is
the minimum number of guards such that the graph can be defended indefinitely.
In this paper we study the m-eternal domination number of cactus graphs, that
is, connected graphs where each edge lies in at most two cycles, and we
consider three variants of the m-eternal domination number: first variant
allows multiple guards to occupy a single vertex, second variant does not allow
it, and in the third variant additional "eviction" attacks must be defended. We
provide a new upper bound for the m-eternal domination number of cactus graphs,
and for a subclass of cactus graphs called Christmas cactus graphs, where each
vertex lies in at most two cycles, we prove that these three numbers are equal.
Moreover, we present a linear-time algorithm for computing them.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07910"><span class="datestr">at July 21, 2019 11:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07889">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07889">Fast permutation-word multiplication and the simultaneous conjugacy problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brodnik:Andrej.html">Andrej Brodnik</a>, Aleksander Malnič, Rok Požar <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07889">PDF</a><br /><b>Abstract: </b>Given a finite sequence $a_1, a_2,\ldots, a_d$ of $d$ permutations in the
symmetric group $S_n$, and a permutation word $k_1k_2\cdots k_{m}$ over the
alphabet $\{1,2,\ldots, d\}$, computation of the product $a_{k_1}a_{k_2}\cdots
a_{k_{m}}$ in a straightforward manner takes $O(n m)$ time. However, it appears
that this multiplication is such an elementary operation that, surprisingly
enough, it went on unquestioned. We show that the above product can be computed
in time $O(\min{\{ n m, n m \log d / \log m\}})$ using $O(m + n m^{\epsilon})$
space, where $0 &lt; \epsilon &lt; 1$. Consequently, this computation takes $o(n m)$
time whenever $\log d = o(\log m)$, which is a reasonable assumption in
practice.
</p>
<p>The above result is used to solve the transitive simultaneous conjugacy
problem in $O(n^2 \log d / \log n + dn\log n)$ time and $O(n^{1+ \epsilon} +
dn)$ space, where $0 &lt; \epsilon &lt;1$. This problem asks whether there exists a
permutation $\tau \in S_n$ such that $b_j = \tau^{-1} a_j \tau$ holds for all
$j = 1,2, \ldots, d$, where $a_1, a_2, \ldots, a_d$ and $b_1, b_2, \ldots, b_d$
are given sequences of $d$ permutations in $S_n$, each of which generates a
transitive subgroup of $S_n$. As from mid 70' it has been know that the problem
can be solved in $O(dn^2)$ time. An algorithm with running time $O(dn
\log(dn))$, proposed in late 80', does not work correctly on all input data.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07889"><span class="datestr">at July 21, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07885">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07885">Formal verification of trading in financial markets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sarswat:Suneel.html">Suneel Sarswat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Abhishek_Kr.html">Abhishek Kr Singh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07885">PDF</a><br /><b>Abstract: </b>We introduce a formal framework for analyzing trades in financial markets. An
exchange is where multiple buyers and sellers participate to trade. These days,
all big exchanges use computer algorithms that implement double sided auctions
to match buy and sell requests and these algorithms must abide by certain
regulatory guidelines. For example, market regulators enforce that a matching
produced by exchanges should be \emph{fair}, \emph{uniform} and
\emph{individual rational}. To verify these properties of trades, we first
formally define these notions in a theorem prover and then give formal proofs
of relevant results on matchings. Finally, we use this framework to verify
properties of two important classes of double sided auctions. All the
definitions and results presented in this paper are completely formalised in
the Coq proof assistant without adding any additional axioms to it.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07885"><span class="datestr">at July 21, 2019 11:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07833">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07833">Approximating Constraint Satisfaction Problems on High-Dimensional Expanders</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alev:Vedat_Levi.html">Vedat Levi Alev</a>, Fernando Granha Jeronimo, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tulsiani:Madhur.html">Madhur Tulsiani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07833">PDF</a><br /><b>Abstract: </b>We consider the problem of approximately solving constraint satisfaction
problems with arity $k &gt; 2$ ($k$-CSPs) on instances satisfying certain
expansion properties, when viewed as hypergraphs. Random instances of $k$-CSPs,
which are also highly expanding, are well-known to be hard to approximate using
known algorithmic techniques (and are widely believed to be hard to approximate
in polynomial time). However, we show that this is not necessarily the case for
instances where the hypergraph is a high-dimensional expander.
</p>
<p>We consider the spectral definition of high-dimensional expansion used by
Dinur and Kaufman [FOCS 2017] to construct certain primitives related to PCPs.
They measure the expansion in terms of a parameter $\gamma$ which is the
analogue of the second singular value for expanding graphs. Extending the
results by Barak, Raghavendra and Steurer [FOCS 2011] for 2-CSPs, we show that
if an instance of MAX k-CSP over alphabet $[q]$ is a high-dimensional expander
with parameter $\gamma$, then it is possible to approximate the maximum
fraction of satisfiable constraints up to an additive error $\epsilon$ using
$q^{O(k)} \cdot (k/\epsilon)^{O(1)}$ levels of the sum-of-squares SDP
hierarchy, provided $\gamma \leq \epsilon^{O(1)} \cdot (1/(kq))^{O(k)}$.
</p>
<p>Based on our analysis, we also suggest a notion of threshold-rank for
hypergraphs, which can be used to extend the results for approximating 2-CSPs
on low threshold-rank graphs. We show that if an instance of MAX k-CSP has
threshold rank $r$ for a threshold $\tau = (\epsilon/k)^{O(1)} \cdot
(1/q)^{O(k)}$, then it is possible to approximately solve the instance up to
additive error $\epsilon$, using $r \cdot q^{O(k)} \cdot (k/\epsilon)^{O(1)}$
levels of the sum-of-squares hierarchy. As in the case of graphs,
high-dimensional expanders (with sufficiently small $\gamma$) have threshold
rank 1 according to our definition.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07833"><span class="datestr">at July 21, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07796">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07796">An Ongoing Project to Improve the Rectilinear and the Pseudolinear Crossing Constants</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aichholzer:Oswin.html">Oswin Aichholzer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Duque:Frank.html">Frank Duque</a>, Ruy Fabila-Monroy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hidalgo=Toscano:Carlos.html">Carlos Hidalgo-Toscano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garc=iacute=a=Quintero:Oscar_E=.html">Oscar E. García-Quintero</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07796">PDF</a><br /><b>Abstract: </b>A drawing of a graph in the plane is {\it pseudolinear} if the edges of the
drawing can be extended to doubly-infinite curves that form an arrangement of
pseudolines, that is, any pair of edges crosses precisely once. A special case
are {\it rectilinear} drawings where the edges of the graph are drawn as
straight line segments. The rectilinear (pseudolinear) crossing number of a
graph is the minimum number of pairs of edges of the graph that cross in any of
its rectilinear (pseudolinear) drawings. In this paper we describe an ongoing
project to continuously obtain better asymptotic upper bounds on the
rectilinear and pseudolinear crossing number of the complete graph $K_n$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07796"><span class="datestr">at July 21, 2019 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07795">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07795">Efficient computation of the Jacobi symbol</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=ouml=ller:Niels.html">Niels Möller</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07795">PDF</a><br /><b>Abstract: </b>The family of left-to-right GCD algorithms reduces input numbers by
repeatedly subtracting the smaller number, or multiple of the smaller number,
from the larger number. This paper describes how to extend any such algorithm
to compute the Jacobi symbol, using a single table lookup per reduction. For
both quadratic time GCD algorithms (Euclid, Lehmer) and subquadratic algorithms
(Knuth, Sch\"onhage, M\"oller), the additional cost is linear, roughly one
table lookup per quotient in the quotient sequence. This method was used for
the 2010 rewrite of the Jacobi symbol computation in GMP.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07795"><span class="datestr">at July 21, 2019 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1907.07783">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1907.07783">Patient-specific Conditional Joint Models of Shape, Image Features and Clinical Indicators</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Egger:Bernhard.html">Bernhard Egger</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schirmer:Markus_D=.html">Markus D. Schirmer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dubost:Florian.html">Florian Dubost</a>, Marco J. Nardin, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rost:Natalia_S=.html">Natalia S. Rost</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Golland:Polina.html">Polina Golland</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1907.07783">PDF</a><br /><b>Abstract: </b>We propose and demonstrate a joint model of anatomical shapes, image features
and clinical indicators for statistical shape modeling and medical image
analysis. The key idea is to employ a copula model to separate the joint
dependency structure from the marginal distributions of variables of interest.
This separation provides flexibility on the assumptions made during the
modeling process. The proposed method can handle binary, discrete, ordinal and
continuous variables. We demonstrate a simple and efficient way to include
binary, discrete and ordinal variables into the modeling. We build Bayesian
conditional models based on observed partial clinical indicators, features or
shape based on Gaussian processes capturing the dependency structure. We apply
the proposed method on a stroke dataset to jointly model the shape of the
lateral ventricles, the spatial distribution of the white matter hyperintensity
associated with periventricular white matter disease, and clinical indicators.
The proposed method yields interpretable joint models for data exploration and
patient-specific statistical shape models for medical image analysis.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1907.07783"><span class="datestr">at July 21, 2019 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17574">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/">Isabella Novik and Hailun Zheng: Neighborly centrally symmetric spheres exist in all dimensions!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><span style="color: #0000ff;">A twit long summary: The cyclic polytope is wonderful and whenever we construct an analogous object we are happy. Examples: Neighborly cubic polytopes; The amplituhedron; and as of last week, the Novik-Zheng new construction of neighborly centrally symmetric spheres!</span></p>
<h2>At last: Neighborly CS spheres!</h2>
<p>The news: Isabella Novik and Hailun Zheng’ paper  <a href="https://arxiv.org/abs/1907.06115">Highly neighborly centrally symmetric spheres</a>, resolves an old standing problem in this field.</p>
<p>Here is the abstract:</p>
<blockquote><p>In 1995, Jockusch constructed an infinite family of centrally symmetric 3-dimensional simplicial spheres that are cs-<em>2</em>-neighborly. Here we generalize his construction and show that for all d ≥ 4 and n ≥ d, there exists a centrally symmetric (d − 1)-dimensional simplicial sphere with <em>2n</em> vertices that is cs-[d/2]-neighborly. This result combined with work of Adin and Stanley completely resolves the upper bound problem for centrally symmetric simplicial spheres.</p></blockquote>
<p>Congratulations to Isabella and Hailun!</p>
<h2>Some background to the Novik and Zheng breakthrough</h2>
<p><strong>Centrally symmetric bodies:</strong> A centrally symmetric (cs) polytope convex body in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R^d" class="latex" title="\mathbb R^d" /> satisfies <img src="https://s0.wp.com/latex.php?latex=x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x \in P" class="latex" title="x \in P" /> implies <img src="https://s0.wp.com/latex.php?latex=-x+%5Cin+P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="-x \in P" class="latex" title="-x \in P" />. Centrally symmetric bodies are the unit balls of normed spaces.</p>
<p><strong>Centrally symmetric simplicial spheres:</strong> A triangulation <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> of a  <img src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(d-1)" class="latex" title="(d-1)" />-dimensional sphere with a set <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> of vertices is centrally symmetric if there is an involution <img src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi" class="latex" title="\phi" /> on <img src="https://s0.wp.com/latex.php?latex=V&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="V" class="latex" title="V" /> that <img src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi" class="latex" title="\phi" /> maps a face of <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> to a face of <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> and for every vertex <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" />, <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi(v) \ne v" class="latex" title="\phi(v) \ne v" /> and <img src="https://s0.wp.com/latex.php?latex=%5C%7Bv+%2C+%5Cphi+%28v%29%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{v , \phi (v)\}" class="latex" title="\{v , \phi (v)\}" /> is not an edge of <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" />.  The boundary complex of a cs <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-polytopes is a cs triangulation of <img src="https://s0.wp.com/latex.php?latex=S%5E%7Bd-1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S^{d-1}" class="latex" title="S^{d-1}" />.</p>
<p><strong>Neighborliness.</strong> A simplicial complex <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" />  is <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />-neighborly of every set of <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> vertices of <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" /> form a face.  (The definition was first considered  for simplicial <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-polytopes <img src="https://s0.wp.com/latex.php?latex=P&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="P" class="latex" title="P" />.) The cyclic <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-polytope with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> vertices is <img src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[d/2]" class="latex" title="[d/2]" />-neighborly. (The only (<img src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[d/2]" class="latex" title="[d/2]" />+1)-neighborly simplicial <img src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(d-1)" class="latex" title="(d-1)" />-sphere is the simplex. There are many other <img src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[d/2]" class="latex" title="[d/2]" />-neighborly simplicial $d$-polytopes and <img src="https://s0.wp.com/latex.php?latex=%28d-1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(d-1)" class="latex" title="(d-1)" />-spheres.</p>
<p><strong>cs-Neighborliness. </strong>Let <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> be a simplicial complex with an involution <img src="https://s0.wp.com/latex.php?latex=%5Cphi&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi" class="latex" title="\phi" /> on its vertices which acts on <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> (maps faces to faces) and has the property that <img src="https://s0.wp.com/latex.php?latex=%5Cphi%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi(v)" class="latex" title="\phi(v)" /> is not adjacent to <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" /> (and <img src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29+%5Cne+v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi (v) \ne v" class="latex" title="\phi (v) \ne v" />). We will call <img src="https://s0.wp.com/latex.php?latex=v&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="v" class="latex" title="v" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cphi+%28v%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\phi (v)" class="latex" title="\phi (v)" /> <strong>antipodal</strong>. <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" /> is cs-<img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />-neighborly if every set of <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" /> vertices that contains no pair of antipodal vertices is a face of <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" />. The only cs-<img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="m" class="latex" title="m" />-neighborly simplicial sphere is the boundary complex of the cross polytope.</p>
<p><strong>The existence of cs-<img src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[d/2]" class="latex" title="[d/2]" />-neighborly spheres. </strong>It was an important open question to understand if cs <img src="https://s0.wp.com/latex.php?latex=%5Bd%2F2%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[d/2]" class="latex" title="[d/2]" />-neighborly simplicial spheres exist. (The only cs-<img src="https://s0.wp.com/latex.php?latex=%28%5Bd%2F2%5D%2B1%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="([d/2]+1)" class="latex" title="([d/2]+1)" />-neighborly spheres is the boundary complex of the cross polytope.)  The first example (whoch is not a cross polytope) was given by Grunbaum in 1969 in his paper “The importance of being straight(?).” In 1995  Jockusch constructed an infinite family cs-2-neighborly centrally symmetric 3-dimensional simplicial spheres. This problem has now been solved by Novik and Zheng.</p>
<p><strong>Neighborly centrally symmetric polytopes.  </strong>In the 1960s Grünbaum noted the big difference between neighborly centrally symmetric spheres and centrally symmetric polytopes. He proved (This is Theorem 4.1 in his book “Convex polytopes”) that no cs-2-neighborly 4 polytope with 12 vertices exists.  This is an example of the important themes of “streightening” or “linearizing” combimatorial objects and  of extending theorems from the “streight” or “linear” case to more general combinatorial settings.)</p>
<p>This result by Grünbaum was extended in various directions. Let me mention two major results in the field:</p>
<p><strong>Theorem</strong> McMullen and Shephard (1968): A cs <em>d</em>-dimensional polytope with <em>2(d + 2)</em> vertices cannot be more than cs-<em>⌊(d + 1)/3⌋</em>-neighborly.</p>
<p><strong>Theorem</strong> <a href="https://arxiv.org/abs/math/0507280">Linial and Novik (2006):</a> A cs-2-neighborly <em>d</em>-dimensional polytope has at most  <img src="https://s0.wp.com/latex.php?latex=2%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^d" class="latex" title="2^d" />;</p>
<p>Novik (2017) <a href="https://arxiv.org/abs/1712.09489">constructed</a>  cs-2-neighborly d polytopes with <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{d-1}+1" class="latex" title="2^{d-1}+1" /> vertices. She used a 2017 <a href="https://arxiv.org/abs/1709.03411">breakthrough construction</a> by Gerencsér–Harang of an acute set of size <img src="https://s0.wp.com/latex.php?latex=2%5E%7Bd-1%7D%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2^{d-1}+1" class="latex" title="2^{d-1}+1" /> in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5Ed&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R^d" class="latex" title="\mathbb R^d" />. (A set <em>S</em> is <em>acute</em> if every three points from <em>S </em>determine an acute triangle.)</p>
<p><strong>Face numbers of centrally-symmetric polytopes and spheres. </strong>As the abstract asserts the new construction is related to questions about face numbers of centrally symmetric polytopes, spheres and other cellular objects. In fact, this was the next item in our planned posts on algebraic combinatorics of cellular objects. (The first and only post so far<a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/"> is here</a>.) Here is a recent survey by Isabella Novik  <a href="https://arxiv.org/abs/1711.09310">A tale on centrally symmetric  polytopes and spheres</a>.</p>
<p><strong>Upper bound theorems.</strong> Neighborly polytopes and spheres are the equality cases of the upper bound theorem (proved by McMullen for polytopes and by Stanley for spheres). A version of the upper bound inequality for centrally symmetric spheres was proved by Adin and Stanley and the new construction shows that the Adin-Stanley inequality is tight. For more on the upper bound theorem and neighborliness see Section 2 of my 2000 survey  <a href="http://www.ma.huji.ac.il/~kalai/VIS.pdf">Combinatorics with geometric flavor. </a> See also the post <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">How the g-conjecture came about</a> and  and the post <a href="https://gilkalai.wordpress.com/2013/09/10/how-the-proof-of-the-upper-bound-theorem-for-spheres-was-found/" rel="bookmark">Richard Stanley: How the Proof of the Upper Bound Theorem (for spheres) was Found.</a></p>
<p> </p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/07/20/isabella-novik-and-hailun-zheng-neighborly-centrally-symmetric-spheres-exist-in-all-dimensions/"><span class="datestr">at July 20, 2019 06:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4267">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4267">Fake it till you make it (to the moon)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>While I wait to board a flight at my favorite location on earth—Philadelphia International Airport—I figured I might as well blog something to mark the 50<sup>th</sup> anniversary of Apollo 11.  (Thanks also to Joshua Zelinsky for a Facebook post that inspired this.)</p>



<p>I wasn’t alive for Apollo, but I’ve been alive for 3/4 of the time <em>after</em> it, even though it now seems like ancient history—specifically, like a Roman cathedral being gawked at by a medieval peasant, like an achievement by some vanished, more cohesive civilization that we can’t even replicate today, let alone surpass.</p>



<p>Which brings me to a depressing mystery: why do so many people now deny that humans walked on the moon at all?  Like, why <em>that</em> specifically?  While they’re at it, why don’t they also deny that WWII happened, or that the Beatles existed?</p>



<p>Surprisingly, skepticism of the reality of Apollo seems to have gone all the way back to the landings themselves.  One of my favorite stories growing up was of my mom, as a teenager, working as a waitress at an Israeli restaurant in Philadelphia, on the night of Apollo 11 landing.  My mom asked for a few minutes off to listen to news of the landing on the radio.  The owners wouldn’t grant it—explaining that it was all Hollywood anyway, just some actors in spacesuits on a sound stage, and obviously my mom wasn’t so naïve as to think anyone was <em>actually</em> walking to the moon?</p>



<p>Alas, as we get further and further from the event, with no serious prospect of ever replicating it past the stage of announcing an optimistic timetable (nor, to be honest, any scientific <em>reason</em> to replicate it), as the people involved die off, and as our civilization becomes ever more awash in social-media-fueled paranoid conspiracies, I fear that moon-landing denalism will become more common.</p>



<p>Because here’s the thing: Apollo could happen, but <em>only</em> because of a wildly improbable, once-in-history confluence of social and geopolitical factors.  It was economically insane, taking 100,000 people and 4% of the US federal budget for some photo-ops, a flag-planting, some data and returned moon rocks that had genuine scientific value but could’ve been provided much more cheaply by robots.  It was dismantled immediately afterwards like a used movie set, rather than leading to any greater successes. Indeed, manned spaceflight severely <em>regressed</em> afterwards, surely mocking the expectations of every last science fiction fan and techno-utopian who was alive at that time.</p>



<p>One could summarize the situation by saying that, in certain respects, the Apollo program really <strong>was</strong> “faked.”  It’s just that the way they “faked” it, involved actually landing people on the moon!</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4267"><span class="datestr">at July 19, 2019 09:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://blogs.princeton.edu/imabandit/?p=1397">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/bubeck.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/">Guest post by Julien Mairal: A Kernel Point of View on Convolutional Neural Networks, part II</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><a href="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?ssl=1" class="liimagelink"><img width="639" alt="" src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/uploads/sites/122/2019/07/Mairal2.jpg?resize=639%2C324&amp;ssl=1" class="alignnone wp-image-1399" height="324" /></a></p>
<p>This is a continuation of <a href="https://lear.inrialpes.fr/people/mairal/" class="liinternal">Julien Mairal</a>‘s guest post on CNNs, see <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" class="liinternal">part I here.</a></p>
<p><strong>Stability to deformations of convolutional neural networks</strong></p>
<p>In their <a href="http://proceedings.mlr.press/v70/zhang17f/zhang17f.pdf" class="lipdf">ICML paper</a> Zhang et al. introduce a functional space for CNNs with one layer, by noticing that for some dot-product kernels, smoothed variants of rectified linear unit activation functions (ReLU) live in the corresponding RKHS, see also <a href="http://proceedings.mlr.press/v48/zhangd16.pdf" class="lipdf">this paper</a> and <a href="https://www.cs.cornell.edu/~sridharan/sicomp.pdf" class="lipdf">that one</a>. By following a similar reasoning with multiple layers, it is then possible to show that the functional space described in <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" class="liinternal">part I</a> <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3e321e5f0406c9879f25b6b1d69a5fc3_l3.png?resize=298%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="20" width="298" alt="\{ f_w: x \mapsto \langle w , \Phi_n(x_0) \rangle; w \in L^2(\Omega,\mathcal{H}_n) \}" class="ql-img-inline-formula " /> contains CNNs with such smoothed ReLU, and that the norm <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-62e1a48032624994ba16c4e26421676e_l3.png?resize=34%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="34" alt="\|f_w\|" class="ql-img-inline-formula " /> of such networks can be controlled by the spectral norms of filter matrices. This is consistent with previous measures of complexity for CNNs, see <a href="https://papers.nips.cc/paper/7204-spectrally-normalized-margin-bounds-for-neural-networks.pdf" class="lipdf">this paper</a> by Bartlett et al.</p>
<p>A perhaps more interesting finding is that the abstract representation <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="45" alt="\Phi_n(x)" class="ql-img-inline-formula " />, which only depends on the network architecture, may provide near-translation invariance and stability to small image deformations while preserving information—that is, <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="10" alt="x" class="ql-img-inline-formula " /> can be recovered from <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ca9a5351b772e88bebe85e7e4a13632_l3.png?resize=45%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="45" alt="\Phi_n(x)" class="ql-img-inline-formula " />. The original characterization we use was introduced by Mallat in <a href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf" class="lipdf">his paper</a> on the scattering transform—a multilayer architecture akin to CNNs based on wavelets, and was extended to <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="21" alt="\Phi_n" class="ql-img-inline-formula " /> by Alberto Bietti, who should be credited for all the hard work here.</p>
<p>Our goal is to understand under which conditions it is possible to obtain a representation that (i) is near-translation invariant, (ii) is stable to deformations, (iii) preserves signal information. Given a <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-2e9ea203bbd77c5cd8bee967e2729d8b_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="15" width="20" alt="C^1" class="ql-img-inline-formula " />-diffeomorphism <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c6f8f1dde2ee4682653c2a6b37d8a42d_l3.png?resize=93%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="93" alt="\tau: \mathbb{R}^2 \to \mathbb{R}^2" class="ql-img-inline-formula " /> and denoting by <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-835d9f864f712213ee317332b3f3675a_l3.png?resize=167%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="167" alt="L_\tau x(u) = x(u-\tau(u))" class="ql-img-inline-formula " /> its action operator (for an image defined on the continuous domain <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d5abe0f29e8cc710ae26f4f0af5a0859_l3.png?resize=20%2C15&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="15" width="20" alt="\mathbb{R}^2" class="ql-img-inline-formula " />), the main stability bound we obtain is the following one, see Theorem 7 in <a href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf" class="lipdf">Mallat’s paper</a> if <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-758b3cac273166048ed1879acf427860_l3.png?resize=104%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="104" alt="\|\nabla \tau\|_\infty \leq 1/2" class="ql-img-inline-formula " />, for all <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-1b9fbfb207b6d17d74b33c6d8342a1a4_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="10" alt="x" class="ql-img-inline-formula " />,</p>
<p style="line-height: 43px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-51041d0067a72066938e31b1f00529fa_l3.png?resize=455%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="43" width="455" alt="\[ \| \Phi_n(L_\tau x) - \Phi_n(x)\| \leq \left ( C_1 (1+n) \|\nabla \tau\|_\infty + \frac{C_2}{\sigma_n} \|\tau\|_\infty \right) \|x\|, \]" class="ql-img-displayed-equation " /></p>
<p>where <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-08d1f29fa9c0981e916619b6c6bc7eee_l3.png?resize=48%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="48" alt="C_1, C_2" class="ql-img-inline-formula " /> are universal constants, <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="18" alt="\sigma_n" class="ql-img-inline-formula " /> is the scale parameter of the pooling operator <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-e1872c7d7a65e0dc92f8a4a04608b88a_l3.png?resize=21%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="21" alt="A_n" class="ql-img-inline-formula " /> corresponding to the “amount of pooling” performed up to the last layer, <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c1a5effb150d36de3c7074eaa980c357_l3.png?resize=39%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="39" alt="\|\tau\|_\infty" class="ql-img-inline-formula " /> is the maximum pixel displacement and <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-ab4c5d3fe8fd25af25beb4f58a55c938_l3.png?resize=53%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="53" alt="\|\nabla \tau\|_\infty" class="ql-img-inline-formula " /> represents the maximum amount of deformation, see <a href="https://www.di.ens.fr/~mallat/papiers/ScatCPAM.pdf" class="lipdf">the paper</a> for the precise definitions of all these quantities. Note that when <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b732bf857c5f04c7d10dda247f1a5022_l3.png?resize=85%2C18&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="18" width="85" alt="C_2/\sigma_n \to 0" class="ql-img-inline-formula " />, the representation <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="21" alt="\Phi_n" class="ql-img-inline-formula " /> becomes translation invariant: indeed, consider the particular case of <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3af6c51247895b176bb502f0ee0857ee_l3.png?resize=10%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="10" alt="\tau" class="ql-img-inline-formula " /> being a translation, then <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-aa1278a7149925a4f299de0dbb85cec0_l3.png?resize=57%2C14&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="14" width="57" alt="\nabla \tau=0" class="ql-img-inline-formula " /> and <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cd1d650abd9970e357384c0653960577_l3.png?resize=186%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="186" alt="\|\Phi_n(L_\tau x) - \Phi_n(x)\| \to 0" class="ql-img-inline-formula " />.</p>
<p>The stability bound and a few additional results tell us a few things about the network architecture: (a) small patches lead to more stable representations (the dependency is hidden in <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-782c65cbd411fb8862688afc92bc1eea_l3.png?resize=19%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="19" alt="C_1" class="ql-img-inline-formula " />); (b) signal preservation for discrete signals requires small subsampling factors (and thus small pooling) between layers. In such a setting, the scale parameter <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c0142846a2999e170f7beec7be1523f2_l3.png?resize=18%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="18" alt="\sigma_n" class="ql-img-inline-formula " /> still grows exponentially with <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a63eb5ff0272d3119fa684be6e7acce8_l3.png?resize=11%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="11" alt="n" class="ql-img-inline-formula " /> and near translation invariance may be achieved with several layers.</p>
<p>Interestingly, we may now come back to the Cauchy-Schwarz inequality from part 1, and note that if <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-273242b8e92b3a9f4dc13c62b2785bd3_l3.png?resize=21%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="21" alt="\Phi_n" class="ql-img-inline-formula " /> is stable, the RKHS norm <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-afe70184469e7e3a14405a7193eedf29_l3.png?resize=24%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="24" alt="\|f\|" class="ql-img-inline-formula " /> is then a natural quantity that provides stability to deformations to the prediction function <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-c7d97b919a3b73617cf2fbb375fff3b1_l3.png?resize=10%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="10" alt="f" class="ql-img-inline-formula " />, in addition to measuring model complexity in a traditional sense.</p>
<p><strong>Feature learning in RKHSs and convolutional kernel networks</strong></p>
<p>The previous paragraph is devoted to the characterization of convolutional architectures such as CNNs but the previous kernel construction can in fact be used to derive more traditional kernel methods. After all, why should one spend efforts defining a kernel between images if not to use it?</p>
<p>This can be achieved by considering finite-dimensional approximations of the previous feature maps. In order to shorten the presentation, we simply describe the main idea based on the Nystrom approximation and refer to <a href="http://papers.nips.cc/paper/6184-end-to-end-kernel-learning-with-supervised-convolutional-kernel-networks.pdf" class="lipdf">the paper</a> for more details. Approximating the infinite-dimensional feature maps <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3ad23c5c360c3f33031a5d000d37416f_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="x_k" class="ql-img-inline-formula " /> (see the figure at the top of <a href="https://blogs.princeton.edu/imabandit/2019/07/10/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-i/" class="liinternal">part I</a>) can be done by projecting each point in <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_k" class="ql-img-inline-formula " /> onto a <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="17" alt="p_k" class="ql-img-inline-formula " />-dimensional subspace <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="20" alt="\mathcal{F}_k" class="ql-img-inline-formula " /> leading to a finite-dimensional feature map <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="17" alt="\tilde{x}_k" class="ql-img-inline-formula " /> akin to CNNs, see the figure at the top of the post.</p>
<p>By parametrizing <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5dd8802df8efddb9acc5056af47339d7_l3.png?resize=297%2C20&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="20" width="297" alt="\mathcal{F}_k=\text{span}(\varphi_k(z_1),\varphi_k(z_2),\ldots,\varphi_k(z_{p_k}))" class="ql-img-inline-formula " /> with <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5c72bc331dc0008f57d454e7071dc39e_l3.png?resize=17%2C12&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="12" width="17" alt="p_k" class="ql-img-inline-formula " /> anchor points <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-4614e1cdba47dc6a6db7957fb1d82632_l3.png?resize=123%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="123" alt="Z=[z_1,\ldots,z_{p_k}]" class="ql-img-inline-formula " />, and using a dot-product kernel, a patch <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-d9d772a59543419785ce66946592259a_l3.png?resize=9%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="9" alt="z" class="ql-img-inline-formula " /> from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="35" alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " /> is encoded through the mapping function</p>
<p style="line-height: 43px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc43da382f024d96cb50e3dc3f051d6f_l3.png?resize=306%2C43&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="43" width="306" alt="\[ \psi_k(z) = \|z\| \kappa_k( Z^\top Z)^{-1/2} \kappa_k\left( Z^\top \frac{z}{\|z\|} \right), \]" class="ql-img-displayed-equation " /></p>
<p>where <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-684fcf23472c51919624049fb4e0129a_l3.png?resize=17%2C11&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="11" width="17" alt="\kappa_k" class="ql-img-inline-formula " /> is applied pointwise. Then, computing <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-5f55b75318f3b8da67917ee0b0e190ce_l3.png?resize=17%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="17" alt="\tilde{x}_k" class="ql-img-inline-formula " /> from <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-6419748397a324cd2a2ebc3f119b7f80_l3.png?resize=35%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="35" alt="\tilde{x}_{k-1}" class="ql-img-inline-formula " /> admits a CNN interpretation, where only the normalization and the matrix multiplication by <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-a74cffbbd51922298a13f864fbedaa98_l3.png?resize=103%2C21&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="21" width="103" alt="\kappa_k( Z^\top Z)^{-1/2}" class="ql-img-inline-formula " /> are not standard operations. It remains now to choose the anchor points:</p>
<ul>
<li><strong>kernel approximation:</strong> a first approach consists of using a variant of the Nystrom method, see <a href="https://papers.nips.cc/paper/1866-using-the-nystrom-method-to-speed-up-kernel-machines.pdf" class="lipdf">this paper</a> and <a href="http://home.cse.ust.hk/~twinsen/nystrom.pdf" class="lipdf">that one</a>. When plugging the corresponding image representation in a linear classifier, the resulting approach behaves as a classical kernel machine. Empirically, we observe that the higher the number of anchor points, the better the kernel approximation, and the higher the accuracy. For instance, a two-layer network with a <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-81a4466abb5fecba81f8a3aa055a1a14_l3.png?resize=36%2C13&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="13" width="36" alt="300k" class="ql-img-inline-formula " />-dimensional representations achieves about <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-0eea28372ada596bc618b4b94fee69ec_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="32" alt="86\%" class="ql-img-inline-formula " /> accuracy on CIFAR-10 without data augmentation (see <a href="https://gitlab.inria.fr/mairal/ckn-cudnn-matlab" class="liinternal">here</a>).</li>
<li><strong>back-propagation, feature selection</strong>: learning the anchor points <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-cc9f8fff9fd24060bc054e78f01d5bfb_l3.png?resize=12%2C12&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="12" width="12" alt="Z" class="ql-img-inline-formula " /> can also be done as in a traditional CNN, by optimizing them end-to-end. This allows using deeper lower-dimensional architectures and empirically seems to perform better when enough data is available, e.g., <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-659ab3cccda2422f955af880d20646cf_l3.png?resize=32%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="32" alt="92\%" class="ql-img-inline-formula " /> accuracy on CIFAR-10 with simple data augmentation. There, the subspaces <img src="https://i1.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b08b176c0bf0adbd9cbe41b31147e1f7_l3.png?resize=20%2C16&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="16" width="20" alt="\mathcal{F}_k" class="ql-img-inline-formula " /> are not learned anymore to provide the best kernel approximation, but the model seems to perform a sort of feature selection in each layer’s RKHS <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-bc26f0de4084a72b9e625a080bd5d674_l3.png?resize=22%2C15&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="15" width="22" alt="\mathcal{H}_k" class="ql-img-inline-formula " />, which is not well understood yet (This feature selection interpretation is due to my collaborator Laurent Jacob).</li>
</ul>
<p>Note that the first CKN model published <a href="https://papers.nips.cc/paper/5348-convolutional-kernel-networks.pdf" class="lipdf">here</a> was based on a different approximation principle, which was not compatible with end-to-end training. We found this to be less scalable and effective.</p>
<p><strong>Other links between neural networks and kernel methods</strong></p>
<p>Finally, other links between kernels and infinitely-wide neural networks with random weights are classical, but they were not the topic of this blog post (they should be the topic of another one!). In a nutshell, for a large collection of weights distributions and nonlinear functions <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-b4680e3f9e8274687d2d04f0a262ed00_l3.png?resize=76%2C13&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="13" width="76" alt="s: \mathbb{R} \to \mathbb{R}" class="ql-img-inline-formula " />, the following quantity admits an analytical form</p>
<p style="line-height: 22px;" class="ql-center-displayed-equation"><span class="ql-right-eqno">   </span><span class="ql-left-eqno">   </span><img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-9144f2d0b847adb69db90629ed805148_l3.png?resize=229%2C22&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="22" width="229" alt="\[ K(x,x') = \E_{w}[ s(w^\top x) s(w^\top x')], \]" class="ql-img-displayed-equation " /></p>
<p>where the terms <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-da82e444bbc3a5e594b7edbf0b1ba3a0_l3.png?resize=56%2C19&amp;ssl=1" title="Rendered by QuickLaTeX.com" height="19" width="56" alt="s(w^\top x)" class="ql-img-inline-formula " /> may be seen as an infinitely-wide single-layer neural network. The first time such a relation appears is likely to be in <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.446.9306&amp;rep=rep1&amp;type=pdf" class="liexternal">the PhD thesis</a> of Radford Neal with a Gaussian process interpretation, and it was revisited later by <a href="http://proceedings.mlr.press/v2/leroux07a/leroux07a.pdf" class="lipdf">Le Roux and Bengio</a> and by <a href="http://papers.nips.cc/paper/3628-kernel-methods-for-deep-learning.pdf" class="lipdf">Cho and Saul</a> with multilayer models.</p>
<p>In particular, when <img src="https://i2.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-3bcfb3f0b6b04be3b598743cd774dd78_l3.png?resize=8%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="8" alt="s" class="ql-img-inline-formula " /> is the rectified linear unit and <img src="https://i0.wp.com/blogs.princeton.edu/imabandit/wp-content/ql-cache/quicklatex.com-78d46af3f19bae0d88ac0cabd450a296_l3.png?resize=13%2C8&amp;ssl=1" style="vertical-align: 0px;" title="Rendered by QuickLaTeX.com" height="8" width="13" alt="w" class="ql-img-inline-formula " /> follows a Gaussian distribution, it is known that we recover the arc-cosine kernel. We may also note that <a href="http://papers.nips.cc/paper/3182-random-features-for-large-scale-kernel-machines.pdf" class="lipdf">random Fourier features</a> also yield a similar interpretation.</p>
<p>Other important links have also been drawn recently between kernel regression and strongly over-parametrized neural networks, see <a href="http://papers.nips.cc/paper/8076-neural-tangent-kernel-convergence-and-generalization-in-neural-networks.pdf" class="lipdf">this paper</a> and <a href="https://arxiv.org/pdf/1812.07956.pdf" class="lipdf">that one</a>, which is another exciting story.</p></div>







<p class="date">
by Sebastien Bubeck <a href="https://blogs.princeton.edu/imabandit/2019/07/17/guest-post-by-julien-mairal-a-kernel-point-of-view-on-convolutional-neural-networks-part-ii/"><span class="datestr">at July 17, 2019 04:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://minimizingregret.wordpress.com/?p=207">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/hazan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/">Boosting for Dynamical Systems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>by Nataly Brukhim, Naman Agarwal and Elad Hazan, based on <a href="https://arxiv.org/abs/1906.08720">this paper</a> </em></p>
<p>In a famous 1906 competition at a local fair in Plymouth, England, participants were asked to guess the weight of an ox. Out of a crowd of hundreds, no one came close to the ox’s actual weight, but the average of all guesses was almost correct. How is it that combining the opinions of laymen can somehow arrive at highly reasoned decisions, despite the weak judgment of individual members? This concept of harnessing wisdom from weak rules of thumb to form a highly accurate prediction rule, is the basis of ensemble methods and <b>boosting</b>. Boosting is a theoretically sound methodology that has transformed machine learning across a variety of applications; in classification and regression tasks, online learning, and many more.</p>
<p>In the case of online learning, examples for training a predictor are not available in advance, but are revealed one at a time. Online boosting combines a set of online prediction rules, or <i>weak learners. </i>At every time step, each weak learner outputs a prediction, suffers some loss and is then updated accordingly. The performance of an online learner is measured using the <i>regret</i> criterion, which compares the accumulated loss over time with that of the best fixed decision in hindsight. A <i>Boosting</i> algorithm can choose which examples are fed to each of the weak learners, as well as the losses they incur. Intuitively, the online booster can encourage some weak learners to become really good in predicting certain common cases, while allowing others to focus on edge cases that are harder to predict. Overall, the <a href="http://proceedings.mlr.press/v37/beygelzimer15.pdf">online</a> <a href="https://arxiv.org/abs/1506.04820">boosting</a> framework can achieve low regret guarantees based on the learners’ individual regret values.</p>
<p>However, online learning can become more challenging when our actions have consequences on the environment. This can be illustrated with the following experiment: imagine learning to balance a long pole on your hand. When you move your hand slightly, the pole tilts. You then move your hand in the opposite direction, and it bounces back and tilts to the other side. One jerk the wrong way might have you struggling for a good few seconds to rebalance. In other words, a <u>sequence of decisions</u> you made earlier determines whether or not the pole is balanced at any given time, rather than the single decision you make at that point.<img src="https://minimizingregret.files.wordpress.com/2019/07/image.jpeg?w=136&amp;h=129" title="" height="129" width="136" alt="" class=" aligncenter" /></p>
<p>More generally, consider cases when our environment has a <b>state, </b>and is in some sense “remembering” our past choices. A stateful framework, able to model a wide range of such phenomena, is a <i>dynamical system</i>. A dynamical system can be thought of as a function that determines, given the current state, what the state of the system will be in the next time step. Think of the physical dynamics that determines our pole’s position based on sequential hand movements. Other intuitive examples are the fluctuations of stock prices in the stock market, or the local weather temperatures; these can all be modeled with dynamical systems.</p>
<p>So how can boosting help us make better predictions for a dynamical system? In <a href="https://arxiv.org/abs/1906.08720">recent work</a> we propose an algorithm, which we refer to as DynaBoost, that achieves this goal. In the paper we provide theoretical regret bounds, as well as an empirical evaluation in a variety of applications, such as online control and time-series prediction.</p>
<p><b>Learning for Online Control</b></p>
<p>Control theory is a field of applied mathematics that deals with the control of various physical processes and engineering systems. The objective is to design an action rule, or <i>controller</i>, for a dynamical system such that steady state values are achieved quickly, and the system maintains stability.</p>
<p>Consider a simple Linear Dynamical System (LDS):</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=x_%7Bt%2B1%7D+%3D+A+x_t+%2B+B+u_t+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_{t+1} = A x_t + B u_t + w_t" class="latex" title="x_{t+1} = A x_t + B u_t + w_t" /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=x_t%2Cu_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_t,u_t" class="latex" title="x_t,u_t" /> are the state and control values at time t, respectively. Assume a known transition dynamics specified by the matrices A and B, and an arbitrary disturbance to the system given by <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" />. The goal of the controller is to minimize a convex cost function <img src="https://s0.wp.com/latex.php?latex=c_t%28x_t%2Cu_t%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="c_t(x_t,u_t)" class="latex" title="c_t(x_t,u_t)" />.</p>
<p>A provably optimal controller for the Gaussian noise case (where <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" /> are normally distributed) and when the cost functions are quadratic, is the Linear Quadratic Regulator (LQR). LQR computes a pre-fixed matrix K such that <img src="https://s0.wp.com/latex.php?latex=u_t%5E%7BLQR%7D+%3D+K+x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t^{LQR} = K x_t" class="latex" title="u_t^{LQR} = K x_t" />. In other words, LQR computes a linear controller – which linearly maps the state into a control at every time step.</p>
<p>A <a href="http://proceedings.mlr.press/v97/agarwal19c/agarwal19c.pdf">recent advancement</a> in online control considers <i>arbitrary</i> disturbances, as opposed to normally distributed noise. In this more general setting, there is no closed form for the optimal controller. Instead, it is proposed to use a weighted sum of previously observed noises, i.e., <img src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%7D+%3D+K+x_t+%2B+%5Csum_%7Bi%3D1%7D%5EH+M_i+w_%7Bt-i%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} " class="latex" title="u_t^{WL} = K x_t + \sum_{i=1}^H M_i w_{t-i} " /> , where <img src="https://s0.wp.com/latex.php?latex=M_1%2C...%2CM_H&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="M_1,...,M_H" class="latex" title="M_1,...,M_H" /> are learned parameters, updated in an online fashion. This method is shown to attain vanishing average regret compared to the best fixed linear controller in hindsight, and is applicable for general convex cost functions as opposed to only quadratics.</p>
<p>Crucially, the state-dependent term <img src="https://s0.wp.com/latex.php?latex=Kx_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="Kx_t" class="latex" title="Kx_t" /> is not learned. Since the learned parameters of the above controller therefore considers only a fixed number of recent disturbances, we can apply existing <a href="http://ocobook.cs.princeton.edu/">online convex optimization</a> techniques developed for <a href="https://papers.nips.cc/paper/6025-online-learning-for-adversaries-with-memory-price-of-past-mistakes">learning with loss functions that have bounded memory</a>.</p>
<p><strong>Boosting for Online Control</strong></p>
<p>Using the insights described above to remove state in online control, we can now use techniques from online boosting. DynaBoost maintains multiple copies of the base-controller above, with each copy corresponding to one stage in boosting. At every time step, the control <img src="https://s0.wp.com/latex.php?latex=u_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t" class="latex" title="u_t" /> is obtained from a convex combination of the base-controllers’ outputs <img src="https://s0.wp.com/latex.php?latex=u_t%5E%7BWL%281%29%7D%2C...%2Cu_t%5E%7BWL%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="u_t^{WL(1)},...,u_t^{WL(N)}" class="latex" title="u_t^{WL(1)},...,u_t^{WL(N)}" />. To update each base-controller’s parameters, DynaBoost feeds each controller with a <i>residual</i> <i>proxy </i>cost function, and seeks to obtain a minimizing point in the direction of the residual loss function’s gradient. Stability ensures that minimizing regret over the proxy costs (which have finite memory) suffices to minimize overall regret. See <a href="https://arxiv.org/abs/1906.08720">our paper</a> for the detailed description of the algorithm and its regret guarantees.</p>
<p><strong>Sanity check experiment</strong></p>
<p>We first conducted experiments for the standard LQR setting with i.i.d. Gaussian noise and known dynamics. We applied our boosting method to the non-optimal controller with learned parameters (Control-WL), and we observe that boosting improves its loss and achieves near-optimal performance (here the optimal controller is given by the fixed LQR solution). We have tested an LDS of different dimensions <img src="https://s0.wp.com/latex.php?latex=d+%3D+1%2C10%2C100&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="d = 1,10,100" class="latex" title="d = 1,10,100" />, and averaged results over multiple runs.</p>
<p><img width="624" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null.png?w=624&amp;h=182" title="" height="182" /></p>
<p><strong>Correlated noise experiment</strong></p>
<p>When the disturbances are not independently drawn, the LQR controller is not guaranteed to perform optimally. We experimented with two LDS settings with correlated disturbances in which (a) the disturbances <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" /> are generated from a Gaussian random-walk, and (b) where they are generated by a sine function applied to the time index. In these cases, boosted controllers perform better compared to the “weak” learned controller, and can also outperform the fixed LQR solution. We have also tested a Recurrent Neural Network, and observed that boosting is effective for RNNs as well.</p>
<p><img width="624" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-1.png?w=624&amp;h=266" title="" height="266" /></p>
<p><strong>Inverted Pendulum experiment</strong></p>
<p>A more challenging experiment with a non-linear dynamical system is the Inverted Pendulum experiment. This is very similar to the pole balancing example we discussed above, and is a standard benchmark for control methods. The goal is to balance the inverted pendulum by applying torque that will stabilize it in a vertically upright position, in the presence of noise. In our experiments, we used correlated disturbances from a Gaussian random-walk. We follow the dynamics implemented in <a href="https://gym.openai.com/">OpenAI Gym</a>, and test the performance of different controllers: LQR, a learned controller, and boosting. The video below visualizes this experiment:</p>
<div class="jetpack-video-wrapper"></div>
<p>When averaging the loss value over multiple experiment runs, we get the following plot:</p>
<p style="text-align: center;"><img width="369" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-2.png?w=369&amp;h=276" title="" height="276" /></p>
<p>It can be seen that the learned controller performs much better than the LQR in the presence of correlated noise, and that boosting can improve its stability and achieve lower average loss.</p>
<p><b>Boosting for Time-Series Prediction</b></p>
<p>Similarly to the control setting, in time-series prediction tasks it is sufficient to use fixed horizons, and online boosting can be efficiently applied here as well. In time-series prediction, the data is often assumed to be generated from an autoregressive moving average (ARMA) model:</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=x_%7Bt%7D+%3D+%5Csum_%7Bi%3D1%7D%5Ek+%5Calpha_i+x_%7Bt-i%7D+%2B+%5Csum_%7Bj%3D1%7D%5Eq+%5Cbeta_j+w_j+%2B+w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t" class="latex" title="x_{t} = \sum_{i=1}^k \alpha_i x_{t-i} + \sum_{j=1}^q \beta_j w_j + w_t" /></p>
<p>In words, each data point <img src="https://s0.wp.com/latex.php?latex=x_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_t" class="latex" title="x_t" /> is given by a weighted sum of previous points, previous noises and a new noise term <img src="https://s0.wp.com/latex.php?latex=w_t&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="w_t" class="latex" title="w_t" />, where <img src="https://s0.wp.com/latex.php?latex=%5Calpha%2C%5Cbeta&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\alpha,\beta" class="latex" title="\alpha,\beta" /> are the coefficients vectors.</p>
<p>To test our boosting method, We experimented with 4 simulated settings: 1) normally distributed noises, 2) coefficients of the dynamical system slowly change over time, 3) a single, abrupt, change of the coefficients, and, 4) correlated noise: Gaussian random walk.</p>
<p>The weak learners tested here are the ARMA-ONS (online newton step) and ARMA-OGD (online gradient descent) algorithms for time-series prediction (See <a href="http://proceedings.mlr.press/v30/Anava13.pdf">this</a> paper for more details). We applied our boosting method, as well as a fast version of it, which applies to quadratic loss functions (we used squared difference in this case).</p>
<p><i><b>1) Gaussian Noise </b></i> <i><b>2) Changing Coefficients</b></i></p>
<p><img width="289" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-3.png?w=289&amp;h=217" title="" height="217" /><img width="289" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-4.png?w=289&amp;h=217" title="" height="217" /><img width="292" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-5.png?w=292&amp;h=218" title="" height="218" /><img width="290" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-6.png?w=290&amp;h=217" title="" height="217" /></p>
<p><i><b>3) Abrupt Change </b></i> <i><b>4) Correlated Noise</b></i></p>
<p>We can see in the plots above that all weak learners’ loss values (red) can be improved by online boosting methods (blue). A similar observation arises when experimenting with real-world data; we experimented with the Air Quality dataset from the <a href="https://archive.ics.uci.edu/ml/index.php">UCI Machine Learning repository</a>, that contains hourly averaged measurements of air quality properties from an Italian city throughout one year, as measured by chemical sensors. We apply similar weak learners to this task, as well as our boosting algorithms. Here we again obtain better averaged losses for boosted methods (blue) compared to the baselines (red).</p>
<p style="text-align: center;"><img width="498" alt="" src="https://minimizingregret.files.wordpress.com/2019/07/null-7.png?w=498&amp;h=373" title="" height="373" /></p></div>







<p class="date">
by Elad Hazan <a href="https://minimizingregret.wordpress.com/2019/07/17/boosting-for-dynamical-systems/"><span class="datestr">at July 17, 2019 02:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=17564">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/">Dan Romik on the Riemann zeta function</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>This post about the Rieman zeta function, among the most important and mysterious mathematical objects is kindly written by Dan Romik. It is related to his paper <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>,  that we mentioned in <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">this post</a>.</em></p>
<h2>Dan Romik on the Riemann zeta function</h2>
<p>Recently when I was thinking about the Riemann zeta function, I had the double thrill of discovering some new results about it, and then later finding out that my new ideas were closely related to some very classical ideas due to two icons of twentieth-century mathematics, George Pólya and Pál Turán. When you are trying to stand on the shoulders of giants, it’s nice to see other giants right there beside you trying to do the same!</p>
<p>It all goes back to one of the most famous problems in mathematics, the Riemann Hypothesis (RH). Both Pólya and Turán were rather enamored with this problem and published about it extensively; Pólya was said to have been preoccupied with the problem to the very end of his life.(1) And they both recognized that an important first step in trying to prove something about the zeros of the zeta function is having a good representation<br />
for the Riemann zeta function. After all, there are many different formulas that can be used to define or compute the zeta function. If you don’t choose the right one, you probably won’t get very far with your analysis.</p>
<p>Pólya in one of his famous attacks on the problem considered the representation of the zeta function (or more precisely of the Riemann xi function, which is a symmetrized and better-behaved version of the zeta function; see below) as a Fourier transform—a standard representation due (essentially) to Riemann. I’ll have more to say about that later.</p>
<p>Turán also looked at the Riemann xi function, and instead of working with one of the standard “named” representations such as the Fourier transform or Taylor series, looked around a bit more intentionally for a representation of the function that seemed particularly suited to answering the specific question of whether the zeros all lie on a line. In a 1950 address to the Hungarian Academy of Sciences, he put forward his ideas about what he thought was the correct representation to look at: the infinite series expansion of the xi function in the Hermite polynomials. About eighty years after Turán’s discovery, my own investigations led me to discover [5] that the Hermite polynomials are not the only polynomials in which it’s interesting to expand the Riemann xi function. It turns out that there are at least two other families of polynomials for which the respective expansions are no less (and, in some ways, more) well-behaved. My motto for these polynomial families, which are known to experts in special functions but have until now been somewhat esoteric (though I hope that is about to change), is that they are “the coolest polynomials that you never heard of.”</p>
<p>Let’s look at some of the technical details so that I can explain why these new expansions are interesting, and how they relate to Turán’s work and ultimately back to Pólya’s ideas and one of the particular threads that grew out of them. First, define the Riemann xi function as</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cxi%28s%29+%3D+%5Cfrac12+s%28s-1%29+%5Cpi%5E%7B-s%2F2%7D+%5CGamma%5Cleft%28%5Cfrac%7Bs%7D%7B2%7D%5Cright%29+%5Czeta%28s%29+%5Cqquad+%28s%5Cin%5Cmathbb%7BC%7D%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), " class="latex" title="\displaystyle \xi(s) = \frac12 s(s-1) \pi^{-s/2} \Gamma\left(\frac{s}{2}\right) \zeta(s) \qquad (s\in\mathbb{C}), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5CGamma%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Gamma(z)}" class="latex" title="{\Gamma(z)}" /> is the Euler gamma function and <img src="https://s0.wp.com/latex.php?latex=%7B%5Czeta%28s%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\zeta(s)}" class="latex" title="{\zeta(s)}" /> is the Riemann zeta function. It’s also common to denote<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Cxi%5Cleft%28%5Cfrac12%2Bit%5Cright%29+%5Cqquad+%28t%5Cin%5Cmathbb%7BC%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). " class="latex" title="\displaystyle \Xi(t) = \xi\left(\frac12+it\right) \qquad (t\in\mathbb{C}). " /></p>
<p>This is Riemann’s “capital xi” function, which is still usually referred to as Riemann’s xi function. (This seems reasonable: the two functions are the same up to a trivial linear change of variables.) The main point of these definitions is that <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> is an entire function of the complex variable <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" />, and that RH can now be reformulated as the statement that the zeros of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> all lie on the real line. Moreover, the famous functional equation satisfied by the Riemann zeta function maps to the statement that <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> is an even function.<br />
Now consider the following four ways of representing the xi function:</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+a_%7B2n%7D+t%5E%7B2n%7D%2C%7E%7E%7E%7E%7E%281%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)" class="latex" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n a_{2n} t^{2n},~~~~~(1)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+b_%7B2n%7D+H_%7B2n%7D%28t%29%2C%7E%7E%7E%7E%7E%282%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)" class="latex" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n b_{2n} H_{2n}(t),~~~~~(2)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+c_%7B2n%7D+f_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29%2C%7E%7E%7E%7E%7E%283%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)" class="latex" title="\displaystyle\Xi(t) = \sum_{n=0}^\infty (-1)^n c_{2n} f_{2n}\left(\frac{t}{2}\right),~~~~~(3)" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CXi%28t%29+%3D+%5Csum_%7Bn%3D0%7D%5E%5Cinfty+%28-1%29%5En+d_%7B2n%7D+g_%7B2n%7D%5Cleft%28%5Cfrac%7Bt%7D%7B2%7D%5Cright%29.%7E%7E%7E%7E%7E%284%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)" class="latex" title="\displaystyle \Xi(t) = \sum_{n=0}^\infty (-1)^n d_{2n} g_{2n}\left(\frac{t}{2}\right).~~~~~(4)" /></p>
<p>Here, the first representation (1) is simply the Taylor expansion of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" />, which contains only even terms since <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> is an even function. The numbers <img src="https://s0.wp.com/latex.php?latex=%7Ba_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_{2n}}" class="latex" title="{a_{2n}}" /> are (up to the <img src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(-1)^n}" class="latex" title="{(-1)^n}" /> sign factor) the Taylor coefficients. Some attempts have been made to understand them, and one interesting and fairly trivial observation (again going back to facts already known to Riemann) is that they are all positive. Some additional and less trivial things can be said—see for example Section 6.1 of my paper [5], and the recent paper by Griffin, Ono, Rolen and Zagier [2]. But at the end of the day, no one has yet succeeded in using the Taylor expansion to prove anything new about the location of the zeros.</p>
<p>The second representation (2) is the infinite series expansion of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" /> in the classical sequence of Hermite polynomials, defined by the well-known formula</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+H_n%28t%29+%3D+%28-1%29%5En+e%5E%7Bt%5E2%7D+%5Cfrac%7Bd%5En%7D%7Bdt%5En%7D+%5Cleft%28+e%5E%7B-t%5E2%7D+%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). " class="latex" title="\displaystyle H_n(t) = (-1)^n e^{t^2} \frac{d^n}{dt^n} \left( e^{-t^2} \right). " /></p>
<p>This is the representation whose use was advocated by Turán. His reasoning was that expanding a function of a complex variable (for example, in the simplest case, a polynomial) in monomials <img src="https://s0.wp.com/latex.php?latex=%7Bt%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t^n}" class="latex" title="{t^n}" /> doesn’t provide useful information to easily decide if the function has only real zeros, because the monomials have, roughly speaking, radial symmetry: their level curves are concentric circles. The Hermite polynomials on the other hand, at least heuristically, have level curves that are closer to being straight lines parallel to the real axis, Turán argued; thus, they are more suited to the geometry of the problem we are trying to solve.</p>
<p>Turán’s case for supporting the Hermite polynomials as the right basis to use is quite detailed—you can read about it in his papers [6,7,8] (and no, he was not able to actually prove anything about the zeros of <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi(t)}" class="latex" title="{\Xi(t)}" />; this is a common theme in most of the attacks on RH to date…). I’ll simply mention that again one interesting and fairly easy observation is that the coefficients <img src="https://s0.wp.com/latex.php?latex=%7Bb_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_{2n}}" class="latex" title="{b_{2n}}" /> in the expansion (2)—adjusted through the introduction of the sign factor <img src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(-1)^n}" class="latex" title="{(-1)^n}" />—end up being positive numbers. Their asymptotic behavior can also be analyzed: I prove a result about this in my paper (though it’s not particularly pretty).</p>
<p>Now comes the part that to me seems the most exciting, involving the expansions (3) and (4). These are the expansions in the more exotic families of polynomials</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+f_n%28x%29%3D%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+2%5Ek%5Cbinom%7Bn%2B%5Cfrac12%7D%7Bn-k%7D%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k}," class="latex" title="\displaystyle f_n(x)=(-i)^n \sum_{k=0}^n 2^k\binom{n+\frac12}{n-k}\binom{-\frac34+ix}{k}," /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+g_n%28x%29%3D+%28-i%29%5En+%5Csum_%7Bk%3D0%7D%5En+%5Cfrac%7B%28n%2Bk%2B1%29%21%7D%7B%28n-k%29%21%283%2F2%29_k%5E2%7D+%5Cbinom%7B-%5Cfrac34%2Bix%7D%7Bk%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}" class="latex" title="\displaystyle g_n(x)= (-i)^n \sum_{k=0}^n \frac{(n+k+1)!}{(n-k)!(3/2)_k^2} \binom{-\frac34+ix}{k}" /></p>
<p>(where <img src="https://s0.wp.com/latex.php?latex=%7B%283%2F2%29_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(3/2)_n}" class="latex" title="{(3/2)_n}" /> is a <a href="https://en.wikipedia.org/wiki/Falling_and_rising_factorials">Pochhammer symbol</a>), mildly rescaled by replacing <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />  with <img src="https://s0.wp.com/latex.php?latex=%7Bt%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t/2}" class="latex" title="{t/2}" />. In the terminology of the theory of orthogonal polynomials, the family <img src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_n(x)}" class="latex" title="{f_n(x)}" /> is a special case of a two-parameter family <img src="https://s0.wp.com/latex.php?latex=%7BP_n%5E%7B%28%5Clambda%29%7D%28x%3B%5Cphi%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_n^{(\lambda)}(x;\phi)}" class="latex" title="{P_n^{(\lambda)}(x;\phi)}" /> known as the Meixner-Pollaczek polynomials, with the parameters taking the particular values <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%3D%5Cfrac%7B%5Cpi%7D%7B2%7D%2C+%5Clambda%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}" class="latex" title="{\phi=\frac{\pi}{2}, \lambda=\frac{3}{4}}" />. Similarly, the family <img src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_n(x)}" class="latex" title="{g_n(x)}" /> is a special case of the four-parameter family <img src="https://s0.wp.com/latex.php?latex=%7Bp_n%28x%3Ba%2Cb%2Cc%2Cd%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_n(x;a,b,c,d)}" class="latex" title="{p_n(x;a,b,c,d)}" /> known as the continuous Hahn polynomials, with the parameters taking the particular values <img src="https://s0.wp.com/latex.php?latex=%7Ba%3Db%3Dc%3Dd%3D%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a=b=c=d=\frac{3}{4}}" class="latex" title="{a=b=c=d=\frac{3}{4}}" />. Their main characterizing property is that they are orthogonal sequences of polynomials for two specific weight functions on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{R}}" class="latex" title="{\mathbb{R}}" />: the <img src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_n(x)}" class="latex" title="{f_n(x)}" /> are orthogonal with respect to the weight function <img src="https://s0.wp.com/latex.php?latex=%7Bw_1%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}" class="latex" title="{w_1(x)=\left|\Gamma\left(\frac34+ix\right)\right|^2}" />, and the <img src="https://s0.wp.com/latex.php?latex=%7Bg_n%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_n(x)}" class="latex" title="{g_n(x)}" /> are orthogonal with respect to <img src="https://s0.wp.com/latex.php?latex=%7Bw_2%28x%29%3D%5Cleft%7C%5CGamma%5Cleft%28%5Cfrac34%2Bix%5Cright%29%5Cright%7C%5E4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}" class="latex" title="{w_2(x)=\left|\Gamma\left(\frac34+ix\right)\right|^4}" />. Again, fairly esoteric. But interesting!</p>
<p>There are several things that make the expansions (3)–(4) well-behaved. First, the coefficients <img src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_{2n}}" class="latex" title="{c_{2n}}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_{2n}}" class="latex" title="{d_{2n}}" /> are again positive. This actually seems pretty relevant for questions like RH: for example, if we consider “toy” versions of (1)–(3) in which the coefficient sequences <img src="https://s0.wp.com/latex.php?latex=%7Ba_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_n}" class="latex" title="{a_n}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bb_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_n}" class="latex" title="{b_n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bc_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_n}" class="latex" title="{c_n}" /> are replaced by the sequence <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^n}" class="latex" title="{\alpha^n}" /> for fixed <img src="https://s0.wp.com/latex.php?latex=%7B0%3C%5Calpha%3C1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0&lt;\alpha&lt;1}" class="latex" title="{0&lt;\alpha&lt;1}" />, all three expansions sum up to rescaled cosines, which are entire functions that of course have only real zeros. (Without the <img src="https://s0.wp.com/latex.php?latex=%7B%28-1%29%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(-1)^n}" class="latex" title="{(-1)^n}" /> factor, we would get a hyperbolic cosine, which has imaginary zeros.)</p>
<p>Second, one can derive asymptotics for <img src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_{2n}}" class="latex" title="{c_{2n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_{2n}}" class="latex" title="{d_{2n}}" />, and they are quite a bit nicer than the asymptotic formulas for the Taylor and Hermite expansion coefficients. In my paper, I proved that <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+c_%7B2n%7D+%5Csim+A+%5Csqrt%7Bn%7D+e%5E%7B-B+%5Csqrt%7Bn%7D%7D%2C+%5Cqquad+d_%7B2n%7D+%5Csim+C+n%5E%7B4%2F3%7D+e%5E%7B-D+n%5E%7B2%2F3%7D%7D+%5Cqquad+%5Ctextrm%7Bas+%7Dn%5Crightarrow%5Cinfty%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, " class="latex" title="\displaystyle c_{2n} \sim A \sqrt{n} e^{-B \sqrt{n}}, \qquad d_{2n} \sim C n^{4/3} e^{-D n^{2/3}} \qquad \textrm{as }n\rightarrow\infty, " /> where <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%2CD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C,D}" class="latex" title="{A,B,C,D}" /> are the constants <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+A+%3D+16%5Csqrt%7B2%7D%5Cpi%5E%7B3%2F2%7D%2C+%5Cqquad+B+%3D+4%5Csqrt%7B%5Cpi%7D%2C+%5Cqquad+C+%3D+%5Cfrac%7B128+%5Ctimes+2%5E%7B1%2F3%7D+%5Cpi%5E%7B2%2F3%7D+e%5E%7B-2%5Cpi+%2F3%7D%7D%7B%5Csqrt%7B3%7D%7D%2C+%5Cqquad+D+%3D+3+%284%5Cpi%29%5E%7B1%2F3%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. " class="latex" title="\displaystyle A = 16\sqrt{2}\pi^{3/2}, \qquad B = 4\sqrt{\pi}, \qquad C = \frac{128 \times 2^{1/3} \pi^{2/3} e^{-2\pi /3}}{\sqrt{3}}, \qquad D = 3 (4\pi)^{1/3}. " /></p>
<p>Third, the expansions have some conceptual meaning: (3) turns out to be equivalent to the expansion of the elementary function <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bd%5E2%7D%7Bdu%5E2%7D+%28u+%5Ccoth%28%5Cpi+u%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{d^2}{du^2} (u \coth(\pi u))}" class="latex" title="{\frac{d^2}{du^2} (u \coth(\pi u))}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bu%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u&gt;0}" class="latex" title="{u&gt;0}" />, in an orthogonal basis of functions related to the Laguerre polynomials <img src="https://s0.wp.com/latex.php?latex=%7BL_n%5E%7B1%2F2%7D%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_n^{1/2}(x)}" class="latex" title="{L_n^{1/2}(x)}" />. And analogously, (4) arises out of the expansion of a certain auxiliary function <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7B%5Cnu%7D%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{\nu}(u)}" class="latex" title="{\tilde{\nu}(u)}" /> (I won’t define it here) in yet another classical family of orthogonal polynomials, the Chebyshev polynomials of the second kind.</p>
<p>Fourth (and fifth, sixth, …): the expansions are just… nice, in the sense that they arise in a way that seems natural when one asks certain questions, that they have excellent convergence properties, and that the coefficients <img src="https://s0.wp.com/latex.php?latex=%7Bc_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_{2n}}" class="latex" title="{c_{2n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bd_%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_{2n}}" class="latex" title="{d_{2n}}" /> have several elegant formulas, each revealing something interesting about them. Read the paper to understand more.</p>
<p>I said I will get back to Pólya’s work on RH. This post is already quite long so I will say only a little bit about this. One of Pólya’s major discoveries was that there are operations on entire functions that (under certain mild assumptions) preserve the property of the function having only real zeros. Specifically this is the case for the operation of multiplying the Fourier transform of the function by the factor <img src="https://s0.wp.com/latex.php?latex=%7Be%5E%7B%5Clambda+u%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e^{\lambda u^2}}" class="latex" title="{e^{\lambda u^2}}" /> for <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda&gt;0}" class="latex" title="{\lambda&gt;0}" />  (where <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> is the frequency variable). This opens the way to defining a family of deformations <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi_\lambda(t)}" class="latex" title="{\Xi_\lambda(t)}" /> of the Riemann xi function arising out of this operation, and trying to generalize RH by asking for which values of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> it is the case that <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi_\lambda(t)}" class="latex" title="{\Xi_\lambda(t)}" /> has only real zeros. Since Pólya’s work, and important later extensions of it by De Bruijn and Newman, this has become a very active topic of research, nowadays referred to under the name of the De Bruijn-Newman constant.<br />
See the recent survey of Newman and Wu [3], a 2018 paper by Rodgers and Tao [4] proving a major conjecture of Newman, and the recent paper [9] by the <a href="https://terrytao.wordpress.com/2018/12/28/polymath-15-eleventh-thread-writing-up-the-results-and-exploring-negative-t/">Polymath15 project</a> (mentioned by Gil in his <a href="https://gilkalai.wordpress.com/2019/02/28/dan-romik-studies-the-riemanns-zeta-function-and-other-zeta-news/">earlier post</a>), for the latest on this subject.</p>
<p>The connection I found between this topic and the idea of expanding the Riemann xi function in families of orthogonal polynomials is the following: expansions such as (2)–(4) suggest yet another natural way of “deforming” the Riemann xi function by adding a parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />: simply multiply the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />th term in the expansion by <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E%7B2n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^{2n}}" class="latex" title="{\alpha^{2n}}" /> (the linear operator that does this is called the Poisson kernel, and generalizes the standard Poisson kernel from complex analysis and the theory of harmonic functions). It turns out—and is actually easy to prove, and really isn’t terribly surprising in the grand scheme of things—that in the case of the Hermite expansion (2), this family of deformations is the same, up to some trivial reparametrization, as the family of deformations <img src="https://s0.wp.com/latex.php?latex=%7B%5CXi_%5Clambda%28t%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Xi_\lambda(t)}" class="latex" title="{\Xi_\lambda(t)}" /> that was studied in connection with the work of Pólya, De Bruijn, Newman and their successors. A nice connection between two threads of research that were not previously recognized as being related to each other, I think. Furthermore, this suggests that the Poisson kernel and associated deformations may yet have an important role to play in the context of the new expansions in the orthogonal polynomial families <img src="https://s0.wp.com/latex.php?latex=%7Bf_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_n}" class="latex" title="{f_n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bg_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g_n}" class="latex" title="{g_n}" />, where we get genuinely new families of deformations of the Riemann xi function. I explore this idea in my paper and it leads to some interesting things.</p>
<p>So let’s summarize. The key questions you are no doubt wondering about are: where does any of this lead? And do these new ideas say anything really useful or especially relevant for the Riemann hypothesis? The answer is that I don’t know (and I’m wondering about the same things). That being said, these orthogonal polynomial expansions seem quite interesting in their own right. The Riemann zeta function is a mysterious object, and there are <a href="https://en.wikipedia.org/wiki/Lindel%C3%B6f_hypothesis">other things</a> we wish to understand about it beside where its zeros are, so it’s always good to have additional points of view from which to approach it. Moreover, even on the question of the zeros there are reasons to be cautiously optimistic that this approach may have something useful to offer; see Chapter 7 of my paper for a brief discussion of why that is the case.</p>
<h2></h2>
<h2>References</h2>
<p>[1] D. Albers and G. L. Alexanderson, editors. Mathematical People: Profiles and Interviews. A K Peters, 2008.</p>
<p>[2] M. Griffin, K. Ono, L. Rolen and D. Zagier. Jensen polynomials for the Riemann zeta function and other sequences. Preprint (2019), <a href="https://arxiv.org/abs/1902.07321">arXiv:1902.07321</a>.</p>
<p>[3] C. M. Newman. Constants of de Bruijn-Newman type in analytic number theory and statistical physics. To appear in Bull. Amer. Math. Soc.</p>
<p>[4] B. Rodgers and T. Tao. The De Bruijn-Newman constant is nonnegative. Preprint (2018), <a href="https://arxiv.org/abs/1801.05914">arXiv:1801.05914</a>.</p>
<p>[5] D. Romik. <a href="https://arxiv.org/abs/1902.06330">Orthogonal polynomial expansions for the Riemann xi function</a>. Preprint (2019), <a href="https://arxiv.org/abs/1902.06330">arXiv:1902.06330</a>.</p>
<p>[6] P. Turán. Sur l’algèbre fonctionelle. Pages 279–290 in: Comptes Rendus du Premier Congrès des Mathématiciens Hongrois, 27 Août–2 Septembre 1950. Akadémiai Kiadó, 1952. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 677–688. Akadémiai Kiadó, 1990. An English translation of the paper by Dan Romik <a href="http://math.ucdavis.edu/~romik/data/uploads/misc/turan1952-english.pdf">On functional algebra</a>.</p>
<p>[7] P. Turán. Hermite-expansion and strips for zeros of polynomials. Arch. Math. 5 (1954), 148–152. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 1, pp. 738–742. Akadémiai Kiadó, 1990.</p>
<p>[8]  P. Turán. To the analytical theory of algebraic equations. Bulgar. Akad. Nauk. Otd. Mat. Fiz. Nauk. Izv. Mat. Inst. 3 (1959), 123–137. Reprinted in Collected Papers of Paul Turán, Ed. P. Erdos, Vol. 2, pp. 1080–1090. Akadémiai Kiadó, 1990.</p>
<p>[9] D.H.J. Polymath. Effective approximation of heat flow evolution of the Riemann ξ function, and a new upper bound for the de Bruijn-Newman constant. Preprint (2019), <a href="https://arxiv.org/abs/1904.12438">arXiv:1904.12438</a>.</p>
<h2>Notes:</h2>
<p>(1) Alexanderson writes in [1, p. 259]: “A week or so before he died, Pólya asked me to look on his desk at home for some papers on which he said he had written down some interesting ideas he had for proving RH. Of course I could find no such notes, but until the day he died he was thinking about that famous problem.”</p>
<p> </p>
<p>(2) Turán’s Hungarian Academy of Sciences talk was published in a rather obscure French-language paper [6] that seems to have been largely forgotten. It’s an interesting read nonetheless, and to make it more accessible to anyone who may be interested, I recently translated it to English.</p>
<p> </p>
<p>(3) Turán mentions in [8] that he discovered the results on the Hermite expansion in 1938–39, but they were not published until much later. Clearly this was not a convenient time in history for publishing such discoveries; Turán, a Hungarian Jew, spent much of World War II interned in labor camps in Hungary.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/07/17/dan-romik-on-the-riemann-zeta-function/"><span class="datestr">at July 17, 2019 06:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16114">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/07/16/summer-reading-in-theory/">Summer Reading in Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Some formative books in mathematics and computing theory</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg"><img src="https://rjlipton.files.wordpress.com/2019/07/biggs-norman-150x150.jpg?w=600" alt="" class="alignright size-full wp-image-16115" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">LSE <a href="https://blogs.lse.ac.uk/maths/2016/04/15/norman-biggs-calculus-on-clay/">source</a>: <i>“Calculus on Clay?”</i></font></td>
</tr>
</tbody>
</table>
<p>
Norman Biggs is the author of the wonderful <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC">book</a> <em>Algebraic Graph Theory</em>. Both Ken and I read it long ago, and both of us have it out now because of its relevance to Hao Huang’s beautiful short <a href="http://www.mathcs.emory.edu/~hhuan30/papers/sensitivity_1.pdf">proof</a> of the Boolean Sensitivity Conjecture. </p>
<p>
Today we wish to ask, <i>What are your top five favorite books on mathematics and theory for summer reading?</i></p>
<p>
There’s an <a href="https://en.wikipedia.org/wiki/Aporia">aporia</a> in that question. A working definition of aporia is: “a self-contradiction that isn’t.” The point is that books for summer reading should be new, so how would you already know which are your favorites? Well, we are thinking of books that are so rich you can always find new things in them—and that also played formative roles earlier in our careers.</p>
<p>
Ken knew Biggs during his first year at Oxford when Biggs was visiting there from London. He took part in a weekly sitting-room seminar organized by Peter Neumann. Biggs’s book was a central reference for Ken’s undergraduate senior thesis at Princeton, and both he and Ken presented material based on it. </p>
<p>
</p><p></p><h2> Best Five Books—Dick </h2><p></p>
<p></p><p>
Here are my votes for all-time best books in mathematics and in computer science theory.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.cambridge.org/core/books/algebraic-graph-theory/6C70471342F19680068C35EF174075DC"><i>Algebraic Graph Theory</i></a>, by Norman Biggs. A wonderful book. First appeared in 1974.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.amazon.com/Introduction-Probability-Theory-Applications-Vol/dp/0471257087/ref=sr_1_1?keywords=William+Feller&amp;qid=1563190401&amp;s=books&amp;sr=1-1"><i> An Introduction to Probability Theory and Its Applications, Vol. 1</i></a>, by William Feller. This is the book I used to learn probability theory.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.amazon.com/gp/product/0199219869/ref=as_li_tl?ie=UTF8&amp;tag=mathblog05-20&amp;camp=1789&amp;creative=9325&amp;linkCode=as2&amp;creativeASIN=0199219869&amp;linkId=a71963a143733e948f50588526d624c0"><i> An Introduction to the Theory of Numbers</i></a>, by Godfrey Hardy and Edward Wright. Now updated by Andrew Wiles, Roger Heath-Brown, and Joseph Silverman. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.amazon.com/Elements-Number-Theory-Dover-Mathematics/dp/0486781658/ref=sr_1_1?keywords=Vinogradov&amp;qid=1563190340&amp;s=books&amp;sr=1-1"><i>Elements of Number Theory</i></a>, by Ivan Vinogradov. Another small book that is loaded with ideas. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <a href="https://www.abebooks.com/Paul-Erds-Art-Counting-Erdos-Joel/13380002114/bd"><i>The Art of Counting</i></a>, by Paul Erdős and Joel Spencer. This book changed my life. Today the book is of course <a href="https://www.amazon.com/dp/0470170204/?tag=stackoverfl08-20"><i>The Probabilistic Method</i></a>, by Noga Alon and Joel Spencer. </p>
<p>
</p><p></p><h2> Best Five Books—Ken </h2><p></p>
<p></p><p>
Ken reaches back to his teen years but it’s still the same span of years as my list. Here he tells it:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> All books by Martin Gardner—in particular, the books of collections of his “Mathematical Games” columns in <em>Scientific American</em>. Here is an <a href="https://blogs.scientificamerican.com/guest-blog/the-top-10-martin-gardner-scientific-american-articles/">overview</a>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://www.lybrary.com/scarne-on-dice-p-655.html"><i>Scarne on Dice</i></a> and <a href="https://www.lybrary.com/scarne-on-cards-p-759.html"><i> Scarne on Cards</i></a>. Originally it was neither of these books—nor John Scarne’s <em>Complete Guide to Gambling</em>—but a different book on in which both Scarne and Gardner figured prominently. Alas I, Ken, cannot trace it. That’s what I used to learn probability theory.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://www.amazon.com/Spectra-Graphs-Application-Applied-Mathematics/dp/0121951502"><i>Spectra of Graphs</i></a>, by Dragoš Cvetković, Michael Doob, and Horst Sachs. I could put Biggs’s book here, but this is the one that got me on to the whole subject just before my senior year at Princeton. It was fresh out in 1980—I recall the tactile sensation of the dark green spanking new cover in the Fine Hall Library’s copy. A great book with pictures and algebra. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://www.amazon.com/Ideals-Varieties-Algorithms-Computational-Undergraduate/dp/0387356509"><i> Ideals, Varieties, and Algorithms</i></a>, by David Cox, John Little, and Donal O’Shea. Fast forward to 1997. Having realized that techniques from algebraic geometry could surmount the “Natural Proofs” <a href="https://rjlipton.wordpress.com/2009/03/25/whos-afraid-of-natural-proofs/">barrier</a> (see also <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">GCT</a>), I went whole-hog after it. See “Manic Monomials” in this <a href="https://rjlipton.wordpress.com/2012/07/04/july-fourth-sale-of-ideas/">post</a> for one thing that tripped it up. The book remains incredibly stimulating. It has a <a href="https://www.amazon.com/Using-Algebraic-Geometry-Graduate-Mathematics/dp/0387984879/">sequel</a>, <em>Using Algebraic Geometry</em>.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://en.wikipedia.org/wiki/Quantum_Computation_and_Quantum_Information"><i>Quantum Computation and Quantum Information</i></a> by Michael Nielsen and Isaac Chuang. As with Hardy and Wright, it has its own Wikipedia page. Dick and I can say this is nominating a competitor, but Chaung &amp; Nielsen is really in a class by itself for the sheer richness and writing style. One odd mark of its influence: In 2006 when I reacted to the sensational and frightening accusations of cheating at the world championship <a href="https://en.wikipedia.org/wiki/World_Chess_Championship_2006">match</a>, my first thought was to apply distributional distance measures of the kind used in its later chapters. Among such measures is (quantum) <a href="https://en.wikipedia.org/wiki/Fidelity_of_quantum_states">fidelity</a>, and although I focused more on Jensen-Shannon divergence before deciding on simpler stuff, my chess research <a href="https://cse.buffalo.edu/~regan/chess/fidelity/">website</a> retains “fidelity” in its name as part of a multi-way reference to <a href="https://en.wikipedia.org/wiki/FIDE">FIDE</a>, faith, and playing in good faith.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What books most influenced you? What are your votes for the best books that might influence others?	 </p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/07/16/summer-reading-in-theory/"><span class="datestr">at July 17, 2019 04:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6069637759837834972">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html">Guest post by Samir Khuller on attending The TCS Women 2019 meeting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
(I will post the solution to the problem in the last blog later in the week---probably Thursday. Meanwhile, enjoy these thoughts from Samir Khuller on the TCS Women 2019 meeting.)<br />
<br />
Guest Post by Samir Khuller:<br />
<br />
Am I even allowed here?” was the first thought that crossed my mind when I entered the room. It was packed with women (over 95%), however a few minutes later, several men had trickled in. I was at the TCS Women spotlight workshop on the day before STOC. Kudos to Barna Saha, Sofya Raskhodnikova, and Virginia Vassilevska Williams for putting this grand (and long needed) event together, which serves as a role model and showcases some of the recent work by rising stars. In addition to the Sun afternoon workshop, the event was followed by both an all women panel and a poster session (which I sadly did not attend).<br />
<br />
<br />
The rising stars talks were given by Naama Ben-David (CMU), Andrea Lincoln (MIT), Debarati Das (Charles University) and Oxana Poburinnaya (Boston U). After a short break the inspirational talk was by Ronitt Rubinfeld from MIT.  Ronitt’s talk was on the topic of Program Checking, but she made it inspirational by putting us in her shoes as a young graduate student, three decades back, trying to make a dent in research by working on something that her advisor Manuel Blum, and his senior graduate student Sampath Kannan had been working on, and I must say she made a pretty big dent in the process! She also related those ideas to other pieces of work done since in a really elegant manner and how these pieces of work lead to work on property testing.<br />
<br />
<br />
I am delighted to say that NSF supported the workshop along with companies such as Amazon, Akamai, Google and Microsoft. SIGACT plans to be a major sponsor next year.<br />
<br />
<br />
The Full program for the workshop is at the following URL<a href="https://sigact.org/tcswomen/tcs-women-2019/">here.</a><br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/07/guest-post-by-samir-khuller-on.html"><span class="datestr">at July 16, 2019 11:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/094">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/094">TR19-094 |  Rainbow coloring hardness via low sensitivity polymorphisms | 

	Venkatesan Guruswami, 

	Sai Sandeep</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A $k$-uniform hypergraph is said to be $r$-rainbow colorable if there is an $r$-coloring of its vertices such that every hyperedge intersects all $r$ color classes. Given as input such a hypergraph, finding a $r$-rainbow coloring of it is NP-hard for all $k \ge 3$ and $r \ge 2$. Therefore, one settles for finding a rainbow coloring with fewer colors (which is an easier task).  When $r=k$ (the maximum possible value), i.e., the hypergraph is $k$-partite, one can efficiently $2$-rainbow color the hypergraph, i.e., $2$-color its vertices so that there are no monochromatic edges. In this work we consider the next smaller value of $r=k-1$, and prove that in this case it is NP-hard to rainbow color the hypergraph with $q :=  \lceil \frac{k-2}{2} \rceil$ colors. In particular, for $k \le 6$, it is NP-hard to $2$-color $(k-1)$-rainbow colorable $k$-uniform hypergraphs.

Our proof follows the algebraic approach to promise constraint satisfaction problems. It proceeds by characterizing the polymorphisms associated with the approximate rainbow coloring problem, which are rainbow colorings of some product hypergraphs on vertex set $[r]^n$. We prove that any such polymorphism $f: [r]^n \to [q]$ must be $C$-fixing, i.e., there is a small subset $S$ of $C$ coordinates and a setting $a \in [q]^S$ such that fixing $x_{|S} = a$ determines the value of $f(x)$. The key step in our proof is bounding the sensitivity of certain rainbow colorings, thereby arguing that they must be juntas. Armed with the $C$-fixing characterization, our NP-hardness is obtained via a reduction from smooth Label Cover.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/094"><span class="datestr">at July 16, 2019 01:19 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/093">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/093">TR19-093 |  Improved 3LIN Hardness via Linear Label Cover | 

	Euiwoong Lee, 

	Subhash Khot, 

	Prahladh Harsha, 

	Devanathan Thiruvenkatachari</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove that for every constant $c$ and $\epsilon = (\log n)^{-c}$, there is no polynomial time algorithm that when given an instance of 3LIN with $n$ variables where an $(1 - \epsilon)$-fraction of the clauses are satisfiable, finds an assignment that satisfies at least $(\frac{1}{2} + \epsilon)$-fraction of clauses unless $\mathbf{NP} \subseteq \mathbf{BPP}$. The previous best hardness using a polynomial time reduction achieves $\epsilon = (\log \log n)^{-c}$, which is obtained by the Label Cover hardness of Moshkovitz and Raz [J. ACM, 57(5), 2010] followed by the reduction from Label Cover to 3LIN of Hastad [J. ACM, 48(4):798--859, 2001].

Our main idea is to prove a hardness result for Label Cover similar to Moshkovitz and Raz where each projection has a linear structure. This linear structure of Label Cover allows us to use Hadamard codes instead of long codes, making the reduction more efficient. For the hardness of Linear Label Cover, we follow the work of Dinur and Harsha [SIAM J. Comput., 42(6):2452--2486, 2013] that simplified the construction of Moshkovitz and Raz, and observe that running their reduction from a hardness of the problem LIN (of unbounded arity) instead of the more standard problem of solving quadratic equations ensures the linearity of the resultant Label Cover.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/093"><span class="datestr">at July 16, 2019 01:10 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/07/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/07/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://www.insidehighered.com/news/2019/07/01/about-700-academics-have-been-criminally-charged-turkey-their-signatures-petition">Turkey has charged over 700 academics with terrorism for signing a peace petition</a> (<a href="https://mathstodon.xyz/@11011110/102367088461002886"></a>). Among the most severely penalized is <a href="https://en.wikipedia.org/wiki/Tuna_Alt%C4%B1nel">Tuna Altınel</a>, a mathematician in France who was arrested visiting family in Turkey, and who <a href="http://math.univ-lyon1.fr/SoutienTunaAltinel/?lang=en">has now been imprisoned for over 50 days</a> (<a href="https://cameroncounts.wordpress.com/2019/05/31/tuna-altnel/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://web.cs.elte.hu/~lovasz/bookxx/geomgraphbook/geombook2019.01.11.pdf">László Lovász’s book “Graphs and Geometry”, on geometric representations of graphs</a> (<a href="https://mathstodon.xyz/@11011110/102374639115017977"></a>, <a href="https://news.ycombinator.com/item?id=20317825">via</a>). <a href="https://bookstore.ams.org/coll-65">The print version</a> should appear in a month or so from the AMS.</p>
  </li>
  <li>
    <p><a href="https://www.insidehighered.com/quicktakes/2019/06/28/huge-budget-cut-university-alaska">University of Alaska budget gutted by 40%</a> (<a href="https://mathstodon.xyz/@11011110/102381510293748063"></a>, <a href="https://www.metafilter.com/181768/We-dont-need-no-stinkin-edumaction">see also</a>). The total amount cut over the past five years (including this new biggest cut) is <a href="https://www.chronicle.com/article/Unprecedented-in-Our/246596">more like 63%, from $522M to $192M</a>. And <a href="https://www.npr.org/2019/07/03/738569508/university-of-alaska-readies-for-budget-slash-we-may-likely-never-recover">the likely response is to close one of its three main campuses and all 13 smaller community campuses</a>. Ironically, the cause is right-wing insistence on a universal basic income of $3000/person from fuel extraction revenues.</p>
  </li>
  <li>
    <p><a href="https://aperiodical.com/category/the-big-internet-math-off/">The annual Big Internet Math-off — view and vote on your favorites!</a> (<a href="https://mathstodon.xyz/@11011110/102385386477969762"></a>). 
The first few matches include <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-1-alex-corner-vs-lucy-rycroft-smith/">commutativity of log-exponentiation vs weather infovis</a>, the <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-2-marianne-rachel-vs-vincent-pantaloni/">geometry of the Sydney Opera House vs straight lines on a donut</a>, <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-3-vicky-neale-vs-jim-propp/">multiplication tables and muffins</a> and <a href="https://aperiodical.com/2019/07/the-big-internet-math-off-2019-group-4-colin-beveridge-vs-kyle-d-evans/">a video on shapes in La Sagrada Familia (shot on location?!) vs an introduction to fractals</a>. More daily for roughly a month.</p>
  </li>
  <li>
    <p><a href="https://www.scmp.com/magazines/post-magazine/long-reads/article/3016267/chinese-scientists-guilty-researching-while">Chinese scientists guilty of “researching while Asian” in Trump’s America</a> (<a href="https://mathstodon.xyz/@11011110/102390640744960409"></a>, <a href="https://news.ycombinator.com/item?id=20319936">via</a>, <a href="https://www.bloomberg.com/news/features/2019-06-13/the-u-s-is-purging-chinese-americans-from-top-cancer-research">see also</a>). The story focuses on star cancer researcher <a href="https://en.wikipedia.org/wiki/Xifeng_Wu">Xifeng Wu</a>, forced to resign from the University of Texas, apparently because she fostered collaboration with Chinese cancer research institutions at the behest of her higher administration.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@ccppurcell/102133405425258779">Chris Purcell thinks about graphs with degree sequence </a>. They have to have at least one cycle of each parity.</p>
  </li>
  <li>
    <p><a href="https://petapixel.com/2019/07/05/goodbye-aberration-physicist-solves-2000-year-old-optical-problem/">A formula for designing lenses with no spherical aberration</a> (<a href="https://mathstodon.xyz/@11011110/102401888807980335"></a>, <a href="https://news.ycombinator.com/item?id=20369960">via</a>). This seems to have little practical value as there was already a numerical solution, and I don’t think it handles chromatic aberration, but it’s interesting that there is an analytic formula for these shapes.</p>
  </li>
  <li>
    <p>Last week I traveled to Milan for the <a href="https://sgp2019.di.unimi.it/">Symposium on Geometry Processing</a> (<a href="https://mathstodon.xyz/@11011110/102407039766140849"></a>). They also have an <a href="https://twitter.com/geometryprocess">official twitter stream</a>, mostly consisting of event photos. The sightseeing highlight of my trip was seeing pages of <a href="https://www.ambrosiana.it/en/discover/codex-atlanticus/">Da Vinci’s Codex Atlanticus at the Ambrosian Library</a>.</p>
  </li>
  <li>
    <p><a href="https://boingboing.net/2019/07/08/check-out-this-cool-synthesize.html">Evoboxx</a> (<a href="https://mathstodon.xyz/@11011110/102412280507996705"></a>), a retro-styled portable device that does only two things: run Conway’s Game of Life and generate sounds from it. Not very practical in these days of cell phones but then maybe that’s what makes it a fun project.</p>
  </li>
  <li>
    <p><a href="http://jdh.hamkins.org/modal-model-theory/">Modal model theory</a> (<a href="https://mathstodon.xyz/@11011110/102418646790775178"></a>). For graphs, this extends first order logic (where the only quantification is over vertices and the only predicate is adjacency) with operators  and .  is true when all supergraphs model  and  is true when at least one supergraph models . This can express nontrivial graph properties like -colorability, and comes in two variants depending on whether you can quantify outside the operators.</p>
  </li>
  <li>
    <p><a href="https://www.instagram.com/p/ByH-R4Ql-NA/">Very quick video tutorial on how to make the Miura-ori fold</a>, by Polly Verity (<a href="https://mathstodon.xyz/@11011110/102429787082169299"></a>, <a href="https://www.thisiscolossal.com/2019/07/new-polly-verity/">via</a>).</p>
  </li>
  <li>
    <p><a href="http://jtra.cz/stuff/essays/math-self-reference-smooth/index.html">Trávník’s smooth self-referential formula</a> (<a href="https://mathstodon.xyz/@11011110/102435762025301458"></a>, <a href="https://twitter.com/johncarlosbaez/status/1141376710551601152">via</a>). It is actually a linked set of formulas, described in a typeset image, that when plotted as described in the image produces the image itself. It follows the same ideas as earlier self-referential formulas like <a href="https://en.wikipedia.org/wiki/Tupper%27s_self-referential_formula">Tupper’s self-referential formula</a> but unlike them describes a smooth vector image based on splines instead of a pixelated bitmap.</p>
  </li>
  <li>
    <p><a href="http://muurformules.nl/">Leiden wall formulas</a> (<a href="https://mathstodon.xyz/@11011110/102444110227078604"></a>). The last time I was in Leiden they were decorating the exterior walls of all their buildings with poems of many different languages. Now they’ve moved on to the language of mathematics.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=eYfpSAxGakI">Numberphile video on Dehn invariants</a> (15-minutes; <a href="https://mathstodon.xyz/@11011110/102448538574760818"></a>). The Dehn invariant is a value derived from a polyhedron that doesn’t change if you cut up the polyhedron into smaller polyhedral pieces and rearrange them into a different polyhedron. It’s 0 for the cube and nonzero for other Platonic solids, proving that they can’t be cut and rearranged into a cube. See <a href="https://en.wikipedia.org/wiki/Dehn_invariant">the Wikipedia article</a> for more technical details.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/07/15/linkage.html"><span class="datestr">at July 15, 2019 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16778">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/">Itai Benjamini and Jeremie Brieussel: Noise Sensitivity Meets Group Theory</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The final  version of my ICM 2018 paper <a href="https://gilkalai.files.wordpress.com/2019/07/main-pf.pdf">Three puzzles on mathematics computation and games</a> is available for some time. (This proceeding’s version unlike the arXived version has a full list of references.)  In this post I would like to advertise one problem that I mentioned in the paper. You can read more about it in the paper  by Itai Benjamini and  Jeremie Brieussel  <a href="https://arxiv.org/abs/1901.03617">Noise sensitivity of random walks on groups</a> and learn about it also from the videotaped lecture by Jeremie. BTW, the name of my ICM paper is a tribute to Avi Wigdeson’s great book <strong><a href="https://www.math.ias.edu/files/Website03-25-19.pdf#page=1" target="”_blank”">Mathematics and Computation</a> </strong>(see <a href="https://gilkalai.wordpress.com/2017/10/27/must-read-book-by-avi-wigderson/">this post</a>). Click on the title for an  almost final draft of Avi’s book (March, 25, 2019) soon to be published by Princeton University Press<strong>. </strong>(We are negotiating with Avi on showing here first how the cover of his book will look like.)</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/07/friends-of-noise.png?w=640&amp;h=381" class="alignnone size-full wp-image-17590" height="381" /></a></p>
<p><a href="http://friendsofnoise.org/about/">source</a></p>
<h2>The problem of Benjamini and Brieussel and their conjecture</h2>
<p> </p>
<p></p>
<p>Consider an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-step simple random walk (SRW) <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> on a Cayley graph of a finitely generated infinite group <img src="https://s0.wp.com/latex.php?latex=%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Gamma" class="latex" title="\Gamma" />. Refresh independently each step with probability <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />, to get <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> from <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" />. Are there groups for which at time <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> the positions <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> and <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> are asymptotically independent? That is, does the <img src="https://s0.wp.com/latex.php?latex=l_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="l_1" class="latex" title="l_1" /> (total variation) distance between the chain <img src="https://s0.wp.com/latex.php?latex=%28X_n%2C+Y_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(X_n, Y_n)" class="latex" title="(X_n, Y_n)" /> and two independent copies <img src="https://s0.wp.com/latex.php?latex=%28X%27_n%2C+X%27%27_n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(X'_n, X''_n)" class="latex" title="(X'_n, X''_n)" /> go to 0, as <img src="https://s0.wp.com/latex.php?latex=n+%5Cto+%5Cinfty&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n \to \infty" class="latex" title="n \to \infty" />?</p>
<p>Note that on the line <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+Z&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb Z" class="latex" title="\mathbb Z" />, they are uniformally correlated, and therefore also on any group with a nontrivial homomorphism to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R" class="latex" title="\mathbb R" />, or on any group that has a finite index subgroup with a nontrivial homomorphism to <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb R" class="latex" title="\mathbb R" />. On the free group and for any non-Liouville group, <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> and <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> are correlated as well, but for a different reason: both <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" /> and <img src="https://s0.wp.com/latex.php?latex=Y_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y_n" class="latex" title="Y_n" /> have a nontrivial correlation with <img src="https://s0.wp.com/latex.php?latex=X_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_1" class="latex" title="X_1" />.</p>
<p>Itai Benjamini and Jeremie Brieussel conjecture that these are the only ways not to be noise sensitive. That is, if a Cayley graph is Liouville and the group does not have a finite index subgroup with a homomorphism to the reals, then the Cayley graph is noise sensitive for the simple random walk. In particular, the Grigorchuk group is noise sensitive for the simple random walk!</p>
<h3>A paragraph of philosophical nature from Benjamini and Brieussel’s paper.</h3>
<p>“Physically, an <em>ℓ</em><img src="https://s0.wp.com/latex.php?latex=%5E1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="^1" class="latex" title="^1" />-noise sensitive process can somewhat not be observed, since the observation <img src="https://s0.wp.com/latex.php?latex=Y%5E%5Crho_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y^\rho_n" class="latex" title="Y^\rho_n" /> does not provide any significant information on the actual output <img src="https://s0.wp.com/latex.php?latex=X_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X_n" class="latex" title="X_n" />. Speculatively, this could account for the rarity of Liouville groups in natural science. Indeed besides virtually nilpotent ones, all known Liouville groups are genuinely mathematical objects .”</p>
<h3>Polytope integrality gap: An update</h3>
<p>An update on polytope integrality gap:  In my ICM paper and also in <a href="https://gilkalai.wordpress.com/2018/01/21/hardness-of-approximating-vertex-cover-polytope-integrality-gap-the-alswede-kachaterian-theorem-and-more/">this post</a>  I asked the beautiful problem that I learned from Anna Karlin if for vertex cover for every graph G and every vector of weights, there is an efficient algorithm achieving the “polytope integrality gap”.  Anna Karlin kindly informed me that <a href="https://www2.isye.gatech.edu/~msingh94/publications.html">Mohit Singh</a> got in touch with her after seeing the conjecture on my blog and pointed out that the hope for approximating the polytope integrality gap for vertex cover is unlikely to be possible because of its relationship to fractional chromatic number. Mohit noted that fractional chromatic number is hard to approximate even when it is constant assuming UGC. I still think that  the notion of polytope integrality gap for vertex cover as well as for more general problems is important and worth further study.</p>
<p> </p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/07/15/itai-benjamini-and-jeremie-brieussel-noise-sensitivity-meets-group-theory/"><span class="datestr">at July 15, 2019 08:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
