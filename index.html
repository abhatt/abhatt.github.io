<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at August 11, 2020 08:21 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.04183">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.04183">Connected Components in Undirected Set--Based Graphs. Applications in Object--Oriented Model Manipulation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kofman:Ernesto.html">Ernesto Kofman</a>, Denise Marzorati, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fern=aacute=ndez:Joaqu=iacute=n.html">Joaquín Fernández</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.04183">PDF</a><br /><b>Abstract: </b>This work introduces a novel algorithm for finding the connected components
of a graph where the vertices and edges are grouped into sets defining a
Set--Based Graph. The algorithm, under certain restrictions on those sets, has
the remarkable property of achieving constant computational costs with the
number of vertices and edges. The mentioned restrictions are related to the
possibility of representing the sets of vertices by intension and the sets of
edges using some particular type of maps. While these restrictions can result
strong in a general context, they are usually satisfied in the problem of
transforming connections into equations in object oriented models, which is the
main application of the proposed algorithm.
</p>
<p>Besides describing the new algorithm and studying its computational cost, the
work describes its prototype implementation and shows its application in
different examples.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.04183"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.04125">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.04125">Storyline Visualizations with Ubiquitous Actors</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Giacomo:Emilio_Di.html">Emilio Di Giacomo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Didimo:Walter.html">Walter Didimo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liotta:Giuseppe.html">Giuseppe Liotta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montecchiani:Fabrizio.html">Fabrizio Montecchiani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tappini:Alessandra.html">Alessandra Tappini</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.04125">PDF</a><br /><b>Abstract: </b>Storyline visualizations depict the temporal dynamics of social interactions,
as they describe how groups of actors (individuals or organizations) change
over time. A common constraint in storyline visualizations is that an actor
cannot belong to two different groups at the same time instant. However, this
constraint may be too severe in some application scenarios, thus we generalize
the model by allowing an actor to simultaneously belong to distinct groups at
any point in time. We call this model Storyline with Ubiquitous Actors (SUA).
Essential to our model is that an actor is represented as a tree rather than a
single line. We describe an algorithmic pipeline to compute storyline
visualizations in the SUA model and discuss case studies on publication data.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.04125"><span class="datestr">at August 11, 2020 01:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.04124">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.04124">Expected Performance and Worst Case Scenario Analysis of the Divide-and-Conquer Method for the 0-1 Knapsack Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Fernando A Morales, Jairo A Martínez <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.04124">PDF</a><br /><b>Abstract: </b>In this paper we furnish quality certificates for the Divide-and-Conquer
method solving the 0-1 Knapsack Problem: the worst case scenario and estimates
for the expected performance. The probabilistic setting is given and the main
random variables are defined for the analysis of the expected performance. The
efficiency is rigorously approximated for one iteration of the method then,
these values are used to derive analytic estimates for the performance of a
general Divide-and-Conquer tree. All the theoretical results are verified with
statistically suited numerical experiments for a wider illustration of the
method.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.04124"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.04116">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.04116">A Phase Transition in Minesweeper</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Ross Dempsey, Charles Guinn <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.04116">PDF</a><br /><b>Abstract: </b>We study the average-case complexity of the classic Minesweeper game in which
players deduce the locations of mines on a two-dimensional lattice. Playing
Minesweeper is known to be co-NP-complete. We show empirically that Minesweeper
exhibits a phase transition analogous to the well-studied SAT phase transition.
Above the critical mine density it becomes almost impossible to play
Minesweeper by logical inference. We use a reduction to Boolean
unsatisfiability to characterize the hardness of Minesweeper instances, and
show that the hardness peaks at the phase transition. Furthermore, we
demonstrate algorithmic barriers at the phase transition for polynomial-time
approaches to Minesweeper inference. Finally, we comment on expectations for
the asymptotic behavior of the phase transition.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.04116"><span class="datestr">at August 11, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03909">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03909">ConnectIt: A Framework for Static and Incremental Parallel Graph Connectivity Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhulipala:Laxman.html">Laxman Dhulipala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hong:Changwan.html">Changwan Hong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shun:Julian.html">Julian Shun</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03909">PDF</a><br /><b>Abstract: </b>Connected components is a fundamental kernel in graph applications due to its
usefulness in measuring how well-connected a graph is, as well as its use as
subroutines in many other graph algorithms. The fastest existing parallel
multicore algorithms for connectivity are based on some form of edge sampling
and/or linking and compressing trees. However, many combinations of these
design choices have been left unexplored. In this paper, we design the
ConnectIt framework, which provides different sampling strategies as well as
various tree linking and compression schemes. ConnectIt enables us to obtain
several hundred new variants of connectivity algorithms, most of which extend
to computing spanning forest. In addition to static graphs, we also extend
ConnectIt to support mixes of insertions and connectivity queries in the
concurrent setting.
</p>
<p>We present an experimental evaluation of ConnectIt on a 72-core machine,
which we believe is the most comprehensive evaluation of parallel connectivity
algorithms to date. Compared to a collection of state-of-the-art static
multicore algorithms, we obtain an average speedup of 37.4x (2.36x average
speedup over the fastest existing implementation for each graph). Using
ConnectIt, we are able to compute connectivity on the largest
publicly-available graph (with over 3.5 billion vertices and 128 billion edges)
in under 10 seconds using a 72-core machine, providing a 3.1x speedup over the
fastest existing connectivity result for this graph, in any computational
setting. For our incremental algorithms, we show that our algorithms can ingest
graph updates at up to several billion edges per second. Finally, to guide the
user in selecting the best variants in ConnectIt for different situations, we
provide a detailed analysis of the different strategies in terms of their work
and locality.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03909"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03855">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03855">An Improved Exact Sampling Algorithm for the Standard Normal Distribution</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Du:Yusong.html">Yusong Du</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fan:Baoying.html">Baoying Fan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wei:Baodian.html">Baodian Wei</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03855">PDF</a><br /><b>Abstract: </b>In 2016, Karney proposed an exact sampling algorithm for the standard normal
distribution. In this paper, we study the computational complexity of this
algorithm under the random deviate model. Specifically, Karney's algorithm
requires the access to an infinite sequence of independently and uniformly
random deviates over the range (0,1). We give an estimate of the expected
number of uniform deviates used by this algorithm until outputting a sample
value, and present an improved algorithm with lower uniform deviate
consumption. The experimental results also shows that our improved algorithm
has better performance than Karney's algorithm.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03855"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03784">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03784">Rectilinear Planarity Testing of Plane Series-Parallel Graphs in Linear Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Didimo:Walter.html">Walter Didimo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaufmann:Michael.html">Michael Kaufmann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liotta:Giuseppe.html">Giuseppe Liotta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ortali:Giacomo.html">Giacomo Ortali</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03784">PDF</a><br /><b>Abstract: </b>A plane graph is rectilinear planar if it admits an embedding-preserving
straight-line drawing where each edge is either horizontal or vertical. We
prove that rectilinear planarity testing can be solved in optimal $O(n)$ time
for any plane series-parallel graph $G$ with $n$ vertices. If $G$ is
rectilinear planar, an embedding-preserving rectilinear planar drawing of $G$
can be constructed in $O(n)$ time. Our result is based on a characterization of
rectilinear planar series-parallel graphs in terms of intervals of orthogonal
spirality that their components can have, and it leads to an algorithm that can
be easily implemented.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03784"><span class="datestr">at August 11, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03759">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03759">Sparsifying the Operators of Fast Matrix Multiplication Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Beniamini:Gal.html">Gal Beniamini</a>, Nathan Cheng, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Holtz:Olga.html">Olga Holtz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karstadt:Elaye.html">Elaye Karstadt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schwartz:Oded.html">Oded Schwartz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03759">PDF</a><br /><b>Abstract: </b>Fast matrix multiplication algorithms may be useful, provided that their
running time is good in practice. Particularly, the leading coefficient of
their arithmetic complexity needs to be small. Many sub-cubic algorithms have
large leading coefficients, rendering them impractical. Karstadt and Schwartz
(SPAA'17, JACM'20) demonstrated how to reduce these coefficients by sparsifying
an algorithm's bilinear operator. Unfortunately, the problem of finding optimal
sparsifications is NP-Hard.
</p>
<p>We obtain three new methods to this end, and apply them to existing fast
matrix multiplication algorithms, thus improving their leading coefficients.
These methods have an exponential worst case running time, but run fast in
practice and improve the performance of many fast matrix multiplication
algorithms. Two of the methods are guaranteed to produce leading coefficients
that, under some assumptions, are optimal.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03759"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03676">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03676">Adjustable Coins</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moran:Shlomo.html">Shlomo Moran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yavneh:Irad.html">Irad Yavneh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03676">PDF</a><br /><b>Abstract: </b>In this paper we consider a scenario where there are several algorithms for
solving a given problem. Each algorithm is associated with a probability of
success and a cost, and there is also a penalty for failing to solve the
problem. The user may run one algorithm at a time for the specified cost, or
give up and pay the penalty. The probability of success may be implied by
randomization in the algorithm, or by assuming a probability distribution on
the input space, which lead to different variants of the problem. The goal is
to minimize the expected cost of the process under the assumption that the
algorithms are independent. We study several variants of this problem, and
present possible solution strategies and a hardness result.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03676"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03675">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03675">Consistent High Dimensional Rounding with Side Information</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dunkelman:Orr.html">Orr Dunkelman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Geyzel:Zeev.html">Zeev Geyzel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keller:Chaya.html">Chaya Keller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Keller:Nathan.html">Nathan Keller</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ronen:Eyal.html">Eyal Ronen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shamir:Adi.html">Adi Shamir</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tessler:Ran_J=.html">Ran J. Tessler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03675">PDF</a><br /><b>Abstract: </b>In standard rounding, we want to map each value $X$ in a large continuous
space (e.g., $R$) to a nearby point $P$ from a discrete subset (e.g., $Z$).
This process seems to be inherently discontinuous in the sense that two
consecutive noisy measurements $X_1$ and $X_2$ of the same value may be
extremely close to each other and yet they can be rounded to different points
$P_1\ne P_2$, which is undesirable in many applications. In this paper we show
how to make the rounding process perfectly continuous in the sense that it maps
any pair of sufficiently close measurements to the same point. We call such a
process consistent rounding, and make it possible by allowing a small amount of
information about the first measurement $X_1$ to be unidirectionally
communicated to and used by the rounding process of $X_2$.
</p>
<p>The fault tolerance of a consistent rounding scheme is defined by the maximum
distance between pairs of measurements which guarantees that they are always
rounded to the same point, and our goal is to study the possible tradeoffs
between the amount of information provided and the achievable fault tolerance
for various types of spaces. When the measurements $X_i$ are arbitrary vectors
in $R^d$, we show that communicating $\log_2(d+1)$ bits of information is both
sufficient and necessary (in the worst case) in order to achieve consistent
rounding for some positive fault tolerance, and when d=3 we obtain a tight
upper and lower asymptotic bound of $(0.561+o(1))k^{1/3}$ on the achievable
fault tolerance when we reveal $\log_2(k)$ bits of information about how $X_1$
was rounded. We analyze the problem by considering the possible colored tilings
of the space with $k$ available colors, and obtain our upper and lower bounds
with a variety of mathematical techniques including isoperimetric inequalities,
the Brunn-Minkowski theorem, sphere packing bounds, and \v{C}ech cohomology.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03675"><span class="datestr">at August 11, 2020 01:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03564">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03564">Online Nash Social Welfare via Promised Utilities</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorokh:Artur.html">Artur Gorokh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Siddhartha.html">Siddhartha Banerjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Billy.html">Billy Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gkatzelis:Vasilis.html">Vasilis Gkatzelis</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03564">PDF</a><br /><b>Abstract: </b>We consider the problem of allocating a set of divisible goods to $N$ agents
in an online manner over $T$ periods, with adversarially-chosen normalized
valuations in each period. Our goal is to maximize the Nash social welfare, a
widely studied objective which provides a balance between fairness and
efficiency. On the positive side, we provide an online algorithm that achieves
a competitive ratio of $O(\log N)$ and $O(\log T)$, but also a stronger
competitive ratio of $O(\log k)$ in settings where the value of any agent for
her most preferred item is no more than $k$ times her average value. We
complement this by showing this bound is essentially tight: no online algorithm
can achieve a competitive ratio of $O(\log^{1-\epsilon} N)$ or
$O(\log^{1-\epsilon} T)$ for any constant $\epsilon&gt;0$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03564"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03556">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03556">A simpler strong refutation of random $k$-XOR</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Ahn:Kwangjun.html">Kwangjun Ahn</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03556">PDF</a><br /><b>Abstract: </b>Strong refutation of random CSPs is a fundamental question in theoretical
computer science that has received particular attention due to the
long-standing gap between the information-theoretic limit and the computational
limit. This gap is recently bridged by Raghavendra, Rao and Schramm where they
study sub-exponential algorithms for the regime between the two limits. In this
work, we take a simpler approach to their algorithm and analysis.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03556"><span class="datestr">at August 11, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03448">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03448">Parameterized Complexity of $(A,\ell)$-Path Packing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Belmonte:R=eacute=my.html">Rémy Belmonte</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hanaka:Tesshu.html">Tesshu Hanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kanzaki:Masaaki.html">Masaaki Kanzaki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kiyomi:Masashi.html">Masashi Kiyomi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yasuaki.html">Yasuaki Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lampis:Michael.html">Michael Lampis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ono:Hirotaka.html">Hirotaka Ono</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Otachi:Yota.html">Yota Otachi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03448">PDF</a><br /><b>Abstract: </b>Given a graph $G = (V,E)$, $A \subseteq V$, and integers $k$ and $\ell$, the
\textsc{$(A,\ell)$-Path Packing} problem asks to find $k$ vertex-disjoint paths
of length $\ell$ that have endpoints in $A$ and internal points in $V \setminus
A$. We study the parameterized complexity of this problem with parameters
$|A|$, $\ell$, $k$, treewidth, pathwidth, and their combinations. We present
sharp complexity contrasts with respect to these parameters. Among other
results, we show that the problem is polynomial-time solvable when $\ell \le
3$, while it is NP-complete for constant $\ell \ge 4$. We also show that the
problem is W[1]-hard parameterized by pathwidth${}+|A|$, while it is
fixed-parameter tractable parameterized by treewidth${}+\ell$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03448"><span class="datestr">at August 11, 2020 01:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03327">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03327">A $4/3$-Approximation Algorithm for the Minimum $2$-Edge Connected Multisubgraph Problem in the Half-Integral Case</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Boyd:S=.html">S. Boyd</a>, J. Cheriyan, R. Cummings, L. Grout, S. Ibrahimpur, Z. Szigeti, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:L=.html">L. Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03327">PDF</a><br /><b>Abstract: </b>Given a connected undirected graph $\bar{G}$ on $n$ vertices, and
non-negative edge costs $c$, the 2ECM problem is that of finding a
$2$-edge~connected spanning multisubgraph of $\bar{G}$ of minimum cost. The
natural linear program (LP) for 2ECM, which coincides with the subtour LP for
the Traveling Salesman Problem on the metric closure of $\bar{G}$, gives a
lower bound on the optimal cost. For instances where this LP is optimized by a
half-integral solution $x$, Carr and Ravi (1998) showed that the integrality
gap is at most $\frac43$: they show that the vector $\frac43 x$ dominates a
convex combination of incidence vectors of $2$-edge connected spanning
multisubgraphs of $\bar{G}$.
</p>
<p>We present a simpler proof of the result due to Carr and Ravi by applying an
extension of Lov\'{a}sz's splitting-off theorem. Our proof naturally leads to a
$\frac43$-approximation algorithm for half-integral instances. Given a
half-integral solution $x$ to the LP for 2ECM, we give an $O(n^2)$-time
algorithm to obtain a $2$-edge connected spanning multisubgraph of $\bar{G}$
whose cost is at most $\frac43 c^T x$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03327"><span class="datestr">at August 11, 2020 01:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03325">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03325">Approximation Algorithms for Radius-Based, Two-Stage Stochastic Clustering Problems with Budget Constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brubach:Brian.html">Brian Brubach</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grammel:Nathaniel.html">Nathaniel Grammel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Harris:David_G=.html">David G. Harris</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Srinivasan:Aravind.html">Aravind Srinivasan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tsepenekas:Leonidas.html">Leonidas Tsepenekas</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vullikanti:Anil.html">Anil Vullikanti</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03325">PDF</a><br /><b>Abstract: </b>The main focus of this paper is radius-based clustering problems in the
two-stage stochastic setting with recourse, where the inherent stochasticity of
the model comes in the form of a budget constraint. We also explore a number of
variants where additional constraints are imposed on the first-stage decisions,
specifically matroid and multi-knapsack constraints. Further, we show that our
problems have natural applications to allocating healthcare testing centers.
</p>
<p>The eventual goal is to provide results for supplier-like problems in the
most general distributional setting, where there is only black-box access to
the underlying distribution. Our framework unfolds in two steps. First, we
develop algorithms for a restricted version of each problem, in which all
possible scenarios are explicitly provided; second, we exploit structural
properties of these algorithms and generalize them to the black-box setting.
These key properties are: \textbf{(1)} the algorithms produce ``simple''
exponential families of black-box strategies, and \textbf{(2)} there exist
\emph{efficient} ways to extend their output to the black-box case, which also
preserve the approximation ratio exactly. We note that prior generalization
approaches, i.e., variants of the \emph{Sample Average Approximation} method,
can be used for the problems we consider, however they would yield worse
approximation guarantees.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03325"><span class="datestr">at August 11, 2020 01:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1361848584634042636">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/08/random-thoughts-on-pandemic.html">Random Thoughts on the Pandemic</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> </p><p>1) Contrast the following two points and, if you have an intelligent way to fill-in-the-blank for the second one, please comment.</p><p>a) When Trump says `open the schools or I will cut of funding' I disagree, or at least he should talk more about how to do it carefully BUT there is an underlying important and serious issue: how to balance health and education. Similar for when he talks about opening up business's - how to balance heath and the economy.</p><p>b) When Trump says `hydroxychloroquine is a potential cure for covid' I (and most of the medical community) disagree, BUT FILL IN THE BLANK. Is there SOME serious issue involved here that I am just missing?</p><p>2) I have seen several approaches to large gathering, say Churchs, beach parties, motorcycle meeting etc. </p><p>a) DO IT ONLINE.  UMCP classes will be on-line in the fall. My church has been online since mid March and seems like it will do the same in the fall. (Note- Choir is much worse than normal talking for spreading it, so Choir might not resume for a much longer time than Church).</p><p>b) HAVE THEM but SOCIAL DISTANCE and MASKS and other precautions. And it works. I hope it works.</p><p>c) HAVE THEM, realize that there IS an issue, TRY to do some of the precautions, but fail. This may be what has happened at some high schools, see <a href="https://www.thedailybeast.com/9-people-test-positive-at-georgia-school-with-photo-of-crowded-hallway?ref=home">Here</a>.</p><p>d) HAVE THEM and ignore ALL precautions either because </p><p>i) God will protect you</p><p>ii) The Government is not my boss. Such people are usually pro-business so they should NOT mind if a business on its own requires masks and SHOULD mind if its the government. I have not seen them making that distinction. Such people are usually against Federalism and for localism. So they should be upset when a Prez or a Gov overides a Mayor's Mask Mandate. I have not seen this.</p><p>iii) The whole think is a Hoax. How can people still believe this?</p><p>These three may overlap.</p><p>3) The Sturgis Motorcycle Rally in South Dakota seems to believe ii and iii. Can someone give any rational reason why they want to have this rally and why its allowed to happen. Given how many people come (usually 250,000- less now?) from all across the country, this could make thinks far far worse. But see next point.</p><p>4) Libertarians think that there is too much Government in our lives. This is a fair point of view but it needs to be tested on a case by case basis. There are some things that REQUIRE a more national response. When this happens Libertarians have two choices:</p><p>a) Apply their thinking to figure out how Gov can help with the least damage. For example, Carbon tax for global warning. In the current pandemic they might have LOCAL govs pass mandatory mask laws.. Or they would at least set a good example by wearing masks themselves. Perhaps relax regulations on medical stuff so that companies can work together without worrying about anti-trust, and perhaps look more carefully at regulations that get in the way (might be a good idea anyway).</p><p>b) Deny its a problem. Man made Global Warming is a myth. Covid is a hoax. Hence its okay to have the Motorcycle Rally. But the problem is, this doesn't just harm the people showing up, it harms others as well.</p><p>5) Early on I was puzzled that Trump didn't care more since older people (his base!) are at more risk. Did he think it would only affect democrats (early on NY was hit badly). Why didn't his advisors tell him that it would kill his own base?I ASK NON-RHETORICALLY  Or did they and he didn't list. My point is, for purely selfish reasons Trump should have taken more action earlier, so I am surprised he did not. See next point.</p><p>6) Trump could have even taken action in a Trumpian way:</p><p>The Chinese and the Democrats are waging a bio-war on real Americans (white rural older) !!! We will STOP them in their tracks and show them they can't mess with us!!  I will LOCKDOWN some cities AND provide online stuff to schools, business's (my cronies)  and churchs (SCREW that stupid sep of church and state- that was only one passage in a letter Thomas Jefferson wrote).  </p><p>He might have even got Democrats to complain that it will choke the economy and hurt the poor, and that giving stuff to churchs is against the constitution (it prob is). </p><p>7) If a vax for covid is found, will Trump urge his base (some of whom are anti-vax) to take it? Having said that, if it comes out in October it may be untested so I doubt I will take it. I'll wait until Dr Fauci says its okay to take it. (See <a href="https://www.youtube.com/watch?v=lUiDLcp_hIw">here</a> for a nice song about Dr. Fauci.)</p><p>8) Some people who thought it was a Hoax and then got a bad case of it are saying loudly `I WAS WRONG! Its Real!'  I wonder if Herman Cain realized it was real before he died of it? I wish he had said `I WAS WRONG! ITS REAL! Wear a MASK' (The Whitehouse denies that he got Covid from the Tulsa Rally, here is headline only since something is behind paywalls: <a href="https://tulsaworld.com/news/local/white-house-denies-herman-cain-contracted-covid-19-at-tulsa-trump-rally-prior-to-his/article_b0c83d3c-c3de-547e-9a5f-434b6a82ac61.html">here</a>)</p><p>9) At Tulsa the presidents people took DOWN signs about safe distancing. So again, why does the Prez want to kill his own base? I ask non rhetorically. I am serious- I want someone to defend his actions intelligently both this one and the hydro-whatever in the first point.</p><p>10) Authoritarian governments often claim that they bring order and can act fast to get things done. So they SHOULD have an advantage during the pandemic since they can more easily ORDER a lockdown. Yet they don't seem to be doing better.  </p><p>Russia: <a href="https://www.worldometers.info/coronavirus/country/russia/">See Here</a>, number of cases going up fast.</p><p>Iran: <a href="https://www.worldometers.info/coronavirus/country/iran/">See here</a> and <a href="https://www.bbc.com/news/world-middle-east-53598965">Here</a>, number of cases going up fast.</p><p>These countries and others, and America, had their leaders LIE about the extend of the virus early on. What is the upside of doing this?  I ask non-rhetorically. </p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/08/random-thoughts-on-pandemic.html"><span class="datestr">at August 10, 2020 01:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03131">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03131">A $2^{O(k)}n$ algorithm for $k$-cycle in minor-closed graph families</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuster:Raphael.html">Raphael Yuster</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03131">PDF</a><br /><b>Abstract: </b>Let ${\mathcal C}$ be a proper minor-closed family of graphs. We present a
randomized algorithm that given a graph $G \in {\mathcal C}$ with $n$ vertices,
finds a simple cycle of size $k$ in $G$ (if exists) in $2^{O(k)}n$ time. The
algorithm applies to both directed and undirected graphs. In previous linear
time algorithms for this problem, the runtime dependence on $k$ is
super-exponential. The algorithm can be derandomized yielding a $2^{O(k)}n\log
n$ time algorithm.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03131"><span class="datestr">at August 10, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03115">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03115">Approximating Constraint Satisfaction Problems Symmetrically</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tucker=Foltz:Jamie.html">Jamie Tucker-Foltz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03115">PDF</a><br /><b>Abstract: </b>This thesis investigates the extent to which the optimal value of a
constraint satisfaction problem (CSP) can be approximated by some sentence of
fixed point logic with counting (FPC). It is known that, assuming $\mathsf{P}
\neq \mathsf{NP}$ and the Unique Games Conjecture, the best polynomial time
approximation algorithm for any CSP is given by solving and rounding a specific
semidefinite programming relaxation. We prove an analogue of this result for
algorithms that are definable as FPC-interpretations, which holds without the
assumption that $\mathsf{P} \neq \mathsf{NP}$. While we are not able to drop
(an FPC-version of) the Unique Games Conjecture as an assumption, we do present
some partial results toward proving it. Specifically, we give a novel
construction which shows that, for all $\alpha &gt; 0$, there exists a positive
integer $q = \text{poly}(\frac{1}{\alpha})$ such that no there is no
FPC-interpretation giving an $\alpha$-approximation of Unique Games on a label
set of size $q$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03115"><span class="datestr">at August 10, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03091">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03091">Low-Congestion Shortcuts for Graphs Excluding Dense Minors</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghaffari:Mohsen.html">Mohsen Ghaffari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Haeupler:Bernhard.html">Bernhard Haeupler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03091">PDF</a><br /><b>Abstract: </b>We prove that any $n$-node graph $G$ with diameter $D$ admits shortcuts with
congestion $O(\delta D \log n)$ and dilation $O(\delta D)$, where $\delta$ is
the maximum edge-density of any minor of $G$. Our proof is simple, elementary,
and constructive - featuring a $\tilde{\Theta}(\delta D)$-round distributed
construction algorithm. Our results are tight up to $\tilde{O}(1)$ factors and
generalize, simplify, unify, and strengthen several prior results. For example,
for graphs excluding a fixed minor, i.e., graphs with constant $\delta$, only a
$\tilde{O}(D^2)$ bound was known based on a very technical proof that relies on
the Robertson-Seymour Graph Structure Theorem.
</p>
<p>A direct consequence of our result is that many graph families, including any
minor-excluded ones, have near-optimal $\tilde{\Theta}(D)$-round distributed
algorithms for many fundamental communication primitives and optimization
problems including minimum spanning tree, minimum cut, and shortest-path
approximations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03091"><span class="datestr">at August 10, 2020 11:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03061">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03061">Hierarchical Clusterings of Unweighted Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/H=oslash=gemo:Svein.html">Svein Høgemo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paul:Christophe.html">Christophe Paul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Telle:Jan_Arne.html">Jan Arne Telle</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03061">PDF</a><br /><b>Abstract: </b>We study the complexity of finding an optimal hierarchical clustering of an
unweighted similarity graph under the recently introduced Dasgupta objective
function. We introduce a proof technique, called the normalization procedure,
that takes any such clustering of a graph $G$ and iteratively improves it until
a desired target clustering of G is reached. We use this technique to show both
a negative and a positive complexity result. Firstly, we show that in general
the problem is NP-complete. Secondly, we consider min-well-behaved graphs,
which are graphs $H$ having the property that for any $k$ the graph $H(k)$
being the join of $k$ copies of $H$ has an optimal hierarchical clustering that
splits each copy of $H$ in the same optimal way. To optimally cluster such a
graph $H(k)$ we thus only need to optimally cluster the smaller graph $H$.
Co-bipartite graphs are min-well-behaved, but otherwise they seem to be scarce.
We use the normalization procedure to show that also the cycle on 6 vertices is
min-well-behaved.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03061"><span class="datestr">at August 10, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.03006">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.03006">Polynomial-time algorithms for Multimarginal Optimal Transport problems with structure</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Altschuler:Jason_M=.html">Jason M. Altschuler</a>, Enric Boix-Adsera <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.03006">PDF</a><br /><b>Abstract: </b>Multimarginal Optimal Transport (MOT) has recently attracted significant
interest due to its many applications. However, in most applications, the
success of MOT is severely hindered by a lack of sub-exponential time
algorithms. This paper develops a general theory about "structural properties"
that make MOT tractable. We identify two such properties: decomposability of
the cost into either (i) local interactions and simple global interactions; or
(ii) low-rank interactions and sparse interactions. We also provide strong
evidence that (iii) repulsive costs make MOT intractable by showing that
several such problems of interest are NP-hard to solve--even approximately.
These three structures are quite general, and collectively they encompass many
(if not most) current MOT applications. We demonstrate our results on a variety
of applications in machine learning, statistics, physics, and computational
geometry.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.03006"><span class="datestr">at August 10, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.02941">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.02941">Exploring entanglement and optimization within the Hamiltonian Variational Ansatz</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Roeland Wiersema, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhou:Cunlu.html">Cunlu Zhou</a>, Yvette de Sereville, Juan Felipe Carrasquilla, Yong Baek Kim, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yuen:Henry.html">Henry Yuen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02941">PDF</a><br /><b>Abstract: </b>Quantum variational algorithms are one of the most promising applications of
near-term quantum computers; however, recent studies have demonstrated that
unless the variational quantum circuits are configured in a problem-specific
manner, optimization of such circuits will most likely fail. In this paper, we
focus on a special family of quantum circuits called the Hamiltonian
Variational Ansatz (HVA), which takes inspiration from the quantum
approximation optimization algorithm and adiabatic quantum computation. Through
the study of its entanglement spectrum and energy gradient statistics, we find
that HVA exhibits favorable structural properties such as mild or entirely
absent barren plateaus and a restricted state space that eases their
optimization in comparison to the well-studied "hardware-efficient ansatz." We
also numerically observe that the optimization landscape of HVA becomes almost
trap free when the ansatz is over-parameterized. We observe a size-dependent
"computational phase transition" as the number of layers in the HVA circuit is
increased where the optimization crosses over from a hard to an easy region in
terms of the quality of the approximations and speed of convergence to a good
solution. In contrast with the analogous transitions observed in the learning
of random unitaries which occur at a number of layers that grows exponentially
with the number of qubits, our Variational Quantum Eigensolver experiments
suggest that the threshold to achieve the over-parameterization phenomenon
scales at most polynomially in the number of qubits for the transverse field
Ising and XXZ models. Lastly, as a demonstration of its entangling power and
effectiveness, we show that HVA can find accurate approximations to the ground
states of a modified Haldane-Shastry Hamiltonian on a ring, which has
long-range interactions and has a power-law entanglement scaling.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.02941"><span class="datestr">at August 10, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.02932">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.02932">Cons-free Programs and Complexity Classes between LOGSPACE and PTIME</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jones:Neil_D=.html">Neil D. Jones</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bhaskar:Siddharth.html">Siddharth Bhaskar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kop:Cynthia.html">Cynthia Kop</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simonsen:Jakob_Grue.html">Jakob Grue Simonsen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02932">PDF</a><br /><b>Abstract: </b>Programming language concepts are used to give some new perspectives on a
long-standing open problem: is logspace = ptime ?
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.02932"><span class="datestr">at August 10, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.02924">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.02924">A Sub-linear Time Algorithm for Approximating k-Nearest-Neighbor with Full Quality Guarantee</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Hengzhao Ma, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jianzhong.html">Jianzhong Li</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.02924">PDF</a><br /><b>Abstract: </b>In this paper we propose an algorithm for the approximate k-Nearest-Neighbors
problem. According to the existing researches, there are two kinds of
approximation criterion. One is the distance criteria, and the other is the
recall criteria. All former algorithms suffer the problem that there are no
theoretical guarantees for the two approximation criterion. The algorithm
proposed in this paper unifies the two kinds of approximation criterion, and
has full theoretical guarantees. Furthermore, the query time of the algorithm
is sub-linear. As far as we know, it is the first algorithm that achieves both
sub-linear query time and full theoretical approximation guarantee.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.02924"><span class="datestr">at August 10, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/119">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/119">TR20-119 |  On parity decision trees for Fourier-sparse Boolean functions | 

	Nikhil Mande, 

	Swagato Sanyal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study parity decision trees for Boolean functions. The motivation of our study is the log-rank conjecture for XOR functions and its connection to Fourier analysis and parity decision tree complexity. Our contributions are as follows. Let $f : \mathbb{F}_2^n \to \{-1, 1\}$ be a Boolean function with Fourier support $\mathcal{S}$ and Fourier sparsity $k$.

1) We prove via the probabilistic method that there exists a parity decision tree of depth $O(\sqrt{k})$ that computes $f$. This matches the best known upper bound on the parity decision tree complexity of Boolean functions (Tsang, Wong, Xie, and Zhang, FOCS 2013). Moreover, while previous constructions (Tsang et al., FOCS 2013, Shpilka, Tal, and Volk, Comput. Complex. 2017) build the trees by carefully choosing the parities to be queried in each step, our proof shows that a naive sampling of the parities suffices.

2) We generalize the above result by showing that if the Fourier spectra of Boolean functions satisfy a natural "folding property", then the above proof can be adapted to establish existence of a tree of complexity polynomially smaller than $O(\sqrt k)$. More concretely, the folding property we consider is that for most distinct $\gamma, \delta$ in $\mathcal{S}$, there are at least a polynomial (in $k$) number of pairs $(\alpha, \beta)$ of parities in $\mathcal{S}$ such that $\alpha+\beta=\gamma+\delta$. We make a conjecture in this regard which, if true, implies that the communication complexity of an XOR function is bounded above by the fourth root of the rank of its communication matrix, improving upon the previously known upper bound of square root of rank (Tsang et al., FOCS 2013, Lovett, J. ACM. 2016).

3) Motivated by the above, we present some structural results about the Fourier spectra of Boolean functions. It can be shown by elementary techniques that for any Boolean function $f$ and all $(\alpha, \beta)$ in ${\mathcal{S} \choose 2}$, there exists another pair $(\gamma, \delta)$ in ${\mathcal{S} \choose 2}$ such that $\alpha + \beta = \gamma + \delta$. One can view this as a "trivial" folding property that all Boolean functions satisfy. Prior to our work, it was conceivable that for all $(\alpha, \beta) \in {\mathcal{S} \choose 2}$, there exists exactly one other pair $(\gamma, \delta) \in {\mathcal{S} \choose 2}$ with $\alpha + \beta = \gamma + \delta$. We show, among other results, that there must exist several $\gamma \in \mathbb{F}_2^n$ such that there are at least three pairs of parities $(\alpha_1, \alpha_2) \in {\mathcal{S} \choose 2}$ with $\alpha_1+\alpha_2=\gamma$. This, in particular, rules out the possibility stated earlier.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/119"><span class="datestr">at August 09, 2020 04:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4933">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4933">Seven announcements</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<ol><li>Good news, everyone!  Following years of requests, this blog finally supports rich HTML and basic TeX in comments.  Also, the German spam that used to plague the blog (when JavaScript was disabled) is gone.  For all this, I owe deep gratitude to a reader and volunteer named <a href="https://filiparena.github.io/">Filip Dimitrovski</a>.<br /></li><li>Filip refused to accept any payment for fixing this blog.  Instead, he asked only one favor: namely, that I use my platform to raise public awareness about the plight of the MAOI antidepressant <a href="https://en.wikipedia.org/wiki/Phenelzine">Nardil</a>.  Filip tells me that, while tens of thousands of people desperately need Nardil—no other antidepressant ever worked for them—it’s become increasingly unavailable because the pharma companies can no longer make money on it.  He points me to a <a href="https://slatestarcodex.com/2015/04/30/prescriptions-paradoxes-and-perversities/">SlateStarCodex post from 2015</a> that explains the problem in more detail (anyone else miss SlateStarCodex?).  More recent links about the worsening crisis <a href="https://www.sps.nhs.uk/articles/shortage-of-phenelzine-15mg-tablets-nardil/">here</a>, <a href="https://healthycanadians.gc.ca/recall-alert-rappel-avis/hc-sc/2020/73411a-eng.php">here</a>, and <a href="https://www.tga.gov.au/sites/default/files/phenelzine-nardil-discontinuation.pdf">here</a>.<br /></li><li>Here’s a <a href="https://www.wired.com/story/bill-gates-on-covid-most-us-tests-are-completely-garbage/">fantastic interview of Bill Gates by Steven Levy</a>, about the coronavirus debacle in the US.  Gates, who’s always been notoriously and strategically nonpartisan, is more explicit than I’ve ever seen him before in explaining how the Trump administration’s world-historic incompetence led to where we are.<br /></li><li>Speaking of which, here’s <a href="https://www.the-american-interest.com/2020/08/06/getting-from-november-to-january/">another excellent article</a>, this one in <em>The American Interest</em>, about the results of “wargames” trying to simulate what happens in the extremely likely event that Trump contests a loss of the November election.  Notably, the article sets out six steps that could be taken over the next few months to decrease the chance of a crisis next to which <em>all the previous crises of 2020 will pale</em>.<br /></li><li>A reader asked me to share a link to an <a href="https://algorithmcompetition.github.io/doc/contest/overview.html">algorithm competition</a>, related to cryptographic “proofs of time,” that ends on August 31.  Apparently, my having shared a link to a predecessor of this competition—at the request of friend-of-the-blog Bram Cohen—played a big role in attracting good entries.<br /></li><li>Huge congratulations to my former PhD student Shalev Ben-David, as well as Eric Blais, for <a href="https://focs2020.cs.duke.edu/index.php/awards/">co-winning the FOCS’2020 Best Paper Award</a>—along with two other papers—for <a href="https://arxiv.org/abs/2002.10802">highly unconventional work</a> about a new minimax theorem for randomized algorithms.  (Ben-David and Blais also have a <a href="https://arxiv.org/abs/2002.10809">second FOCS paper</a>, which applies their award paper to get the first tight composition theorem for randomized query complexity.  Here’s the <a href="https://focs2020.cs.duke.edu/index.php/accepted-papers/">full list</a> of FOCS papers—lots of great stuff, for a conference that of course won’t physically convene!)  Anyway, a central idea in Ben-David and Blais’s new work is to use <a href="https://en.wikipedia.org/wiki/Scoring_rule">proper scoring rules</a> to measure the performance of randomized algorithms—algorithms that now make statements like “I’m 90% sure that this is a yes-input,” rather than just outputting a 1-bit guess.  Notably, Shalev tells me that he learned about proper scoring rules by <em>reading rationalist blogs</em>.  So next time you lament your untold hours sacrificed to that pastime, remind yourself of where it once led!<br /></li><li>What have I been up to lately?  Besides Busy Beaver, hanging out with my kids, and just trying to survive?  Mostly giving a lot of Zoom lectures!  For those interested, <a href="https://m.youtube.com/watch?v=n2nnY_xLCN4">here’s a Q&amp;A that I recently did</a> on the past and present of quantum computing, hosted by Andris Ambainis in Latvia.  It did feel a bit surreal when my “interviewer” asked me to explain how I got into quantum computing research, and my answer was basically: “well, <em>as you know</em>, Andris, a lot of it started when I got hold of <a href="https://arxiv.org/abs/quant-ph/0002066">your seminal paper</a> back in 1999…”</li></ol>



<p></p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4933"><span class="datestr">at August 09, 2020 08:36 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17394">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/">Fran Allen: 1932-2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>We lost a great computer scientist.</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p>
Frances Allen was one of the leaders who helped create the field of <a href="https://en.wikipedia.org/wiki/Compiler">compilers</a> research. Fran was an elite researcher at IBM, and won a Turing Award for this pioneering work. Allen also collected other awards. </p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/fran/" rel="attachment wp-att-17396"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/fran.png?w=300&amp;h=180" class="alignright size-medium wp-image-17396" height="180" /></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>Perhaps the coolest award is one that Fran could never win: The <a href="https://www.ieee.org/about/awards/medals/frances-e-allen-medal.html">Frances E. Allen</a> award created this year by the IEEE: </p>
<blockquote><p><b> </b> <em> <i>For innovative work in computing leading to lasting impact on other fields of engineering, technology, or science.</i> </em>
</p></blockquote>
<p></p><p>
Today we will talk about Fran, who sadly just passed away.</p>
<p>
I consider Fran a friend, although we never worked together—our areas of interest were different. One fond memory of mine is being on panel a while ago with Fran. What a delightful presence.</p>
<p>
Fran always seemed to be smiling, always with that smile. The following images come in large part from interviews and lectures and award events-the fact that it is so easy to find them is a testament to her public engagement as well as scientific contributions.</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/collage/" rel="attachment wp-att-17398"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/collage.png?w=300&amp;h=290" class="aligncenter size-medium wp-image-17398" height="290" /></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p></p><h2> Compliers were Key </h2><p></p>
<p></p><p>
There was a time when compliers were the most important program available on any new computer. Perhaps on any computer. Here is proof: </p>
<ol>
<li>
Computers are there to solve problems. <p></p>
</li><li>
We must write programs to solve problems. <p></p>
</li><li>
Details of the computer and instructions, are complicated, which make writing programs hard. <p></p>
</li><li>
Thus, automating the writing of programs is important. <p></p>
</li><li>
QED: we must have compliers.
</li></ol>
<p>
Okay this is not really a “proof”, but there is some truth to the argument. Fran was at IBM and worked on some of the early compliers, including FORTRAN and related languages. IBM wanted to sell computers, well actually in the early days rent them. One potential roadblock, IBM realized, was that new computers could be hard to program. Thus to ensure that companies rented new machines as fast as IBM could manufacture them was important. This created the need for compliers and even more for <i>optimizing compilers</i>.</p>
<p>
In order to ship more machines, the code that a complier created had to be efficient. Hence, a stress on Allen was to figure out how compliers could generate high quality code. This led Fran and others like John Cocke to discover many complier techniques that are still used today. A short list of the ideas is: </p>
<ul>
<li>
Branch prediction <p></p>
</li><li>
Register allocation <p></p>
</li><li>
Control flow graphs <p></p>
</li><li>
Program dependence graphs <p></p>
</li><li>
And many more.
</li></ul>
<p>
What is so important is that Allen’s work was not just applicable to this machine or that language. Rather the work was able to be used for almost any machine and for almost any language. This universal nature of the work on compliers reminds me of what we try to do in theory. Allen’s research was so important because it could be used for future hardware as well as future languages. </p>
<p>
</p><p></p><h2> Register Allocation </h2><p></p>
<p></p><p>
Guy Steele interviewed Allen for the ACM <a href="https://cacm.acm.org/magazines/2011/1/103191-an-interview-with-frances-e-allen/fulltext">here</a>. During the interview Fran talked about register allocation:</p>
<blockquote><p><b> </b> <em> I have a story about register allocation. FORTRAN back in the 1950’s had the beginnings of a theory of register allocation, even though there were only three registers on the target machine. Quite a bit later, John Backus became interested in applying graph coloring to allocating registers; he worked for about 10 years on that problem and just couldn’t solve it. I considered it the biggest outstanding problem in optimizing compilers for a long time. Optimizing transformations would produce code with symbolic registers; the issue was then to map symbolic registers to real machine registers, of which there was a limited set. For high-performance computing, register allocation often conflicts with instruction scheduling. There wasn’t a good algorithm until the Chaitin algorithm. Chaitin was working on the PL compiler for the 801 system. Ashok Chandra, another student of Knuth’s, joined the department and told about how he had worked on the graph coloring problem, which Knuth had given out in class, and had solved it not by solving the coloring problem directly, but in terms of what is the minimal number of colors needed to color the graph. Greg immediately recognized that he could apply this solution to the register allocator issue. It was a wonderful kind of serendipity. </em>
</p></blockquote>
<p>
</p><p></p><h2> Compliers Create Theory </h2><p></p>
<p></p><p>
The early goal of creating compliers lead directly to some wonderful theory problems. One whole area that dominated early theory research was language theory. In particular understanding questions that arise in defining programming languages. Syntax came first—later semantics was formalized.</p>
<p>
Noam Chomsky created context-free grammars to help understand natural languages in the 1950s. His ideas were used by John Backus, also a Turing award winner from IBM, to describe the then new programming language IAL. This is known today as ALGOL 58, which became ALGOL 60. Peter Naur on the ALGOL 60 committee called Backus’s notation for ALGOL’s syntax: Backus normal form, but is now called BNF-Backus-Naur form. </p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/bnf-2/" rel="attachment wp-att-17399"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/bnf.png?w=300&amp;h=39" class="aligncenter size-medium wp-image-17399" height="39" /></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
Theorists worked on, I confess I did, many questions about such languages. Existence problems, decidability problems, efficient algorithms, and closure properties were just some of the examples. Not clear how much of this theory effected compiler design, but I would like to think that some was useful. Theorist should thank the complier researchers. I do. </p>
<p>
For instance the 1970 STOC <a href="https://dblp.org/db/conf/stoc/stoc70">program</a> had many papers on language related topics—here are some:</p>
<ul>
<li>
A Result on the Relationship between Simple Precedence Languages and Reducing Transition Languages. 		Gary Lindstrom <p></p>
</li><li>
The Design of Parsers for Incremental Language Processors: 		Ronald Book, Sheila Greibach, Ben Wegbreit <p></p>
</li><li>
Tape- and Time-Bounded Turing Acceptors and AFLs. 		David Lewis <p></p>
</li><li>
Closure of Families of Languages under Substitution Operators. 		William Rounds <p></p>
</li><li>
Tree-Oriented Proofs of Some Theorems on Context-Free and Indexed Languages. 		Barry Rosen <p></p>
</li><li>
On Syntax-Directed Transduction and Tree Transducers. 		Alfred Aho, Jeffrey Ullman <p></p>
</li><li>
The Analysis of Two-Dimensional Patterns using Picture Processing Grammars. 		Jean-Francois Perrot <p></p>
</li><li>
On Some Families of Languages Related to the Dyck Language. 		Joseph Ullian <p></p>
</li><li>
Three Theorems on Abstract Families of Languages. 	Joseph Ullian
</li></ul>
<p>
By the way Abstract Families of Languages or <a href="https://en.wikipedia.org/wiki/Abstract_family_of_languages">AFL</a>s was created by Seymour Ginsburg and Sheila Greibach in 1967 as a way to generalize context free languages. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Fran was asked by Steele in that <a href="https://cacm.acm.org/magazines/2011/1/103191-an-interview-with-frances-e-allen/fulltext">interview</a>: <i>Any advice for the future?</i></p>
<blockquote><p><b> </b> <em> Yes, I do have one thing. Students aren’t joining our field, computer science, and I don’t know why. It’s just such an amazing field, and it’s changed the world, and we’re just at the beginning of the change. We have to find a way to get our excitement out to be more publicly visible. It is exciting, in the 50 years that I’ve been involved, the change has been astounding. </em>
</p></blockquote>
<p></p><p>
Thanks Fran. Much of that change is due to pioneers like you. Thanks for everything.</p>
<p></p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/08/08/fran-allen-1932-2020/"><span class="datestr">at August 08, 2020 02:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/08/07/report-from-cccg">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/08/07/report-from-cccg.html">Report from CCCG</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I spent the last few days participating in the <a href="http://vga.usask.ca/cccg2020/">Canadian Conference in Computational Geometry</a>, originally planned for Saskatoon but organized virtually instead.</p>

<p>The way the conference was organized was that (after the usual submission reviewing process) the accepted authors provided both a proceedings paper and a 10-15 minute talk video to the conference organizers. Participants were required to register, but with no registration fee, and were provided with links to the papers and talks (which are all still live on the conference program). Then, during the conference itself, live online Zoom sessions ran for only 2-3 hours daily, scheduled for 10AM-1PM Saskatoon time: very convenient for anywhere in North America or Europe, not so much for the participants in Iran, India, China, Japan, and Korea (all of which did have participants). The sessions included a daily 1-hour live invited talk, and question-and-answer sessions for the contributed works, in which we were shown a one-minute teaser for each video and then invited to ask questions of authors, at least one of whom was required to be present.</p>

<p>I think it all worked very well; so well, in fact, that during the business meeting there were calls for having at least some of the content similarly online so that people could participate remotely again. The ability to ask and answer questions either by live video on Zoom or through Zoom chat was useful, and used. Attendance was far above previous levels: 162 registrants, and over 120 unique participants at the most heavily attended of the two daily parallel sessions, compared to roughly 60 attendees each at the last two physical conferences. Despite the free registration, the conference organization was not without cost: they spent roughly $1500 (Canadian) in video production costs and video conferencing fees, but this was more than made up for by institutional support for the conference, so they ended up running a surplus which may (if it can be kept) end up providing some float for future conference organizers.</p>

<p>There are two changes I would suggest for future events of this type:</p>

<ul>
  <li>
    <p>The contributed sessions were for a short enough time that holding them in parallel seemed unnecessary, and made it impossible to participate in all discussions. So this format may work better with less parallelism.</p>
  </li>
  <li>
    <p>The one-minute teaser videos were cut together by the conference organizers from the longer videos provided by the authors, but in some cases the pacing of the longer videos from which they were cut meant that these teaser videos could not clearly state the results of their papers. I think it would have been better to ask authors to provide these alongside the longer talk videos.</p>
  </li>
</ul>

<p>Some of the highlights of the event:</p>

<ul>
  <li>
    <p>Wednesday’s invited talk by Erik Demaine was a moving tribute to Godfried Toussaint and a survey of some of both Toussaint’s research, and Erik’s research on problems started by Toussaint, including <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Nagy_theorem">convexifying polygons by flips</a>, sona curves (<a href="https://arxiv.org/abs/2007.15784">the subject of one of my own contributions</a>), the <a href="https://en.wikipedia.org/wiki/The_Geometry_of_Musical_Rhythm">geometry of musical rhythms</a>, and perhaps most importantly “supercollaboration”, the model of shared research and shared authorship developed by Toussaint at the Barbados research workshops and also used by Erik within many of his MIT classes. <a href="https://www.youtube.com/watch?v=exzxGODi2YU">Erik’s talk was recorded and is now on YouTube</a>; I hope the same will be true of the other two invited talks.</p>
  </li>
  <li>
    <p>In Wednesday’s contributed session on unfolding (in which I had two papers) I particularly liked Satyan Devadoss’s talk, “Nets of higher-dimensional cubes”. The main result is that if you unfold a hypercube, then no path of facets of the unfolded shape can contain a u-turn: if the path takes a step in one any coordinate direction, it cannot step in the opposite direction. This implies that all dual spanning trees unfold flat without self-intersection. The same property was known for all the Platonic solids, and Satyan can prove it for regular simplices in any dimension, but that still leaves several regular polytopes for which it is still open whether all unfoldings work: the cross-polytopes in all dimensions, and the three exceptional regular polytopes in four dimensions.</p>
  </li>
  <li>
    <p>Thursday’s invited talk was by Jeff Erickson, “Chasing puppies”. It was an entertaining presentation of an elegant topological proof of the following result: if you and a puppy can both move around a simple closed curve in the plane, with the puppy always moving along the curve to a local minimum of distance to you, then you can always find a path to follow that will bring you and the puppy to the same point.</p>
  </li>
  <li>
    <p>There wasn’t an official prize for best contributed presentation, but in the data structures session on Thursday, several comments nominated <a href="https://medium.com/photos-we-love/the-trinity-of-incongruity-or-why-i-still-love-this-tuxedo-sewing-machine-ups-truck-photograph-39712dd32fcb">Don Sheehy</a> as the unofficial winner, for a video artfully mixing live action with computer animations. His paper, “One-hop greedy permutations” concerned heuristics for improving the <a href="https://en.wikipedia.org/wiki/Farthest-first_traversal">farthest-first traversal</a> of a set of points by looking near each point as the sequence is constructed for a better point to use instead.</p>
  </li>
  <li>
    <p>There was an official best student paper award, and it went to <a href="https://www.cs.umd.edu/people/afloresv">Alejandro Flores Velazco</a> for his paper “Social distancing is good for points too!” It concerns the problem of reducing the size of a data set while preserving the quality of nearest-neighbor classification using the reduced set. It proves that FCNN, which it calls the most popular heuristic for this problem, can produce significantly less-reduced outputs than some other proven heuristics, and shows how to modify FCNN to get a heuristic with guaranteed output quality.</p>
  </li>
  <li>
    <p>The third of the invited sessions was by Yusu Wang, newly moved from Ohio State to UC San Diego. She gave a nice introduction to combinatorial methods for reconstructing road networks (or other networks embedded into higher-dimensional geometry) from noisy samples of points on the network by combining discrete Morse theory to find the ridge lines of sample density with persistent homology to clean some of the noise from the data.</p>
  </li>
  <li>
    <p>The final technical component of the conference was an open problem session, also recorded and presumably to be uploaded at some point. Satyan posed his question on regular polytope unfolding there. Mike Paterson asked whether one can construct “Plato’s torus”, an embedded torus with six equilateral-triangle faces meeting at each vertex; <a href="https://11011110.github.io/blog/2009/02/03/flat-equilateral-tori.html">in a blog post I made on this problem in 2009 I traced its history to Nick Halloway in 1997</a> but Mike says he discussed it already with Christopher Zeeman in the 1970s. Another problem that caught my attention asked for an algorithmic version of the polyhedral <a href="https://en.wikipedia.org/wiki/Theorem_of_the_three_geodesics">theorem of the three geodesics</a>, the existence of a path across the surface of a convex polyhedron that stays straight across each edge or face of the polyhedron, and has at most \(\pi\) surface angle on each side of it when it passes through a vertex. Again there’s some history here: Joe O’Rourke says he once mentioned the problem to Gromov, who said it was easy but unfortunately didn’t elaborate.</p>
  </li>
</ul>

<p>CCCG 2021 is planned for Halifax, colocated with WADS. One somewhat controversial issue is that the current plan is to have both conferences overlap for two days, with one overlap-free day for each conference at each end of the overlap period. But if both conferences are double-session, this means that participants can only choose one of four overlapping talks. At this point everyone is still hoping that events allow for a physical conference by then but that remains to be seen.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104651090140382005">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/08/07/report-from-cccg.html"><span class="datestr">at August 07, 2020 05:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4290135672537490640">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/08/do-senators-have-advantage-for-being.html">Do Senators have an Advantage for being Dem VP Nominee?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
This is a non-partisan post. Even so:  I plan to vote for Joe Biden.<div><br /></div><div>(Lance says that whenever I write `this is a non-partisan post'  its partisan anyway.)</div><div><br /></div><div>I've had posts on predicting VPs before:</div><div><br /></div><div>In <a href="https://blog.computationalcomplexity.org/2019/02/using-who-will-be-dem-vp-choice-article.html">this post</a> I looked at a Nate Silver column a few months ago where they were trying to predict the democratic VP nomination <i>before the Prez nominee was know</i>n. Some of what they said seems relevant.</div><div><br /></div><div>In <a href="https://blog.computationalcomplexity.org/2008/09/i-would-be-on-intrade-that-intrade-will.html">this post</a> I PREDICTED that bets on INTRADE would not do well on picking VPs since VP picks are hard to predict and often are not from anyone's short list. I DID NOT PREDICT that INTRADE would go out of business.</div><div><br /></div><div>I came across a statistic recently that seems relevant and inspired this post. Actually this post asks IS this statistic relevant?</div><div><br /></div><div>From Prez candidate  Harry Truman to Prez candidate Hillary Clinton there have been 15 Dem VP nominees (not  counting incumbents) of which 13 have been Senators:</div><div><br /></div><div>Harry Truman(Prez)-Alben Barkely. Sen from Kentucky</div><div>Adelaide Stevenson(Gov-Illinois) -John Sparkman. Sen from Alabama</div><div>Adelaide Stevenson(Gov-Illinois)-Estes Kefauver, Sen from Tennessee </div><div>John F Kennedy(Sen-Mass)-Lyndon B Johnson, Sen from Texas</div><div>Lyndon B Johnson(Prez)-Hubert Humphrey,Sen from Minnesoda</div><div>Hubert Humphrey(VP)-Ed Muskie, Sen from Maine</div><div>George McGovern Sen-South Dakota)-Sgt Shriver Amb to France, Office of Econ Activity</div><div>Jimmy Carter(Gov Georgia)-Walter Mondale- Senator from Minnesota</div><div>Walter Mondale(Senator Minnesota)-Geraldine Ferraro Congressperson- NY</div><div>Mike Dukakis (Gov Mass), Lloyd Benson-Sen Texas</div><div>Bill Clinton(Gov Arkansas), Al Gore Sen from Tennesee</div><div>Al Gore (VP), Joe Lieberman Senator from Conn</div><div>John Kerry (Sen-Mass), John Edwards Sen from NC</div><div>Barack Obama (Sen-Illinois), Joe Biden Sen from Del</div><div>Hillary Clinton (Sen-NY), Tom Kaine- Sen Virginia</div><div><br /></div><div>Of the 15 Dem VP nominees, 13 are Senators</div><div><br /></div><div>Of the 13 Rep VP nominees, 4 are Senators  <a href="http://www.cs.umd.edu/~gasarch/BLOGPAPERS/rebvp.txt">see here</a></div><div><br /></div><div>My Speculations: </div><div><br /></div><div>1)  When a gov runs he wants someone with fed experience. That explains 5 of the cases above.</div><div><br /></div><div>2) Senators tend to be better known than other politicians, so perhaps being well known is what you need. Note on the Republican Side Paul Ryan was a House member but was well known.</div><div><br /></div><div>3) Why do the Reps and Dems differ on this? Is the sample size too small to make this question interesting? </div><div><br /></div><div>So here is the question: When trying to predict who the Dem VP will be (this year or any year) should being a Senator give someone a plus? A higher weight in a Neural Net? </div><div><br /></div><div>Kamela Harris is the favorite on the betting markets.  Is this because she is a Senator?</div><div><br /></div><div>She has a national profile and has already been vetted since she rana serious campaign  for Prez in the primaries. So I would say that THATS the reason (and other reasons), not that she is a Senator. But would she have been able to run a serious campaign  in the primaries if she wasn't already a Senator? I ask non rhetorically.</div><div><br /></div><div><br /></div><div><br /></div><div><br /></div><div><br /></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/08/do-senators-have-advantage-for-being.html"><span class="datestr">at August 06, 2020 06:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1380">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1380">Videos from the WoLA 2020 workshop</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>The 4th <a href="https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html">Workshop on Local Algorithms (WoLA 2020)</a> recently concluded: aimed at <em>“fostering dialogue and cross-pollination of ideas between the various communities</em>” related to local algorithms, broadly construed, it featured invited and contributed talks on a variety of topics, many (if not most) very relevant to the sublinear algorithms and property testing community.</p>



<p>Because of the online format of the workshop (imposed by the current circumstances), all talks were recorded and posted online. As such, all videos all available on the workshop’s <a href="https://www.mit.edu/~mahabadi/workshops/WOLA-2020.html">website</a> and <a href="https://www.youtube.com/channel/UCMBSZ3q2FKJntpcK72h9eeA/videos">YouTube channel</a>: a good list of resources to peruse!</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1380"><span class="datestr">at August 06, 2020 12:33 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5510">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2020/08/05/mind-benders-for-the-quarantined/">Mind-Benders for the Quarantined</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Peter Winkler is a world expert on mathematical puzzles (he is also an excellent researcher and this year’s resident mathematician of the MoMath). I just learned about two things that he is currently up to. Winkler is running Mind-Benders for the Quarantined. After signing up to this free service, you receive a mathematical puzzle every […]</div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2020/08/05/mind-benders-for-the-quarantined/"><span class="datestr">at August 05, 2020 10:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://corner.mimuw.edu.pl/?p=1091">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/banach.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://corner.mimuw.edu.pl/?p=1091">Faster PageRank on MPC</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Years ago when I learned about Google PageRank algorithm, my first reaction was this is not the way it should be done! There should be some proof. This probably just shows that my CS education was too theoretical ;). Years later I have learned that indeed there are some nice tools to argue about the running time of PageRank algorithm. And very recently we were able to give some new parallel (in MPC model) algorithms for computing vanilla PageRank. We improved the number of rounds needed from O(log n) to O(log^2 log n) time. You can hear Solbodan talking out it here:  <a href="https://www.youtube.com/watch?v=xoodhmjJ9Xs">https://www.youtube.com/watch?v=xoodhmjJ9Xs</a> .<br /> </p></div>







<p class="date">
by sank <a href="http://corner.mimuw.edu.pl/?p=1091"><span class="datestr">at August 05, 2020 06:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/open-problem-all-pairs/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/open-problem-all-pairs/">Open Problem: Private All-Pairs Distances</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><strong>Background:</strong> Suppose we are interested in computing the distance between two vertices in a graph. Under edge or node differential privacy, this problem is not promising because the removal of a single edge can make distances change from 1 to \(n − 1\) or can even disconnect the graph. However, a different setting that makes sense to consider is that of a weighted graph \((G, w)\) whose topology \(G = (V, E)\) is publicly known but edge weight function \(w : E \to \mathbb{R}^+\) must be kept private. (For instance, consider transit times on a road network. The topology of the road network may be publicly available as a map, but the edge weights corresponding to transit times may be based on private GPS locations of individual cars.)</p>

<p>Suppose that two weight functions \(w\) and \(w’\) of the same graph \(G\) are considered to be neighbors if they differ by at most 1 in \(\ell^1\) norm. Then the length of any fixed path is sensitivity-one, so the distance between any pair of vertices is also sensitivity-one and can be released privately via the Laplace mechanism. But what if we want to release all \(\Theta(n^2)\) distances between all pairs of vertices in \(G\)? We can do this with accuracy roughly \(O(n \log n )/\varepsilon\) by adding noise to each edge, or roughly \(O(n \sqrt{\log(1/\delta)}/\varepsilon)\) using composition theorems. Both of these are roughly \(n/\varepsilon\). But is this linear dependence on \(n\) inherent, or is it possible to release all-pairs distances with error sublinear in \(n\)?</p>

<p>This setting and question were considered in [<a href="https://arxiv.org/abs/1511.04631">S16</a>].</p>

<p><strong>Problem 1:</strong> Let \(G\) be an arbitrary public graph, and \(w : E \to \mathbb{R}^+\) be an edge weight function. Can we release approximate all-pairs distances in \((G, w)\) with accuracy sublinear in \(n\) while preserving the privacy of the edge weight function, where two weight functions \(w, w’\) are neighbors if \(\|w − w’\|_1 \le 1\)? Or can we show that any private algorithm must have error \(\Omega(n)\)? A weaker (but nontrivial) lower bound would also be nice.</p>

<p><strong>Reward:</strong> A bar of chocolate.</p>

<p><strong>Other related work:</strong> [<a href="https://arxiv.org/abs/1511.04631">S16</a>] provided algorithms with better error for two special cases, trees and graphs of a priori bounded weight. For trees, it is possible to release all-pairs distances with error roughly \(O(\log^{1.5} n)/\varepsilon\), while for arbitrary graphs with edge weights restricted to the interval \([0,M]\), it is possible to release all-pairs distances with error roughly \(O( \sqrt{nM\varepsilon^{-1}\log(1/\delta)})\)</p>

<p><em>Submitted by <a href="http://www.mit.edu/~asealfon/">Adam Sealfon</a> on April 9, 2019.</em></p></div>







<p class="date">
by Audra McMillan <a href="https://differentialprivacy.org/open-problem-all-pairs/"><span class="datestr">at August 05, 2020 06:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=755">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2020/08/05/previous-vs-concurrent-independent-work/">Previous vs. concurrent/independent work</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Should Paper X cite Paper Y as previous or concurrent/independent work?  This is sometimes tricky: maybe Paper Y circulated privately before Paper X, maybe the authors of Paper X knew about Paper Y maybe not — nobody can know for sure.  One can say that the authors of Paper Y should have posted Paper Y online earlier to prevent this issue, but <a href="https://emanueleviola.wordpress.com/2014/07/02/only-papers-on-the-arxiv-can-be-submitted-for-publication/">that is not standard practice </a>and might lead to other problems, <a href="https://emanueleviola.wordpress.com/2016/08/10/paper-x-on-the-arxiv-keeps-getting-rejected/">including Paper Y never getting published!</a></p>



<p>I propose the following guiding principle:</p>



<p>“If a different accept/reject outcome would have forced paper X to cite paper Y as previous work, then paper X should cite paper Y as previous work.”<br /></p>



<p>The reasons behind my principle seem to me especially valid in the fast-moving theoretical computer science community, where papers are typically sent to conferences and thus seen by the entire program committee plus around 3 external referees, who are typically experts — only to be rejected.  Moreover, the progress is extremely fast, with the next conference cycle making obsolete a number of papers in just the previous cycle.</p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2020/08/05/previous-vs-concurrent-independent-work/"><span class="datestr">at August 05, 2020 02:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/118">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/118">TR20-118 |  On Testing Asymmetry in the Bounded Degree Graph Model | 

	Oded Goldreich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We consider the problem of testing asymmetry in the bounded-degree graph model, where a graph is called asymmetric if the identity permutation is its only automorphism. Seeking to determine the query complexity of this testing problem, we provide partial results. Considering the special case of $n$-vertex graphs with connected components of size at most $s(n)=\Omega(\log n)$, we show that the query complexity of $\epsilon$-testing asymmetry (in this case) is at most $O({\sqrt n}\cdot s(n)/\epsilon)$, whereas the query complexity of $o(1/s(n))$-testing asymmetry (in this case) is at least $\Omega({\sqrt{n/s(n)}})$.

In addition, we show that testing asymmetry in the dense graph model is almost trivial.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/118"><span class="datestr">at August 04, 2020 09:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=2561">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/integration-by-parts-abel-transformation/">The many faces of integration by parts – I : Abel transformation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">Integration by parts is a highlight of any calculus class. It leads to multiple classical applications for integration of logarithms, exponentials, etc., and it is the source of an infinite number of exercises and applications to <a href="https://en.wikipedia.org/wiki/Special_functions">special functions</a>. In this post, I will look at a classical discrete extension that is useful in machine learning and optimization, namely <a href="https://en.wikipedia.org/wiki/Summation_by_parts">Abel transformation</a>, with applications to convergence proofs for the (stochastic) <a href="https://en.wikipedia.org/wiki/Subgradient_method">subgradient method</a>. Next month, extensions to higher dimensions will be considered, with applications to score functions [<a href="http://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf">2</a>, <a href="https://www.jstor.org/stable/1914309">3</a>] and randomized smoothing [4, <a href="https://arxiv.org/pdf/2002.08676">5</a>].</p>



<h2>Abel transformation: from continuous to discrete</h2>



<p class="justify-text">The most classical version of integration by parts goes as follows. Given two continuously differentiable functions from \(\mathbb{R}\) to \(\mathbb{R}\), we have: $$ \int_a^b \!\!\!\!f(x)g'(x) dx = \Big[ f(x) g(x) \Big]_a^b \!-\! \int_a^b\!\!\! \!f'(x) g(x) dx =  f(b) g(b)\, – f(a)g(a)-\! \int_a^b\! \!\!\! f'(x) g(x) dx.$$ This is valid for less regular functions, but this is not the main concern here. The proof follows naturally from the derivative of a product, but there is a nice “proof without words” (see, e.g., [1, p. 42] or <a href="https://en.wikipedia.org/wiki/Integration_by_parts#Visualization">here</a>).</p>



<p class="justify-text">There is a discrete analogue referred to as <a href="https://en.wikipedia.org/wiki/Summation_by_parts">Abel transformation</a> or summation by parts, where derivatives are replaced by increments: given two real-valued sequences \((a_n)_{n \geq 0}\) and \((b_n)_{n \geq 0}\) (the second sequence could also be taken vector-valued), we can expand $$ \sum_{k=1}^n a_k ( b_k\, – b_{k-1}) =\sum_{k=1}^n a_k  b_k \ – \sum_{k=1}^n a_k  b_{k-1} = \sum_{k=1}^n a_k b_k \ – \sum_{k=0}^{n-1} a_{k+1} b_{k},$$ using a simple index increment in the second sum.  Rearranging terms, this leads to $$ \sum_{k=1}^n a_k ( b_k\, – b_{k-1}) = a_n b_n \ – a_0 b_0\  – \sum_{k=0}^{n-1} ( a_{k+1} – a_{k } ) b_k.$$ In other words, we can transfer the first-order difference from the sequence \((b_k)_{k \geq 0}\) to the sequence \((a_k)_{k \geq 0}\).  A few remarks:</p>



<ul class="justify-text"><li><strong>Warning</strong>! It is very easy/common to make mistakes with indices and signs.</li><li>I gave the direct proof but a proof through explicit integration by part is also possible, by introducing the piecewise-constant function \(f\) equal to \(a_k\) on \([k,k+1)\), and \(g\) continuous  piecewise affine equal to \(b_{k} + (t-k) ( b_{k+1}-b_{k})\) for \(t \in [k,k+1]\), and integrating between \(0+\) and \(n+\). </li></ul>



<p class="justify-text">There are classical applications for the convergence of series (see <a href="https://en.wikipedia.org/wiki/Summation_by_parts">here</a>), but in this post, I will show how it can lead to an elegant result for stochastic gradient descent for non-smooth functions and <em>decaying</em> step-sizes.</p>



<h2>Decaying step-sizes in stochastic gradient descent</h2>



<p class="justify-text">The Abel summation formula is quite useful when analyzing optimization algorithms, and we give a simple example below. We consider a sequence of random potentially <em>non-smooth</em> convex functions \((f_k)_{k \geq 0}\) which are independent and identically distributed functions from \(\mathbb{R}^d \) to \(\mathbb{R}\), with expectation \(F\). The goal is to find a minimizer \(x_\ast\) of \(F\) over a some convex bounded set \(\mathcal{C}\), only being given access to some stochastic gradients of \(f_k\) at well-chosen points. The most classical example is supervised machine learning, where \(f_k(\theta)\) is the loss of a random observation for the predictor parameterized by \(\theta\).  The difficulty here is the potential non-smoothness of the function \(f_k\) (e.g., for the <a href="https://en.wikipedia.org/wiki/Hinge_loss">hinge loss</a> and the <a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machine</a>).</p>



<p class="justify-text">We consider the projected stochastic subgradient descent method. The deterministic version of this method dates back to Naum Shor [6] in 1962 (see nice history <a href="https://www.math.uni-bielefeld.de/documenta/vol-ismp/43_goffin-jean-louis.pdf">here</a>). The method goes as follows: starting from some \(\theta_0 \in \mathbb{R}^d\), we perform the iteration $$ \theta_{k} = \Pi_{ \mathcal{C} } \big( \theta_{k-1} – \gamma_k  \nabla f_k(\theta_{k-1}) \big),$$ where \(\Pi_{ \mathcal{C}}: \mathbb{R}^d \to \mathbb{R}^d\) is the orthogonal projection onto the set \(\mathcal{C}\), and \(\nabla f_k(\theta_{k-1})\) is any subgradient of \(f_k\) at \(\theta_{k-1}\). </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="528" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/gradient_contours_projection-1024x410.png" class="wp-image-4324" height="211" />One step of projected (sub)gradient descent: from a vector \(\theta\), we go down the direction of a negative subgradient \(\nabla f(\theta)\) of the function \(f\) (here typically a random function) and an orthogonal projection is performed to obtain the new vector \(\theta_+\).</figure></div>



<p class="justify-text">We make the following standard assumptions: (a) the set \(\mathcal{C}\) is convex and compact with diameter \(\Delta\) (with respect to the \(\ell_2\)-norm), (b) the functions \(f_k\) are almost surely convex and \(B\)-Lipschitz-continuous (or equivalently with gradients bounded in \(\ell_2\)-norm by \(B\)). We denote by \(\theta_\ast\) a minimizer of \(f\) on \(\mathcal{C}\) (there can be multiple ones). </p>



<p class="justify-text">For non-smooth problems, choosing a constant step-size does not lead to an algorithm converging to a global minimizer: decaying step-sizes are then needed.</p>



<h2>Convergence proof through Lyapunov functions</h2>



<p class="justify-text">Since the functions \(f_k\) are non-smooth, we cannot use Taylor expansions, and we rely on a now classical proof technique dating back from the 1960’s (see, e.g., a <a href="http://www.mathnet.ru/links/5d71a255cae8f1a313ac599b8f20a123/dan33049.pdf">paper</a> by Boris Polyak [7] in Russian), that has led to several extensions in particular for online learning [<a href="http://www.cs.cmu.edu/~maz/publications/techconvex.pdf">8</a>]. The proof relies on the concept of “<a href="https://en.wikipedia.org/wiki/Lyapunov_function">Lyapunov functions</a>“, often also referred to as “potential functions”. This is a non-negative function \(V(\theta_k)\) of the iterates \(\theta_k\), that is supposed to go down along iterations (at least in expectation). In optimization, standard Lyapunov functions are \(V(\theta)  = F(\theta)\, – F(\theta_\ast)\) or \(V(\theta) = \| \theta \ – \theta_\ast\|_2^2\). </p>



<p class="justify-text">For the subgradient method, we will not be able to show that the Lyapunov function is decreasing, but this will lead through a manipulation which is standard in linear dynamical system analysis to a convergence proof for the averaged iterate: that is, if \(V(\theta_k) \leqslant V(\theta_{k-1})\ – W(\theta_{k-1}) + \varepsilon_k\),  for a certain function \(W\) and extra positive terms \(\varepsilon_k\), then, using telescoping sums, $$ \frac{1}{n} \sum_{k=1}^n W(\theta_{k-1}) \leqslant \frac{1}{n} \big( V(\theta_0)\ – V(\theta_n) \big) + \frac{1}{n} \sum_{k=1}^n \varepsilon_k.$$ We can then either use <a href="https://en.wikipedia.org/wiki/Jensen%27s_inequality">Jensen’s inequality</a> to get a bound on \(W \big( \frac{1}{n} \sum_{k=1}^n \theta_{k-1} \big)\), or directly get a bound on \(\min_{k \in \{1,\dots,n\}} W(\theta_{k-1})\). The first solution gives a performance guarantee for a well-defined iterate, while the second solution only shows that among the first \(n-1\) iterates, one of them has a performance guarantee; in the stochastic set-up where latex \(W\) is an expectation, it is not easily possible to know which one, so we will consider only averaging below.</p>



<p class="justify-text"><strong>Standard inequality. </strong>We have, by contractivity of orthogonal projections: $$ \|\theta_k \ – \theta_\ast\|_2^2 =  \big\|  \Pi_{ \mathcal{C} } \big( \theta_{k-1} – \gamma_k   \nabla f_k(\theta_{k-1}) \big) – \Pi_{ \mathcal{C} } (\theta_\ast)  \big\|_2^2 \leqslant  \big\|   \theta_{k-1} – \gamma_k  \nabla f_k(\theta_{k-1}) -\   \theta_\ast  \big\|_2^2.$$ We can then expand the squared Euclidean norm to get: $$ \|\theta_k – \theta_\ast\|_2^2 \leqslant  \|\theta_{k-1} – \theta_\ast\|_2^2 \ – 2\gamma_k (\theta_{k-1} – \theta_\ast)^\top \nabla f_k (\theta_{k-1}) + \gamma_k^2 \|  \nabla f_k(\theta_{k-1})\|_2^2.$$ The last term is upper-bounded by \(\gamma_k^2 B^2\) because of the regularity assumption on \(f_k\). For the middle term, we use the convexity of \(f_k\), that is,  the function \(f_k\) is greater than its tangent at \(\theta_{k-1}\). See figure below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="513" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/tangent_convex-1-1024x440.png" class="wp-image-4331" height="220" />Convex function above its tangent at \(\theta_{k-1}\), leading to the desired inequality.</figure></div>



<p class="justify-text">We then obtain $$ f_k(\theta_\ast) \geqslant f_k(\theta_{k-1}) + \nabla f_k(\theta_{k-1})^\top ( \theta_{\ast} – \theta_{k-1}).$$</p>



<p class="justify-text">Putting everything together, this leads to $$ \|\theta_k \ – \theta_\ast\|_2^2 \leqslant  \|\theta_{k-1}\  – \theta_\ast\|_2^2 \ – 2\gamma_k  \big[ f_k(\theta_{k-1}) \ – f_k(\theta_\ast) \big] + \gamma_k^2 B^2.$$ At this point, except the last term, all terms are random. We can now take expectations, with a particular focus on the term \(\mathbb{E} \big[ f_k(\theta_{k-1}) \big]\), for which we can use the fact that the random function \(f_k\) is independent from the past, so that $$ \mathbb{E} \big[ f_k(\theta_{k-1}) \big] =  \mathbb{E} \Big[  \mathbb{E} \big[ f_k(\theta_{k-1}) \big| f_{1},\dots,f_{k-1}  \big] \Big] =\mathbb{E} \big[   F(\theta_{k-1})   \big] . $$ We thus get $$ \mathbb{E} \big[ \|\theta_k – \theta_\ast\|_2^2\big] \leqslant  \mathbb{E} \big[ \|\theta_{k-1} – \theta_\ast\|_2^2\big]  – 2\gamma_k \big( \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \big) + \gamma_k^2 B^2.$$ As above, we can now isolate the excess in function values as: $$ \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast)  \leqslant \frac{1}{2 \gamma_k} \Big( \mathbb{E} \big[ \|\theta_{k-1} – \theta_\ast\|_2^2\big] – \mathbb{E} \big[ \|\theta_{k} – \theta_\ast\|_2^2\big] \Big) + \frac{\gamma_k}{2} B^2.$$ At this point, the “optimization part” of the proof is done. Only algebraic manipulations are needed to obtain a convergence rate. This is where Abel transformation will come in.</p>



<h2>From fixed horizon to anytime algorithms</h2>



<p class="justify-text"><strong>The lazy way.</strong> At this point, many authors (including me sometimes) will take a constant step-size \(\gamma_k = \gamma\) so as to obtain a telescopic sum, leading to $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{2n\gamma}     \Big( \mathbb{E} \big[ \|\theta_{0} \ – \theta_\ast\|_2^2\big] – \mathbb{E} \big[ \|\theta_{n}\  – \theta_\ast\|_2^2\big] \Big) + \frac{\gamma}{2} B^2,$$ which is less than \(\displaystyle \frac{\Delta^2}{2n \gamma} + \frac{\gamma}{2} B^2\), and minimized for \(\displaystyle \gamma = \frac{ \Delta}{B \sqrt{n}}\), leading to a convergence rate less than \(\displaystyle \frac{ B \Delta}{\sqrt{n}}\). Using Jensen’s inequality, we then get for \(\bar{\theta}_n = \frac{1}{n} \sum_{k=1}^n \theta_{k-1}\): $$\mathbb{E} \big[ F(\bar{\theta}_{n}) \big] – F(\theta_\ast) \leqslant \frac{ B \Delta}{\sqrt{n}} .$$ This result leads to the desired rate but can be improved in at least one way: the step-size currently has to depend on the “horizon” \(n\) (which has to be known in advance), and the algorithm is not “anytime”, which is not desirable in practice (where one often launches an algorithm and stops it when it the performance gains have plateaued or when the user gets bored waiting).</p>



<p class="justify-text"><strong>Non-uniform averaging.</strong> Another way [<a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">9</a>] is to consider the non-uniform average $$ \eta_{k} =   \frac{\sum_{k=1}^n \gamma_{k} \theta_{k-1}}{\sum_{k=1}^n \gamma_{k}}, $$ for which telescoping sums apply as before, to get $$ \mathbb{E} \big[ F(\eta_k) \big] – F(\theta_\ast) \leqslant \frac{1}{2} \frac{\Delta^2 + B^2 \sum_{k=1}^n \gamma_k^2}{\sum_{k=1}^n \gamma_{k}}.$$  Then, by selecting a decaying step-size \(\displaystyle \gamma_k = \frac{ \Delta}{B \sqrt{k}}\), that depends on the iteration number, we get a rate proportional to \(\displaystyle \frac{ B \Delta}{\sqrt{n}} ( 1 + \log n)\). We now have an anytime algorithm, but we have lost a logarithmic term, which is not the end of the world, but still disappointing. In [<a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">9</a>], “tail-averaging” (only averaging iterates between a constant times \(n\) and \(n\)) is proposed, that removes the logarithmic term but requires to store iterates (moreover, the non-uniform averaging puts too much weight on the first iterates, slowing down convergence).</p>



<p class="justify-text"><strong>Using Abel transformation.</strong> If we start to sum inequalities from \(k=1\) to \(k=n\), we get, with \(\delta_k = \mathbb{E} \big[ \|\theta_{k} – \theta_\ast\|_2^2\big]\) (which is always between \(0\) and \(\Delta^2\)): $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast)  \leqslant  \frac{1}{n} \sum_{k=1}^n \bigg( \frac{1}{2 \gamma_k} \Big( \delta_{k-1} –  \delta_k \Big)\bigg) +  \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2,$$ which can be transformed through Abel transformation into $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{n} \sum_{k=1}^{n-1}  {\delta_k} \bigg(\frac{1}{ 2\gamma_{k+1}}- \frac{1}{ 2\gamma_{k}} \bigg) + \frac{\delta_0}{2 \gamma_1}- \frac{\delta_t}{2 \gamma_t}+ \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2.$$ For decreasing step-size sequences, this leads to $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{1}{n} \sum_{k=1}^{n-1} {\Delta^2} \bigg(\frac{1}{ 2\gamma_{k+1}}- \frac{1}{ 2\gamma_{k}} \bigg) + \frac{\Delta^2}{2 \gamma_1}+ \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2,$$ and thus $$ \frac{1}{n} \sum_{k=1}^n \mathbb{E} \big[ F(\theta_{k-1}) \big] – F(\theta_\ast) \leqslant \frac{\Delta^2 }{2 n \gamma_n} + \frac{1}{n} \sum_{k=1}^n \frac{\gamma_k}{2} B^2.$$ For \(\gamma_k = \frac{  \Delta}{B \sqrt{k}}\), this leads to an upper bound $$\frac{\Delta B }{2 \sqrt{n}} \big( 1+ \frac{1}{\sqrt{n}} \sum_{k=1}^n \frac{1}{\sqrt{k}}\big) \leqslant \frac{3 \Delta B }{2 \sqrt{n}},$$ which is up to a factor \(\frac{3}{2}\) exactly the same bound as with a constant step-size, but now with an anytime algorithm.</p>



<h2>Experiments</h2>



<p class="justify-text">To illustrate the behaviors above, let’s consider minimizing \(\mathbb{E}_x \| x – \theta \|_1\), with respect to \(\theta\), with \(f_k(\theta) = \| x_k- \theta\|_1\), where \(x_k\) is sampled independently from a given distribution (here independent log-normal distributions for each coordinate). The global optimum \(\theta_\ast\) is the per-coordinate median of the distribution of \(x\)’s.</p>



<p class="justify-text">When applying SGD, the chosen subgradient of \(f_k\) has components in \(\{-1,1\}\). Hence in the plots below in two dimensions, the iterates are always on a grid. With a constant step-size: if the \(\gamma\) is too large (right), there are large oscillations, while if \(\gamma\) is too small (left), optimization is too slow. Note that while the SGD iterate with a constant step-size is always oscillating, the averaged iterate converges to some point (which is not the global optimum, and is typically at distance \(O(\gamma)\) away from it [<a href="https://arxiv.org/pdf/1707.06386">11</a>]).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="545" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/sgd-1.gif" class="wp-image-4339" height="230" />Stochastic gradient descent (averaged or not), with constant step-size. Left: small step-size. Right: large step-size (8 times larger).</figure></div>



<p class="justify-text">With a decaying step-size (figure below), the initial conditions are forgotten reasonably fast and the iterates converge to the global optimum (and of course, we get an anytime algorithm!).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="310" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/sgd_decaying.gif" class="wp-image-4340" height="295" />Stochastic gradient descent (averaged or not), with decreasing step-size.</figure></div>



<p>We can now compare in terms of function values, showing that a constant step-size only works well for a specific range of iteration numbers.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img width="371" alt="" src="https://francisbach.com/wp-content/uploads/2020/07/convergence_proofs.png" class="wp-image-4335" height="276" />Comparison of expected performance for decaying and constant-step sizes. Several constant step-sizes are tested, with uniform spacings in log-scale (hence the the uniform spacings in performance for large \(n\)).</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">Being able to deal with decaying step-sizes and anytime algorithms is arguably not a major improvement, but quite a satisfactory one, at least to me! Discrete integration by parts is the key enabler here.</p>



<p class="justify-text">There is another rewarding aspect which is totally unrelated to integration by parts: when applied to supervised machine learning, we just obtained from elementary principles (convexity) and few calculations a generalization bound <em>on unseen data</em>, which is as good as regular bounds from statistics [<a href="https://www.esaim-ps.org/articles/ps/pdf/2005/01/ps0420.pdf">10</a>] that use much more complex tools such as <a href="https://en.wikipedia.org/wiki/Rademacher_complexity">Rademacher complexities</a> (but typically no convexity assumptions): here, statistics considered independently from optimization is not only slower (considering the empirical risk and minimizing it using the plain non-stochastic subgradient method would lead to an \(n\) times slower algorithm) but also more difficult to analyze! </p>



<h2>References</h2>



<p class="justify-text">[1] Roger B. Nelsen, <em>Proofs without Words: Exercises in Visual Thinking</em>, Mathematical Association of America, 1997.<br />[2] Aapo Hyvärinen, <a href="http://www.jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf">Estimation of non-normalized statistical models by score matching</a>. <em>Journal of Machine Learning Research</em>, <em>6</em>(Apr), 695-709, 2005.<br />[3] Thomas M. Stoker, <a href="https://www.jstor.org/stable/1914309">Consistent estimation of scaled coefficients</a>.  <em>Econometrica: Journal of the Econometric Society</em>, 54(6):1461-1481, 1986.<br />[4] Tamir Hazan, George Papandreou, and Daniel Tarlow. <a href="https://mitpress.mit.edu/books/perturbations-optimization-and-statistics">Perturbation, Optimization, and Statistics</a>. MIT Press, 2016.<br />[5] Quentin Berthet, Matthieu Blondel, Olivier Teboul, Marco Cuturi, Jean-Philippe Vert, Francis Bach, <a href="https://arxiv.org/pdf/2002.08676">Learning with differentiable perturbed optimizers</a>. Technical report arXiv 2002.08676, 2020.<br />[6] Naum Z. Shor. An application of the method of gradient descent to the solution of the network transportation problem. <em>Notes of Scientific Seminar on Theory and Applications of Cybernetics and Operations Research</em>, <em>Ukrainian Academy of Sciences</em>, Kiev, 9–17, 1962.<br />[7] Boris T. Polyak, <a href="http://www.mathnet.ru/links/5d71a255cae8f1a313ac599b8f20a123/dan33049.pdf">A general method for solving extremal problems</a>. <em>Doklady Akademii Nauk SSSR</em>, 174(1):33–36, 1967.<br />[8] Martin Zinkevich. <a href="http://www.cs.cmu.edu/~maz/publications/techconvex.pdf">Online convex programming and generalized infinitesimal gradient ascent</a>. <em>Proceedings of the international conference on machine learning )(ICML)</em>, 2003.<br />[9] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, Alexander Shapiro<em>.</em> <a href="https://www2.isye.gatech.edu/~nemirovs/SIOPT_RSA_2009.pdf">Robust stochastic approximation approach to stochastic programming</a>. <em>SIAM Journal on optimization</em>, 19(4):1574-1609, 2009.<br />[10] Stéphane Boucheron, Olivier Bousquet, Gabor Lugosi. <a href="https://www.esaim-ps.org/articles/ps/pdf/2005/01/ps0420.pdf">Theory of classification: A survey of some recent advances</a>. <em>ESAIM: probability and statistics</em>, <em>9</em>, 323-375, 2005.<br />[11] Aymeric Dieuleveut, Alain Durmus, and Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the gap between constant step size stochastic gradient descent and Markov chains</a>. Annals of Statistics, 48(3):1348-1382, 2020.</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/integration-by-parts-abel-transformation/"><span class="datestr">at August 04, 2020 03:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/117">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/117">TR20-117 |  New bounds on the half-duplex communication complexity | 

	Alexander Smal, 

	Yuriy Dementiev, 

	Artur Ignatiev, 

	Vyacheslav Sidelnik, 

	Mikhail Ushakov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work, we continue the research started in [HIMS18], where the authors suggested to study the half-duplex communication complexity. Unlike the classical model of communication complexity introduced by Yao, in the half-duplex model, Alice and Bob can speak or listen simultaneously, as if they were talking using a walkie-talkie. The motivation for such a communication model comes from the study of the KRW conjecture. Following the open questions formulated in [HIMS18], we prove lower bounds for the disjointness function in all variants of half-duplex models and an upper bound in the half-duplex model with zero, that separates disjointness from the inner product function in this setting. Next, we prove lower and upper bounds on the half-duplex complexity of the Karchmer-Wigderson games for the counting functions and for the recursive majority function, adapting the ideas used in the classical communication complexity. Finally, we define the non-deterministic half-duplex complexity and establish bounds connecting it with non-deterministic complexity in the classical model.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/117"><span class="datestr">at August 04, 2020 03:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1371">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1371">News for July 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>We hope you’re all staying safe and healthy! To bring you some news (and distraction?) during this… atypical summer,here are the recent papers on property testing and sublinear algorithms we saw appear this month. Graphs, probability distributions, functions… there is a something for everyone.</p>



<p><strong>On Testing Hamiltonicity in the Bounded Degree Graph Model,</strong> by Oded Goldreich (<a href="https://eccc.weizmann.ac.il/report/2020/109/">ECCC</a>). The title sort of gives it away: this relatively short paper shows that testing whether an unknown bounded-degree graph has a Hamiltonian path (or Hamiltonian cycle) in the bounded-degree model requires a number of queries linear in \(n\), the number of nodes. The results also hold for directed graphs (with respect to directed Hamiltonian path or cycle), and are shown via a local reduction to a promise problem of satisfiability of 3CNF formulae. Also included: a complete proof of the linear lower bound for another problem, Independent Set Size; and an open problem: <em>what is the query complexity of testing graph isomorphism in the bounded-degree model?</em></p>



<p><strong>Local Access to Sparse Connected Subgraphs Via Edge Sampling</strong>, by Rogers Epstein (<a href="https://arxiv.org/abs/2007.05523">arXiv</a>). Given access to a connected graph \(G=(V,E)\), can we efficiently provide access to some <em>sparse</em> connected subgraph \(G’=(V,E’)\subseteq G\) with \(|E’|\ll |E|\)? This question, well-studied in particular for the case where \(G\) had bounded degree and the goal is to achieve \(|E’|\leq (1-\varepsilon)|V|\), is the focus of this paper which provides a trade-off between the query complexity of the oracle and \(|E’|\). Specifically, for every parameter \(T\), one can give oracle access to \(G’\) with \(|E’|=O(|V|T)\), with a query complexity \(=\tilde{O}(|E|/T)\). </p>



<p>Switching gears, we move from graphs to probability distributions:</p>



<p><strong>Tolerant Distribution Testing in the Conditional Sampling Model</strong>, by Shyam Narayanan (<a href="https://arxiv.org/abs/2007.09895">arXiv</a>). In the conditional sampling model for distribution testing, which we have covered a few times on this blog, the algorithm at each step gets to specify a subset \(S\) of the domain, and observe a sample from the distribution <em>conditioned on \(S\).</em> As it turns out, this can speed things up a <strong>lot</strong>: as Canonne, Ron, and Servedio (2015) showed, even tolerant uniformity testing, which with i.i.d. samples requires a near-linear (in the domain size \(n\)) number of samples, can be done in a <em>constant</em> number of conditional queries. Well, sort of constant: no dependence on \(n\), but the dependence on the distance parameter \(\varepsilon\) was, in CRS15, quite bad: \(\tilde{O}(1/\varepsilon^{20})\).  This work gets rid of this badness, and shows the (nearly) optimal \(\tilde{O}(1/\varepsilon^{2})\) query complexity! Among other results, it also generalizes it to tolerant identity testing  (\(\tilde{O}(1/\varepsilon^{4})\)), for which previously no constant-query upper bound was known. Things have become <em>truly</em> sublinear.</p>



<p>I<strong>nteractive Inference under Information Constraints</strong>, by Jayadev Acharya, Clément Canonne, Yuhan Liu, Ziteng Sun, and Himanshu Tyagi (<a href="https://arxiv.org/abs/2007.10976">arXiv</a>). Say you want to do uniformity/identity testing (or learn, but let’s focus on testing) on a discrete distribution, but you can’t actually observe the i.i.d. samples: instead, you can only do some sort of limited, “local” measurement on each sample. How hard is the task, compared to what you’d do if you fully had the samples? This setting, which captures things like distributed testing with communication or local privacy constraints, erasure channels, etc., was well-understood from previous recent work in the <em>non-adaptive</em> setting. But what if the “measurements” could be made <em>adaptively</em>? This paper shows general lower bounds for identity testing and learning, as a function of the type of local measurement allowed: as a corollary, this gives tight bounds for communication constraints and local privacy, and shows the first separation between adaptive and non-adaptive uniformity testing, for a type of “leaky” membership query measurement.</p>



<p><strong>Efficient Parameter Estimation of</strong> <strong>Truncated Boolean Product Distributions</strong>, by Dimitris Fotakis, Alkis Kalavasis, and Christos Tzamos (<a href="https://arxiv.org/abs/2007.02392">arXiv</a>). Suppose there is a fixed and unknown subset \(S\) of the hypercube, a “truncation” set, which you can only accessible via membership query; and you receive i.i.d. samples from an unknown product distribution on the hypercube, <em>truncated</em> on that set \(S\) (for instance, because your polling strategy or experimental measurements have limitations). Can you still learn that distribution efficiently? Can you test it for various properties, as you typically really would like to? (or is it just me?) This paper identifies some natural sufficient condition on \(S\), which they call <em>fatness</em>, under which the answer is a resounding <em>yes</em>. Specifically, if \(S\) satisfies this condition, one can actually generate honest-to-goodness i.i.d. samples (non-truncated) from the true distribution, given truncated samples! </p>



<p>Leaving distribution testing, our last paper is on testing functions in the <em>distribution-free</em> model:</p>



<p><strong>Downsampling for Testing and Learning in Product Distributions,</strong> by Nathaniel Harms and Yuichi Yoshida (<a href="https://arxiv.org/abs/2007.07449">arXiv</a>). Suppose you want to test (or learn) a class of Boolean functions \(\mathcal{C}\) over some domain \(\Omega^n\), with respect to some (unknown) product distribution (i.e., in the distribution-free testing model, or PAC-learning model). This paper develops a general technique, downsampling, which allows one to reduce such distribution-free testing of \(\mathcal{C}\) under a product distribution to testing \(\mathcal{C}\) over \([r]^d\) under the <em>uniform</em> distribution, for a suitable parameter \(r=r(d,\varepsilon,\mathcal{C})\). This allows the authors, among many other things and learning results, to easily re-establish (and, in the second case, improve upon) recent results on testing of monotonicity over \([n]^d\) (uniform distribution) and over \(\mathbb{R}^d\) (distribution-free). </p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1371"><span class="datestr">at August 04, 2020 02:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17379">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/08/03/cleverer-automata-exist/">Cleverer Automata Exist</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>A breakthrough on the separating words problem</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/?attachment_id=17371" rel="attachment wp-att-17371"><img width="125" alt="" class="alignright wp-image-17371" src="https://rjlipton.files.wordpress.com/2020/08/chase.png?w=125" /></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p></p><p>
Zachary Chase is a graduate student of Ben Green at Oxford. Chase has already solved a number of interesting problems–check his <a href="http://people.maths.ox.ac.uk/~chase/">site</a> for more details. His advisor is famous for his brilliant work—especially in additive combinatorics. One example is his joint work with Terence Tao <a href="https://en.wikipedia.org/wiki/Green-Tao_theorem">proving</a> this amazing statement:</p>
<blockquote><p><b>Theorem 1</b> <em> The prime numbers contain arbitrarily long arithmetic progressions. </em>
</p></blockquote>
<p>
</p><p>
Today we wish to report Chase’s new <a href="https://arxiv.org/pdf/2007.12097.pdf">paper</a> on a problem we have twice discussed before. </p>
<p>
But first Ken wants to say something about Oxford where he got his degree long before Green arrived. </p>
<p>
</p><p></p><h2> Oxford Making Waves </h2><p></p>
<p></p><p>
Green moved to Oxford in 2013. He holds a professorship associated to Magdalen College. I (Ken) did not know him when I started at Oxford in 1981. It would have been hard, as Green was only 4 years old at the time. But I did know the preteen Ruth Lawrence when she started there and even once played a departmental croquet match including her in which Bryan Birch made some epic long shots. Lawrence had <a href="https://en.wikipedia.org/wiki/Ruth_Lawrence">joined</a> St. Hugh’s College in 1983 at the age of twelve.</p>
<p>
Oxford has been Dick’s and my mind more in the past six years than before. Both of us were guests of Joël Ouaknine in 2012–2015 when he was there. Oxford has developed a front-line group in quantum computation, which fits as David Deutsch’s role as an originator began from there—note my story in the middle of this recent <a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/">post</a>.</p>
<p>
Recently Oxford has been in the <a href="https://www.statnews.com/2020/07/20/study-provides-first-glimpse-of-efficacy-of-oxford-astrazeneca-covid-19-vaccine/">news</a> for developing a promising Covid-19 vaccine. <a href="https://www.precisionvaccinations.com/vaccines/chadox1-mers-coronavirus-vaccine">ChAdOx1</a> heads Wikipedia’s <a href="https://en.wikipedia.org/wiki/COVID-19_vaccine#Vaccine_candidates">list</a> of candidate vaccines and has gone to final <a href="https://www.nationalgeographic.com/science/2020/07/oxford-vaccine-enters-final-phase-of-covid-19-trials-in-brazil-cvd/">trials</a>, though there is still a long evaluation process before approval for general use.</p>
<p>
Before that, a modeling <a href="https://nymag.com/intelligencer/2020/03/oxford-study-coronavirus-may-have-infected-half-of-u-k.html">study</a> from Oxford in March raised the question of whether many more people have had Covid-19 without symptoms or any knowledge. This kind of possibility has since been <a href="https://marginalrevolution.com/marginalrevolution/2020/06/karl-friston-on-immunological-dark-matter.html">likened</a> to a “dark matter” hypothesis, not just now regarding Covid-19 but a decade <a href="https://pubmed.ncbi.nlm.nih.gov/21839767/">ago</a> and before. </p>
<p>
A main <a href="https://theconversation.com/coronavirus-techniques-from-physics-promise-better-covid-19-models-can-they-deliver-139925">supporting</a> <a href="https://www.brunel.ac.uk/news-and-events/news/articles/Coronavirus-techniques-from-physics-promise-better-COVID-19-models-can-they-deliver">argument</a> is that a wide class of mathematical models can be fitted with higher relative likelihood if the hypothesis is true. I have wanted to take time to evaluate this argument amid the wider backdrop of <a href="https://rjlipton.wordpress.com/2018/05/19/lost-in-complexity/">controversy</a> over inference methods in physics, but online chess with unfortunately ramped-up frequency of cheating has filled up all disposable time and more.</p>
<p>
</p><p></p><h2> The Problem </h2><p></p>
<p></p><p>
Back to Chase’s new results on the following problem: </p>
<blockquote><p><b> </b> <em> Given two distinct binary strings of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> there is always a finite state deterministic automaton (FSA) that accepts one and rejects the other. <i>How few states can such a machine have?</i> </em>
</p></blockquote>
<p></p><p>
This is called the <em>separating words problem</em> (SWP). Here we consider it for binary strings only.</p>
<p>
John Robson proved <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B2%2F5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(n^{2/5})}" class="latex" title="{O(n^{2/5})}" /> states are enough—we suppress any log factors. Some like to write this as <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B2%2F5%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{O}(n^{2/5})}" class="latex" title="{\tilde{O}(n^{2/5})}" />. Chase <a href="https://arxiv.org/pdf/2007.12097.pdf">improves</a> this to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{O}(n^{1/3})}" class="latex" title="{\tilde{O}(n^{1/3})}" />:</p>
<blockquote><p><b>Theorem 2</b> <em><a name="Chasethm"></a> For any distinct <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+%5C%7B0%2C1%5C%7D%5E%7Bn%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x,y \in \{0,1\}^{n}}" class="latex" title="{x,y \in \{0,1\}^{n}}" />, there is a finite state deterministic automaton with <img src="https://s0.wp.com/latex.php?latex=%7BO%28n%5E%7B1%2F3%7D+%5Clog%5E%7B7%7D+n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{O(n^{1/3} \log^{7} n)}" class="latex" title="{O(n^{1/3} \log^{7} n)}" /> states that accepts <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> but not <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />. </em>
</p></blockquote>
<p></p><p>
We previously discussed this twice at GLL. We discussed the background and early results <a href="https://rjlipton.wordpress.com/2019/09/08/separating-words-by-automata/">here</a>. The original problem is due to Pavel Goralcik and Vaclav Koubek. They proved an upper bound that was <img src="https://s0.wp.com/latex.php?latex=%7Bo%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{o(n)}" class="latex" title="{o(n)}" />. Then we went over Robson’s bound <a href="https://rjlipton.wordpress.com/2019/09/16/separating-words-decoding-a-paper/">here</a>. The best upper bound was Robson’s result until Chase came along.</p>
<p>
</p><p></p><h2> The Approach </h2><p></p>
<p></p><p>
All the approaches to SWP seem to have a common thread. They find some family of “hash” functions <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> so that:</p>
<ol>
<li>
Any <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BH%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{H}" class="latex" title="{H}" /> can be computed by a FSA with few states. <p></p>
</li><li>
For any <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cneq+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \neq y}" class="latex" title="{x \neq y}" /> binary strings of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, there is an <img src="https://s0.wp.com/latex.php?latex=%7Bh+%5Cin+H%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h \in H}" class="latex" title="{h \in H}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7Bh%28x%29+%5Cneq+h%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h(x) \neq h(y)}" class="latex" title="{h(x) \neq h(y)}" />.
</li></ol>
<p>
The challenge is to find clever families that can do do both. Be easy to compute and also be able to tell strings apart. Actually this is only a coarse outline—Chase’s situation is a bit more complicated. </p>
<p>
</p><p></p><h2> The Proof </h2><p></p>
<p></p><p>
We have taken the statement of Theorem <a href="https://rjlipton.wordpress.com/feed/#Chasethm">2</a> verbatim from the paper. It has a common pecadillo of beginning a sentence for a specific <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> but writing <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Ccdots+n+%5Ccdots%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\cdots n \cdots)}" class="latex" title="{O(\cdots n \cdots)}" /> later. However, this is how we think intuitively: in terms of how the pieces of the formula behave. Chase declares right away his intent to ignore the power of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log n}" class="latex" title="{\log n}" />. How he gets the power <img src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/3}" class="latex" title="{1/3}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is the real point. We can convey the intuition in brief.</p>
<p>
A length-<img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> binary string can be identified with its set <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Csubseteq+%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \subseteq [n]}" class="latex" title="{A \subseteq [n]}" /> of positions where the string has a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. Chase begins by showing how a power of <img src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/2}" class="latex" title="{1/2}" /> on <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is obtainable by considering sets of the form </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bi%2Cp%7D+%3D+%5C%7Bj+%3A+j+%5Cin+A+%5Cwedge+j+%5Cequiv+i+%5Cpmod%7Bp%7D%5C%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  A_{i,p} = \{j : j \in A \wedge j \equiv i \pmod{p}\}, " class="latex" title="\displaystyle  A_{i,p} = \{j : j \in A \wedge j \equiv i \pmod{p}\}, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> is prime and <img src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i &lt; p}" class="latex" title="{i &lt; p}" />. Suppose we know a bound <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> such that for all distinct <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B \subseteq n}" class="latex" title="{A,B \subseteq n}" /> (that is, all distinct binary strings of legnth <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />) there is a prime <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3C+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p &lt; k}" class="latex" title="{p &lt; k}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i &lt; p}" class="latex" title="{i &lt; p}" /> such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |A_{i,p}| \neq |B_{i,p}|. " class="latex" title="\displaystyle  |A_{i,p}| \neq |B_{i,p}|. " /></p>
<p>Then by the Chinese Remainder Theorem, there is a prime <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> of magnitude about <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log n}" class="latex" title="{\log n}" /> such that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_%7Bi%2Cp%7D%7C+%5Cnot%5Cequiv+%7CB_%7Bi%2Cp%7D%7C+%5Cpmod%7Bq%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  |A_{i,p}| \not\equiv |B_{i,p}| \pmod{q}. " class="latex" title="\displaystyle  |A_{i,p}| \not\equiv |B_{i,p}| \pmod{q}. " /></p>
<p>Now we can make a finite automaton <img src="https://s0.wp.com/latex.php?latex=%7BM_%7BA%2CB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_{A,B}}" class="latex" title="{M_{A,B}}" /> with states <img src="https://s0.wp.com/latex.php?latex=%7B%28j%2C%5Cell%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(j,\ell)}" class="latex" title="{(j,\ell)}" /> that always increments <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> modulo <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and increments <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> modulo <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> each time it reads a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> when <img src="https://s0.wp.com/latex.php?latex=%7Bj+%5Cequiv+i+%5Cpmod%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j \equiv i \pmod{p}}" class="latex" title="{j \equiv i \pmod{p}}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7BM_%7BA%2CB%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_{A,B}}" class="latex" title="{M_{A,B}}" /> has order-of <img src="https://s0.wp.com/latex.php?latex=%7Bpq+%5Capprox+k%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{pq \approx k\log n}" class="latex" title="{pq \approx k\log n}" /> states. The finisher is that <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F2%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k = \tilde{O}(n^{1/2})}" class="latex" title="{k = \tilde{O}(n^{1/2})}" /> suffices. Again we ignore the pecadillo but we add some redundant words to the statement in the paper between dashes:</p>
<blockquote><p><b>Lemma 3</b> <em> For any distinct <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A,B \subseteq [n]}" class="latex" title="{A,B \subseteq [n]}" />—of size at most <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />—there is a prime <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{p = \tilde{O}(n^{1/2})}" class="latex" title="{p = \tilde{O}(n^{1/2})}" /> such that for some <img src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bp%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i \in [p]}" class="latex" title="{i \in [p]}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{|A_{i,p}| \neq |B_{i,p}|.}" class="latex" title="{|A_{i,p}| \neq |B_{i,p}|.}" /> </em>
</p></blockquote>
<p></p><p>
The power <img src="https://s0.wp.com/latex.php?latex=%7B1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/2}" class="latex" title="{1/2}" /> is of course weaker than Robson’s <img src="https://s0.wp.com/latex.php?latex=%7B2%2F5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2/5}" class="latex" title="{2/5}" />, but this statement conceals two “<a href="https://rjlipton.wordpress.com/2011/08/05/give-me-a-lever/">levers</a>” that enable leap-frogging <img src="https://s0.wp.com/latex.php?latex=%7B2%2F5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2/5}" class="latex" title="{2/5}" /> to get <img src="https://s0.wp.com/latex.php?latex=%7B1%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1/3}" class="latex" title="{1/3}" />. The first is that we don’t have to limit attention to sets <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B}" class="latex" title="{A,B}" /> that come from places where the corresponding strings <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y}" class="latex" title="{x,y}" /> have a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. Consider any string <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> and take <img src="https://s0.wp.com/latex.php?latex=%7BA_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_w}" class="latex" title="{A_w}" /> to be the set of index positions <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> in which <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> has the substring <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> beginning at place <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" />. Define <img src="https://s0.wp.com/latex.php?latex=%7BB_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B_w}" class="latex" title="{B_w}" /> likewise for <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />. Then we can try to prove results of the following form given <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m &lt; n}" class="latex" title="{m &lt; n}" />:</p>
<blockquote><p><b>Proposition 4</b> <em> For all distinct <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x,y \in \{0,1\}^n}" class="latex" title="{x,y \in \{0,1\}^n}" /> there is <img src="https://s0.wp.com/latex.php?latex=%7Bw+%5Cin+%5C%7B0%2C1%5C%7D%5Em%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{w \in \{0,1\}^m}" class="latex" title="{w \in \{0,1\}^m}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7BA_w+%5Cneq+B_w%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A_w \neq B_w}" class="latex" title="{A_w \neq B_w}" /> and </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%7CA_w%7C%2C%7CB_w%7C+%3D+O%28%5Cfrac%7Bn%7D%7Bm%7D%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  |A_w|,|B_w| = O(\frac{n}{m}). " class="latex" title="\displaystyle  |A_w|,|B_w| = O(\frac{n}{m}). " /></p>
</em><p><em></em>
</p></blockquote>
<p></p><p>
A finite automaton using this extension needs <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> states to store <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> in its finite control. The second lever is to try to prove results of this form, where now the words “of size at most <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" />” are not redundant:</p>
<blockquote><p><b>Lemma 5 (?)</b> <em><a name="conjlemma"></a> For any distinct <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB+%5Csubseteq+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A,B \subseteq [n]}" class="latex" title="{A,B \subseteq [n]}" /> of size at most <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> there is a prime <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Ctilde%7BO%7D%28N%5E%7B1%2F2%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{p = \tilde{O}(N^{1/2})}" class="latex" title="{p = \tilde{O}(N^{1/2})}" /> such that for some <img src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bp%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i \in [p]}" class="latex" title="{i \in [p]}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%7CA_%7Bi%2Cp%7D%7C+%5Cneq+%7CB_%7Bi%2Cp%7D%7C.%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{|A_{i,p}| \neq |B_{i,p}|.}" class="latex" title="{|A_{i,p}| \neq |B_{i,p}|.}" />  </em> [Update: see note below.]
</p></blockquote>
<p></p><p>
Now we need to balance the levers using the proposition and the lemma together.  Since <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> will add order-<img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> states to the automaton, we balance it against <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> from the previous argument.  So take <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+n%5E%7B1%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m = n^{1/3}}" class="latex" title="{m = n^{1/3}}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7BN+%3D+%5Cfrac%7Bn%7D%7Bm%7D+%5Capprox+n%5E%7B2%2F3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N = \frac{n}{m} \approx n^{2/3}}" class="latex" title="{N = \frac{n}{m} \approx n^{2/3}}" />. Lemma <a href="https://rjlipton.wordpress.com/feed/#conjlemma">5</a> then gives the bound </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++k+%3D+%5Ctilde%7BO%7D%28N%5E%7B1%2F2%7D%29+%3D+%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  k = \tilde{O}(N^{1/2}) = \tilde{O}(n^{1/3}) " class="latex" title="\displaystyle  k = \tilde{O}(N^{1/2}) = \tilde{O}(n^{1/3}) " /></p>
<p>on the magnitude of the needed primes <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />. This yields the <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BO%7D%28n%5E%7B1%2F3%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{O}(n^{1/3})}" class="latex" title="{\tilde{O}(n^{1/3})}" /> breakthrough on SWP.</p>
<p></p><p>
Here a famous New Yorker <a href="https://www.allposters.com/-sp/Oh-if-only-it-were-so-simple-New-Yorker-Cartoon-Posters_i9168200_.htm?UPI=PGQEG50&amp;PODConfigID=8419447&amp;sOrigID=169338">cartoon</a> with the caption “If only it were so simple” comes to mind.  But there is a catch. Chase is not quite able to prove lemma <a href="https://rjlipton.wordpress.com/feed/#conjlemma">5</a>. However, the <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> lever comes with extra flexibility that enables finding <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> that make <img src="https://s0.wp.com/latex.php?latex=%7BA_w+%5Cneq+B_w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A_w \neq B_w}" class="latex" title="{A_w \neq B_w}" /> and also give those sets an extra regularity property <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. Using <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, he is able to show the existence of good hash functions of a certain type. The modified lemma is enough to prove his new bound.  The proof still uses intricate analysis including integrals.</p>
<p>
This is classic high-power mathematics. When some idea is blocked, try to weaken the requirements. Sometimes it is possible to still proceed. It is a lesson that we sometimes forget, but a valuable one nevertheless.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We like the SWP and think Chase’s contribution is impressive. Note that it adds a third element <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> in the automaton.  Can the argument be pushed further by finding more levers to add more elements?  Is Lemma 5 true as stated, and with what (other) tradeoffs of <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> between it and Proposition 4?  [<b>Update</b>: not for extreme tradeoffs—see this <a href="https://rjlipton.wordpress.com/2020/08/03/cleverer-automata-exist/#comment-111915">comment</a>—but plausibly for <img src="https://s0.wp.com/latex.php?latex=%7Bm%2Cn%2CN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m,n,N}" class="latex" title="{m,n,N}" /> polynomially related.]</p>
<p>
We feel there could also be interesting applications for his theorem as it stands. Is the ability to tell two strings apart with a simple device—a FSA with not many states—useful? Could it solve some open problem? It does seem like a basic insight, yet we have no candidate application. Perhaps you have an idea. </p>
<p></p><p><br />
[added Q on Lemma 5 to “Open Problems”, “lower” bound –&gt; “upper” bound in third section, update in Open Problems.]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2020/08/03/cleverer-automata-exist/"><span class="datestr">at August 03, 2020 02:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsmath.wordpress.com/?p=2293">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/jrl.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsmath.wordpress.com/2020/08/02/itcs-2021-call-for-papers/">ITCS 2021 Call for Papers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The <strong>12th Innovations in Theoretical Computer Science (ITCS)</strong> conference will be held <strong>online</strong> from <strong>January 6-8, 2021</strong>.   The <strong>submission deadline</strong> is <strong>September 7, 2020</strong>.</p>



<p>The <a href="http://itcs-conf.org/">program committee</a> encourages you to send your papers our way!  See the <a href="http://itcs-conf.org/">call for papers</a> for information about submitting to the conference.</p>



<p>ITCS seeks to promote research that carries a strong conceptual message (e.g., introducing a new concept, model or understanding, opening a new line of inquiry within traditional or interdisciplinary areas, introducing new mathematical techniques and methodologies, or new applications of known techniques). ITCS welcomes both conceptual and technical contributions whose contents will advance and inspire the greater theory community.</p>



<p></p>



<h3>Important dates</h3>



<ul><li><strong>Submission deadline: </strong> September 7, 2020 (05:59PM PDT) </li><li><strong>Notification to authors:</strong> November 1, 2020</li><li><strong>Conference dates: </strong>January 6-8, 2021</li></ul>



<p></p>



<p></p></div>







<p class="date">
by James <a href="https://tcsmath.wordpress.com/2020/08/02/itcs-2021-call-for-papers/"><span class="datestr">at August 03, 2020 02:06 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
