<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="https://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="http://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="no data">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://scottaaronson.blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at February 23, 2022 05:39 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19673">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2022/02/23/simons-awards-for-2022/">Simons Awards for 2022</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<i>To receive this award from an organization I admire so much makes me totally happy and grateful—James Welch</i></p>
<p>
Jin-Yi Cai is one of the 2022 winners of the Simons awards in mathematics. Congrats to him. </p>
<p>
Jin-Yi is a dear and long time friend of ours. We are thrilled to see that he has been selected for this high honor:  The Simons Fellows program extends academic leaves from one term to a full year, enabling recipients to focus solely on research for the long periods often necessary for significant advances. The foundation is proud to support the work of these distinguished scientists. </p>
<p>
<a href="https://rjlipton.wpcomstaging.com/2022/02/23/simons-awards-for-2022/cai/" rel="attachment wp-att-19679"><img width="150" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/cai.png?resize=150%2C190&amp;ssl=1" class="aligncenter size-full wp-image-19679" height="190" /></a></p>
<p>
</p><p><b> The Mathematics Winners 2022 </b></p>
<p></p><p>
The winners are clickable below:<br />
<a href="https://people.math.wisc.edu/~anderson/">David Anderson</a>	University of Wisconsin-Madison <br />
 <a href="http://comet.lehman.cuny.edu/behrstock/">Jason Behrstock</a>	Lehman College <br />
 <a href="https://pages.cs.wisc.edu/~jyc/">Jin-Yi Cai</a> University of Wisconsin-Madison <br />
 <a href="https://people.math.rochester.edu/faculty/xchen84/">Xuwen Chen</a>	University of Rochester <br />
 <a href="https://www.math.uh.edu/~climenha/">Vaughn Climenhaga</a>	University of Houston <br />
 <a href="https://www.math.mcgill.ca/darmon/">Henri Darmon</a>	McGill University <br />
 <a href="https://www-math.umd.edu/people/faculty/item/299-gforni.html">Giovanni Forni	</a> University of Maryland, College Park <br />
 <a href="https://personal.math.ubc.ca/~afraser/">Ailana Fraser</a>	University of British Columbia <br />
 <a href="https://users.math.yale.edu/users/goncharov/">Alexander Goncharov</a>Yale University <br />
 <a href="https://math.nd.edu/people/faculty/matthew-gursky/">Matthew Gursky<br />
 </a><a href="https://www.mathematics.pitt.edu/people/piotr-hajlasz">Piotr Hajlasz</a>	University of Pittsburgh <br />
 <a href="https://people.math.gatech.edu/~jhom6/">Jennifer Hom</a>	Georgia Institute of Technology <br />
 <a href="https://mathweb.ucsd.edu/~aioana/">Adrian Ioana</a>	University of California, San Diego <br />
 <a href="http://shell.cas.usf.edu/~jonoska/">Natasa Jonoska</a>	University of South Florida <br />
 <a href="https://en.wikipedia.org/wiki/Jeff_Kahn">Jeff Kahn	</a> Rutgers, The State University of New Jersey <br />
 <a href="https://en.wikipedia.org/wiki/Jeremy_Kahn">Jeremy Kahn</a>	Brown University <br />
 <a href="https://ls.wisc.edu/faculty-staff/ls-tenure/chanwoo-kim-l-s-tenured-faculty">Chanwoo Kim</a>	University of Wisconsin-Madison <br />
 <a href="https://people.brandeis.edu/~kleinboc/">Dmitry Kleinbock</a>	Brandeis University <br />
 <a href="https://pages.uoregon.edu/klesh/">Alexander Kleshchev</a>	University of Oregon <br />
 <a href="https://math.washington.edu/people/sandor-kovacs">Sandor Kovacs</a>	University of Washington <br />
 <a href="https://en.wikipedia.org/wiki/Michael_J._Larsen">Michael Larsen</a>	Indiana University <br />
 <a href="http://www.math.stonybrook.edu/~blaine/">Blaine Lawson	</a> Stony Brook University <br />
 <a href="https://mathweb.ucsd.edu/~mleok/">Melvin Leok</a>	University of California, San Diego <br />
 <a href="https://www.bc.edu/bc-web/schools/mcas/departments/math/people/faculty-directory/tao-li.html">Tao Li</a>	Boston College <br />
 <a href="https://math.indiana.edu/about/faculty/lindenstrauss-ayelet.html">Ayelet Lindenstrauss</a>	Indiana University <br />
 <a href="https://math.uoregon.edu/profile/lipshitz">Robert Lipshitz</a>	University of Oregon <br />
 <a href="https://en.wikipedia.org/wiki/Robert_McCann_(mathematician)">Robert McCann</a>	University of Toronto <br />
 <a href="https://math.jhu.edu/~eriehl/">Emily Riehl</a>	Johns Hopkins University <br />
 <a href="https://lsa.umich.edu/math/people/faculty/rudelson.html">Mark Rudelson</a>	University of Michigan <br />
 <a href="https://mathweb.ucsd.edu/~rsaab/">Rayan Saab</a>	University of California, San Diego <br />
 <a href="https://math.cornell.edu/laurent-saloff-coste">Laurent Saloff-Coste</a>	Cornell University <br />
 <a href="https://pi.math.cornell.edu/~mike/">Michael Stillman</a>	Cornell University <br />
 <a href="https://math.illinois.edu/directory/profile/vesna">Vesna Stojanoska</a>	University of Illinois at Urbana-Champaign <br />
 <a href="https://www.math.uci.edu/people/jeffrey-streets">Jeffrey Streets</a> University of California, Irvine <br />
 <a href="https://sites.math.rutgers.edu/~pht19/">Pham Tiep</a>	Rutgers, The State University of New Jersey <br />
 <a href="http://pi.math.cornell.edu/~ajt/">Alex Townsend</a>	Cornell University <br />
 <a href="https://www.urbanskimath.com">Mariusz Urbanski</a>	University of North Texas <br />
 <a href="https://math.unl.edu/azupan2">Alexander Zupan</a>	University of Nebraska-Lincoln </p>
<p>
Note that University of Wisconsin-Madison has three winners—pretty impressive.</p>
<p>
</p><p><b> Open Problems </b></p>
<p></p><p>
Again congrats to all. We look forward to hearing about future results from them all. </p>
<p></p></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wpcomstaging.com/2022/02/23/simons-awards-for-2022/"><span class="datestr">at February 23, 2022 05:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/02/23/postdoc-in-parallel-and-distributed-algorithms-at-university-of-warwick-apply-by-march-13-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/02/23/postdoc-in-parallel-and-distributed-algorithms-at-university-of-warwick-apply-by-march-13-2022/">Postdoc in Parallel and Distributed Algorithms at University of Warwick (apply by March 13, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>We are looking for excellent candidates for a 2 years postdoc position in the area of the design and analysis of parallel and distributed algorithms, focusing on fundamental research in this area.</p>
<p>Applicants should be recent PhDs in relevant research areas.</p>
<p>Informal enquiries are welcome and may be sent to Artur Czumaj (A.Czumaj@warwick.ac.uk).</p>
<p>Website: <a href="https://warwick.ac.uk/dcs/people/artur_czumaj/postdoc-advert-feb-2022">https://warwick.ac.uk/dcs/people/artur_czumaj/postdoc-advert-feb-2022</a><br />
Email: A.Czumaj@warwick.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/02/23/postdoc-in-parallel-and-distributed-algorithms-at-university-of-warwick-apply-by-march-13-2022/"><span class="datestr">at February 23, 2022 03:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/028">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/028">TR22-028 |  The plane test is a local tester for  Multiplicity Codes | 

	Dan Karliner, 

	Amnon Ta-Shma, 

	Roie Salama</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Multiplicity codes are a generalization of RS and RM codes where for each evaluation point we output the evaluation of a low-degree polynomial  and all of its directional derivatives up  to order $s$. Multi-variate multiplicity codes are locally decodable with the natural local decoding algorithm that reads values on a random line and corrects to the closest uni-variate multiplicity code. However, it was not known whether multiplicity codes are locally testable, and this question has been posed since the introduction of these codes with no progress up to date. In fact, it has been also open whether multiplicity codes can be characterized by local constraints, i.e., if there exists a subset $B$ such that $c$ is in the code iff $c \cdot z=0$ for any $z\in B$, and,
every $z \in B$ has small Hamming weight, i.e., few non-zero symbols.

We begin by giving a simple example showing the line test does not give local characterization when $d&gt;q$. Surprisingly, 
we then show the plane test is a local characterization when $s&lt;q$ and $d&lt;qs-1$ for prime $q$. 
In addition, we show the $k$-dimensional test is a local tester for multiplicity codes, when $s &lt; q$ and $k$ is at least $\lceil \frac{d+1}{q-1} \rceil$.
Combining the two results, we show that the plane test is a local tester for multiplicity codes, with constant rejection probability for constant $s$.

Our technique is new. We represent the given input as a possibly very high-degree polynomial,  and we show that for some choice of plane,  the restriction of the polynomial to the plane is a high-degree bi-variate polynomial. The argument has to work modulo the appropriate kernels, and for that we use Grobner theory, the Combinatorial Nullstellensatz theorem and its generalization to multiplicities. Even given that, the argument is delicate and requires choosing a non-standard monomial order for the argument to work.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/028"><span class="datestr">at February 23, 2022 03:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/02/23/postdoc-3-4-years-at-university-of-bergen-up-valencia-apply-by-march-15-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/02/23/postdoc-3-4-years-at-university-of-bergen-up-valencia-apply-by-march-15-2022/">Postdoc 3-4 years at University of Bergen &amp; UP Valencia (apply by March 15, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Associated with the project “Machine Teaching for Explainable AI”, at the Algorithms and Machine Learning groups at the University of Bergen, the Valencian Research Institute for AI (VRAIN), and the Norwegian companies Equinor and Eviny. The position includes visits and stays at VRAIN in the periods commonly agreed with the candidate of up to 1 year in total.</p>
<p>Website: <a href="https://www.jobbnorge.no/en/available-jobs/job/220813/postdoctoral-research-fellow-position-within-informatics-ai-and-algorithms">https://www.jobbnorge.no/en/available-jobs/job/220813/postdoctoral-research-fellow-position-within-informatics-ai-and-algorithms</a><br />
Email: telle@ii.uib.no</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/02/23/postdoc-3-4-years-at-university-of-bergen-up-valencia-apply-by-march-15-2022/"><span class="datestr">at February 23, 2022 08:18 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/027">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/027">TR22-027 |  New Near-Linear Time Decodable Codes Closer to the GV Bound | 

	Dean Doron, 

	Guy Blanc</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We construct a family of binary codes of relative distance $\frac{1}{2}-\varepsilon$ and rate $\varepsilon^{2} \cdot 2^{-\log^{\alpha}(1/\varepsilon)}$ for $\alpha \approx \frac{1}{2}$ that are decodable, probabilistically, in near linear time. This improves upon the rate of the state-of-the-art near-linear time decoding near the GV bound due to Jeronimo, Srivastava, and Tulsiani, who gave a randomized decoding of Ta-Shma codes with $\alpha \approx \frac{5}{6}$ [T17,JST21].
Each code in our family can be constructed in probabilistic polynomial time, or deterministic polynomial time given sufficiently good explicit $3$-uniform hypergraphs. 
     
Our construction is based on a new graph-based bias amplification method. While previous works start with some base code of relative distance $\frac{1}{2} \varepsilon_0$ for $\varepsilon_0 \gg \varepsilon$ and amplify the distance to $\frac{1}{2}-\varepsilon$ by walking on an expander, or on a carefully tailored product of expanders, we walk over very sparse, highly mixing, hypergraphs. 
Study of such hypergraphs further offers an avenue toward achieving rate $\widetilde{\Omega}(\varepsilon^2)$.
For our unique- and list-decoding algorithms, we employ the framework developed in [JST21].</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/027"><span class="datestr">at February 23, 2022 05:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2022/02/23/standard-errors/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2022/02/23/standard-errors/">Let us never speak of these values again.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>A recent <a href="https://twitter.com/emollick/status/1493428796539772937">Twitter quiz</a> asked “what is a powerful concept from your field that, if more people understood it, their lives would be better?” Unambiguously, the answer from my field is statistical significance. Significance testing is a confusing, obscure statistical practice. It is hard to explain and usually impossible to justify. But papers can only be published if they are “statistically significant.” Here, I’ll explain in as plain terms as I can what statistical significance means in almost every published scientific study. I’ll do this without ever defining a p-value, as p-values have nothing to do with the way significance testing is used. Instead, significance testing amounts to hand wavy arguments about precision and variability. Laying it out this way shows why the authority granted to significance testing is so suspect and unearned.</p>

<p>Let’s suppose we’re trying to evaluate the benefit of some intervention. We test the intervention on a bunch of individuals and compute the average benefit which we call the effect size. The effect size could be the number of years of life a person gains with some cancer treatment or the amount of money gained with an investment strategy.</p>

<p>Since the effect size is the <em>average</em> of all the individuals in a study some individuals will have received less benefit than average and some more than average. Combining this varied benefit with the reality that experiments are always noisy and complicated, it may very well be that even if we measure a positive benefit on average, the intervention may actually be mostly harmful to the general population.</p>

<p>Think about the hypothetical situation where on half the population the benefit is equal to 1 and on the other half it’s negative 1. In this case, the average benefit is zero. If we collected a random set of people and computed the average effect size, we’d see a positive effect size about half of the time. In other words, if your experiment was “flip a coin ten times,” you’ll see 5 or more heads about half of the times you run this experiment.</p>

<p>The experimenter’s goal is to distinguish whether the benefit is large, small, or if the intervention is actually harmful. What the paradigm of statistical significance aims to do is to find a way to determine if an intervention is “mostly good.” It goes forth like this: using statistics, you estimate the standard error (SE) of the measured effect size. Roughly speaking, the standard error measures how spread out the effect size is over a population. When the standard error is small, everyone in the population experiences the same effect from a treatment. When the standard error is large, even if the effect size is positive, some may experience negative effects and some positive.</p>

<p>If the measured effect size is greater than twice the standard error, you declare that you have discovered your intervention is statistically significant at the “p&lt;0.05” level. If the effect size is bigger than 2.6 times the standard error you declare statistical significance at the
“p&lt;0.01” level. If effect size is even bigger than three times the standard error you declare statistical significance at the “p&lt;0.003” level! Wow! There’s a Nobel Prize in your future. But if the effect size is only 1.9 times bigger than the standard error, you unfortunately have not found a statistically significant result and have to throw all your work in the trash. Unless, of course, you are an economist. In this case, you are allowed the special “p&lt;0.1” level, which occurs when the effect size is 1.7 times the standard error.</p>

<p>The following figure, adapted from a tweet by <a href="https://twitter.com/TAH_Sci/status/1490701257769734145">Thomas House</a>, nicely illustrates the situation:</p>

<p class="center"><img width="100%" alt="Only one of these droids is signficant" src="http://www.argmin.net/assets/significant.png" /></p>

<p>Here, there are four hypothetical distributions of benefit. All but (a) are “statistically significant.” The interventions we are always striving for are ones with clear benefit, like (d) in the bottom right. Interventions like this do exist: In the Pfizer trial, the effect size was 12 times larger than the standard error. Vaccines work! But most interventions are not vaccines (or parachutes for that matter).</p>

<p>The other panels show why statistical significance alone is so problematic. Figures (a) and (b) are nearly indistinguishable plots, but one is significant and the other is not. Moreover, statistical significance also misses the forest for the trees. You can have a miniscule effect size and still have a significant effect. Do we always prefer the (c) to the (a)? Is a meager, but mostly positive benefit necessarily better than a treatment potentially of large benefit to some but harmful to others necessarily? Wouldn’t it be in our interest to understand this spread of outcomes so we could isolate the group of individuals who benefit from the treatment?</p>

<p>The fact that a mere factor of 1.5 separates the difference between “not publishable” and “undoubtedly real” is deeply concerning. And every statistician knows how estimates of standard error can be <em>very</em> sensitive. Simple approximations can make the standard error appear 1.4 times smaller, which is enough to transform an insignificant result into a significant one. This is what is commonly known as “data dredging” or “p-hacking”: trying to find the appropriate set of assumptions under which your experiment has small standard error and is hence statistically significant.</p>

<p>The precise definitions of standard error and p-value don’t illuminate the situation. Since p-values lead you to pedantry and quibbling about tiny effects, their actual definition, which is complicated and hard to even explain to other statisticians, just confuses people and doesn’t fix science. Most practicing scientists would be better off not knowing what a p-value is.</p>

<p>And a lot of the other fixes also don’t help. For example, the <a href="https://clincalc.com/Stats/FragilityIndex.aspx">fragility index</a> is often used in medicine to describe how many “non-events” have to become events for the significance to vanish. But this is just a way to conflate sample size and p-values, and isn’t getting away from the core problem that statistical significance testing is a mass waste of time.</p>

<p>I am by no means the first person to complain about the absurdity of significance testing. Some examples from the last 50 years include <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.200.7648&amp;rep=rep1&amp;type=pdf">Meehl</a> (1978), <a href="https://www.jstor.org/stable/1803924">Leamer</a> (1983), <a href="https://www.jstor.org/stable/270939">Freedman</a> (1991), <a href="https://www.bmj.com/content/308/6924/283">Altman</a> (1994), <a href="http://www.principlesofeconometrics.com/poe5/writing/kennedy.pdf">Kennedy</a> (2002), <a href="https://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.0020124">Ioannidis</a> (2005), <a href="https://www.princeton.edu/~deaton/downloads/Instruments_of_Development.pdf">Deaton</a> (2009), <a href="https://www.press.umich.edu/186351/cult_of_statistical_significance">Ziliak and McCloskey</a> (2008), and <a href="https://stat.columbia.edu/~gelman/research/published/asa_pvalues.pdf">Gelman</a> (2016). The significance testing framework is barely 100 years old. And people have been rightfully attacking it for nearly as long. Why do we remain so stuck?</p>

<p>The aforementioned list of grumpy people have a deeper criticism of contemporary science beyond significance testing, and this critique is one I hope to take up in future blogs. When can we trust scientific consensus and what structures and methods are necessary to build such consensus? One of the core questions is that of experimental validity. Statistical validity is a small part of the big picture that establishes the trustworthiness of a study. The study must be <em>construct valid</em>, measuring the right quantities. It must be <em>internally valid</em>, avoiding bias and confounding. And it must be <em>externally valid</em>, generalizable to other contexts. The next few blogs will try to unpack some thoughts on validity, and why validity and design remain the most pressing challenges in contemporary scientific inquiry.</p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2022/02/23/standard-errors/"><span class="datestr">at February 23, 2022 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09904">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09904">Cyclic generators and an improved linear kernel for the rooted subtree prune and regraft distance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kelk:Steven.html">Steven Kelk</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Linz:Simone.html">Simone Linz</a>, Ruben Meuwese <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09904">PDF</a><br /><b>Abstract: </b>The rooted subtree prune and regraft (rSPR) distance between two rooted
binary phylogenetic trees is a well-studied measure of topological
dissimilarity that is NP-hard to compute. Here we describe an improved linear
kernel for the problem. In particular, we show that if the classical subtree
and chain reduction rules are augmented with a modified type of chain reduction
rule, the resulting trees have at most 9k-3 leaves, where k is the rSPR
distance; and that this bound is tight. The previous best-known linear kernel
had size O(28k). To achieve this improvement we introduce cyclic generators,
which can be viewed as cyclic analogues of the generators used in the
phylogenetic networks literature. As a corollary to our main result we also
give an improved weighted linear kernel for the minimum hybridization problem
on two rooted binary phylogenetic trees.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09904"><span class="datestr">at February 22, 2022 11:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09892">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09892">Comparing the Complexity of Robotic Tasks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Michelle Ho, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Farid:Alec.html">Alec Farid</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Majumdar:Anirudha.html">Anirudha Majumdar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09892">PDF</a><br /><b>Abstract: </b>We are motivated by the problem of comparing the complexity of one robotic
task relative to another. To this end, we define a notion of reduction that
formalizes the following intuition: Task 1 reduces to Task 2 if we can
efficiently transform any policy that solves Task 2 into a policy that solves
Task 1. We further define a quantitative measure of the relative complexity
between any two tasks for a given robot. We prove useful properties of our
notion of reduction (e.g., reflexivity, transitivity, and antisymmetry) and
relative complexity measure (e.g., nonnegativity and monotonicity). In
addition, we propose practical algorithms for estimating the relative
complexity measure. We illustrate our framework for comparing robotic tasks
using (i) examples where one can analytically establish reductions, and (ii)
reinforcement learning examples where the proposed algorithm can estimate the
relative complexity between tasks.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09892"><span class="datestr">at February 22, 2022 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09883">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09883">On Efficient Noncommutative Polynomial Factorization via Higman Linearization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>V. Arvind, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Joglekar:Pushkar_S=.html">Pushkar S. Joglekar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09883">PDF</a><br /><b>Abstract: </b>In this paper we study the problem of efficiently factorizing polynomials in
the free noncommutative ring F&lt;x_1,x_2,...,x_n&gt; of polynomials in noncommuting
variables x_1,x_2,..., x_n over the field F. We obtain the following result:
</p>
<p>Given a noncommutative arithmetic formula of size s computing a
noncommutative polynomial f in F&lt;x_1,x_2,...,x_n&gt; as input, where F=F_q is a
finite field, we give a randomized algorithm that runs in time polynomial in s,
n and log q that computes a factorization of f as a product f=f_1f_2\cdots f_r,
where each f_i is an irreducible polynomial that is output as a noncommutative
algebraic branching program.
</p>
<p>The algorithm works by first transforming f into a linear matrix L using
Higman's linearization of polynomials. We then factorize the linear matrix L
and recover the factorization of f. We use basic elements from Cohn's theory of
free ideals rings combined with Ronyai's randomized polynomial-time algorithm
for computing invariant subspaces of a collection of matrices over finite
fields.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09883"><span class="datestr">at February 22, 2022 10:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09797">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09797">Tight Bounds for Sketching the Operator Norm, Schatten Norms, and Subspace Embeddings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yi.html">Yi Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09797">PDF</a><br /><b>Abstract: </b>We consider the following oblivious sketching problem: given $\epsilon \in
(0,1/3)$ and $n \geq d/\epsilon^2$, design a distribution $\mathcal{D}$ over
$\mathbb{R}^{k \times nd}$ and a function $f: \mathbb{R}^k \times
\mathbb{R}^{nd} \rightarrow \mathbb{R}$, so that for any $n \times d$ matrix
$A$, $$\Pr_{S \sim \mathcal{D}} [(1-\epsilon) \|A\|_{op} \leq f(S(A),S) \leq
(1+\epsilon)\|A\|_{op}] \geq 2/3,$$ where $\|A\|_{op}$ is the operator norm of
$A$ and $S(A)$ denotes $S \cdot A$, interpreting $A$ as a vector in
$\mathbb{R}^{nd}$. We show a tight lower bound of $k = \Omega(d^2/\epsilon^2)$
for this problem. Our result considerably strengthens the result of Nelson and
Nguyen (ICALP, 2014), as it (1) applies only to estimating the operator norm,
which can be estimated given any OSE, and (2) applies to distributions over
general linear operators $S$ which treat $A$ as a vector and compute $S(A)$,
rather than the restricted class of linear operators corresponding to matrix
multiplication. Our technique also implies the first tight bounds for
approximating the Schatten $p$-norm for even integers $p$ via general linear
sketches, improving the previous lower bound from $k = \Omega(n^{2-6/p})$
[Regev, 2014] to $k = \Omega(n^{2-4/p})$. Importantly, for sketching the
operator norm up to a factor of $\alpha$, where $\alpha - 1 = \Omega(1)$, we
obtain a tight $k = \Omega(n^2/\alpha^4)$ bound, matching the upper bound of
Andoni and Nguyen (SODA, 2013), and improving the previous $k =
\Omega(n^2/\alpha^6)$ lower bound. Finally, we also obtain the first lower
bounds for approximating Ky Fan norms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09797"><span class="datestr">at February 22, 2022 10:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09718">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09718">Finding shortest non-separating and non-disconnecting paths</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yasuaki.html">Yasuaki Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nagano:Shunsuke.html">Shunsuke Nagano</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Otachi:Yota.html">Yota Otachi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09718">PDF</a><br /><b>Abstract: </b>For a connected graph $G = (V, E)$ and $s, t \in V$, a non-separating $s$-$t$
path is a path $P$ between $s$ and $t$ such that the set of vertices of $P$
does not separate $G$, that is, $G - V(P)$ is connected. An $s$-$t$ path is
non-disconnecting if $G - E(P)$ is connected. The problems of finding shortest
non-separating and non-disconnecting paths are both known to be NP-hard. In
this paper, we consider the problems from the viewpoint of parameterized
complexity. We show that the problem of finding a non-separating $s$-$t$ path
of length at most $k$ is W[1]-hard parameterized by $k$, while the
non-disconnecting counterpart is fixed-parameter tractable parameterized by
$k$. We also consider the shortest non-separating path problem on several
classes of graphs and show that this problem is NP-hard even on bipartite
graphs, split graphs, and planar graphs. As for positive results, the shortest
non-separating path problem is fixed-parameter tractable parameterized by $k$
on planar graphs and polynomial-time solvable on chordal graphs if $k$ is the
shortest path distance between $s$ and $t$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09718"><span class="datestr">at February 22, 2022 11:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09697">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09697">A Quantum Polynomial-Time Solution to The Dihedral Hidden Subgroup Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Moore:Matthew.html">Matthew Moore</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Young:Grace.html">Grace Young</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09697">PDF</a><br /><b>Abstract: </b>We present a polynomial-time quantum algorithm for the Hidden Subgroup
Problem over $\mathbb{D}_{2^n}$. The usual approach to the Hidden Subgroup
Problem relies on harmonic analysis in the domain of the problem, and the best
known algorithm using this approach has time complexity in
$2^{\mathcal{O}(\sqrt{n})}$. By focusing on structure encoded in the codomain
of the problem, we develop a polynomial-time algorithm which uses this
structure to direct a "walk" down the subgroup lattice of $\mathbb{D}_{2^n}$
terminating at the hidden subgroup.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09697"><span class="datestr">at February 22, 2022 11:08 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09686">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09686">Local Decomposition of Hexahedral Singular Nodes into Singular Curves</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Paul.html">Paul Zhang</a>, Judy Chiang, XinyiFan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mundilova:Klara.html">Klara Mundilova</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09686">PDF</a><br /><b>Abstract: </b>Hexahedral (hex) meshing is a long studied topic in geometry processing with
many fascinating and challenging associated problems. Hex meshes vary in
complexity from structured to unstructured depending on application or domain
of interest. Fully structured meshes require that all interior mesh edges are
adjacent to exactly four hexes. Edges not satisfying this criteria are
considered singular and indicate an unstructured hex mesh. Singular edges join
together into singular curves that either form closed cycles, end on the mesh
boundary, or end at a singular node, a complex junction of more than two
singular curves. While all hex meshes with singularities are unstructured,
those with more complex singular nodes tend to have more distorted elements and
smaller scaled Jacobian values. In this work, we study the topology of singular
nodes. We show that all eight of the most common singular nodes are
decomposable into just singular curves. We further show that all singular
nodes, regardless of edge valence, are locally decomposable. Finally we
demonstrate these decompositions on hex meshes, thereby decreasing their
distortion and converting all singular nodes into singular curves. With this
decomposition, the enigmatic complexity of 3D singular nodes becomes
effectively 2D.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09686"><span class="datestr">at February 22, 2022 11:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09685">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09685">Scalable Fine-Grained Parallel Cycle Enumeration Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Jovan Blanuša, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ienne:Paolo.html">Paolo Ienne</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Atasu:Kubilay.html">Kubilay Atasu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09685">PDF</a><br /><b>Abstract: </b>This paper investigates scalable parallelisation of state-of-the-art cycle
enumeration algorithms by Johnson and Read-Tarjan along with their applications
to temporal graphs. We provide a comprehensive theoretical analysis of various
parallel versions of these algorithms and evaluate their performance on
multi-core processors. We show that a straightforward coarse-grained
parallelisation approach is not scalable and suffers from load imbalance
issues. To eliminate the load imbalance, we modify the Johnson and the
Read-Tarjan algorithms to exploit finer-grained parallelism. We show that our
fine-grained parallel Read-Tarjan algorithm is theoretically work efficient --
i.e., it does no more work than its serial version. However, our fine-grained
parallel Johnson algorithm does not share this property. Yet, in practice, our
fine-grained parallel Johnson algorithm outperforms our fine-grained parallel
Read-Tarjan algorithm. In any case, both of our contributed fine-grained
parallel algorithms are scalable, meaning that they can effectively utilise an
increasing number of software threads, which we prove theoretically and
demonstrate through extensive experiments. On a cluster of multi-core CPUs with
$256$ physical cores that can execute $1024$ simultaneous threads, our
fine-grained parallel Johnson and Read-Tarjan algorithms are respectively up to
$435\times$ and $470\times$ faster than their single-threaded versions. On the
same compute cluster, our fine-grained parallel algorithms are on average an
order of magnitude faster than their coarse-grained parallel counterparts.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09685"><span class="datestr">at February 22, 2022 11:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.09495">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.09495">Sorting Balls and Water: Equivalence and Computational Complexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ito:Takehiro.html">Takehiro Ito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kawahara:Jun.html">Jun Kawahara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Minato:Shin=ichi.html">Shin-ichi Minato</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Otachi:Yota.html">Yota Otachi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saitoh:Toshiki.html">Toshiki Saitoh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suzuki:Akira.html">Akira Suzuki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uehara:Ryuhei.html">Ryuhei Uehara</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uno:Takeaki.html">Takeaki Uno</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamanaka:Katsuhisa.html">Katsuhisa Yamanaka</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshinaka:Ryo.html">Ryo Yoshinaka</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.09495">PDF</a><br /><b>Abstract: </b>Various forms of sorting problems have been studied over the years. Recently,
two kinds of sorting puzzle apps are popularized. In these puzzles, we are
given a set of bins filled with colored units, balls or water, and some empty
bins. These puzzles allow us to move colored units from a bin to another when
the colors involved match in some way or the target bin is empty. The goal of
these puzzles is to sort all the color units in order. We investigate
computational complexities of these puzzles. We first show that these two
puzzles are essentially the same from the viewpoint of solvability. That is, an
instance is sortable by ball-moves if and only if it is sortable by
water-moves. We also show that every yes-instance has a solution of polynomial
length, which implies that these puzzles belong to in NP. We then show that
these puzzles are NP-complete. For some special cases, we give polynomial-time
algorithms. We finally consider the number of empty bins sufficient for making
all instances solvable and give non-trivial upper and lower bounds in terms of
the number of filled bins and the capacity of bins.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.09495"><span class="datestr">at February 22, 2022 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2202.06115">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2202.06115">Trinomials and Deterministic Complexity Limits for Real Solving</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Erick Boniface, Weixun Deng, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rojas:J=_Maurice.html">J. Maurice Rojas</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2202.06115">PDF</a><br /><b>Abstract: </b>Consider a univariate polynomial f in Z[x] with degree d, exactly t monomial
terms, and coefficients in {-H,...,H}. Solving f over the reals, R, in
polynomial-time can be defined as counting the exact number of real roots of f
and then finding (for each such root z) an approximation w of logarithmic
height (log(dH))^{O(1)} such that the Newton iterates of w have error decaying
at a rate of O((1/2)^{2^i}). Solving efficiently in this sense, using
(log(dH))^{O(1)} deterministic bit operations, is arguably the most honest
formulation of solving a polynomial equation over R in time polynomial in the
input size. Unfortunately, deterministic algorithms this fast are known only
for t=2, unknown for t=3, and provably impossible for t=4. (One can of course
resort to older techniques with complexity (d\log H)^{O(1)} for t&gt;=4.)
</p>
<p>We give evidence that polynomial-time real-solving in the strong sense above
is possible for t=3: We give a polynomial-time algorithm employing
A-hypergeometric series that works for all but a fraction of 1/Omega(log(dH))
of the input f. We also show an equivalence between fast trinomial solving and
sign evaluation at rational points of small height. As a consequence, we show
that for "most" trinomials f, we can compute the sign of f at a rational point
r in time polynomial in log(dH) and the logarithmic height of r. (This was
known only for binomials before.) We also mention a related family of
polynomial systems that should admit a similar speed-up for solving.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2202.06115"><span class="datestr">at February 22, 2022 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/02/21/postdoc-at-lip-ens-lyon-apply-by-march-1-2022-2/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/02/21/postdoc-at-lip-ens-lyon-apply-by-march-1-2022-2/">Postdoc at LIP, ENS Lyon (apply by March 1, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A postdoctoral position in Computer Science is available at LIP, ENS Lyon. Details on the website.</p>
<p>Website: <a href="http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html">http://perso.ens-lyon.fr/edouard.bonnet/postdocOffer.html</a><br />
Email: edouard.bonnet@ens-lyon.fr</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/02/21/postdoc-at-lip-ens-lyon-apply-by-march-1-2022-2/"><span class="datestr">at February 21, 2022 09:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2182374389954850731">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2022/02/i-will-be-on-instagramif-you-have-two.html">I will be on Instagram/If you have two reals in a box.... (Guest Post by David Marcus)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I will be on instragram:</p><p>We,  Prof. Mohammad Hajiaghayi and Prof. William Gasarch plan to have an Instagram Live at @mhajiaghayi this SAT FEB 26, 1:30PM EDT (in English).</p><p> We talk about our lives as well as blogging, research, and how to inspire young minds. Please join if you can.</p><p>#PvsNP #blogging #youngminds #instagram</p><p>-------------------------------------</p><p> (David Marcus emailed me this for a guest post, inspired by my posts on a similar problem where I gave the question <a href="https://blog.computationalcomplexity.org/2021/07/would-you-take-this-bet-part-1.html">here</a> and the answer <a href="https://blog.computationalcomplexity.org/2021/07/would-you-take-this-bet-part-2.html">here</a>.)</p><p>This is a well known problem, but I have learned over time that not everyone knows things that are well known.</p><p>PICK THE LARGEST NUMBER:</p><p>There are two distinct reals in a box (how do they fit! aren't reals infinite!). They are called the first and second number. </p><p>You want to pick the larger one. You can pick one of the numbers at random and look at it</p><p>before deciding which one you want. </p><p>Is there a strategy that will win with probability &gt; 1/2.</p><p>CLARIFICATIONS:</p><p>1) We do not want a strategy that does well on average or in the long run. Even if the games is played just once, we want the probability of winning to be &gt; 1/2.</p><p>2) It must have prob of winning &gt; 1/2 for EVERY pair of reals.</p><p>3) Here is an example of a strategy that does NOT work: Pick the first number with prob 1/2. If its positive then keep it, else dump it. If the numbers are{1,2} this only works half the time.</p><p>(Warning: I will NOT block comments that give away the answer, so if you want to work on it without knowing the answer, do not look at comments.) </p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2022/02/i-will-be-on-instagramif-you-have-two.html"><span class="datestr">at February 21, 2022 05:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/026">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/026">TR22-026 |  Trading Time and Space in Catalytic Branching Programs | 

	Ian Mertz, 

	James  Cook</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
An $m$-catalytic branching program (Girard, Koucky, McKenzie 2015) is a set of $m$ distinct branching programs for $f$ which are permitted to share internal (i.e. non-source non-sink) nodes. While originally introduced as a non-uniform analogue to catalytic space, this also gives a natural notion of amortized non-uniform space complexity for $f$, namely the smallest value $|G|/m$ for an $m$-catalytic branching program $G$ for $f$ (Potechin 2017).

Potechin (2017) showed that every function $f$ has amortized size $O(n)$, witnessed by an $m$-catalytic branching program where $m = 2^{2^n-1}$. We recreate this result by defining a catalytic algorithm for evaluating polynomials using a large amount of space but $O(n)$ time. This allows us to balance this with previously known algorithms which are efficient with respect to space at the cost of time (Cook, Mertz 2020, 2021). We show that for any $\epsilon \geq 2n^{-1}$, every function $f$ has an $m$-catalytic branching program of size $O_\epsilon(mn)$, where $m = 2^{2^{\epsilon n}}$. We similarly recreate an improved result due to Robere and Zuiddam (2021), and show that for $d \leq n$ and $\epsilon \geq 2d^{-1}$, the same result holds for $m = 2^{n \choose \leq \epsilon d}$ as long as $f$ is a degree-$d$ polynomial over $\mathbb{F}_2$. We also show that for certain classes of functions, $m$ can be reduced to $2^{poly(n)}$ while still maintaining linear or quasi-linear amortized size.

In the other direction, we bound the necessary length, and by extension the amortized size, of any permutation branching program for an arbitrary function between $3n$ and $4n-4$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/026"><span class="datestr">at February 20, 2022 12:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/025">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/025">TR22-025 |  Efficient Low-Space Simulations From the Failure of the Weak Pigeonhole Principle | 

	Oliver Korten</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A recurring challenge in the theory of pseudorandomness and circuit complexity is the explicit construction of ``incompressible strings,'' i.e. finite objects which lack a specific type of structure or simplicity. In most cases, there is an associated NP search problem which we call the ``compression problem,'' where we are given a candidate object and must either find a compressed/structured representation of it or determine that none exist. For a particular notion of compressibility, a natural question is whether an efficient algorithm for the compression problem would aide us in the construction of incompressible objects. Consider the following two instances of this question:

(1) Does an efficient algorithm for circuit minimization imply efficient constructions of hard truth tables?

(2) Does an efficient algorithm for factoring integers imply efficient constructions of large prime numbers?
 
In this work, we connect these kinds of questions to the long-standing challenge of proving space/time tradeoffs for Turing machines, and proving stronger separations between the RAM and 1-tape computation models. In particular, one of our main theorems shows that modest space/time tradeoffs for deterministic exponential time, or separations between basic Turing machine memory models, would imply a positive answer to both (1) and (2). 
These results apply to a more general class of explicit construction problems, where we have some efficient compression scheme that encodes $n$-bit strings using $&lt;n$ bits, and we aim to construct an $n$-bit string which cannot be recovered from its encoding.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/025"><span class="datestr">at February 20, 2022 12:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2022/02/20/prague-summer-school-on-discrete-mathematics-2/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2022/02/20/prague-summer-school-on-discrete-mathematics-2/">Prague Summer School on Discrete Mathematics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
July 11-15, 2022 Prague, Czech Republic https://www.mff.cuni.cz/en/iuuk/events/prague-summer-school-on-discrete-mathematics Registration deadline: March 1, 2022 Prague Summer School on Discrete Mathematics 2022 will feature lecture series on statistical physics methods in combinatorics (Will Perkins) and the container method (Wojciech Samotij). The School is primarily intended for PhD students and postdocs, but students and researchers in other stages of … <a href="https://cstheory-events.org/2022/02/20/prague-summer-school-on-discrete-mathematics-2/" class="more-link">Continue reading <span class="screen-reader-text">Prague Summer School on Discrete Mathematics</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2022/02/20/prague-summer-school-on-discrete-mathematics-2/"><span class="datestr">at February 20, 2022 08:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/024">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/024">TR22-024 |  Pseudorandomness of Expander Random Walks for Symmetric Functions and Permutation Branching Programs | 

	Louis Golowich, 

	Salil Vadhan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the pseudorandomness of random walks on expander graphs against tests computed by symmetric functions and permutation branching programs. These questions are motivated by applications of expander walks in the coding theory and derandomization literatures. We show that expander walks fool symmetric functions up to a $O(\lambda)$ error in total variation distance. This bound improves upon a line of prior work, which gave bounds that were weaker or applied only in more restricted cases. We extend our analysis to unify it with and strengthen the expander walk Chernoff bound. We then show that expander walks fool permutation branching programs up to a $O(\lambda)$ error in $\ell_2$-distance, and we prove that much tighter bounds hold for programs with a certain structure. We also prove lower bounds to show that our results are tight. To prove our results for symmetric functions, we analyze the Fourier coefficients of the relevant distributions using linear-algebraic techniques. Our analysis for permutation branching programs is likewise linear-algebraic in nature, but also makes use of the recently introduced singular-value approximation notion for matrices (Ahmadinejad et al. 2021).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/024"><span class="datestr">at February 20, 2022 08:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/023">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/023">TR22-023 |  Nisan--Wigderson generators in Proof Complexity: New lower bounds | 

	Erfan Khaniki</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A map $g:\{0,1\}^n\to\{0,1\}^m$ ($m&gt;n$) is a hard proof complexity generator for a proof system $P$ iff for every string $b\in\{0,1\}^m\setminus Rng(g)$, formula $\tau_b(g)$ naturally expressing $b\not\in Rng(g)$ requires superpolynomial size $P$-proofs. One of the well-studied maps in the theory of proof complexity generators is Nisan--Wigderson generator. Razborov (Annals of Mathematics 2015) conjectured that if $A$ is a suitable matrix and $f$ is a $NP\cap CoNP$ function hard-on-average for $P/poly$, then $NW_{f, A}$ is a hard proof complexity generator for Extended Frege.
 In this paper, we prove a form of Razborov's conjecture for $AC^0$-Frege. We show that for any symmetric $NP\cap CoNP$ function $f$ that is exponentially hard for depth two $AC^0$ circuits, $NW_{f,A}$ is a hard proof complexity generator for $AC^0$-Frege in a natural setting. As direct applications of this theorem, we show that:

1. For any $f$ with the specified properties, $\tau_b(NW_{f,A})$ based on a random $b$ and a random matrix $A$ with probability $1-o(1)$ is a tautology and requires superpolynomial (or even exponential) $AC^0$-Frege proofs.

2. Certain formalizations of the principle $f_n\not\in(NP\cap CoNP)/poly$ requires superpolynomial $AC^0$-Frege proofs.
        
These applications relate to two questions that were asked by Krajícek (Cambridge University Press 2019).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/023"><span class="datestr">at February 19, 2022 11:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/022">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/022">TR22-022 |  On Efficient Noncommutative Polynomial Factorization via Higman Linearization | 

	Vikraman Arvind, 

	Pushkar Joglekar</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper we study the problem of efficiently factorizing polynomials in the free noncommutative ring F  of polynomials in noncommuting variables x_1,x_2,…,x_n over the field F. We obtain the following result:

Given a noncommutative arithmetic formula of   size s computing a noncommutative polynomial f in F as input, where F=F_q is a finite field, we give a randomized algorithm that runs in time polynomial in s, n and log q that computes a factorization of the polynomial f as a product f=f_1f_2… f_r, where each f_i is an irreducible polynomial that is output as a noncommutative algebraic branching program. 

The algorithm works by first transforming f into a linear matrix L using Higman's linearization of polynomials. We then factorize the linear matrix L and recover the factorization of the polynomial f. We use basic elements from Cohn's theory of free ideals rings combined with Ronyai's randomized polynomial-time algorithm for computing invariant subspaces of a collection of matrices over finite fields.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/022"><span class="datestr">at February 19, 2022 05:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/021">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/021">TR22-021 |  Improved Pseudorandom Generators for $\mathrm{AC}^0$ Circuits | 

	Xin Lyu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give PRG for depth-$d$, size-$m$ $\mathrm{AC}^0$ circuits with seed length $O(\log^{d-1}(m)\log(m/\varepsilon)\log\log(m))$. Our PRG improves on previous work [TX13, ST19, Kel21] from various aspects. It has optimal dependence on $\frac{1}{\varepsilon}$ and is only one “$\log\log(m)$” away from the lower bound barrier. For the case of $d=2$, the seed length tightly matches the best-known PRG for CNFs [DETT10, Tal17].

There are two technical ingredients behind our new result; both of them might be of independent interest. First, we develop a “partitioning-based” approach to construct PRGs based on restriction lemmas for AC0. Previous works [TX13, ST19, Kel21] usually built PRGs on the Ajtai-Wigderson framework [AW89]. Compared with them, our new approach avoids the extra “$\log(n)$” factor that usually arises from the Ajtai-Wigderson framework, allowing us to get the almost-tight seed length. Our partitioning-based approach is quite general, and we believe it can help design PRGs for classes beyond constant-depth circuits.

Second, improving and extending [TX13, ST19, Kel21], we prove a full derandomization of the powerful multi-switching lemma [Hås14]. We show that one can use a short random seed to sample a restriction, such that a family of DNFs simultaneously simplifies under the restriction with high probability. This answers an open question in [Kel21]. Previous derandomizations were either partial (that is, they pseudorandomly choose variables to restrict, and then fix those variables to truly-random bits) or had sub-optimal seed length. In our application, having a fully-derandomized switching lemma is crucial, and the randomness-efficiency of our derandomization allows us to get an almost-tight seed length.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/021"><span class="datestr">at February 19, 2022 01:50 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2022/02/18/postdoc-at-yale-university-apply-by-march-15-2022/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2022/02/18/postdoc-at-yale-university-apply-by-march-15-2022/">Postdoc at Yale University (apply by March 15, 2022)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Applications are solicited for a postdoctoral position at Yale in Algorithms, Optimization, and Machine Learning. The position is expected to start in Fall 2022. Applicants should have an exceptional mathematical background and a proven track record. They should have their CV, research statement, and three recommendation letters emailed directly to Nisheeth Vishnoi</p>
<p>Website: <a href="https://www.cs.yale.edu/homes/vishnoi/postdoc.html">https://www.cs.yale.edu/homes/vishnoi/postdoc.html</a><br />
Email: nisheeth.vishnoi@gmail.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2022/02/18/postdoc-at-yale-university-apply-by-march-15-2022/"><span class="datestr">at February 18, 2022 07:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3539">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2022/02/18/cfp-scw-special-issue-on-fair-public-decision-making/">CFP: SCW Special Issue on “Fair Public Decision Making”</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>Social Choice and Welfare</strong> will publish a special issue on “Fair Public Decision Making: Allocating budgets, seats, and probability” (<strong>submission deadline: May 1st, 2022</strong>) that will be concerned with <em>apportionment, multi-winner elections, participatory budgeting, donor coordination, probabilistic social choice, sortition, multiple referenda</em>, and related topics. See the <a href="https://www.springer.com/journal/355/updates/19966564">Call for Papers</a>.</p>



<p>Guest editors: Haris Aziz, Felix Brandt, Edith Elkind, Jérôme Lang</p>



<p></p></div>







<p class="date">
by felixbrandt <a href="https://agtb.wordpress.com/2022/02/18/cfp-scw-special-issue-on-fair-public-decision-making/"><span class="datestr">at February 18, 2022 02:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/020">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/020">TR22-020 |  Worst-Case to Average-Case Reductions via Additive Combinatorics | 

	Vahid Reza Asadi, 

	Alexander Golovnev, 

	Tom Gur, 

	Igor Shinkar</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We present a new framework for designing worst-case to average-case reductions. For a large class of problems, it provides an explicit transformation of algorithms running in time $T$ that are only correct on a small (subconstant) fraction of their inputs into algorithms running in time $\widetilde{O}(T)$ that are correct on all inputs. 

Using our framework, we obtain such efficient worst-case to average-case reductions for fundamental problems in a variety of computational models; namely, algorithms for matrix multiplication, streaming algorithms for the online matrix-vector multiplication problem, and static data structures for all linear problems as well as for the multivariate polynomial evaluation problem.

Our techniques crucially rely on additive combinatorics. In particular, we show a local correction lemma that relies on a new probabilistic version of the quasi-polynomial Bogolyubov-Ruzsa lemma.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/020"><span class="datestr">at February 18, 2022 10:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=6397">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/matrix-monotony-and-convexity/">Playing with positive definite matrices – I: matrix monotony and convexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">In a series of a few blog posts, I will present classical and non-classical results on symmetric positive definite matrices. Beyond being mathematically exciting, they arise naturally a lot in machine learning and optimization, as Hessians of twice continuously differentiable convex functions and through kernel methods. In this post, I will focus on the benefits and perils of using the <a href="https://en.wikipedia.org/wiki/Loewner_order">Löwner order</a> between symmetric matrices as a tool for proving inequalities.</p>



<p class="justify-text">I will consider symmetric matrices \(A \in \mathbb{R}^{d \times d}\) of size \(d \times d\), denoting by \(\mathcal{S}_d\) the set all such matrices. There are many characterizations of symmetric positive semi-definite (PSD) matrices: (a) non-negative eigenvalues, (b) \(x^\top A x \geqslant 0\) for all \(x \in \mathbb{R}^d\), or (c) expression as a square as \(A = BB^\top\). Let’s denote this set by \(\mathcal{S}_d^+\).</p>



<p class="justify-text">A very useful tool in matrix analysis is the use of the Löwner order. It is defined as follows on \(\mathcal{S}_d\): $$ A \preccurlyeq B \Leftrightarrow B-A \in \mathcal{S}_d^+.$$ In other words, \(A\) is smaller than \(B\) if and only if \(B\, – A\) is positive semi-definite (PSD). The notation \(B \succcurlyeq A\) is defined as equivalent to \(A \preccurlyeq B\).</p>



<p class="justify-text">This defines a classical <a href="https://en.wikipedia.org/wiki/Order_theory">order relation</a> which is reflexive (\(A \preccurlyeq A\) for all \(A\)), antisymmetric (for all \(A, B \in \mathcal{S}_d\), \(A \preccurlyeq B\) and \(B \preccurlyeq A\) imply \(A=B\)), and transitive (\(A \preccurlyeq B\) and \(B \preccurlyeq C\) imply \(A \preccurlyeq C\)).</p>



<p class="justify-text">Using operations on the Löwner order can make proofs much simpler, but it can also lead to atrocious mistakes. The main reason ends up being the lack of commutativity of the matrix product, that is, <em>in general </em>\(AB \neq BA\).</p>



<p class="justify-text"><strong>Representing positive matrices through ellipsoids.</strong> Any strictly PSD matrix \(A\) defines an ellipsoid $$ \mathcal{E}_A = \big\{ x \in \mathbb{R}^d, \ x^\top A^{-1} x \leqslant 1 \big\}$$ centered at zero. The eigenvectors are the traditional principal axes of the ellipsoid and the eigenvalues the lengths of these axes. See an illustration below with \(d = 2\), and the two eigenvectors \(u_1\) and \(u_2\).</p>



<div class="wp-block-image"><figure class="aligncenter size-full is-resized"><img width="246" alt="" src="https://francisbach.com/wp-content/uploads/2022/02/ellipsoid-1.png" class="wp-image-6580" height="151" /></figure></div>



<p class="justify-text">The key property here is that \(\mathcal{E}_A \subset \mathcal{E}_B\) if and only if \(A \preccurlyeq B\). This representation immediately highlights that the order is partial. See examples below.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="503" alt="" src="https://francisbach.com/wp-content/uploads/2022/02/ellipsoids_notaligned-1024x571.png" class="wp-image-6581" height="280" /></figure></div>



<p class="justify-text">Moreover, if two matrices commute, then they are jointly diagonalizable, that is, the principal axes are aligned, and once expressed in the common eigenbasis, we obtain diagonal matrices, and we then have \({\rm Diag}(\lambda)  \preccurlyeq {\rm Diag}(\mu)\) if and only if for all \(i\), \(\lambda_i \leqslant \mu_i\).</p>



<p class="justify-text">Several good books are available and reading them is both enjoyable and fruitful [1, 4, 10]. Let’s now look at some properties of this Löwner order.</p>



<h2 id="fun-and-useful-facts-and-common-mistakes">Fun (and useful) facts and common mistakes</h2>



<p class="justify-text">Here I list classical properties that are constantly used in proofs using positive matrices. This is crucially used in the analysis of gradient methods for least-squares [<a href="http://proceedings.neurips.cc/paper/2013/file/7fe1f8abaad094e0b5cb1b01d712f708-Paper.pdf">6</a>, <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">7</a>], as well as in analyzing linear dynamical systems, with control or not [<a href="http://web.stanford.edu/~boyd/lmibook/lmibook.pdf">8</a>].</p>



<p class="justify-text"><strong>Direct consequence of the definition.</strong> For any \(d \times n\) matrix \(X\), and \(A,B \in \mathcal{S}_d\) such that \( A \preccurlyeq B\), $$ X^\top A X \preccurlyeq X^\top B X, $$ with the simple proof \(y^\top X^\top A X y = ( X y)^\top A ( X y) \leqslant ( X y)^\top B ( X y)  =  y^\top X^\top B X y \) for all \(y \in \mathbb{R}^n\). </p>



<p class="justify-text">Another similar formulation is $$ A \preccurlyeq B \Rightarrow {\rm tr}(AM) \leqslant {\rm tr} (BM) \mbox{ for all } M \succcurlyeq 0.$$ However this <em>not</em> true if \(M\) is <em>not</em> PSD. In particular, if \(A \preccurlyeq B\) we do <em>not</em> have in general for all \(x, y \in \mathbb{R}^d\), \(x^\top A y \leqslant x^\top B y \), which is a common mistake.</p>



<p class="justify-text">Another consequence, with \(X = B^{\, -1/2}\) the inverse of the square root of \(B\) (assuming that \(B\) is invertible), is \(A \preccurlyeq B \Rightarrow B^{\, -1/2} A B^{\, -1/2} \preccurlyeq I\).</p>



<p class="justify-text"><strong>Schur complements.</strong> A very useful identity is, for any rectangular matrix \(C\): $$ CC^\top \preccurlyeq I \Leftrightarrow  C^\top C \preccurlyeq I.$$ This can be extended to (with matrices of proper sizes): $$ C B^{\, -1} C^\top \preccurlyeq A \Leftrightarrow  C^\top A^{-1} C \preccurlyeq B$$ for PSD invertible matrices \(A, B\), both properties being equivalent to $$ \bigg( \begin{array}{cc} A &amp; C \\ C^\top &amp; B \end{array} \bigg) \succcurlyeq 0.$$ This is the usual characterization of positive-definiteness of block matrices through <a href="https://en.wikipedia.org/wiki/Schur_complement">Schur complements</a>.</p>



<p class="justify-text"><strong>Trace inequalities.</strong> If \(A \succcurlyeq 0 \) and \(B \succcurlyeq 0 \), then we have $$ 0 \leqslant {\rm tr}(AB)  \leqslant {\rm tr(A)} \lambda_{\max}(B) \leqslant {\rm tr(A)} {\rm tr}(B).$$ Moreover, still if  \(A \succcurlyeq 0 \) and \(B \succcurlyeq 0 \), $$ {\rm tr} (AB) \geqslant 0 \mbox{ with equality if and only if } AB=0.$$ This is used a lot in <a href="https://en.wikipedia.org/wiki/Semidefinite_programming">semi-definite programming</a>, in particular for optimality conditions (see [<a href="http://stanford.edu/~boyd/papers/pdf/semidef_prog.pdf">9</a>] for details), and can be shown (for the non-trivial direction) by using an eigenvalue decomposition of \(A\) as \(A = \sum_{i=1}^d \lambda_i u_i u_i^\top\), writing \({\rm tr}(AB) = \sum_{i=1}^d \lambda_i u_i^\top B_i u_i\), which is a sum of non-negative terms and thus if \({\rm tr}(AB)=0\), all terms have to be equal to zero, leading exactly to the result (since \(u^\top B u =0\) is equivalent to \(Bu=0\) when \(B \succcurlyeq 0\)).</p>



<h2 id="matrix-functions">Matrix functions</h2>



<p class="justify-text">One particularly elegant and efficient way of using symmetric matrices is through matrix functions. Some are based on classical linear algebra such as the matrix inverse \(A^{\, -1}\), the matrix square root \(A^{1/2}\), or any polynomial or rational functions. Many others are defined as spectral functions. That is, given a function \(f:I \to \mathbb{R}\), defined on some interval \(I\) we can define for any symmetric matrix latex \(A \in \mathbb{S}_d\) with eigenvalue decomposition \(A = \sum_{i=1}^d \lambda_i u_i u_i^\top\), and all eigenvalues in \(I\): $$f(A) = \sum_{i=1}^d f(\lambda_i) u_i u_i^\top.$$</p>



<p class="justify-text">We get the usual definition of matrix powers \(A^p\), inverse \(A^{-1}\), but also logarithm \(\log A\) for PSD matrices, exponential \(\exp(A)\), etc. When the matrix is diagonal, then we apply the function on diagonal elements $$f({\rm Diag}(\lambda)) = {\rm Diag}(f(\lambda)).$$</p>



<p class="justify-text">For real numbers, a function \(f\) is non-decreasing if and only if for all \(\lambda,\mu\), $$ \lambda \leqslant \mu \Rightarrow f(\lambda) \leqslant f(\mu).$$ When \(f\) is non-decreasing, then for \(d=1\), we do have \(f(A)  \preccurlyeq  f(B)\) as soon as \(A \preccurlyeq B\). Moreover, when \(A\) and \(B\) commute, then can be <a href="https://kconrad.math.uconn.edu/blurbs/linmultialg/minpolyandappns.pdf">jointly diagonalized</a>, and then the property above is true for all non-decreasing functions. This is the same if we just want \({\rm tr} [ f(A) ] \leqslant {\rm tr}[f(B)]\).</p>



<p class="justify-text">When does it extend to \(d&gt;1\), beyond taking the trace, and for non-commuting matrices? Functions for which $$ \forall A, B \in \mathcal{S}_d, \  A \preccurlyeq B \Rightarrow  f(A) \preccurlyeq f(B)$$ for all dimensions \(d\) are called <em>matrix-monotone</em>. Let us start with a few positive examples with simple direct proofs.</p>



<p class="justify-text"><strong>Matrix inverse.</strong> If \( A \preccurlyeq B\) and \(A\)  is invertible, then, \(B\) is invertible, and \(B^{\, -1/2} A B^{\, -1/2} \preccurlyeq I\), which is equivalent to \((A^{1/2} B^{\, -1/2})^\top A^{1/2} B^{\, -1/2} \preccurlyeq I\) and thus \(A^{1/2} B^{\, -1} A^{1/2} = A^{1/2} B^{\, -1/2} (A^{1/2} B^{\, -1/2})^\top  \preccurlyeq I\), and then \(A^{\:\! -1} \succcurlyeq B^{\, -1} \). The function \(\lambda \mapsto -\lambda^{-1}\) is thus matrix-monotone.</p>



<p class="justify-text"><strong>Matrix square root.</strong> From the paragraph above, if \( A \preccurlyeq B\) and \(A\)  is invertible, then \(\|A^{1/2} B^{\, -1/2} \|_{\rm op} \leqslant 1\), thus all (potentially complex) eigenvalues of \(A^{1/2} B^{\, -1/2}\) have magnitude less than one, and thus this is the same for all eigenvalues of the <a href="https://en.wikipedia.org/wiki/Matrix_similarity">similar</a> matrix \(B^{\, -1/4} ( A^{1/2} B^{\, -1/2} ) B^{1/4}= B^{\, -1/4}   A^{1/2} B^{\, -1/4}\), which finally implies \(B^{\, -1/4}   A^{1/2} B^{\, -1/4} \preccurlyeq  I\), and thus \(A^{1/2} \preccurlyeq B^{1/2}\). The function \(\lambda \mapsto \lambda^{1/2}\) is thus matrix-monotone.</p>



<p class="justify-text"><strong>Matrix square.</strong> “Unfortunately” \(A \succcurlyeq B \succcurlyeq 0\) does not imply \(A^2 \succcurlyeq B^2\). This is a very common mistake! (I have made it at several occasions). </p>



<p class="justify-text">In fact, this is rarely true, indeed, if \(B = A + \Delta\), we have \(B^2 – A^2 = \Delta^2 + A \Delta + \Delta A,\) and as soon as the column space of \(\Delta\) does not contain the one of \(A\), the equality between squares is impossible. See an illustration below in two dimensions.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="298" alt="" src="https://francisbach.com/wp-content/uploads/2022/02/ellipsoid-1.gif" class="wp-image-6602" height="294" />For  \(A = \frac{1}{5} \Big(\begin{array}{cc}\!  2 \! \!&amp;  \! \! 1 \! \\[-.25cm] \! 1\!\! &amp;\!\! 1 \!\end{array} \Big)\) and \(B = \frac{1}{5} \Big(\begin{array}{cc} \! 4 \!\!&amp; \!\! 1 \! \\[-.25cm] \! 1 \! \!&amp; \! \! 1 \! \end{array} \Big)\) which are such that \(0 \preccurlyeq A \preccurlyeq B\), represented by their ellipsoid, we represent \(A^p\) and \(B^p\) for various powers \(p \in [0,4]\). We have \(A^p \preccurlyeq B^p\) only for \(p \in [0,1]\).</figure></div>



<p class="justify-text">Luckily, as mentioned by my colleague <a href="https://www.di.ens.fr/~rudi/">Alessandro Rudi</a>, for any incorrect matrix inequality, there is a close by true inequality. Here, for example, we have that \(A \succcurlyeq  B \succcurlyeq 0\) does imply \({\rm tr}(A^2) \geqslant {\rm tr}(B^2)\) (as can be seen by from the positivity of the trace of products of PSD matrices). Moreover, there are the so-called <em>Furuta</em> <em>inequalities</em>, (see Corollary 1.18 in [4]): $$ A \succcurlyeq B \succcurlyeq 0 \Rightarrow A^2 \succcurlyeq ( AB^2A)^{1/2} \mbox{ and } (BA^2B)^{1/2} \succcurlyeq B^2, $$ which can prove useful.</p>



<p class="justify-text"><strong>Towards a characterization of matrix-monotone functions.</strong> We have seen that \(\lambda \mapsto \lambda^2\) is not matrix-monotone, while \(\lambda \mapsto \lambda^{1/2}\) and \(\lambda \mapsto -1/\lambda\) are. So what functions are matrix monotone? It turns out that there is a general answer, which is an amazing result from Löwner: he gives a precise characterization of matrix-monotone functions [<a href="http://gdz.sub.uni-goettingen.de/id/PPN266833020_0038?tify={">2</a>], with a whole book [3] about it with 11 different proofs!</p>



<h2 id="positivity-of-lowner-matrices">Positivity of Löwner matrices</h2>



<p class="justify-text">We start with a first characterization that will please the kernel enthusiasts. The question here is as follows. Given a differentiable function \(f: I \to \mathbb{R}\), and \(n\) real numbers \(\lambda_1,\dots,\lambda_n \in I\) the domain of \(f\), when is the \(n \times n\) matrix \(L\) with values $$L_{ij} = \frac{f(\lambda_i)-f(\lambda_j)}{\lambda_i – \lambda_j} \mbox{ for } i \neq j,$$ and \(L_{ii} = f'(\lambda_i)\), always positive semi-definite? These matrices are called Löwner matrices and it turns out that the differentiable functions \(f\) for which all Löwner matrices are PSD are exactly the matrix-monotone functions.</p>



<p class="justify-text">To see this, we simply need to compute the derivative at \(t=0\) of the matrix-valued function \(g: [0,1] \to \mathcal{S}_d\) defined as  $$g(t) =  f(A + t(B-A)).$$ Using a former <a href="https://francisbach.com/cauchy-residue-formula/">blog post</a>, we have with the eigenvalue decomposition \(A=\sum_{i=1}^d \! \lambda_i u_i u_i^\top\), $$g'(0) = \sum_{i,j=1}^d \frac{f(\lambda_i)-f(\lambda_j)}{\lambda_i – \lambda_j} u_i^\top (B-A)u_j,$$ with the convention that for \(i=j\), \(\frac{f(\lambda_i)-f(\lambda_j)}{\lambda_i – \lambda_j}  = f'(\lambda_i)\). Therefore, \(g'(0) = \sum_{i,j=1}^d L_{ij}  u_i^\top (B-A)u_j\).</p>



<p class="justify-text">Thus, if \(f\) is matrix-monotone, we have \(g'(0) \geqslant 0\), and by choosing \(A = {\rm Diag}(\lambda)\) diagonal and \(B\, – A = zz^\top\) rank-one, we get \(g'(0) = \sum_{i,j=1}^d L_{ij}  z_i z_j \geqslant 0\), which leads to the positivity of \(L\) since this is true for any vector \(z \in \mathbb{R}^n\).</p>



<p class="justify-text">In the other direction, if \(L \succcurlyeq 0\) all Löwner matrices are PSD, then as soon as \(B-A \succcurlyeq 0\), we can then get with a similar reasoning \(g'(t) \geqslant 0\) for \(t \in [0,1]\), and thus \(f(B) = g(1) \geqslant g(0) = f(A)\), which shows monotonicity.</p>



<p class="justify-text">Note that, like all generic results on positive-definiteness of matrices (like <a href="https://en.wikipedia.org/wiki/Bochner%27s_theorem">Bochner theorem</a>), this is an infinite source of “<a href="https://fr.wikipedia.org/wiki/Colle_(pr%C3%A9pa)">problèmes de colle</a>” (oral mathematical exams which are common in France).</p>



<h2 id="characterizing-all-matrix-monotone-functions">Characterizing all matrix-monotone functions</h2>



<p class="justify-text">There are many different characterizations of matrix monotonicity (see [3]). I will only mention a simple intuitive result for \(I = (0,+\infty)\), with a sketch of a particularly elegant proof coming from [<a href="http://arxiv.org/pdf/1112.0098.pdf">5</a>].</p>



<p class="justify-text"><strong>A family of non-negative monotone functions.</strong> As seen above, the function \(\lambda \mapsto -1/\lambda\) is matrix-monotone on \(\mathbb{R}_+^\ast\). So is \(\lambda \mapsto \frac{\lambda}{(1-t)\lambda+t}\) for any \(t \in [0,1]\). Moreover, for all \(t \in [0,1]\), these functions are non-negative on \(\mathbb{R}_+^\ast\) and the value at 1 is 1. Note that with \(t=1\), we recover \(\lambda \mapsto \lambda\), while for \(t=0\), we recover \(\lambda \mapsto 1\). </p>



<p class="justify-text">Since matrix-monotonicity is a property which is invariant by taking convex combinations of functions, all functions of the form $$ \lambda \mapsto \int_{0}^{1}\frac{\lambda}{(1-t)\lambda+t}d\mu(t)$$ for a probability measure \(\mu\) on \([ 0 , 1 ]\), are also matrix-monotone, non-negative and with value 1 at 1. It turns out we cover them all! The argument is based on showing that the functions \(\lambda \mapsto \frac{\lambda}{(1-t)\lambda+t}\) are the extreme points of the of functions defined above. See details in [<a href="http://arxiv.org/pdf/1112.0098.pdf">5</a>].</p>



<p class="justify-text">We can then recover all matrix-monotone functions on \( (0,+\infty)\) by adding a constant and letting the mass of \(\mu\) be different from one (and potentially infinite). By making the change of variable \(u = t / (1-t)\), we get the representation as $$f(\lambda) = \alpha + \beta (\lambda-1) + (\lambda-1) \int_0^\infty \!\!\frac{ 1  }{\lambda + u} d\nu(u)$$ for some positive measure \(\nu\) and \(\beta&gt;0\). For example, we have: $$ \log \lambda = (\lambda-1) \int_0^{+\infty} \!\!\frac{1}{\lambda +u} \frac{du}{1+u},$$ and for \(p \in (0,1]\), $$ \lambda^p = 1 + (\lambda-1) \frac{ \sin p \pi}{\pi} \int_0^{+\infty} \!\!\frac{1}{\lambda+u} u^{p-1} du,$$ showing the matrix-monotonicity of the logarithm and of certain powers. Note that the exponential function is <em>not</em> matrix-monotone, and that the only powers \(p \neq 0\) such that \(\lambda \mapsto \lambda^p\) or \(\lambda \mapsto -\lambda^p\) are matrix-monotone are \(p \in (0,1]\) and \(p \in [-1, 0)\).</p>



<h2 id="matrix-convex-functions">Matrix-convex functions</h2>



<p class="justify-text">Similarly to matrix-monotone functions, matrix-convex functions are functions for which $$ \forall A, B \in \mathcal{S}_d, \forall \lambda \in [0,1], \ f( \lambda A + (1-\lambda) B) \preccurlyeq \lambda f(A) + ( 1-\lambda) f(B).$$ Like for real-valued functions, there is an intimate link between monotonicity and convexity here. Indeed, one can show that \(f\) is matrix-convex on the interval \(I\) if and only if for all \(\mu \in I\), the function \(\lambda \mapsto \frac{f(\lambda)-f(\mu)}{\lambda-\mu}\) is matrix-monotone (this is one of these cases where a natural property extends to the matrix case). Using similar arguments than for matrix-monotone functions, all functions of the form $$f(\lambda) = \gamma + \alpha (\lambda-1) + \beta (\lambda-1)^2 + (\lambda-1)^2 \int_0^\infty \!\!\frac{ 1  }{\lambda + u} d\nu(u)$$ for some positive measure \(\nu\) on \([0,+\infty)\) with finite mass, and \(\beta&gt;0\) are matrix-convex on \((0,\infty)\). They also happen to be the only ones (see, e.g., [<a href="http://arxiv.org/pdf/math-ph/9808016">11</a>]). </p>



<p class="justify-text">The classical examples are then \(f(\lambda) = \, – \log \lambda\), \(f(\lambda) = \lambda \log \lambda\), \(f(\lambda) = \lambda^p\) for \(p \in [1,2]\) and \(p \in [-1,0)\).</p>



<p class="justify-text">Note that like for monotonicity, if we just want the <em>real-valued</em> function \(A \mapsto {\rm tr} [ f(A)]\) to be convex, this is equivalent to \(f\) being convex.</p>



<p class="justify-text"><strong>Beyond spectral functions. </strong>There are many nice matrix convex functions beyond spectral functions: for example (see [<a href="http://sciencedirect.com/science/article/pii/0024379579901794/pdf?md5=45d3cff8e7f727933ea9aef11cae997c&amp;pid=1-s2.0-0024379579901794-main.pdf">12</a>]) \(A \mapsto A^{-1} \) or \(A \mapsto A^2 \). Among ones that come up naturally: $$ (A,B) \mapsto A B^{\, -1} A$$ $$ (A,B) \mapsto\  – (A^{-1} + B^{\, -1})^{-1} $$ $$ (A,B) \mapsto\  – A^{1/2} ( A^{-1/2}  B A^{-1/2} )^{1/2} A^{1/2} .$$ Add your favorite one!</p>



<h2 id="conclusion">Conclusion</h2>



<p class="justify-text">Next months, we will see applications of matrix monotonicity and convexity, from sharp concentration inequalities for eigenvalues of random matrices [<a href="https://arxiv.org/pdf/1501.01571">13</a>] to a brand new mix of (quantum) information theory and kernels methods [<a href="https://arxiv.org/pdf/2202.08545.pdf">14</a>].<br /><br /><strong>Acknowledgements</strong>. I would like to thank Alessandro Rudi for fruitful discussions, and Loucas Pillaud-Vivien for proofreading this blog post and making good clarifying suggestions.</p>



<h2 id="references">References</h2>



<p class="justify-text">[1] Rajendra Bhatia. <em><a href="http://www.cmat.edu.uy/~lessa/tesis/Positive%20Definite%20Matrices.pdf">Positive Definite Matrices</a></em>. Princeton University Press, 2009.<br />[2] Karl T. Löwner. <a href="https://gdz.sub.uni-goettingen.de/id/PPN266833020_0038?tify=%7B%22view%22:%22info%22,%22pages%22:%5B183%5D%7D">Über monotone Matrixfunktionen</a>. <em>Mathematische Zeitschrift</em>, 38:177-216, 1934.<br />[3] Barry Simon.<em> <a href="https://www.ams.org/journals/bull/2020-57-04/S0273-0979-2019-01688-7/S0273-0979-2019-01688-7.pdf">Löwner’s Theorem on Monotone Matrix Functions</a></em>. Springer, 2019.<br />[4] Xingzhi Zhan. <em>Matrix inequalities</em>. Springer Science &amp; Business Media, 2002.<br />[5] Frank Hansen. <a href="https://arxiv.org/pdf/1112.0098.pdf">The fast track to Löwner’s theorem</a>. <em>Linear Algebra and its Applications</em> 438.11: 4557-4571, 2013.<br />[6] Francis Bach and Eric Moulines. <a href="https://proceedings.neurips.cc/paper/2013/file/7fe1f8abaad094e0b5cb1b01d712f708-Paper.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate \(O(1/n)\)</a>. <em>Advances in Neural Information Processing Systems</em> 26, 2013.<br />[7] Aymeric Dieuleveut, Nicolas Flammarion, and Francis Bach. <a href="http://jmlr.org/papers/volume18/16-335/16-335.pdf">Harder, Better, Faster, Stronger Convergence Rates for Least-Squares Regression</a>. <em>Journal of Machine Learning Research</em>, 18(101):1−51, 2017.<br />[8] Stephen Boyd, Laurent El Ghaoui, Eric Feron, and Venkataramanan Balakrishna.<em> <a href="https://web.stanford.edu/~boyd/lmibook/lmibook.pdf">Linear Matrix Inequalities in System and Control Theory</a></em>. SIAM, 1994.<br />[9] Lieven Vandenberghe, Stephen Boyd. <a href="https://stanford.edu/~boyd/papers/pdf/semidef_prog.pdf">Semidefinite Programming</a>. <em>SIAM Review</em>, 38:49–95.<br />[10] Rajendra Bhatia. <em>Matrix analysis</em>. Springer Science &amp; Business Media, 2013.<br />[11] Andrew Lesniewski and Mary Beth Ruskai. <a href="https://arxiv.org/pdf/math-ph/9808016">Monotone Riemannian metrics and relative entropy on noncommutative probability spaces</a>. Journal of Mathematical Physics, 40(11):5702–5724, 1999.<br />[12] Tsuyoshi Ando. <a href="https://www.sciencedirect.com/science/article/pii/0024379579901794/pdf?md5=45d3cff8e7f727933ea9aef11cae997c&amp;pid=1-s2.0-0024379579901794-main.pdf">Concavity of certain maps on positive definite matrices and applications to Hadamard products</a>. <em>Linear algebra and its applications</em>, 26: 203-241, 1979.<br />[13] Joel A. Tropp. <a href="https://arxiv.org/pdf/1501.01571">An introduction to matrix concentration inequalities</a>. <em>Foundations and Trends in Machine Learning</em>, 8(1-2):1–230, 2015.<br />[14] Francis Bach. <a href="https://arxiv.org/pdf/2202.08545.pdf">Information Theory with Kernel Methods</a>. Technical Report, arXiv-2202.08545, 2022.<br /></p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/matrix-monotony-and-convexity/"><span class="datestr">at February 17, 2022 08:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/019">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/019">TR22-019 |  Simulation Methods in Communication Lower Bounds, Revisited | 

	Guangxu Yang, 

	Jiapeng Zhang</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The notion of lifting theorems is a generic method to lift hardness of one-party functions to two-party lower bounds in communication model. It has many applications in different areas such as proof complexity, game theory, combinatorial optimization. Among many lifting results, a central idea is called Raz-McKenize simulation (FOCS 1997). This simulation provides a systematic way to convert a communication protocol into a corresponding decision tree. Though it is very convenient in many applications, there are still some challenges in this framework. A major problem is that Raz-McKenize simulation requires a very large gadget.

In this paper, we revise Raz-McKenzie simulation. We introduce a white-box simulation, proving lifting theorems for block sensitivity with constant-size gadgets. Concretely, we show there is a constant-size gadget $g$ such that for any Boolean function $f$, the corruption bound of $f\circ g^n$ is lower bounded by $\Omega(\mathrm{bs}(f))$. Combined with a result of Beame et al. (CCC 2005), this implies the randomized communication complexity of $f\circ g^n$ is lower bounded by $\Omega(\mathrm{bs}(f))$. Besides the result itself, we believe our simulation technique may have more applications in diverse areas. We also discuss why our simulation method has a potential to avoid the large-size gadget bottleneck in Raz-McKenzie simulation.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/019"><span class="datestr">at February 17, 2022 09:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/018">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/018">TR22-018 |  Further Collapses in TFNP | 

	Mika Göös, 

	Alexandros Hollender, 

	Siddhartha Jain, 

	Gilbert Maystre, 

	William Pires, 

	Robert Robere, 

	Ran Tao</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show $\text{EOPL}=\text{PLS}\cap\text{PPAD}$. Here the class $\text{EOPL}$ consists of all total search problems that reduce to the End-of-Potential-Line problem, which was introduced in the works by Hubacek and Yogev (SICOMP 2020) and Fearnley et al. (JCSS 2020). In particular, our result yields a new simpler proof of the breakthrough collapse $\text{CLS}=\text{PLS}\cap\text{PPAD}$ by Fearnley et al. (STOC 2021). We also prove a companion result $\text{SOPL}=\text{PLS}\cap\text{PPADS}$, where $\text{SOPL}$ is the class associated with the Sink-of-Potential-Line problem.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/018"><span class="datestr">at February 15, 2022 10:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2022/02/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2022/02/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://www.youtube.com/watch?v=Vf1m2L2rhkQ">Relevant points for nearest-neighbor classification</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107727015706308147">\(\mathbb{M}\)</a>).</span> The 48-minute extended remix of my SOSA talk, from the New York computational geometry seminar, somehow still going strong decades after I first started attending it in the late 1980s.</p>
  </li>
  <li>
    <p>The journal I recently co-founded, <a href="https://www.cgt-journal.org/index.php/cgt"><em>Computing in Geometry and Topology</em></a>, has published its first paper! It’s “<a href="https://www.cgt-journal.org/index.php/cgt/article/view/4">On the pathwidth of hyperbolic 3-manifolds</a>” by Kristóf Huszár <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107729561681398073">\(\mathbb{M}\)</a>).</span> Hyperbolic 3-manifolds were known to have triangulations of treewidth linear in their hyperbolic volume — the paper improves this to pathwidth. Having small pathwidth, in turn, simplifies certain dynamic programming computations over tree decompositions of the triangulation.</p>
  </li>
  <li>
    <p><a href="https://conwaylife.com/book/"><em>Conway’s Game of Life: Mathematics and Construction</em></a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107738145296241309">\(\mathbb{M}\)</a>).</span> Free online book by Nathaniel Johnston and Dave Greene detailing the engineering behind some of the most complex patterns in Life including universal computers, large variable-speed spaceships and replicators, and metacells that can emulate any other 2d cellular automaton.</p>
  </li>
  <li>
    <p><a href="https://jaydaigle.net/blog/replication-crisis-math/">Why isn’t there a replication crisis in math</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107746496400902945">\(\mathbb{M}\)</a></span>, <a href="https://news.ycombinator.com/item?id=30181696">via</a>)? It’s not like there’s any shortage of papers with incorrect proofs in them; the bigger mystery is why, much of the time, the broken proofs turn out to be fixable.</p>
  </li>
  <li>
    <p><a href="https://doctorow.medium.com/a-bug-in-early-creative-commons-licenses-has-enabled-a-new-breed-of-superpredator-5f6360713299">A bug in the old version-2 Creative Commons licenses spawns a new breed of copyright troll</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107750081780995135">\(\mathbb{M}\)</a></span>, <a href="https://www.metafilter.com/194192/CC-will-have-them-quaking-in-their-boots">via</a>): seed the open web with CC2-licensed stock photography and the like, wait for unsuspecting people to use it without exactly following the proper format of attribution, sue. Cory Doctorow describes being threatened for using one of these images despite attributing it correctly. See also a <a href="https://doctorow.medium.com/an-open-letter-to-pixsy-ceo-kain-jones-who-keeps-sending-me-legal-threats-5dfc54558f2c">later followup from Doctorow</a>.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@christianp/107744005909936952">Christian Lawson-Perfect asks for names for the glyph you use to depict holes in tori</a>. Suggestions include donut hole, hologram, omphalos, and some made-up words. Incidentally, trying to re-create it as the image below ran into a bizarre Adobe Illustrator bug where saving an intersection of two circles in svg turned it into an ellipse; instead, I had to keep the top and bottom arcs as separate objects.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/omphalos.svg" alt="The hole in a torus" /></p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/an-ancient-geometry-problem-falls-to-new-mathematical-techniques-20220208/">Squaring the circle, by cutting a square into fractal pieces and reassembling them into a circle</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107763584211385922">\(\mathbb{M}\)</a>).</span> The original paper, “<a href="https://arxiv.org/abs/2202.01412">Circle squaring with pieces of small boundary and low Borel complexity</a>” by András Máthé, Jonathan A. Noel, and Oleg Pikhurko, is very technical, but the main improvement on earlier work in the same line of research is that now the pieces all have positive measure and their boundaries have dimension less than two. The pretty animation at the start of the <em>Quanta</em> link is a little misleading, though: the number of pieces is huge, around \(10^{200}\).</p>
  </li>
  <li>
    <p>I made a project of illustrating an Erdős–Rényi–Gilbert random graph in which the <a href="https://en.wikipedia.org/wiki/Giant_component">giant component</a> (or at least, a large component) is clearly visible <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107766972074585140">\(\mathbb{M}\)</a>).</span> Used <a href="https://arxiv.org/abs/1209.0748">social gravity</a> to get the component centered and separated from everything else. Came out reasonably well, I think.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/ERG1000.svg" alt="Random graph on 1000 vertices at the critical edge probability, showing a large component" /></p>
  </li>
  <li>
    <p><a href="https://ar5iv.org">Ar5iv, a project for automatically converting most arXiv preprints (the ones with LaTeX source) into html</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107772439338813071">\(\mathbb{M}\)</a></span>, <a href="https://www.metafilter.com/194267/LaTeX-to-HTML5-at-scale">via</a>). Too bad about the not-up-to-TeX-quality math formula formatting, though. They’re using mathml instead of MathJax, and it shows. For instance, when I view formulas like \(O\bigl(n^{4/3+\varepsilon}+k^{5/3}n^{2/3}\log^{O(1)}n\bigr)\) (from <a href="https://arxiv.org/abs/2110.06163">one of my recent papers</a>) in Firefox, the exponents get at least two inconsistent baselines, maybe four. Fortunately, CLP has a <a href="https://checkmyworking.com/misc/mathjax-bookmarklet/">MathJaxification bookmarklet</a> that can make things better…</p>
  </li>
  <li>
    <p>The lists of accepted papers are now up at the web sites for the <a href="https://www.inf.fu-berlin.de/inst/ag-ti/socg22/socg.html">2022 Symposium on Computational Geometry</a> and <a href="https://eurocg2022.unipg.it/accepted-papers.html">European Workshop on Computational Geometry</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107783558042391525">\(\mathbb{M}\)</a>).</span></p>
  </li>
  <li>
    <p><a href="https://blog.plover.com/math/finding-factors.html">Factoring composite numbers into nearly equal factors</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@mjd/107747910032997935">\(\mathbb{M}\)</a>)</span> turns out to be complete for \(\mathsf{NP}\) under randomized reductions, or properly <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete</span> if the gaps between prime numbers are small enough to allow a deterministic reduction from the subset sum problem to go through.</p>
  </li>
  <li>
    <p><a href="https://terrytao.wordpress.com/2022/02/08/perfectly-packing-a-square-by-squares-of-nearly-harmonic-sidelength/">Perfectly packing a square by squares of nearly harmonic sidelength</a> <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107800881701660495">\(\mathbb{M}\)</a>).</span> Terry Tao attacks an old question of whether inverse-integer squares pack into a single square of area \(\zeta(2)=\pi^2/6\), showing that squares of sides <span style="white-space: nowrap;">1/integer\({}^{1+\varepsilon}\)</span> do pack. A key insight: the high perimeter of not-yet-packed squares is an obstacle, but can be controlled by grouping squares into rough grids before packing. (This is why the epsilon is needed: perimeter diverges without it.)</p>
  </li>
  <li>
    <p>What do you get when you combine an indigenous Australian painting aesthetic with vaguely-Kabbalistic astronomical charts and geometric diagrams <span style="white-space: nowrap;">(<a href="https://mathstodon.xyz/@11011110/107805270173949870">\(\mathbb{M}\)</a>)?</span> Answer: <a href="https://www.thisiscolossal.com/2020/03/shane-drinkwater-astronomical-maps/">the art</a> of <a href="https://www.thisiscolossal.com/2022/01/shane-drinkwater-paintings/">Shane Drinkwater</a>.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2022/02/15/linkage.html"><span class="datestr">at February 15, 2022 06:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2022/017">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2022/017">TR22-017 |  Collision-Resistance from Multi-Collision-Resistance | 

	Prashant Nalini Vasudevan, 

	Ron D. Rothblum</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Collision-resistant hash functions (CRH) are a fundamental and ubiquitous cryptographic primitive. Several recent works have studied a relaxation of CRH called t-way multi-collision-resistant hash functions (t-MCRH). These are families of functions for which it is computationally hard to find a t-way collision, even though such collisions are abundant (and even (t-1)-way collisions may be easy to find). The case of t=2 corresponds to standard CRH, but it is natural to study t-MCRH for larger values of t.

Multi-collision-resistance seems to be a qualitatively weaker property than standard collision-resistance. In particular, Komargodski et al. (Eurocrypt, 2018) showed that there does not exist a blackbox transformation of MCRH into CRH. Nevertheless, in this work we show a non-blackbox transformation of any moderately shrinking t-MCRH, for t in {3,4}, into an (infinitely often secure) CRH. This transformation is non-constructive - we can prove the existence of a CRH but cannot explicitly point out a construction.

Our result partially extends to larger values of t. In particular, we show that for suitable values of t&gt;t', we can transform a t-MCRH into a t'-MCRH, at the cost of reducing the shrinkage of the resulting hash function family and settling for infinitely often security. This result utilizes the list-decodability properties of Reed-Solomon codes.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2022/017"><span class="datestr">at February 15, 2022 03:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8907273297572905957">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html">Belated happy 80th, Allan Borodin!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><i></i></p><div style="clear: both; text-align: center;" class="separator"><div style="clear: both; text-align: center;" class="separator"><a style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;" href="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg"><img src="https://www.fields.utoronto.ca/programs/scientific/00-01/borodin/image.jpg" border="0" width="213" height="320" /></a></div><i style="text-align: left;">Guest Post by Aravind Srinivasan</i><span style="text-align: left;"> </span></div><p></p><p><a href="https://en.wikipedia.org/wiki/Allan_Borodin">Allan Borodin</a> turned 80 in 2021. This post is to belatedly wish him a very happy 80th, and to give a short personal perspective. </p><p>Three things come to mind when I think of Allan:</p><p></p><ol style="text-align: left;"><li>His range of research topics: I was first exposed to his work (Borodin's Gap Theorem) in a complexity-theory class by Hartmanis in Spring 1990, and have since enjoyed reading---at varying levels of depth---his works on algebraic complexity, space complexity and tradeoffs, circuit complexity, lower bounds in general, routing, adversarial queuing, online algorithms, priority algorithms, and E-commerce (I am surely leaving out some areas). This is an amazingly broad sweep!</li><li>His enthusiasm in learning about and developing new models, as our field has evolved greatly over time.</li><li>The enthusiastic embrace he has given to researchers spanning generations. Indeed, I am one of many who have been inspired by various facets of his research and personality.</li></ol><p></p><p>Photos from Allan’s 60th can be seen at <a href="http://www.cs.toronto.edu/~bor/birthday/index.htm">Amos Fiat’s page</a>.</p><p>Thank you for everything Allan, and wishing you continued robust health and enjoyment of your academic work! </p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="http://blog.computationalcomplexity.org/2022/02/belated-happy-80th-allan-borodin.html"><span class="datestr">at February 14, 2022 01:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids.html">Triangulation thickens grids</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>If you zigzag back and forth through the columns (or rows) of an ordinary two-dimensional grid graph, following a pattern dignified with the fancy name “<a href="https://en.wikipedia.org/wiki/Boustrophedon">boustrophedon</a>”, you get a one-dimensional ordering of the vertices that can be used as the basis of a nice planar <a href="https://en.wikipedia.org/wiki/Arc_diagram">arc diagram</a> of this graph.</p>

<p style="text-align: center;"><img width="80%" alt="Boustrophedon layout of a 2d grid" src="https://11011110.github.io/blog/assets/2022/boustrophedon.svg" /></p>

<p>The same idea works in 3d. You can divide a 3d grid graph into 2d layers, zigzag within each layer, and then reverse the same zigzagging order in alternating layers, to get another nice one-dimensional ordering of the vertices. It doesn’t give a planar drawing (this graph is not planar), but it does allow it to be drawn without crossings on the four half-planes of a four-page <a href="https://en.wikipedia.org/wiki/Book_embedding">book embedding</a>. More generally, any \(d\)-dimensional grid graph can be drawn in the same way as a book embedding with \(2(d-1)\) pages.</p>

<p style="text-align: center;"><img width="80%" alt="Double boustrophedon layout of a 3d grid" src="https://11011110.github.io/blog/assets/2022/double-boustrophedon.svg" /></p>

<p>I’m a coauthor on a new preprint showing that this one-dimensional layout is very sensitive to the way you connect nearby vertices in the 3d grid. If you modify the grid just a little bit, triangulating it by adding a diagonal to each grid square, then the resulting graph no longer has a book embedding with a constant number of pages. Instead, for a triangulated \(n\times n\times n\) grid, \(\Theta(n^{1/3})\) pages are necessary (and sufficient). The preprint is “Three-dimensional graph products with unbounded stack-number”, with Robert Hickingbotham, Laura Merker, Sergey Norin, Michał T. Seweryn, and David R. Wood, <a href="https://arxiv.org/abs/2202.05327">arXiv:2202.05327</a>; the long coauthor list is because it comes from a collaboration that began at the Banff workshop on Graph Product Structure Theory last November.</p>

<p>There are many other related results packed into the same preprint, but rather than summarizing them all I’d rather take a step back and look at the big picture. The result that triangulated grids have high book thickness turns out to follow from a sequence of connections that is closely analogous to results about the high width of 2d grids, and I think the analogies between these connections are very interesting. For 2d grids:</p>

<ul>
  <li>
    <p>Two standard measures of one-dimensionality of graphs are <a href="https://en.wikipedia.org/wiki/Cutwidth">cutwidth</a> and <a href="https://en.wikipedia.org/wiki/Pathwidth">pathwidth</a>. Both can be defined in terms of continuous maps from the graph (considered as a one-dimensional topological space) to a line. A graph has cutwidth at most \(c\) if it has a map in which every point of the line belongs to the images of at most \(c\) edges, and pathwidth at most \(p\) if it has a map in which every point of the line belongs to the images of edges that have at most \(p\) distinct vertices as their left endpoints.</p>
  </li>
  <li>
    <p>For a graph of maximum degree \(d\), at most \(d\) edges can share a left endpoint, so if the graph has cutwidth \(c\) it has pathwidth at least \(c/d\).</p>
  </li>
  <li>
    <p>A complete graph with \(n\) vertices and \(\tbinom{n}{2}\) edges, mapped continuously to a line, always has a point covered by \(\Omega(n^2)\) edges, at the median vertex of the mapping.</p>
  </li>
  <li>
    <p>For a 2d grid graph, we can associate each vertex with a subgraph consisting of the union of the row and column of the grid containing that vertex.</p>

    <p style="text-align: center;"><img width="50%" alt="Bramble associating each grid vertex with the union of its row and column" src="https://11011110.github.io/blog/assets/2022/grid-bramble.svg" /></p>

    <p>This family of subgraphs is a <a href="https://en.wikipedia.org/wiki/Bramble_(graph_theory)">bramble</a>, meaning that all of the subgraphs are connected and touch each other. In this case, they all touch at shared vertices, but brambles also allow subgraphs to touch across edges. In the bramble for an \(n\times n\) grid graph, each graph vertex or edge belongs to \(O(n)\) subgraphs.</p>
  </li>
  <li>
    <p>We can map \(K_{n^2}\) continuously onto the grid, vertex-to-vertex, by mapping each edge of \(K_{n^2}\) onto a path through the two touching subgraphs for its endpoints. This map has low congestion: each grid vertex or edge is in the image of \(O(n)\) vertices or edges of \(K_{n^2}\).</p>
  </li>
  <li>
    <p>Any map of the grid to a line can be composed with the map from \(K_{n^2}\) to the grid, giving a map of \(K_{n^2}\) onto the line. Because of the low congestion of the map to the grid, a point of the line that is covered by \(\Omega(n^2)\) edges of the complete graph must also be covered by \(\Omega(n)\) edges of the grid. Since this is true for all maps to a line, the grid has pathwidth and cutwidth \(\Omega(n)\).</p>
  </li>
</ul>

<p>Now let’s do the same thing, stepped up a dimension!</p>

<ul>
  <li>
    <p>Instead of graphs, let’s consider 2-dimensional simplicial complexes, systems of points, edges, and triangles. And instead of mapping them to a one-dimensional line, let’s map them (topologically, not necessarily linearly) to a two-dimensional plane. We’ll say that the mapping has high thickness if some point is covered by many triangles (corresponding to cutwidth), or by many vertex-disjoint triangles (corresponding to pathwidth).</p>
  </li>
  <li>
    <p>For a graph of maximum  degree \(d\), at most \(\tbinom{d}{2}\) triangles can share a vertex, so a point covered by many triangles will be covered by many vertex-disjoint triangles. More importantly, this is where the book thickness comes in: an argument related to the <a href="https://en.wikipedia.org/wiki/Erd%C5%91s%E2%80%93Szekeres_theorem">Erdős–Szekeres theorem</a> proves that, when a graph has a \(\theta\)-page book embedding, drawn with its vertices on a circle and its edges as chords of the circle, then at most \(\theta^3\) vertex-disjoint triangles in the graph can contain any point within the circle. So if every mapping into the plane produces a system of triangles of thickness \(t\), you also get book thickness \(\Omega(t^{1/3})\).</p>
  </li>
  <li>
    <p>A complete simplicial complex with \(n\) vertices, \(\tbinom{n}{2}\) edges, and \(\tbinom{n}{3}\) triangles, mapped to the plane, always leads to a point covered by \(\Omega(n^3)\) triangles, by a result of Gromov. (This is closely related to the earlier work of Regina Liu on <a href="https://en.wikipedia.org/wiki/Simplicial_depth">simplicial depth</a> but we want to allow any continuous mapping to the plane, whereas simplicial depth involves mappings that are linear on each edge and triangle.)</p>
  </li>
  <li>
    <p>For an \(n\times n\times n\) grid graph, with its squares triangulated to form a 2d complex \(C\), we can associate each vertex with a subcomplex of \(C\) consisting of the union of the 2d grid planes containing that vertex. This family of subcomplexes has connected pairwise unions and simply connected triplewise unions, analogous to the properties of a bramble for a graph.</p>
  </li>
  <li>
    <p>We can map the complete simplicial complex onto the grid, vertex-to-vertex, by mapping each edge onto a path through the union of two subgraphs and each triangle onto a triangulated surface within the union of three subgraphs. This map has low congestion: each grid vertex, edge, or triangle is in the image of \(O(n^2)\) vertices, edges, or triangles of the complete complex.</p>
  </li>
  <li>
    <p>Any map of the triangulated 3d grid onto the plane can be composed with the map from the complete 2-complex to the grid, giving a map of the complete complex onto the plane. Because of the low congestion of the map to the grid, a point of the plane that is covered by \(\Omega(n^3)\) triangles of the complete complex must also be covered by \(\Omega(n)\) triangles of the triangulated grid. Since this is true for all maps to a plane, the triangulated grid has book thickness \(\Omega(n^{1/3})\).</p>
  </li>
</ul>

<p>For details, generalizations to triangulated products of trees and non-grid tessellations of space, matching upper bounds on book thickness, and more, please see the preprint.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/107795266201400204">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2022/02/13/triangulation-thickens-grids.html"><span class="datestr">at February 13, 2022 10:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19647">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/">Inequalities on the Gridiron</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>Q: Why are Buffalo Bills unlike Dollar Bills? A: Dollar Bills are good for 4 quarters</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/joshallen/" rel="attachment wp-att-19649"><img width="155" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/JoshAllen.jpg?resize=155%2C128&amp;ssl=1" class="alignright wp-image-19649" height="128" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Reddit “outsmarting math” <a href="https://www.reddit.com/r/buffalobills/comments/km67tw/josh_allen_the_entirety_of_math_and_all_of/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Josh Allen is not appearing in today’s Super Bowl. He led the Buffalo Bills to not just one but two go-ahead touchdowns in the final 2:00 of the game at Kansas City three weeks ago, but the Bills lost both leads and KC won in overtime.</p>
<p>
Today we note an inequality that treats the real numbers like a football gridiron.</p>
<p>
The <a href="https://en.wikipedia.org/wiki/Hurry-up_offense#Two-minute_drill">two-minute drill</a> is the hallmark of quarterback heroism. KC’s Patrick Mahomes, however, demonstrated the <a href="https://dailystatuss.com/13-seconds-meme-13-seconds-chief-nfl-2022/">13-second drill</a> in two plays plus a tying field goal. That is, the Bills were good for 3 quarters plus 14:47. But Mahomes is not in the Super Bowl either. Two weeks ago, he lost the magic touch in both the closing minute of the fourth quarter and the beginning of overtime as KC squandered a big lead and lost to the Cincinnati Bengals. Whose quarterback, Joe Burrow, <i>is</i> playing in today’s Super Bowl, opposite Matthew Stafford of the Los Angeles Rams.</p>
<p>
The American football field is divided into 100 yards, but rarely subdivided beyond that. The announcers may refer to “a long two yards” or “a short 3,” but never 2.5 yards. It is not just the announcers. Official statistics are kept in units of whole yards, more often rounded up than down. A fourth-down quarterback plunge with 3 inches to go still counts as a 1-yard gain. Perhaps it is essential to the yard that it not be divided into dyadic or decimal units, the way the meter is. As the US celebrates an event still enjoyed by “one nation indivisible,” we note the indivisible.</p>
<p>
</p><p></p><h2> Inequalities </h2><p></p>
<p></p><p>
Godfrey Hardy, John Littlewood, George Polya are famous for many things separately and together. All three lent their names to the timeless book <a href="https://mathematicalolympiads.files.wordpress.com/2012/08/inequalities-hardy-littlewood-polya.pdf">Inequalities</a>. It codifies the theory of real inequalities. </p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/inequalitiescover/" rel="attachment wp-att-19650"><img width="171" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/InequalitiesCover.jpg?resize=171%2C250&amp;ssl=1" class="aligncenter wp-image-19650" height="250" /></a></p>
<p></p><p><br />
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/hlp/" rel="attachment wp-att-19652"><img width="276" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/HLP.png?resize=276%2C105&amp;ssl=1" class="aligncenter wp-image-19652" height="105" /></a></p>
<p>
</p><p></p><h2> An Inequality </h2><p></p>
<p></p><p>
We recently had reason to look at the following inequality: </p>
<blockquote><p><b> </b> <em> If <img src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a^2 - b^2 = c&gt;0}" class="latex" />, then 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  c \ge a+b. " class="latex" /></p>
</em><p><em></em>
</p></blockquote>
<p>We noted that this fails in general: Let <img src="https://s0.wp.com/latex.php?latex=%7Ba%3D1%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a=1/2}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb%3D1%2F4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{b=1/4}" class="latex" />. Then <img src="https://s0.wp.com/latex.php?latex=%7Bc%3D3%2F16%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c=3/16}" class="latex" /> and 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++3%2F16+%3C+1%2F2+%2B+1%2F4.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  3/16 &lt; 1/2 + 1/4. " class="latex" /></p>
<p>This is not even close. But wait—the following lemma is true:</p>
<blockquote><p><b>Lemma 1</b> <em> If <img src="https://s0.wp.com/latex.php?latex=%7Ba%5E2+-+b%5E2+%3D+c%3E0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a^2 - b^2 = c&gt;0}" class="latex" />, then 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%5Cge+a%2Bb+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  c \ge a+b " class="latex" /></p>
</em><p><em>provided <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a,b,c}" class="latex" /> are integers. </em>
</p></blockquote>
<p></p><p>
The proof is quite simple. We note that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++c+%3D+%28a-b%29%28a%2Bb%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  c = (a-b)(a+b). " class="latex" /></p>
<p>But this shows that <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a+b}" class="latex" /> is a non-zero divisor of <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c}" class="latex" />. But then 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%2Bb+%5Cle+c.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  a+b \le c. " class="latex" /></p>
<p>This proves the inequality. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Is this interesting at all? We have an application of the above lemma, which we will discuss in the future. Are there other good examples of inequalities that are general and natural and only hold over the integers? Or is seeking them like trying to “outsmart math itself”?</p>
<p><br /></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/allenoutsmartsmath/" rel="attachment wp-att-19653"><img width="400" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/AllenOutsmartsMath.jpg?resize=400%2C177&amp;ssl=1" class="aligncenter wp-image-19653" height="177" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">SB Nation <a href="https://www.sbnation.com/nfl/2018/4/24/17271686/josh-allen-nfl-draft-2018-stats-analysis-comparisons">source</a></font>
</td>
</tr>
</tbody></table></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2022/02/13/inequalities-on-the-gridiron/"><span class="datestr">at February 13, 2022 09:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://scottaaronson.blog/?p=6299">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://scottaaronson.blog/?p=6299">Happy 70th birthday Dad!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://scottaaronson.blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<figure class="wp-block-image size-large"><a href="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-scaled.jpg"><img width="1024" alt="" src="https://149663533.v2.pressablecdn.com/wp-content/uploads/2022/02/dad70-1024x768.jpg" class="wp-image-6302" height="768" /></a></figure>



<p>When, before covid, I used to travel the world giving quantum computing talks, every once in a while I’d meet an older person who asked whether I had any relation to a 1970s science writer by the name of Steve Aaronson.  So, yeah, Steve Aaronson is my dad.  He majored in English in Penn State, where he was lucky enough to study under the legendary <a href="https://en.wikipedia.org/wiki/William_Tenn">Phil Klass</a>, who wrote under the pen name William Tenn and who basically created the genre of science-fiction comedy, half a century before there were any such things as <em>Futurama</em>.  After graduating, my dad became a popular physics and cosmology writer, who interviewed greats like Steven Weinberg and John Archibald Wheeler and Arno Penzias (discoverer of the cosmic microwave background radiation).  He published not only in science magazines but in <em>Playboy</em> and <em>Penthouse</em>, which (as he explained to my mom) paid better than the science magazines.  When I was growing up, my dad had a <em>Playboy</em> on his office shelf, which I might take down if for example I wanted to show a friend a 2-page article, with an Aaronson byline, about the latest thinking on the preponderance of matter over antimatter in the visible universe.</p>



<p>Eventually, partly motivated by the need to make money to support … well, me, and then my brother, my dad left freelancing to become a corporate science writer at AT&amp;T Bell Labs.  There, my dad wrote speeches, delivered on the floor of Congress, about how breaking up AT&amp;T’s monopoly would devastate Bell Labs, a place that stood with ancient Alexandria and Cambridge University among the human species’ most irreplaceable engines of scientific creativity.  (Being a good writer, my dad didn’t put it in <em>quite</em> those words.)  Eventually, of course, AT&amp;T <em>was</em> broken up, and my dad’s dire warning about Bell Labs turned out to be 100% vindicated … although on the positive side, Americans got much cheaper long distance.</p>



<p>After a decade at Bell Labs, my dad was promoted to be a public relations executive at AT&amp;T itself, where when I was a teenager, he was centrally involved in the launch of the AT&amp;T spinoff <a href="https://en.wikipedia.org/wiki/Lucent">Lucent Technologies</a> (motto: “Bell Labs Innovations”), and then later the Lucent spinoff <a href="https://en.wikipedia.org/wiki/Avaya">Avaya</a>—developments that AT&amp;T’s original breakup had caused as downstream effects.</p>



<p>In the 1970s, somewhere between his magazine stage and his Bell Labs stage, my dad also worked for <a href="https://en.wikipedia.org/wiki/Eugene_Garfield">Eugene Garfield</a>, the pioneer of bibliometrics for scientific papers and founder of the <a href="https://en.wikipedia.org/wiki/Institute_for_Scientific_Information">Institute for Scientific Information</a>, or ISI.  (Sergey Brin and Larry Page would later cite Garfield’s work, on the statistics of the scientific-citation graph, as one of the precedents for the PageRank algorithm at the core of Google.)</p>



<p>My dad’s job at ISI was to supply Eugene Garfield with “raw material” for essays, which the latter would then write and publish in ISI’s journal <em>Current Contents</em> under the byline Eugene Garfield.  Once, though, my dad supplied some “raw material” for a planned essay about “Style in Scientific Writing”—and, well, I’ll let Garfield <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">tell</a> the rest:</p>



<blockquote class="wp-block-quote"><p>This topic of style in scientific writing was first proposed as something I should undertake myself, with some research and drafting help from Steve.  I couldn’t, with a clear conscience, have put my name to the “draft” he submitted.  And, though I don’t disagree with much of it, I didn’t want to modify or edit it in order to justify claiming it as my own.  So here is Aaronson’s “draft,” as it was submitted for “review.”  You can say I got a week’s vacation.  After reading what he wrote it required little work to write this introduction.</p></blockquote>



<p>Interested yet?  You can <a href="http://www.garfield.library.upenn.edu/essays/v3p004y1977-78.pdf">read “Style in Scientific Writing” here</a>.  You can, if we’re being honest, tell that this piece was originally intended as “raw material”—but only because of the way it calls forth such a fierce armada of all of history’s awesomest quotations about what makes scientific writing good or bad, like Ben Franklin and William James and the whole gang, which would make it worth the read regardless.  I <em>love</em> eating raw dough, I confess, and I love my dad’s essay.  (My dad, ironically enough, likes everything he eats to be thoroughly cooked.)</p>



<p>When I read that essay, I hear my dad’s voice from my childhood.  “Omit needless words.”  There were countless revisions and pieces of advice on every single thing I wrote, but usually, “omit needless words” was the core of it.  And as terrible as you all know me to be on that count, imagine <em>how much worse</em> it would’ve been if not for my dad!  And I know that as soon as he reads this post, he’ll find needless words to omit.</p>



<p>But hopefully he won’t omit these:</p>



<p>Happy 70th birthday Pops, congrats on beating the cancer, and here’s to many more!</p></div>







<p class="date">
by Scott <a href="https://scottaaronson.blog/?p=6299"><span class="datestr">at February 12, 2022 08:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://nisheethvishnoi.wordpress.com/?p=147">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/nisheeth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://nisheethvishnoi.wordpress.com/2022/02/11/focs-2021-talk-videos/">FOCS 2021 Talk Videos</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>After more than a year of planning, FOCS 2021 concluded yesterday. </p>



<p>In case you missed all or part of the event, the talks for all of 117 papers and for the three workshops are now available on <a href="https://www.youtube.com/channel/UClrteoQ-ULzlZZaWi6c6iKw/playlists">this youtube</a> channel.</p>



<p>The full versions of all papers (and videos) are also freely available <a href="https://focs2021.cs.colorado.edu/program/">here</a>.</p>



<p>Many thanks to more than 1000 people, including authors, program committee members, external reviewers, organizers, TCMF members, volunteers, and attendees for making this happen! </p>



<figure class="wp-block-video"></figure></div>







<p class="date">
by nisheethvishnoi <a href="https://nisheethvishnoi.wordpress.com/2022/02/11/focs-2021-talk-videos/"><span class="datestr">at February 11, 2022 02:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://rjlipton.wpcomstaging.com/?p=19636">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/">National Academy of Engineering Elects</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>
<font color="#0044cc"><br />
<em>The problem in this business isn’t to keep people from stealing your ideas; it’s making them steal your ideas!—Howard Aiken</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/egak/" rel="attachment wp-att-19638"><img width="155" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/EGAK.png?resize=155%2C115&amp;ssl=1" class="alignright size-full wp-image-19638" height="115" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of homepage photos</font></td>
</tr>
</tbody>
</table>
<p>
Taher Elgamal and Anna Karlin are among 111 <a href="https://www.nae.edu/270224/National-Academy-of-Engineering-Elects-111-Members-and-22-International-Members">new US members</a> of the National Academy of Engineering (NAE). That’s one-hundred-and-eleven, not seven in binary.</p>
<p>
Today we congratulate them and all the new members.<br />
<span id="more-19636"></span></p>
<p>
Elgamal and Karlin are the two closest to theory, by my reckoning. Elgamal developed the <a href="https://en.wikipedia.org/wiki/ElGamal_encryption">ElGamal</a> encryption scheme. Elgamal spelled his name with a capital G at the time of his famous 1985 <a href="https://caislab.kaist.ac.kr/lecture/2010/spring/cs548/basic/B02.pdf">paper</a> but it is lowercased on his own LinkedIn <a href="https://www.linkedin.com/in/taherelgamal/">page</a>, on Wikipedia, on his RSA conference <a href="https://www.rsaconference.com/experts/dr-taherelgamal">page</a>, and by the NAE. Wikipedia explains that he spells it more simply so that “it is less likely to be mangled in English.” Yet his invention keeps the capital G. Ken and I think a good reason for this is that it uses a large cyclic group <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G}" class="latex" />. The citation also hails his work on <a href="https://en.wikipedia.org/wiki/Transport_Layer_Security#SSL_1.0,_2.0,_and_3.0">SSL</a> and other internet protocols.</p>
<p>
We featured Karlin’s nifty joint paper on the metric TSP problem recently <a href="https://rjlipton.wpcomstaging.com/2020/10/26/a-vast-and-tiny-breakthrough/">here</a>. She is also on the editorial board of the new TheoretiCS <a href="https://rjlipton.wpcomstaging.com/2021/12/01/the-new-journal/">journal</a>. I was glad to serve with her on an NSF committee to promote <a href="https://rjlipton.wpcomstaging.com/2011/07/12/time-chunks-and-theory-nuggets/">nuggets</a> of theory. She holds the Bill and Melinda Gates Chair at the Paul Allen School of Computer Science and Engineering at the University of Washington.</p>
<p>
The new members bring the total US membership in the NAE to 2,388. Joining them are 22 new international members. They include Natarajan Chandrasekaran of Tata Sons for advancing the Indian software industry and Hongjiang Zhang of The Carlyle Group in Beijing for multimedia computing. </p>
<p><a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/nae/" rel="attachment wp-att-19639"><img width="120" alt="" src="https://i0.wp.com/rjlipton.wpcomstaging.com/wp-content/uploads/2022/02/nae.png?resize=120%2C120&amp;ssl=1" class="aligncenter wp-image-19639" height="120" /></a></p>
<p>
</p><p></p><h2> New Members in Computing </h2><p></p>
<p></p><p>
There are many other new members in areas of computing besides theory. Here are some of the new members that work in computer science—including the citations for Elgamal and Karlin. </p>
<ul>
<p></p><li>
Bergeron, Kathleen, vice president, Hardware Engineering, Apple Inc., Los Gatos, Calif. <i>For contributions to and leadership in the invention and engineering product realization of innovative designs.</i><p></p>
<p></p></li><li>
Bovik, Alan C., Cockrell Family Regents Endowed Chair in Engineering and professor, Electrical and Computer Engineering, University of Texas, Austin. <i>For contributions to the development of tools for image and video quality assessment.</i><p></p>
<p></p></li><li>
Cohn, John Maxwell, IBM Fellow, MIT-IBM Watson AI Lab, Cambridge, Mass. <i>For improving design productivity of high-performance analog and mixed-signal circuits and for evangelizing STEM education.</i><p></p>
<p></p></li><li>
Croak, Marian R., vice president, Engineering, Google LLC, Fair Haven, N.J. <i>For technical and managerial leadership in the implementation of packet voice networking and for promotion of minority inclusion in engineering.</i><p></p>
<p></p></li><li>
Czerwinski, Mary, partner researcher and research manager, Microsoft Research, Redmond, Wash. <i>For the application of psychological principles to the design and understanding of human computer interaction.</i><p></p>
<p></p></li><li>
Elgamal, Taher, chief technology officer, Security, Salesforce, San Francisco. <i>For contributions to cryptography, e-commerce, and protocols for secure internet transactions.</i><p></p>
<p></p></li><li>
Fields, Craig I., chairman, Defense Science Board, U.S. Department of Defense, Washington, D.C. <i>For contributions to the development of systems and technology for national security and their transfer to commercial applications.</i><p></p>
<p></p></li><li>
Hammack, William S., William H. and Janet G. Lycan Professor, Chemical and Biomolecular Engineering, University of Illinois, Urbana-Champaign. <i>For innovations in multidisciplinary engineering education, outreach, and service to the profession through development and communication of internet-delivered content.</i><p></p>
<p></p></li><li>
Karlin, Anna, Bill and Melinda Gates Chair, Allen School of Computer Science &amp; Engineering, University of Washington, Seattle. <i>For contributions to the design and analysis of randomized algorithms and their impact on computer systems and the internet.</i><p></p>
<p></p></li><li>
Karniadakis, George Em, Charles Pitts Robinson and John Palmer Barstow Professor, Division of Applied Mathematics and School of Engineering, Brown University, Providence, R.I. <i>For computational tools, from high-accuracy algorithms to machine learning, and applications to complex flows, stochastic processes, and microfluidics.</i><p></p>
<p></p></li><li>
Levoy, Marc, Vmware Founders Professor (emeritus), Computer Science, Stanford University, Stanford, Calif. <i>For contributions to computer graphics and digital photography.</i><p></p>
<p></p></li><li>
Mauro, John C., professor, Department of Materials Science and Engineering, Pennsylvania State University, University Park. <i>For developing and applying data-driven models and machine learning that enable high-strength, damage-resistant glasses.</i><p></p>
<p></p></li><li>
Nadella, Satya, chairman and chief executive officer, Microsoft Corp., Redmond, Wash. <i>For advancing corporate computing infrastructure as a cloud service, and for international leadership on sociotechnical systems and practice.</i> <p></p>
<p></p></li><li>
Nahrstedt, Klara, Grainger Distinguished Chair, Grainger College of Engineering, University of Illinois, Urbana-Champaign. <i>For contributions to managing quality of service in distributed multimedia systems and networks.</i><p></p>
<p></p></li><li>
Reiman, Martin I., professor, Department of Industrial Engineering and Operations Research, Columbia University, Murray Hill, N.J. <i>For contributions to network theory and applications in large-scale stochastic systems.</i><p></p>
<p></p></li><li>
Sahinidis, Nikolaos V., Gary C. Butler Family Chair and Professor, H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute of Technology, Atlanta. <i>For contributions to global optimization and the development of widely used software for optimization and machine learning.</i><p></p>
<p></p></li><li>
Sapiro, Guillermo, James B. Duke Distinguished Professor, Electrical and Computer Engineering, Duke University, Durham, N.C. <i>For contributions to the theory and practice of imaging.</i><p></p>
<p></p></li><li>
Veloso, Manuela M., head, Artificial Intelligence Research, JPMorgan Chase &amp; Co., New York City. <i>For contributions to machine learning and its applications in robotics and the financial services industry.</i><p></p>
<p></p></li><li>
Whitney, Telle, CEO, Telle Whitney Consulting LLC, Scotts Valley, Calif. <i>For contributions to structured silicon design and for increasing the participation of women in computing careers.</i><p></p>
<p></p></li><li>
Willcox, Karen E., director, Oden Institute for Computational Engineering and Sciences, University of Texas, Austin. <i>For contributions to computational engineering methods for the design and optimal control of high-dimensional systems with uncertainties.</i><p></p>
</li></ul>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We count 8 women of the 20 above: Bergeron, Croak, Czerwinski, Karlin, Nahrstedt, Veloso, Whitney, and Willcox. That’s quite a lot better than other rations we’ve observed. How can awareness of this success be filtered through? We also note Anna’s <a href="https://medium.com/@karlin_41004/why-women-and-everyone-else-should-code-18e4a0a46a47">essay</a>, “Why Women (and Everyone Else) Should Code.”</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wpcomstaging.com/2022/02/10/national-academy-of-engineering-elects/"><span class="datestr">at February 11, 2022 01:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2022/02/10/hereditary-first-order">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2022/02/10/hereditary-first-order.html">Hereditary first order graph properties can be hard</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Many natural classes of undirected graphs are <a href="https://en.wikipedia.org/wiki/Hereditary_property">hereditary</a>, meaning that if you delete vertices from any graph in the class, the induced subgraph that you get always remains in this class. Every hereditary class of graphs can be defined by its <a href="https://en.wikipedia.org/wiki/Forbidden_graph_characterization">forbidden induced subgraphs</a>, the minimal graphs that do not belong to the class. When there are only finitely many of these forbidden subgraphs, it is possible to define the class by a formula in the first-order <a href="https://en.wikipedia.org/wiki/Logic_of_graphs">logic of graphs</a> describing the graphs that do not have these subgraphs, and to test membership in the class in polynomial time by searching for a forbidden subgraph. Examples include:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Threshold_graph">threshold graphs</a>, whose forbidden subgraphs are a four-vertex path, four-vertex cycle, or four-vertex perfect matching.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Cograph">cographs</a>, whose single forbidden subgraph is a four-vertex path.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Triangle-free_graph">triangle-free graphs</a>, whose single forbidden subgraph is a <span style="white-space: nowrap;">triangle \(K_3\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Claw-free_graph">claw-free graphs</a>, whose single forbidden subgraph is the four-vertex <span style="white-space: nowrap;">tree \(K_{1,3}\).</span></p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Line_graph">line graphs</a>, which have a forbidden subgraph characterization with nine forbidden subgraphs:</p>
  </li>
</ul>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/nonline.svg" alt="The nine forbidden induced subgraphs of line graphs" /></p>

<p>However, there might be infinitely many forbidden subgraphs. In many such cases, it is still possible to recognize these graphs in polynomial time, often by a greedy algorithm that removes vertices one at a time based on some local structure. Additionally, in these cases, it is often possible to describe the property of being one of the forbidden subgraphs by a first-order formula, so that the graph class is the class of graphs none of whose subgraphs model that formula. For instance:</p>

<ul>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Degeneracy_(graph_theory)"><span style="white-space: nowrap;">\(d\)-degenerate</span> graphs</a> are graphs in which no non-empty induced subgraph has all vertices of degree greater <span style="white-space: nowrap;">than \(d\).</span> They can be recognized in polynomial time as the graphs reducible to empty by repeatedly removing low-degree vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Distance-hereditary_graph">distance-hereditary graphs</a> are graphs in which every induced subgraph with two or more vertices has a degree-one vertex, or twins, two vertices with equal closed or open neighborhoods. They can be recognized in polynomial time by repeatedly removing degree-one vertices or merging twins.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Chordal_graph">chordal graphs</a> are graphs with no induced cycle of more than three vertices, or the graphs in which every non-empty induced subgraph has a simplicial vertex, a vertex whose neighbors are all adjacent. They can be recognized in polynomial time by repeatedly removing simplicial vertices.</p>
  </li>
  <li>
    <p>The <a href="https://en.wikipedia.org/wiki/Perfect_graph">perfect graphs</a> are graphs with no odd induced cycle of more than three vertices, or its complement. They can be recognized in polynomial time but the algorithm is complicated.</p>
  </li>
</ul>

<p>Obviously, not all hereditary classes are like that; one could, for instance, forbid induced cycles whose lengths belong to an undecidable set of integers, and get a hereditary class of graphs whose recognition problem is again undecidable. But this led me to wonder: is there a connection between the first-order recognizability of the forbidden subgraphs and the polynomial recognizability of the graph class itself? Could it be that every hereditary class defined by a first-order set of forbidden subgraphs is polynomially recognizable?</p>

<p>No!</p>

<p>The counterexample I found is the family of graphs whose forbidden subgraphs are the non-empty <a href="https://en.wikipedia.org/wiki/Perfect_graph">cubic (3-regular) graphs</a>. Let’s call these the cubic-free graphs. Being cubic is easily expressed in first-order logic, so the forbidden subgraphs for the cubic-free graphs are first-order recognizable. However, under standard assumptions, the cubic-free graphs themselves are not polynomially recognizable: their recognition problem is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span> Put another way, the problem <small>CUBIC INDUCED SUBGRAPH</small> asking whether a given graph has a non-empty cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete.</span></p>

<p>I found lots of references in the literature to problems of finding non-empty cubic subgraphs (not required to be induced subgraphs; see Garey &amp; Johnson GT32), or to finding cubic induced subgraphs with some constraint on their size, but not to the <small>CUBIC INDUCED SUBGRAPH</small> problem itself. So instead, I found an <span style="white-space: nowrap;">\(\mathsf{NP}\)-completeness</span> reduction myself, from <a href="https://en.wikipedia.org/wiki/3-dimensional_matching"><small>3-DIMENSIONAL MATCHING</small></a>, in which the input is a 3-uniform hypergraph (meaning that each hyperedge touches three hypervertices) and one must find a subset of the hyperedges that touches every hypervertex exactly once. An example of my reduction is shown below, from which I think the general case should be more clear.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2022/3dm23is.svg" alt="NP-completeness reduction from 3-dimensional matching to cubic induced subgraph" /></p>

<p>The input hypergraph is shown with its hypervertices as large blue disks and its hyperedges as medium-sized yellow disks. Inside each of these disks is shown part of a graph, a gadget into which that piece of the hypergraph is translated to form a piece of a <small>CUBIC INDUCED SUBGRAPH</small> instance. The example hypergraph used in the image is 4-regular (every hypervertex touches four hyperedges) but that’s not essential. Once you start making choices of which vertices to include or exclude in an induced subgraph, you can make a chain of inferences from that choice:</p>
<ul>
  <li>If you have included a vertex that has only three non-excluded neighbors, you must include all three of them.</li>
  <li>If you have included a vertex that has three included neighbors, you must exclude all its other neighbors.</li>
  <li>If some vertex has fewer than three neighbors that are not excluded, you must exclude it.</li>
</ul>

<p>It follows from this sort of reasoning that the only non-empty cubic induced subgraphs are like the ones shown by the dark red vertices in these gadgets: a vertex for each of the the hyperedges in a matching (such as the matching of dark-yellow hyperedges), and a corresponding subset of the vertices in every hypervertex gadget. Because finding a cubic induced subgraph is <span style="white-space: nowrap;">\(\mathsf{NP}\)-complete,</span> its complementary problem, testing whether a graph is cubic-free, is <span style="white-space: nowrap;">\(\mathsf{coNP}\)-complete.</span></p>

<p>(<a href="https://mathstodon.xyz/@11011110/107776994325248199">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2022/02/10/hereditary-first-order.html"><span class="datestr">at February 10, 2022 05:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
