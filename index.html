<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://www.blogger.com/feeds/25562705/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://benjamin-recht.github.io/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://www.blogger.com/feeds/21224994/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="http://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/8890204/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/21129445/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://www.blogger.com/feeds/32902056/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at October 30, 2019 11:25 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-25562705.post-4967614199435754464">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/roth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://aaronsadventures.blogspot.com/2019/10/forc-new-conference-you-should-know.html">FORC: A new conference you should know about.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Here is the CFP: <a href="https://responsiblecomputing.org/forc-2020-call-for-paper/">https://responsiblecomputing.org/forc-2020-call-for-paper/</a><br /><br /><h1 class="headline">FORC 2020: CALL FOR PAPERS</h1><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px; text-align: center;"><b>Symposium on Foundations of Responsible Computing</b></div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;">The Symposium on Foundations of Responsible Computing (FORC) is a forum for mathematical research in computation and society writ large.  The Symposium aims to catalyze the formation of a community supportive of the application of theoretical computer science, statistics, economics and other relevant analytical fields to problems of pressing and anticipated societal concern. </div><hr style="background-color: #dddddd; border: 0px; color: #dddddd; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; height: 1px; margin: 6px 0px 8px; padding: 0px; width: 1024px;" /><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;"><b>Important Dates</b></div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;">February 11: Submission Deadline<br />March 23: Notification to Authors<br />April 1: Camera Ready Deadline<br />June 1-3: The conference</div><hr style="background-color: #dddddd; border: 0px; color: #dddddd; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; height: 1px; margin: 6px 0px 8px; padding: 0px; width: 1024px;" /><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;">Any mathematical work on computation and society is welcomed, including topics that are not yet well-established and topics that will arise in the future. This includes the investigation of definitions, algorithms and lower bounds, trade-offs, and economic incentives in a variety of areas. A small sample of topics follow: formal approaches to privacy, including differential privacy; fairness and discrimination in machine learning; bias in the formation of, and diffusion in, social networks; electoral processes and allocation of elected representatives (including redistricting). </div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;">The inaugural FORC will be held on June 1-3 at the Harvard Center for Mathematical Sciences and Applications (CMSA), and will have its proceedings published by LIPIcs. The program committee will review submissions to ensure a high quality program based on novel, rigorous and significant scientific contributions. Authors of accepted papers will have the option of publishing a 10-page version of their paper in the proceedings, or publishing only a 1-page extended abstract, to facilitate the publication of their work in another venue. 1-page abstracts will appear on the website, but not in the proceedings. The symposium itself will feature a mixture of talks by authors of accepted papers and invited talks.</div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;">Authors should upload a PDF of the paper through Easychair: <a style="color: #99cc33;" href="https://easychair.org/conferences/?conf=forc2020">https://easychair.org/conferences/?conf=forc2020</a>. The font size should be at least 11 point and the paper should be formatted in a single column. Beyond these, there are no formatting or length requirements, but reviewers will only be asked to read the first 10 pages of the paper. It is the authors’ responsibility that the main results of the paper and their significance be clearly stated within the first 10 pages. Submissions should include proofs of all central claims, and the committee will put a premium on writing that conveys clearly and in the simplest possible way what the paper is accomplishing.  Authors are free to post their paper on arXiv, etc. Future details will appear on the conference website: <a style="color: #99cc33;" href="https://responsiblecomputing.org/">https://responsiblecomputing.org/</a>.</div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;"><b>Steering Committee</b></div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;">Avrim Blum<br />Cynthia Dwork<br />Sampath Kannan<br />Jon Kleinberg<br />Shafi Goldwasser<br />Kobbi Nissim<br />Toni Pitassi<br />Omer Reingold<br />Guy Rothblum<br />Salvatore Ruggieri<br />Salil Vadhan<br />Adrian Weller</div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;"><b>Program Committee</b></div><div style="color: #666666; font-family: Roboto, Arial, Helvetica, sans-serif; font-size: 16px; padding: 12px 0px;">Yiling Chen, Harvard<br />Rachel Cummings, Georgia Tech<br />Anupam Datta, Carnegie Mellon University<br />Moritz Hardt, UC Berkeley<br />Nicole Immorlica, Microsoft Research<br />Michael Kearns, University of Pennsylvania<br />Katrina Ligett, Hebrew University<br />Audra McMillan, Boston University and Northeastern<br />Aaron Roth, University of Pennsylvania (<span style="font-weight: 700;">Chair</span>)<br />Guy Rothblum, Weizmann Institute<br />Adam Smith, Boston University<br />Steven Wu, University of Minnesota<br />Jonathan Ullman, Northeastern<br />Jenn Wortman Vaughan, Microsoft Research<br />Suresh Venkatasubramanian, University of Utah<br />Nisheeth Vishnoi, Yale<br />James Zou, Stanford</div></div>







<p class="date">
by Aaron (noreply@blogger.com) <a href="http://aaronsadventures.blogspot.com/2019/10/forc-new-conference-you-should-know.html"><span class="datestr">at October 30, 2019 08:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1520">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/10/30/toc-for-society/">TOC for Society</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I am delighted that <a href="https://responsiblecomputing.org/">the Symposium on Foundations of Responsible Computing (FORC)</a> is on its way. This is a new forum that will host mathematical research in computation and society, under an inclusive umbrella. A major purpose is to give a home and to nurture the growing community within the Theory of Computing and neighboring fields whose research is focused on the societal impact of computing. This vision is shared by many in this area, and I am very proud of the remarkable list of steering committee members that have volunteered to create and promote the new conference.</p>
<p>The <a href="https://responsiblecomputing.org/forc-2020-call-for-paper/">call for papers for FORC 2020</a> is out. The PC chair, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, has done a remarkable job forming a strong program committee, and we are off to a great start. Please consider sending your research papers and looking forward to seeing many of you at FORC 2020 in the beginning of June at Harvard.</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2019/10/30/toc-for-society/"><span class="datestr">at October 30, 2019 03:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4400">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4400">My New York Times op-ed on quantum supremacy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><a href="https://www.nytimes.com/2019/10/30/opinion/google-quantum-computer-sycamore.html">Here it is</a>.</p>



<p>I’d like to offer special thanks to the editor in charge, <a href="https://twitter.com/eleanorbarkhorn?ref_src=twsrc%5Egoogle%7Ctwcamp%5Eserp%7Ctwgr%5Eauthor">Eleanor Barkhorn</a>, who commissioned this piece and then went way, <strong>way</strong> beyond the call of duty to get it right—including relaxing the usual length limit to let me squeeze in amplitudes and interference, and working late into the night to fix last-minute problems.  Obviously I take sole responsibility for whatever errors remain.</p>



<p>Of course a lot of material still ended up on the cutting room floor, including a little riff about Andrew Yang’s tweet that because of quantum supremacy, now “no code is uncrackable,” as well as Ivanka Trump’s tweet giving credit for Google’s experiment (one that Google was working toward since 2015) partly to her father’s administration.</p>



<p>While I’m posting: those of a more technical bent might want to check out my <a href="https://arxiv.org/abs/1910.12085">new short preprint</a> with UT undergraduate Sam Gunn, where we directly study the complexity-theoretic hardness of spoofing Google’s linear cross-entropy benchmark using a classical computer.  Enjoy!</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4400"><span class="datestr">at October 30, 2019 11:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=18400">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/10/30/amazing-keith-frankston-jeff-kahn-bhargav-narayanan-jinyoung-park-thresholds-versus-fractional-expectation-thresholds/">Amazing! Keith Frankston, Jeff Kahn, Bhargav Narayanan, Jinyoung Park: Thresholds versus fractional expectation-thresholds</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This post describes a <a href="https://arxiv.org/abs/1910.13433">totally unexpected breakthrough</a> about expectation and thresholds. The result  by Frankston, Kahn, Narayanan, and Park has many startling applications and it builds on the <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">recent breakthrough work of Alweiss, Lovett, Wu and Zhang on the sunflower conjecture</a>. Warm congratulations to Keith, Jeff, Bhargav, and Jinyoung!</p>
<p><span style="color: #0000ff;">Let me start with an update on the matter of applying the intermediate value theorem for football (or soccer as referred to in the US). You can read about it <a href="https://gilkalai.wordpress.com/2009/04/20/the-intermediate-value-theorem-applied-to-football/">in this 2009 post</a>. As you may recall, Shmuel Weinberger’s <a href="https://gilkalai.wordpress.com/2009/04/20/the-intermediate-value-theorem-applied-to-football/#comment-1010">raised the concern</a> of instability of fixed points. (A partial solution of Gowers apply the original idea for three foreheads.) Sylvia Serfaty mentioned to me a possible one-player implementation based on <a href="https://en.wikipedia.org/wiki/Inverted_pendulum">inverted pendulum</a> control (See<a href="https://www.youtube.com/watch?v=5oGYCxkgnHQ"> this video</a>, and <a href="https://youtu.be/D3bblng-Kcc?t=1912">this one</a>, and <a href="https://www.youtube.com/watch?v=gnn21smGVrQ">this one</a>, and <a href="https://youtu.be/OCXrXUhJCTI?t=5118">this one</a>, and for the fascinating mathematics  <a href="https://youtu.be/swFwHWMTA4k">this lecture</a> by Jean-Michel Coron. <strong>Please, don’t try it at home.</strong>) <span style="color: #ff0000;">Implement this method in football is a notable remaining challenge <span style="color: #0000ff;">(this you can try at home)</span></span>. On another matter, for readers interested in the Google’s quantum supremacy news, here is a link of my <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/">main post on the matter</a>.</span></p>
<h2>Thresholds versus fractional expectation-thresholds</h2>
<p class="title mathjax">This morning the following paper appeared on the arXive: <a href="https://arxiv.org/abs/1910.13433">Thresholds versus fractional expectation-thresholds</a> by Keith Frankston, Jeff Kahn, Bhargav Narayanan, and Jinyoung Park.</p>
<p><strong>Abstract:</strong> Proving a conjecture of Talagrand, a fractional version of the ‘expectation-threshold’ conjecture of Kalai and the second author, we show for any increasing family <strong>F</strong> on a finite set <strong>X</strong> that <img src="https://s0.wp.com/latex.php?latex=p_c%28F%29%3DO%28q_f%28F%29+%5Clog+%5Cell+%28%7B%5Cbf+F%7D%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_c(F)=O(q_f(F) \log \ell ({\bf F}))" class="latex" title="p_c(F)=O(q_f(F) \log \ell ({\bf F}))" />, where <img src="https://s0.wp.com/latex.php?latex=p_c%28%7B%5Cbf+F%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="p_c({\bf F})" class="latex" title="p_c({\bf F})" /> and <img src="https://s0.wp.com/latex.php?latex=q_f%28%7B%5Cbf+F%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="q_f({\bf F})" class="latex" title="q_f({\bf F})" /> are the threshold and ‘fractional expectation-threshold’ of <strong>F</strong>, and ℓ(<strong>F</strong>) is the largest size of a minimal member of <strong>F</strong>. This easily implies various heretofore difficult results in probabilistic combinatorics, e.g. thresholds for perfect hypergraph matchings (Johansson-Kahn-Vu) and bounded-degree spanning trees (Montgomery). We also resolve (and vastly extend) one version of the ‘random multi-dimensional assignment’ problem of Frieze and Sorkin. Our approach builds on recent breakthrough work of Alweiss, Lovett, Wu and Zhang on the Erdős-Rado ‘sunflower’ conjecture.</p>
<h2>The expectation-threshold conjecture</h2>
<p><a href="https://gilkalai.files.wordpress.com/2019/10/kahn-kalai.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2019/10/kahn-kalai.png?w=640&amp;h=476" class="alignnone size-full wp-image-18406" height="476" /></a></p>
<p>The 2006 <a href="https://arxiv.org/abs/math/0603218">expectation threshold conjecture</a> gives a justification for a naive way to estimate the threshold probability of a random graph property. Suppose that you are asked about the critical probability for a random graph in G(n,p) for having a perfect matching (or a Hamiltonian cycle). You compute the expected number of perfect matchings and realize that when p is C/n this expected number equals 1/2. (For Hamiltonian cycles it will be C’/n.) Of course, if the expectation is one half the probability for a perfect matching can be very low, indeed in this case, an isolated vertex is quite likely but when there is no isolated vertices the expected number of perfect matchings is rather large. Our 2006 conjecture boldly asserts that the gap between the value given by such a naive computation and the true threshold value is at most logarithmic in the number of vertices. Jeff and I tried hard to find a counterexample but instead we managed to find more general and stronger forms of the conjecture that we could not disprove.</p>
<h2>Conjectures by Talagrand</h2>
<p>The expectation threshold conjecture had some connections with a 1995 paper of Michel Talagrand entitled <a href="https://link.springer.com/chapter/10.1007%2F978-3-0348-9090-8_25">Are all sets of positive measure essentially convex?</a> In a 2010 STOC paper <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.165.6973&amp;rep=rep1&amp;type=pdf">Are Many Small Sets Explicitly Small?</a> Michel formulated a weaker fractional version of the expectation threshold conjecture which is sufficient for the various applications of the original conjecture. This conjecture (as well as a stronger form also posed by Talagrand) is now verified in the new paper!</p>
<h2>Connection to isoperimetry</h2>
<p>In our 2006 paper we tried to relate the expectation threshold conjecture to various questions of independent interest related to stability theorems for discrete isoperimetric inequalities. This direction did not play a role in the new paper. Let me note that the isoperimetric problems served as partial motivation for the recent breakthrough results by Peter Keevash, Noam Lifshitz, Eoin Long, and Dor Minzer that are reported in this <a href="https://gilkalai.wordpress.com/2018/10/30/exciting-beginning-of-the-year-activities-and-seminars/">October 2018 post</a>. See their paper <a href="https://arxiv.org/abs/1906.05568">Hypercontractivity for global functions and sharp thresholds</a>.</p>
<h2>A sample from the applications</h2>
<ol>
<li>The threshold value for perfect matching – this was proved already by Erdos and Renyi (1960)  and it follow from the new results. The same goes for the threshold for connectivity.</li>
<li>The threshold value for Hamiltonian circuits – posed as a problem by  Erdos and Renyi it was solved by Korshunov (1976) and by Posa (1976).</li>
<li>The threshold for perfect matching in 3-uniform hypergraphs – was posed by Schmidt and Shamir (1983) and was settled by  Johansson, Kahn, and Vu. (It was one of the motivation for my 2006 paper with Jeff.)</li>
<li>The threshold for bounded degree spanning trees that was open for a long time and was settled by Montgomery (2019).</li>
</ol>
<p>Let me mention that in various cases the gap between the (fractional) expectation threshold and threshold is a smaller power of log <em>n, </em>or is a constant, or has different behavior. Understanding this through a general theory is still unknown.</p>
<h2><strong>Connection to the sunflower breakthrough</strong></h2>
<p>What did play a major role in the new development was the recent <a href="https://arxiv.org/abs/1908.08483">breakthrough work</a> of Alweiss, Lovett, Wu and Zhang on the Erdős-Rado ‘sunflower’ conjecture. (See <a href="https://gilkalai.wordpress.com/2019/08/23/amazing-ryan-alweiss-shachar-lovett-kewen-wu-jiapeng-zhang-made-dramatic-progress-on-the-sunflower-conjecture/">this post</a>.)  I expected that the method of the sunflower paper will have major applications but this application took me by a surprise.</p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/10/30/amazing-keith-frankston-jeff-kahn-bhargav-narayanan-jinyoung-park-thresholds-versus-fractional-expectation-thresholds/"><span class="datestr">at October 30, 2019 08:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1910.13386">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1910.13386">NC Algorithms for Popular Matchings in One-Sided Preference Systems and Related Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Changyong.html">Changyong Hu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Vijay_K=.html">Vijay K. Garg</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1910.13386">PDF</a><br /><b>Abstract: </b>The popular matching problem is of matching a set of applicants to a set of
posts, where each applicant has a preference list, ranking a non-empty subset
of posts in the order of preference, possibly with ties. A matching M is
popular if there is no other matching M' such that more applicants prefer M' to
M. We give the first NC algorithm to solve the popular matching problem without
ties. We also give an NC algorithm that solves the maximum-cardinality popular
matching problem. No NC or RNC algorithms were known for the matching problem
in preference systems prior to this work. Moreover, we give an NC algorithm for
a weaker version of the stable matching problem, that is, the problem of
finding the "next" stable matching given a stable matching.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1910.13386"><span class="datestr">at October 30, 2019 11:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1910.13367">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1910.13367">Derivation and Analysis of Fast Bilinear Algorithms for Convolution</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Caleb Ju, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Solomonik:Edgar.html">Edgar Solomonik</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1910.13367">PDF</a><br /><b>Abstract: </b>The prevalence of convolution in applications within signal processing, deep
neural networks, and numerical solvers has motivated the development of
numerous fast convolution algorithms. In many of these problems, convolution is
performed on terabytes or petabytes of data, so even constant factors of
improvement can significantly reduce the computation time. We leverage the
formalism of bilinear algorithms to describe and analyze all of the most
popular approaches. This unified lens permits us to study the relationship
between different variants of convolution as well as to derive error bounds and
analyze the cost of the various algorithms. We provide new derivations, which
predominantly leverage matrix and tensor algebra, to describe the Winograd
family of convolution algorithms as well as reductions between 1D and
multidimensional convolution. We provide cost and error bounds as well as
experimental numerical studies. Our experiments for two of these algorithms,
the overlap-add approach and Winograd convolution algorithm with polynomials of
degree greater than one, show that fast convolution algorithms can rival the
accuracy of the fast Fourier transform (FFT) without using complex arithmetic.
These algorithms can be used for convolution problems with multidimensional
inputs or for filters larger than size of four, extending the state-of-the-art
in Winograd-based convolution algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1910.13367"><span class="datestr">at October 30, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1910.13352">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1910.13352">Equipartitions with Wedges and Cones</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schnider:Patrick.html">Patrick Schnider</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1910.13352">PDF</a><br /><b>Abstract: </b>A famous result about mass partitions is the so called \emph{Ham-Sandwich
theorem}. It states that any $d$ mass distributions in $\mathbb{R}^d$ can be
simultaneously bisected by a single hyperplane. In this work, we study two
related questions.
</p>
<p>The first one is, whether we can bisect more than $d$ masses, if we allow for
bisections with more general objects such as cones, wedges or double wedges. We
answer this question in the affirmative by showing that with all of these
objects, we can simultaneously bisect $d+1$ masses. For double wedges, we prove
a stronger statement, namely that $d$ families of $d+1$ masses each can each by
simultaneously bisected by some double wedge such that all double wedges have
one hyperplane in common.
</p>
<p>The second question is, how many masses we can simultaneously equipartition
with a $k$-fan, that is, $k$ half-hyperplanes in $\mathbb{R}^d$, emanating from
a common $(d-2)$-dimensional apex. This question was already studied in the
plane, our contribution is to extend the planar results to higher dimensions.
</p>
<p>All of our results are proved using topological methods. We use some
well-established techniques, but also some newer methods. In particular, we
introduce a Borsuk-Ulam theorem for flag manifolds, which we believe to be of
independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1910.13352"><span class="datestr">at October 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1910.13297">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1910.13297">Flexible Graph Connectivity: Approximating Network Design Problems Between 1- and 2-connectivity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Adjiashvili:David.html">David Adjiashvili</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hommelsheim:Felix.html">Felix Hommelsheim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/M=uuml=hlenthaler:Moritz.html">Moritz Mühlenthaler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1910.13297">PDF</a><br /><b>Abstract: </b>Graph connectivity and network design problems are among the most fundamental
problems in combinatorial optimization. The minimum spanning tree problem, the
two edge-connected spanning subgraph problem (2-ECSS) and the tree augmentation
problem (TAP) are all examples of fundamental well-studied network design tasks
that postulate different initial states of the network and different
assumptions on the reliability of network components. In this paper we motivate
and study \emph{Flexible Graph Connectivity} (FGC), a problem that mixes
together both the modeling power and the complexities of all aforementioned
problems and more. In a nutshell, FGC asks to design a connected network, while
allowing to specify different reliability levels for individual edges. While
this non-uniform nature of the problem makes it appealing from the modeling
perspective, it also renders most existing algorithmic tools for dealing with
network design problems unfit for approximating FGC.
</p>
<p>In this paper we develop a general algorithmic approach for approximating FGC
that yields approximation algorithms with ratios that are very close to the
best known bounds for many special cases, such as 2-ECSS and TAP. Our algorithm
and analysis combine various techniques including a weight-scaling algorithm, a
charging argument that uses a variant of exchange bijections between spanning
trees and a factor revealing non-linear optimization problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1910.13297"><span class="datestr">at October 30, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1910.13292">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1910.13292">Real-time Bidding campaigns optimization using attribute selection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miralles:Luis.html">Luis Miralles</a>, M. Atif Qureshi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Namee:Brian_Mac.html">Brian Mac Namee</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1910.13292">PDF</a><br /><b>Abstract: </b>Real-Time Bidding is nowadays one of the most promising systems in the online
advertising ecosystem. In the presented study, the performance of RTB campaigns
is improved by optimising the parameters of the users' profiles and the
publishers' websites. Most studies about optimising RTB campaigns are focused
on the bidding strategy. In contrast, the objective of our research consists of
optimising RTB campaigns by finding out configurations that maximise both the
number of impressions and their average profitability. The experiments
demonstrate that, when the number of required visits by advertisers is low, it
is easy to find configurations with high average profitability, but as the
required number of visits increases, the average profitability tends to go
down. Additionally, configuration optimisation has been combined with other
interesting strategies to increase, even more, the campaigns' profitability.
Along with parameter configuration the study considers the following
complementary strategies to increase profitability: i) selecting multiple
configurations with a small number of visits instead of a unique configuration
with a large number, ii) discarding visits according to the thresholds of cost
and profitability, iii) analysing a reduced space of the dataset and
extrapolating the solution, and iv) increasing the search space by including
solutions below the required number of visits. The developed campaign
optimisation methodology could be offered by RTB platforms to advertisers to
make their campaigns more profitable.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1910.13292"><span class="datestr">at October 30, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1910.13123">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1910.13123">Reconstruction of time-consistent species trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lafond:Manuel.html">Manuel Lafond</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hellmuth:Marc.html">Marc Hellmuth</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1910.13123">PDF</a><br /><b>Abstract: </b>The history of gene families -- which are equivalent to event-labeled gene
trees -- can to some extent be reconstructed from empirically estimated
evolutionary event-relations containing pairs of orthologous, paralogous or
xenologous genes. The question then arises as whether inferred event-labeled
gene trees are "biologically feasible" which is the case if one can find a
species tree with which the gene tree can be reconciled in a time-consistent
way.
</p>
<p>In this contribution, we consider event-labeled gene trees that contain
speciation, duplication as well as horizontal gene transfer and we assume that
the species tree is unknown. We provide a cubic-time algorithm to decide
whether a "time-consistent" binary species for a given event-labeled gene tree
exists and, in the affirmative case, to construct the species tree within the
same time-complexity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1910.13123"><span class="datestr">at October 30, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1910.13011">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1910.13011">A Survey on Subgraph Counting: Concepts, Algorithms and Applications to Network Motifs and Graphlets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ribeiro:Pedro.html">Pedro Ribeiro</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paredes:Pedro.html">Pedro Paredes</a>, Miguel E. P. Silva, David Aparicio, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Fernando.html">Fernando Silva</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1910.13011">PDF</a><br /><b>Abstract: </b>Computing subgraph frequencies is a fundamental task that lies at the core of
several network analysis methodologies, such as network motifs and
graphlet-based metrics, which have been widely used to categorize and compare
networks from multiple domains. Counting subgraphs is however computationally
very expensive and there has been a large body of work on efficient algorithms
and strategies to make subgraph counting feasible for larger subgraphs and
networks.
</p>
<p>This survey aims precisely to provide a comprehensive overview of the
existing methods for subgraph counting. Our main contribution is a general and
structured review of existing algorithms, classifying them on a set of key
characteristics, highlighting their main similarities and differences. We
identify and describe the main conceptual approaches, giving insight on their
advantages and limitations, and provide pointers to existing implementations.
We initially focus on exact sequential algorithms, but we also do a thorough
survey on approximate methodologies (with a trade-off between accuracy and
execution time) and parallel strategies (that need to deal with an unbalanced
search space).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1910.13011"><span class="datestr">at October 30, 2019 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1903.02185">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1903.02185">Stable Noncrossing Matchings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ruangwises:Suthee.html">Suthee Ruangwises</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Itoh:Toshiya.html">Toshiya Itoh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1903.02185">PDF</a><br /><b>Abstract: </b>Given a set of $n$ men represented by $n$ points lying on a line, and $n$
women represented by $n$ points lying on another parallel line, with each
person having a list that ranks some people of opposite gender as his/her
acceptable partners in strict order of preference. In this problem, we want to
match people of opposite genders to satisfy people's preferences as well as
making the edges not crossing one another geometrically. A noncrossing blocking
pair w.r.t. a matching $M$ is a pair $(m,w)$ of a man and a woman such that
they are not matched with each other but prefer each other to their own
partners in $M$, and the segment $(m,w)$ does not cross any edge in $M$. A
weakly stable noncrossing matching (WSNM) is a noncrossing matching that does
not admit any noncrossing blocking pair. In this paper, we prove the existence
of a WSNM in any instance by developing an $O(n^2)$ algorithm to find one in a
given instance.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1903.02185"><span class="datestr">at October 30, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/144">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/144">TR19-144 |  An Adaptive Step Toward the Multiphase Conjecture | 

	Omri Weinstein, 

	Young Ko</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In 2010, Patrascu proposed a dynamic set-disjointness problem, known as the Multiphase problem, as a candidate for proving $polynomial$ lower bounds on the operational time of dynamic data structures. Patrascu conjectured that any data structure for the Multiphase problem must make $n^\epsilon$ cell-probes in either the update or query phase, and showed that this would imply similar $unconditional$ lower bounds on many important dynamic data structure problems. Alas, there has been almost no progress on this conjecture in the past decade since its introduction. 

We show an $\tilde{\Omega}(\sqrt{n})$ cell-probe lower bound on the Multiphase problem for data structures with general (adaptive) updates, and queries with unbounded but "layered" adaptivity. This result captures all known set-intersection data structures  and significantly strengthens previous Multiphase lower bounds, which only captured non-adaptive data structures.
Our main technical result is a communication lower bound on a 4-party variant of Patrascu's Number-On-Forehead  Multiphase game, using information complexity techniques.  We also show that a lower bound on Patrascu's original NOF game would imply a polynomial ($n^{1+\epsilon}$) lower bound on the number of wires of any constant-depth circuit with $arbitrary$ gates computing a random $\tilde{O}(n)\times n$ $linear$ operator $x \mapsto Ax$, a long-standing open problem in circuit complexity. This suggests that the NOF conjecture is much stronger than its data structure counterpart.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/144"><span class="datestr">at October 29, 2019 10:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/10/29/multiple-postdoctoral-fellowships-in-quantum-information-at-cu-boulder-center-for-theory-of-quantum-matter-apply-by-december-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/10/29/multiple-postdoctoral-fellowships-in-quantum-information-at-cu-boulder-center-for-theory-of-quantum-matter-apply-by-december-1-2019/">Multiple postdoctoral fellowships in quantum information at CU Boulder Center for Theory of Quantum Matter (apply by December 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Successful candidates will interact with CTQM faculty (O. DeWolfe, V. Gurarie, M. Hermele, M. Holland, E. Knill, A. Lucas, R. Nandkishore, E. Neil, L. Radzihovsky, A. M. Rey, P. Romatschke, G. Smith) and can also work with faculty throughout the Boulder Physics Department &amp; JILA. Applications esp. encouraged from candidates whose interests and/or expertise span traditionally distinct subfields.</p>
<p>Website: <a href="https://jobs.colorado.edu/jobs/JobDetail/?jobId=21755">https://jobs.colorado.edu/jobs/JobDetail/?jobId=21755</a><br />
Email: Graeme.Smith@colorado.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/10/29/multiple-postdoctoral-fellowships-in-quantum-information-at-cu-boulder-center-for-theory-of-quantum-matter-apply-by-december-1-2019/"><span class="datestr">at October 29, 2019 07:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://adamsheffer.wordpress.com/?p=5464">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sheffer.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://adamsheffer.wordpress.com/2019/10/29/incidences-open-problems-part-2/">Incidences: Open Problems (part 2)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We now continue our journey of seeing how we still don’t know much about geometric incidences. So far, we looked at two main problems concerning incidences with curves in the plane (see the first post of the series). It might make sense to move to study incidences in higher dimensions. Instead, we are now regressing […]</div>







<p class="date">
by Adam Sheffer <a href="https://adamsheffer.wordpress.com/2019/10/29/incidences-open-problems-part-2/"><span class="datestr">at October 29, 2019 06:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3222567344389850699">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/09/random-non-partisan-thoughts-on-prez.html">Random non-partisan thoughts on the Prez Election</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
This post is non-partisan, but in the interest of full disclosure I disclose that I will almost surely be voting for the Democratic Nominee. And I say <i>almost surely</i> because very weird things could happen.I can imagine a republican saying, in 2015 <i>I will almost surely be voting for the Republican Nominee</i> and then later deciding to not vote for Trump. <br />
<br />
<br />
<i>My Past Predictions</i>: Early on in 2007 I predicted it would be Obama vs McCain and that Obama would win. Was I smart or lucky? Early in 2011 I predicted Paul Ryan would be the Rep. Candidate. Early in 2015 and even into 2016 I predicted  that Trump would not get the nomination. After he got the nomination I predicted  he would not become president. So, in answer to my first question, I was lucky not smart. Having said all of this I predict that the Dem. candidate will be Warren. Note- this is an honest prediction, not one fueled by what I want to see happen. I predict Warren since she seems to be someone who can bridge the so-called establishment and the so-called left (I dislike the terms LEFT and RIGHT since issues and views change over time). Given my past record I would not take me too seriously. Also, since this prediction is not particularly unusual, if I am right this would NOT be impressive (My Obama prediction was impressive, and my Paul Ryan prediction would have been very impressive had I been right.)<br />
<br />
<i>Electability</i>: My spell checker doesn't think its a word. Actually it shouldn't be a word. It's a stupid concept. Recall<br />
<br />
JFK was unelectable since he was Catholic. <br />
<br />
Ronald Reagan was unelectable because he was too conservative.<br />
<br />
A draft dodging adulterer named Bill Clinton could not possible beat a sitting president who just won a popular war.<br />
<br />
Nobody named Barack Hussein Obama, who is half-black,  could possibly get the nomination, never mind the presidency. And Hillary had the nomination locked up in 2008--- she had no any serious challengers. <br />
<br />
(An article in <i>The New Republic</i> in 2007 predicted a brokered convention for the Republicans where Fred Thompson, Mitt Romney, and Rudy Guilliani would split the vote, and at the same time a cake walk for Hillary Clinton with<br />
Barak Obama winning Illinois in the primaries but not much else. Recall that 2008 was McCain vs Obama.)<br />
<br />
Donald Trump will surely be stopped from getting the nomination because, in the end, <a href="https://www.amazon.com/Party-Decides-Presidential-Nominations-American/dp/0226112373/ref=cm_cr_arp_d_product_top?ie=UTF8">The Party Decides</a>.<br />
<br />
Republican voters in 2016  will prefer  Rubio to Trump since Marco is more electable AND more conservative. Hence, in the space of Rep. Candidates, Rubio dominates Trump. So, by simple game theory, Trump can't get the nomination.  The more electable Rubio, in the 2016 primaries, won Minnesota, Wash DC,  and Puerto Rico (Puerto Rico has a primary. Really!) One of my friends thought he also won Guam (Guam?) but I could not find evidence of that on the web. Okay, so why did Trump win? <i>Because voters are not game theorists.</i><br />
<br />
ANYWAY, my point is that how can anyone take the notion of electability seriously when unelectable people have gotten elected?<br />
<br />
<i>Primaries</i>: Dem primary  voters are torn between who they want to be president and who can beat Trump.  Since its so hard to tell who can beat who, I would recommend voting for who you like and not say stupid things like<br />
<br />
American would never elect  a 76 year old socialist whose recently had a heart attack.<br />
<br />
or<br />
<br />
Trump beat a women in 2016 so we can't nominate a women<br />
<br />
or<br />
<br />
America is not ready to elect a gay president yet. (America is never ready to do X until after it does X and then the pundits ret-con their opinions.For example, of course America is ready for Gay-Marriage. Duh.)<br />
<br />
<i>Who won the debate?<br />
</i> Whoever didn't bother watching it :-). I think the question is stupid and has become who got out a clever sound bite. We need sound policy, not sound bites!</div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/09/random-non-partisan-thoughts-on-prez.html"><span class="datestr">at October 28, 2019 02:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16320">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/">Quantum Supremacy At Last?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>What it takes to understand and verify the claim</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/10/martinis1.png"><img width="153" alt="" src="https://rjlipton.files.wordpress.com/2019/10/martinis1.png?w=153&amp;h=180" class="alignright wp-image-16322" height="180" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from 2014 <i>Wired</i> <a href="https://www.wired.com/2014/09/martinis/">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Martinis of U.C. Santa Barbara and Google is the <em>last</em> author of a <a href="https://www.nature.com/articles/s41586-019-1666-5">paper</a> published Wednesday in <em>Nature</em> that claims to have demonstrated a task executed with minimum effort by a quantum computer that no classical computer can emulate without expending Herculean—or Sisyphean—effort. </p>
<p>
Today we present a lay understanding of the claim and discuss degrees of establishing it.</p>
<p>
There are 76 other authors of the paper. The first 75 are alphabetical, then comes Hartmut Neven before Martinis. Usually pride of place goes to the first author, but that depends on size. Martinis is also the corresponding author. The cox in a rowing race rides at the rear. We have discussed aspects of papers with a huge number of authors <a href="https://rjlipton.wordpress.com/2014/02/13/seeing-atoms/">here</a>. </p>
<p>
Three planks of a quantum supremacy claim are:</p>
<ol>
<li>
<em>Build a physical device capable of a nontrivial sampling task.</em> <p></p>
</li><li>
<em>Prove that it gains advantage over known classical approaches.</em> <p></p>
</li><li>
<em>Prove that comparable classical hardware cannot gain such advantage.</em>
</li></ol>
<p>
Scott Aaronson not only has made <a href="https://www.scottaaronson.com/blog/?p=4317">two</a> great <a href="https://www.scottaaronson.com/blog/?p=4372">posts</a> on these and many other aspects of the claim, he independently proposed in 2015 the sampling task that was programmed, and he analyzed it in a foundational <a href="https://arxiv.org/abs/1612.05903">paper</a> with Lijie Chen of MIT. Researchers at Google had already been thinking along those lines, and they anchored the team composed from numerous other institutions as well. As if on cue—just a couple days before Wednesday’s announcement—a group from IBM put out a <a href="https://www.ibm.com/blogs/research/2019/10/on-quantum-supremacy/">post</a> and <a href="https://arxiv.org/abs/1910.09534">paper</a> taking issue with the argument for the third plank.</p>
<p>
We’ll start with the task and go in order 1-3-2.</p>
<p>
</p><p></p><h2> The Task </h2><p></p>
<p></p><p>
Any <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit quantum circuit <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> and input <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> induces a probability distribution <img src="https://s0.wp.com/latex.php?latex=%7BD_C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_C}" class="latex" title="{D_C}" /> on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0,1\}^n}" class="latex" title="{\{0,1\}^n}" />. Because it will not matter if we prepend up to <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> NOT gates to <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, we may suppose <img src="https://s0.wp.com/latex.php?latex=%7Bx+%3D+0%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x = 0^n}" class="latex" title="{x = 0^n}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7BC%280%5En%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C(0^n)}" class="latex" title="{C(0^n)}" /> is a unit complex vector of length <img src="https://s0.wp.com/latex.php?latex=%7BN+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N = 2^n}" class="latex" title="{N = 2^n}" /> with entries <img src="https://s0.wp.com/latex.php?latex=%7Ba_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a_z}" class="latex" title="{a_z}" /> corresponding to possible outputs <img src="https://s0.wp.com/latex.php?latex=%7Bz+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z \in \{0,1\}^n}" class="latex" title="{z \in \{0,1\}^n}" />. Then the probability of getting <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> by a final measurement of all qubits is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++p_z+%3D+D_C%28z%29+%3D+%7Ca_z%7C%5E2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  p_z = D_C(z) = |a_z|^2. " class="latex" title="\displaystyle  p_z = D_C(z) = |a_z|^2. " /></p>
<p>
Next we consider probability distributions <img src="https://s0.wp.com/latex.php?latex=%7BD_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_1}" class="latex" title="{D_1}" /> that are generated uniformly at random by the following process, for some <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cgeq+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \geq n}" class="latex" title="{r \geq n}" /> and taking <img src="https://s0.wp.com/latex.php?latex=%7BR+%3D+2%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R = 2^r}" class="latex" title="{R = 2^r}" />:</p>
<blockquote><p><b> </b> <em> for <img src="https://s0.wp.com/latex.php?latex=%7Bi+%3D+1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i = 1}" class="latex" title="{i = 1}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />:<br />
   choose a <img src="https://s0.wp.com/latex.php?latex=%7Bz+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{z \in \{0,1\}^n}" class="latex" title="{z \in \{0,1\}^n}" /> uniformly at random;<br />
   increment its probability <img src="https://s0.wp.com/latex.php?latex=%7BD_1%28z%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{D_1(z)}" class="latex" title="{D_1(z)}" /> by <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7BR%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\frac{1}{R}}" class="latex" title="{\frac{1}{R}}" />. </em>
</p></blockquote>
<p></p><p>
Here we intend <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> to be the number of binary nondeterministic gates in the circuit. In place of Hadamard gates the experimental circuits get their nondeterminism from these three single-qubit gates (ignoring global phase for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BY%7D%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbf{Y}^{1/2}}" class="latex" title="{\mathbf{Y}^{1/2}}" /> in particular): </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cmathbf%7BX%7D%5E%7B1%2F2%7D+%3D+%5Cfrac%7B1%7D%7B2%7D%5Cbegin%7Bbmatrix%7D+1+%2B+i+%26+1+-+i+%5C%5C+1+-+i+%26+1+%2B+i+%5Cend%7Bbmatrix%7D%2C%7E+%5Cmathbf%7BY%7D%5E%7B1%2F2%7D+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%5Cbegin%7Bbmatrix%7D+1+%26+-1+%5C%5C+1+%26+1+%5Cend%7Bbmatrix%7D%2C%7E+%5Cmathbf%7BW%7D%5E%7B1%2F2%7D+%3D+%5Cfrac%7B1%7D%7B2%7D%5Cbegin%7Bbmatrix%7D+1+%2B+i+%26+-+i%5Csqrt%7B2%7D+%5C%5C+%5Csqrt%7B2%7D+%26+1+%2B+i+%5Cend%7Bbmatrix%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \mathbf{X}^{1/2} = \frac{1}{2}\begin{bmatrix} 1 + i &amp; 1 - i \\ 1 - i &amp; 1 + i \end{bmatrix},~ \mathbf{Y}^{1/2} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 &amp; -1 \\ 1 &amp; 1 \end{bmatrix},~ \mathbf{W}^{1/2} = \frac{1}{2}\begin{bmatrix} 1 + i &amp; - i\sqrt{2} \\ \sqrt{2} &amp; 1 + i \end{bmatrix}. " class="latex" title="\displaystyle  \mathbf{X}^{1/2} = \frac{1}{2}\begin{bmatrix} 1 + i &amp; 1 - i \\ 1 - i &amp; 1 + i \end{bmatrix},~ \mathbf{Y}^{1/2} = \frac{1}{\sqrt{2}}\begin{bmatrix} 1 &amp; -1 \\ 1 &amp; 1 \end{bmatrix},~ \mathbf{W}^{1/2} = \frac{1}{2}\begin{bmatrix} 1 + i &amp; - i\sqrt{2} \\ \sqrt{2} &amp; 1 + i \end{bmatrix}. " /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D+%3D+%5Cfrac%7B1%7D%7B%5Csqrt%7B2%7D%7D%28%5Cmathbf%7BX%7D+%2B+%5Cmathbf%7BY%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbf{W} = \frac{1}{\sqrt{2}}(\mathbf{X} + \mathbf{Y})}" class="latex" title="{\mathbf{W} = \frac{1}{\sqrt{2}}(\mathbf{X} + \mathbf{Y})}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BY%7D+%3D+%5Cbegin%7Bbmatrix%7D+0+%26+-i+%5C%5C+i+%26+0+%5Cend%7Bbmatrix%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbf{Y} = \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}}" class="latex" title="{\mathbf{Y} = \begin{bmatrix} 0 &amp; -i \\ i &amp; 0 \end{bmatrix}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbf{X}}" class="latex" title="{\mathbf{X}}" /> is another name for NOT. The difference from using Hadamard gates matters to technical analysis of the distributions <img src="https://s0.wp.com/latex.php?latex=%7BD_C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_C}" class="latex" title="{D_C}" /> but the interplay between quantum nondeterministic gates and classical random coins remains in force. </p>
<p>
The choice of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BX%7D%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbf{X}^{1/2}}" class="latex" title="{\mathbf{X}^{1/2}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BY%7D%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbf{Y}^{1/2}}" class="latex" title="{\mathbf{Y}^{1/2}}" />, or <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbf%7BW%7D%5E%7B1%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbf{W}^{1/2}}" class="latex" title="{\mathbf{W}^{1/2}}" /> is itself uniformly random at each point where a single-qubit gate is used, except for not repeating the same gate on the same qubit, and those choices determine <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. Now we can give an initial statement of the task tailored to what the paper achieves:</p>
<blockquote><p><b> </b> <em> Given randomly-generated quantum circuits <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> as inputs, distinguish <img src="https://s0.wp.com/latex.php?latex=%7BD_C%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{D_C}" class="latex" title="{D_C}" /> with high probability from any <img src="https://s0.wp.com/latex.php?latex=%7BD_1%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{D_1}" class="latex" title="{D_1}" />. </em>
</p></blockquote>
<p></p><p>
In more detail, the object is to take a number <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" /> and moderately large integer <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, both dictated by practical elements of the experiment, and fulfill this task statement:</p>
<blockquote><p><b> </b> <em> Given randomly-generated <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />, generate samples <img src="https://s0.wp.com/latex.php?latex=%7Bz_1%2C...%2Cz_k+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{z_1,...,z_k \in \{0,1\}^n}" class="latex" title="{z_1,...,z_k \in \{0,1\}^n}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Bk%7D%28D_C%28z_1%29+%2B+%5Ccdots+D_C%28z_k%29%29+%5Cgeq+1+%2B+%5Cdelta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\frac{1}{k}(D_C(z_1) + \cdots D_C(z_k)) \geq 1 + \delta}" class="latex" title="{\frac{1}{k}(D_C(z_1) + \cdots D_C(z_k)) \geq 1 + \delta}" />. </em>
</p></blockquote>
<p></p><p>
It’s important to note that there are two <em>stages</em> of randomness: one over <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> which chooses <img src="https://s0.wp.com/latex.php?latex=%7BD_C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_C}" class="latex" title="{D_C}" />, and then the stage of measuring after (perhaps imperfectly) executing <img src="https://s0.wp.com/latex.php?latex=%7BC%280%5En%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C(0^n)}" class="latex" title="{C(0^n)}" />. The latter can be repeated to get a large sample of strings <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> for a given <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. The nature of the former stage matters most to justifying how to interpret tests of the samples and to closing loopholes. Our <img src="https://s0.wp.com/latex.php?latex=%7BD_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_1}" class="latex" title="{D_1}" /> does not signify having uniform distribution in the latter sampling, but rather covers classical alternatives in the former stage that (with overwhelming probability) belong to a class we call <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_1}" class="latex" title="{\mathcal{D}_1}" />. The <img src="https://s0.wp.com/latex.php?latex=%7BD_C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_C}" class="latex" title="{D_C}" /> for random <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> will (again w.o.p.) belong to a class <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_2}" class="latex" title="{\mathcal{D}_2}" /> which we explain next.</p>
<p>
</p><p></p><h2> The World Series of Quantum Computing </h2><p></p>
<p></p><p>
In honor of the baseball World Series, we offer a baseball analogy. To make differences sharper to see, we take <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = n}" class="latex" title="{r = n}" />, so <img src="https://s0.wp.com/latex.php?latex=%7BR+%3D+N+%3D+2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R = N = 2^n}" class="latex" title="{R = N = 2^n}" />. This is not what the experiment does: their biggest instance has 20 layers totaling <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%2C%5C%21113%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = 1,\!113}" class="latex" title="{r = 1,\!113}" /> nondeterministic single-qubit gates (plus <img src="https://s0.wp.com/latex.php?latex=%7B430%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{430}" class="latex" title="{430}" /> two-qubit gates) on the <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+53%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 53}" class="latex" title="{n = 53}" /> qubits. But let us continue.</p>
<p>
We are distributing <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> units of probability among <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> “batters” <img src="https://s0.wp.com/latex.php?latex=%7Bz+%5Cin+%5C%7B0%2C1%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z \in \{0,1\}^n}" class="latex" title="{z \in \{0,1\}^n}" />. A batter who gets two units hits a double, three units makes a triple, and so on. The key distinction is between the familiar batting average and the <em>slugging average</em>, which averages all the bases scored with hits:</p>
<ul>
<li>
The chance of making an out—that is, getting no units—is <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cfrac%7BN-1%7D%7BN%7D%29%5EN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\frac{N-1}{N})^N}" class="latex" title="{(\frac{N-1}{N})^N}" /> which is approximately <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Be%7D+%3D+0.367879%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{1}{e} = 0.367879\dots}" class="latex" title="{\frac{1}{e} = 0.367879\dots}" /> <p></p>
</li><li>
The chance of hitting a single is also about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7Be%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{1}{e}}" class="latex" title="{\frac{1}{e}}" />, leaving <img src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B2%7D%7Be%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 - \frac{2}{e}}" class="latex" title="{1 - \frac{2}{e}}" /> as the frequency of getting an extra-base hit—which makes <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> a “heavy hitter.” <p></p>
</li><li>
From <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> batters chosen uniformly at random, their expected batting average will be <img src="https://s0.wp.com/latex.php?latex=%7B1+-+%5Cfrac%7B1%7D%7Be%7D+%3D+0.632%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 - \frac{1}{e} = 0.632\dots}" class="latex" title="{1 - \frac{1}{e} = 0.632\dots}" />. <p></p>
</li><li>
Their expected slugging average, however, will just be <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />: they expect <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> units to be distributed among them.
</li></ul>
<p>
Thus with respect to a random <img src="https://s0.wp.com/latex.php?latex=%7BD_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_1}" class="latex" title="{D_1}" />, and without any knowledge of <img src="https://s0.wp.com/latex.php?latex=%7BD_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_1}" class="latex" title="{D_1}" />, a chosen team of <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> hitters cannot expect to have a joint slugging average higher than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. Moreover, for any fixed <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" />, the chance of getting a slugging average higher than <img src="https://s0.wp.com/latex.php?latex=%7B1+%2B+%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 + \delta}" class="latex" title="{1 + \delta}" /> tails away exponentially in <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> (provided <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> also grows). </p>
<p>
With respect to <img src="https://s0.wp.com/latex.php?latex=%7BD_C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_C}" class="latex" title="{D_C}" />, however, a quantum device can do better. Google’s device programs itself given <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> as the blueprint. So it just executes <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> and measures all qubits to sample the output. Finding its own heavy hitters is what a quantum circuit is good at. The probability of getting a hitter who hits a triple is magnified by <img src="https://s0.wp.com/latex.php?latex=%7B3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3}" class="latex" title="{3}" /> compared to a uniform choice. Moreover, <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> will never output a string with zero hits—a “can’t miss” property denied to a classical reader of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. For large <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> the probability distribution approaches <img src="https://s0.wp.com/latex.php?latex=%7Bxe%5E%7B-x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{xe^{-x}}" class="latex" title="{xe^{-x}}" /> and the slugging expectation is approximately </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cint_0%5E%5Cinfty+x%5E2+e%5E%7B-x%7D+%3D+2.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \int_0^\infty x^2 e^{-x} = 2. " class="latex" title="\displaystyle  \int_0^\infty x^2 e^{-x} = 2. " /></p>
<p>That is, a team <img src="https://s0.wp.com/latex.php?latex=%7Bz_1%2C%5Cdots%2Cz_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z_1,\dots,z_k}" class="latex" title="{z_1,\dots,z_k}" /> drafted by sampling from random quantum circuits <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> expects to have a slugging average near <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />. This defines the class <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_2}" class="latex" title="{\mathcal{D}_2}" />. If <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> works perfectly, the average will surpass <img src="https://s0.wp.com/latex.php?latex=%7B1+%2B+%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 + \delta}" class="latex" title="{1 + \delta}" /> whenever <img src="https://s0.wp.com/latex.php?latex=%7B0+%3C+%5Cdelta+%3C+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 &lt; \delta &lt; 1}" class="latex" title="{0 &lt; \delta &lt; 1}" /> with near certainty as <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{N}" class="latex" title="{N}" /> grows. </p>
<p>
Google’s circuits have up to <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+20n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = 20n}" class="latex" title="{r = 20n}" />, so <img src="https://s0.wp.com/latex.php?latex=%7BR+%5Cgg+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R \gg N}" class="latex" title="{R \gg N}" />. Then the “can’t miss” aspect of the quantum advantage is less sharp but the <img src="https://s0.wp.com/latex.php?latex=%7Bxe%5E%7B-x%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{xe^{-x}}" class="latex" title="{xe^{-x}}" /> approximation is closer and the idea of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_2}" class="latex" title="{\mathcal{D}_2}" /> is the same. The nature of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_2}" class="latex" title="{\mathcal{D}_2}" /> can actually be <em>seen</em> from point intensities in <a href="https://en.wikipedia.org/wiki/Speckle_pattern">speckle</a> patterns of laser light:</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2019/10/375px-objective_speckle.jpg"><img width="150" alt="" src="https://rjlipton.files.wordpress.com/2019/10/375px-objective_speckle.jpg?w=150&amp;h=150" class="aligncenter wp-image-16324" height="150" /></a></p>
<p>
</p><p></p><h2> Real-World Execution </h2><p></p>
<p></p><p>
The practical challenge is that the implementation of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> is not perfect. The consequence of an error in the final output is severe. The heavy-hitter outputs <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> of a random <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> are generally not bit-wise similar, so sampling their neighbors is like sampling uniform distribution. As the paper says, “A single bit or phase flip over the course of the algorithm will completely shuffle the speckle pattern and result in close to zero fidelity.”</p>
<p>
Their circuits are sufficiently random that effects of sporadic errors over millions of samples can be modeled by a simple equation using quantum mixed states. We shortcut the paper’s physical analysis by drawing on John Preskill’s illustration of a <em>de-polarizing channel</em> in <a href="http://www.theory.caltech.edu/~preskill/ph219/chap3_15.pdf">chapter 3</a> of his wonderful online <a href="http://www.theory.caltech.edu/~preskill/ph219/ph219_2018-19">notes</a> on quantum computation to reach the same equation (<a href="https://rjlipton.wordpress.com/feed/#F">1</a>). The modeling has informative symmetry when the errors of a <b>bit flip</b>, <b>phase flip</b>, or both are considered equally likely with probability <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{p}{3}}" class="latex" title="{\frac{p}{3}}" />. The action on the entangled pair <img src="https://s0.wp.com/latex.php?latex=%7B%7C%5CPhi%5E%2B%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|\Phi^+\rangle}" class="latex" title="{|\Phi^+\rangle}" /> in the <a href="https://en.wikipedia.org/wiki/Bell_state#Bell_basis">Bell basis</a> is given by the density matrix evolution <img src="https://s0.wp.com/latex.php?latex=%7B%5Crho+%3D+%7C%5CPhi%5E%2B%5Crangle%5Clangle%5CPhi%5E%2B%7C+%5Cmapsto+%5Crho%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\rho = |\Phi^+\rangle\langle\Phi^+| \mapsto \rho'}" class="latex" title="{\rho = |\Phi^+\rangle\langle\Phi^+| \mapsto \rho'}" /> where </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Crho%27+%26%3D%26+%281+-+p%29%7C%5CPhi%5E%2B%5Crangle%5Clangle%5CPhi%5E%2B%7C+%5C%3B%2B%5C%3B+%5Cfrac%7Bp%7D%7B3%7D%5Cleft%28%7C%5CPsi%5E%2B%5Crangle%5Clangle%5CPsi%5E%2B%7C+%5C%3B%2B%5C%3B+%7C%5CPhi%5E-%5Crangle%5Clangle%5CPhi%5E-%7C+%5C%3B%2B%5C%3B+%7C%5CPsi%5E-%5Crangle%5Clangle%5CPsi%5E-%7C%5Cright%29%5C%5C+%7E%7E%7E%5C%5C+%26%3D%26+%281+-+p%27%29+%7C%5CPhi%5E%2B%5Crangle%5Clangle%5CPhi%5E%2B%7C+%5C%3B%2B%5C%3B+p%27%5Cfrac%7BI%7D%7B4%7D%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  \rho' &amp;=&amp; (1 - p)|\Phi^+\rangle\langle\Phi^+| \;+\; \frac{p}{3}\left(|\Psi^+\rangle\langle\Psi^+| \;+\; |\Phi^-\rangle\langle\Phi^-| \;+\; |\Psi^-\rangle\langle\Psi^-|\right)\\ ~~~\\ &amp;=&amp; (1 - p') |\Phi^+\rangle\langle\Phi^+| \;+\; p'\frac{I}{4}, \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  \rho' &amp;=&amp; (1 - p)|\Phi^+\rangle\langle\Phi^+| \;+\; \frac{p}{3}\left(|\Psi^+\rangle\langle\Psi^+| \;+\; |\Phi^-\rangle\langle\Phi^-| \;+\; |\Psi^-\rangle\langle\Psi^-|\right)\\ ~~~\\ &amp;=&amp; (1 - p') |\Phi^+\rangle\langle\Phi^+| \;+\; p'\frac{I}{4}, \end{array} " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7Bp%27+%3D+%5Cfrac%7B4%7D%7B3%7D+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p' = \frac{4}{3} p}" class="latex" title="{p' = \frac{4}{3} p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7BI%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{I}{4}}" class="latex" title="{\frac{I}{4}}" /> is the density matrix of the completely mixed two-qubit state which is just a classical distribution. This presumes <img src="https://s0.wp.com/latex.php?latex=%7Bp+%5Cleq+%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p \leq \frac{3}{4}}" class="latex" title="{p \leq \frac{3}{4}}" />; note that <img src="https://s0.wp.com/latex.php?latex=%7Bp+%3D+%5Cfrac%7B3%7D%7B4%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p = \frac{3}{4}}" class="latex" title="{p = \frac{3}{4}}" /> completely mixes the Bell basis already. The <b>fidelity</b> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7B%5Crho%7D%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\vec{\rho}'}" class="latex" title="{\vec{\rho}'}" /> to the original state is then given by </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F+%3D+%5Clangle%5CPhi%5E%2B%7C%5Crho%27%7C%5CPhi%5E%2B%5Crangle+%3D+1+-+p%27.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F = \langle\Phi^+|\rho'|\Phi^+\rangle = 1 - p'. " class="latex" title="\displaystyle  F = \langle\Phi^+|\rho'|\Phi^+\rangle = 1 - p'. " /></p>
<p>
This modeling already indicates that with <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> serial opportunities for error the fidelity will decay as <img src="https://s0.wp.com/latex.php?latex=%7B%281+-+p%27%29%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1 - p')^m}" class="latex" title="{(1 - p')^m}" />.  The Google team found low ‘crosstalk’ between qubits and they used exactly this expression in the form <img src="https://s0.wp.com/latex.php?latex=%7B%281+-+%5Cfrac%7Be_1%7D%7B1+-+1%2FD%5E2%7D%29%5Em%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1 - \frac{e_1}{1 - 1/D^2})^m}" class="latex" title="{(1 - \frac{e_1}{1 - 1/D^2})^m}" />, evidently with <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> being the native gate error rate they call <img src="https://s0.wp.com/latex.php?latex=%7Be_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e_1}" class="latex" title="{e_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BD+%3D+2%5Ek%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D = 2^k,}" class="latex" title="{D = 2^k,}" /> where having <img src="https://s0.wp.com/latex.php?latex=%7Bk%3D1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k=1}" class="latex" title="{k=1}" /> for single-qubit gates supplies the factor <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B2%5E%7B2k%7D%7D%7B2%5E%7B2k%7D+-+1%7D+%3D+%5Cfrac%7B4%7D%7B3%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{2^{2k}}{2^{2k} - 1} = \frac{4}{3}}" class="latex" title="{\frac{2^{2k}}{2^{2k} - 1} = \frac{4}{3}}" />.<br />
The error <img src="https://s0.wp.com/latex.php?latex=%7Be_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e_2}" class="latex" title="{e_2}" /> for the two-qubit gates is similarly represented.  (The full modeling in the <a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-019-1666-5/MediaObjects/41586_2019_1666_MOESM1_ESM.pdf">supplement</a>, section V, is more refined.)</p>
<p>
By observing their benchmarks (discussed below) for varying small <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> they could calculate the decay concretely and hence estimate values of <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> for the vast majority of runs with larger <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" />.  The random nature of the circuits <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> evidently makes covariance of errors that could systematically upset this modeling negligible.  Thus they can conclude that their device effectively samples from the distribution <a name="F"></a></p><a name="F">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%7C%5Clangle+z+%5C%3B%7C%5C%3B+C+%5C%3B%7C%5C%3B+0%5En%5Crangle%7C%5E2+%5C%3B%5C%3B%2B%5C%3B%5C%3B+%281+-+F%29%5Cfrac%7B1%7D%7BN%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F|\langle z \;|\; C \;|\; 0^n\rangle|^2 \;\;+\;\; (1 - F)\frac{1}{N}. \ \ \ \ \ (1)" class="latex" title="\displaystyle  F|\langle z \;|\; C \;|\; 0^n\rangle|^2 \;\;+\;\; (1 - F)\frac{1}{N}. \ \ \ \ \ (1)" /></p>
</a><p><a name="F"></a> Such distributions can be said to belong to the class <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_%7B1+%2B+F%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_{1 + F}}" class="latex" title="{\mathcal{D}_{1 + F}}" />. The paper reports that their <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is driven below <img src="https://s0.wp.com/latex.php?latex=%7B0.01%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0.01}" class="latex" title="{0.01}" /> but stays above <img src="https://s0.wp.com/latex.php?latex=%7B0.001%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0.001}" class="latex" title="{0.001}" /> in trials. This bounds the range of the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> they can separate by. That <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> is separated from zero achieves the first plank and starts on the second. The third needs attention first, however. </p>
<p>
</p><p></p><h2> The Third Plank </h2><p></p>
<p></p><p>
Both <em>concrete</em> and <em>asymptotic</em> complexity evidence matter for the third plank, the former for now and the latter for how <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> and everything else may scale up in the future. In asymptotic complexity, we still don’t know that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BPSPACE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{PSPACE}}" class="latex" title="{\mathsf{PSPACE}}" />, which sandwich the quantum feasible class <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BBQP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{BQP}}" class="latex" title="{\mathsf{BQP}}" />, are different. Thus asymptotic evidence about polynomial bounds must be conditional. Asymptotic evidence about linear time bounds can be sharper but then tends to be conditioned on forms of <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">SETH</a> in ways we still find <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">puzzling</a>.</p>
<p>
Lower bounds in concrete complexity are less known and have a self-defeating aspect: We are trying to say that any program <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> run for less than an infeasible time <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" /> must fail. But we can’t run <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> for time <img src="https://s0.wp.com/latex.php?latex=%7BT-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T-1}" class="latex" title="{T-1}" /> to show that it fails because time <img src="https://s0.wp.com/latex.php?latex=%7BT-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T-1}" class="latex" title="{T-1}" /> is just as infeasible as time <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />. The best we can do is run <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> for a feasible <img src="https://s0.wp.com/latex.php?latex=%7BT_0+%5Cll+T%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_0 \ll T}" class="latex" title="{T_0 \ll T}" />, either (i) on a smaller task size, or (ii) on the original task but argue it doesn’t show <em>progress</em>. Neither is the same; we <a href="https://rjlipton.wordpress.com/2010/08/28/lower-bounds-and-progressive-algorithms/">made</a> some <a href="https://rjlipton.wordpress.com/2012/11/17/progress-on-progressive-algorithms/">attempts</a> on (ii). </p>
<p>
What the paper does instead is argue that a particular classical approach <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> (also from the Aaronson-Chen paper) would take 10,000 years on today’s hardware. This reminds us of a famous 1977 “Mathematical Games” <a href="https://simson.net/ref/1977/Gardner_RSA.pdf">column</a> by Martin Gardner, which quotes an estimate by Ron Rivest that for factoring a 126-digit number on then-current hardware, “the running time required would be about 40 quadrillion years!” It took only until <a href="https://en.wikipedia.org/wiki/The_Magic_Words_are_Squeamish_Ossifrage">1994</a> for this to be broken. Sure enough, IBM calculated that a more-clever implementation of <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> on the <a href="https://en.wikipedia.org/wiki/Summit_(supercomputer)">Summit</a> supercomputer would take under 3 days. The point is not so much that the Summit hardware is comparable as that estimates based on what are currently thought to be the best possible (classical) methods need asterisks.</p>
<p>
On the asymptotic side, the last section (XI) of the paper’s 66-page <a href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41586-019-1666-5/MediaObjects/41586_2019_1666_MOESM1_ESM.pdf">supplement</a> proves a theorem toward showing that a classical simulation from <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_%7B1+%2B+%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_{1 + \delta}}" class="latex" title="{\mathcal{D}_{1 + \delta}}" /> that scales polynomially with <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> would collapse <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7B%5C%23P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{\#P}}" class="latex" title="{\mathsf{\#P}}" /> to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{AM}}" class="latex" title="{\mathsf{AM}}" />, and similarly for sub-exponential running times. It does not get all the way there, however: improvements would need to be made in upper bounds for approximation and for worst-case to average-case equivalence. Moreover, there is a difference from what their statistical testing achieves that we try to explain next. </p>
<p>
</p><p></p><h2> The Statistical Tests </h2><p></p>
<p></p><p>
We can cast the second plank in the general context of predictive modeling. Consider a forecaster who places estimates <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bq_i%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{q_i\}}" class="latex" title="{\{q_i\}}" /> on the true probabilities <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Bp_i%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{p_i\}}" class="latex" title="{\{p_i\}}" /> of various events. In the quantum case, the <img src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_i}" class="latex" title="{p_i}" /> come from distributions in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_%7B1%2BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_{1+F}}" class="latex" title="{\mathcal{D}_{1+F}}" />, where the <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> that applies to the latter sampling stage can be estimated based on the size and depth of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. The <img src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i}" class="latex" title="{q_i}" /> come from the physical quantum device—that is to say, from the strings <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> that it outputs. What’s needed is to compute the corresponding outcome probability <img src="https://s0.wp.com/latex.php?latex=%7Bq_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_z}" class="latex" title="{q_z}" /> analytically based on the given circuit <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. This must be done <em>classically</em>, and incurs the “<img src="https://s0.wp.com/latex.php?latex=%7BT_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T_0}" class="latex" title="{T_0}" />-versus-<img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />” issue discussed above.  <b>[See Addendum below.]</b></p>
<p>
But before we get to that issue, let’s say more from the viewpoint of predictive modeling. We measure how well the forecasts <img src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i}" class="latex" title="{q_i}" /> conform to the true <img src="https://s0.wp.com/latex.php?latex=%7Bp_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_i}" class="latex" title="{p_i}" /> by applying a prediction scoring <a href="https://en.wikipedia.org/wiki/Scoring_rule">rule</a>. If outcome <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> happens, then the <em>log-likelihood rule</em> assesses a penalty of </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_i+%3D+%5Clog%28%5Cfrac%7B1%7D%7Bq_i%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_i = \log(\frac{1}{q_i}). " class="latex" title="\displaystyle  L_i = \log(\frac{1}{q_i}). " /></p>
<p>This is zero if the outcome was predicted with certainty but goes to infinity if the individual <img src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i}" class="latex" title="{q_i}" /> is very low—which is an issue in the quantum case. The expected score based on the true probabilities is <a name="XE"></a></p><a name="XE">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++E%5BL_i%5D+%3D+%5Csum_i+p_i+%5Clog%28%5Cfrac%7B1%7D%7Bq_i%7D%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  E[L_i] = \sum_i p_i \log(\frac{1}{q_i}). \ \ \ \ \ (2)" class="latex" title="\displaystyle  E[L_i] = \sum_i p_i \log(\frac{1}{q_i}). \ \ \ \ \ (2)" /></p>
</a><p><a name="XE"></a> The log-likelihood rule is <b>strictly proper</b> insofar as the unique way to minimize <img src="https://s0.wp.com/latex.php?latex=%7BE%5BL_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E[L_i]}" class="latex" title="{E[L_i]}" /> is to set <img src="https://s0.wp.com/latex.php?latex=%7Bq_i+%3D+p_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i = p_i}" class="latex" title="{q_i = p_i}" /> for each <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. In human contexts this means the model has incentive to be as accurate as possible. For the quantum device, knowing the <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> that applies to its running of circuits <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> suffices to calculate <img src="https://s0.wp.com/latex.php?latex=%7BE%5BL_i%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E[L_i]}" class="latex" title="{E[L_i]}" /> as “<img src="https://s0.wp.com/latex.php?latex=%7BE_%7B1%2BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_{1+F}}" class="latex" title="{E_{1+F}}" />,” and hence to benchmark how accurately the device is conforming to the target.</p>
<p>
The formula (<a href="https://rjlipton.wordpress.com/feed/#XE">2</a>) is the <a href="https://en.wikipedia.org/wiki/Cross_entropy">cross-entropy</a> between the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bp%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\vec{p}}" class="latex" title="{\vec{p}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cvec%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\vec{q}}" class="latex" title="{\vec{q}}" /> distributions. It is advocated in several predecessor papers on quantum supremacy experiments, but in fact the team shifted to something simpler they call “linear cross-entropy.” They simply show that the <img src="https://s0.wp.com/latex.php?latex=%7Bq_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_z}" class="latex" title="{q_z}" /> from their samples collectively beat the “<img src="https://s0.wp.com/latex.php?latex=%7BE_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_1}" class="latex" title="{E_1}" />” that applies to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_1}" class="latex" title="{\mathcal{D}_1}" />—more simply put, that when summed over <img src="https://s0.wp.com/latex.php?latex=%7BT%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T}" class="latex" title="{T}" />-many trials <img src="https://s0.wp.com/latex.php?latex=%7Bz_t%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z_t}" class="latex" title="{z_t}" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1%7D%7BT%7D+%5Csum_%7Bt+%3D+1%7D%5ET+q_%7Bz_t%7D+%3E+%5Cfrac%7B1%7D%7BN%7D+%2B+%5Cdelta.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{1}{T} \sum_{t = 1}^T q_{z_t} &gt; \frac{1}{N} + \delta. \ \ \ \ \ (3)" class="latex" title="\displaystyle  \frac{1}{T} \sum_{t = 1}^T q_{z_t} &gt; \frac{1}{N} + \delta. \ \ \ \ \ (3)" /></p>
<p>This just boils down to giving a <a href="https://en.wikipedia.org/wiki/Standard_score">z-score</a> based on the modeling for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_1}" class="latex" title="{\mathcal{D}_1}" />. It is analogous to how I (Ken writing this) test for cheating at chess. We are flagging the physical device as getting surreptitious input from quantum to achieve a strength of <img src="https://s0.wp.com/latex.php?latex=%7B1+%2B+%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 + \delta}" class="latex" title="{1 + \delta}" /> compared to a “classical player” who is “rated” as having strength <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. </p>
<p>
The difference from showing that the device’s score from (<a href="https://rjlipton.wordpress.com/feed/#XE">2</a>) is within a hair of <img src="https://s0.wp.com/latex.php?latex=%7BE_%7B1%2BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_{1+F}}" class="latex" title="{E_{1+F}}" /> is that this is based on <img src="https://s0.wp.com/latex.php?latex=%7BE_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_1}" class="latex" title="{E_1}" />. To be sure, the paper shows that their <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" />-scores conform to those one would expect an “<img src="https://s0.wp.com/latex.php?latex=%7BE_%7B1%2BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E_{1+F}}" class="latex" title="{E_{1+F}}" />-rated” device to achieve. But this is still not the same as (<a href="https://rjlipton.wordpress.com/feed/#XE">2</a>). Whether it is tantamount for enough purposes—including the theorem about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{AM}}" class="latex" title="{\mathsf{AM}}" />—is where we’re most unsure, and we note distinctions between fully (classically) sampling and “spoofing” the statistical tests(s) raised by Scott (including directly in reply to me <a href="https://www.scottaaronson.com/blog/?p=4372#comment-1822570">here</a>) and others. The authors say that using “linear cross-entropy” gave sharper results and that they tried other (unspecified) measures. We wonder how much of the space of scoring rules familiar in predictive modeling has been tried, and whether rules having more gentle tail behavior for tiny <img src="https://s0.wp.com/latex.php?latex=%7Bq_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_i}" class="latex" title="{q_i}" /> than <img src="https://s0.wp.com/latex.php?latex=%7BL_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_i}" class="latex" title="{L_i}" /> might do better.</p>
<p>
Finally, there is the issue that the team were able to verify <img src="https://s0.wp.com/latex.php?latex=%7Bq_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_z}" class="latex" title="{q_z}" /> exactly only for circuits up to <img src="https://s0.wp.com/latex.php?latex=%7B43%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{43}" class="latex" title="{43}" /> qubits and/or with <img src="https://s0.wp.com/latex.php?latex=%7B14%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{14}" class="latex" title="{14}" /> levels, not <img src="https://s0.wp.com/latex.php?latex=%7B53%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{53}" class="latex" title="{53}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B20%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{20}" class="latex" title="{20}" /> levels. This creates a dilemma in that IBM’s paper may push them toward <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+60%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 60}" class="latex" title="{n = 60}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B70%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{70}" class="latex" title="{70}" />, but that increases the gap from instance sizes they can verify. This also pushes away from the possibly of observing the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BD%7D_%7B1%2BF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{D}_{1+F}}" class="latex" title="{\mathcal{D}_{1+F}}" /> nature of <img src="https://s0.wp.com/latex.php?latex=%7BD_C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D_C}" class="latex" title="{D_C}" /> more directly by finding repeated strings <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> in the second-stage sampling of a fixed <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />. The “birthday paradox” threshold for repeats is roughly <img src="https://s0.wp.com/latex.php?latex=%7B2%5E%7Bn%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^{n/2}}" class="latex" title="{2^{n/2}}" /> samples, which might be feasible for <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> around <img src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{50}" class="latex" title="{50}" /> (given the classical work needed for each <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" />, which IBM’s cleverness might speed) but not above <img src="https://s0.wp.com/latex.php?latex=%7B60%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{60}" class="latex" title="{60}" />. The distinguishing power of repeats drops further with <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" />. We intend to say more about these last few points, and we are sure there are many chapters still to write about supremacy experiments. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Is the evidence so far convincing to you? Is enough being done on the third plank to exclude possible clever classical use of the fact that the circuits <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> are given as “white boxes”? Are there possible loopholes? </p>
<p>
We would also be grateful to know where we may have oversimplified our characterization of the task and our analysis of the issues.</p>
<p></p><p><br />
<b>Addendum 10/28:</b> On further review, the “outcome probability” of a string <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> comes from first exhaustively computing the probability <img src="https://s0.wp.com/latex.php?latex=%7Br_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_z}" class="latex" title="{r_z}" /> that would result from error-free operation of <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> and plugging that in to make <img src="https://s0.wp.com/latex.php?latex=%7BFr_z+%2B+%281+-+F%29%5Cfrac%7B1%7D%7BN%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Fr_z + (1 - F)\frac{1}{N}.}" class="latex" title="{Fr_z + (1 - F)\frac{1}{N}.}" />  Although derived from the estimate of <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> and taking <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> from the device, this seems better to regard as the “true probability” <img src="https://s0.wp.com/latex.php?latex=%7Bp_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_z}" class="latex" title="{p_z}" />, rather than “<img src="https://s0.wp.com/latex.php?latex=%7Bq_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_z}" class="latex" title="{q_z}" />” as stated above.  The actual quantity to regard as “<img src="https://s0.wp.com/latex.php?latex=%7Bq_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_z}" class="latex" title="{q_z}" />” is not calculable and estimating it would require observing repeats from the physical device.  Equation (2) remains correct on principle, but as explained in these <a href="https://www.cs.cmu.edu/~odonnell/quantum18/lecture25.pdf">notes</a> by Ryan O’Donnell, the reversed equation is used instead: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++E%5BL%27_i%5D+%3D+%5Csum_z+q_z+%5Clog%28%5Cfrac%7B1%7D%7Bp_z%7D%29.+%5C+%5C+%5C+%5C+%5C+%282%27%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  E[L'_i] = \sum_z q_z \log(\frac{1}{p_z}). \ \ \ \ \ (2')" class="latex" title="\displaystyle  E[L'_i] = \sum_z q_z \log(\frac{1}{p_z}). \ \ \ \ \ (2')" /></p>
<p>
The difference is that <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog%28%5Cfrac%7B1%7D%7Bp_z%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log(\frac{1}{p_z})}" class="latex" title="{\log(\frac{1}{p_z})}" /> can be calculated, and while <img src="https://s0.wp.com/latex.php?latex=%7Bq_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_z}" class="latex" title="{q_z}" /> still cannot be, the act of sampling from the physical device estimates the idealized sum <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+q_i+%5Clog%28%5Cfrac%7B1%7D%7Bp_i%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_i q_i \log(\frac{1}{p_i})}" class="latex" title="{\sum_i q_i \log(\frac{1}{p_i})}" /> closely enough.  This switches the roles of “forecaster” and “forecastee,” but the optimality of <img src="https://s0.wp.com/latex.php?latex=%7Bq_z+%3D+p_z%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_z = p_z}" class="latex" title="{q_z = p_z}" /> remains valid and the target value is the same as before.  O’Donnell calls this inversion “slightly dicey” but (i) it was ultimately not used anyway, (ii) has an interpretation that regards the physical device as the ground truth, and (iii) may be equally amenable to asymptotic conditional hardness results.  Likewise “<img src="https://s0.wp.com/latex.php?latex=%7Bq_%7Bz_t%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_{z_t}}" class="latex" title="{q_{z_t}}" />” should be re-named as “<img src="https://s0.wp.com/latex.php?latex=%7Bp_%7Bz_t%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_{z_t}}" class="latex" title="{p_{z_t}}" />” in (3).]</p>
<p></p><p><br />
[Added more error-modeling details to the real-world section; some minor word changes; clarified how X,Y,W are chosen; addendum to clarify modeling issues.]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/"><span class="datestr">at October 27, 2019 01:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=18384">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/10/27/starting-today-kazhdan-sunday-seminar-computation-quantumness-symplectic-geometry-and-information/">Starting today: Kazhdan Sunday seminar: “Computation, quantumness, symplectic geometry, and information”</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Sunday, 27 October, 2019 – 14:00 to 16:00</p>
<p>Repeats every week every Sunday until Sat Feb 01 2020</p>
<p>Location: Ross 70</p>
<p>See also: <a href="https://mathematics.huji.ac.il/event/kazhdan-sunday-seminar-computation-quantumness-symplectic-geometry-and-information-gil?delta=0">Seminar announcement</a>; previous post <a href="https://gilkalai.wordpress.com/2013/01/01/symplectic-geometry-quantization-and-quantum-noise/" rel="bookmark">Symplectic Geometry, Quantization, and Quantum Noise.</a></p>
<p>The Google supremacy claims are discussed (with updates from time to time) in <a href="https://gilkalai.wordpress.com/2019/09/23/quantum-computers-amazing-progress-google-ibm-and-extraordinary-but-probably-false-supremacy-claims-google/">this earlier post</a>. Don’t miss <a href="https://gilkalai.wordpress.com/2019/10/13/gerard-cornuejolss-bakers-eighteen-5000-dollars-conjectures/">our previous post</a> on combinatorics.</p>
<h3>Tentative syllabus for “Computation, quantumness, symplectic geometry, and information”</h3>
<p>1. Mathematical models of classical and quantum mechanics.</p>
<p>2. Correspondence principle and quantization.</p>
<p>3. Classical and quantum computation: gates, circuits, algorithms (Shor, Grover). Solovay-Kitaev. Some ideas of cryptography</p>
<p>4. Quantum noise and measurement, and rigidity of the Poisson bracket.</p>
<p>5. Noisy classical and quantum computing and error correction, threshold theorem- quantum fault tolerance (small noise is good for quantum computation). Kitaev’s surface code.</p>
<p>6. Quantum speed limit/time-energy uncertainty vs symplectic displacement energy.</p>
<p>7. Time-energy uncertainty and quantum computation (Dorit or her student?)</p>
<p>8. Berezin transform, Markov chains, spectral gap, noise.</p>
<p>9. Adiabatic computation, quantum PCP (probabilistically checkable proofs) conjecture [? under discussion]</p>
<p>10. Noise stability and noise sensitivity of Boolean functions, noisy boson sampling</p>
<p>11. Connection to quantum field theory (Guy?).</p>
<p>Literature: Aharonov, D. Quantum computation, In “Annual Reviews of Computational Physics” VI, 1999 (pp. 259-346). <a href="https://arxiv.org/abs/quant-ph/9812037">https://arxiv.org/abs/quant-ph/9812037</a></p>
<p>Kalai, G., Three puzzles on mathematics computations, and games, Proc. Int Congress Math 2018, Rio de Janeiro, Vol. 1 pp. 551–606. <a href="https://arxiv.org/abs/1801.02602">https://arxiv.org/abs/1801.02602</a></p>
<p>Nielsen, M.A., and Chuang, I.L., Quantum computation and quantum information. Cambridge University Press, Cambridge, 2000.</p>
<p>Polterovich, L., Symplectic rigidity and quantum mechanics, European Congress of Mathematics, 155–179, Eur. Math. Soc., Zürich, 2018. <a href="https://sites.google.com/site/polterov/miscellaneoustexts/symplectic-rigidity-and-quantum-mechanics">https://sites.google.com/site/polterov/miscellaneoustexts/symplectic-rig…</a></p>
<p>Polterovich L., and Rosen D., Function theory on symplectic manifolds. American Mathematical Society; 2014. [Chapters 1,9] <a href="https://sites.google.com/site/polterov/miscellaneoustexts/function-theory-on-symplectic-manifolds">https://sites.google.com/site/polterov/miscellaneoustexts/function-theor…</a></p>
<p>Wigderson, A., Mathematics and computation, Princeton Univ. Press, 2019. <a href="https://www.math.ias.edu/files/mathandcomp.pdf">https://www.math.ias.edu/files/mathandcomp.pdf</a></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/10/27/starting-today-kazhdan-sunday-seminar-computation-quantumness-symplectic-geometry-and-information/"><span class="datestr">at October 27, 2019 06:09 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/143">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/143">TR19-143 |  Equivalence of Systematic Linear Data Structures and Matrix Rigidity | 

	Sivaramakrishnan Natarajan Ramamoorthy, 

	Cyrus Rashtchian</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Recently, Dvir, Golovnev, and Weinstein have shown that sufficiently strong lower bounds for linear data structures would imply new bounds for rigid matrices. However, their result utilizes an algorithm that requires an $NP$ oracle, and hence, the rigid matrices are not explicit. In this work, we derive an equivalence between rigidity and the systematic linear model of data structures. For the $n$-dimensional inner product problem with $m$ queries, we prove that lower bounds on the query time imply rigidity lower bounds for the query set itself. In particular, an explicit lower bound of $\omega\left(\frac{n}{r}\log m\right)$ for $r$ redundant storage bits would yield better rigidity parameters than the best bounds due to Alon, Panigrahy, and Yekhanin. We also prove a converse result, showing that rigid matrices directly correspond to hard query sets for the systematic linear model. As an application, we prove that the set of vectors obtained from rank one binary matrices is rigid with parameters matching the known results for explicit sets. This implies that the vector-matrix-vector problem requires query time $\Omega(n^{3/2}/r)$ for redundancy $r \geq \sqrt{n}$ in the systematic linear model, improving a result of Chakraborty, Kamma, and Larsen. Finally, we prove a cell probe lower bound for the vector-matrix-vector problem in the  high error regime, improving a result of Chattopadhyay, Koucký, Loff, and Mukhopadhyay.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/143"><span class="datestr">at October 25, 2019 07:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/10/25/tenure-track-faculties-at-krannert-school-of-management-purdue-university-apply-by-december-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/10/25/tenure-track-faculties-at-krannert-school-of-management-purdue-university-apply-by-december-1-2019/">Tenure track faculties at Krannert School of Management, Purdue University (apply by December 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Krannert School of Management invites applicants for two tenure-track faculty positions at the assistant professor level in the Quantitative Methods area, to begin in the fall semester of 2020. We welcome applicants from all research areas represented within the Quantitative Methods area.</p>
<p>Website: <a href="https://career8.successfactors.com/sfcareer/jobreqcareer?jobId=8013&amp;company=purdueuniv&amp;userna%20me=">https://career8.successfactors.com/sfcareer/jobreqcareer?jobId=8013&amp;company=purdueuniv&amp;userna%20me=</a><br />
Email: nguye161@purdue.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/10/25/tenure-track-faculties-at-krannert-school-of-management-purdue-university-apply-by-december-1-2019/"><span class="datestr">at October 25, 2019 06:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/10/24/simons-berkeley-research-fellowship-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/10/24/simons-berkeley-research-fellowship-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2019/">Simons-Berkeley Research Fellowship at Simons Institute for the Theory of Computing (apply by December 15, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Simons Institute for the Theory of Computing invites applications for the Simons-Berkeley Research Fellowships to participate in one or more of the semester-long programs during the 2020-21 academic year: Probability, Geometry, and Computation in High Dimensions; Theory of Reinforcement Learning; Satisfiability: Theory, Practice, and Beyond; and Theoretical Foundations of Computer Systems</p>
<p>Website: <a href="https://simons.berkeley.edu/fellows2020">https://simons.berkeley.edu/fellows2020</a><br />
Email: simonsvisitorservices@berkeley.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/10/24/simons-berkeley-research-fellowship-at-simons-institute-for-the-theory-of-computing-apply-by-december-15-2019/"><span class="datestr">at October 24, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1513">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2019/10/24/shopping-for-grain-in-the-market-works-a-fine-job/">Shopping for Grain in the Market Works –   a Fine Job!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I’m excited to share the news of two upcoming workshops…</p>
<p> </p>
<h3>TCS Early Career Mentoring Workshop</h3>
<p>Yael Kalai, Matt Weinberg, and I are organizing a TCS mentoring workshop in <a href="http://focs2019.cs.jhu.edu/">upcoming FOCS</a> with a focus on <strong>demystifying the job market</strong>.</p>
<p>The program includes a senior panel featuring Shafi Goldwasser, Samir Khuller, Tim Roughgarden, and Eva Tardos, a junior panel starring Inbal Talgam-Cohen, Omri Weinstein, and Henry Yuen, and two exemplary job talks by Eshan Chattopadhyay and Pravesh Kothari.</p>
<p>Visit our <a href="https://www.cs.princeton.edu/~smattw/FOCS19/index.html">website</a> to see the full program and most importantly <a href="https://forms.gle/5kw7Zydo4Cvw2D4r7">suggest panel questions</a>.</p>
<p> </p>
<h3>Fine-grained Complexity Workshop</h3>
<p>Amir Abboud and I are organizing a workshop on fine-grained complexity, to be held Jan 2nd 2020 at Tel-Aviv University, closing the first annual <a href="https://sites.google.com/view/tau-theory-fest/home">TAU Theory-Fest</a>.</p>
<p>The program includes a morning of plenary talks (Karl Bringmann, Seth Pettie, and Barna Saha) and shorter cutting-edge technical talks in the afternoon.</p>
<p>(If you have something interesting to share with the fine-grained complexity community, and we haven’t contacted you yet about giving a talk, please let us know.)</p>
<p> </p>
<p>Looking forward to seeing you in Baltimore and Tel-Aviv!</p></div>







<p class="date">
by aviad.rubinstein <a href="https://theorydish.blog/2019/10/24/shopping-for-grain-in-the-market-works-a-fine-job/"><span class="datestr">at October 24, 2019 05:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7561">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2019/10/24/boazs-inferior-classical-inferiority-faq/">Boaz’s inferior classical inferiority FAQ</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>(For better info, see <a href="https://www.scottaaronson.com/blog/?p=4317">Scott’s Supreme Quantum Superiority FAQ</a> and also his <a href="https://www.scottaaronson.com/blog/?p=4372">latest post on the Google paper</a>; also this is not really an FAQ but was inspired by a question about the Google paper from a former <a href="https://cs121.boazbarak.org/schedule/">CS 121 </a>student)</p>



<blockquote class="wp-block-quote"><p><em> “Suppose aliens invade the earth and threaten to obliterate it in a year’s time unless human beings can find the Ramsey number for red five and blue five. We could marshal the world’s best minds and fastest computers, and within a year we could probably calculate the value. If the aliens demanded the Ramsey number for red six and blue six, however, we would have no choice but to launch a preemptive attack.</em>“</p><cite>Paul Erdős (as quoted by Graham and Spencer, 1990, hat tip: <a href="https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/#comment-42659">Lamaze Tishallishmi</a>)</cite></blockquote>



<p>In a <a href="https://www.nature.com/articles/s41586-019-1666-5">Nature paper</a> published this week, a group of researchers from John Martinis’s lab at Google announced arguably the first demonstration of “quantum supremacy” – a computational task carried out by a 53 qubit quantum computer that would require a prohibitive amount of time to simulate classically. </p>



<p>Google’s calculations of the “classical computation time” might have been overly pessimistic (from the classical point of view), and there has been work from <a href="https://arxiv.org/abs/1910.09534">IBM</a> as well as some <a href="https://www.caltech.edu/campus-life-events/master-calendar/iqi-weekly-seminar-2019-10-01">work of Johnnie Gray</a> suggesting that there are significant savings to be made. Indeed, given the lessons that we learned from private key cryptography, where techniques such as linear and differential cryptanalysis were used to “shave factors from exponents”, we know that even if a problem requires exponential time in general, this does not mean that by being very clever we can’t make significant savings over the naive brute force algorithm. This holds doubly  so in this case, where, unlike the designers of block ciphers, the Google researchers were severely constrained by factors of geometry and the kind of gates they can reliably implement.</p>



<p>I would not be terribly surprised if we will see more savings and even an actual classical simulation of the same sampling task that Google achieved. In fact, I very much hope this happens, since it will allow us to independently verify the reliability of Google’s chip and whether it actually did in fact sample from the distribution it is supposed to have sampled from (or at least rule out some “null hypothesis”).  But this would not change the main point that the resources for classical simulation, as far as we know, scale exponentially with the number of qubits and their quality. While we could perhaps with great effort simulate a 53 qubit depth 20 circuit classically, once we reach something like 100 qubits and depth then all current approaches will be hopelessly behind.</p>



<p>In the language of <a href="https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/">my essay on quantum skepticism</a>, I think this latest result, and the rest of the significant experimental progress that has been going on, all but rules out the possibility of “Skepticland”  where there would be some fundamental physical reason why it is not possible to build quantum computers that offer exponential advantage in the amount of resources to achieve certain tasks over classical computers.</p>



<p>While the worlds of “Popscitopia”  (quantum computers can do everything) and “Classicatopia” (there is an efficient classical algorithm to simulate BQP) remain mathematical possiblities (just as P=NP is), most likely we live in <strong>“Superiorita”</strong> where quantum computers do offer exponential advantage for <em>some</em> computational problems.</p>



<p>Some people question whether these kind of “special purpose” devices that might be very expensive to build are worth the investment. First of all (and most importantly for me), as I argued in <a href="https://windowsontheory.org/2017/10/30/the-different-forms-of-quantum-computing-skepticism/">my essay</a>, exploring the limits of physically realizable computation is a grand scientific goal in its own right worthy of investment regardless  of applications. Second, technology is now a <a href="https://www.gartner.com/en/newsroom/press-releases/2019-01-28-gartner-says-global-it-spending-to-reach--3-8-trillio#targetText=Worldwide%20IT%20spending%20is%20projected,latest%20forecast%20by%20Gartner%2C%20Inc.">3.8 trillion dollar </a>per year industry, and quantum computers are in a very real sense the first qualitatively different computing devices since the days of Babbage and Turing. Spending a fraction of a percent of the industry’s worth to the economy on exploring the potential for quantum computing seems like a good investment, even if there will be no practical application in the next decade or two. (By the same token, spending a fraction of a percent on exploring algorithm design and the limitations of <em>classical </em>algorithms is a very good investment as well.)</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2019/10/24/boazs-inferior-classical-inferiority-faq/"><span class="datestr">at October 24, 2019 01:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/142">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/142">TR19-142 |  Semi-Algebraic Proofs, IPS Lower Bounds and the $\tau$-Conjecture: Can a Natural Number be Negative? | 

	Yaroslav Alekseev, 

	Dima Grigoriev, 

	Edward Hirsch, 

	Iddo  Tzameret</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We introduce the `binary value principle' which is a simple subset-sum instance expressing that a natural number written in binary cannot be negative, relating it to central problems in proof and algebraic complexity. We prove conditional superpolynomial lower bounds on the Ideal Proof System (IPS) refutation size of this instance, based on a well-known hypothesis by Shub and Smale about the hardness of computing factorials, where IPS is the strong algebraic proof system introduced by Grochow and Pitassi (2018). Conversely, we show that short IPS refutations of this instance bridge the gap between sufficiently strong algebraic and semi-algebraic proof systems. Our results extend to full-fledged IPS the paradigm introduced in Forbes et al. (2016), whereby lower bounds against subsystems of IPS were obtained using restricted algebraic circuit lower bounds, and demonstrate that the binary value principle captures the advantage of semi-algebraic over algebraic reasoning, for sufficiently strong systems. Specifically, we show the following:

*Conditional IPS lower bounds:* The Shub-Smale hypothesis (1995) implies a superpolynomial lower bound on the size of IPS refutations of the binary value principle over the rationals defined as the unsatisfiable linear equation $\sum_{i=1}^{n} 2^{i-1}x_i = -1$, for boolean $x_i$'s. Further, the related $\tau$-conjecture (1995) implies a superpolynomial lower bound on the size of IPS refutations of a variant of the binary value principle over the ring of rational functions. No prior conditional lower bounds were known for IPS or for apparently much weaker propositional proof systems such as Frege.

*Algebraic vs. semi-algebraic proofs:* Admitting short refutations of the binary value principle is necessary for any algebraic proof system to fully simulate any known semi-algebraic proof system, and for strong enough algebraic proof systems it is also sufficient. In particular, we introduce a very strong proof system that simulates all known semi-algebraic proof systems (and most other known concrete propositional proof systems), under the name Cone Proof System (CPS), as a semi-algebraic analogue of the ideal proof system: CPS establishes the unsatisfiability of collections of polynomial equalities and inequalities over the reals, by representing sum-of-squares proofs (and extensions) as algebraic circuits. We prove that IPS is polynomially equivalent to CPS iff IPS admits polynomial-size refutations of the binary value principle (for the language of systems of equations that have no 0/1-solutions), over both $\mathbb{Z}$ and $\mathbb{Q}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/142"><span class="datestr">at October 24, 2019 12:45 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/141">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/141">TR19-141 |  On Rich $2$-to-$1$ Games | 

	Mark Braverman, 

	Subhash Khot, 

	Dor Minzer</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We propose a variant of the $2$-to-$1$ Games Conjecture that we call the Rich $2$-to-$1$ Games Conjecture and show that it is equivalent to the Unique Games Conjecture. We are motivated by two considerations. Firstly, in light of the recent proof of the $2$-to-$1$ Games Conjecture, we hope to understand how one might make further progress towards a proof of the Unique Games Conjecture. Secondly, the new variant along with perfect completeness in addition, might imply hardness of approximation results that necessarily require perfect completeness and (hence) are not implied by the Unique Games Conjecture.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/141"><span class="datestr">at October 24, 2019 12:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4372">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4372">Quantum supremacy: the gloves are off</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong>Links:</strong><br /><a href="https://www.nature.com/articles/s41586-019-1666-5">Google paper in </a><em><a href="https://www.nature.com/articles/s41586-019-1666-5">Nature</a></em><br /><em><a href="https://www.nytimes.com/2019/10/23/technology/quantum-computing-google.html?action=click&amp;module=Top%20Stories&amp;pgtype=Homepage">New York Times</a></em><a href="https://www.nytimes.com/2019/10/23/technology/quantum-computing-google.html?action=click&amp;module=Top%20Stories&amp;pgtype=Homepage"> article</a><br />IBM <a href="https://arxiv.org/abs/1910.09534">paper</a> and <a href="https://www.ibm.com/blogs/research/2019/10/on-quantum-supremacy/">blog post</a> responding to Google’s announcement<br />Boaz Barak’s new post: <a href="https://windowsontheory.org/2019/10/24/boazs-inferior-classical-inferiority-faq/">“Boaz’s inferior classical inferiority FAQ”</a><br /><a href="https://rjlipton.wordpress.com/2019/10/27/quantum-supremacy-at-last/">Lipton and Regan’s post</a><br /><a href="https://www.bbc.co.uk/sounds/play/w3csym2f">My quantum supremacy interview with the BBC</a> (featuring some of my fewest “uhms” and “ahs” ever!)<br /><strong>NEW:</strong> My preprint with Sam Gunn, <a href="https://arxiv.org/abs/1910.12085">On the Classical Hardness of Spoofing Linear Cross-Entropy Benchmarking</a><br /><a href="https://radio.wosu.org/post/tech-tuesday-ai-criminal-justice#stream/0">My interview on NPR affiliate WOSU</a> (starts around 16:30)</p>



<p>When Google’s quantum supremacy paper leaked a month ago—not through Google’s error, but through NASA’s—I had a hard time figuring out how to cover the news here.  I had to say <em>something</em>; on the other hand, I wanted to avoid any detailed technical analysis of the leaked paper, because I was acutely aware that my colleagues at Google were still barred by <em>Nature</em>‘s embargo rules from publicly responding to anything I or others said.  (I was also one of the reviewers for the <em>Nature</em> paper, which put additional obligations on me.)</p>



<p>I ended up with <a href="https://www.scottaaronson.com/blog/?p=4317">Scott’s Supreme Quantum Supremacy FAQ</a>, which tried to toe this impossible line by “answering general questions about quantum supremacy, and the consequences of its still-hypothetical achievement, in light of the leak.”  It wasn’t an ideal solution—for one thing, because while I still regard Google’s sampling experiment as a historic milestone for our whole field, there <em>are</em> some technical issues, aspects that subsequent experiments (hopefully coming soon) will need to improve.  Alas, the ground rules of my FAQ forced me to avoid such issues, which caused some readers to conclude mistakenly that I didn’t think there were any.</p>



<p>Now, though, the Google paper has <a href="https://www.nature.com/articles/s41586-019-1666-5">come out as </a><em><a href="https://www.nature.com/articles/s41586-019-1666-5">Nature</a></em><a href="https://www.nature.com/articles/s41586-019-1666-5">‘s cover story</a>, at the same time as there have been new technical developments—most obviously, the <a href="https://arxiv.org/abs/1910.09534">paper from IBM</a> (see also their <a href="https://www.ibm.com/blogs/research/2019/10/on-quantum-supremacy/">blog post</a>) saying that they could simulate the Google experiment in 2.5 days, rather than the 10,000 years that Google had estimated.</p>



<p>(Yesterday I was deluged by emails asking me “whether I’d seen” IBM’s paper.  As a science blogger, I try to respond to stuff pretty quickly when necessary, but I don’t—can’t—respond in Twitter time.)</p>



<p>So now the gloves are off.  No more embargo.  Time to address the technical stuff under the hood—which is the purpose of this post.</p>



<p>I’m going to assume, from this point on, that you already understand the basics of sampling-based quantum supremacy experiments, and that I don’t need to correct beginner-level misconceptions about what the term “quantum supremacy” does and doesn’t mean (no, it doesn’t mean scalability, fault-tolerance, useful applications, breaking public-key crypto, etc. etc.).  If this is not the case, you could start (e.g.) with <a href="https://www.scottaaronson.com/blog/?p=4317">my FAQ</a>, or with John Preskill’s <a href="https://www.quantamagazine.org/john-preskill-explains-quantum-supremacy-20191002/">excellent </a><em><a href="https://www.quantamagazine.org/john-preskill-explains-quantum-supremacy-20191002/">Quanta</a></em><a href="https://www.quantamagazine.org/john-preskill-explains-quantum-supremacy-20191002/"> commentary</a>.</p>



<p>Without further ado:</p>



<p><strong>(1) So what about that IBM thing?  <em>Are</em> random quantum circuits easy to simulate classically?</strong></p>



<p>OK, so let’s carefully spell out what the IBM paper says.  They argue that, by commandeering the full attention of <a href="https://en.wikipedia.org/wiki/Summit_(supercomputer)">Summit</a> at Oak Ridge National Lab, the most powerful supercomputer that currently exists on Earth—one that fills the area of two basketball courts, and that (crucially) has <strong>250 petabytes</strong> of hard disk space—one could just barely store the entire quantum state vector of Google’s 53-qubit Sycamore chip in hard disk.  And once one had done that, one could simulate the chip in ~2.5 days, more-or-less just by updating the entire state vector by brute force, rather than the 10,000 years that Google had estimated on the basis of my and Lijie Chen’s <a href="https://arxiv.org/abs/1612.05903">“Schrödinger-Feynman algorithm”</a> (which can get by with less memory).</p>



<p>The IBM group understandably hasn’t actually done this yet—even though IBM set it up, the world’s #1 supercomputer isn’t just sitting around waiting for jobs!  But I see little reason to doubt that their analysis is basically right.  I don’t know why the Google team didn’t consider how such near-astronomical hard disk space would change their calculations; probably they wish they had.</p>



<p>I find this to be much, <em>much</em> better than IBM’s initial reaction to the Google leak, which was simply to <a href="https://www.ft.com/content/cede11e0-dd51-11e9-9743-db5a370481bc">dismiss</a> the importance of quantum supremacy as a milestone.  Designing better classical simulations is precisely how IBM and others <em>should</em> respond to Google’s announcement, and how I said a month ago that I hoped they <em>would</em> respond.  If we set aside the pass-the-popcorn PR war (or even if we don’t), this is how science progresses.</p>



<p>But does IBM’s analysis mean that “quantum supremacy” hasn’t been achieved?  No, it doesn’t—at least, not under any definition of “quantum supremacy” that I’ve ever used.  The Sycamore chip took about 3 minutes to generate the ~5 million samples that were needed to pass the “linear cross-entropy benchmark”—the statistical test that Google applies to the outputs of its device.</p>



<p>(<strong>Technical note added:</strong> Google’s samples are extremely noisy—the actual distribution being sampled from is something like 0.998U+0.002D, where U is the uniform distribution and D is the hard distribution that you want.  What this means, in practice, is that you need to take a number of samples that’s large compared to 1/0.002<sup>2</sup>, in order to extract a signal corresponding to D.  But the good news is that Google <em>can</em> take that many samples in just a few minutes, since once the circuit has been loaded onto the chip, generating each sample takes only about 40 microseconds.  And once you’ve done this, what hardness results we have for passing the linear cross-entropy test—to be discussed later in this post—apply basically just as well as if you’d taken a single noiseless sample.)</p>



<p>Anyway, you might notice that three minutes versus 2.5 days is still a quantum speedup by a factor of 1200.  But even more relevant, I think, is to compare the number of “elementary operations.”  Let’s generously count a FLOP (floating-point operation) as the equivalent of a quantum gate.  Then by my estimate, we’re comparing ~5×10<sup>9</sup> quantum gates against ~2×10<sup>20</sup> FLOPs—a quantum speedup by a factor of ~40 billion.</p>



<p>For me, though, the broader point is that neither party here—certainly not IBM—denies that the top-supercomputers-on-the-planet-level difficulty of classically simulating Google’s 53-qubit programmable chip really <em>is</em> coming from the exponential character of the quantum states in that chip, <em>and nothing else</em>.  That’s what makes this back-and-forth fundamentally different from the previous one between D-Wave and the people who sought to simulate <em>its</em> devices classically.  The skeptics, like me, didn’t much care what speedup over classical benchmarks there was or wasn’t today: we cared about the <em>increase</em> in the speedup as D-Wave upgraded its hardware, and the trouble was that we never saw a convincing case that there would be one.  I’m a theoretical computer scientist, and this is what I believe: that after the constant factors have come and gone, what remains are asymptotic growth rates.</p>



<p>In the present case, while increasing the circuit depth won’t evade IBM’s “store everything to hard disk” strategy, increasing the number of qubits will.  If Google, or someone else, upgraded from 53 to 55 qubits, that would apparently already be enough to exceed Summit’s 250-petabyte storage capacity.  At 60 qubits, you’d need 33 Summits.  At 70 qubits, enough Summits to fill a city … you get the idea.</p>



<p>From the beginning, it was clear that quantum supremacy would not be a milestone like the moon landing—something that’s achieved in a moment, and is then clear to everyone for all time.  It would be more like eradicating measles: it could be achieved, then temporarily unachieved, then re-achieved.  For by definition, quantum supremacy all about <em>beating</em> something—namely, classical computation—and the latter can, at least for a while, fight back.</p>



<p>As Boaz Barak put it to me, the current contest between IBM and Google is analogous to <a href="https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov">Kasparov versus Deep Blue</a>—<em>except with the world-historic irony that IBM is playing the role of Kasparov!</em>  In other words, Kasparov can put up a heroic struggle, during a “transitional period” that lasts a year or two, but the fundamentals of the situation are that he’s toast.  If Kasparov had narrowly beaten Deep Blue in 1997, rather than narrowly losing, the whole public narrative would likely have been different (“humanity triumphs over computers after all!”).  Yet as Kasparov himself well knew, the very fact that the contest was <em>close</em> meant that, either way, human dominance would soon end for good.</p>



<p>Let me leave the last word on this to friend-of-the-blog Greg Kuperberg, who graciously gave me permission to quote his comments about the IBM paper.</p>



<blockquote class="wp-block-quote"><p>I’m not entirely sure how embarrassed Google should feel that they overlooked this.   I’m sure that they would have been happier to anticipate it, and happier still if they had put more qubits on their chip to defeat it.   However, it doesn’t change their real achievement.</p><p>I respect the IBM paper, even if the press along with it seems more grouchy than necessary.   I tend to believe them that the Google team did not explore all avenues when they said that their 53 qubits aren’t classically simulable.   But if this is the best rebuttal, then you should still consider how much Google and IBM still agree on this as a proof-of-concept of QC.   This is still quantum David vs classical Goliath, in the extreme.   53 qubits is in some ways still just 53 bits, only enhanced with quantum randomness.  To answer those 53 qubits, IBM would still need entire days of computer time with the world’s fastest supercomputer, a 200-petaflop machine with hundreds of thousands of processing cores and trillions of high-speed transistors.   If we can confirm that the Google chip actually meets spec, but we need this much computer power to do it, then to me that’s about as convincing as a larger quantum supremacy demonstration that humanity can no longer confirm at all.</p><p>Honestly, I’m happy to give both Google and IBM credit for helping the field of QC, even if it is the result of a strange dispute. </p></blockquote>



<p>I should mention that, even before IBM’s announcement, Johnnie Gray, a postdoc at Imperial College, gave a talk (<a href="https://www.caltech.edu/campus-life-events/master-calendar/iqi-weekly-seminar-2019-10-01">abstract here</a>) at Caltech’s Institute for Quantum Information with a proposal for a <em>different</em> faster way to classically simulate quantum circuits like Google’s—in this case, by doing tensor network contraction more cleverly.  Unlike both IBM’s proposed brute-force simulation, and the Schrödinger-Feynman algorithm that Google implemented, Gray’s algorithm (as far as we know now) would need to be repeated k times if you wanted k independent samples from the hard distribution.  Partly because of this issue, Gray’s approach doesn’t currently look competitive for simulating thousands or millions of samples, but we’ll need to watch it and see what happens.</p>



<p><strong>(2) Direct versus indirect verification.</strong></p>



<p>The discussion of IBM’s proposed simulation brings us to a curious aspect of the Google paper—one that was already apparent when <em>Nature</em> sent me the paper for review back in August.  Namely, Google took its supremacy experiments well past the point <em>where even they themselves knew how to verify the results</em>, by any classical computation that they knew how to perform feasibly (say, in less than 10,000 years).</p>



<p>So you might reasonably ask: if they couldn’t even verify the results, then how did they get to claim quantum speedups from those experiments?  Well, they resorted to various gambits, which basically involved estimating the fidelity on quantum circuits that looked almost the same as the hard circuits, but happened to be easier to simulate classically, and then making the (totally plausible) assumption that that fidelity would be maintained on the hard circuits.  Interestingly, they also cached their outputs and put them online (as part of the supplementary material to their <em>Nature</em> paper), in case it became feasible to verify them in the future.</p>



<p>Maybe you can now see where this is going.  From Google’s perspective, IBM’s rainstorm comes with a big silver lining.  Namely, by using Summit, hopefully it will now be possible to verify Google’s hardest (53-qubit and depth-20) sampling computations directly!  This should provide an excellent test, since not even the Google group themselves would’ve known how to cheat and bias the results had they wanted to.</p>



<p>This whole episode has demonstrated the importance, when doing a sampling-based quantum supremacy experiment, of <em>going deep into the regime where you can no longer classically verify the outputs</em>, as weird as that sounds.  Namely, you need to leave yourself a margin, in the likely event that the classical algorithms improve!</p>



<p>Having said that, I don’t mind revealing at this point that the lack of direct verification of the outputs, for the largest reported speedups, was my single biggest complaint when I reviewed Google’s <em>Nature</em> submission.  It was because of my review that they added a paragraph explicitly pointing out that they <em>did</em> do direct verification for a smaller quantum speedup:</p>



<blockquote class="wp-block-quote"><p>The largest circuits for which the fidelity can still be directly verified have 53 qubits and a simplified gate arrangement. Performing random circuit sampling on these at 0.8% fidelity takes one million cores 130 seconds, corresponding to a million-fold speedup of the quantum processor relative to a single core. </p></blockquote>



<p>(An earlier version of this post misstated the numbers involved.)</p>



<p><strong>(3) The asymptotic hardness of spoofing Google’s benchmark.</strong></p>



<p>OK, but if Google thought that spoofing its test would take 10,000 years, using the best known classical algorithms running on the world’s top supercomputers, and it turns out instead that it could probably be done in more like 2.5 days, then how much else could’ve been missed?  Will we find out next that Google’s benchmark can be classically spoofed in mere milliseconds?</p>



<p>Well, no one can rule that out, but we do have some reasons to think that it’s unlikely—and crucially, that even if it turned out to be true, one would just have to add 10 or 20 or 30 more qubits to make it no longer true.  (We can’t be more definitive than that?  Aye, such are the perils of life at a technological inflection point—and of computational complexity itself.)</p>



<p>The key point to understand here is that we really are talking about simulating a <em>random</em> quantum circuit, with no particular structure whatsoever.  While such problems <em>might</em> have a theoretically efficient classical algorithm—i.e., one that runs in time polynomial in the number of qubits—I’d personally be much less surprised if you told me there was a polynomial-time classical algorithm for factoring.  In the universe where amplitudes of random quantum circuits turn out to be efficiently computable—well, you might as well just tell me that P=PSPACE and be done with it.</p>



<p>Crucially, if you look at IBM’s approach to simulating quantum circuits classically, <em>and</em> Johnnie Gray’s approach, <em>and</em> Google’s approach, they could all be described as different flavors of “brute force.”  That is, they all use extremely clever tricks to parallelize, shave off constant factors, make the best use of available memory, etc., but none involves any deep new mathematical insight that could roust BPP and BQP and the other complexity gods from their heavenly slumber.  More concretely, none of these approaches seem to have any hope of “breaching the 2<sup>n</sup> barrier,” where n is the number of qubits in the quantum circuit to be simulated (assuming that the circuit depth is reasonably large).  Mostly, they’re just trying to get down to that barrier, while taking the maximum advantage of whatever storage and connectivity and parallelism are there.</p>



<p>Ah, but at the end of the day, we only believe that Google’s Sycamore chip is solving a classically hard problem because of the statistical test that Google applies to its outputs: the so-called “Linear Cross-Entropy Benchmark,” which I described in Q3 of my <a href="https://www.scottaaronson.com/blog/?p=4317">FAQ</a>.  And even if we grant that calculating the output probabilities for a random quantum circuit is almost certainly classically hard, and sampling the output distribution of a random quantum circuit is almost certainly classically hard—still, couldn’t <em>spoofing Google’s benchmark</em> be classically easy?</p>



<p>This last question is where complexity theory can contribute something to the story.  A couple weeks ago, UT undergraduate Sam Gunn and I adapted the hardness analysis from my and Lijie Chen’s 2017 paper <a href="https://arxiv.org/abs/1612.05903">“Complexity-Theoretic Foundations of Quantum Supremacy Experiments,”</a> to talk directly about the classical hardness of spoofing the Linear Cross-Entropy benchmark.  Our short paper about this <s>should be on the arXiv later this week (or early next week, given that there are no arXiv updates on Friday or Saturday nights)</s> <a href="https://arxiv.org/abs/1910.12085">here it is</a>.</p>



<p>Briefly, Sam and I show that if you had a sub-2<sup>n</sup> classical algorithm to spoof the Linear Cross-Entropy benchmark, then you’d also have a sub-2<sup>n</sup> classical algorithm that, given as input a random quantum circuit, could estimate a <em>specific</em> output probability (for example, that of the all-0 string) with variance at least <em>slightly</em> (say, Ω(2<sup>-3n</sup>)) better than that of the trivial estimator that just always guesses 2<sup>-n</sup>.  Or in other words: we show that spoofing Google’s benchmark is no easier than the general problem of nontrivially estimating amplitudes in random quantum circuits.  Furthermore, this result automatically generalizes to the case of noisy circuits: all that the noise affects is the threshold for the Linear Cross-Entropy benchmark, and thus (indirectly) the number of samples one needs to take with the QC.  Our result helps to explain why, indeed, neither IBM nor Johnnie Gray nor anyone else suggested any attack that’s specific to Google’s Linear Cross-Entropy benchmark: they all simply attack the general problem of calculating the final amplitudes.</p>



<p><strong>(4) Why use Linear Cross-Entropy at all?</strong></p>



<p>In the comments of my FAQ, some people wondered why Google chose the Linear Cross-Entropy benchmark specifically—especially since they’d used a different benchmark (<em>multiplicative</em> cross-entropy, which unlike the linear version actually <em>is</em> a cross-entropy) in their earlier papers.  I asked John Martinis this question, and his answer was simply that linear cross-entropy had the lowest variance of any estimator they tried.  Since I <em>also</em> like linear cross-entropy—it turns out, for example, to be convenient for the analysis of my certified randomness protocol—I’m 100% happy with their choice.  Having said that, there are many other choices of benchmark that would’ve also worked fine, and with roughly the same level of theoretical justification.</p>



<p><strong>(5) Controlled-Z versus iSWAP gates.</strong></p>



<p>Another interesting detail from the Google paper is that, in their previous hardware, they could implement a particular 2-qubit gate called the Controlled-Z.  For their quantum supremacy demonstration, on the other hand, they modified their hardware to implement a different 2-qubit gate called the <s>iSWAP</s> some weird combination of iSWAP and Controlled-Z; see the comments section for more.  Now, this other gate has no known advantages over the Controlled-Z, for any applications like quantum simulation or Shor’s algorithm or Grover search.  Why then did Google make the switch?  Simply because, with certain classical simulation methods that they’d been considering, the simulation’s running time grows like 4 to the power of the number of these other gates, but only like 2 to the power of the number of Controlled-Z gates!  In other words, they made this engineering choice purely and entirely to make a classical simulation of their device sweat more.  This seems totally fine and entirely within the rules to me.  (Alas, this choice has no effect on a proposed simulation method like IBM’s.)</p>



<p><strong>(6) Gil Kalai’s objections.</strong></p>



<p>Over the past month, <em>Shtetl-Optimized</em> regular and noted quantum computing skeptic Gil Kalai has been posting one objection to the Google experiment after another on his <a href="https://gilkalai.wordpress.com/">blog</a>.  Unlike the IBM group and many of Google’s other critics, Gil completely accepts the centrality of quantum supremacy as a goal.  Indeed, he’s firmly predicted for years that quantum supremacy could never be achieved for fundamental reasons—and he agrees that the Google result, if upheld, would refute his worldview.  Gil also has no dispute with the exponential classical hardness of the problem that Google is solving.</p>



<p>Instead, Gil—if we’re talking not about <a href="https://en.wikipedia.org/wiki/Straw_man#Steelmanning">“steelmanning”</a> his beliefs, but about what he himself actually said—has taken the position that the Google experiment must’ve been done wrong and will need to be retracted.  He’s offered varying grounds for this.  First he said that Google never computed the full histogram of probabilities with a smaller number of qubits (for which such an experiment is feasible), which would be an important sanity check.  Except, it turns out they <em>did</em> do that, and it’s in their <a href="https://arxiv.org/abs/1709.06678">2018 <em>Science</em> paper</a>.  Next he said that the experiment is invalid because the qubits have to be calibrated in a way that depends on the specific circuit to be applied.  Except, this too turns out to be false: John Martinis explicitly confirmed for me that once the qubits are calibrated, you can run any circuit on them that you want.  In summary, unlike the objections of the IBM group, so far I’ve found Gil’s objections to be devoid of scientific interest or merit.</p>



<p><strong><font color="red">Update #1:</font></strong> Alas, I’ll have limited availability today for answering comments, since we’ll be grading the midterm exam for my Intro to Quantum Information Science course!  I’ll try to handle the backlog tomorrow (Thursday).</p>



<p><strong><font color="red">Update #2:</font></strong> Aaannd … timed to coincide with the Google paper, last night the group of Jianwei Pan and Chaoyang Lu put up a <a href="https://arxiv.org/abs/1910.09930">preprint on the arXiv</a> reporting a BosonSampling experiment with <s>20 photons</s> 14 photons observed out of 20 generated (the previous record had been 6 photons).   At this stage of the quantum supremacy race, many had of course written off BosonSampling—or said that its importance was mostly historical, in that it inspired Google’s random circuit sampling effort.  I’m thrilled to see BosonSampling itself take such a leap; hopefully, this will eventually lead to a demonstration that BosonSampling was (is) a viable pathway to quantum supremacy as well.  And right now, with fault-tolerance still having been demonstrated in <em>zero</em> platforms, we need all the viable pathways we can get.  What an exciting day for the field.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4372"><span class="datestr">at October 23, 2019 03:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=674">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2019/10/22/newton-ma-votes-on-november-5-residents-vs-developers/">Newton MA votes on November 5: Residents vs. developers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Historically, progressive people have been understandably quite skeptical of big business, including developers. (I hesitated before using the word “progressive” because the meaning is obscure, and there are several related words, like “liberal” and so on. But the meaning on this post should be clear.)</p>
<p>Recently, something shocking happened. Self-declared progressive people in Newton have come to believe that the way to solve the world’s problems is to slash regulations, rewrite zoning documents, chop down forests, and give a free hand to developers (not residents in Newton) to build whatever they want, no questions asked.  (Wait, we are putting solar panels on the new roofs!)</p>
<p>As a consequence, there is now a heated  battle in Newton, ward for ward, to try to protect our city against this well-funded and politically well-connected assault.</p>
<p>And we are not even discussing if we should build a mega complex as opposed to creating new green spaces and protected bike lanes, or improving public transportation, or finally having a gym and a swimming pool — all things that would improve our health and the quality of life.  The discussion is just how big the mega complex should be.</p>
<p><a href="https://www.newtonvotes.org/">This website describes the issues and tells you who to vote for.</a></p>
<p><a href="https://rightsizenewton.org/">This one too (endorsements have strong overlap with above but are not identical).</a></p>
<p><a href="http://www.newtonma.gov/gov/elections/upcoming_elections.asp">Sample ballots are here.</a></p>
<p> </p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2019/10/22/newton-ma-votes-on-november-5-residents-vs-developers/"><span class="datestr">at October 22, 2019 06:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/10/22/postdoc-at-the-euler-international-mathematical-institute-apply-by-november-30-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/10/22/postdoc-at-the-euler-international-mathematical-institute-apply-by-november-30-2019/">postdoc at The Euler International Mathematical Institute (apply by November 30, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Euler International Mathematical Institute in St.Petersburg is seeking<br />
postdocs in Math, TCS, Mathematical and Theoretical Physics. St.Petersburg is the most beautiful city in the world and has multiple mathematical locations including Steklov Institute of Mathematics and Dept. of Mathematics and CS in St.Petersburg State Univ. The preference is given to applications sent before 11/30/19.</p>
<p>Website: <a href="http://math-cs.spbu.ru/en/news/news-2019-10-22/">http://math-cs.spbu.ru/en/news/news-2019-10-22/</a><br />
Email: euler.postdoc@gmail.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/10/22/postdoc-at-the-euler-international-mathematical-institute-apply-by-november-30-2019/"><span class="datestr">at October 22, 2019 08:52 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16309">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/10/21/a-polemical-overreach/">A Polemical Overreach?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Our 1977 paper on the role of formal methods</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2019/10/21/a-polemical-overreach/unknown-129/" rel="attachment wp-att-16312"><img width="170" alt="" class="alignright  wp-image-16312" src="https://rjlipton.files.wordpress.com/2019/10/unknown.jpeg?w=170" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Harvard ]</font></td>
</tr>
</tbody>
</table>
<p>
Harry Lewis is known for his research in mathematical logic, and for his wonderful contributions to teaching. He had two students that you may have heard of before: a Bill Gates and a Mark Zuckerberg.</p>
<p>
Today I wish to talk about a recent request from Harry about a book that he is editing.<br />
<span id="more-16309"></span></p>
<p>
The book is the “Classic Papers of CS” based on a course that he has been teaching for years. It will contain 46 papers with short introductions by Harry. My paper from 1977 with Alan Perlis and Rich DeMillo will be included. The <a href="https://www.cs.umd.edu/~gasarch/BLOGPAPERS/social.pdf">paper</a> is “Social Processes and Proofs of Theorems and Programs”.</p>
<p>
Harry says that “A valued colleague believes this paper displays such polemical overreach that it should not appear in this collection”. I hope that it does still appear anyway. Harry goes on to say </p>
<blockquote><p><b> </b> <em> And though verification techniques are widely used today for hardware designs, formal verification of large software systems is still a rarity. </em>
</p></blockquote>
<p></p><p>
Indeed.</p>
<p>
</p><p></p><h2> Our Point </h2><p></p>
<p></p><p>
I have mixed feeling about our paper, which is now getting close to fifty years old. I believe we had some good points to make then. And that these are still relevant today. Our paper starts with:</p>
<blockquote><p><b> </b> <em> Many people have argued that computer programming should strive to become more like mathematics. Maybe so, but not in the way they seem to think. </em>
</p></blockquote>
<p></p><p>
Our point was just this: Proofs in mathematics and not just formal arguments that show that a theorem is correct. They are much more. They must show why and how something is true. They must explain and extend our understanding of why something is true. They must do more than just demonstrate that something is correct.</p>
<p>
They must also make it clear what they claim to prove. A difficulty we felt, then, was that care must be given to what one is claiming to prove. In mathematics often what is being proved is simple to state. In practice that is less clear. A long complex statement may not correctly capture what one is trying to prove.</p>
<p>
Who proves that the specification is correct? </p>
<p>
</p><p></p><h2> Proof Of Our Point </h2><p></p>
<p></p><p>
I have often wondered why some do not see this point. That proofs are more than “correctness checks”. I thought I would list some “proofs” of this point.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> The great Carl Gauss gave the first <a href="https://en.wikipedia.org/wiki/Quadratic_reciprocity">proof</a> of the law of quadratic reciprocity. He later published six more proofs, and two more were found in his posthumous papers. There are now over two hundred published proofs.</p>
<p>
So much to say that a proof is just a check.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> Thomas Hales solved the Kepler conjecture on sphere packing in three-dimensional Euclidean space. He faced some comments that his <a href="https://en.wikipedia.org/wiki/Kepler_conjecture">proof</a> might not be certain—it was said to be <img src="https://s0.wp.com/latex.php?latex=%7B99%5C%25%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{99\%}" class="latex" title="{99\%}" />. So he used formal methods to get a formal proof. But <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /></p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> Maryna Viazovska solved the related problem in eight dimensions. Her <a href="https://arxiv.org/pdf/1603.04246.pdf">proof</a> is here. The excitement of this packing result is striking compared with Hales’s result. No need for correctness checks in her proof. </p>
<p>
Henry Cohn says <a href="https://arxiv.org/pdf/1603.04246.pdf">here</a>: </p>
<blockquote><p><b> </b> <em> One measure of the complexity of a proof is how long it takes the community to digest it. By this standard, Viazovska’s proof is remarkably simple. It was understood by a number of people within a few days of her arXiv posting, and within a week it led to further progress: Abhinav Kumar, Stephen Miller, Danylo Radchenko, and I worked with Viazovska to adapt her methods to prove that the Leech lattice is an optimal sphere packing in twenty-four dimensions. This is the only other case above three dimensions in which the sphere packing problem has been solved. </em>
</p></blockquote>
<p></p><p>
So, a proof that a great proof is a proof that helps create new proofs of something else. Okay, nasty way to say it. What mean is a great proof is one that enables new insights, that enables further progress, that advances the field. Not just a result that “checks” for correctness. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> The famous ABC conjecture of Joseph Oesterle and David Masser has been claimed by Shinichi Mochizuki. Arguments continue about his <a href="http://www.kurims.kyoto-u.ac.jp/~motizuki/papers-english.html">proof</a>. Peter Scholze and Jakob Stix <a href="https://www.math.columbia.edu/~woit/wordpress/?p=10560">believe</a> his proof is flawed and is unfixable. Mochizuki claims they are wrong. </p>
<p>
Will a formal proof solve this impasse? Perhaps not. A proof that explains why it is true might. A proof that advances number theory elsewhere might, a proof that could solve other problems would likely.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What do you think about the role of proofs? Did we miss the point years ago? </p>
<p>
Will formal verification become effective in the near future? And when it does, will it help provide <em>explanations</em>? We note this recent <a href="https://www.vice.com/en_us/article/8xwm54/number-theorist-fears-all-published-math-is-wrong-actually">discussion</a> of a <a href="http://wwwf.imperial.ac.uk/~buzzard/one_off_lectures/msr.pdf">presentation</a> by Kevin Buzzard of Imperial College, London, and one-day <a href="http://www.helixcenter.org/roundtables/mechanization-of-math/">workshop</a> on “The Mechanization of Math” which took place two weeks ago in New York City.</p>
<p>[Typo fixed]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2019/10/21/a-polemical-overreach/"><span class="datestr">at October 21, 2019 03:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6670392427379771547">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/10/differentiation-and-integration.html">Differentiation and Integration</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Recently there was an excellent xkcd about differentiation and integration, see <a href="https://xkcd.com/2117/">here</a>.<br />
<br />
This brings up thoughts on diff and int:<br />
<br />
1) For some students Integration is when math gets hard.<br />
<br />
Diff (at least on the level of Calc I) is rote memorization. A computer program can EASILY do diff<br />
<br />
Integration by humans requires more guesswork and thought, Computers can now do it very well but I think that it was  harder to get to work.<br />
<br />
Someone who has worked on programs for both, please comment.<br />
<br />
2) When I took Honors Calculus back in 1976 (from Jeff Cheeger at SUNY Stonybrook) he made a comment which really puzzled the class, and myself, but later I understood it:<br />
<br />
             <i>Integration is easier than Differentiation</i><br />
<br />
The class thought this was very odd since the problem of, GIVEN a function, find its diff was easier than GIVEN a function, find its int.  And of course I am talking about the kinds of functions one is<br />
given in Calc I and Calc II, so this is not meant to be a formal statement.<br />
<br />
What he meant was that integration  has better mathematical properties than differentiation.  For example, differentiating the function f(x)=abs(x) (absolute value of x)  is problematic at 0, where it has no problem with integration anywhere (alas, if only our society was as relaxed about integration as f(x)=abs(x) is).<br />
<br />
So I would say that the class and Dr. Cheeger were both right (someone else might say they were both wrong) we were just looking at different notions of easy and hard.<br />
<br />
Are there other cases in math where `easy' and `hard' can mean very different things?<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/10/differentiation-and-integration.html"><span class="datestr">at October 21, 2019 03:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsmath.wordpress.com/?p=2291">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/jrl.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsmath.wordpress.com/2019/10/21/uw-cse-hiring-in-quantum-computing/">UW CSE hiring in quantum computing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This year we have a targeted search in all areas of quantum computing, with a particular emphasis on quantum algorithms and quantum complexity theory.  Candidates interested in a faculty position <a href="https://apply.interfolio.com/64708">should apply here</a>. </p></div>







<p class="date">
by James <a href="https://tcsmath.wordpress.com/2019/10/21/uw-cse-hiring-in-quantum-computing/"><span class="datestr">at October 21, 2019 08:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/10/20/faculty-at-johns-hopkins-university-apply-by-december-15-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/10/20/faculty-at-johns-hopkins-university-apply-by-december-15-2019/">Faculty at Johns Hopkins University (apply by December 15, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Johns Hopkins University Department of Computer Science seeks applicants for tenure-track faculty positions at all levels and across all areas of computer science. The department will consider offers in two tracks: (1) an open track seeking excellent candidates across all areas of computer science; and (2) a track seeking candidates in the areas of human computer interaction (HCI).</p>
<p>Website: <a href="http://www.cs.jhu.edu/about/employment-opportunities/">http://www.cs.jhu.edu/about/employment-opportunities/</a><br />
Email: mdinitz@cs.jhu.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/10/20/faculty-at-johns-hopkins-university-apply-by-december-15-2019/"><span class="datestr">at October 20, 2019 04:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/10/19/dont-walk">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/10/19/dont-walk.html">Don’t walk</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Like many UC Irvine faculty I live in <a href="https://en.wikipedia.org/wiki/University_Hills,_Irvine">University Hills</a>, a faculty housing complex associated with UC Irvine. It’s a great place to live: the prices are significantly lower than the surrounding area, I like my neighbors, and I love living so close to my office (ten minutes by foot) that I can walk to work instead of having to deal with the twin headaches of Southern California traffic and university parking.</p>

<p>Because it’s so convenient for walking, University Hills is filled with footpaths, many of which pass through greenbelts instead of running alongside the roads. The main footpath leading to the campus from the neighborhood heads towards a building designed in the shape of a giant arch, with the intent of providing a gateway into the central campus. Because the building is part of the engineering school, it’s called the Engineering Gateway. Here it is from the campus side:</p>

<p style="text-align: center;"><img src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/GatewayFromCampus-m.jpg" alt="Engineering Gateway from the UC Irvine campus" style="border-style: solid; border-color: black;" /></p>

<p>It looks inviting, but you wouldn’t know from this view that it’s now a dead end. Here’s a view from the other side, from the end of the footpath that used to connect to it via a crosswalk across the ring road around campus. The crosswalk has been ripped out, replaced by a fence, and planted with ivy to discourage anyone from crossing that way.</p>

<p style="text-align: center;"><img src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/GatewayFromHills-m.jpg" alt="Engineering Gateway from University Hills" style="border-style: solid; border-color: black;" /></p>

<p>Instead, the path has been rerouted to dump you onto the ring road, where a little farther along there’s a new replacement crosswalk. You can get into the campus by crossing there and following a service road (creatively named “Engineering Service Road”) past this lovely view:</p>

<p style="text-align: center;"><img src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/ServiceRoad-m.jpg" alt="Engineering Service Road, UC Irvine" style="border-style: solid; border-color: black;" /></p>

<p>Alternatively, you can still get to the Engineering Gateway by walking a half-block out of your way down the ring road, crossing, and then following this inviting sidewalk another half-block back the way you came:</p>

<p style="text-align: center;"><img src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/PeltasonToGateway-m.jpg" alt="Along Peltason Road to the Engineering Gateway" style="border-style: solid; border-color: black;" /></p>

<p>I don’t usually take either of those two routes. Instead, I take a different path down a different service road, between two loading docks, where a narrow gap between the backs of two buildings (the University Club and the computer science department) leads into the campus. Here’s what it looks like on weekends; on weekdays, it’s often completely blocked by delivery trucks.</p>

<p style="text-align: center;"><img src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/LosTrancos-m.jpg" alt="Los Trancos Drive, UC Irvine" style="border-style: solid; border-color: black;" /></p>

<p>It’s almost as if by making these routes so awkward and ugly, the campus offices of transportation and physical and environmental planning, which pride themselves on their <a href="https://sustainability.uci.edu/sustainablecampus/transportation/">sustainability</a>, are trying to send the faculty a message. But what could that message be?</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img width="420" alt="Stop, Do Not Enter" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/StopDoNotEnter-m.jpg" /></td>
<td style="padding: 10px;"><img width="280" alt="Don't Walk" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/DontWalk-m.jpg" /></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img width="280" alt="No Pedestrians" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/NoPeds-m.jpg" /></td>
<td style="padding: 10px;"><img width="420" alt="No Pedestrian Access" style="border-style: solid; border-color: black;" src="http://www.ics.uci.edu/~eppstein/pix/dontwalk/NoPedAccess-m.jpg" /></td>
</tr></tbody></table></div>

<p>(<a href="https://mathstodon.xyz/@11011110/102993193993079892">Discuss on Mastodon</a> or more likely on the UHills mailing list)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/10/19/dont-walk.html"><span class="datestr">at October 19, 2019 08:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/10/18/tenure-track-assistant-professor-within-algorithms-at-department-of-computer-science-faculty-of-science-university-of-copenhagen-apply-by-january-5-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/10/18/tenure-track-assistant-professor-within-algorithms-at-department-of-computer-science-faculty-of-science-university-of-copenhagen-apply-by-january-5-2020/">Tenure-track assistant Professor within Algorithms at Department of Computer Science, Faculty of Science, University of Copenhagen (apply by January 5, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The position is open from 1 June 2020 or as soon as possible thereafter.</p>
<p>Using the power of mathematics, we strive to create fundamental breakthroughs in algorithmic thinking. While the focus of BARC is algorithms theory, we do have a track record of surprising algorithmic discoveries leading to major industrial applications. Please find the full job advertisement at <a href="http://employment.ku.dk/.">http://employment.ku.dk/.</a></p>
<p>Website: <a href="https://candidate.hr-manager.net/ApplicationInit.aspx?cid=1307&amp;ProjectId=150516&amp;DepartmentId=18971&amp;MediaId=4642">https://candidate.hr-manager.net/ApplicationInit.aspx?cid=1307&amp;ProjectId=150516&amp;DepartmentId=18971&amp;MediaId=4642</a><br />
Email: mthorup@di.ku.dk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/10/18/tenure-track-assistant-professor-within-algorithms-at-department-of-computer-science-faculty-of-science-university-of-copenhagen-apply-by-january-5-2020/"><span class="datestr">at October 18, 2019 07:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4529441142077494484">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/10/2019-fall-jobs-post.html">2019 Fall Jobs Post</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Starting PhD students over time would always assume that the computer science academic job market would be a strong or as weak when they graduate as it is when they were starting, and they would always be wrong. That may have changed. We've had such a stretch of strong growth in computer science, starting as we pulled out of the financial crisis in 2012, that students who started in the strong market back then see only a much stronger market today.<br />
<br />
Every fall I recap advice for students, and others, looking for academic jobs. Best source are the ads from the <a href="https://cra.org/ads/">CRA</a> and the <a href="https://jobs.acm.org/">ACM</a>. For theoretical computer science specific postdoc and faculty positions check out <a href="https://cstheory-jobs.org/">TCS Jobs</a> and <a href="http://dmatheorynet.blogspot.com/">Theory Announcements</a>. If you have jobs to announce, please post to the above and/or feel free to leave a comment on this post. Even if you don't see an ad, almost surely your favorite university is looking to hire computer scientists. Check out their website or email someone at the department. The CRA just published a <a href="https://cra.org/2019-member-book-full-size">member book</a>, a collection of one pagers for several departments, almost all of which are trying to grow.<br />
<br />
Needless to say we're trying to greatly expand computing at Illinois Tech, come <a href="https://science.iit.edu/computer-science/people/openings#tenure-track">join us</a>.<br />
<br />
Something new this year, CATCS is <a href="https://thmatters.wordpress.com/2019/10/02/a-solicitation-for-tcs-job-market-profiles/">collecting and disseminating</a> profiles of junior theory researchers on the job market this year. Definitely take advantage whether to sign up as a job seeker or to reach out to theorists on the market once the profiles are posted. The CRA also maintains a <a href="https://cra.org/cv-database/">CV database</a> for candidates for academic, industrial and government research positions.<br />
<br />
While this is a job-seekers market, you still need to put your best foot forward. Reach out to professors at conferences, such as the upcoming FOCS. Polish your CV and get your Google Scholar page in good shape. Practice your job talk, a bad one can kill your visit. Research the people you will see during the interview ahead of time, I like to write down one interesting discussion topic for each. You'll need to sell yourself to non-theorists. Data, cybersecurity and quantum are hot this year, highlight your work in those areas without making it look fake.<br />
<br />
In any case have fun! You'll meet lots of interesting people in your job search and eat way too much.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/10/2019-fall-jobs-post.html"><span class="datestr">at October 17, 2019 08:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/10/17/mathjax-3-jekyll">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/10/17/mathjax-3-jekyll.html">MathJax 3 in Jekyll and Kramdown</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The mathematical equations in my blog posts, and the ones you see on many other web sites, are formatted with <a href="https://www.mathjax.org/">MathJax</a>, a JavaScript library that lets web developers write LaTeX formulas and turns them within your browser into nicely formatted math. The web pages of my blog are generated by <a href="https://jekyllrb.com">Jekyll</a>, a static web site generation system (meaning that it doesn’t go querying a database for its content, they are just web pages stored in files somewhere). I can write my posts in more than one format, but since the <a href="https://11011110.github.io/blog/2017/04/10/back-up.html">April 2017 LiveJournal apocalypse</a> I’ve been writing them using <a href="https://kramdown.gettalong.org">kramdown</a>, a system built into Jekyll for transforming marked-up text files into html ready for browsers to read and display. And so far mostly those different systems have been getting along really well together. Kramdown knows about MathJax and can handle equations in its input without trying to interpret their syntax as kramdown codes, Jekyll only needs me to modify a template somewhere so that my blog pages include an invocation of the MathJax library, and MathJax in your browser happily formats the equations in my posts. But recently, the MathJax people released MathJax version 3.0.0, and that doesn’t work so well with Jekyll and Kramdown. Despite some difficulty, I seem to have gotten them working again. So I thought it might be helpful to post here what went wrong and how I fixed it, in case others run into the same issues.</p>

<p>There are multiple ways of invoking MathJax, but the one I’ve been using is simply to put a line in my html headers saying to load the MathJax library from a content distribution network (asynchronously, so that it doesn’t delay the pages from being shown to readers). Once MathJax loads, it scans through the html that it has been applied to, looking for blocks of math to reformat. The default way of marking these blocks is to include them in <code class="highlighter-rouge">\( ... \)</code> or <code class="highlighter-rouge">\[ ... \]</code> delimiters (for inline formulas and display formulas that go on a line of their own, as you might use in LaTeX if you aren’t still using <code class="highlighter-rouge">$ ... $</code> or <code class="highlighter-rouge">$$ ... $$</code> instead). There are ways of changing the defaults, and those ways have also changed between MathJax 2 and MathJax 3, but I wasn’t using them.</p>

<p>In kramdown, you don’t use the same delimiters for math. Kramdown expects to see mathematical formulas delimited by <code class="highlighter-rouge">$$ ... $$</code> in its marked-up text input, always. It will determine from context whether it’s an inline formula or a display formula. It also doesn’t use the default delimiters in the html that it generates. Instead it outputs html that puts inline formulas inside <code class="highlighter-rouge">&lt;script type="math/tex"&gt; ... &lt;/script&gt;</code> html tags, and, similarly, puts display formulas inside <code class="highlighter-rouge">&lt;script type="math/tex; mode=display"&gt; ... &lt;/script&gt;</code> tags. This all worked in MathJax 2, and these script delimiters are <a href="http://docs.mathjax.org/en/latest/upgrading/earlier/jsMath.html">still recommended in the MathJax 3 documentation</a>, but they don’t work any more.</p>

<p>The right way to fix this would be either to get MathJax 3 to understand the script delimiters, or to get kramdown to know how to generate something that works in MathJax 3, but I don’t have a lot of control over either. And the second-best fix might be to use some other software after kramdown runs, to change the delimiters in the static html files before they get served to anyone, but I don’t have that option on my blog host. Instead, I followed <a href="https://kramdown.gettalong.org/math_engine/mathjax.html">a suggestion in the kramdown documentation</a> for working with <a href="https://katex.org">KaTeX</a>, a competing JavaScript library to MathJax for formatting mathematical equations in web pages. The suggestion is to add to your html files a little bit of glue JavaScript code that recognizes the formula delimiters produced by kramdown and does something with them. In my case, the something that I want to do is just to convert them to the delimiters that MathJax defaultly recognizes.</p>

<p>Timing is crucial here. If I try to run the JavaScript to convert the delimiters too early, they won’t yet be part of the html document that the JavaScript is running on and won’t be found and converted. In particular, running it at the time the html headers are parsed is too early. If I run it too late, the web page will already have been shown to the person viewing it, and each conversion step of each delimiter will also be shown as a slow and unsightly change of the text, on top of the later changes performed by MathJax. You can put JavaScript code at the end of the body of an html page, but that would be too late. Additionally, MathJax should be loaded asynchronously (to prevent slowdowns before the viewer sees something useful from the web page) but must not run until all of the delimiter conversions are complete, because otherwise it won’t see the converted delimiters. So I ended up with the following chunk of JavaScript code, in the Jekyll file <code class="highlighter-rouge">_includes/head.html</code> that gets copied into the headers of my html pages. It waits until the entire document is loaded, converts the delimiters, and then loads the MathJax library.</p>

<figure class="highlight"><pre><code class="language-html"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">"text/javascript"</span><span class="nt">&gt;</span>
<span class="nb">document</span><span class="p">.</span><span class="nx">addEventListener</span><span class="p">(</span><span class="dl">'</span><span class="s1">DOMContentLoaded</span><span class="dl">'</span><span class="p">,</span> <span class="kd">function</span><span class="p">(){</span>
  <span class="nb">document</span><span class="p">.</span><span class="nx">querySelectorAll</span><span class="p">(</span><span class="dl">"</span><span class="s2">script[type='math/tex']</span><span class="dl">"</span><span class="p">).</span><span class="nx">forEach</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">el</span><span class="p">){</span>
    <span class="nx">el</span><span class="p">.</span><span class="nx">outerHTML</span> <span class="o">=</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">(</span><span class="dl">"</span> <span class="o">+</span> <span class="nx">el</span><span class="p">.</span><span class="nx">textContent</span> <span class="o">+</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">)</span><span class="dl">"</span><span class="p">;</span>
  <span class="p">});</span>
  <span class="nb">document</span><span class="p">.</span><span class="nx">querySelectorAll</span><span class="p">(</span><span class="dl">"</span><span class="s2">script[type='math/tex; mode=display']</span><span class="dl">"</span><span class="p">).</span><span class="nx">forEach</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">el</span><span class="p">){</span>
    <span class="nx">el</span><span class="p">.</span><span class="nx">outerHTML</span> <span class="o">=</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">[</span><span class="dl">"</span> <span class="o">+</span> <span class="nx">el</span><span class="p">.</span><span class="nx">textContent</span> <span class="o">+</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">]</span><span class="dl">"</span><span class="p">;</span>
  <span class="p">});</span>
  <span class="kd">var</span> <span class="nx">script</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">createElement</span><span class="p">(</span><span class="dl">'</span><span class="s1">script</span><span class="dl">'</span><span class="p">);</span>
  <span class="nx">script</span><span class="p">.</span><span class="nx">src</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js</span><span class="dl">"</span><span class="p">;</span>
  <span class="nb">document</span><span class="p">.</span><span class="nx">head</span><span class="p">.</span><span class="nx">appendChild</span><span class="p">(</span><span class="nx">script</span><span class="p">);</span>
<span class="p">},</span> <span class="kc">false</span><span class="p">);</span>
<span class="nt">&lt;/script&gt;</span></code></pre></figure>

<p>This could be simplified somewhat with JQuery, but I didn’t do that because this is the only JavaScript in my files and the overhead of loading JQuery seemed too much for that small use. It’s my first JavaScript code ever, so it could probably be done better by someone with more experience. And it’s a bit of a hack, but it seems to work. One other change that I made implies that you won’t see this code in the html for this post, though. The reason is that I don’t want MathJax incorrectly interpreting the example delimiters in my post and in the code block above as actual mathematics formula delimiters. So I also added some Jekyll conditionals that, with the right keyword in the header of a post, disable including the MathJax Javascript, and I’m using that keyword on this post.</p>

<p>…and I thought I was done, until I started looking at some mathematics-intensive older posts, and found some more problems. In a few cases, kramdown has been putting more than just the script delimiters around its math formulas. Within the script tags, the math has been surrounded by a second level of delimiters, <code class="highlighter-rouge">% &lt;![CDATA[ ... %]]&gt;</code>. This coding tells the html parser not to worry about weird special characters in the formula, and it was ignored by the old MathJax because the percent signs cause the rest of their lines to be treated as a comment. But the new MathJax parser doesn’t like the comments (or maybe treats the whole formula as a comment despite the newline characters within it) and displays a blank. This behavior is triggered in kramdown when a formula uses <code class="highlighter-rouge">&lt;</code> instead of <code class="highlighter-rouge">\lt</code> (easy enough to avoid), or when it uses <code class="highlighter-rouge">&amp;</code> (e.g. in an aligned set of equations, not easy to avoid). So the actual code I ended up with is a little more complicated:</p>

<figure class="highlight"><pre><code class="language-html"><span class="nt">&lt;script </span><span class="na">type=</span><span class="s">"text/javascript"</span><span class="nt">&gt;</span>
<span class="nb">document</span><span class="p">.</span><span class="nx">addEventListener</span><span class="p">(</span><span class="dl">'</span><span class="s1">DOMContentLoaded</span><span class="dl">'</span><span class="p">,</span> <span class="kd">function</span><span class="p">(){</span>
  <span class="kd">function</span> <span class="nx">stripcdata</span><span class="p">(</span><span class="nx">x</span><span class="p">)</span> <span class="p">{</span>
    <span class="k">if</span> <span class="p">(</span><span class="nx">x</span><span class="p">.</span><span class="nx">startsWith</span><span class="p">(</span><span class="dl">'</span><span class="s1">% &lt;![CDATA[</span><span class="dl">'</span><span class="p">)</span> <span class="o">&amp;&amp;</span> <span class="nx">x</span><span class="p">.</span><span class="nx">endsWith</span><span class="p">(</span><span class="dl">'</span><span class="s1">%]]&gt;</span><span class="dl">'</span><span class="p">))</span>
      <span class="k">return</span> <span class="nx">x</span><span class="p">.</span><span class="nx">substring</span><span class="p">(</span><span class="mi">11</span><span class="p">,</span><span class="nx">x</span><span class="p">.</span><span class="nx">length</span><span class="o">-</span><span class="mi">4</span><span class="p">);</span>
    <span class="k">return</span> <span class="nx">x</span><span class="p">;</span>
  <span class="p">}</span>
  <span class="nb">document</span><span class="p">.</span><span class="nx">querySelectorAll</span><span class="p">(</span><span class="dl">"</span><span class="s2">script[type='math/tex']</span><span class="dl">"</span><span class="p">).</span><span class="nx">forEach</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">el</span><span class="p">){</span>
    <span class="nx">el</span><span class="p">.</span><span class="nx">outerHTML</span> <span class="o">=</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">(</span><span class="dl">"</span> <span class="o">+</span> <span class="nx">stripcdata</span><span class="p">(</span><span class="nx">el</span><span class="p">.</span><span class="nx">textContent</span><span class="p">)</span> <span class="o">+</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">)</span><span class="dl">"</span><span class="p">;</span>
  <span class="p">});</span>
  <span class="nb">document</span><span class="p">.</span><span class="nx">querySelectorAll</span><span class="p">(</span><span class="dl">"</span><span class="s2">script[type='math/tex; mode=display']</span><span class="dl">"</span><span class="p">).</span><span class="nx">forEach</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">el</span><span class="p">){</span>
    <span class="nx">el</span><span class="p">.</span><span class="nx">outerHTML</span> <span class="o">=</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">[</span><span class="dl">"</span> <span class="o">+</span> <span class="nx">stripcdata</span><span class="p">(</span><span class="nx">el</span><span class="p">.</span><span class="nx">textContent</span><span class="p">)</span> <span class="o">+</span> <span class="dl">"</span><span class="se">\\</span><span class="s2">]</span><span class="dl">"</span><span class="p">;</span>
  <span class="p">});</span>
  <span class="kd">var</span> <span class="nx">script</span> <span class="o">=</span> <span class="nb">document</span><span class="p">.</span><span class="nx">createElement</span><span class="p">(</span><span class="dl">'</span><span class="s1">script</span><span class="dl">'</span><span class="p">);</span>
  <span class="nx">script</span><span class="p">.</span><span class="nx">src</span> <span class="o">=</span> <span class="dl">"</span><span class="s2">https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js</span><span class="dl">"</span><span class="p">;</span>
  <span class="nb">document</span><span class="p">.</span><span class="nx">head</span><span class="p">.</span><span class="nx">appendChild</span><span class="p">(</span><span class="nx">script</span><span class="p">);</span>
<span class="p">},</span> <span class="kc">false</span><span class="p">);</span>
<span class="nt">&lt;/script&gt;</span></code></pre></figure>

<p>If you see any mathematics glitches in any of my old or new posts, please tell me; they could be more interactions like this that I haven’t spotted yet.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102982168716719916">Discuss on Mathstodon</a>, which <a href="https://mathstodon.xyz/@christianp/102955345066926415">also recently switched to MathJax 3</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/10/17/mathjax-3-jekyll.html"><span class="datestr">at October 17, 2019 08:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/10/16/from-one-fold">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/10/16/from-one-fold.html">From one fold to another</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>If an origami crease pattern tells you where to put the folds, but not which way to fold them, you may have many choices left to make. A familiar example is the square grid. You can pleat (accordion-fold) the horizontal lines of the grid, and then pleat the resulting folded strip of paper along the vertical lines; the result will be that each horizontal line is consistently a mountain fold or a valley fold, but each vertical line has folds that alternate between mountain and valley. Or you could pleat the vertical lines first, and then the horizontal lines, getting a different folded state. There are many other choices beyond these two.</p>

<p>The famous <a href="https://en.wikipedia.org/wiki/Miura_fold">Miura-ori</a> is another grid-like fold made out of parallelograms instead of squares, and known for its ability to continuously unfold from its folded state to an expanded and completely open state. Like the square grid, a pattern of crease lines in the same positions has many alternative foldings. In fact, this multiplicity of folded states can be helpful in making the miura-ori out of paper. To make it, you can start with pleating a set of parallel lines (like the square grid) to form a folded strip of paper, and then pleat in a different direction that forms a non-right angle to the first pleating direction. The result will be a fold that is not the Miura-ori, but that has its folds in the same places as the Miura-ori. By reversing the orientation of some of these folds, you get the Miura-ori itself.</p>

<p>When working with the space of all foldings of a crease pattern, it’s unfortunately a bit complicated to understand which patterns fold flat (globally, as an entire structure) and which don’t. In a celebrated result from SODA 1996, Bern and Hayes showed that, for arbitrary crease patterns, even determining whether there exists a globally flat-foldable state is NP-complete. So it’s easier to work with “local flat foldings”, meaning a labeling of all of the creases as mountain or valley folds with the property that the creases surrounding each vertex of the folding pattern could be folded flat, if only all of that other stuff farther away from the vertex didn’t get in the way. It’s easy to check whether a single vertex can be folded flat using <a href="https://en.wikipedia.org/wiki/Maekawa%27s_theorem">Maekawa’s theorem</a>, <a href="https://en.wikipedia.org/wiki/Kawasaki%27s_theorem">Kawasaki’s theorem</a> and related results.</p>

<p><a href="https://11011110.github.io/blog/2014/10/08/forced-creases-in.html">In an earlier paper</a>, my co-authors and I studied the space of all local flat foldings of the Miura-ori crease pattern, from the point of view of seeking <em>forcing sets</em>, mountain-valley assignments to small subsets of the creases with the property that there is only one way to extend them to a locally flat-foldable mountain-valley assignment on the whole crease pattern. My new preprint, “Face flips in origami tessellations” (with Akitaya, Dujmović, Hull, Jain, and Lubiw, <a href="https://arxiv.org/abs/1910.05667">arXiv:1910.05667</a>) instead looks at the connectivity of the system of all local flat foldings. If you’re in one locally flat-folded state (say, the state that you get from pleating the paper once and then pleating the folded strip a second time in a non-orthogonal direction) and you want to get to a different flat-folded state (say, the Miura-ori itself), how many moves does it take? Here, we’re not just allowing any change of a single crease from mountain to valley or vice versa to count as a move. Instead, a move is what happens when you change all of the folds surrounding a single face of the crease pattern, in such a way that the new mountain-valley assignment remains flat-foldable.</p>

<p>The results vary dramatically according to the folding pattern. For the square grid, every square can be flipped, and given any two mountain-valley assignments you can color the squares black or white according to whether they are surrounded an even or odd number of times by cycles of creases that need to be changed. Then the shortest way to get from one assignment to the other is either to flip all the black squares or to flip all the white squares. For a grid of equilateral triangles, it is possible to flip from any mountain-valley assignment to any other one within a polynomial number of steps, but finding the shortest sequence is NP-complete. And for the Miura-ori, it’s again always possible, and there’s a nontrivial polynomial time algorithm for finding the shortest flip sequence. We also have examples of crease patterns forming periodic tilings of the plane where nothing is flippable (so the state space becomes totally disconnected) or where the flippable faces form an independent set (so you merely have to flip the faces whose surrounding mountain-valley assignments differ, in any order). The image below shows two crease patterns of the latter type (called square twist tessellations) with the flippable faces colored blue.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/sqtwist.svg" alt="Square twist tessellations" /></p>

<p>I think the results for the Miura-ori are particularly neat, so I want to outline them in a little more detail. There’s a natural bijection between local flat-foldings of the Miura crease pattern and 3-colorings of the squares of a square grid, which we used <a href="https://11011110.github.io/blog/2014/10/08/forced-creases-in.html">in the earlier paper</a>, and flips of Miura faces correspond in the same way to recoloring steps in which we change the color of a single square. There’s also a natural correspondence (but not a bijection!) between 3-colorings of a grid and “height functions”, giving an integer height to each square, with each two adjacent squares having heights that are one step apart. In one direction, you can get a coloring from a height function by taking the heights mod 3. In the other direction, starting from a colored grid and a choice of the height of one of the squares (with the correct value modulo 3) you can go from there to adjacent squares step by step and figure out what their height has to be. It all works out so that, no matter how you do it, you always get a consistent height function from each 3-coloring. But the function depends on the starting height of the first square. If you add a multiple of 3 to this height, you translate the whole function up or down by that amount, and the translation turns out to be important.</p>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2019/heightfn.svg" alt="Height function of a 3-coloring of a square grid" /></p>

<p>So if you have two different local flat foldings of the Miura crease pattern, you can translate them in this way into two different 3-colorings, and two different height functions. Then you can convert one of the height functions into the other one, move by move, by repeatedly finding the square whose height is farthest away from its final value and shifting it two steps closer. The total number of steps equals half the volume of the three-dimensional space between the two height functions, and that’s the best you can do to get one height function to the other. But it might not be the best you can do to get one 3-coloring to the other, because of the choice of starting heights. To find the minimum number of moves to get from one local flat folding to another there’s one more computation that you have to do first: find two starting heights for the two height functions that makes the volume between them as small as possible.</p>

<p>For a bit more on height functions, 3-colorings, and the “arctic circle” that one gets by choosing 3-colorings of the square grid randomly, you can read the web page “<a href="http://www.joakimlinde.se/projects/3coloring/">random 3-coloring of the square and cubic lattice</a>”, by Joakim Linde, describing his joint work with Cris Moore in this area.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/102975981383652764">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/10/16/from-one-fold.html"><span class="datestr">at October 16, 2019 09:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/10/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/10/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="http://www.mi.fu-berlin.de/inf/groups/ag-ti/theses/master_finished/obenaus_johannes/index.html">Spanning Trees with Low (Shallow) Stabbing Number</a> (<a href="https://mathstodon.xyz/@11011110/102889509192917880"></a>) is the master’s thesis of Johannes Obenaus at the Free University of Berlin and ETH Zürich. The stabbing number of a tree is how many edges a line can cross. Any   points in  have a tree with stabbing number , useful in some data structures. The thesis includes a solution to Open Problem 17.5 of my book <em><a href="https://www.ics.uci.edu/~eppstein/forbidden/">Forbidden Configurations in Discrete Geometry</a></em>: removing points from a point set might cause the minimum stabbing number of a spanning tree to increase.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@unknown/102886703193339814">A pretty result in inversive geometry</a> from the <a href="https://en.wikipedia.org/wiki/Japanese_mathematics">Japanese “Wasan” period</a>, relating the diameters of circles in <a href="https://en.wikipedia.org/wiki/Steiner_chain">Steiner chains</a> between two parallel lines to regular polygons.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2019/10/counting-memories-chiharu-shiota/"><em>Counting Memories</em> by Chiharu Shiota</a> (<a href="https://mathstodon.xyz/@11011110/102902367049416667"></a>), an installation art piece in Katowice, Poland that prompts visitors to reflect on how numbers “connect us universally, comfort us, and help us understand ourselves” by writing down their feelings and memories about numbers that are meaningful to them.</p>
  </li>
  <li>
    <p><a href="https://www.flyingcoloursmaths.co.uk/revisiting-minesweeper/">Revisiting Minesweeper</a> (<a href="https://mathstodon.xyz/@11011110/102908475220191484"></a>). As Uncle Colin shows, calculating the probabilities of different scenarios for the boundary of the cleared region needs to consider as well the number of mines in non-boundary cells. Based on that, one can find the safest move, at least when there are few enough scenarios to list them all. But it looks much harder to find the move most likely to lead to clearing the whole board, even for simple initial situations like the one he shows.</p>
  </li>
  <li>
    <p><a href="https://agtb.wordpress.com/2019/10/05/blind-folks-and-the-evolving-elephant-by-vijay-vazirani/">Blind folks and the evolving elephant</a> (<a href="https://mathstodon.xyz/@11011110/102911898094940725"></a>). Guest post by my colleague Vijay Vazirani on the “Turing’s Invisible Hand” blog, on the different perspectives brought by economics and computer science to problems of matching resource providers with resource consumers.</p>
  </li>
  <li>
    <p>My new dining room ceiling lamp is a trefoil knot (<a href="https://mathstodon.xyz/@11011110/102918306472064994"></a>, <a href="https://www.ics.uci.edu/~eppstein/pix/trefoil/">gallery</a>)!  It’s the “Vornado” LED lamp from <a href="http://www.waclighting.com">WAC lighting</a>. We chose it to replace a halogen lamp that shorted out, burned through its power cable, fell onto the table below it, and shattered hot glass all over the room, fortunately without causing a fire or seriously damaging the table and while the room was unoccupied.</p>

    <p style="text-align: center;"><a href="http://www.ics.uci.edu/~eppstein/pix/trefoil/4.html"><img src="http://www.ics.uci.edu/~eppstein/pix/trefoil/4-m.jpg" alt="Vornado lamp from WAC lighting" style="border-style: solid; border-color: black;" /></a></p>
  </li>
  <li>
    <p><a href="https://www.schneier.com/blog/archives/2019/10/speakers_censor.html">Two speakers censored at AISA, an Australian information security conference</a> (<a href="https://mathstodon.xyz/@11011110/102929889723236018"></a>). One of them is Australian, the other not. They were both scheduled to talk long before and cancelled after a last minute demand from the Australian Cyber Security Centre. As Bruce Schneier writes, this kind of action merely calls attention to their work and makes the Australian government look stupid and repressive while doing nothing to actually increase security.</p>
  </li>
  <li>
    <p><a href="https://www.laphamsquarterly.org/roundtable/beware-cranks">A history of mathematical crankery</a> (<a href="https://mathstodon.xyz/@11011110/102935540787245230"></a>, <a href="https://news.ycombinator.com/item?id=21206633">via</a>), excerpted from David S. Richeson’s book <em>Tales of Impossibility: The 2000-Year Quest to Solve the Mathematical Problems of Antiquity</em></p>
  </li>
  <li>
    <p><a href="https://blog.plover.com/math/cake.html">Incenters of chocolate-iced cakes</a> and <a href="https://blog.plover.com/math/cake-2.html">more fair cake-cutting</a> (<a href="https://mathstodon.xyz/@mjd/102940560151410572"></a>). If you want to divide both cake and frosting (area and perimeter) into equal pieces, it helps to start with a shape that has an inscribed circle.</p>

    <p>Relatedly, Erel Segal has written up for Wikipedia a <a href="https://en.wikipedia.org/wiki/List_of_unsolved_problems_in_fair_division">collection of open problems in fair division</a>.</p>
  </li>
  <li>
    <p><a href="https://www.eff.org/deeplinks/2019/10/tell-hud-algorithms-are-no-excuse-discrimination">The Trump administration wants to roll back fair housing laws by allowing racist algorithms to discriminate on behalf of racist landlords</a> (<a href="https://mathstodon.xyz/@JordiGH/102945130948597301"></a>). The deadline for telling them this is a stupid idea is this Friday, October 18.</p>
  </li>
  <li>
    <p><a href="https://mymodernmet.com/kitkat-origami-packaging-nestle-japan/">Japanese KitKats are replacing plastic packaging with origami paper</a> (<a href="https://mathstodon.xyz/@11011110/102958848550617732"></a>, <a href="https://news.ycombinator.com/item?id=21212664">via</a>), in a bid to be both more fun and more environmentally conscious.</p>
  </li>
  <li>
    <p><em><a href="https://www.ams.org/about-us/LivingProof.pdf">Living Proof</a></em> (<a href="https://cybre.space/@takaeri/102959864574470843"></a>), a free e-book collecting stories of mathematicians about the roadblocks on their paths to where they are now.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Kotzig%27s_theorem">Kotzig’s theorem</a> (<a href="https://mathstodon.xyz/@11011110/102970322274233229"></a>). Every convex polyhedron has an edge whose endpoints have total degree at most 13. You might think that (because the average vertex degree in a convex polyhedron is &lt; 6) there will always be an edge whose endpoints have total degree at most 11, but it’s not true. As Anton Kotzig proved in 1955, the answer is 13. A worst-case example is the triakis icosahedron, whose minimum-degree edges connect vertices of degrees 3 and 10.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/10/15/linkage.html"><span class="datestr">at October 15, 2019 10:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=373">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/10/15/tcs-talk-tuesday-october-22-hao-huang-emory-university/">TCS+ talk: Tuesday, October 22 — Hao Huang, Emory University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Tuesday, October 22th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC) <span style="color: #993300;"><em>(note the unusual day)</em></span>. <strong>Hao Huang</strong> from Emory University will speak about “<em>A proof of the Sensitivity Conjecture</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In the <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" alt="n" class="latex" title="n" />-dimensional hypercube graph, one can easily choose half of the vertices such that they induce an empty graph. However, having even just one more vertex would cause the induced subgraph to contain a vertex of degree at least <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7Bn%7D&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\sqrt{n}" class="latex" title="\sqrt{n}" />. This result is best possible, and improves a logarithmic lower bound shown by Chung, Furedi, Graham and Seymour in 1988. In this talk we will discuss a very short algebraic proof of it.</p>
<p>As a direct corollary of this purely combinatorial result, the sensitivity and degree of every boolean function are polynomially related. This solves an outstanding foundational problem in theoretical computer science, the Sensitivity Conjecture of Nisan and Szegedy.</p></blockquote>
<p> </p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/10/15/tcs-talk-tuesday-october-22-hao-huang-emory-university/"><span class="datestr">at October 15, 2019 09:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2019/10/15/phd-student-basic-research-on-algorithms-at-it-university-of-copenhagen-apply-by-december-1-2019/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2019/10/15/phd-student-basic-research-on-algorithms-at-it-university-of-copenhagen-apply-by-december-1-2019/">PhD student, basic research on algorithms at IT University of Copenhagen (apply by December 1, 2019)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>BARC is a leading center for fundamental algorithmic research, headed by VILLUM Investigator Mikkel Thorup, aiming to attract top talent from around the world to an ambitious, creative, collaborative, and fun environment. We use the power of mathematics we strive to create fundamental breakthroughs in algorithmic thinking.</p>
<p>Website: <a href="https://candidate.hr-manager.net/ApplicationInit.aspx?cid=119&amp;ProjectId=181097&amp;DepartmentId=3439&amp;MediaId=1282">https://candidate.hr-manager.net/ApplicationInit.aspx?cid=119&amp;ProjectId=181097&amp;DepartmentId=3439&amp;MediaId=1282</a><br />
Email: thore@itu.dk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2019/10/15/phd-student-basic-research-on-algorithms-at-it-university-of-copenhagen-apply-by-december-1-2019/"><span class="datestr">at October 15, 2019 07:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
