<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at April 29, 2020 12:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12633">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12633">On Perturbation Resilience of Non-Uniform $k$-Center</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bandyapadhyay:Sayan.html">Sayan Bandyapadhyay</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12633">PDF</a><br /><b>Abstract: </b>The Non-Uniform $k$-center (NUkC) problem has recently been formulated by
Chakrabarty, Goyal and Krishnaswamy [ICALP, 2016] as a generalization of the
classical $k$-center clustering problem. In NUkC, given a set of $n$ points $P$
in a metric space and non-negative numbers $r_1, r_2, \ldots , r_k$, the goal
is to find the minimum dilation $\alpha$ and to choose $k$ balls centered at
the points of $P$ with radius $\alpha\cdot r_i$ for $1\le i\le k$, such that
all points of $P$ are contained in the union of the chosen balls. They showed
that the problem is NP-hard to approximate within any factor even in tree
metrics. On the other hand, they designed a "bi-criteria" constant
approximation algorithm that uses a constant times $k$ balls. Surprisingly, no
true approximation is known even in the special case when the $r_i$'s belong to
a fixed set of size 3. In this paper, we study the NUkC problem under
perturbation resilience, which was introduced by Bilu and Linial
[Combinatorics, Probability and Computing, 2012]. We show that the problem
under 2-perturbation resilience is polynomial time solvable when the $r_i$'s
belong to a constant sized set. However, we show that perturbation resilience
does not help in the general case. In particular, our findings imply that even
with perturbation resilience one cannot hope to find any "good" approximation
for the problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12633"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12590">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12590">In-Place Bijective Burrows-Wheeler Transforms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/K=ouml=ppl:Dominik.html">Dominik Köppl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hashimoto:Daiki.html">Daiki Hashimoto</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hendrian:Diptarama.html">Diptarama Hendrian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shinohara:Ayumi.html">Ayumi Shinohara</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12590">PDF</a><br /><b>Abstract: </b>One of the most well-known variants of the Burrows-Wheeler transform (BWT)
[Burrows and Wheeler, 1994] is the bijective BWT (BBWT) [Gil and Scott, arXiv
2012], which applies the extended BWT (EBWT) [Mantaci et al., TCS 2007] to the
multiset of Lyndon factors of a given text. Since the EBWT is invertible, the
BBWT is a bijective transform in the sense that the inverse image of the EBWT
restores this multiset of Lyndon factors such that the original text can be
obtained by sorting these factors in non-increasing order. In this paper, we
present algorithms constructing or inverting the BBWT in-place using quadratic
time. We also present conversions from the BBWT to the BWT, or vice versa,
either (a) in-place using quadratic time, or (b) in the run-length compressed
setting using $O(n \lg r / \lg \lg r)$ time with $O(r \lg n)$ bits of words,
where $r$ is the sum of character runs in the BWT and the BBWT.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12590"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12532">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12532">In-Place Parallel-Partition Algorithms using Exclusive-Read-and-Write Memory: An In-Place Algorithm With Provably Optimal Cache Behavior</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, Alek Westover <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12532">PDF</a><br /><b>Abstract: </b>We present an in-place algorithm for the parallel partition problem that has
linear work and polylogarithmic span. The algorithm uses only exclusive
read/write shared variables, and can be implemented using parallel-for-loops
without any additional concurrency considerations (i.e., the algorithm is
EREW). A key feature of the algorithm is that it exhibits provably optimal
cache behavior, up to small-order factors.
</p>
<p>We also present a second in-place EREW algorithm that has linear work and
span $O(\log n \cdot \log \log n)$, which is within an $O(\log\log n)$ factor
of the optimal span. By using this low-span algorithm as a subroutine within
the cache-friendly algorithm, we are able to obtain a single EREW algorithm
that combines their theoretical guarantees: the algorithm achieves span $O(\log
n \cdot \log \log n)$ and optimal cache behavior. As an immediate consequence,
we also get an in-place EREW quicksort algorithm with work $O(n \log n)$, span
$O(\log^2 n \cdot \log \log n)$.
</p>
<p>Whereas the standard EREW algorithm for parallel partitioning is
memory-bandwidth bound on large numbers of cores, our cache-friendly algorithm
is able to achieve near-ideal scaling in practice by avoiding the
memory-bandwidth bottleneck. The algorithm's performance is comparable to that
of the Blocked Strided Algorithm of Francis, Pannan, Frias, and Petit, which is
the previous state-of-the art for parallel EREW sorting algorithms, but which
lacks theoretical guarantees on its span and cache behavior.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12532"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12497">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12497">Forty New Invariants of N-Periodics in the Elliptic Billiard</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reznik:Dan.html">Dan Reznik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garcia:Ronaldo.html">Ronaldo Garcia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koiller:Jair.html">Jair Koiller</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12497">PDF</a><br /><b>Abstract: </b>We present some 40 newfound invariants displayed by N-periodics in the
Elliptic Billiard, obtained through experimental exploration. These involve
distances, areas, angles and centers of mass of N-periodics and associated
polygons (inner, outer, pedal, antipedal). Some depend on the parity of N,
others on other positional constraints. A few invariants have already been
proven with elegant tools of Analytic and Algebraic Geometry. We welcome reader
input to add to the list of proofs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12497"><span class="datestr">at April 29, 2020 12:08 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12465">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12465">Succinct Filters for Sets of Unknown Sizes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Mingmou.html">Mingmou Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yin:Yitong.html">Yitong Yin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Huacheng.html">Huacheng Yu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12465">PDF</a><br /><b>Abstract: </b>The membership problem asks to maintain a set $S\subseteq[u]$, supporting
insertions and membership queries, i.e., testing if a given element is in the
set. A data structure that computes exact answers is called a dictionary. When
a (small) false positive rate $\epsilon$ is allowed, the data structure is
called a filter.
</p>
<p>The space usages of the standard dictionaries or filters usually depend on
the upper bound on the size of $S$, while the actual set can be much smaller.
</p>
<p>Pagh, Segev and Wieder (FOCS'13) were the first to study filters with varying
space usage based on the current $|S|$. They showed in order to match the space
with the current set size $n=|S|$, any filter data structure must use
$(1-o(1))n(\log(1/\epsilon)+(1-O(\epsilon))\log\log n)$ bits, in contrast to
the well-known lower bound of $N\log(1/\epsilon)$ bits, where $N$ is an upper
bound on $|S|$. They also presented a data structure with almost optimal space
of $(1+o(1))n(\log(1/\epsilon)+O(\log\log n))$ bits provided that
$n&gt;u^{0.001}$, with expected amortized constant insertion time and worst-case
constant lookup time.
</p>
<p>In this work, we present a filter data structure with improvements in two
aspects:
</p>
<p>- it has constant worst-case time for all insertions and lookups with high
probability;
</p>
<p>- it uses space $(1+o(1))n(\log (1/\epsilon)+\log\log n)$ bits when
$n&gt;u^{0.001}$, achieving optimal leading constant for all $\epsilon=o(1)$.
</p>
<p>We also present a dictionary that uses $(1+o(1))n\log(u/n)$ bits of space,
matching the optimal space in terms of the current size, and performs all
operations in constant time with high probability.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12465"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12258">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12258">How to hide a clique?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feige:Uriel.html">Uriel Feige</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Grinberg:Vadim.html">Vadim Grinberg</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12258">PDF</a><br /><b>Abstract: </b>In the well known planted clique problem, a clique (or alternatively, an
independent set) of size $k$ is planted at random in an Erdos-Renyi random
$G(n, p)$ graph, and the goal is to design an algorithm that finds the maximum
clique (or independent set) in the resulting graph. We introduce a variation on
this problem, where instead of planting the clique at random, the clique is
planted by an adversary who attempts to make it difficult to find the maximum
clique in the resulting graph. We show that for the standard setting of the
parameters of the problem, namely, a clique of size $k = \sqrt{n}$ planted in a
random $G(n, \frac{1}{2})$ graph, the known polynomial time algorithms can be
extended (in a non-trivial way) to work also in the adversarial setting. In
contrast, we show that for other natural settings of the parameters, such as
planting an independent set of size $k=\frac{n}{2}$ in a $G(n, p)$ graph with
$p = n^{-\frac{1}{2}}$, there is no polynomial time algorithm that finds an
independent set of size $k$, unless NP has randomized polynomial time
algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12258"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12224">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12224">A $(1-e^{-1}-\varepsilon)$-Approximation for the Monotone Submodular Multiple Knapsack Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fairstein:Yaron.html">Yaron Fairstein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kulik:Ariel.html">Ariel Kulik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naor:Joseph.html">Joseph Naor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raz:Danny.html">Danny Raz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shachnai:Hadas.html">Hadas Shachnai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12224">PDF</a><br /><b>Abstract: </b>We study the problem of maximizing a monotone submodular function subject to
a Multiple Knapsack constraint (SMKP) . The input is a set $I$ of items, each
associated with a non-negative weight, and a set of bins, each having a
capacity. Also, we are given a submodular, monotone and non-negative function
$f$ over subsets of the items. The objective is to find a subset of items $A
\subseteq I$ and a packing of the items in the bins, such that $f(A)$ is
maximized. SMKP is a natural extension of both Multiple Knapsack and the
problem of monotone submodular maximization subject to a knapsack constraint.
</p>
<p>Our main result is a nearly optimal polynomial time
$(1-e^{-1}-\varepsilon)$-approximation algorithm for the problem, for any
$\varepsilon&gt;0$. Our algorithm relies on a refined analysis of techniques for
constrained submodular optimization combined with sophisticated application of
tools used in the development of approximation schemes for packing problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12224"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12223">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12223">Online Mincut: Advice, Randomization and More</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Banerjee:Avah.html">Avah Banerjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Ding:Guoli.html">Guoli Ding</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12223">PDF</a><br /><b>Abstract: </b>In this paper we study the mincut problem on connected graphs in the online
setting. We consider the vertex arrival model; whenever a new vertex arrives
it's adjacency to previously revealed vertices are given. An online algorithm
must make an irrevocable decision to determine the side of the cut that the
vertex must belong to in order to minimize the size of the cut.
</p>
<p>Various models are considered. 1) For classical and advice models we give
tight bounds on the competitive ratio of deterministic algorithms. 2) Next we
consider few semi-adversarial inputs: random order of arrival with
adversarially generated and sparse graphs. 3) Lastly we introduce a new model,
which we call the friendly sequence model. We look at several online
optimization problems : mincut, maxcut and submodular maximization and show
that there are input ordering where a greedy strategy can produce an optimal
answer.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12223"><span class="datestr">at April 29, 2020 12:08 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12222">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12222">Extending Partial 1-Planar Drawings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganian:Robert.html">Robert Ganian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hamm:Thekla.html">Thekla Hamm</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klute:Fabian.html">Fabian Klute</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/N=ouml=llenburg:Martin.html">Martin Nöllenburg</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12222">PDF</a><br /><b>Abstract: </b>Algorithmic extension problems of partial graph representations such as
planar graph drawings or geometric intersection representations are of growing
interest in topological graph theory and graph drawing. In such an extension
problem, we are given a tuple $(G,H,\mathcal{H})$ consisting of a graph $G$, a
connected subgraph $H$ of $G$ and a drawing $\mathcal{H}$ of $H$, and the task
is to extend $\mathcal{H}$ into a drawing of $G$ while maintaining some desired
property of the drawing, such as planarity.
</p>
<p>In this paper we study the problem of extending partial 1-planar drawings,
which are drawings in the plane that allow each edge to have at most one
crossing. In addition we consider the subclass of IC-planar drawings, which are
1-planar drawings with independent crossings. Recognizing 1-planar graphs as
well as IC-planar graphs is \NP-complete and the \NP-completeness easily
carries over to the extension problem. Therefore, our focus lies on
establishing the tractability of such extension problems in a weaker sense than
polynomial-time tractability. Here, we show that both problems are
fixed-parameter tractable when parameterized by the number of edges missing
from $H$, i.e., the edge deletion distance between $H$ and $G$. The second part
of the paper then turns to a more powerful parameterization which is based on
measuring the vertex+edge deletion distance between the partial and complete
drawing, i.e., the minimum number of vertices and edges that need to be deleted
to obtain $H$ from $G$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12222"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12166">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12166">An algorithmic weakening of the Erd\H{o}s-Hajnal conjecture</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonnet:=Eacute=douard.html">Édouard Bonnet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thomass=eacute=:St=eacute=phan.html">Stéphan Thomassé</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tran:Xuan_Thang.html">Xuan Thang Tran</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Watrigant:R=eacute=mi.html">Rémi Watrigant</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12166">PDF</a><br /><b>Abstract: </b>We study the approximability of the Maximum Independent Set (MIS) problem in
$H$-free graphs (that is, graphs which do not admit $H$ as an induced
subgraph). As one motivation we investigate the following conjecture: for every
fixed graph $H$, there exists a constant $\delta &gt; 0$ such that MIS can be
$n^{1 - \delta}$-approximated in $H$-free graphs, where $n$ denotes the number
of vertices of the input graph. We first prove that a constructive version of
the celebrated Erd\H{o}s-Hajnal conjecture implies ours. We then prove that the
set of graphs $H$ satisfying our conjecture is closed under the so-called graph
substitution. This, together with the known polynomial-time algorithms for MIS
in $H$-free graphs (e.g. $P_6$-free and fork-free graphs), implies that our
conjecture holds for many graphs $H$ for which the Erd\H{o}s-Hajnal conjecture
is still open. We then focus on improving the constant $\delta$ for some graph
classes: we prove that the classical Local Search algorithm provides an
$OPT^{1-\frac{1}{t}}$-approximation in $K_{t,t}$-free graphs (hence a
$\sqrt{OPT}$-approximation in $C_4$-free graphs), and, while there is a simple
$\sqrt{n}$-approximation in triangle-free graphs, it cannot be improved to
$n^{\frac{1}{4}-\varepsilon}$ for any $\varepsilon &gt; 0$ unless $NP \subseteq
BPP$. More generally, we show that there is a constant $c$ such that MIS in
graphs of girth $\gamma$ cannot be $n^{\frac{c}{\gamma}}$-approximated. Up to a
constant factor in the exponent, this matches the ratio of a known
approximation algorithm by Monien and Speckenmeyer, and by Murphy. To the best
of our knowledge, this is the first strong (i.e., $\Omega(n^\delta)$ for some
$\delta &gt; 0$) inapproximability result for Maximum Independent Set in a proper
hereditary class.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12166"><span class="datestr">at April 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12144">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12144">Multi-robot motion planning of k-colored discs is PSPACE-hard</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brocken:Thomas.html">Thomas Brocken</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heijden:G=_Wessel_van_der.html">G. Wessel van der Heijden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kostitsyna:Irina.html">Irina Kostitsyna</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lo=Wong:Lloyd_E=.html">Lloyd E. Lo-Wong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Surtel:Remco_J=_A=.html">Remco J. A. Surtel</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12144">PDF</a><br /><b>Abstract: </b>In the problem of multi-robot motion planning, a group of robots, placed in a
polygonal domain with obstacles, must be moved from their starting positions to
a set of target positions. We consider the specific case of unlabeled disc
robots of two different sizes. That is, within one class of robots, where a
class is given by the robots' size, any robot can be moved to any of the
corresponding target positions. We prove that the decision problem of whether
there exists a schedule moving the robots to the target positions is
PSPACE-hard.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12144"><span class="datestr">at April 29, 2020 12:08 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4369">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/04/28/phase-2-ready-or-not-here-it-comes/">Phase 2, ready or not, here it comes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Yesterday the Italian prime minister announced the timeline of the loosening of the lockdown. Some manufacturing restarted yesterday, and some customer-facing businesses will gradually reopen between next Monday and the beginning of June.</p>
<p><span id="more-4369"></span></p>
<p>Since the start of the lockdown 51 days ago, it was clear that the condition to “reopen” was to have in place a “test-trace-isolate” plan to find infected people as soon as possible after their contagion, trace their contacts, and isolate them. For this, one needs an infrastructure for large-scale testing with quick turnaround, a well-staffed agency to do manual tracing or an app to do it automatically, and facilities to isolate people who are infected and not in need of hospitalization.</p>
<p>None of this has been done. There hasn’t been a sufficient ramp-up of testing capacity; as far as I know no additional people have been hired and trained for manual contact-tracing; there is an app for digital contact-tracing, but the plan to adopt it appears to have been shelved; if people test positive and are well they are asked to stay home, potentially with their family members, who are free to leave as they please.</p>
<p>All our eggs are in the basket of social distancing. The humor site Kotiomkin posted “Basically, phase 2 will rely on everybody’s common sense. We are fucked”.</p>
<p>The problem is that social distancing requires a common-sense avoidance of close contacts with other people, and the government can give guidelines on how to achieve it, but eventually it has to rely on everybody’s sense of responsibility. Unfortunately, the national mood around regulations is to immediately look for loopholes. </p>
<p>For example the initial lockdown measures stipulated that one could leave home to go buy groceries. Then when the police would stop people tens of miles away from their home, people would say “I drove here to buy groceries”, “but we are thirty miles away from where you live”, “yes but here the groceries are better”. So a subsequent amendment stipulated that one could buy groceries only in the town of residence, making it hard for people living next to a town border, for whom the closest grocery store was across the town line. In fact, every time I have encountered a crazy Italian law or regulation, and asked around for the likely reason it was instituted, it was usually to close a loophole in a previous regulation, which in turn had been put in place to close a loophole in a third regulation, and basically it’s loophole-closing all the way down to <a href="https://en.wikipedia.org/wiki/Roman_law">Roman law</a>.</p>
<p>I think that, from this point on, the story of the Italian covid-19 epidemic will not show the future of the rest of the Western world, but will evolve in its own timeline. Meanwhile, there are a couple of lessons that are still relevant, particularly in the comparison between Lombardy and NYC, which continue to track each other remarkably well.</p>
<p><img src="https://lucatrevisan.files.wordpress.com/2020/04/2020-05-28-nyc-daily.png?w=584" alt="2020-05-28-nyc-daily" class="alignnone size-full wp-image-4375" /><img src="https://lucatrevisan.files.wordpress.com/2020/04/2020-05-28-nyc.png?w=584" alt="2020-05-28-nyc" class="alignnone size-full wp-image-4376" /></p>
<p>One is that, at one point, it was decided to move older people with mild cases of covid-19 from hospital to nursing homes, to open up beds in hospitals. Since the personnel of nursing homes are not trained in the safety procedures for infectious diseases, and since nursing homes host older, frail people who are the highest-risk category for this illness, the result was a huge number of deaths in these nursing homes. Now nursing homes in New York are <a href="https://www.nytimes.com/2020/04/24/us/nursing-homes-coronavirus.html">being asked to take covid-19 patients from hospitals</a>.</p>
<p>The other is that an analysis of all-cause mortality shows a spike in March such that the difference between the typical March all-cause mortality and the March 2020 all-cause mortality is much bigger than the number of confirmed covid-19 deaths. Now the same phenomenon is being <a href="https://www.nytimes.com/interactive/2020/04/27/upshot/coronavirus-deaths-new-york-city.html"> observed in New York City</a>, with numbers similar to Lombardy’s. Notably, the baseline all-case mortality rate in Lombardy is much higher than in New York City (because  population growth has stalled and the demographic skews older), so while the absolute number of additional deaths is similar, the relative increase is a much more dramatic 6x in NYC versus roughly 4x in Lombardy. </p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/04/28/phase-2-ready-or-not-here-it-comes/"><span class="datestr">at April 28, 2020 04:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/061">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/061">TR20-061 |  Tree-depth and the Formula Complexity of Subgraph Isomorphism | 

	Benjamin Rossman, 

	Deepanshu Kush</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
For a fixed "pattern" graph $G$, the $\textit{colored}$ $G\textit{-subgraph isomorphism problem}$ (denoted $\mathrm{SUB}(G)$) asks, given an $n$-vertex graph $H$ and a coloring $V(H) \to V(G)$, whether $H$ contains a properly colored copy of $G$. The complexity of this problem is tied to parameterized versions of $\mathit{P}$ ${=}?$ $\mathit{NP}$ and $\mathit{L}$ ${=}?$ $\mathit{NL}$, among other questions. An overarching goal is to understand the complexity of $\mathrm{SUB}(G)$, under different computational models, in terms of natural invariants of the pattern graph $G$.

In this paper, we establish a close relationship between the $\textit{formula complexity}$ of $\mathrm{SUB}$ and an invariant known as $\textit{tree-depth}$ (denoted $\mathrm{td}(G)$). $\mathrm{SUB}(G)$ is known to be solvable by monotone $\mathit{AC^0}$ formulas of size $O(n^{\mathrm{td}(G)})$. Our main result is an $n^{\tilde\Omega(\mathrm{td}(G)^{1/3})}$ lower bound for formulas that are monotone $\textit{or}$ have sub-logarithmic depth. This complements a lower bound of Li, Razborov and Rossman (SICOMP 2017) relating tree-width and $\mathit{AC^0}$ circuit size. As a corollary, it implies a stronger homomorphism preservation theorem for first-order logic on finite structures (Rossman, ITCS 2017).

The technical core of this result is an $n^{\Omega(k)}$ lower bound in the special case where $G$ is a complete binary tree of height $k$, which we establish using the $\textit{pathset framework}$ introduced in (Rossman, SICOMP 2018). (The lower bound for general patterns follows via a recent excluded-minor characterization of tree-depth (Czerwi\'nski et al, arXiv:1904.13077).) Additional results of this paper extend the pathset framework and improve upon both, the best known upper and lower bounds on the average-case formula size of $\mathrm{SUB}(G)$ when $G$ is a path.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/061"><span class="datestr">at April 28, 2020 11:49 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/04/28/tenure-track-assistant-associate-or-full-professor-theory-of-computation-at-university-of-groningen-the-netherlands-apply-by-may-5-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/04/28/tenure-track-assistant-associate-or-full-professor-theory-of-computation-at-university-of-groningen-the-netherlands-apply-by-may-5-2020/">Tenure Track Assistant, Associate or Full Professor Theory of Computation at University of Groningen, the Netherlands  (apply by May 5, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The University of Groningen seeks for an outward looking researcher in Computer Science who will perform research on theory of computation, broadly construed, in relation to new (neuromorphic) computing systems and architectures. We offer a challenging position in a unique world-class research environment, where close collaborations between research groups with different expertise are encouraged.</p>
<p>Website: <a href="https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0007KLP">https://www.rug.nl/about-ug/work-with-us/job-opportunities/?details=00347-02S0007KLP</a><br />
Email: b.noheda@rug.nl, j.b.t.m.roerdink@rug.nl and/or j.h.m.van.der.velde@rug.nl</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/04/28/tenure-track-assistant-associate-or-full-professor-theory-of-computation-at-university-of-groningen-the-netherlands-apply-by-may-5-2020/"><span class="datestr">at April 28, 2020 08:50 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12683">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12683">Approximate Turing Kernelization for Problems Parameterized by Treewidth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hols:Eva=Maria_C=.html">Eva-Maria C. Hols</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kratsch:Stefan.html">Stefan Kratsch</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pieterse:Astrid.html">Astrid Pieterse</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12683">PDF</a><br /><b>Abstract: </b>We extend the notion of lossy kernelization, introduced by Lokshtanov et al.
[STOC 2017], to approximate Turing kernelization. An $\alpha$-approximate
Turing kernel for a parameterized optimization problem is a polynomial-time
algorithm that, when given access to an oracle that outputs $c$-approximate
solutions in $O(1)$ time, obtains an $(\alpha \cdot c)$-approximate solution to
the considered problem, using calls to the oracle of size at most $f(k)$ for
some function $f$ that only depends on the parameter.
</p>
<p>Using this definition, we show that Independent Set parameterized by
treewidth $\ell$ has a $(1+\varepsilon)$-approximate Turing kernel with
$O(\frac{\ell^2}{\varepsilon})$ vertices, answering an open question posed by
Lokshtanov et al. [STOC 2017]. Furthermore, we give
$(1+\varepsilon)$-approximate Turing kernels for the following graph problems
parameterized by treewidth: Vertex Cover, Edge Clique Cover, Edge-Disjoint
Triangle Packing and Connected Vertex Cover.
</p>
<p>We generalize the result for Independent Set and Vertex Cover, by showing
that all graph problems that we will call "friendly" admit
$(1+\varepsilon)$-approximate Turing kernels of polynomial size when
parameterized by treewidth. We use this to obtain approximate Turing kernels
for Vertex-Disjoint $H$-packing for connected graphs $H$, Clique Cover,
Feedback Vertex Set and Edge Dominating Set.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12683"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12667">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12667">Robust Algorithms under Adversarial Injections</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Garg:Paritosh.html">Paritosh Garg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kale:Sagar.html">Sagar Kale</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rohwedder:Lars.html">Lars Rohwedder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Svensson:Ola.html">Ola Svensson</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12667">PDF</a><br /><b>Abstract: </b>In this paper, we study streaming and online algorithms in the context of
randomness in the input. For several problems, a random order of the input
sequence---as opposed to the worst-case order---appears to be a necessary evil
in order to prove satisfying guarantees. However, algorithmic techniques that
work under this assumption tend to be vulnerable to even small changes in the
distribution. For this reason, we propose a new \emph{adversarial injections}
model, in which the input is ordered randomly, but an adversary may inject
misleading elements at arbitrary positions. We believe that studying algorithms
under this much weaker assumption can lead to new insights and, in particular,
more robust algorithms. We investigate two classical combinatorial-optimization
problems in this model: Maximum matching and cardinality constrained monotone
submodular function maximization. Our main technical contribution is a novel
streaming algorithm for the latter that computes a $0.55$-approximation. While
the algorithm itself is clean and simple, an involved analysis shows that it
emulates a subdivision of the input stream which can be used to greatly limit
the power of the adversary.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12667"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12646">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12646">Input-Sparsity Low Rank Approximation in Schatten Norm</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Yi.html">Yi Li</a>, David Woodruff <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12646">PDF</a><br /><b>Abstract: </b>We give the first input-sparsity time algorithms for the rank-$k$ low rank
approximation problem in every Schatten norm. Specifically, for a given
$n\times n$ matrix $A$, our algorithm computes $Y,Z\in \mathbb{R}^{n\times k}$,
which, with high probability, satisfy $\|A-YZ^T\|_p \leq
(1+\epsilon)\|A-A_k\|_p$, where $\|M\|_p = \left (\sum_{i=1}^n \sigma_i(M)^p
\right )^{1/p}$ is the Schatten $p$-norm of a matrix $M$ with singular values
$\sigma_1(M), \ldots, \sigma_n(M)$, and where $A_k$ is the best rank-$k$
approximation to $A$. Our algorithm runs in time
$\tilde{O}(\operatorname{nnz}(A) +
n^{\alpha_p}\operatorname{poly}(k/\epsilon))$, where $\alpha_p = 1$ for $p\in
[1,2)$ and $\alpha_p = 1 + (\omega-1)(1-2/p)$ for $p&gt;2$ and $\omega \approx
2.374$ is the exponent of matrix multiplication. For the important case of $p =
1$, which corresponds to the more "robust" nuclear norm, we obtain
$\tilde{O}(\operatorname{nnz}(A) + n \cdot \operatorname{poly}(k/\epsilon))$
time, which was previously only known for the Frobenius norm ($p = 2$).
Moreover, since $\alpha_p &lt; \omega$ for every $p$, our algorithm has a better
dependence on $n$ than that in the singular value decomposition for every $p$.
Crucial to our analysis is the use of dimensionality reduction for Ky-Fan
$p$-norms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12646"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12496">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12496">Learning and Testing Junta Distributions with Subcube Conditioning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Xi.html">Xi Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jayaram:Rajesh.html">Rajesh Jayaram</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levi:Amit.html">Amit Levi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Waingarten:Erik.html">Erik Waingarten</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12496">PDF</a><br /><b>Abstract: </b>We study the problems of learning and testing junta distributions on
$\{-1,1\}^n$ with respect to the uniform distribution, where a distribution $p$
is a $k$-junta if its probability mass function $p(x)$ depends on a subset of
at most $k$ variables. The main contribution is an algorithm for finding
relevant coordinates in a $k$-junta distribution with subcube conditioning
[BC18, CCKLW20]. We give two applications:
</p>
<p>1. An algorithm for learning $k$-junta distributions with
$\tilde{O}(k/\epsilon^2) \log n + O(2^k/\epsilon^2)$ subcube conditioning
queries, and
</p>
<p>2. An algorithm for testing $k$-junta distributions with $\tilde{O}((k +
\sqrt{n})/\epsilon^2)$ subcube conditioning queries.
</p>
<p>All our algorithms are optimal up to poly-logarithmic factors.
</p>
<p>Our results show that subcube conditioning, as a natural model for accessing
high-dimensional distributions, enables significant savings in learning and
testing junta distributions compared to the standard sampling model. This
addresses an open question posed by Aliakbarpour, Blais, and Rubinfeld [ABR17].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12496"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12424">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12424">An Efficient Index Method for the Optimal Route Query over Multi-Cost Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yang:Yajun.html">Yajun Yang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Hang.html">Hang Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Hong.html">Hong Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Qinghua.html">Qinghua Hu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Xin.html">Xin Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12424">PDF</a><br /><b>Abstract: </b>Smart city has been consider the wave of the future and the route
recommendation in networks is a fundamental problem in it. Most existing
approaches for the shortest route problem consider that there is only one kind
of cost in networks. However, there always are several kinds of cost in
networks and users prefer to select an optimal route under the global
consideration of these kinds of cost. In this paper, we study the problem of
finding the optimal route in the multi-cost networks. We prove this problem is
NP-hard and the existing index techniques cannot be used to this problem. We
propose a novel partition-based index with contour skyline techniques to find
the optimal route. We propose a vertex-filtering algorithm to facilitate the
query processing. We conduct extensive experiments on six real-life networks
and the experimental results show that our method has an improvement in
efficiency by an order of magnitude compared to the previous heuristic
algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12424"><span class="datestr">at April 28, 2020 11:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12143">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12143">Lazy listing of equivalence classes -- A paper on dynamic programming and tropical circuits</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yishu.html">Yishu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mary:Arnaud.html">Arnaud Mary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sagot:Marie=France.html">Marie-France Sagot</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinaimeri:Blerina.html">Blerina Sinaimeri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12143">PDF</a><br /><b>Abstract: </b>When a problem has more than one solution, it is often important, depending
on the underlying context, to list them all. Even when the listing can be done
in polynomial delay, that is, spending no more than polynomial time to go from
one solution to the next, this can be costly as the number of solutions
themselves may be huge, including sometimes exponential. This paper addresses
this problem by proposing what we called a \emph{lazy listing} algorithm. By
this we mean that, instead of listing all solutions, we list, in an efficient
way, directly only the equivalence classes or one representative per class.
Besides the need to then provide an \emph{a priori} relation of equivalence
between solutions, we place ourselves in the special context where the problem
to be addressed, either after some preliminary polynomial time dynamic
programming computation or directly from the start, leads to a decomposable
tropical circuit.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12143"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12063">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12063">Low-Degree Hardness of Random Optimization Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gamarnik:David.html">David Gamarnik</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jagannath:Aukosh.html">Aukosh Jagannath</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Alexander_S=.html">Alexander S. Wein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12063">PDF</a><br /><b>Abstract: </b>We consider the problem of finding nearly optimal solutions of optimization
problems with random objective functions. Such problems arise widely in the
theory of random graphs, theoretical computer science, and statistical physics.
Two concrete problems we consider are (a) optimizing the Hamiltonian of a
spherical or Ising p-spin glass model, and (b) finding a large independent set
in a sparse Erdos-Renyi graph. Two families of algorithms are considered: (a)
low-degree polynomials of the input---a general framework that captures methods
such as approximate message passing and local algorithms on sparse graphs,
among others; and (b) the Langevin dynamics algorithm, a canonical Monte Carlo
analogue of the gradient descent algorithm (applicable only for the spherical
p-spin glass Hamiltonian).
</p>
<p>We show that neither family of algorithms can produce nearly optimal
solutions with high probability. Our proof uses the fact that both models are
known to exhibit a variant of the overlap gap property (OGP) of near-optimal
solutions. Specifically, for both models, every two solutions whose objectives
are above a certain threshold are either close or far from each other. The crux
of our proof is the stability of both algorithms: a small perturbation of the
input induces a small perturbation of the output. By an interpolation argument,
such a stable algorithm cannot overcome the OGP barrier.
</p>
<p>The stability of the Langevin dynamics is an immediate consequence of the
well-posedness of stochastic differential equations. The stability of
low-degree polynomials is established using concepts from Gaussian and Boolean
Fourier analysis, including noise sensitivity, hypercontractivity, and total
influence.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12063"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.12002">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.12002">Finding Planted Cliques in Sublinear Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mardia:Jay.html">Jay Mardia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Asi:Hilal.html">Hilal Asi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chandrasekher:Kabir_Aladin.html">Kabir Aladin Chandrasekher</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.12002">PDF</a><br /><b>Abstract: </b>We study the planted clique problem in which a clique of size $k$ is planted
in an Erd\H{o}s-R\'enyi graph of size $n$ and one wants to recover this planted
clique. For $k=\Omega(\sqrt{n})$, polynomial time algorithms can find the
planted clique. The fastest such algorithms run in time linear $O(n^2)$ (or
nearly linear) in the size of the input [FR10,DGGP14,DM15a]. In this work, we
develop sublinear time algorithms that find the planted clique when
$k=\omega(\sqrt{n \log \log n})$. Our algorithms can recover the clique in time
$\widetilde{O}\left(n+(\frac{n}{k})^{3}\right)=\widetilde{O}\left(n^{\frac{3}{2}}\right)$
when $k=\Omega(\sqrt{n\log n})$, and in time
$\widetilde{O}\left(n^2/\exp{\left(\frac{k^2}{24n}\right)}\right)$ for
$\omega(\sqrt{n\log \log n})=k=o(\sqrt{n\log{n}})$. An ${\Omega}(n)$ running
time lower bound for the planted clique recovery problem follows easily from
the results of [RS19] and therefore our recovery algorithms are optimal
whenever $k = \Omega(n^{\frac{2}{3}})$. As the lower bound of [RS19] builds on
purely information theoretic arguments, it cannot provide a detection lower
bound stronger than $\widetilde{\Omega}(\frac{n^2}{k^2})$. Since our algorithms
for $k = \Omega(\sqrt{n \log n})$ run in time
$\widetilde{O}\left(\frac{n^3}{k^3} + n\right)$, we show stronger lower bounds
based on computational hardness assumptions. With a slightly different notion
of the planted clique problem we show that the Planted Clique Conjecture
implies the following. A natural family of non-adaptive algorithms---which
includes our algorithms for clique detection---cannot reliably solve the
planted clique detection problem in time $O\left(
\frac{n^{3-\delta}}{k^3}\right)$ for any constant $\delta&gt;0$. Thus we provide
evidence that if detecting small cliques is hard, it is also likely that
detecting large cliques is not \textit{too} easy.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.12002"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2004.11937">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2004.11937">A linear fixed parameter tractable algorithm for connected pathwidth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kant=eacute=:Mamadou_Moustapha.html">Mamadou Moustapha Kanté</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paul:Christophe.html">Christophe Paul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thilikos:Dimitrios_M=.html">Dimitrios M. Thilikos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2004.11937">PDF</a><br /><b>Abstract: </b>The graph parameter of pathwidth can be seen as a measure of the topological
resemblance of a graph to a path. A popular definition of pathwidth is given in
terms of node search where we are given a system of tunnels that is
contaminated by some infectious substance and we are looking for a search
strategy that, at each step, either places a searcher on a vertex or removes a
searcher from a vertex and where an edge is cleaned when both endpoints are
simultaneously occupied by searchers. It was proved that the minimum number of
searchers required for a successful cleaning strategy is equal to the pathwidth
of the graph plus one. Two desired characteristics for a cleaning strategy is
to be monotone (no recontamination occurs) and connected (clean territories
always remain connected). Under these two demands, the number of searchers is
equivalent to a variant of pathwidth called {\em connected pathwidth}. We prove
that connected pathwidth is fixed parameter tractable, in particular we design
a $2^{O(k^2)}\cdot n$ time algorithm that checks whether the connected
pathwidth of $G$ is at most $k.$ This resolves an open question by
[Dereniowski, Osula, and Rz{\k{a}}{\.{z}}ewski, Finding small-width connected
path-decompositions in polynomial time. Theor. Comput. Sci., 794:85-100, 2019].
For our algorithm, we enrich the typical sequence technique that is able to
deal with the connectivity demand. Typical sequences have been introduced in
[Bodlaender and Kloks. Efficient and constructive algorithms for the pathwidth
and treewidth of graphs. J. Algorithms, 21(2):358-402, 1996] for the design of
linear parameterized algorithms for treewidth and pathwidth. The proposed
extension is based on an encoding of the connectivity property that is quite
versatile and may be adapted so to deliver linear parameterized algorithms for
the connected variants of other width parameters as well.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2004.11937"><span class="datestr">at April 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7716">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/04/27/lessons-from-covid-19-what-works-online-and-what-doesnt/">Lessons from COVID-19: What works online and what doesn’t</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>(I am now on <a href="https://twitter.com/boazbaraktcs">Twitter</a> ,  so you can follow this blog there too if you prefer it. –Boaz)</p>



<p>Between Zoom meetings and deadlines, I thought I’d jot down a few of my impressions so far on what lessons we can draw from this period on how well research and education can work online.  I’ve had a few surprises in both directions – things that worked better than I would have expected, and aspects that were more problematic than I realized. These are personal impressions – please do comment on your own experiences.</p>



<p>As a rule of thumb, the interactions that most successfully replicate online are those that are relatively short and focused (an hour or so – e.g., a focused research meeting, seminar talk, or a lecture in a course).  Other interactions (e.g., faculty meetings) are also fairly easily to port online, perhaps because the original wasn’t that great to begin with.</p>



<p>The things that are harder to replicate are sustained interactions over longer periods. These include more extended and less directed research collaborations, informal workshops, as well as support for students outside lectures in education.</p>



<p><strong>Works well: Research seminars</strong></p>



<p>I’ve been pleasantly surprised by how effective research seminars such as our <a href="https://mltheory.org/">machine learning theory seminar</a> are over Zoom. In particular these were no less interactive than physical seminars – in fact people are offten <em>more</em> comfortable asking questions on chat than they would during in-person seminars. I hope such seminars become common practice even after this period ends- flying a speaker across the country or the world to give an hour talk doesn’t makes much sense given that there is a perfectly satisfactory alternative. </p>



<p><strong>Works well: Lectures</strong></p>



<p>This term I am teaching <a href="https://cs127.boazbarak.org/schedule/">cryptography</a>, and online lectures on Zoom have gone surprisingly well (after  working out some <a href="https://windowsontheory.org/2020/03/26/technology-for-theory-covid-19-edition/">technical issues</a>). Students participate on chat and ask questions, and seem to be following the lecture quite well. The important caveat is that lectures only work well for the students that attend and can follow them. For students who need extra support, it’s become much harder to access it.  It’s also much easier for students to (literally) “fall off the screen” and fall behind in a course, which brings me to the next point.</p>



<p><strong>Works less well: Support outside lectures</strong></p>



<p>Lectures are just one component of a course. Most of students’ learning occurs outside the classroom, where students meet together and work on problem sets, or discuss course material. These interactions between students (both related and unrelated to course) are where much of their intellectual growth happens. </p>



<p>All these interactions are greatly diminished online, and I did not yet see a good alternative. I’ve seen reduced attendance in office hours and sections, and reports are that students find it much harder to have the sort of chance discussions and opportunities to find study partners that they value so much.  If anything, this experience had made me <em>less</em> positive about the possibility of online education replacing physical colleges (though there are interesting <a href="https://en.wikipedia.org/wiki/Minerva_Schools_at_KGI">hybrid models</a>, where the students are co-located but lecturers are online).</p>



<p><strong>Works less well: unstructured research collaborations</strong></p>



<p>A focused meeting reporting on results or deciding on work allocation works pretty well over Zoom. So far it seems that extended brainstorming meetings, such as talking to someone over several hours in a coffeeshop, are much harder to replicate. In particular, a good part of such meetings is often spent with people staring in silence into their notebooks. As I <a href="https://twitter.com/boazbaraktcs/status/1253330145789673473">wrote</a>,  mutual silence seems to be very hard to do over Zoom.</p>



<p>Generally, informal week-long workshops, where much time is devoted to unstructured discussions, are ones that are most important to hold in person, and are hard (or maybe impossible) to replicate online. I have still not attended an online conference, but I suspect that these aspects of the conference would also be the ones hardest to replicate.</p>



<p><strong>Works well: faculty meetings</strong></p>



<p>I’ve always found it hard to bring a laptop to a faculty meeting and get work done, while listening with one ear to what’s going on. This is so much easier over Zoom <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" style="height: 1em;" class="wp-smiley" alt="🙂" /></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/04/27/lessons-from-covid-19-what-works-online-and-what-doesnt/"><span class="datestr">at April 27, 2020 09:01 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1676">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/04/27/whats-your-story/">What’s Your Story?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Last quarter, I taught <a href="https://omereingold.wordpress.com/cs-353-the-practice-of-theory-research/">a course on research methods</a> in TOC, which gave me an opportunity to think through many aspects of research. I was promoting a human-centric perspective on research: how to facilitate better research by addressing the conditions needed for an individual researcher and groups of researchers to succeed. As science is a communal effort, the communication of science is critical, and thus one of the topics we covered is oral presentations.</p>
<p>There are plenty of resources about research talks, and mostly they emphasize form over matter. How many words in a slide? How many slides in a talk? how to and how not to use font colors? How to and how not to use animation? and so on. While all of these are important, I find that the failing of many research talks is on a much more basic level.</p>
<p>Think back to a research talk you heard recently, or to one you heard a few months ago. You may remember how you felt and what you thought of the talk but what do you remember of this talk in terms of content? Most of us will find that we don’t remember much, I rarely do. Yet in our presentations, we often follow a research-paper-like mold and squeeze in many little details that are somehow important to us, forgetting that they will all vanish in our audience’s memory soon after (or completely missed in the first place). Giving a talk (writing a paper, writing a blog post etc.) is about communication: who is your audience? what are the limitation of the medium? what is the message you want to convey? Since so little stays with the audience long term, it makes sense to make sure that this little will be what seems most important for you to convey.</p>
<p>The idea I am promoting here is not new, and there are various techniques towards this goal. One (which I think Oded Goldreich shared with me), is to think of audience’s attention as a limited currency. Whenever you share a big idea you spend a big token and other ideas cost a smaller token. Imagine you have one or two big tokens and a few smaller tokens. <a href="https://www.youtube.com/watch?v=5OFAhBw0OXs">Another approach</a>, emphasizes the notion of <strong>a premise</strong>. The idea promoted here is that a talk needs a premise and this should be the title of the talk. Furthermore, every slide needs a premise and it should be the title of the slide. A premise is a main idea and is a complete sentence. It is not unusual to find a slide titled “Analysis” or “Efficiency” but neither of these is a premise. “Problem X has an efficient algorithm” could be. The talk’s premise could help you distill what you want the audience to take out of your talk. It also helps shape the talk, as everything that doesn’t serve the premise shouldn’t be there. Note that each paper can provoke many different premises and thus many different talks.</p>
<p>Here I want to play with a different idea, that I find intriguing, even if it may seem a bit extreme. It will not be controversial that a good talk (and paper) tells a story. After all, humans understand and remember narratives. But could we take inspiration from the form of storytelling in fiction writing? A vast literature, classifies different kinds of stories and explores their templates (see for example <a href="http://storybistro.com/7-story-frameworks/">this short discussion</a>).  Can we find analogues to these types in scientific research talks?</p>
<p>The type of story that is easiest to relate to is the <strong>Quest/Hero’s Journey</strong> (think Lord of the Rings). These have several distinct ingredients: a call to adventure, tests, allies, enemies, ordeal, reward, victorious return. Some research talks that follow this template do it well and preserve a sense of suspense and excitement, others seem like a long list of problems and the tricks that the work uses to handle them.</p>
<p>I believe that many other story templates can find analogues is research talks as well. Here are my initial attempts:</p>
<ul>
<li><strong>Coming of age</strong> stories – this area of research previously only had naive ideas but this works brings significant depth.</li>
<li><strong>The Under<span style="color: #000000;">dog</span></strong><span style="color: #000000;"> (think David and Goliath): a modest technique that concurred a great challenge.</span></li>
<li><strong>Rags to Riches</strong> (think the Ugly Duckling): an area or technique that were not successful prove powerful.
<ul>
<li>Similarly: <strong>Rebirth</strong> (reinvention, renewal).</li>
</ul>
</li>
<li><strong>Comedy</strong> (or the Clarity Tale) – conceptual works shedding a new perspective.</li>
<li><strong>Tragedy</strong> (or the Cautionary Tale) – Some impossibility results come to mind (couldn’t we view Arrow’s impossibility theorem as being tragic?)</li>
<li><strong>Redemption stories</strong>: the field so far has missed the point, was misleading or harmful, but this work makes amends.</li>
</ul>
<p>Can you suggest papers and a story type that could fit them?</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/04/27/whats-your-story/"><span class="datestr">at April 27, 2020 04:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/060">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/060">TR20-060 |  Leakage-Resilient Extractors and Secret-Sharing against Bounded Collusion Protocols | 

	Eshan Chattopadhyay, 

	Xin Li, 

	Vipul Goyal, 

	Jesse Goodman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a recent work, Kumar, Meka, and Sahai (FOCS 2019) introduced the notion of bounded collusion protocols (BCPs), in which $N$ parties wish to compute some joint function $f:(\{0,1\}^n)^N\to\{0,1\}$ using a public blackboard, but such that only $p$ parties may collude at a time. This generalizes well studied models in multiparty communication complexity, such as the number-in-hand (NIH) and number-on-forehead (NOF) models, which are just endpoints on this rich spectrum. We construct explicit hard functions against this spectrum, and achieve a tradeoff between collusion and complexity. Using this, we obtain improved leakage-resilient secret sharing schemes against bounded collusion protocols. 

Our main tool in obtaining hard functions against BCPs are explicit constructions of leakage resilient extractors against BCPs for a wide range of parameters. Kumar et al. (FOCS 2019) studied  such extractors and called them cylinder intersection extractors. In fact, such extractors directly yield correlation bounds against BCPs. We focus on the following setting: the input to the extractor consists of $N$ independent sources of length $n$, and the leakage function Leak $:(\{0,1\}^n)^N\to\{0,1\}^\mu\in\mathcal{F}$ is a BCP with some collusion bound $p$ and leakage (output length) $\mu$. While our extractor constructions are very general, we highlight some interesting parameter settings:

1. In the case when the input sources are uniform, and $p=0.99N$ parties collude, our extractor can handle $n^{\Omega(1)}$ bits of leakage, regardless of the dependence between $N,n$. The best NOF lower bound (i.e., $p=N-1$) on the other hand requires $N&lt;\log n$ even to handle $1$ bit of leakage.

2. Next, we show that for the same setting as above, we can drop the entropy requirement to $k=$ polylog $n$, while still handling polynomial leakage for $p=0.99N$.  This resolves an open question about cylinder intersection extractors raised by Kumar et al. (FOCS 2019), and we find an application of such low entropy extractors in a new type of secret sharing.

We also provide an explicit compiler that transforms any function with high NOF (distributional) communication complexity into a leakage-resilient extractor that can handle polylogarithmic entropy and substantially more leakage against BCPs. Thus any improvement of NOF lower bounds will immediately yield better leakage-resilient extractors.

Using our extractors against BCPs, we obtain improved $N$-out-of-$N$ leakage-resilient secret sharing schemes. The previous best scheme from Kumar et al. (FOCS 2019) required share size to grow exponentially in the collusion bound, and thus cannot efficiently handle $p=\omega(\log N)$. Our schemes have no dependence of this form, and can thus handle collusion size $p=0.99N$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/060"><span class="datestr">at April 27, 2020 06:12 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/059">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/059">TR20-059 |  Pr-ZSUBEXP is not contained in Pr-RP | 

	Gonen Krak, 

	Noam Parzanchevski, 

	Amnon Ta-Shma</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We unconditionally prove there exists a promise problem in promise ZSUBEXP that cannot be solved in promise RP. 
The proof technique builds upon Kabanets' easy witness method [Kab01] as implemented by Impagliazzo et. al [IKW02], with a separate diagonalization carried out on each of the two alternatives in the win-win argument. We remark that even though the easy witness method is a key component in many celebrated results in derandomization, we are not aware of any previous unconditional separation like the one we show.

We remark that the result relativizes. We could not prove a similar result for total functions, nor for functions in ZTime(T(n)) for T(n) below a half-exponential function (i.e., T such that T(T(n)) &lt; 2^n).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/059"><span class="datestr">at April 27, 2020 05:27 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/058">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/058">TR20-058 |  Interactive Proofs for Verifying Machine Learning | 

	Jonathan Shafer, 

	Amir Yehudayoff, 

	Shafi Goldwasser, 

	Guy Rothblum</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We consider the following question: using a source of labeled data and interaction with an untrusted prover, what is the complexity of verifying that a given hypothesis is "approximately correct"? We study interactive proof systems for PAC verification, where a verifier that interacts with a prover is required to accept good hypotheses, and reject bad hypotheses. Both the verifier and the prover are efficient and have access to data samples from an unknown distribution. We are interested in cases where the verifier can use significantly less data than is required for (agnostic) PAC learning, or use a substantially cheaper data source (e.g., using only random samples for verification, even though learning requires membership queries). We believe that today, when data and data-driven algorithms are quickly gaining prominence, the question of verifying purported outcomes of data analyses is very well-motivated.
		
We show three main results. First, we prove that for a specific hypothesis class, verification is significantly cheaper than learning in terms of the number of random samples required, even if the verifier engages with the prover only in a single-round (NP-like) protocol. Moreover, for this class we prove that single-round verification is also significantly cheaper than testing closeness to the class. Second, for the broad class of Fourier-sparse boolean functions, we show a multi-round (IP-like) verification protocol, where the prover uses membership queries, and the verifier is able to assess the result while only using random samples. Third, we show that verification is not always more efficient. Namely, we show a class of functions where verification requires as many samples as learning does, up to a logarithmic factor.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/058"><span class="datestr">at April 27, 2020 01:42 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16982">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/">Time For Some Jokes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Can we still smile?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/unknown-139/" rel="attachment wp-att-16991"><img src="https://rjlipton.files.wordpress.com/2020/04/unknown-2.jpeg?w=600" alt="" class="alignright size-full wp-image-16991" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Hardy and Littlewood]</font></td>
</tr>
</tbody>
</table>
<p>
John Littlewood lived through the 1918–1919 flu pandemic, yet he appears not to have remarked on it in print. Nor can we find mention of it by Godfrey Hardy in <em>A Mathematician’s Apology</em>—though Hardy did write about the ravages of WW I.</p>
<p>
Today, Ken and I thought you might like some fun comments that are not about the current pandemic. </p>
<p>
This is not to say we are ignoring it. We are all fighting the virus in one way or another. Our hearts go out to those of you fighting it directly. We are all worried about ourselves and others. We are stuck at home, at least most of us. We are all in this terrible time together. We hope you all are safe and well. </p>
<p>
We thought we would list a few jokes and stories that you might enjoy. We wrote recently about one kind of mathematical <a href="https://rjlipton.wordpress.com/2020/02/28/reductions-and-jokes/">joke</a> that can be given various proportions of pure levity and mathematical content. Our friends Lance Fortnow and Bill Gasarch, plus commenters in their <a href="https://blog.computationalcomplexity.org/2006/06/funniest-computer-science-joke-ever.html">item</a>, collected some jokes on the computer science side.</p>
<p>
Littlewood’s notion of “mathematical joke” leaned more on mathematical content, though his <a href="https://en.wikipedia.org/wiki/A_Mathematician's_Miscellany">memoir</a> <em>A Mathematician’s Miscellany</em> includes many funny stories as well. At the end of his introduction to the book, he wrote:</p>
<blockquote><p><b> </b> <em> A good mathematical joke is better, and better mathematics, than a dozen mediocre papers. </em>
</p></blockquote>
<p></p><p>
We will start at the levity end. This is almost a math <a href="http://web.sonoma.edu/Math/faculty/falbo/jokes.html">joke</a>:</p>
<blockquote><p><b> </b> <em> The Daily News published a story saying that one-half of the MP (Members of Parliament) were crooks.<br />
The Government took great exception to that and demanded a retraction and an apology.<br />
The newspaper responded the next day with an apology and reported that one-half of the MPs were not crooks. </em>
</p></blockquote>
<p></p><p>
We like this one, even if it is not really a hardcore math one. It does rely on the fact that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B1%7D%7B2%7D+%2B+%5Cfrac%7B1%7D%7B2%7D+%3D+1.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{1}{2} + \frac{1}{2} = 1.}" class="latex" title="{\frac{1}{2} + \frac{1}{2} = 1.}" /></p>
<p>
</p><p></p><h2> Jokes and More </h2><p></p>
<p></p><p>
The following are some examples that we hope you all like. They are from a variety of sources: </p>
<ul>
<li>
Jokes that mathematicians think are <a href="https://www.businessinsider.com/13-math-jokes-that-every-mathematician-finds-absolutely-hilarious-2013-5">funny</a>. <p></p>
</li><li>
Some are from <a href="https://cstheory.stackexchange.com/questions/3111/funny-tcs-related-papers-etc">StackExchange</a>. <p></p>
</li><li>
Others are from Andrej Cherkaev’s <a href="https://www.math.utah.edu/~cherk/mathjokes.html">page</a>.
</li></ul>
<p>We have lightly edited a few.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> “My age is two billion years old,” said Paul Erdös. The point is: </p>
<blockquote><p><b> </b> <em> When I was seventeen years old it was said the earth was two billion years old. Now they say it is four billion years old. So my age is about two billion years old. </em>
</p></blockquote>
<p></p><p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> There was a statistician that drowned crossing a river <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /> It was 3 feet deep on average. </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> An infinite number of mathematicians walk into a bar. The first one orders a beer. The second orders half a beer. The third orders a third of a beer. The bartender bellows, “Get the heck out of here, are you trying to ruin me?”</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> An chemist, a physicist, and a mathematician are stranded on an island when a can of food rolls ashore. The chemist and the physicist comes up with many ingenious ways to open the can. Then suddenly the mathematician gets a bright idea: “Assume we have a can opener <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" />” </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> A theorist decides she wants to learn more about practical problems. She sees a seminar with the title: “The Theory of Gears.” So she goes. The speaker stands up and begins, “The theory of gears with a finite number of teeth is well known <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /></p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> The reason that every major university maintains a department of mathematics is that it is cheaper to do this than to institutionalize all those people.</p>
<p>
Regarding the last one, Littlewood did after all write in his book:</p>
<blockquote><p><b> </b> <em> Mathematics is a dangerous profession; an appreciable proportion of us go mad. </em>
</p></blockquote>
<p></p><p>
This appears to have been a playful swipe at Hardy’s decision to leave Cambridge for Oxford. It was couched in a discussion of events that would seem to have had tiny probabilities before they happened. </p>
<p>
The last two we’ve picked out from the above sites verge into philosophy:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> The cherry theorem: Question: What is a small, red, round thing that has a cherry pit inside? <br />
Answer: A cherry.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> René Descartes went into his favorite bar and the bartender asked, “would you like your usual drink tonight, Monsieur Descartes?” Descartes replied “I think not.” Then he promptly ceased to exist.</p>
<p>
</p><p></p><h2> Wrong Derivations, Right Results </h2><p></p>
<p></p><p>
Littlewood’s standards for a “mathematical joke” were higher than ours, but we will start by adapting an example from this MathOverflow <a href="https://mathoverflow.net/questions/38856/jokes-in-the-sense-of-littlewood-examples">discussion</a> of Littlewood-style jokes. Sometimes we can play a joke on ourselves by deriving a result we know is right but with an incorrect proof. Here is the example:</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet}" class="latex" title="{\bullet}" /> <a href="https://www.reddit.com/r/math/comments/1bntfg/are_there_or_can_there_be_jokes_or_puns_in/">Casting out 6’s</a>. Suppose we want to simplify the fraction <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7B166%7D%7B664%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{166}{664}}" class="latex" title="{\frac{166}{664}}" />. We can use the rule of casting out 6’s to get </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B166%7D%7B664%7D+%3D+%5Cfrac%7B16%7D%7B64%7D+%3D+%5Cfrac%7B1%7D%7B4%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. " class="latex" title="\displaystyle  \frac{166}{664} = \frac{16}{64} = \frac{1}{4}. " /></p>
<p>
The rule works quite generally:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B1666%7D%7B6664%7D+%3D+%5Cfrac%7B16666%7D%7B66664%7D+%3D+%5Cfrac%7B166666%7D%7B666664%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots " class="latex" title="\displaystyle  \frac{1666}{6664} = \frac{16666}{66664} = \frac{166666}{666664} = \cdots " /></p>
<p></p><p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B26%7D%7B65%7D+%3D+%5Cfrac%7B266%7D%7B665%7D+%3D+%5Cfrac%7B2666%7D%7B6665%7D+%3D+%5Cfrac%7B26666%7D%7B66665%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots " class="latex" title="\displaystyle  \frac{26}{65} = \frac{266}{665} = \frac{2666}{6665} = \frac{26666}{66665} = \cdots " /></p>
<p>You can even turn the paper upside down and cast out the <img src="https://s0.wp.com/latex.php?latex=%7B6%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{6}" class="latex" title="{6}" />‘s that you see then:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B19%7D%7B95%7D+%3D+%5Cfrac%7B199%7D%7B995%7D+%3D+%5Cfrac%7B1999%7D%7B9995%7D+%3D+%5Cfrac%7B19999%7D%7B99995%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots " class="latex" title="\displaystyle  \frac{19}{95} = \frac{199}{995} = \frac{1999}{9995} = \frac{19999}{99995} = \cdots " /></p>
<p></p><p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B49%7D%7B98%7D+%3D+%5Cfrac%7B499%7D%7B998%7D+%3D+%5Cfrac%7B4999%7D%7B9998%7D+%3D+%5Cfrac%7B49999%7D%7B99998%7D+%3D+%5Ccdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots " class="latex" title="\displaystyle  \frac{49}{98} = \frac{499}{998} = \frac{4999}{9998} = \frac{49999}{99998} = \cdots " /></p>
<p>
Note, this is a joke: The rule of course does not actually work all the time: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B56%7D%7B65%7D+%3D+%5Cfrac%7B5%7D%7B5%7D+%3D+1.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. " class="latex" title="\displaystyle  \frac{56}{65} = \frac{5}{5} = 1. " /></p>
<p></p><p><br />
We thought to try to come up with our own examples, or at least blend in other sources. It once struck me (Ken), on reading a column by Martin Gardner on difference equations, that they give a “convincing proof” of <img src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0^0 = 1}" class="latex" title="{0^0 = 1}" />. Consider the powers of a natural number <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />, say <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k = 5}" class="latex" title="{k = 5}" />. Take differences like so: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+5+%26+%26+25+%26+%26+125+%26+%26+625+%26+%26+%5Cdots%5C%5C+%26+4+%26+%26+20+%26+%26+100+%26+%26+500+%26+%26+%5Cdots%5C%5C+%26+%26+16+%26+%26+80+%26+%26+400+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+64+%26+%26+320+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+256+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" title="\displaystyle  \begin{array}{ccccccccccc} 1 &amp; &amp; 5 &amp; &amp; 25 &amp; &amp; 125 &amp; &amp; 625 &amp; &amp; \dots\\ &amp; 4 &amp; &amp; 20 &amp; &amp; 100 &amp; &amp; 500 &amp; &amp; \dots\\ &amp; &amp; 16 &amp; &amp; 80 &amp; &amp; 400 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 64 &amp; &amp; 320 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 256 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " /></p>
<p>
The powers of <img src="https://s0.wp.com/latex.php?latex=%7Bk-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k-1}" class="latex" title="{k-1}" /> always appear on the bottom diagonal. Thus we have: <img src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(k-1)^0 = 1}" class="latex" title="{(k-1)^0 = 1}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(k-1)}" class="latex" title="{(k-1)}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%28k-1%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(k-1)^2}" class="latex" title="{(k-1)^2}" />, and so on. Now do this for <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k = 1}" class="latex" title="{k = 1}" />:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Bccccccccccc%7D+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+1+%26+%26+%5Cdots%5C%5C+%26+0+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots%5C%5C+%26+%26+0+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%5C%5C+%26+%26+%26+0+%26+%26+0+%26+%26+%5Cdots+%26+%26+%26%5C%5C+%26+%26+%26+%26+0+%26+%26+%26+%26+%5C%5C+%26+%26+%26+%26+%26+%5Cddots+%26+%26+%26+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " class="latex" title="\displaystyle \begin{array}{ccccccccccc} 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; 1 &amp; &amp; \dots\\ &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots\\ &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; \\ &amp; &amp; &amp; 0 &amp; &amp; 0 &amp; &amp; \dots &amp; &amp; &amp;\\ &amp; &amp; &amp; &amp; 0 &amp; &amp; &amp; &amp; \\ &amp; &amp; &amp; &amp; &amp; \ddots &amp; &amp; &amp; \end{array} " /></p>
<p>The diagonal now holds the powers of <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />. It thus follows that <img src="https://s0.wp.com/latex.php?latex=%7B0%5E0+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0^0 = 1}" class="latex" title="{0^0 = 1}" />.</p>
<p></p><h2> Open Problems </h2><p></p>
<p>What are your favorite mathematical jokes? Please send them to us. Be safe. Be well.</p>
<p><a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/sign-2/" rel="attachment wp-att-16987"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/04/sign-1.png?w=300&amp;h=111" class="aligncenter size-medium wp-image-16987" height="111" /></a></p>
<p>
[fixed equations in last main section]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/04/26/time-for-some-jokes/"><span class="datestr">at April 27, 2020 12:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-32902056.post-3346245643417184590">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/goldberg.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://paulwgoldberg.blogspot.com/2020/04/surge-pricing-anyone.html">Surge pricing, anyone?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div style="text-align: left;" dir="ltr">One social contribution that I tentatively attribute to Uber is popularisation of the concept of surge pricing. That is, we try to call an Uber and all-too-frequently get told that we have to pay a premium at this particular point in time, due to high demand. On the other hand, recent shortages of toilet paper, paracetamol, and certain foods were not accompanied by any kind of surge pricing, and the limits imposed on how much stuff you can buy, were not so effective in keeping these goods available. At this point, things have improved, although I have not been able to buy flour recently: the shortage of flour in the supermarkets I visit seems to be chronic.<br /><br />Now I appreciate the objection to charging to charging a premium to allcomers, rich and poor alike, in the context of vital food and medicine. (Although, limits on purchases can also be criticised as being unfair to a single purchaser buying for a large family, or a key worker who is short of time and doesn't want to search excessively for a desired item.) In trying to advocate surge pricing, let me turn instead to possible examples less controversial, such as hairdressers and garden centres. When these establishments are allowed to reopen, it seems reasonable that they should charge a premium (temporarily). Not only do they need the money, but it would help to control a flood of customers all causing long queues and infecting each other at close quarters. To be honest, I’m not optimistic that this will happen, since they will still worry about accusations of price-gouging, plus there’s the question of how big a premium is appropriate.<br /><br /><a href="https://www.economist.com/britain/2020/04/25/the-impossibility-of-measuring-inflation-in-a-pandemic">An article in the Economist</a> highlights a related problem, which is the difficulty of measuring the rate of inflation, at a time when various goods and services (whose prices get used to measure inflation) are unavailable. Coming back to flour, it may be felt that some of it (not all!) should be sold at market price, meaning one that some people will pay, but where it stays on the shelves for a few days, at least. There is a moral case against selling goods too cheaply, which is that it becomes an attempt to hide a problem — a successful attempt, if inflation cannot be measured.<br /><br />Finally, the problem discussed here touches on a defect at the heart of traditional economic theory, which is the <a href="https://en.wikipedia.org/wiki/Arrow%E2%80%93Debreu_model">celebrated existence</a> of “correct” prices, unaccompanied by a means of arriving at those prices. The Algorithmic Game Theory community has quite rightly worried about price discovery and its computational obstacles. But the obstacles are also social, and status quo bias plays a big part.</div></div>







<p class="date">
by Paul Goldberg (noreply@blogger.com) <a href="http://paulwgoldberg.blogspot.com/2020/04/surge-pricing-anyone.html"><span class="datestr">at April 26, 2020 02:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-21129445.post-1422354062966011246">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/pizza.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mysliceofpizza.blogspot.com/2020/04/john-conway.html">John Conway</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div style="text-align: left;" dir="ltr">I managed to join a zoom meeting yesterday to honor John Conway. Peter Winkler paid tribute with a story about the brick-stacking puzzle (was interesting to hear "skintle" in context of puzzles). Roger Penrose paid tribute with tilings but also an old classic,  Morley's Trisector Theorem. Others like Don Knuth appeared in the pre-meeting chat room, but I could not stay for the entire 3 hrs+ homage. Thanks to everyone!  JHC, RIP.  I was reminded that we are the math, friends and puzzles we leave behind.<br /><br />Friends Ada and Phillip have created a short hardware tribute to JHC, video embedded below. <a href="https://blog.adafruit.com/category/adafruitchronicles/" target="_blank">Ada and Phillip,</a> thanks for repurposing your NYC manufacturing line to produce face shields and PPEs.  Loved the <a href="https://blog.adafruit.com/2020/04/27/the-woman-who-discovered-the-first-coronavirus/" target="_blank">blog on the scientist who discovered the first coronavirus</a> and the handsanitizer made in Detroit.<br /><br /><div style="clear: both; text-align: center;" class="separator"></div><br /></div></div>







<p class="date">
by metoo (noreply@blogger.com) <a href="http://mysliceofpizza.blogspot.com/2020/04/john-conway.html"><span class="datestr">at April 26, 2020 02:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/057">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/057">TR20-057 |  Polynomial Data Structure Lower Bounds in the Group Model | 

	Omri Weinstein, 

	Gleb Posobin, 

	Oded Regev, 

	Alexander Golovnev</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Proving super-logarithmic data structure lower bounds in the static \emph{group model} has been a fundamental challenge in computational geometry since the early 80's. We prove a polynomial ($n^{\Omega(1)}$) lower bound for an explicit range counting problem of $n^3$ convex polygons in $\R^2$ (each with $n^{\tilde{O}(1)}$ facets/semialgebraic-complexity), against linear storage arithmetic data structures in the group model. Our construction and analysis are based on a combination of techniques in Diophantine approximation, pseudorandomness, and compressed sensing---in particular, on the existence and partial derandomization of optimal \emph{binary} compressed sensing matrices in the polynomial sparsity regime ($k = n^{1-\delta}$). As a byproduct, this establishes a (logarithmic) separation between compressed sensing matrices and the stronger RIP property.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/057"><span class="datestr">at April 26, 2020 11:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/056">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/056">TR20-056 |  Catalytic Approaches to the Tree Evaluation Problem | 

	Ian Mertz, 

	James  Cook</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The study of branching programs for the Tree Evaluation Problem, introduced by S. Cook et al. (TOCT 2012), remains one of the most promising approaches to separating L from P. Given a label in $[k]$ at each leaf of a complete binary tree and an explicit function  in $[k]^2 \to [k]$ for recursively computing the value of each internal node from its children, the problem is to compute the value at the root node. The problem is parameterized by the alphabet size $k$ and the height $h$ of the tree. A branching program implementing the straightforward recursive algorithm uses $\Theta((k + 1)^h)$ states, organized into $2^h-1$ layers of width up to $k^h$. Until now no better deterministic algorithm was known.

We present a series of three new algorithms solving the Tree Evaluation Problem. They are inspired by the work of Buhrman et al. on catalytic space (STOC 2012), applied outside the catalytic-space setting. First we give a novel branching program with $2^{4h} poly(k)$ layers of width $2^{3k}$, which beats the straightforward algorithm when $h = \omega(k / \log k)$. Next we give a branching program with $k^{2h} poly(k)$ layers of width $k^3$.  This has total size comparable to the straightforward algorithm, but is implemented using the catalytic framework. Finally we interpolate between the two algorithms to give a branching program with $(O(k/h))^{2h} poly(k)$ layers of width $(O(k/h))^{\epsilon h}$ for any constant $\epsilon &gt; 0$, which beats the straightforward algorithm for all $h \geq k^{1/2 + poly(\epsilon)}$. These are the first deterministic branching programs to beat the straightforward algorithm, but more importantly this is the first non-trivial approach to proving deterministic upper bounds for Tree Evaluation.

We also contribute new machinery to the catalytic computing program, which may be of independent interest to some readers.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/056"><span class="datestr">at April 26, 2020 06:11 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2020/04/24/ExpLR1/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2020/04/24/ExpLR1/">Exponential Learning Rate Schedules for Deep Learning (Part 1)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>This blog post concerns our <a href="https://arxiv.org/pdf/1910.07454.pdf">ICLR20 paper</a> on a surprising discovery about learning rate (LR), the most basic hyperparameter in deep learning.</p>

<p>As illustrated in many online blogs, setting LR too small  might slow down the optimization, and setting it too large  might make the network overshoot the area of low losses. The standard mathematical analysis for  the right choice of LR relates it to <a href="https://en.wikipedia.org/wiki/Smoothness">smoothness</a> of the loss function.</p>

<p>Many practitioners use a ‘step decay’ LR schedule, which systematically drops the LR after specific training epochs. One often hears the intuition—with some mathematical justification if one treats SGD as a random walk in the  loss landscape— that large learning rates are useful in the initial (“exploration”) phase of training whereas lower rates  in later epochs allow a slow settling down to a local minimum in the landscape. Intriguingly, this intuition is called into  question by the success of exotic learning rate schedules such as <a href="https://arxiv.org/abs/1608.03983">cosine</a> (Loshchilov&amp;Hutter, 2016), and <a href="https://arxiv.org/abs/1506.01186">triangular</a> (Smith, 2015), featuring an oscillatory LR.  These divergent approaches suggest that LR, the most basic and intuitive hyperparameter in deep learning, has not revealed all its mysteries yet.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/lr_schedules.png" style="width: 450px;" />
<br />
<b>Figure 1.</b> Examples of Step Decay, Triangular and Cosine LR schedules.
</div>
<p><br /></p>

<h1 id="surprise-exponentially-increasing-lr">Surprise: Exponentially increasing LR</h1>

<p>We report experiments that state-of-the-art networks for image recognition tasks can be trained with an exponentially increasing LR (ExpLR): in each iteration it increases by $(1+\alpha)$ for some $\alpha &gt; 0$.  (The $\alpha$ can be varied over epochs.) Here $\alpha$ is not too small in our experiments, so as you would imagine, the LR hits astronomical values in no time.  To the best of our knowledge, this is the first time such a rate schedule has been successfully used, let alone for highly successful architectures. In fact, as we will see below, the reason we even did this bizarre experiment  was that we already had a mathematical proof that it would work. Specifically, we could show that such ExpLR schedules are at least as powerful as the standard step-decay ones, by which we mean that ExpLR can let us achieve (in function space) all the nets obtainable via the currently popular step-decay schedules.</p>

<h2 id="so-why-does-this-work">So why does this work?</h2>

<p>One key property of state-of-the-art nets we rely on is that they all use some normalization of parameters within layers, usually Batch Norm (BN), which has been shown to give benefits in optimization and generalization across architectures. Our result also holds for other normalizations, including Group Normalization (Wu &amp; He, 2018), Layer Normalization (Ba et al., 2016), Instance Norm (Ulyanov et al., 2016), etc.</p>

<p>The second key property of current training is that they use weight decay (aka $\ell_2$ regularizer). When combined with BN, this implies strange dynamics in parameter space, and the experimental papers (<a href="https://arxiv.org/abs/1706.05350">van Laarhoven, 2017</a>, <a href="https://arxiv.org/abs/1803.01814">Hoffer et al., 2018a</a> and <a href="https://openreview.net/forum?id=B1lz-3Rct7">Zhang et al., 2019</a>),  noticed that combining BN and weight decay can  be viewed as increasing the LR.</p>

<p>Our paper gives a rigorous proof of the power of ExpLR by showing the following about the end-to-end function  being computed (see Main Thm in the paper):</p>

<blockquote>
  <p>(Informal Theorem) For commonly  used values of the paremeters, every net produced by <em>Weight Decay + Constant LR + BN + Momentum</em> can also be produced (in function space) via <em>ExpLR + BN + Momentum</em></p>
</blockquote>

<p>*NB: If the LR is not fixed but decaying in discrete steps, then the equivalent ExpLR training decays the exponent. (See our paper for details.)</p>

<p>At first sight such a claim may seem difficult (if not impossible) to prove given that we lack any mathematical characterization of nets produced by training (note that the theorem makes no mention of the dataset!).  The  equivalence is shown by reasoning about <em>trajectory</em> of optimization, instead of the usual “landscape view” of stationary points, gradient norms, Hessian norms, smoothness, etc.. This is an example of the importance of trajectory analysis, as argued in <a href="http://www.offconvex.org/2019/06/03/trajectories/">earlier blog post of Sanjeev’s</a> because optimization and generalization are deeply intertwined for deep learning. Conventional wisdom says LR controls optimization, and the regularizer controls generalization. Our result shows that the effect of weight decay can  under fairly normal conditions be * exactly*  realized by the ExpLR rate schedule.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/exp_lr.png" style="width: 550px;" />
</div>
<p><strong>Figure 2.</strong> Training PreResNet32 on CIFAR10 with fixed LR $0.1$, momentum $0.9$ and other standard hyperparameters. Trajectory was unchanged when WD was turned off  and LR at iteration $t$ was $\tilde{\eta}_ t = 0.1\times1.481^t$. (The constant $1.481$ is predicted by our theory given the original hyperparameters.) Plot on right shows  weight norm $\pmb{w}$ of the first convolutional layer in the second residual block. It grows exponentially as one would expect, satisfying $|\pmb{w}_ t|_ 2^2/\tilde{\eta}_ t = $ constant.</p>

<p><a href="http://www.offconvex.org/feed.xml# (We first want to clarify that the exponential LR schedules work for normalized networks only and will lead parameter and output explosion for networks without normalization. )">comment</a>:# (In the rest of the post, we will first explain how does this equivalence result arises from various types of normalization schemes and then sketch the proof. We will also present a more general exponential growing learning schedule called ‘'’Tapered Exponential Learning Rate Schedule’, or TEXP, which is both experimentally and theoretically equivalent to the standard Step Decay schedule + Weight Decay. )</p>

<h2 id="scale-invariance-and-equivalence">Scale Invariance and Equivalence</h2>

<p>The formal proof holds for any training loss satisfying 
what we call <em>Scale Invariance</em>:</p>



<p>BN and other normalization schemes result in a Scale-Invariant Loss for the popular deep architectures (Convnet, Resnet, DenseNet etc.) if the output layer –where normally no normalization is used– is fixed throughout training. Empirically, <a href="https://openreview.net/forum?id=S1Dh8Tg0-">Hoffer et al. (2018b)</a>  found that randomly fixing the output layer at the start does not harm the final accuracy. 
(Appendix C of our paper demonstrates scale invariance for  various architectures; it is somewhat nontrivial.)</p>

<p>For batch ${\mathcal{B}} = \{ x_ i \} _ {i=1}^B$, network parameter ${\pmb{\theta}}$, we  denote the network by $f_ {\pmb{\theta}}$ and the loss function at iteration $t$ by $L_ t(f_ {\pmb{\theta}}) = L(f_ {\pmb{\theta}}, {\mathcal{B}}_ t)$ . We also use $L_ t({\pmb{\theta}})$ for convenience. We say the network $f_ {\pmb{\theta}}$ is <em>scale invariant</em> if $\forall c&gt;0$, $f_ {c{\pmb{\theta}}} = f_ {\pmb{\theta}}$, which implies the loss $L_ t$ is also scale invariant, i.e., $L_  t(c{\pmb{\theta}}_ t)=L_ t({\pmb{\theta}}_ t)$, $\forall c&gt;0$. A key source of intuition is the following lemma provable via chain rule:</p>

<blockquote>
  <p><strong>Lemma 1</strong>. A scale-invariant loss $L$ satisfies
(1). $\langle\nabla_ {\pmb{\theta}} L, {\pmb{\theta}} \rangle=0$ ;<br />
(2). $\left.\nabla_ {\pmb{\theta}} L \right|_ {\pmb{\theta} = \pmb{\theta}_ 0} = c \left.\nabla_ {\pmb{\theta}} L\right|_  {\pmb{\theta} = c\pmb{\theta}_ 0}$, for any $c&gt;0$.</p>
</blockquote>

<p>The first property immediately implies that $|{\pmb{\theta}}_ t|$ is monotone increasing for SGD if WD is turned off by Pythagoren Theorem. And based on this, <a href="https://arxiv.org/pdf/1812.03981.pdf">our previous work</a> with Kaifeng Lyu shows that GD with any fixed learning rate can reach $\varepsilon$ approximate stationary point for scale invariant objectives in $O(1/\varepsilon^2)$ iterations.</p>
<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/inv_lemma.png" style="width: 360px;" />
<br />
<b>Figure 3.</b> Illustration of Lemma 1. 
</div>
<p><br /></p>

<p>Below is the main result of the paper. We will explain the proof idea (using scale-invariance) in a later post.</p>
<blockquote>
  <p><strong>Theorem 1(Main, Informal).</strong> SGD on a scale-invariant objective with initial learning rate $\eta$, weight decay factor $\lambda$, and momentum factor $\gamma$ is equivalent to SGD with momentum factor $\gamma$ where at iteration $t$, the ExpLR $\tilde{\eta}_ t$  is defined as $\tilde{\eta}_ t = \alpha^{-2t-1} \eta$ without weight decay($\tilde{\lambda} = 0$) where $\alpha$ is a non-zero root of equation 
     </p>
</blockquote>

<blockquote>
  <p>Specifically, when momentum $\gamma=0$,  the above schedule can be simplified as $\tilde{\eta}_ t = (1-\lambda\eta)^{-2t-1} \eta$.</p>
</blockquote>

<h3 id="sota-performance-with-exponential-lr">SOTA performance with exponential LR</h3>

<p>As mentioned, reaching state-of-the-art accuracy  requires reducing the learning rate a few times. Suppose the training has $K$ phases, and the learning rate is divided by some constant $C_I&gt;1$ when entering phase $I$. To realize the same effect with an exponentially increasing LR, we have:</p>

<blockquote>
  <p><strong>Theorem 2:</strong> ExpLR with the below modification generates the same network sequence as Step Decay with momentum factor $\gamma$ and WD $\lambda$ does. We call it <em>Tapered Exponential LR schedule</em> (TEXP).<br />
<strong>Modification when entering a new phase $I$</strong>: (1). switching to some smaller exponential growing rate; (2). divinding the current LR by $C_I$.</p>
</blockquote>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/texp_lr.png" style="width: 235px;" />
<img src="http://www.offconvex.org/assets/TEXP.png" style="width: 500px;" />
</div>
<p><strong>Figure 5.</strong> PreResNet32 trained with Step Decay (as in Figure 1) and its corresponding TEXP schedule. As predicted by Theorem 2, they have similar trajectories and performances.</p>

<h2 id="conclusion">Conclusion</h2>

<p>We hope that this bit of theory and supporting experiments have changed your outlook on learning rates for deep learning.</p>

<p>A follow-up post will present the proof idea and give more insight into why ExpLR suggests a rethinking of the “landscape view” of optimization in deep learning.</p></div>







<p class="date">
<a href="http://offconvex.github.io/2020/04/24/ExpLR1/"><span class="datestr">at April 24, 2020 10:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4772">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4772">Martinis, The Plot Against America, Kill Chain</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>As if we didn’t have enough to worry us, this week brought the <a href="https://www.wired.com/story/googles-head-quantum-computing-hardware-resigns/">sad news</a> that John Martinis, who for five years was the leader and public face of Google’s experimental quantum computing effort, has quit Google and returned to his earlier post at UC Santa Barbara.  I’ve spoken about what happened both with John and with Hartmut Neven, the head of Google’s Quantum AI Lab.  Without betraying confidences, or asserting anything that either side would disagree with, I think I can say that it came down to a difference in management philosophies.  Google tends to be consensus-driven, whereas John is of the view that building a million-qubit, error-corrected quantum computer will take more decisive leadership.  I can add: I’d often wondered how John had time to travel the world, giving talks about quantum supremacy, while also managing the lab’s decisions on a day-to-day basis.  It looks now like I was right to wonder!  Potential analogies flood the mind: is this like a rock band that breaks up right after its breakout hit?  Is it like Steve Jobs leaving Apple?  Anyway, I wish the Google team the best in John’s absence, and I also wish John the best with whatever he does next.</p>



<p>I was never big on HBO (e.g., I still haven’t seen a single minute of <em>Game of Thrones</em>), but in the last couple of weeks, Dana and I found ourselves watching two absolutely compelling HBO shows—one a fictional miniseries and the other a documentary, but both on the theme of the fragility of American democracy.</p>



<p><a href="https://www.hbo.com/the-plot-against-america"><em>The Plot Against America</em></a>, based on the <a href="https://en.wikipedia.org/wiki/The_Plot_Against_America">2004 Philip Roth novel</a> of the same name (which Dana read and which I now plan to read), is about an alternate history where the aviator Charles Lindbergh defeats FDR in the 1940 presidential election, on a fascist and isolationist platform, in events that—as countless people have pointed out—are eerily, terrifyingly prescient of what would actualy befall the US in 2016.  The series follows a Jewish insurance salesman and his family in Newark, NJ—isn’t that what it always is with Philip Roth?—as they try to cope with the country’s gradual, all-too-plausible slide downward, from the genteel antisemitism that already existed in <em>our</em> timeline’s 1940 all the way to riots, assassinations, and pogroms (although never to an American Holocaust).  One of the series’ final images is of paper ballots, in a rematch presidential election, being carted away and burned, underscoring just how much depends here on the mundane machinery of democracy.</p>



<p>Which brings me to <a href="https://www.hbo.com/documentaries/kill-chain-the-cyber-war-on-americas-elections"><em>Kill Chain: The Cyber War on America’s Elections</em></a>, a documentary about the jaw-droppingly hackable electronic voting machines used in US elections and the fight to do something about them.  The show mostly follows the journey of <a href="https://en.wikipedia.org/wiki/Harri_Hursti">Harri Hursti</a>, a Finnish-born programmer who’s made this issue his life’s work, but it also extensively features my childhood best friend <a href="https://en.wikipedia.org/wiki/Alex_Halderman">Alex Halderman</a>.  OK, but isn’t this a theoretical issue, one that (perhaps rightly) exercises security nerds like Alex, but surely hasn’t changed the outcomes of actual elections?</p>



<p>Yeah, so about that.  You know Brian Kemp, the doofus governor of Georgia, who’s infamously announced plans to reopen the state right away, ignoring the pleading of public health experts—a  act that will fill Georgia’s ICUs and morgues as surely as night follows day?  And you know how Kemp defeated the Democrat, Stacey Abrams, by a razor-thin margin, in a 2018 election of which Kemp himself was the overseer?  It turns out that Kemp’s office distributed defective memory cards to African-American and Democratic precincts, though not to white and Republican ones.  There’s also striking statistical evidence that at least some voting machines were hacked, although because there was no paper trail it can never be proved.</p>



<p>In short, what <em>The Plot Against America</em> and <em>Kill Chain</em> have in common is that they <em>would be</em> desperately needed warnings about the ease with which democracy could collapse in the US, except for the detail that much of what they warn about has already happened, and now it’s not clear how we get back.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4772"><span class="datestr">at April 23, 2020 06:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=426">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/04/23/tcs-talk-wednesday-april-29-sepideh-mahabadi-ttic/">TCS+ talk: Wednesday, April 29 — Sepideh Mahabadi, TTIC</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, April 29th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Sepideh Mahabadi</strong> from TTIC will speak about “<em>Non-Adaptive Adaptive Sampling in Turnstile Streams</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a>the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The link to the YouTube livestream will also be posted <a>on our website</a> on the day of the talk, so people who did not sign up will still be able to watch the talk live.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a>suggest</a> a possible topic or speaker, please see <a>the website</a>.</p>
<blockquote><p>Abstract: Adaptive sampling is a useful algorithmic tool for data summarization problems in the classical centralized setting, where the entire dataset is available to the single processor performing the computation. Adaptive sampling repeatedly selects rows of an underlying <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=fff&amp;fg=444444&amp;s=0" alt="n" class="latex" title="n" /> by <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0" alt="d" class="latex" title="d" /> matrix <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=fff&amp;fg=444444&amp;s=0" alt="A" class="latex" title="A" />, where <img src="https://s0.wp.com/latex.php?latex=n+%5Cgg+d&amp;bg=fff&amp;fg=444444&amp;s=0" alt="n \gg d" class="latex" title="n \gg d" />, with probabilities proportional to their distances to the subspace of the previously selected rows. Intuitively, adaptive sampling seems to be limited to trivial multi-pass algorithms in the streaming model of computation due to its inherently sequential nature of assigning sampling probabilities to each row only after the previous iteration is completed. Surprisingly, we show this is not the case by giving the first one-pass algorithms for adaptive sampling on turnstile streams and using space <img src="https://s0.wp.com/latex.php?latex=%5Ctext%7Bpoly%7D%28d%2Ck%2C%5Clog+n%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\text{poly}(d,k,\log n)" class="latex" title="\text{poly}(d,k,\log n)" />, where <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=fff&amp;fg=444444&amp;s=0" alt="k" class="latex" title="k" /> is the number of adaptive sampling rounds to be performed.</p>
<p>Our adaptive sampling procedure has a number of applications to various data summarization problems on turnstile streams that either improve state-of-the-art or have only been previously studied in the more relaxed row-arrival model. This includes column subset selection, subspace approximation, projective clustering, and volume maximization. We complement our volume maximization algorithmic results with lower bounds that are tight up to lower order terms, even for multi-pass algorithms. By a similar construction, we also obtain lower bounds for volume maximization in the row-arrival model, which we match with competitive upper bounds.</p>
<p>This is a joint work with Ilya Razenshteyn, David Woodruff, and Samson Zhou.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/04/23/tcs-talk-wednesday-april-29-sepideh-mahabadi-ttic/"><span class="datestr">at April 23, 2020 04:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/055">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/055">TR20-055 |  Bounded Collusion Protocols, Cylinder-Intersection Extractors and Leakage-Resilient Secret Sharing | 

	Ashutosh Kumar, 

	Raghu Meka, 

	David Zuckerman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work we study bounded collusion protocols (BCPs) recently introduced in the context of secret sharing by Kumar, Meka, and Sahai (FOCS 2019). These are multi-party communication protocols on $n$ parties where in each round a subset of $p$-parties (the collusion bound) collude together and write a function of their inputs on a public blackboard. 

BCPs interpolate elegantly between the well-studied number-in-hand (NIH) model ($p=1$) and the number-on-forehead (NOF) model ($p=n-1$). Motivated by questions in communication complexity, secret sharing, and pseudorandomness we investigate BCPs more thoroughly answering several questions about them. 

* We prove a polynomial (in the input-length) lower bound for an explicit function against BCPs where any constant fraction of players can collude. Previously, non-trivial lower bounds were only known when the collusion bound was at most logarithmic in the input-length (owing to bottlenecks in NOF lower bounds). 

* For all $t \leq n$, we construct efficient $t$-out-of-$n$ secret sharing schemes where the secret remains hidden even given the transcript of a BCP with collusion bound $O(t/\log t)$. Prior work could only handle collusions of size $O(\log n)$. Along the way, we construct leakage-resilient schemes against disjoint and adaptive leakage,  resolving a question asked by Goyal and Kumar (STOC 2018).

* An explicit $n$-source cylinder intersection extractor whose output is close to uniform even when given the transcript of a BCP with a constant fraction of parties colluding. The min-entropy rate we require is $0.3$ (independent of collusion bound $p \ll n$). 

Our results rely on a new class of exponential sums that interpolate between the ones considered in additive combinatorics by Bourgain (Geometric and Functional Analysis 2009) and Petridis and Shparlinski (Journal d'Analyse Mathématique 2019).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/055"><span class="datestr">at April 23, 2020 09:54 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/054">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/054">TR20-054 |  Communication Complexity with Defective Randomness  | 

	Marshall Ball, 

	Oded Goldreich, 

	Tal Malkin</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Starting with the two standard model of randomized communication complexity, we study the communication complexity of functions when the protocol has access to a defective source of randomness. 
Specifically, we consider both the public-randomness and private-randomness cases, while replacing the commonly postulated perfect randomness with distributions over $\ell$ bit strings that have min-entropy at least $k\leq\ell$. 
We present general upper and lower bounds on the communication complexity in these cases, where the bounds are typically linear in $\ell-k$ and also depend on the size of the fooling set for the function being computed and on its standard randomized complexity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/054"><span class="datestr">at April 22, 2020 07:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8100403263538580223">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/04/complexity-vidcast-future-edition.html">Complexity Vidcast - Future Edition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Bill and Lance aim to <a href="https://www.youtube.com/watch?v=4G2cxVRe0X8">talk about the future</a> but can't escape the present.<br />
<br />
<br /></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/04/complexity-vidcast-future-edition.html"><span class="datestr">at April 22, 2020 06:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1650">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/04/22/private-libraries/">Reading in Private</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><i>(This blog post is based on joint work with </i><a href="https://cs.stanford.edu/~dkogan/"><i>Dima Kogan</i></a><i>.)</i></p>
<p>One of the great unsung perks of being a college student is having access to the university library. There is something thrilling about hunting down exactly the right reference deep in the stacks, or reading through the archived papers of a public figure from years back.</p>
<p>The pandemic has closed all of our libraries for the time being. Even so, through the fruits of computer science—databases, the Internet, e-readers, and so on—we can get access to much of the same information even when we are cooped up at home.</p>
<p>But for me, one of the true pleasures of using a library is the fact that I can browse through any book I want in complete privacy. If I want to go up to the stacks and read about tulip gardening, or road-bike maintenance, or strategies for managing anxiety, I can do that pretty much without anyone else knowing.</p>
<p>In contrast, if I go online today and search for “tulip gardening,” Google will take careful note of my interest in tulips and I will be seeing ads about gardening tools for months.</p>
<p>An ideal digital library would let us download and read books without anyone—not even the library itself—learning which books we are reading. How could we build such a privacy-respecting digital library?</p>
<p>In this post, we will discuss the private-library problem and how <a href="https://eprint.iacr.org/2019/1075">our recent work on private information retrieval</a> might be able to help solve it.</p>
<h3><b>The Private-Library Problem</b></h3>
<p>Let us define the problem a little more precisely. We will imagine a protocol running between a library, which holds the books, and a student, who wants to download a particular book.</p>
<p>Say that the library has <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> books—let’s call the books <img src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x=(x_1, \dots, x_N)" class="latex" title="x=(x_1, \dots, x_N)" />. To keep things simple, let’s pretend that each book consists of just a single bit of information, so <img src="https://s0.wp.com/latex.php?latex=x_i+%5Cin+%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_i \in \{0,1\}" class="latex" title="x_i \in \{0,1\}" /> for all <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i \in \{1, \dots, N\}" class="latex" title="i \in \{1, \dots, N\}" />.</p>
<p>The student starts out holding the index <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i \in \{1, \dots, N\}" class="latex" title="i \in \{1, \dots, N\}" /> of her desired book. To fetch the digital book from the library, the student and library exchange some messages. At the end of the interaction, we want the following two properties to hold:</p>
<ul>
<li><b>Correctness.</b> The student should have her desired book (i.e., the bit <img src="https://s0.wp.com/latex.php?latex=x_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x_i" class="latex" title="x_i" />).</li>
<li><b>Privacy. </b>The library should have not learned any information, in a cryptographic sense, about which book the student downloaded.</li>
</ul>
<p>Of course, we have grossly simplified the problem: a real book is more than a single bit in length, book titles are not consecutive integers, maybe the student would like to find a book using a keyword search, etc. But even this simplified private-information-retrieval problem, which <a href="http://www.tau.ac.il/~bchor/PIR.pdf">Chor, Goldreich, Kushilevitz, and Sudan introduced</a> in the 90s, is already interesting enough.</p>
<h3><b>A simple but inefficient solution</b></h3>
<p>There is a simple solution to this problem: the student can just ask the library to send her the contents of all <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> books. This solution achieves both correctness and privacy, so what’s the problem? Are we done?</p>
<p>Well, there are two problems:</p>
<ol>
<li>The amount of <b>communication</b> is large: Just to read a single book, the client must download the contents of the entire library! So this is terribly inefficient.</li>
<li>The amount of <b>computation</b> is large: Just to fetch a single book, the library must do work proportional to the size of the entire library. So “checking out” a book from this digital library will take a long time.</li>
</ol>
<p>Research on private information retrieval typically focuses on the first problem: how can we reduce the <i>communication</i> cost? Using a <a href="https://dl.acm.org/doi/abs/10.1145/2968443">variety</a> of <a href="https://ieeexplore.ieee.org/abstract/document/646125">clever</a> <a href="https://dl.acm.org/doi/abs/10.1145/2976749.2978429">techniques</a>, it is possible to drive down the communication cost to something very small—sub-polynomial or even logarithmic in the library size <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" />.</p>
<p>But today we are interested in the <i>computational</i> burden on the library. Is there any way that the student can privately download a book from the library while requiring the library to do only <img src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="o(N)" class="latex" title="o(N)" /> work in the process?</p>
<h3><b>Doing the hard work in advance</b></h3>
<p>To have both correctness and privacy, it seems that the library needs to touch each of the <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> books in the process of responding to each student’s request. And, in some sense, <a href="http://groups.csail.mit.edu/cis/pubs/malkin/BIM.ps">this is true</a>. So, to allow the library to run in time sublinear in <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" />, we will have to tweak the problem slightly.</p>
<p>Our idea is to have the library do the <img src="https://s0.wp.com/latex.php?latex=O%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="O(N)" class="latex" title="O(N)" />-time computation in an <b>offline phase</b>, which takes place <i>before</i> the student decides which book she wants to read. For example, this offline phase might happen overnight while the library’s servers would otherwise be idle.</p>
<p>Later on, once the student decides which book in the library she wants to read, the student and library can run a <img src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="o(N)" class="latex" title="o(N)" />-time <b>online phase</b> in which the student is able to retrieve her desired book. The total communication cost, in both offline and online phases, will be <img src="https://s0.wp.com/latex.php?latex=o%28N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="o(N)" class="latex" title="o(N)" />.</p>
<p>So, by pushing the library’s expensive linear scan to an offline phase, the library can service the student’s request for a book in sublinear online time.</p>
<h3><b>Our offline/online private information retrieval scheme</b></h3>
<p>Let’s see how to construct such an offline/online scheme. To make things simple for the purposes of this post, let’s assume that the student has access to two non-colluding libraries that hold the same set of books. To be concrete, let’s call the two libraries “Stanford” and “Berkeley.”</p>
<p>The privacy property will hold as long as the librarians at Stanford and Berkeley don’t get together and share the information that they learned while running the protocol with the student. So Stanford and Berkeley here are “non-colluding.” (Equivalently, our scheme that protects privacy against an adversary that controls one of the two libraries—but not both.)</p>
<div style="width: 571px;" class="wp-caption aligncenter" id="attachment_1670"><img width="561" alt="Offline-online PIR" src="https://theorydish.files.wordpress.com/2020/04/offlineonline.png?w=561&amp;h=365" class=" wp-image-1670" height="365" /><p class="wp-caption-text" id="caption-attachment-1670">In the offline phase, which happens before the student knows which book she wants to read, the Stanford library does linear work. In the online phase, which runs once the student has the index of her desired book, the Berkeley library runs in sublinear time. (We are suppressing log factors here.)</p></div>
<p>Now, let’s describe an offline/online protocol by which the student can privately fetch a book from the digital library:</p>
<p><b>Offline Phase.</b></p>
<ul>
<li>The student partitions the integers <img src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+..%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{1, .., N\}" class="latex" title="\{1, .., N\}" /> into <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sqrt{N}" class="latex" title="\sqrt{N}" /> non-overlapping sets chosen at random, where each set has size <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sqrt{N}" class="latex" title="\sqrt{N}" />. Call these sets <img src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_1, \dots, S_{\sqrt{N}}" class="latex" title="S_1, \dots, S_{\sqrt{N}}" />.</li>
<li>The student sends these sets <img src="https://s0.wp.com/latex.php?latex=S_1%2C+%5Cdots%2C+S_%7B%5Csqrt%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_1, \dots, S_{\sqrt{N}}" class="latex" title="S_1, \dots, S_{\sqrt{N}}" /> to Stanford (the first library). To reduce the communication cost here, the student can compress these sets using pseudorandomness.</li>
<li>For each set <img src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_j" class="latex" title="S_j" />, the Stanford library computes the <i>parity</i> of all of the books indexed by set <img src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_j" class="latex" title="S_j" /> and returns the parity bits <img src="https://s0.wp.com/latex.php?latex=%28b_1%2C+%5Cdots%2C+b_%7B%5Csqrt%7BN%7D%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(b_1, \dots, b_{\sqrt{N}})" class="latex" title="(b_1, \dots, b_{\sqrt{N}})" /> to the student. In other words, if the books are <img src="https://s0.wp.com/latex.php?latex=x%3D%28x_1%2C+%5Cdots%2C+x_N%29+%5Cin+%5C%7B0%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="x=(x_1, \dots, x_N) \in \{0,1\}^n" class="latex" title="x=(x_1, \dots, x_N) \in \{0,1\}^n" />, then <img src="https://s0.wp.com/latex.php?latex=b_j+%3D+%5Csum_%7Bk+%5Cin+S_j%7D+x_k+%5Cbmod+2&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="b_j = \sum_{k \in S_j} x_k \bmod 2" class="latex" title="b_j = \sum_{k \in S_j} x_k \bmod 2" />.</li>
</ul>
<p>The total communication in this phase is only <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="O(\sqrt{N})" class="latex" title="O(\sqrt{N})" /> bits and the student and the Stanford library can run this step <i>before</i> the student decides which book she wants to read.</p>
<p><b>Online Phase.</b> Once the student decides that she wants to read book <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i \in \{1, \dots, N\}" class="latex" title="i \in \{1, \dots, N\}" />, the student and Berkeley (the second library) run the following steps:</p>
<ul>
<li>The student finds the set <img src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_j" class="latex" title="S_j" /> that contains the index <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i" class="latex" title="i" /> of her desired book.</li>
<li>The student flips a coin that is weighted to come up heads with some probability <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p" class="latex" title="p" />, to be fixed later.</li>
<li>If the coin lands <span style="text-decoration: underline;">heads</span>:
<ul>
<li>The student sends <img src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S \gets S_j \setminus \{i\}" class="latex" title="S \gets S_j \setminus \{i\}" /> to the Berkeley library.</li>
</ul>
</li>
<li>If the coin lands <span style="text-decoration: underline;">tails</span>:
<ul>
<li>The student samples <img src="https://s0.wp.com/latex.php?latex=i%27+%5Cgets_R+S_j+%5Csetminus+%5C%7Bi%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i' \gets_R S_j \setminus \{i\}" class="latex" title="i' \gets_R S_j \setminus \{i\}" />.</li>
<li>The student sends <img src="https://s0.wp.com/latex.php?latex=S+%5Cgets+S_j+%5Csetminus+%5C%7Bi%27%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S \gets S_j \setminus \{i'\}" class="latex" title="S \gets S_j \setminus \{i'\}" /> to the Berkeley library.</li>
</ul>
</li>
<li>The Berkeley library receives the set <img src="https://s0.wp.com/latex.php?latex=S+%5Csubseteq+%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S \subseteq \{1, \dots, N\}" class="latex" title="S \subseteq \{1, \dots, N\}" /> from the student. The Berkeley library returns the contents of all books whose indices appear in set <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S" class="latex" title="S" /> to the student.</li>
<li>Now, the student can recover its desired book as follows:
<ul>
<li>If <span style="text-decoration: underline;">heads</span>: the student now has the parity of the books in <img src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_j" class="latex" title="S_j" /> (from the offline phase) and the value of all books in <img src="https://s0.wp.com/latex.php?latex=S_j&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_j" class="latex" title="S_j" /> that are not book <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i" class="latex" title="i" />. This is enough to recover the contents of book <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i" class="latex" title="i" />.</li>
<li>If <span style="text-decoration: underline;">tails</span>: <img src="https://s0.wp.com/latex.php?latex=i+%5Cin+S&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i \in S" class="latex" title="i \in S" />. In this case the Berkeley library has sent the contents of book <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i" class="latex" title="i" /> to the student in the online phase.</li>
</ul>
</li>
</ul>
<p>Even before we fix the weight <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p" class="latex" title="p" /> of the coin, we see that the protocol satisfies <b>correctness</b>, since no matter how the coin lands the client recovers its desired book. Also, the total communication cost is <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D+%5Clog+N%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="O(\sqrt{N} \log N)" class="latex" title="O(\sqrt{N} \log N)" /> bits, which is sublinear as we had hoped. Finally, the <b>online computation cost</b> is also sublinear: the Berkeley library just needs to return <img src="https://s0.wp.com/latex.php?latex=%5Csqrt%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\sqrt{N}" class="latex" title="\sqrt{N}" /> books to the client, which it can do in time roughly <img src="https://s0.wp.com/latex.php?latex=O%28%5Csqrt%7BN%7D%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="O(\sqrt{N})" class="latex" title="O(\sqrt{N})" />.</p>
<p>The last matter to address is <b>privacy</b>. Again, we are assuming that the adversary controls only one of the two libraries.</p>
<ul>
<li>In the offline phase, the student’s message to the Stanford library is independent of <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i" class="latex" title="i" />, so the protocol is perfectly private with respect to Stanford.</li>
<li>In the online phase, we must be more careful. It turns out that if we choose the weight <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p" class="latex" title="p" /> of the coin as <img src="https://s0.wp.com/latex.php?latex=p+%3D+1+-+%28%5Csqrt%7BN%7D+-+1%29%2FN&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p = 1 - (\sqrt{N} - 1)/N" class="latex" title="p = 1 - (\sqrt{N} - 1)/N" />, then the set <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S" class="latex" title="S" /> that the student sends to UC Berkeley in the online phase is just a uniformly random size-<img src="https://s0.wp.com/latex.php?latex=%28%5Csqrt%7BN%7D-1%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(\sqrt{N}-1)" class="latex" title="(\sqrt{N}-1)" /> subset of <img src="https://s0.wp.com/latex.php?latex=%5C%7B1%2C+%5Cdots%2C+N%5C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{1, \dots, N\}" class="latex" title="\{1, \dots, N\}" />.</li>
</ul>
<h3><b>Open problems</b></h3>
<p>So, the student can privately fetch a book from our digital libraries in sublinear online time. What else is left to do?</p>
<ul>
<li>Getting rid of the need for two non-colluding libraries is a clear next step. <a href="https://eprint.iacr.org/2019/1075">Our work</a> has some results along these lines, but they pay a price either in (a) asymptotic efficiency or in (b) the strength of the cryptographic assumptions required.</li>
<li>A beautiful paper of <a href="https://www.cs.bgu.ac.il/~beimel/Papers/BIM.pdf">Beimel, Ishai, and Malkin</a> shows that if the library can store its collection of books using a special type of error-correcting encoding, the <b>total</b> computational time at the libraries (not just the online time) can be sublinear in <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" />. As far as we know, these schemes are not concretely efficient enough to use in practice. Could they be made so?</li>
<li>Privacy is just one of the many pleasures of using a physical library. During this period of confinement, I also miss the smell of the books, the beauty of light filtering through the stacks, and the peacefulness of thinking in a study carrel. Can a digital library ever give us these things too?</li>
</ul>
<p>If any of these questions catch your fancy, please check out <a href="https://eprint.iacr.org/2019/1075">our Eurocrypt paper</a> for more background, pointers, and results.</p>
<p>Don Knuth <a href="http://jmlr.csail.mit.edu/reviewing-papers/knuth_mathematical_writing.pdf">has reportedly said</a> “Using a great library to solve a specific problem… Now <i>that</i> […] is real living.” With better digital libraries, maybe we could all live a little bit more during these challenging days.</p></div>







<p class="date">
by Henry Corrigan-Gibbs <a href="https://theorydish.blog/2020/04/22/private-libraries/"><span class="datestr">at April 22, 2020 07:07 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
