<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://www.blogger.com/feeds/25562705/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at July 01, 2020 06:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16947">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16947">Sampling from a $k$-DPP without looking at all items</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Calandriello:Daniele.html">Daniele Calandriello</a>, Michał Dereziński, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Valko:Michal.html">Michal Valko</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16947">PDF</a><br /><b>Abstract: </b>Determinantal point processes (DPPs) are a useful probabilistic model for
selecting a small diverse subset out of a large collection of items, with
applications in summarization, stochastic optimization, active learning and
more. Given a kernel function and a subset size $k$, our goal is to sample $k$
out of $n$ items with probability proportional to the determinant of the kernel
matrix induced by the subset (a.k.a. $k$-DPP). Existing $k$-DPP sampling
algorithms require an expensive preprocessing step which involves multiple
passes over all $n$ items, making it infeasible for large datasets. A na\"ive
heuristic addressing this problem is to uniformly subsample a fraction of the
data and perform $k$-DPP sampling only on those items, however this method
offers no guarantee that the produced sample will even approximately resemble
the target distribution over the original dataset. In this paper, we develop an
algorithm which adaptively builds a sufficiently large uniform sample of data
that is then used to efficiently generate a smaller set of $k$ items, while
ensuring that this set is drawn exactly from the target distribution defined on
all $n$ items. We show empirically that our algorithm produces a $k$-DPP sample
after observing only a small fraction of all elements, leading to several
orders of magnitude faster performance compared to the state-of-the-art.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16947"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16924">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16924">Quantum algorithm for Petz recovery channels and pretty good measurements</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gily=eacute=n:Andr=aacute=s.html">András Gilyén</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lloyd:Seth.html">Seth Lloyd</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marvian:Iman.html">Iman Marvian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quek:Yihui.html">Yihui Quek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wilde:Mark_M=.html">Mark M. Wilde</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16924">PDF</a><br /><b>Abstract: </b>The Petz recovery channel plays an important role in quantum information
science as an operation that approximately reverses the effect of a quantum
channel. The pretty good measurement is a special case of the Petz recovery
channel, and it allows for near-optimal state discrimination. A hurdle to the
experimental realization of these vaunted theoretical tools is the lack of a
systematic and efficient method to implement them. This paper sets out to
rectify this lack: using the recently developed tools of quantum singular value
transformation and oblivious amplitude amplification, we provide a quantum
algorithm to implement the Petz recovery channel when given the ability to
perform the channel that one wishes to reverse. Moreover, we prove that our
quantum algorithm's usage of the channel implementation cannot be improved by
more than a quadratic factor. Our quantum algorithm also provides a procedure
to perform pretty good measurements when given multiple copies of the states
that one is trying to distinguish.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16924"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16909">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16909">Complexity of Modification Problems for Best Match Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>David Schaller, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stadler:Peter_F=.html">Peter F. Stadler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hellmuth:Marc.html">Marc Hellmuth</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16909">PDF</a><br /><b>Abstract: </b>Best match graphs (BMGs) are vertex-colored directed graphs that were
introduced to model the relationships of genes (vertices) from different
species (colors) given an underlying evolutionary tree that is assumed to be
unknown. In real-life applications, BMGs are estimated from sequence similarity
data. Measurement noise and approximation errors therefore result in
empirically determined graphs that in general violate properties of BMGs. The
arc modification problems for BMGs therefore provide a mean of correcting and
improving the initial estimates of the best matches. We show here that the arc
deletion, arc completion and arc editing problems for BMGs are NP-complete and
that they can be formulated and solved as integer linear programs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16909"><span class="datestr">at July 01, 2020 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16898">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16898">Lower Bounds for Dynamic Distributed Task Allocation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Su:Hsin=Hao.html">Hsin-Hao Su</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wein:Nicole.html">Nicole Wein</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16898">PDF</a><br /><b>Abstract: </b>We study the problem of distributed task allocation in multi-agent systems.
Suppose there is a collection of agents, a collection of tasks, and a demand
vector, which specifies the number of agents required to perform each task. The
goal of the agents is to cooperatively allocate themselves to the tasks to
satisfy the demand vector. We study the dynamic version of the problem where
the demand vector changes over time. Here, the goal is to minimize the
switching cost, which is the number of agents that change tasks in response to
a change in the demand vector. The switching cost is an important metric since
changing tasks may incur significant overhead.
</p>
<p>We study a mathematical formalization of the above problem introduced by Su,
Su, Dornhaus, and Lynch, which can be reformulated as a question of finding a
low distortion embedding from symmetric difference to Hamming distance. In this
model it is trivial to prove that the switching cost is at least 2. We present
the first non-trivial lower bounds for the switching cost, by giving lower
bounds of 3 and 4 for different ranges of the parameters.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16898"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16762">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16762">Online Multi-Facility Location</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Markarian:Christine.html">Christine Markarian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kassar:Abdul=Nasser.html">Abdul-Nasser Kassar</a>, Manal Yunis <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16762">PDF</a><br /><b>Abstract: </b>Facility Location problems ask to place facilities in a way that optimizes a
given objective function so as to provide a service to all clients. These are
one of the most well-studied optimization problems spanning many research areas
such as operations research, computer science, and management science.
Traditionally, these problems are solved with the assumption that clients need
to be served by one facility each. In many real-world scenarios, it is very
likely that clients need a robust service that requires more than one facility
for each client. In this paper, we capture this robustness by exploring a
generalization of Facility Location problems, called Multi-Facility Location
problems, in the online setting. An additional parameter k, which represents
the number of facilities required to serve a client, is given. We propose the
first online algorithms for the metric and non-metric variants of
Multi-Facility Location and measure their performance with competitive
analysis, the standard to measure online algorithms, in the worst case, in
which the cost of the online algorithm is compared to that of the optimal
offline algorithm that knows the entire input sequence in advance.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16762"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16726">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16726">Linear transformations between dominating sets in the TAR-model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Nicolas.html">Nicolas Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Joffard:Alice.html">Alice Joffard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouvrard:Paul.html">Paul Ouvrard</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16726">PDF</a><br /><b>Abstract: </b>Given a graph $G$ and an integer $k$, a token addition and removal ({\sf TAR}
for short) reconfiguration sequence between two dominating sets $D_{\sf s}$ and
$D_{\sf t}$ of size at most $k$ is a sequence $S= \langle D_0 = D_{\sf s}, D_1
\ldots, D_\ell = D_{\sf t} \rangle$ of dominating sets of $G$ such that any two
consecutive dominating sets differ by the addition or deletion of one vertex,
and no dominating set has size bigger than $k$.
</p>
<p>We first improve a result of Haas and Seyffarth, by showing that if
$k=\Gamma(G)+\alpha(G)-1$ (where $\Gamma(G)$ is the maximum size of a minimal
dominating set and $\alpha(G)$ the maximum size of an independent set), then
there exists a linear {\sf TAR} reconfiguration sequence between any pair of
dominating sets.
</p>
<p>We then improve these results on several graph classes by showing that the
same holds for $K_{\ell}$-minor free graph as long as $k \ge \Gamma(G)+O(\ell
\sqrt{\log \ell})$ and for planar graphs whenever $k \ge \Gamma(G)+3$. Finally,
we show that if $k=\Gamma(G)+tw(G)+1$, then there also exists a linear
transformation between any pair of dominating sets.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16726"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16651">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16651">Vertex guarding for dynamic orthogonal art galleries</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Debangshu Banerjee, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inkulu:R=.html">R. Inkulu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16651">PDF</a><br /><b>Abstract: </b>Given an orthogonal polygon with orthogonal holes, we devise a dynamic
algorithm for guarding with vertex guards, i.e., whenever orthogonal polygon is
modified, algorithm updates the set of vertex guards and their positions for
guarding the modified orthogonal polygon. Our algorithm modifies the guard
placement locally while ensuring the updated orthogonal polygon with $h$ holes
and $n$ vertices, is guarded using at most $\lfloor (n+2h)/4 \rfloor$ vertex
guards. The algorithm to update vertex guards after any modification to the
polygon takes $O(k \lg{(n+ n')})$ amortized time. Here, $n'$ and $n$ are the
number of vertices of the orthogonal polygon before and after the update,
respectively; and, $k$ is the sum of the number of vertices added to or removed
from the orthogonal polygon, the number of cuts in the L-shaped partitioning of
the free space of the orthogonal polygon that got affected due to the update,
and the number of channels affected due to the update. For the special case of
the initial orthogonal polygon being hole-free, and each update resulting in a
hole-free orthogonal polygon, our dynamic guard updating algorithm takes
$O(k\lg{(n+n')})$ worst-case time. Initially, we preprocess the input
orthogonal polygon with $q$ vertices in $O(q \lg{q})$ time to construct data
structures of size $O(q\frac{\lg{q}}{\lg\lg{q}})$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16651"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16632">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16632">Counting Homomorphisms to $K_4$-minor-free Graphs, modulo 2</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Focke:Jacob.html">Jacob Focke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goldberg:Leslie_Ann.html">Leslie Ann Goldberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roth:Marc.html">Marc Roth</a>, Stanislav Živný <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16632">PDF</a><br /><b>Abstract: </b>We study the problem of computing the parity of the number of homomorphisms
from an input graph $G$ to a fixed graph $H$. Faben and Jerrum [ToC'15]
introduced an explicit criterion on the graph $H$ and conjectured that, if
satisfied, the problem is solvable in polynomial time and, otherwise, the
problem is complete for the complexity class $\oplus\mathrm{P}$ of parity
problems. We verify their conjecture for all graphs $H$ that exclude the
complete graph on $4$ vertices as a minor. Further, we rule out the existence
of a subexponential-time algorithm for the $\oplus\mathrm{P}$-complete cases,
assuming the randomised Exponential Time Hypothesis. Our proofs introduce a
novel method of deriving hardness from globally defined substructures of the
fixed graph $H$. Using this, we subsume all prior progress towards resolving
the conjecture (Faben and Jerrum [ToC'15]; G\"obel, Goldberg and Richerby
[ToCT'14,'16]). As special cases, our machinery also yields a proof of the
conjecture for graphs with maximum degree at most $3$, as well as a full
classification for the problem of counting list homomorphisms, modulo $2$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16632"><span class="datestr">at July 01, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16613">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16613">Efficient Splitting of Measures and Necklaces</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alon:Noga.html">Noga Alon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Graur:Andrei.html">Andrei Graur</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16613">PDF</a><br /><b>Abstract: </b>We provide approximation algorithms for two problems, known as NECKLACE
SPLITTING and $\epsilon$-CONSENSUS SPLITTING. In the problem
$\epsilon$-CONSENSUS SPLITTING, there are $n$ non-atomic probability measures
on the interval $[0, 1]$ and $k$ agents. The goal is to divide the interval,
via at most $n (k-1)$ cuts, into pieces and distribute them to the $k$ agents
in an approximately equitable way, so that the discrepancy between the shares
of any two agents, according to each measure, is at most $2 \epsilon / k$. It
is known that this is possible even for $\epsilon = 0$. NECKLACE SPLITTING is a
discrete version of $\epsilon$-CONSENSUS SPLITTING. For $k = 2$ and some
absolute positive constant $\epsilon$, both of these problems are PPAD-hard.
</p>
<p>We consider two types of approximation. The first provides every agent a
positive amount of measure of each type under the constraint of making at most
$n (k - 1)$ cuts. The second obtains an approximately equitable split with as
few cuts as possible. Apart from the offline model, we consider the online
model as well, where the interval (or necklace) is presented as a stream, and
decisions about cutting and distributing must be made on the spot.
</p>
<p>For the first type of approximation, we describe an efficient algorithm that
gives every agent at least $\frac{1}{nk}$ of each measure and works even
online. For the second type of approximation, we provide an efficient online
algorithm that makes $\text{poly}(n, k, \epsilon)$ cuts and an offline
algorithm making $O(nk \log \frac{k}{\epsilon})$ cuts. We also establish lower
bounds for the number of cuts required in the online model for both problems
even for $k=2$ agents, showing that the number of cuts in our online algorithm
is optimal up to a logarithmic factor.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16613"><span class="datestr">at July 01, 2020 01:26 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16573">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16573">Subspace approximation with outliers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deshpande:Amit.html">Amit Deshpande</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pratap:Rameshwar.html">Rameshwar Pratap</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16573">PDF</a><br /><b>Abstract: </b>The subspace approximation problem with outliers, for given $n$ points in $d$
dimensions $x_{1},\ldots, x_{n} \in R^{d}$, an integer $1 \leq k \leq d$, and
an outlier parameter $0 \leq \alpha \leq 1$, is to find a $k$-dimensional
linear subspace of $R^{d}$ that minimizes the sum of squared distances to its
nearest $(1-\alpha)n$ points. More generally, the $\ell_{p}$ subspace
approximation problem with outliers minimizes the sum of $p$-th powers of
distances instead of the sum of squared distances. Even the case of robust PCA
is non-trivial, and previous work requires additional assumptions on the input.
Any multiplicative approximation algorithm for the subspace approximation
problem with outliers must solve the robust subspace recovery problem, a
special case in which the $(1-\alpha)n$ inliers in the optimal solution are
promised to lie exactly on a $k$-dimensional linear subspace. However, robust
subspace recovery is Small Set Expansion (SSE)-hard.
</p>
<p>We show how to extend dimension reduction techniques and bi-criteria
approximations based on sampling to the problem of subspace approximation with
outliers. To get around the SSE-hardness of robust subspace recovery, we assume
that the squared distance error of the optimal $k$-dimensional subspace summed
over the optimal $(1-\alpha)n$ inliers is at least $\delta$ times its
squared-error summed over all $n$ points, for some $0 &lt; \delta \leq 1 -
\alpha$. With this assumption, we give an efficient algorithm to find a subset
of $poly(k/\epsilon) \log(1/\delta) \log\log(1/\delta)$ points whose span
contains a $k$-dimensional subspace that gives a multiplicative
$(1+\epsilon)$-approximation to the optimal solution. The running time of our
algorithm is linear in $n$ and $d$. Interestingly, our results hold even when
the fraction of outliers $\alpha$ is large, as long as the obvious condition $0
&lt; \delta \leq 1 - \alpha$ is satisfied.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16573"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16422">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16422">Ideal Membership Problem for Boolean Minority</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bharathi:Arpitha_P=.html">Arpitha P. Bharathi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mastrolilli:Monaldo.html">Monaldo Mastrolilli</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16422">PDF</a><br /><b>Abstract: </b>The Ideal Membership Problem (IMP) tests if an input polynomial $f\in
\mathbb{F}[x_1,\dots,x_n]$ with coefficients from a field $\mathbb{F}$ belongs
to a given ideal $I \subseteq \mathbb{F}[x_1,\dots,x_n]$. It is a well-known
fundamental problem with many important applications, though notoriously
intractable in the general case. In this paper we consider the IMP for
polynomial ideals encoding combinatorial problems and where the input
polynomial $f$ has degree at most $d=O(1)$ (we call this problem IMP$_d$).
</p>
<p>A dichotomy result between ``hard'' (NP-hard) and ``easy'' (polynomial time)
IMPs was recently achieved for Constraint Satisfaction Problems over finite
domains [Bulatov FOCS'17, Zhuk FOCS'17] (this is equivalent to IMP$_0$) and
IMP$_d$ for the Boolean domain [Mastrolilli SODA'19], both based on the
classification of the IMP through functions called polymorphisms. The
complexity of the IMP$_d$ for five polymorphisms has been solved in
[Mastrolilli SODA'19] whereas for the ternary minority polymorphism it was
incorrectly declared to have been resolved by a previous result. As a matter of
fact the complexity of the IMP$_d$ for the ternary minority polymorphism is
open.
</p>
<p>In this paper we provide the missing link by proving that the IMP$_d$ for
Boolean combinatorial ideals whose constraints are closed under the minority
polymorphism can be solved in polynomial time. This result, along with the
results in [Mastrolilli SODA'19], completes the identification of the precise
borderline of tractability for the IMP$_d$ for constrained problems over the
Boolean domain.
</p>
<p>This paper is motivated by the pursuit of understanding the issue of bit
complexity of Sum-of-Squares proofs raised by O'Donnell [ITCS'17]. Raghavendra
and Weitz [ICALP'17] show how the IMP$_d$ tractability for combinatorial ideals
implies bounded coefficients in Sum-of-Squares proofs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16422"><span class="datestr">at July 01, 2020 01:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16406">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16406">Recovery of Sparse Signals from a Mixture of Linear Samples</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mazumdar:Arya.html">Arya Mazumdar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pal:Soumyabrata.html">Soumyabrata Pal</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16406">PDF</a><br /><b>Abstract: </b>Mixture of linear regressions is a popular learning theoretic model that is
used widely to represent heterogeneous data. In the simplest form, this model
assumes that the labels are generated from either of two different linear
models and mixed together. Recent works of Yin et al. and Krishnamurthy et al.,
2019, focus on an experimental design setting of model recovery for this
problem. It is assumed that the features can be designed and queried with to
obtain their label. When queried, an oracle randomly selects one of the two
different sparse linear models and generates a label accordingly. How many such
oracle queries are needed to recover both of the models simultaneously? This
question can also be thought of as a generalization of the well-known
compressed sensing problem (Cand\`es and Tao, 2005, Donoho, 2006). In this
work, we address this query complexity problem and provide efficient algorithms
that improves on the previously best known results.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16406"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16339">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16339">Parallel Betweenness Computation in Graph Database for Contingency Selection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Yongli.html">Yongli Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dai:Renchang.html">Renchang Dai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Guangyi.html">Guangyi Liu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16339">PDF</a><br /><b>Abstract: </b>Parallel betweenness computation algorithms are proposed and implemented in a
graph database for power system contingency selection. Principles of the graph
database and graph computing are investigated for both node and edge
betweenness computation. Experiments on the 118-bus system and a real power
system show that speed-up can be achieved for both node and edge betweenness
computation while the speeding effect on the latter is more remarkable due to
the data retrieving advantages of the graph database on the power network data.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16339"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16312">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16312">Dynamic Knapsack Optimization Towards Efficient Multi-Channel Sequential Advertising</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hao:Xiaotian.html">Xiaotian Hao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Zhaoqing.html">Zhaoqing Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Ma:Yi.html">Yi Ma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Guan.html">Guan Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jin:Junqi.html">Junqi Jin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hao:Jianye.html">Jianye Hao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Shan.html">Shan Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bai:Rongquan.html">Rongquan Bai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xie:Mingzhou.html">Mingzhou Xie</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Miao.html">Miao Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zheng:Zhenzhe.html">Zhenzhe Zheng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Chuan.html">Chuan Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Han.html">Han Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Jian.html">Jian Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gai:Kun.html">Kun Gai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16312">PDF</a><br /><b>Abstract: </b>In E-commerce, advertising is essential for merchants to reach their target
users. The typical objective is to maximize the advertiser's cumulative revenue
over a period of time under a budget constraint. In real applications, an
advertisement (ad) usually needs to be exposed to the same user multiple times
until the user finally contributes revenue (e.g., places an order). However,
existing advertising systems mainly focus on the immediate revenue with single
ad exposures, ignoring the contribution of each exposure to the final
conversion, thus usually falls into suboptimal solutions. In this paper, we
formulate the sequential advertising strategy optimization as a dynamic
knapsack problem. We propose a theoretically guaranteed bilevel optimization
framework, which significantly reduces the solution space of the original
optimization space while ensuring the solution quality. To improve the
exploration efficiency of reinforcement learning, we also devise an effective
action space reduction approach. Extensive offline and online experiments show
the superior performance of our approaches over state-of-the-art baselines in
terms of cumulative revenue.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16312"><span class="datestr">at July 01, 2020 01:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.16297">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.16297">Optimization Landscape of Tucker Decomposition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Frandsen:Abraham.html">Abraham Frandsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ge:Rong.html">Rong Ge</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.16297">PDF</a><br /><b>Abstract: </b>Tucker decomposition is a popular technique for many data analysis and
machine learning applications. Finding a Tucker decomposition is a nonconvex
optimization problem. As the scale of the problems increases, local search
algorithms such as stochastic gradient descent have become popular in practice.
In this paper, we characterize the optimization landscape of the Tucker
decomposition problem. In particular, we show that if the tensor has an exact
Tucker decomposition, for a standard nonconvex objective of Tucker
decomposition, all local minima are also globally optimal. We also give a local
search algorithm that can find an approximate local (and global) optimal
solution in polynomial time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.16297"><span class="datestr">at July 01, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/">postdoc at University of Oxford (apply by September 11, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>All Souls College Oxford are advertising a 5 year postdoctoral research fellowship in theoretical computer science, with a tentative start date 1 Oct 2021. This is an exceptional opportunity for a first-rate early career researcher in theoretical computer science.</p>
<p>Website: <a href="https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars">https://www.asc.ox.ac.uk/post-doctoral-research-fellowships-2020-further-particulars</a><br />
Email: pdrf.admin@all-souls.ox.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/06/30/postdoc-at-university-of-oxford-apply-by-september-11-2020/"><span class="datestr">at June 30, 2020 04:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/06/30/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/06/30/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://scilogs.spektrum.de/hlf/the-five-bridges-puzzle/">The five bridges puzzle</a> (<a href="https://mathstodon.xyz/@11011110/104357604444143899"></a>). Sort of like the bridges of Königsberg, but stochastic. A cute puzzle with a connection to percolation theory and connection games.</p>
  </li>
  <li>
    <p>Dubious journal publisher MDPI provides special-issue editors with some number of no-publication-charge slots, but requires that priority for these slots be given to first-world scholars, because they are the ones with “more abundant scientific research resources” (read: funds to pay publication charges). This didn’t sit well with three environmental health failure researchers, who <a href="https://retractionwatch.com/2020/06/16/failure-fails-as-publisher-privileges-the-privileged/">resigned their guest editorship over it</a> (<a href="https://mathstodon.xyz/@11011110/104363585936972806"></a>, <a href="https://wash.leeds.ac.uk/what-the-f-how-we-failed-to-publish-a-journal-special-issue-on-failures/">see also</a>).</p>
  </li>
  <li>
    <p>On today’s edition of <a href="https://11011110.github.io/blog/2018/06/24/la-maddalena-non-reuleaux.html">not the Reuleaux triangle</a>, we have <a href="https://twitter.com/Nukaq/status/1273803547574972416">the logo of Whale Cove, Nunavut</a> (<a href="https://mathstodon.xyz/@11011110/104368587916436396"></a>, <a href="https://www.metafilter.com/187552/Nunavut-Aesthetics">via</a>).  The sides of the triangle are straighter than a Reuleaux triangle would be, and its corners are slightly narrower than equilateral. Cool logo, though.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/beluga-reuleaux.png" alt="Logo of Whale Cove, Nunavut" /></p>
  </li>
  <li>
    <p><a href="https://computerhistory.org/blog/discovering-dennis-ritchies-lost-dissertation/">Discovering Dennis Ritchie’s lost dissertation</a> (<a href="https://mathstodon.xyz/@11011110/104375200069651123"></a>, <a href="https://news.ycombinator.com/item?id=23582070">via</a>). Ritchie’s doctoral committee signed off in 1968, but the Harvard Library wanted a bound copy and he was unwilling to pay the binding costs so he never officially received his Ph.D. According to the post, the thesis defines a simple model of computation characterizing primitive recursion, within which one can prove that the complexity and growth rates of primitive recursive functions are equal.</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@tpfto/104376254903441351">J.M. redraws the xkcd golden spiral in Mathematica</a>. The thing that annoys me about it is the non-monotonic curvature, but that appears to be unavoidable.</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/playlist?list=PLn0nrSd4xjjadfcMd5xvmJ_GNSLDi1ATn">Playlist of talk videos from this year’s Symposium on Theory of Computing</a> (<a href="https://mathstodon.xyz/@11011110/104389387469883738"></a>).</p>
  </li>
  <li>
    <p><a href="https://www.youtube.com/watch?v=wujEE3PRVUo">Video on the projective geometry of sidewalk trompe-l’oeil chalk art</a> (<a href="https://mathstodon.xyz/@11011110/104397742913356589"></a>), and <a href="https://www.youtube.com/watch?v=L95cNBEfi5I">another one with less mathematics, more flying pigs and cute space aliens</a>.</p>
  </li>
  <li>
    <p><a href="https://www.makeuseof.com/tag/reduce-video-file-size-without-sacrificing-quality/">Some advice I needed on how to reduce video file size</a> (<a href="https://mathstodon.xyz/@11011110/104402114011362297"></a>). Their suggestion of Handbrake worked well on its default settings and easily reached the file size I needed to reach, without sacrificing quality. (This was for a video of voice over still slides, so it should have been easy to compress, but iMovie couldn’t do it.)</p>
  </li>
  <li>
    <p><a href="https://blogs.ams.org/beyondreviews/2020/06/29/the-mathematics-genealogy-project-moves-to-the-cloud/">The Mathematics Genealogy Project rises into the clouds</a> (<a href="https://mathstodon.xyz/@11011110/104407629370705734"></a>) like a phoenix from the flames of its dead former server. Or maybe not quite as poetically as that, but I use this resource daily in Wikipedia biography editing, so it’s a relief to learn that it’s back after its recent outage.</p>
  </li>
  <li>
    <p><a href="https://dl.acm.org/doi/10.1145/3357713.3384232">QCSP monsters and the demise of the Chen conjecture</a> (<a href="https://mathstodon.xyz/@11011110/104414859746330563"></a>, <a href="https://www.youtube.com/watch?v=c2HjFlcTjQ0">talk video</a>). In STOC’20, Zhuk and Martin show that <a href="https://en.wikipedia.org/wiki/Schaefer%27s_dichotomy_theorem">dichotomy for constraint satisfaction</a> gets messier for quantified CSP. Chen conjectured that QCSP problems are either in NP or PSPACE-complete, but this new paper shows that coNP-completeness can happen for 3 elements and more elements lead to even more classes. Relatedly, <a href="http://eatcs.org/index.php/component/content/article/1-news/2849-the-eatcs-bestows-the-presburger-award-2020">Zhuk just won the Presburger Award</a>.</p>
  </li>
  <li>
    <p>I learned while writing <a href="https://en.wikipedia.org/wiki/Doyle_spiral">a Wikipedia article on Doyle spirals</a> (<a href="https://mathstodon.xyz/@11011110/104418935123493700"></a>) that although the pure-mathematics work in this area dates to Coxeter in 1968 and the work of Thurston and his followers in the 1980s and 1990s, the use of spiral patterns of tangent circles to model plant growth can be traced back much earlier, to Gerrit van Iterson in 1907. The image below, which I used as the lead for the article, is an illustration of phylogeny from <a href="https://archive.org/details/popularsciencemo79newy/page/450/mode/2up">a 1911 <em>Popular Science</em> story about mathematical patterns in nature</a>.</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/Doyle.png" alt="Doyle spiral from _Popular Science_, 1911" /></p>
  </li>
  <li>
    <p><a href="https://www.lms.ac.uk/news-entry/26062020-1657/lms-prize-winners-2020">This year’s London Math Soc. prizewinners</a> (<a href="https://mathstodon.xyz/@11011110/104431647996227722"></a>, <a href="https://twitter.com/hollykrieger/status/1276590144628416512">via</a>). For some reason they keep the <a href="https://www.lms.ac.uk/prizes/louisbachelierprize">Louis Bachelier Prize in a separate listing</a>. These results have already led me to add to Wikipedia brief articles on <a href="https://en.wikipedia.org/wiki/Maria_Bruna">Maria Bruna</a> (a Whitehead Prize winner) and <a href="https://en.wikipedia.org/wiki/Pauline_Barrieu">Pauline Barrieu</a> (Bachelier 2018).</p>
  </li>
  <li>
    <p><a href="https://www.chronicle.com/article/georgia-s-top-down/249095">A power struggle between the Georgia state university system and state government blocks Georgia Tech and other campuses from enacting any coronavirus safety rules</a> (<a href="https://mathstodon.xyz/@11011110/104435200227063842"></a>).</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/06/30/linkage.html"><span class="datestr">at June 30, 2020 04:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/097">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/097">TR20-097 |  6-Uniform Maker-Breaker Game Is PSPACE-Complete | 

	Md Lutfar Rahman, 

	Thomas Watson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a STOC 1976 paper, Schaefer proved that it is PSPACE-complete to determine the winner of the so-called Maker-Breaker game on a given set system, even when every set has size at most 11. Since then, there has been no improvement on this result. We prove that the game remains PSPACE-complete even when every set has size 6.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/097"><span class="datestr">at June 30, 2020 03:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=188">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/">Virtual STOC 2020 – Behind the Screens</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In order to assist organizers of other virtual conferences, the general chairs of STOC 2020 (myself, Konstantin Makarychev, Yury Makarychev and Madhur Tulsiani, with input from PC chair Julia Chuzhoy) wrote a detailed document describing the design and execution of the conference. I personally felt the conference went about as well as it could have gone, and despite many moving parts, there were minimal technical difficulties.</p>



<p>The guide is available here: <a href="https://docs.google.com/document/d/1nzyvfdsXLzqYXxxdjw1y_OHAYwGolHCZUkRVmlxG9BE/edit?ts=5efa758c" target="_blank" rel="noreferrer noopener">Virtual STOC 2020 – Behind the Screens</a>.</p>



<p>If you have any questions or comments, feel free to comment below, or join in the conversation on <a href="https://twitter.com/thegautamkamath/status/1277959908168695808">Twitter</a>.</p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/06/30/virtual-stoc-2020-behind-the-screens/"><span class="datestr">at June 30, 2020 01:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4886">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4886">David Poulin</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<div class="wp-block-image"><figure class="aligncenter"><img src="https://media-exp1.licdn.com/dms/image/C4E03AQG9DmvmxhU3RA/profile-displayphoto-shrink_200_200/0?e=1597276800&amp;v=beta&amp;t=wav_nmh_CgU1IgzEbc89IQlfL5fNg0k6lcxs9_F_6qk" alt="100+ &quot;Dave Poulin&quot; profiles | LinkedIn" /></figure></div>



<p>2020 sucks.</p>



<p>Yesterday I learned that <a href="https://www.cifar.ca/cifarnews/2020/06/18/a-quantum-festschrift-for-david-poulin">David Poulin</a>, a creative and widely-beloved quantum computing and information theorist, has died at age 43, of an aggressive brain cancer.  After studying under many of the field’s legends—Gilles Brassard, Wojciech Zurek, Ray Laflamme, Gerard Milburn, John Preskill—David became a professor at the University of Sherbrooke in Quebec.  There he played a leading role in CIFAR (the Canadian Institute For Advanced Research), eventually co-directing its quantum information science program with Aephraim Steinberg.  Just this fall (!), David moved to Microsoft Research to start a new phase of his career.  He’s survived by a large family.</p>



<p>While I can’t claim any deep knowledge of David’s work—he and I pursued very different problems—it seems appropriate to mention some of his best-known contributions.  With David Kribs, Ray Laflamme, and Maia Lesosky, he <a href="https://arxiv.org/abs/quant-ph/0504189">introduced</a> the formalism of operator quantum error correction, and made many other contributions to the theory of quantum error-correction and fault-tolerance (including the estimation of thresholds).  He and coauthors <a href="https://www.nature.com/articles/ncomms1147">showed</a> in a <em>Nature</em> paper how to do quantum state tomography on 1D matrix product states efficiently.  With Pavithran Iyer, he <a href="https://arxiv.org/abs/1310.3235">proved</a> that optimal decoding of stabilizer codes is #P-hard.</p>



<p>And if none of that makes a sufficient impression on <em>Shtetl-Optimized</em> readers: well, back in 2013, when D-Wave was claiming to have achieved huge quantum speedups, David Poulin was one of the few experts willing to take a clear skeptical stance in public (including right in my comment section—see <a href="https://www.scottaaronson.com/blog/?p=1400#comment-79596">here</a> for example).</p>



<p>I vividly remember being officemates with David back in 2003, at the Perimeter Institute in Waterloo—before Perimeter had its sleek black building, when it still operated out of a converted tavern.  (My and David’s office was in the basement, reached via a narrow staircase.)  David liked to tease me: for example, if I found him in conversation with someone else and asked what it was about, he’d say, “oh, nothing to do with computational efficiency, no reason for you to care.”  (And yet, much of David’s work ultimately <em>would</em> have to do with computational efficiency.)</p>



<p>David was taken way too soon and will be missed by everyone who knew him.  Feel free to share David stories in the comments.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4886"><span class="datestr">at June 30, 2020 04:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15812">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15812">Statistical-Query Lower Bounds via Functional Gradients</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goel:Surbhi.html">Surbhi Goel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gollakota:Aravind.html">Aravind Gollakota</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klivans:Adam.html">Adam Klivans</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15812">PDF</a><br /><b>Abstract: </b>We give the first statistical-query lower bounds for agnostically learning
any non-polynomial activation with respect to Gaussian marginals (e.g., ReLU,
sigmoid, sign). For the specific problem of ReLU regression (equivalently,
agnostically learning a ReLU), we show that any statistical-query algorithm
with tolerance $n^{-\Theta(\epsilon^{-1/2})}$ must use at least $2^{n^c}
\epsilon$ queries for some constant $c &gt; 0$, where $n$ is the dimension and
$\epsilon$ is the accuracy parameter. Our results rule out general (as opposed
to correlational) SQ learning algorithms, which is unusual for real-valued
learning problems. Our techniques involve a gradient boosting procedure for
"amplifying" recent lower bounds due to Diakonikolas et al. (COLT 2020) and
Goel et al. (ICML 2020) on the SQ dimension of functions computed by two-layer
neural networks. The crucial new ingredient is the use of a nonstandard convex
functional during the boosting procedure. This also yields a best-possible
reduction between two commonly studied models of learning: agnostic learning
and probabilistic concepts.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15812"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15747">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15747">The Hylland-Zeckhauser Rule Under Bi-Valued Utilities</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aziz:Haris.html">Haris Aziz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15747">PDF</a><br /><b>Abstract: </b>The Hylland-Zeckhauser (HZ) rule is a well-known rule for probabilistic
assignment of items. The complexity of the rule has received renewed interest
recently with Vazirani and Yannakakis (2020) proposing a strongly
polynomial-time algorithm for the rule under bi-valued utilities, and making
several general insights. We study the rule under the case of agents having
bi-valued utilities. We point out several characterizations of the HZ rule,
drawing clearer relations with several well-known rules in the literature. As a
consequence, we point out alternative strongly polynomial-time algorithms for
the HZ solution. We also give reductions from computing the HZ solution to
computing well-known solutions based on leximin or Nash social welfare. An
interesting contrast is that the HZ rule is group-strategyproof whereas the
unconstrained competitive equilibrium with equal incomes rule is not even
strategyproof. We also clarify which results change when moving from 1-0 binary
utilities to the more general bi-valued utilities.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15747"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15744">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15744">Fast and Private Submodular and $k$-Submodular Functions Maximization with Matroid Constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rafiey:Akbar.html">Akbar Rafiey</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yoshida:Yuichi.html">Yuichi Yoshida</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15744">PDF</a><br /><b>Abstract: </b>The problem of maximizing nonnegative monotone submodular functions under a
certain constraint has been intensively studied in the last decade, and a wide
range of efficient approximation algorithms have been developed for this
problem. Many machine learning problems, including data summarization and
influence maximization, can be naturally modeled as the problem of maximizing
monotone submodular functions. However, when such applications involve
sensitive data about individuals, their privacy concerns should be addressed.
In this paper, we study the problem of maximizing monotone submodular functions
subject to matroid constraints in the framework of differential privacy. We
provide $(1-\frac{1}{\mathrm{e}})$-approximation algorithm which improves upon
the previous results in terms of approximation guarantee. This is done with an
almost cubic number of function evaluations in our algorithm.
</p>
<p>Moreover, we study $k$-submodularity, a natural generalization of
submodularity. We give the first $\frac{1}{2}$-approximation algorithm that
preserves differential privacy for maximizing monotone $k$-submodular functions
subject to matroid constraints. The approximation ratio is asymptotically tight
and is obtained with an almost linear number of function evaluations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15744"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15664">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15664">Minimizing The Maximum Distance Traveled To Form Patterns With Systems of Mobile Robots</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Jared Coleman, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kranakis:Evangelos.html">Evangelos Kranakis</a>, Oscar Morales-Ponce, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Opatrny:Jaroslav.html">Jaroslav Opatrny</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Urrutia:Jorge.html">Jorge Urrutia</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vogtenhuber:Birgit.html">Birgit Vogtenhuber</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15664">PDF</a><br /><b>Abstract: </b>In the pattern formation problem, robots in a system must self-coordinate to
form a given pattern, regardless of translation, rotation, uniform-scaling,
and/or reflection. In other words, a valid final configuration of the system is
a formation that is \textit{similar} to the desired pattern. While there has
been no shortage of research in the pattern formation problem under a variety
of assumptions, models, and contexts, we consider the additional constraint
that the maximum distance traveled among all robots in the system is minimum.
Existing work in pattern formation and closely related problems are typically
application-specific or not concerned with optimality (but rather feasibility).
We show the necessary conditions any optimal solution must satisfy and present
a solution for systems of three robots. Our work also led to an interesting
result that has applications beyond pattern formation. Namely, a metric for
comparing two triangles where a distance of $0$ indicates the triangles are
similar, and $1$ indicates they are \emph{fully dissimilar}.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15664"><span class="datestr">at June 30, 2020 11:57 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15650">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15650">Social Distancing is Good for Points too!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Flores=Velazco:Alejandro.html">Alejandro Flores-Velazco</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15650">PDF</a><br /><b>Abstract: </b>The nearest-neighbor rule is a well-known classification technique that,
given a training set P of labeled points, classifies any unlabeled query point
with the label of its closest point in P. The nearest-neighbor condensation
problem aims to reduce the training set without harming the accuracy of the
nearest-neighbor rule.
</p>
<p>FCNN is the most popular algorithm for condensation. It is heuristic in
nature, and theoretical results for it are scarce. In this paper, we settle the
question of whether reasonable upper-bounds can be proven for the size of the
subset selected by FCNN. First, we show that the algorithm can behave poorly
when points are too close to each other, forcing it to select many more points
than necessary. We then successfully modify the algorithm to avoid such cases,
thus imposing that selected points should "keep some distance". This
modification is sufficient to prove useful upper-bounds, along with
approximation guarantees for the algorithm.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15650"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15584">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15584">A Polynomial Kernel for Line Graph Deletion</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lochet:William.html">William Lochet</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15584">PDF</a><br /><b>Abstract: </b>The line graph of a graph $G$ is the graph $L(G)$ whose vertex set is the
edge set of $G$ and there is an edge between $e,f\in E(G)$ if $e$ and $f$ share
an endpoint in $G$. A graph is called line graph if it is a line graph of some
graph. We study the Line-Graph-Edge Deletion problem, which asks whether we can
delete at most $k$ edges from the input graph $G$ such that the resulting graph
is a line graph. More precisely, we give a polynomial kernel for
Line-Graph-Edge Deletion with $\mathcal{O}(k^{5})$ vertices. This answers an
open question posed by Falk H\"{u}ffner at Workshop on Kernels (WorKer) in
2013.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15584"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15575">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15575">Random Access in Persistent Strings</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bille:Philip.html">Philip Bille</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oslash=rtz:Inge_Li.html">Inge Li Gørtz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15575">PDF</a><br /><b>Abstract: </b>We consider compact representations of collections of similar strings that
support random access queries. The collection of strings is given by a rooted
tree where edges are labeled by an edit operation (inserting, deleting, or
replacing a character) and a node represents the string obtained by applying
the sequence of edit operations on the path from the root to the node. The goal
is to compactly represent the entire collection while supporting fast random
access to any part of a string in the collection. This problem captures natural
scenarios such as representing the past history of a edited document or
representing highly-repetitive collections. Given a tree with $n$ nodes, we
show how to represent the corresponding collection in $O(n)$ space and optimal
$O(\log n/ \log \log n)$ query time. This improves the previous time-space
trade-offs for the problem. To obtain our results, we introduce new techniques
and ideas, including a reduction to a new geometric line segment selection
together with an efficient solution.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15575"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15512">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15512">Parallel Weighted Model Counting with Tensor Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dudek:Jeffrey_M=.html">Jeffrey M. Dudek</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vardi:Moshe_Y=.html">Moshe Y. Vardi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15512">PDF</a><br /><b>Abstract: </b>A promising new algebraic approach to weighted model counting makes use of
tensor networks, following a reduction from weighted model counting to
tensor-network contraction. Prior work has focused on analyzing the single-core
performance of this approach, and demonstrated that it is an effective addition
to the current portfolio of weighted-model-counting algorithms.
</p>
<p>In this work, we explore the impact of multi-core and GPU use on
tensor-network contraction for weighted model counting. To leverage multiple
cores, we implement a parallel portfolio of tree-decomposition solvers to find
an order to contract tensors. To leverage a GPU, we use TensorFlow to perform
the contractions. We compare the resulting weighted model counter on 1914
standard weighted model counting benchmarks and show that it significantly
improves the virtual best solver.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15512"><span class="datestr">at June 30, 2020 11:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15463">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15463">Queues with Small Advice</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitzenmacher:Michael.html">Michael Mitzenmacher</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15463">PDF</a><br /><b>Abstract: </b>Motivated by recent work on scheduling with predicted job sizes, we consider
the performance of scheduling algorithms with minimal advice, namely a single
bit. Besides demonstrating the power of very limited advice, such schemes are
quite natural. In the prediction setting, one bit of advice can be used to
model a simple prediction as to whether a job is "large" or "small"; that is,
whether a job is above or below a given threshold. Further, one-bit advice
schemes can correspond to mechanisms that tell whether to put a job at the
front or the back for the queue, a limitation which may be useful in many
implementation settings. Finally, queues with a single bit of advice have a
simple enough state that they can be analyzed in the limiting mean-field
analysis framework for the power of two choices. Our work follows in the path
of recent work by showing that even small amounts of even possibly inaccurate
information can greatly improve scheduling performance.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15463"><span class="datestr">at June 30, 2020 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15412">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15412">Submodular Combinatorial Information Measures with Applications in Machine Learning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iyer:Rishabh.html">Rishabh Iyer</a>, Ninad Khargoankar, Jeff Bilmes, Himanshu Asanani <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15412">PDF</a><br /><b>Abstract: </b>Information-theoretic quantities like entropy and mutual information have
found numerous uses in machine learning. It is well known that there is a
strong connection between these entropic quantities and submodularity since
entropy over a set of random variables is submodular. In this paper, we study
combinatorial information measures that generalize independence, (conditional)
entropy, (conditional) mutual information, and total correlation defined over
sets of (not necessarily random) variables. These measures strictly generalize
the corresponding entropic measures since they are all parameterized via
submodular functions that themselves strictly generalize entropy. Critically,
we show that, unlike entropic mutual information in general, the submodular
mutual information is actually submodular in one argument, holding the other
fixed, for a large class of submodular functions whose third-order partial
derivatives satisfy a non-negativity property. This turns out to include a
number of practically useful cases such as the facility location and set-cover
functions. We study specific instantiations of the submodular information
measures on these, as well as the probabilistic coverage, graph-cut, and
saturated coverage functions, and see that they all have mathematically
intuitive and practically useful expressions. Regarding applications, we
connect the maximization of submodular (conditional) mutual information to
problems such as mutual-information-based, query-based, and privacy-preserving
summarization -- and we connect optimizing the multi-set submodular mutual
information to clustering and robust partitioning.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15412"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15381">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15381">The Generalized Independent and Dominating Set Problems on Unit Disk Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jena:Sangram_K=.html">Sangram K. Jena</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jallu:Ramesh_K=.html">Ramesh K. Jallu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Gautam_K=.html">Gautam K. Das</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nandy:Subhas_C=.html">Subhas C. Nandy</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15381">PDF</a><br /><b>Abstract: </b>In this article, we study a generalized version of the maximum independent
set and minimum dominating set problems, namely, the maximum $d$-distance
independent set problem and the minimum $d$-distance dominating set problem on
unit disk graphs for a positive integer $d&gt;0$. We first show that the maximum
$d$-distance independent set problem and the minimum $d$-distance dominating
set problem belongs to NP-hard class. Next, we propose a simple polynomial-time
constant-factor approximation algorithms and PTAS for both the problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15381"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15349">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15349">Chroma Intra Prediction with attention-based CNN architectures</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=oacute=rriz:Marc.html">Marc Górriz</a>, Saverio Blasi, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Smeaton:Alan_F=.html">Alan F. Smeaton</a>, Noel E. O'Connor, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mrak:Marta.html">Marta Mrak</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15349">PDF</a><br /><b>Abstract: </b>Neural networks can be used in video coding to improve chroma
intra-prediction. In particular, usage of fully-connected networks has enabled
better cross-component prediction with respect to traditional linear models.
Nonetheless, state-of-the-art architectures tend to disregard the location of
individual reference samples in the prediction process. This paper proposes a
new neural network architecture for cross-component intra-prediction. The
network uses a novel attention module to model spatial relations between
reference and predicted samples. The proposed approach is integrated into the
Versatile Video Coding (VVC) prediction pipeline. Experimental results
demonstrate compression gains over the latest VVC anchor compared with
state-of-the-art chroma intra-prediction methods based on neural networks.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15349"><span class="datestr">at June 30, 2020 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15259">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15259">Reconstructing Biological and Digital Phylogenetic Trees in Parallel</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Ramtin Afshar, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goodrich:Michael_T=.html">Michael T. Goodrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Matias:Pedro.html">Pedro Matias</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Osegueda:Martha_C=.html">Martha C. Osegueda</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15259">PDF</a><br /><b>Abstract: </b>In this paper, we study the parallel query complexity of reconstructing
biological and digital phylogenetic trees from simple queries involving their
nodes. This is motivated from computational biology, data protection, and
computer security settings, which can be abstracted in terms of two parties, a
\emph{responder}, Alice, who must correctly answer queries of a given type
regarding a degree-$d$ tree, $T$, and a \emph{querier}, Bob, who issues batches
of queries, with each query in a batch being independent of the others, so as
to eventually infer the structure of $T$. We show that a querier can
efficiently reconstruct an $n$-node degree-$d$ tree, $T$, with a logarithmic
number of rounds and quasilinear number of queries, with high probability, for
various types of queries, including \emph{relative-distance queries} and
\emph{path queries}. Our results are all asymptotically optimal and improve the
asymptotic (sequential) query complexity for one of the problems we study.
Moreover, through an experimental analysis using both real-world and synthetic
data, we provide empirical evidence that our algorithms provide significant
parallel speedups while also improving the total query complexities for the
problems we study.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15259"><span class="datestr">at June 30, 2020 11:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15254">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15254">Optimizing Cuckoo Filter for high burst tolerance,low latency, and high throughput</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Aman Khalid <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15254">PDF</a><br /><b>Abstract: </b>In this paper, we present an implementation of a cuckoo filter for membership
testing, optimized for distributed data stores operating in high workloads. In
large databases, querying becomes inefficient using traditional search methods.
To achieve optimal performance it is necessary to use probabilistic data
structures to test the membership of a given key, at the cost of getting false
positives while querying data. The widely used bloom filters can be used for
this, but they have limitations like no support for deletes. To improve upon
this we use a modified version of the cuckoo filter that gives better amortized
times for search, with less false positives.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15254"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15166">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15166">Dominate or Delete: Decentralized Competing Bandits with Uniform Valuation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankararaman:Abishek.html">Abishek Sankararaman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Basu:Soumya.html">Soumya Basu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankararaman:Karthik_Abinav.html">Karthik Abinav Sankararaman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15166">PDF</a><br /><b>Abstract: </b>We study regret minimization problems in a two-sided matching market where
uniformly valued demand side agents (a.k.a. agents) continuously compete for
getting matched with supply side agents (a.k.a. arms) with unknown and
heterogeneous valuations. Such markets abstract online matching platforms (for
e.g. UpWork, TaskRabbit) and falls within the purview of matching bandit models
introduced in Liu et al. \cite{matching_bandits}. The uniform valuation in the
demand side admits a unique stable matching equilibrium in the system. We
design the first decentralized algorithm - \fullname\; (\name), for matching
bandits under uniform valuation that does not require any knowledge of reward
gaps or time horizon, and thus partially resolves an open question in
\cite{matching_bandits}. \name\; works in phases of exponentially increasing
length. In each phase $i$, an agent first deletes dominated arms -- the arms
preferred by agents ranked higher than itself. Deletion follows dynamic
explore-exploit using UCB algorithm on the remaining arms for $2^i$ rounds.
{Finally, the preferred arm is broadcast in a decentralized fashion to other
agents through {\em pure exploitation} in $(N-1)K$ rounds with $N$ agents and
$K$ arms.} Comparing the obtained reward with respect to the unique stable
matching, we show that \name\; achieves $O(\log(T)/\Delta^2)$ regret in $T$
rounds, where $\Delta$ is the minimum gap across all agents and arms. We
provide a (orderwise) matching regret lower-bound.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15166"><span class="datestr">at June 30, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17244">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/">Taking a Problem Down a Peg</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>By blowing up its objects</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/greenelobb/" rel="attachment wp-att-17246"><img width="183" alt="" src="https://rjlipton.files.wordpress.com/2020/06/greenelobb.png?w=183&amp;h=120" class="alignright wp-image-17246" height="120" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://math.berkeley.edu/people/faculty/joshua-evan-greene">src1</a>, <a href="https://groups.oist.jp/mathprog/andrew-lobb">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Joshua Greene and Andrew Lobb <a href="https://arxiv.org/pdf/2005.09193.pdf">proved</a> last month that every <em>smooth</em> Jordan curve in the plane and real <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cleq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \leq 1}" class="latex" title="{r \leq 1}" />, there are four points on the curve that form a rectangle with sides of ratio <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />.</p>
<p>
Today we explain how this result relates to Otto Toeplitz’s famous “square peg conjecture,” which is the case <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = 1}" class="latex" title="{r = 1}" /> when the curve need not be smooth.</p>
<p>
We noticed this via an <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> last Thursday by Kevin Hartnett for <em>Quanta</em>. Hartnett describes this research advance as a product of the pandemic inducing them to take time for deeper reflection on fundamental problems. We wonder how much is bubbling on hard problems in our own field—this is one reason for our last post’s <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news">interest</a> in (good kinds of) “gossip.”  He also gives great diagrams for the geometrical intuition.</p>
<p>
We will portray this advance instead along lines of things we’ve said recently about how to attack hard problems by seeking and solving simpler ones or special cases as stepping stones. Dick wrote a <a href="https://rjlipton.wordpress.com/2018/10/21/the-inscribed-square-problem/">post</a> two years ago on the original Toeplitz problem, which this work still leaves open. That post focused on ways general Jordan curves can be nasty. This one needs an extra niceness condition but proves a stronger result for all <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />. How much can progress on “nice” inform problems with “nasty”? That kind of question comes up in complexity theory all the time.</p>
<p>
</p><p></p><h2> Pegging Rectangles </h2><p></p>
<p></p><p>
A <em>Jordan curve</em> is the image of a continuous 1-1 map <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> from the circle to the plane. The condition of being 1-1 prevents the image from intersecting itself, so it is a single closed loop. By the Jordan curve <a href="https://en.wikipedia.org/wiki/Jordan_curve_theorem">theorem</a>, the loop always partitions the rest of the plane into two connected regions, exactly one of which is bounded. Amazingly, a Jordan curve <a href="https://en.wikipedia.org/wiki/Osgood_curve">can</a> have positive Lebesgue measure, yet cannot fill all of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{R}^2}" class="latex" title="{\mathbb{R}^2}" />. Such curves can, however, approach the kind of space-filling curves defined by Giuseppe Peano, and thus have any Lebesgue density less than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, as was noted also by William Osgood in his 1903 <a href="https://www.jstor.org/stable/pdf/1986455.pdf">paper</a>.</p>
<p>
The Toeplitz conjecture is that every Jordan curve has four points that form a square. As noted in Dick’s post, the positive-area case is actually an easy yes-case. Nasty cases are where the curve is nowhere-differentiable with zero area. Thus far, the problem has been answered <em>yes</em> only in the presence of some uniformity condition that limits the local nastiness of the curve. The simplest one is for the curve to be <em>smooth</em> in that <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has a continuous first derivative. Here is a smooth curve that is not convex, so that the square need not be “inside” the curve:</p>
<p></p><p></p>
<p><a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/matschkefig2/" rel="attachment wp-att-17247"><img src="https://rjlipton.files.wordpress.com/2020/06/matschkefig2.jpg?w=600" alt="" class="aligncenter size-full wp-image-17247" /></a></p>
<p>
This diagram is from Benjamin Matchske’s wonderful recent <a href="https://www.ams.org/notices/201404/rnoti-p346.pdf">survey</a> of the peg problem in the <em>AMS Notices</em>. Four months ago we’d have said it looks like a thin heart or fat boomerang. <i>Now</i> it looks to us like a face mask.</p>
<p>
As the survey notes, it is easy to show that every Jordan curve has <em>some</em> rectangle. The rectangle problem is to show that rectangles of <i>every</i> aspect ratio <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> can be pegged to the curve. There are two main reasons the square and rectangle problems are hard and harder:</p>
<ol>
<li>
Although any Jordan curve can be written as a limit of nice ones, the squares in the nice ones can degenerate to a single point in the limit. <p></p>
</li><li>
Even for nice curves, a parity property that holds for squares can fail for rectangles.
</li></ol>
<p>
The property in the second point enables arguments of the kind: <em>for generic curves the number of squares is odd, therefore it is nonzero</em>. This then carries over to sufficiently nice curves in the generic closure. The failure of this property for rectangles is a main reason the results by Greene and Lobb are new.</p>
<p>
</p><p></p><h2> The Paper </h2><p></p>
<p></p><p>
The new paper is written tersely at a high level, and we must confess not being able to catch all details in compressed time. But we can highlight some aspects of the argument. First, as we have said, it exemplifies:</p>
<ul>
<li>
<em>Solve a Simpler Problem</em>.
</li></ul>
<p>
This is however coupled with a second aspect:</p>
<ul>
<li>
<em>Bring Up the Reserves</em>.
</li></ul>
<p>
It may be that the rectangle conjecture is not only true but “equally true” in the sense that the fundamental reason applies equally well to the case of rectangles. The parity argument that works for cases involving squares may be a crutch that misses the deepest explanations. Promoting arguments that avoid this crutch may marshal resources needed to make a breakthrough on the main problem for completely general Jordan curves.</p>
<p>
This runs somewhat counter to what we have said about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> versus <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> proof attempts recently. The reason for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P &lt; NP}}" class="latex" title="{\mathsf{P &lt; NP}}" /> believed by most is that problems like SAT require <em>exponential</em> time, not just super-polynomial time. Yet no one knows even a <em>super-linear</em> lower bound, apart from barely-superlinear bounds that exploit grainy aspects of the multitape Turing machine model and apply only to it. Nor is any super-linear lower bound known on Boolean circuit size. Maybe it is a viable strategy also to “bring up reserves” by finding restricted cases where (conditional) exponential lower bounds can be proven, as well as to explore contingencies like <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">SETH</a>, as we covered <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">here</a>. But both of use have always felt that the super-linear frontier holds the buried keys to further progress.</p>
<p>
The Greene-Lobb proof has two aspects that may also resonate in complexity:</p>
<ul>
<li>
<em>Blow Up the Objects</em>.
</li></ul>
<p>
The <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> in <em>Quanta</em> has great diagrams illustrating how the set of pairs of points on the curve corresponds to a Möbius strip in a related space. Cole Hugelmeyer, a graduate student at Princeton, <a href="https://arxiv.org/pdf/1911.07336.pdf">proved</a> last year how to get rectangles covering at least one-third of possible values <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+%280%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \in (0,1]}" class="latex" title="{r \in (0,1]}" /> by embedding the Möbius strips in a four-dimensional space. Intersections between a strip and a rotated copy yield rectangles on the original Jordan curve. </p>
<p>
That led Greene and Lobb to consider larger objects with properties like pairs of Möbius strips in the larger space. The Klein bottle is the natural next thing to consider and led to a feature of their proof that made the desired conclusion pop out:</p>
<ul>
<li>
<em>Identify and Rule Out Obstructions</em>.
</li></ul>
<p>
The clever point pivots on the fact that a Klein bottle cannot be smoothly embedded into the complex plane <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{C}^2}" class="latex" title="{\mathbb{C}^2}" /> as a Lagrangian submanifold. The proof shows that for any prescribed aspect ratio <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> one can construct a mapping that almost succeeds in embedding such a Klein bottle. The fact that it must fail means that the image must yield a point of intersection witnessing the failure. The presence of this point then yields the construction of four other points on the Jordan curve that form the vertices of the needed rectangle.</p>
<p>
We have briefly <a href="https://rjlipton.wordpress.com/2018/06/06/princeton-is-invariant/">mentioned</a> how the concept of <em>obstructions</em> is integral to the <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">Geometric</a> <a href="https://dl.acm.org/doi/10.1145/1944345.1944346">Complexity</a> <a href="http://gct.cs.uchicago.edu/">Theory</a> attack on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P &lt; NP}}" class="latex" title="{\mathsf{P &lt; NP}}" />. Closer to home, however, is how László Babai's graph isomorphism algorithm and proof works by identifying a subclass of graphs called Johnson graphs as obstructions to a simpler algorithm, as we highlighted <a href="https://rjlipton.wordpress.com/2017/01/06/snow-and-theory/">here</a>.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Can you find more lessons from the new advance on the Toeplitz problem?  Dick and I have considered ideas of blowing up from languages to pairs of languages (and making <i>reductions</i> between problems the fundamental units of analysis) but this has not gone beyond dreamwork.</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/"><span class="datestr">at June 29, 2020 09:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-7761235140481153504">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html">Can you name a famous living Chemist? Can anyone?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
I was re-watching the  Greatest-of-all-time Jeopardy championship and the following happen (I paraphrase)<br />
<br />
----------------------<br />
Alex Trebek: The category is Chemistry and we have a special guest reading the clues.<br />
<br />
Darling: I wonder who that will be.<br />
<br />
Bill: Hmm. I assume some famous chemist.<br />
------------------------<br />
<br />
So who was it? Bryan Cranston, the actor who PLAYED chemist Walter White on <i>Breaking Bad.</i><br />
<br />
Why couldn't they get a famous living chemist to read the clues?<br />
<br />
My guess: there are no famous living chemists.<br />
<br />
The number of famous living scientists is fairly short and they are often known for things that are not quite their science. Some are famous because the popularize science (deGrasse Tyson, Dawkins) or because of something unusual about their life (Hawkings when he was alive) or for something else entirely that they did (Ted Kaczynski).  Are any famous for the actual work that they do in the science?<br />
<br />
Andrew Wiles was famous for a brief time, and even made People Magazine's <i>25 most intriguing people of the year</i> list in the early 1990's (after he solved Fermat's Last Theorem). So he was famous but it was short lived.<br />
<br />
Terry Tao was on the Colbert Report (see <a href="http://www.cc.com/video-clips/6wtwlg/the-colbert-report-terence-tao">here</a>) after he won the Fields Medal, the MacAuthor Genius award, and the Breakthrough prize. And even that fame was short lived.<br />
<br />
I looked at the web page of Nobel Prize winners, <a href="https://www.nobelprize.org/prizes/lists/all-nobel-prizes">here</a>.<br />
<br />
The only Chemistry Nobel's I recognized were Marie Curie,  Irene Joilet-Curie (Marie's Daughter), and Erst Rutherford.<br />
<br />
The only Physics Nobel's I recognized were<br />
<br />
Richard Feynman,<br />
<br />
 Eugene Wigner (for writing about <a href="https://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html">The unreasonable effectiveness of mathematics in the natural sciences</a>),<br />
<br />
Richard Hofstadter (since he was the father of Douglas H and an uncle of Leonard H)<br />
<br />
 Andrew Geim (since he won  both an Ig-Noble prize and a Nobel prize, see  <a href="https://blog.computationalcomplexity.org/2010/10/noble-and-ig-noble-prizes.html">here</a>)<br />
<br />
Wolfgang Pauli (I've heard the term `Pauli Principle" though I did not know what it was until I looked it up while preparing this blog. I prob still don't really know what it means.)<br />
<br />
Enrico Fermi<br />
<br />
Erwin Schrodinger<br />
<br />
Paul Dirac<br />
<br />
Robert Millikan<br />
<br />
Albert Einstein<br />
<br />
Max Karl Ernest Ludwig Planck (I thought his last name was `Institute')<br />
<br />
Johannes Diderik van der Waals<br />
<br />
Pierre Curie<br />
<br />
Marie Curie<br />
<br />
<br />
So, some questions:<br />
<br />
a) Am I wrong? Are there famous living chemists I never heard of? Are there any famous living scientists who are famous for their work in science?<br />
<br />
b) If I am right then was there ever a time when there were famous scientists?<br />
<br />
c) If there was such a time, what changed?<br />
<br />
(I ask all of this non-rhetorically and with no agenda to push.)<br />
<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html"><span class="datestr">at June 29, 2020 08:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/">Postdocs &amp; PhD students in the theory of distributed &amp; parallel computing at Aalto University (apply by August 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing.</p>
<p>Website: <a href="https://research.cs.aalto.fi/da/jobs/">https://research.cs.aalto.fi/da/jobs/</a><br />
Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/"><span class="datestr">at June 29, 2020 04:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2020/06/29/tour-revisited/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2020/06/29/tour-revisited/">What We've Learned to Control</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I’m giving a keynote address at the <a href="https://www.ifac2020.org/">virtual IFAC congress this July</a>, and I submitted an abstract that forces me to reflect on the current state of research at the intersection of machine learning and control. 2020 is particularly appropriate for reflection: For personal reasons, I’ve been working in this space for about half a decade now and <a href="https://www.argmin.net/2018/06/25/outsider-rl/">wrote a blog series on the topic two years ago</a> and it seemed like ideal timing. For the broader community, 2020 happens to be the year we were promised fleets of self-driving cars. Of course, for a myriad of reasons, we’re nowhere close to achieving this goal. Full self-driving has been a key motivator of work in learning-enabled autonomous systems, and it’s important to note this example as a marker of how difficult problems this space really are.</p>

<p>The research community has come to terms with this difficulty, and has committed itself to address the many pressing challenges. Over the last year I attended several great meetings on this topic, including an <a href="https://ajwagen.github.io/adsi_learning_and_control/">NSF funded workshop at UW</a>, a plenary session at <a href="https://ita.ucsd.edu/ws/">ITA</a>, a workshop on intersections of <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">learning, control, and optimization at IPAM</a>, and the <a href="https://sites.google.com/berkeley.edu/l4dc/home">second annual conference on Learning for Dynamics and Control</a>. There is clearly a ton of enthusiasm from researchers in a many different disciplines, and we’re seeing fascinating results mixing techniques from machine learning, computer science, and control. Obviously, I’m going to be leaving out many incredible papers, but, focusing on the theoretical end of the spectrum, perhaps I could highlight <a href="https://arxiv.org/abs/1912.11899">new work on policy optimization</a> that demonstrates how simple optimization techniques can efficiently solve classic, nonconvex control-design problems or <a href="https://arxiv.org/abs/1902.08721">work connecting regret minimization and adaptive control</a> that provides nonasymptotic bounds.</p>

<p>This work has been very useful for establishing language to bridge communication between the diverse research camps interested in the space of learning, dynamics and automation. But, as I’ll discuss shortly, I’d argue that it hasn’t provided many promising approaches to improving large-scale autonomy. That’s ok! These problems are incredibly difficult and aren’t going to be solved by wishing for them to be solved. But I also think it might be worth taking a moment to reflect on which problems we are working on. It’s always a bit too easy for theorists to focus  on improving technical results and lose sight of why someone proved those results in the first place.</p>

<p>As an illustrative example, my research group spent a lot of time studying the <a href="http://www.argmin.net/2018/02/08/lqr/">Linear Quadratic Regulator</a> (LQR). The point of this work was initially to establish baselines: LQR has a closed form solution when the model is known, so we wanted to understand how different algorithms might perform when the underlying model was unknown. It turns out that if you are willing to collect enough data, the best thing you can do for LQR is <a href="https://arxiv.org/abs/1902.07826">estimate the dynamical model, and then exploit this model as if it were true</a>. This so-called “certainty equivalent control” is what practitioners have been doing since the mid-60s to fly satellites and solve other optimal control problems. Proving this result required a bunch of new mathematical insights that established connections between high dimensional statistics and automatic control theory. But it did not bring us closer to solving new challenges in robotics or autonomous systems. Our work here merely showed that what the controls community had been doing for 50 years was already about as well as we could do for this important baseline problem.</p>

<p>So what are the ways forward? Are there things that theory-minded folks can work on short term that might help us understand paths towards improving learning systems in complex feedback loops? Let me suggest a few challenges that I see as both very pressing, but also ones where we might be able to make near-term progress.</p>

<h2 id="machine-learning-is-still-not-reliable-technology">Machine Learning is still not reliable technology</h2>

<p>At the aforementioned <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">IPAM meeting</a>, Richard Murray gave a <a href="https://www.youtube.com/watch?v=Wi8Y---ce28">fantastic survey of the sorts of standards of reliability imposed in aerospace engineering</a>. Go watch it! I don’t want to spoil it for you, but his discussion of Ram Air Turbines is gripping. Richard covers what is needed to get to the sorts of reliability we’d like in autonomous systems. Unfortunately, having <a href="https://arxiv.org/abs/2003.08237">88.5% Top-1 accuracy on ImageNet</a>—while a stunning achievement—doesn’t tell us how to get to systems with failure rates on the order of 1 in a billion. As Boeing has tragically shown, cutting corners on autonomous system safety standards has horrible, tragic consequences.</p>

<p>How can we make machine learning more robust? How can we approach the failure rates needed for safe, reliable autonomy? And how can we establish testing protocols to assure we have such low failure rates?</p>

<h2 id="prediction-systems-in-feedback-loops">Prediction systems in feedback loops</h2>

<p>One particular aspect that I think is worth considering is how supervised learning systems can function as “sensors” in feedback loops. Even if you know everything about a dynamical system, when you observe the state via an estimator generated by a learned component, it’s not clear how to best take action on this observation. Most classic control and planning assumes that your errors in state-estimation are Gaussian or nicely uniformly bounded. Of course, the errors from machine learning systems are neither of these (I recommend checking out the <a href="https://youtu.be/A0cb7wZVFf4">crazy videos</a> of the <a href="https://twitter.com/greentheonly/status/1130956365063761920">confusion</a> that comes out of Tesla Autopilot’s vision systems). How to properly characterize the errors of machine learning systems for control applications seems like a useful, understudied problem. Using off-the-shelf machine learing analysis, it’s unavoidable to have to densely sample all of the possible scenarios in advance in order to guarantee the sort of uniform error bounds desired by control algorithms. This isn’t practical, and, indeed, it’s clear that this sort of sensor characterization is not needed to make reasonable demos work. Though it’s a bit mundane, I think a huge contribution lies in understanding how much data we need to quantify the uncertainty in learned perception components. It’s still not clear to me if this is a machine learning question or a closed-loop design question, and I suspect both views of the problem will be needed to make progress.</p>

<h2 id="why-are-we-all-sleeping-on-model-predictive-control">Why are we all sleeping on model predictive control?</h2>

<p>I still remain baffled by how <a href="http://www.argmin.net/2018/05/02/adp/">model predictive control</a> (MPC) is consistently under appreciated. We’ll commonly see the same tasks in the same meeting, one task done on a robot using some sort of deep reinforcement learning and the other done using model predictive control, and the disparity in performance is stark. It’s like the difference between watching an Olympic level sprinter and me jogging in my neighborhood with a set of orthotics.</p>

<p>Here’s an example from the IPAM workshop. Martin Riedmiller presented work at DeepMind to catch a ball in a cup:</p>



<p>This system uses two cameras, has a rather large “cup,” (it’s a wastepaper basket) and yet still takes 3 days to train on the robot. Francesco Borrelli presented a different approach. Using only a single camera and basic, simple Newtonian physics, and MPC they were able to achieve this performance on the standard-sized “ball-in-a-cup” toy:</p>



<p>If you only saw these two videos, I can’t fathom why would you invest all of your assets into deep RL. I understand there are still a lot of diehards out there, and I know this will offend them. But I want to make a constructive point: so many theorists are spending a lot of time studying RL algorithms, but few in the ML community are analyzing MPC and why it’s so successful. We should rebalance our allocation of mental resources!</p>

<p>Now, while the basic idea of MPC is very simple, the theory gets very hairy very quickly. It definitely takes some time and effort to learn about how to prove convergence of MPC protocols. I’d urge the MPC crowd to connect more with the learning theory crowd to see if a common ground can be found to better understand how MPC works and how we might push its performance even farther.</p>

<h2 id="perhaps-we-should-stop-taking-cues-from-alphago">Perhaps we should stop taking cues from AlphaGo?</h2>

<p>One of the grand goals in RL is to use function approximation algorithms to estimate value functions. The conventional wisdom asserts that the world is a giant Markov Decision Process and once you have its value function, you can just greedily maximize it and you’ll win at life. Now, this sort of approach clearly doesn’t work for robots, and I’m perplexed by why people still think it will work at all. Part of the motivation is that this approach was used to solve Go. But at some point I think we all have to come to terms with the fact that games are not the real world.</p>

<p>Now, I’d actually argue that RL <em>does</em> work in the real world, but it’s in systems that most people don’t actively think of as RL systems. Greedy value function estimation and exploitation is <em>literally</em> how all internet revenue is made. Systems simply use past data to estimate value functions and then choose the action that maximizes the value at the next step. Though seldom described as such, these are instances of the “greedy contextual bandit” algorithm, and this algorithm makes tech companies tons of money. But many researchers have also pointed out that this algorithm leads to misinformation, polarization, and radicalization.</p>

<p>Everyone tries to motivate RL by the success of AlphaGo, but they should be using the success of Facebook and Google instead. And if they did this, I think it would be a lot more clear why RL is terrifying and dangerous, and one whose limitations we desperately need to understand so that we can build safer tools.</p>

<h2 id="lessons-from-the-70s-about-optimal-control">Lessons from the 70s about optimal control</h2>

<p>I have one set of ideas along these lines that, while I think is important, I still am having a hard time articulating. Indeed, I might just take a few blog posts to work through my thoughts on this, but let me close this blog with a teaser of discussions to come. As I mentioned above, optimal control was a guiding paradigm for a variety of control applications in the 60s and 70s. During this time, it seemed like there might even be hidden benefits to a full-on optimization paradigm: though you’d optimize a single, simple objective, you would often get additional robustness guarantees for free. However, it turned out that this was very misleading and that <a href="https://ieeexplore.ieee.org/document/1101812">there were no guarantees of robustness even for simple optimal control problems</a>. This shouldn’t be too surprising, as if you devote a lot of resources towards one objective, you are likely neglecting some other objective. But showing how and why these fragilities arise is quite delicate. It’s not always obvious how you <em>should</em> be devoting your resources.</p>

<p>Trying to determine how to allocate engineering resources to balance safety and performance is the heart of “robust control.” One thing I’m fascinated by moving forward is if any of the early developments in robust control might transfer over for a new kind of “robust ML.” Unfortunately for all of us, robust control is a rather encrypted literature. There is a lot of mathematics, but often not clear statements about <em>why</em> we study particular problems or what are the fundamental limits of feedback. While diligent young learning theorists have been scouring classic control theory text books for insights, these books don’t always articulate what we can and cannot do and what are the problems that control theory might help solve. We still have a lot of work to do in communicating what we know and what problems remain challenging. I think it would be useful for control theorists to think of how to best communicate the fundamental concepts of robust control. I hope to take up this challenge in the next few months on this blog.</p>

<p><em>I’d like to thank Sarah Dean, Horia Mania, Nik Matni, and Ludwig Schmidt for their helpful feedback on this post. I’d also like to thank John Doyle for several inspiring conversations about robustness in optimal control and on the encrypted state of the control theory literature.</em></p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2020/06/29/tour-revisited/"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html">Sorting with integer offsets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</p>

<p>Suppose you’re given as input a set of real numbers , and an integer parameter . Describe an algorithm for sorting the  numbers  in time . You can assume that standard arithmetic operations on real numbers (including comparisons and rounding down to an integer) take constant time per operation.</p>

<p>Models of computation that mix constant-time real arithmetic and rounding operations can be problematic, as by building up and then rounding numbers with unlimited precision you can access a level of computational power beyond what actual computers can do, but I don’t think that’s a concern here. If someone wants to use bit-packing tricks to implement a crazy but fast sorting algorithm in this model, they’re beyond the level of this exercise.</p>

<p>The same method (which I’m not going to describe, to preserve its value as an exercise) more generally allows you to take as input pairs  and sort the numbers  in time  where . But it relies heavily on the fact that you’re adding integers to the ’s. For a problem that can’t be handled in this way, consider instead sorting the numbers  where we multiply instead of adding. Or, if you prefer to view this as a type of <a href="https://en.wikipedia.org/wiki/X_%2B_Y_sorting"> sorting</a> problem, take logs in your favorite base and sort the numbers . It’s not at all obvious to me whether this can be done in the same  time bound.</p>

<p>The motivation for looking at all this is <a href="https://cstheory.stackexchange.com/q/47120/95">a question about how to implement the greedy set cover quickly</a>. You can find the unweighted <a href="https://en.wikipedia.org/wiki/Set_cover_problem#Greedy_algorithm">greedy set cover</a> in linear time (linear in the sum of the sizes of the input sets; this is an exercise in CLRS), and you can approximate the weighted greedy set cover very accurately in linear time using similar ideas. If you could sort  quickly you could use the sorted order to compute the weighted greedy set cover exactly in the same time as the sorting algorithm. Which is totally useless because the greedy cover is already an approximation, so a fast and accurate approximation to the greedy cover is good enough. But I think the question of sorting  is interesting despite its uselessness in this application.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/104424777130789257">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html"><span class="datestr">at June 28, 2020 05:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
