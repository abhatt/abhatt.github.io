<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="http://www.minimizingregret.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.minimizingregret.com/" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/?tag=tcs&amp;feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="http://learningwitherrors.org/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://learningwitherrors.org" title="Learning With Errors">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://kintali.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kintali.wordpress.com" title="My Brain is Open">Shiva Kintali</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at February 28, 2019 08:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=341">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2019/02/27/tcs-talk-wednesday-march-6th-shayan-oveis-gharan-university-of-washington/">TCS+ talk: Wednesday, March 6th, Shayan Oveis Gharan, University of Washington</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, March 6th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Shayan Oveis Gharan</strong> from University of Washington will speak about “<em>Strongly log concave polynomials, high dimensional simplicial complexes, and an FPRAS for counting Bases of Matroids</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: A matroid is an abstract combinatorial object which generalizes the notions of spanning trees, and linearly independent sets of vectors. I will talk about an efficient algorithm based on the Markov Chain Monte Carlo technique to approximately count the number of bases of any given matroid.</p>
<p>The proof is based on a new connections between high dimensional simplicial complexes, and a new class of multivariate polynomials called completely log-concave polynomials. In particular, we exploit a fundamental fact from our previous work that the bases generating polynomial of any given matroid is a log-concave function over the positive orthant.</p>
<p>Based on joint works with Nima Anari, Kuikui Liu, and Cynthia Vinzant.</p></blockquote>
<p> </p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2019/02/27/tcs-talk-wednesday-march-6th-shayan-oveis-gharan-university-of-washington/"><span class="datestr">at February 28, 2019 04:15 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/025">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/025">TR19-025 |  On Nonadaptive Reductions to the Set of Random Strings and Its Dense Subsets | 

	Shuichi Hirahara, 

	Osamu Watanabe</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We investigate the computational power of an arbitrary distinguisher for (not necessarily computable) hitting set generators as well as the set of Kolmogorov-random strings. This work contributes to (at least) two lines of research. One line of research is the study of the limits of black-box reductions to some distributional NP problem. We show that a black-box nonadaptive randomized reduction to any distinguisher for (not only polynomial-time but even) exponential-time computable hitting set generators can be simulated in AM $\cap$ coAM; we also show an upper bound of $\mathrm{S_2^{NP}}$ even if there is no computational bound on a hitting set generator. These results further strengthen the evidence that the recent worst-case to average-case reductions within NP shown by Hirahara (2018, FOCS) are inherently non-black-box. As an application, we show that GapMCSP $\in$ P/poly implies that GapMCSP is low for $\mathrm{S_2^p}$, which is proved by combining our proof techniques with the non-black-box reductions.

Another line of research concerns the computational power of nonadaptive deterministic polynomial-time reductions to the set of Kolmogorov-random strings. It was conjectured by Allender (CiE, 2012) and others that the computational power is exactly characterized by BPP, intuitively because nonadaptive deterministic reductions could only make use of Kolmogorov-random strings as a source of pseudorandomness.

We present strong evidence *against* this conjecture by showing that every language in the exponential-time hierarchy is reducible to the set of Kolmogorov-random strings under PH reductions; in particular, the conjecture is false unless the exponential-time hierarchy collapses to BPEXP. Moreover, our reduction cannot be regarded as a black-box reduction to avoiding hitting set generators (unless the exponential-time hierarchy collapses to the second level), thereby showing that nonadaptive deterministic efficient reductions can exploit the power of Kolmogorov-random strings not just as a distinguisher for hitting set generators.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/025"><span class="datestr">at February 28, 2019 03:10 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10633">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10633">Dimension-independent Sparse Fourier Transform</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapralov:Michael.html">Michael Kapralov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Velingker:Ameya.html">Ameya Velingker</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zandieh:Amir.html">Amir Zandieh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10633">PDF</a><br /><b>Abstract: </b>The Discrete Fourier Transform (DFT) is a fundamental computational
primitive, and the fastest known algorithm for computing the DFT is the FFT
(Fast Fourier Transform) algorithm. One remarkable feature of FFT is the fact
that its runtime depends only on the size $N$ of the input vector, but not on
the dimensionality of the input domain: FFT runs in time $O(N\log N)$
irrespective of whether the DFT in question is on $\mathbb{Z}_N$ or
$\mathbb{Z}_n^d$ for some $d&gt;1$, where $N=n^d$.
</p>
<p>The state of the art for Sparse FFT, i.e. the problem of computing the DFT of
a signal that has at most $k$ nonzeros in Fourier domain, is very different:
all current techniques for sublinear time computation of Sparse FFT incur an
exponential dependence on the dimension $d$ in the runtime. In this paper we
give the first algorithm that computes the DFT of a $k$-sparse signal in time
$\text{poly}(k, \log N)$ in any dimension $d$, avoiding the curse of
dimensionality inherent in all previously known techniques. Our main tool is a
new class of filters that we refer to as adaptive aliasing filters: these
filters allow isolating frequencies of a $k$-Fourier sparse signal using $O(k)$
samples in time domain and $O(k\log N)$ runtime per frequency, in any dimension
$d$.
</p>
<p>We also investigate natural average case models of the input signal: (1)
worst case support in Fourier domain with randomized coefficients and (2)
random locations in Fourier domain with worst case coefficients. Our techniques
lead to an $\widetilde O(k^2)$ time algorithm for the former and an $\widetilde
O(k)$ time algorithm for the latter.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10633"><span class="datestr">at February 28, 2019 02:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10582">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10582">Polynomial-time Algorithms for Combinatorial Pure Exploration with Full-bandit Feedback</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuroki:Yuko.html">Yuko Kuroki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/x/Xu:Liyuan.html">Liyuan Xu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Miyauchi:Atsushi.html">Atsushi Miyauchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Honda:Junya.html">Junya Honda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sugiyama:Masashi.html">Masashi Sugiyama</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10582">PDF</a><br /><b>Abstract: </b>We study the problem of stochastic combinatorial pure exploration (CPE),
where an agent sequentially pulls a set of single arms (a.k.a. a super arm) and
tries to find the best super arm. Among a variety of problem settings of the
CPE, we focus on the full-bandit setting, where we cannot observe the reward of
each single arm, but only the sum of the rewards. Although we can regard the
CPE with full-bandit feedback as a special case of pure exploration in linear
bandits, an approach based on linear bandits is not computationally feasible
since the number of super arms may be exponential. In this paper, we first
propose a polynomial-time bandit algorithm for the CPE under general
combinatorial constraints and provide an upper bound of the sample complexity.
Second, we design an approximation algorithm for the 0-1 quadratic maximization
problem, which arises in many bandit algorithms with confidence ellipsoids.
Based on our approximation algorithm, we propose novel bandit algorithms for
the top-k selection problem, and prove that our algorithms run in polynomial
time. Finally, we conduct experiments on synthetic and real-world datasets, and
confirm the validity of our theoretical analysis in terms of both the
computation time and the sample complexity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10582"><span class="datestr">at February 28, 2019 02:23 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10489">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10489">Dispersion of Mobile Robots: The Power of Randomness</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Molla:Anisur_Rahaman.html">Anisur Rahaman Molla</a>, William K. Moses Jr <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10489">PDF</a><br /><b>Abstract: </b>We consider cooperation among insects, modeled as cooperation between mobile
robots on a graph. Within this setting, we consider the problem of mobile robot
dispersion on graphs. The study of mobile robots on a graph is an interesting
paradigm with many interesting problems and applications. The problem of
dispersion in this context, introduced by Augustine and Moses Jr., asks that
$n$ robots, initially placed arbitrarily on an $n$ node graph, work together to
quickly reach a configuration with exactly one robot at each node. Previous
work on this problem has looked at the trade-off between the time to achieve
dispersion and the amount of memory required by each robot. However, the
trade-off was analyzed for \textit{deterministic algorithms} and the minimum
memory required to achieve dispersion was found to be $\Omega(\log n)$ bits at
each robot. In this paper, we show that by harnessing the power of
\textit{randomness}, one can achieve dispersion with $O(\log \Delta)$ bits of
memory at each robot, where $\Delta$ is the maximum degree of the graph.
Furthermore, we show a matching lower bound of $\Omega(\log \Delta)$ bits for
any \textit{randomized algorithm} to solve dispersion.
</p>
<p>We further extend the problem to a general $k$-dispersion problem where $k&gt;
n$ robots need to disperse over $n$ nodes such that at most $\lceil k/n \rceil$
robots are at each node in the final configuration.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10489"><span class="datestr">at February 28, 2019 02:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10419">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10419">Reconciliation k-median: Clustering with Non-Polarized Representatives</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ordozgoiti:Bruno.html">Bruno Ordozgoiti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gionis:Aristides.html">Aristides Gionis</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10419">PDF</a><br /><b>Abstract: </b>We propose a new variant of the k-median problem, where the objective
function models not only the cost of assigning data points to cluster
representatives, but also a penalty term for disagreement among the
representatives. We motivate this novel problem by applications where we are
interested in clustering data while avoiding selecting representatives that are
too far from each other. For example, we may want to summarize a set of news
sources, but avoid selecting ideologically-extreme articles in order to reduce
polarization.
</p>
<p>To solve the proposed k-median formulation we adopt the local-search
algorithm of Arya et al. We show that the algorithm provides a provable
approximation guarantee, which becomes constant under a mild assumption on the
minimum number of points for each cluster. We experimentally evaluate our
problem formulation and proposed algorithm on datasets inspired by the
motivating applications. In particular, we experiment with data extracted from
Twitter, the US Congress voting records, and popular news sources. The results
show that our objective can lead to choosing less polarized groups of
representatives without significant loss in representation fidelity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10419"><span class="datestr">at February 28, 2019 02:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10328">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10328">Weighted Maximum Independent Set of Geometric Objects in Turnstile Streams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bakshi:Ainesh.html">Ainesh Bakshi</a>, Nadiia Chepurko, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10328">PDF</a><br /><b>Abstract: </b>We study the Maximum Independent Set problem for geometric objects given in
the data stream model. A set of geometric objects is said to be independent if
the objects are pairwise disjoint. We consider geometric objects in one and two
dimensions, i.e., intervals and disks. Let $\alpha$ be the cardinality of the
largest independent set. Our goal is to estimate $\alpha$ in a small amount of
space, given that the input is received as a one-pass turnstile stream. We also
consider a generalization of this problem by assigning weights to each object
and estimating $\beta$, the largest value of a weighted independent set. We
provide the first algorithms for estimating $\alpha$ and $\beta$ in turnstile
streams.
</p>
<p>For unit-length intervals, we obtain a $(2+\epsilon)$-approximation to
$\alpha$ and $\beta$ in poly$\left(\frac{\log(n)}{\epsilon}\right)$ space. We
also show a matching lower bound. For arbitrary-length intervals, we show any
$c$-approximation to $\alpha$, and thus also $\beta$, requires
$\Omega\left(\frac{n^{1/c}}{2^c}\right)$ space. To this end, we introduce a new
communication problem and lower bound its information complexity. In light of
the lower bound we provide algorithms for estimating $\alpha$ for
arbitrary-length intervals under a bounded intersection assumption. We also
study the parameterized space complexity of estimating $\alpha$ and $\beta$,
where the parameter is the ratio of maximum to minimum interval length. For
unit-radius disks, we obtain a
$\left(\frac{8\sqrt{3}}{\pi}\right)$-approximation to $\alpha$ and $\beta$ in
$\textrm{poly}\left(\frac{\log(n)}{\epsilon}\right)$ space, which is closely
related to the hexagonal circle packing constant.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10328"><span class="datestr">at February 28, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10271">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10271">On the extension complexity of scheduling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tiwary:Hans_Raj.html">Hans Raj Tiwary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Verdugo:Victor.html">Victor Verdugo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wiese:Andreas.html">Andreas Wiese</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10271">PDF</a><br /><b>Abstract: </b>Linear programming is a powerful method in combinatorial optimization with
many applications in theory and practice. For solving a linear program quickly
it is desirable to have a formulation of small size for the given problem. A
useful approach for this is the construction of an extended formulation, which
is a linear program in a higher dimensional space whose projection yields the
original linear program. For many problems it is known that a small extended
formulation cannot exist. However, most of these problems are either
$\mathsf{NP}$-hard (like TSP), or only quite complicated polynomial time
algorithms are known for them (like for the matching problem). In this work we
study the minimum makespan problem on identical machines in which we want to
assign a set of $n$ given jobs to $m$ machines in order to minimize the maximum
load over the machines. We prove that the canonical formulation for this
problem has extension complexity $2^{\Omega(n/\log n)}$, even if each job has
size 1 or 2 and the optimal makespan is 2. This is a case that a trivial greedy
algorithm can solve optimally! For the more powerful configuration integer
program, we even prove a lower bound of $2^{\Omega(n)}$. On the other hand, we
show that there is an abstraction of the configuration integer program
admitting an extended formulation of size $f(\text{opt})\cdot
\text{poly}(n,m)$. In addition, we give an $O(\log n)$-approximate integral
formulation of polynomial size, even for arbitrary processing times and for the
far more general setting of unrelated machines.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10271"><span class="datestr">at February 28, 2019 02:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10188">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10188">Decidability of the Mortality Problem: from multiplicative matrix equations to linear recurrence sequences and beyond</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bell:Paul_C=.html">Paul C. Bell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Potapov:Igor.html">Igor Potapov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Semukhin:Pavel.html">Pavel Semukhin</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10188">PDF</a><br /><b>Abstract: </b>We consider the following variant of the Mortality Problem: given $k\times k$
matrices $A_1, A_2, \dots,A_{t}$, does there exist nonnegative integers $m_1,
m_2, \dots,m_t$ such that the product $A_1^{m_1} A_2^{m_2} \cdots
A_{t}^{m_{t}}$ is equal to the zero matrix? It is known that this problem is
decidable when $t \leq 2$ for matrices over algebraic numbers but becomes
undecidable for sufficiently large $t$ and $k$ even for integral matrices.
</p>
<p>In this paper, we prove the first decidability results for $t&gt;2$. We show as
one of our central results that for $t=3$ this problem in any dimension is
Turing equivalent to the well-known Skolem problem for linear recurrence
sequences. This implies that it is decidable for $t=3$ and $k \leq 3$ for
matrices over algebraic numbers and for $t=3$ and $k=4$ for matrices over real
algebraic numbers. Another corollary is that the set of triples $(m_1,m_2,m_3)$
for which the equation $A_1^{m_1} A_2^{m_2} A_3^{m_3}$ equals the zero matrix
is equal to a finite union of direct products of semilinear sets.
</p>
<p>For $t=4$ we show that the solution set can be non-semilinear, and thus it
seems unlikely that there is a direct connection to the Skolem problem. However
we prove that the problem is still decidable for upper-triangular $2 \times 2$
rational matrices by employing powerful tools from transcendence theory such as
Baker's theorem and S-unit equations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10188"><span class="datestr">at February 28, 2019 02:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10176">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10176">A Memoization Framework for Scaling Submodular Optimization to Large Scale Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Rishabh Iyer, Jeff Bilmes <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10176">PDF</a><br /><b>Abstract: </b>We are motivated by large scale submodular optimization problems, where
standard algorithms that treat the submodular functions in the \emph{value
oracle model} do not scale. In this paper, we present a model called the
\emph{precomputational complexity model}, along with a unifying memoization
based framework, which looks at the specific form of the given submodular
function. A key ingredient in this framework is the notion of a
\emph{precomputed statistic}, which is maintained in the course of the
algorithms. We show that we can easily integrate this idea into a large class
of submodular optimization problems including constrained and unconstrained
submodular maximization, minimization, difference of submodular optimization,
optimization with submodular constraints and several other related optimization
problems. Moreover, memoization can be integrated in both discrete and
continuous relaxation flavors of algorithms for these problems. We demonstrate
this idea for several commonly occurring submodular functions, and show how the
precomputational model provides significant speedups compared to the value
oracle model. Finally, we empirically demonstrate this for large scale machine
learning problems of data subset selection and summarization.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10176"><span class="datestr">at February 28, 2019 02:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10140">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10140">Planning in Hierarchical Reinforcement Learning: Guarantees for Using Local Policies</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zahavy:Tom.html">Tom Zahavy</a>, Avinatan Hasidim, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kaplan:Haim.html">Haim Kaplan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mansour:Yishay.html">Yishay Mansour</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10140">PDF</a><br /><b>Abstract: </b>We consider a settings of hierarchical reinforcement learning, in which the
reward is a sum of components. For each component we are given a policy that
maximizes it and our goal is to assemble a policy from the individual policies
that maximizes the sum of the components. We provide theoretical guarantees for
assembling such policies in deterministic MDPs with collectible rewards. Our
approach builds on formulating this problem as a traveling salesman problem
with discounted reward. We focus on local solutions, i.e., policies that only
use information from the current state; thus, they are easy to implement and do
not require substantial computational resources. We propose three local
stochastic policies and prove that they guarantee better performance than any
deterministic local policy in the worst case; experimental results suggest that
they also perform better on average.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10140"><span class="datestr">at February 28, 2019 02:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10132">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10132">Quadratic Decomposable Submodular Function Minimization: Theory and Practice</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Pan.html">Pan Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Niao.html">Niao He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Milenkovic:Olgica.html">Olgica Milenkovic</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10132">PDF</a><br /><b>Abstract: </b>We introduce a new convex optimization problem, termed quadratic decomposable
submodular function minimization (QDSFM), which allows to model a number of
learning tasks on graphs and hypergraphs. The problem exhibits close ties to
decomposable submodular function minimization (DSFM), yet is much more
challenging to solve. We approach the problem via a new dual strategy and
formulate an objective that can be optimized through a number of double-loop
algorithms. The outer-loop uses either random coordinate descent (RCD) or
alternative projection (AP) methods, for both of which we prove linear
convergence rates. The inner-loop computes projections onto cones generated by
base polytopes of the submodular functions, via the modified min-norm-point or
Frank-Wolfe algorithm. We also describe two new applications of QDSFM:
hypergraph-adapted PageRank and semi-supervised learning. The proposed
hypergraph-based PageRank algorithm can be used for local hypergraph
partitioning, and comes with provable performance guarantees. For
hypergraph-adapted semi-supervised learning, we provide numerical experiments
demonstrating the efficiency of our QDSFM solvers and their significant
improvements on prediction accuracy when compared to state-of-the-art methods.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10132"><span class="datestr">at February 28, 2019 02:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/024">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/024">TR19-024 |  The Surprising Power of Constant Depth Algebraic Proofs | 

	Sasank Mouli, 

	Russell Impagliazzo, 

	Toniann Pitassi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A major open problem in proof complexity is to prove super-polynomial lower bounds for AC^0[p]-Frege proofs. This system is the analog of AC^0[p], the class of bounded depth circuits with prime modular counting gates. Despite strong lower bounds for this class dating back thirty years (Razborov, '86 and Smolensky, '87), there are no significant lower bounds for AC^0[p]-Frege. Significant and extensive *degree* lower bounds have been obtained for a variety of subsystems of AC^0[p]-Frege, including Nullstellensatz (Beame et. al. '94), Polynomial Calculus (Clegg et. al. '96), and SOS (Griegoriev and Vorobjov, '01). However to date there has been no progress on AC^0[p]-Frege lower bounds.
In this paper we study constant-depth extensions of the Polynomial Calculus introduced by Griegoriev and Hirsch, '03. We show that these extensions are much more powerful than was previously known. Our main result is that small depth Polynomial Calculus (over a sufficiently large field) can polynomially simulate all of the well-studied semialgebraic proof systems: Cutting Planes, Sherali-Adams and Sum-of-Squares, and they can also quasi-polynomially simulate AC^0[p]-Frege as well as TC^0-Frege. Thus, proving strong lower bounds for AC^0[p]-Frege would seem to require proving lower bounds for systems as strong as TC^0-Frege.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/024"><span class="datestr">at February 27, 2019 09:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4129">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4129">De-sneering my life</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>If I’m being honest, the most exciting recent development in my life is this: a little over a month ago,<strong> I stopped checking “SneerClub”</strong> (a place I’d previously resolved not even to name here, but I think an exception is warranted now).  Permanently, cold turkey.  I won’t even visit to read their sneers about this post.  I’ve made progress cutting down on other self-destructive social media fixations as well.  Many friends suggested this course to me, and I thank them all, though I ultimately had to follow my own path to the obvious.</p>



<p>Ironically, <em>the SneerClubbers themselves</em> begged me to stop reading them (!), so presumably for once they’ll be okay with something I did (but if not, I don’t care).  If any of them still have something to say to me, they can come to <em>this</em> blog, or email me, or if they pass through Austin, set up a time to hash it out over chips and queso (my treat).  What I’ll no longer do is spend hours every week binge-reading a forum of people who’ve adopted nastiness and bad faith as their explicit principles.  I’ll no longer toss and turn at night wondering how it came about that two thousand Redditors hate Scott Aaronson so much, and what I could say or do (short of total self-abnegation) that would make them hate me less.  I plan to spend the freed-up time <em>being</em> Scott Aaronson.</p>



<p>Resolving to ignore one particular online hate pit—and then <em>sticking</em> to the resolution, as so far I have—has been a pure, unmitigated improvement to my quality of life.  If you don’t believe me, ask my wife and kids.  I recommend this course to anyone.</p>



<p>You could sensibly ask: why did I <em>ever</em> spend time worrying about an anti-nerds-like-me forum that’s so poisonous for its targets and participants alike?  After long introspection, I think the answer is: there’s a part of me, perhaps a gift from the childhood bullies, that’s so obsessed with “society’s hatred of STEM nerds,” that it <em>constantly seeks out evidence to confirm that its fears are justified—</em>evidence that it can then wave in front of the rest of my brain to say “you see??  what did I always tell you?”  And alas, whenever that part of my brain seeks such evidence, the world dutifully supplies mountains of it.  It’s never once disappointed.</p>



<p>Now the SneerClubbers—who are perceptive and talented in their cruelty, if in nothing else—notice this about me, and gleefully ridicule me for it.  But they’re oblivious to the central irony: that unlike the vast majority of humankind, or even the vast majority of social justice activists, they (the SneerClubbers) <em>really do</em> hate everyone like me.  They’re <em>precisely</em> what the paranoid part of my brain wrongly fears that everyone else I meet is secretly like.  They’re like someone who lectures you about your hilariously overblown fear of muggers, <em>while simultaneously mugging you</em>.</p>



<p>But at least they’re not the contented and self-confident bullies of my childhood nightmares, kicking dirt down at nerds from atop their pinnacle of wokeness and social adeptness.  If you spend enough time studying them, they themselves come across as angry, depressed, pathetic.  So for example: <a href="https://www.reddit.com/r/math/comments/aexi9v/michael_atiyah_has_passed_away/edtrcc5/">here’s</a> one of my most persistent attackers, popping up on a math thread commemorating Michael Atiyah (one of the great mathematicians of the 20th century), just to insult Atiyah—randomly, gratuitously, and a few days after Atiyah had died.  Almost everything posted all over Reddit by this individual—who uses the accurate tagline “unpleasantly radical”—has the same flavor.  Somehow seeing this made it click for me: wait a second, <em>these</em> are the folks are lecturing <em>me</em> about my self-centeredness and arrogance and terrible social skills?  Like, at least I <em><a href="https://www.quora.com/Why-is-Scott-Aaronson-so-nice">try</a></em> to be nice.</p>


<hr />
<p>Scott Alexander, who writes the <a href="https://slatestarcodex.com/">world’s best blog</a> and is a more central target of SneerClub than I’ve been, <a href="https://slatestarcodex.com/2019/02/22/rip-culture-war-thread/">recently announced</a> that he asked the moderators of <a href="https://www.reddit.com/r/slatestarcodex/">r/ssc</a> to close its notorious “Culture War” thread, and they’ve done so—moving the thread to a new home on Reddit called <a href="https://www.reddit.com/r/TheMotte/">“TheMotte.”</a></p>
<p>For those who don’t know: r/ssc is the place on Reddit to discuss Scott’s SlateStarCodex blog, though Scott himself was never too involved as more than a figurehead.  The Culture War thread was the place within r/ssc to discuss race, gender, immigration, and other hot-button topics.  The thread, which filled up with a bewildering thousands of comments per week (!), attracted the, err … <em>full range</em> of political views, including leftists, libertarians, and moderates but also alt-righters, neoreactionaries, and white nationalists. Predictably, SneerClub treated the thread as a gift from heaven: a constant source of inflammatory material that they could use to smear Scott personally (even if most of the time, Scott hadn’t even <em>seen</em> the offending content, let alone endorsing it).</p>


<p>Four months ago, I was one of the apparently many friends who told Scott that I felt he should dissociate the Culture War thread from his brand.  So I congratulate him on his decision, which (despite his eloquently-expressed misgivings) I feel confident was the right one.  Think about it this way: nobody’s freedom of speech has been curtailed—the thread continues full steam at TheMotte, for anyone who enjoys it—but meanwhile, the sneerers have been deprived of a golden weapon with which to slime Scott.  Meanwhile, while the sneerers themselves might never change their minds about anything, Scott has demonstrated to third parties that he’s open and reasonable and ready to compromise, like the debater who happily switches to his opponent’s terminology.  What’s not to like?</p>


<hr />
<p>A couple weeks ago, while in Albuquerque for the <a href="http://physics.unm.edu/SQuInT/2019/index.php">SQuInT</a> conference, I visited the excellent <a href="https://www.nuclearmuseum.org/">National Museum of Nuclear Science and History</a>.  It was depressing, as it should have been, to tour the detailed exhibits about the murderous events surrounding the birth of the nuclear era: the Holocaust, the Rape of Nanking, the bombings of Hiroshima and Nagasaki. It was depressing in a different way to tour the exhibits about the early Atomic Age, and see the boundless optimism that ‘unleashing the power of the atom’ would finally usher in a near-utopia of space travel and clean energy—and then to compare that vision to where we are now, with climate change ravaging the planet and (in a world-historic irony) the people who care most about the environment having denounced and marginalized the most reliable source of carbon-free energy, the one that probably had the best chance to avert our planet’s terrifying future.</p>


<p>But on the bright side: how wonderful to have born into a time and place when, for the most part, those who hate you have only the power to destroy your life that you yourself grant them.  How wonderful when one can blunt their knives by simply refusing to open a browser tab.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4129"><span class="datestr">at February 27, 2019 09:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2019/02/27/caleidoscope-complexity-as-a-kaleidoscope/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2019/02/27/caleidoscope-complexity-as-a-kaleidoscope/">Caleidoscope : Complexity as a Kaleidoscope</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
June 17-21, 2019 Paris, France https://caleidoscope.sciencesconf.org/ Research school in computational complexity. 17-21 June 2019, Institut Henri Poincaré, Paris. LECTURES The Caleidoscope school will be comprise of four main lecture courses, based on some of the most developed approaches to computational complexity today. 1. Boolean circuits and lower bounds. (Rahul Santhanam, University of Oxford). 2. Algebraic … <a href="https://cstheory-events.org/2019/02/27/caleidoscope-complexity-as-a-kaleidoscope/" class="more-link">Continue reading <span class="screen-reader-text">Caleidoscope : Complexity as a Kaleidoscope</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2019/02/27/caleidoscope-complexity-as-a-kaleidoscope/"><span class="datestr">at February 27, 2019 08:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-248160526006611455">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2019/02/call-for-prize-nominations-prize-for.html">Call for Prize Nominations: Prize for Innovation in Distributed Computing 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<i>Michele Flammini asked me to distrbute this call for nominations. Sharpen your pencils and nominate one of the many worthy candidates from the SIROCCO community!</i><br /><br /><span>Call for Prize Nominations:</span><br /><span>Prize for Innovation in Distributed Computing 2020</span><br /><span>------------------------------</span><span>----</span><br /><br /><span>Awarded by the Colloquium on Structural Information and Communication Complexity (SIROCCO).</span><br /><br /><span>Deadline for nominations: April 30, 2019.</span><br /><br /><span>Nominations are requested for the Prize for Innovation In Distributed Computing. This prize was established to recognize individuals whose research contributions expanded the collective investigative horizon in SIROCCO's area of interest. That is, they formulated new problems, or identified new research areas, that were at the time of their introduction, unorthodox and outside the mainstream, but later attracted the interest of the SIROCCO community.</span><br /><br /><span>This community is interested in the relationships between information and efficiency in decentralized computing. The prize recognizes originality, innovation, and creativity -- the qualities that reflect the spirit of the SIROCCO conference.</span><br /><br /><span>The winner of the Prize for Innovation in Distributed Computing 2020 is expected to give an invited talk at SIROCCO 2020. The winner of the 2019 edition of the prize (Paola Flocchini) will give a talk at SIROCCO 2019 which is going to be held on July 1-4, in L’Aquila, Italy.</span><br /><br /><span>Past prize winners are Nicola Santoro, Jean-Claude Bermond, David Peleg, Roger Wattenhofer, Andrzej Pelc, Pierre Fraigniaud, Michel Raynal, Masafumi Yamashita, Shmuel Zaks,  Zvi Lotker and Paola Flocchini.</span><br /><br /><span>The prize may not necessarily be awarded every year.</span><br /><br /><br /><span>Eligibility</span><br /><span>-----------</span><br /><br /><span>The following conditions must be met by the nominees to be eligible for the prize. It is requested that a nomination letter explains and demonstrates how the nominee matches these conditions.</span><br /><br /><span>(1) The original innovative contribution was introduced by the nominee(s) for the first time in a publication at least five years before the nomination deadline, and the publication must have appeared in a conference proceedings or a scientific journal.</span><br /><br /><span>(2) At least one paper (co)authored by the nominee(s), either the original</span><br /><span>paper, or a paper closely related to the innovative contribution, must have</span><br /><span>appeared in a SIROCCO proceedings.</span><br /><br /><span>A nomination letter should identify the paper(s) that make(s) the nominee eligible according to conditions (1) and (2) above, as well as explain the contribution, its originality, and its significance.</span><br /><br /><span>Past SIROCCO papers and authors can be found at indexing sites, e.g. Google Scholar or </span><a href="http://www.informatik.uni-trier.de/~ley/db/conf/sirocco/index.html" target="_blank">http://www.informatik.uni-trier.de/~ley/db/conf/sirocco/index.html</a><span>.</span><br /><br /><span>Selection process</span><br /><span>------------------</span><br /><br /><span>The prize winners are selected by the Award Committee composed of the current Steering Committee (SC) Chair of the SIROCCO conference, the PC chairs, including co-chairs, of the three SIROCCO conferences immediately preceding the nominations deadline, plus one additional member of the Advisory Board, or one past winner, selected by the Steering Committee for the current year.</span><br /><br /><span>The Award Committee of the Prize for Innovation in Distributed Computing 2020 consists of: Shantanu Das (Aix-Marseille Université),</span><br /><span>Zvi Lotker (Ben Gurion University of the Negev), Boaz Patt-Shamir (Tel Aviv University), Andrzej Pelc - chair (Université du Québec en Outaouais), Michel Raynal (IRISA), Jukka Suomela (Aalto University) and Sébastien Tixeuil (Sorbonne Université).</span><br /><br /><span>Nominations can be made by any member of the scientific community.</span><br /><br /><span>DEADLINE : The deadline for nominations is April 30, 2019.</span><br /><span>Please send the nomination to the prize committee chair, Andrzej Pelc, by e-mail </span><a href="mailto:pelc@uqo.ca" target="_blank">pelc@uqo.ca</a></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2019/02/call-for-prize-nominations-prize-for.html"><span class="datestr">at February 27, 2019 09:43 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10051">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10051">Plane Hop Spanners for Unit Disk Graphs: Simpler and Better</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Biniaz:Ahmad.html">Ahmad Biniaz</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10051">PDF</a><br /><b>Abstract: </b>The unit disk graph (UDG) is a widely employed model for the study of
wireless networks. In this model, wireless nodes are represented by points in
the plane and there is an edge between two points if and only if their
Euclidean distance is at most one. A hop spanner for the UDG is a spanning
subgraph $H$ such that for every edge $(p,q)$ in the UDG the topological
shortest path between $p$ and $q$ in $H$ has a constant number of edges. The
hop stretch factor of $H$ is the maximum number of edges of these paths. A hop
spanner is plane (i.e. embedded planar) if its edges do not cross each other.
</p>
<p>The problem of constructing hop spanners for the UDG has received
considerable attention in both computational geometry and wireless ad hoc
networks. Despite this attention, there has not been significant progress on
getting hop spanners that (i) are plane, and (ii) have low hop stretch factor.
Previous constructions either do not ensure the planarity or have high hop
stretch factor. The only construction that satisfies both conditions is due to
Catusse, Chepoi, and Vax\`{e}s (2010); their plane hop spanner has hop stretch
factor at most 449.
</p>
<p>Our main result is a simple algorithm that constructs a plane hop spanner for
the UDG. In addition to the simplicity, the hop stretch factor of the
constructed spanner is at most 341. Even though the algorithm itself is simple,
its analysis is rather involved. Several results on the plane geometry are
established in the course of the proof. These results are of independent
interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10051"><span class="datestr">at February 27, 2019 11:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.10046">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.10046">Arithmetic Progressions of Length Three in Multiplicative Subgroups of $\mathbb{F}_p$</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Jeremy F Alm <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.10046">PDF</a><br /><b>Abstract: </b>In this paper, we give an algorithm for detecting non-trivial 3-APs in
multiplicative subgroups of $\mathbb{F}_p^\times$ that is substantially more
efficient than the naive approach. It follows that certain Var der Waerden-like
numbers can be computed in polynomial time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.10046"><span class="datestr">at February 27, 2019 11:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09959">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09959">Shapes from Echoes: Uniqueness from Point-to-Plane Distance Matrices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Krekovic:Miranda.html">Miranda Krekovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dokmanic:Ivan.html">Ivan Dokmanic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vetterli:Martin.html">Martin Vetterli</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09959">PDF</a><br /><b>Abstract: </b>We study the problem of localizing a configuration of points and planes from
the collection of point-to-plane distances. This problem models simultaneous
localization and mapping from acoustic echoes as well as the notable "structure
from sound" approach to microphone localization with unknown sources. In our
earlier work we proposed computational methods for localization from
point-to-plane distances and noted that such localization suffers from various
ambiguities beyond the usual rigid body motions; in this paper we provide a
complete characterization of uniqueness. We enumerate equivalence classes of
configurations which lead to the same distance measurements as a function of
the number of planes and points, and algebraically characterize the related
transformations in both 2D and 3D. Here we only discuss uniqueness;
computational tools and heuristics for practical localization from
point-to-plane distances using sound will be addressed in a companion paper.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09959"><span class="datestr">at February 27, 2019 11:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09958">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09958">An Automatic Speedup Theorem for Distributed Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brandt:Sebastian.html">Sebastian Brandt</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09958">PDF</a><br /><b>Abstract: </b>Recently, Brandt et al. [STOC'16] proved a lower bound for the distributed
Lov\'asz Local Lemma, which has been conjectured to be tight for sufficiently
relaxed LLL criteria by Chang and Pettie [FOCS'17]. At the heart of their
result lies a speedup technique that, for graphs of girth at least $2t+2$,
transforms any $t$-round algorithm for one specific LLL problem into a
$(t-1)$-round algorithm for the same problem. We substantially improve on this
technique by showing that such a speedup exists for any locally checkable
problem $\Pi$, with the difference that the problem $\Pi_1$ the inferred
$(t-1)$-round algorithm solves is not (necessarily) the same problem as $\Pi$.
Our speedup is automatic in the sense that there is a fixed procedure that
transforms a description for $\Pi$ into a description for $\Pi_1$ and
reversible in the sense that any $(t-1)$-round algorithm for $\Pi_1$ can be
transformed into a $t$-round algorithm for $\Pi$. In particular, for any
locally checkable problem $\Pi$ with exact deterministic time complexity $T(n,
\Delta) \leq t$ on graphs with $n$ nodes, maximum node degree $\Delta$, and
girth at least $2t+2$, there is a sequence of problems $\Pi_1, \Pi_2, \dots$
with time complexities $T(n, \Delta)-1, T(n, \Delta)-2, \dots$, that can be
inferred from $\Pi$.
</p>
<p>As a first application of our generalized speedup, we solve a long-standing
open problem of Naor and Stockmeyer [STOC'93]: we show that weak $2$-coloring
in odd-degree graphs cannot be solved in $o(\log^* \Delta)$ rounds, thereby
providing a matching lower bound to their upper bound.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09958"><span class="datestr">at February 27, 2019 11:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09953">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09953">Cellular morphogenesis of three-dimensional tensegrity structures</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aloui:Omar.html">Omar Aloui</a>, Jessica Flores, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Orden:David.html">David Orden</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rhode=Barbarigos:Landolf.html">Landolf Rhode-Barbarigos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09953">PDF</a><br /><b>Abstract: </b>The topology and form finding of tensegrity structures have been studied
extensively since the introduction of the tensegrity concept. However, most of
these studies address topology and form separately, where the former
represented a research focus of rigidity theory and graph theory, while the
latter attracted the attention of structural engineers. In this paper, a
biomimetic approach for the combined topology and form finding of spatial
tensegrity systems is introduced. Tensegrity cells, elementary infinitesimally
rigid self-stressed structures that have been proven to compose any tensegrity,
are used to generate more complex tensegrity structures through the
morphogenesis mechanisms of adhesion and fusion. A methodology for constructing
a basis to describe the self-stress space is also provided. Through the
definition of self-stress, the cellular morphogenesis method can integrate
design considerations, such as a desired shape or number of nodes and members,
providing great flexibility and control over the tensegrity structure
generated.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09953"><span class="datestr">at February 27, 2019 11:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09841">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09841">A new lower bound on the maximum number of plane graphs using production matrices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huemer:Clemens.html">Clemens Huemer</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilz:Alexander.html">Alexander Pilz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silveira:Rodrigo_I=.html">Rodrigo I. Silveira</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09841">PDF</a><br /><b>Abstract: </b>We use the concept of production matrices to show that there exist sets of
$n$ points in the plane that admit $\Omega(42.11^n)$ crossing-free geometric
graphs. This improves the previously best known bound of $\Omega(41.18^n)$ by
Aichholzer et al. (2007).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09841"><span class="datestr">at February 27, 2019 11:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09733">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09733">Towards Real-time 3D Reconstruction using Consumer UAVs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Qiaosong.html">Qiaosong Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09733">PDF</a><br /><b>Abstract: </b>We present a near real-time solution for 3D reconstruction from aerial images
captured by consumer UAVs. Our core idea is to simplify the multi-view stereo
problem into a series of two-view stereo matching problems. Our method applies
to UAVs equipped with only one camera and does not require special stereo
capturing setups. We found that the neighboring two video frames taken by UAVs
flying at a mid-to-high cruising altitude can be approximated as left and right
views from a virtual stereo camera. Leveraging GPU-accelerated real-time stereo
estimation and efficient PnP correspondence solving algorithms, our system
simultaneously predicts scene geometry and camera position/orientation from the
virtual stereo cameras. Also, this method allows user-selection of varying
baseline lengths, which provides more flexibility given the trade-off between
camera resolution, effective measuring distance, flight altitude and mapping
accuracy. Our method outputs dense point clouds at a constant speed of 25
frames per second and is validated on a variety of real-world datasets with
satisfactory results.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09733"><span class="datestr">at February 27, 2019 11:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09702">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09702">A Unifying Framework for Spectrum-Preserving Graph Sparsification and Coarsening</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Gecia Bravo Hermsdorff, Lee M. Gunderson <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09702">PDF</a><br /><b>Abstract: </b>How might one "reduce" a graph? That is, generate a smaller graph that
preserves the global structure at the expense of discarding local details?
There has been extensive work on both graph sparsification (removing edges) and
graph coarsening (merging nodes, often by edge contraction); however, these
operations are currently treated separately. Interestingly, for a planar graph,
edge deletion corresponds to edge contraction in its planar dual (and more
generally, for a graphical matroid and its dual). Moreover, with respect to the
dynamics induced by the graph Laplacian (e.g., diffusion), deletion and
contraction are physical manifestations of two reciprocal limits: edge weights
of $0$ and $\infty$, respectively. In this work, we provide a unifying
framework that captures both of these operations, allowing one to
simultaneously coarsen and sparsify a graph, while preserving its large-scale
structure. Using synthetic models and real-world datasets, we validate our
algorithm and compare it with existing methods for graph coarsening and
sparsification. While modern spectral schemes focus on the Laplacian (indeed,
an important operator), our framework preserves its inverse, allowing one to
quantitatively compare the effect of edge deletion with the (now finite) effect
of edge contraction.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09702"><span class="datestr">at February 27, 2019 11:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09597">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09597">On reachability problems for low dimensional matrix semigroups</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Colcombet:Thomas.html">Thomas Colcombet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouaknine:Jo=euml=l.html">Joël Ouaknine</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Semukhin:Pavel.html">Pavel Semukhin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Worrell:James.html">James Worrell</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09597">PDF</a><br /><b>Abstract: </b>We consider the Membership and the Half-space Reachability Problems for
matrices in dimensions two and three. Our first main result is that the
Membership Problem is decidable for fintely generated sub-semigroups of the
Heisenberg group over integer numbers. Furthermore, we prove two decidability
results for the Half-space reachability problem. Namely, we show that this
problem is decidable for sub-semigroups of $\mathrm{GL}(2,\mathbb{Z})$ and of
the Heisenberg group over rational numbers.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09597"><span class="datestr">at February 27, 2019 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09565">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09565">Dynamic Maintenance of the Lower Envelope of Pseudo-Lines</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Agarwal:Pankaj_K=.html">Pankaj K. Agarwal</a>, Ravid Cohen, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Halperin:Dan.html">Dan Halperin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mulzer:Wolfgang.html">Wolfgang Mulzer</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09565">PDF</a><br /><b>Abstract: </b>We present a fully dynamic data structure for the maintenance of lower
envelopes of pseudo-lines. The structure has $O(\log^2 n)$ update time and
$O(\log n)$ vertical ray shooting query time. To achieve this performance, we
devise a new algorithm for finding the intersection between two lower envelopes
of pseudo-lines in $O(\log n)$ time, using \emph{tentative} binary search; the
lower envelopes are special in that at $x=-\infty$ any pseudo-line contributing
to the first envelope lies below every pseudo-line contributing to the second
envelope. The structure requires $O(n)$ storage space.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09565"><span class="datestr">at February 27, 2019 11:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.09523">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.09523">Characterizing PSPACE with shallow non-confluent P systems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leporati:Alberto.html">Alberto Leporati</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manzoni:Luca.html">Luca Manzoni</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mauri:Giancarlo.html">Giancarlo Mauri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Porreca:Antonio_E=.html">Antonio E. Porreca</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zandron:Claudio.html">Claudio Zandron</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.09523">PDF</a><br /><b>Abstract: </b>In P systems with active membranes, the question of understanding the power
of non-confluence within a polynomial time bound is still an open problem. It
is known that, for shallow P systems, that is, with only one level of nesting,
non-confluence allows them to solve conjecturally harder problems than
confluent P systems, thus reaching PSPACE. Here we show that PSPACE is not only
a bound, but actually an exact characterization. Therefore, the power endowed
by non-confluence to shallow P systems is equal to the power gained by
confluent P systems when non-elementary membrane division and polynomial depth
are allowed, thus suggesting a connection between the roles of non-confluence
and nesting depth.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.09523"><span class="datestr">at February 27, 2019 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1902.07785">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1902.07785">Counting basic-irreducible factors mod $p^k$ in deterministic poly-time and $p$-adic applications</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwivedi:Ashish.html">Ashish Dwivedi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mittal:Rajat.html">Rajat Mittal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saxena:Nitin.html">Nitin Saxena</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1902.07785">PDF</a><br /><b>Abstract: </b>Finding an irreducible factor, of a polynomial $f(x)$ modulo a prime $p$, is
not known to be in deterministic polynomial time. Though there is such a
classical algorithm that {\em counts} the number of irreducible factors of
$f\bmod p$. We can ask the same question modulo prime-powers $p^k$. The
irreducible factors of $f\bmod p^k$ blow up exponentially in number; making it
hard to describe them. Can we count those irreducible factors $\bmod~p^k$ that
remain irreducible mod $p$? These are called {\em basic-irreducible}. A simple
example is in $f=x^2+px \bmod p^2$; it has $p$ many basic-irreducible factors.
Also note that, $x^2+p \bmod p^2$ is irreducible but not basic-irreducible!
</p>
<p>We give an algorithm to count the number of basic-irreducible factors of
$f\bmod p^k$ in deterministic poly(deg$(f),k\log p$)-time. This solves the open
questions posed in (Cheng et al, ANTS'18 \&amp; Kopp et al, Math.Comp.'19). In
particular, we are counting roots $\bmod\ p^k$; which gives the first
deterministic poly-time algorithm to compute Igusa zeta function of $f$. Also,
our algorithm efficiently partitions the set of all basic-irreducible factors
(possibly exponential) into merely deg$(f)$-many disjoint sets, using a compact
tree data structure and {\em split} ideals.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1902.07785"><span class="datestr">at February 27, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/1901.06628">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/1901.06628">Efficiently factoring polynomials modulo $p^4$</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwivedi:Ashish.html">Ashish Dwivedi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mittal:Rajat.html">Rajat Mittal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Saxena:Nitin.html">Nitin Saxena</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/1901.06628">PDF</a><br /><b>Abstract: </b>Polynomial factoring has famous practical algorithms over fields-- finite,
rational \&amp; $p$-adic. However, modulo prime powers it gets hard as there is
non-unique factorization and a combinatorial blowup ensues. For example, $x^2+p
\bmod p^2$ is irreducible, but $x^2+px \bmod p^2$ has exponentially many
factors! We present the first randomized poly(deg $f, \log p$) time algorithm
to factor a given univariate integral $f(x)$ modulo $p^k$, for a prime $p$ and
$k \leq 4$. Thus, we solve the open question of factoring modulo $p^3$ posed in
(Sircana, ISSAC'17).
</p>
<p>Our method reduces the general problem of factoring $f(x) \bmod p^k$ to that
of {\em root finding} in a related polynomial $E(y) \bmod\langle p^k,
\varphi(x)^\ell \rangle$ for some irreducible $\varphi \bmod p$. We could
efficiently solve the latter for $k\le4$, by incrementally transforming $E(y)$.
Moreover, we discover an efficient and strong generalization of Hensel lifting
to lift factors of $f(x) \bmod p$ to those $\bmod\ p^4$ (if possible). This was
previously unknown, as the case of repeated factors of $f(x) \bmod p$ forbids
classical Hensel lifting.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/1901.06628"><span class="datestr">at February 27, 2019 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-25562705.post-2251645165874378750">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/roth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://aaronsadventures.blogspot.com/2019/02/impossibility-results-in-fairness-as.html">Impossibility Results in Fairness as Bayesian Inference</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
One of the most striking results about fairness in machine learning is the impossibility result that <a href="https://www.liebertpub.com/doi/full/10.1089/big.2016.0047">Alexandra Chouldechova</a>, and separately<a href="https://arxiv.org/abs/1609.05807"> Jon Kleinberg, Sendhil Mullainathan, and Manish Raghavan</a> discovered a few years ago. These papers say something very crisp. I'll focus here on the binary classification setting that Alex studies because it is much simpler. There are (at least) three reasonable properties you would want your "fair" classifiers to have. They are:<br /><div><ol><li><b>False Positive Rate Balance</b>: The rate at which your classifier makes errors in the positive direction (i.e. labels negative examples positive) should be the same across groups.</li><li><b>False Negative Rate Balance</b>:  The rate at which your classifier makes errors in the negative direction (i.e. labels positive examples negative) should be the same across groups.</li><li><b>Predictive Parity</b>: The statistical "meaning" of a positive classification should be the same across groups (we'll be more specific about what this means in a moment)</li></ol><div>What Chouldechova and KMR show is that if you want all three, you are out of luck --- unless you are in one of two very unlikely situations: Either you have a <i>perfect</i> classifier that never errs, or the <i>base rate</i> is exactly the same for both populations --- i.e. both populations have exactly the same frequency of positive examples. If you don't find yourself in one of these two unusual situations, then you have to give up on properties 1, 2, or 3. </div></div><div><br /></div><div>This is discouraging, because there are good reasons to want each of properties 1, 2, and 3. And these aren't measures made up in order to formulate an impossibility result --- they have their root in the <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">Propublica/COMPASS controversy</a>. Roughly speaking, Propublica discovered that the COMPASS recidivism prediction algorithm violated false positive and negative rate balance, and they took the position that this made the classifier <i>unfair</i>. Northpointe (the creators of the COMPASS algorithm) responded by saying that their algorithm satisfied predictive parity, and took the position that this made the classifier fair. They were seemingly talking past each other by using two different definitions of what "fair" should mean. What the impossibility result says is that there is no way to satisfy both sides of this debate. </div><div><br /></div><div>So why is this result true? The proof in Alex's paper can't be made simpler --- its already a one liner, following from an algebraic identity. But the first time I read it I didn't have a great intuition for <i>why</i> it held. Viewing the statement through the lens of Bayesian inference made the result very intuitive (at least for me). With this viewpoint, all the impossibility result is saying is: "If you have different <i>priors</i> about some event (say that a released inmate will go on to commit a crime) for two different populations, and you receive evidence of the same strength for both populations, then you will have different posteriors as well". This is now bordering on obvious --- because your posterior belief about an event is a combination of your prior belief and the new evidence you have received, weighted by the strength of that evidence.  </div><div><br /></div><div>Lets walk through this. Suppose we have two populations, call them $A$s and $B$s. Individuals $x$ from these populations have some true binary label $\ell(x) \in \{0,1\}$ which we are trying to predict. Individuals from the two populations are drawn from different distributions, which we'll call $D_A$ and $D_B$. We have some classifier that predicts labels $\hat\ell(x)$, and we would like it to satisfy the three fairness criteria defined above. First, lets define some terms:<br /><br />The <i>base rate</i> for a population $i$ is just the frequency of positive labels:<br />$$p_i = \Pr_{x \sim D_i}[\ell(x) = 1].$$<br />The <i>false positive </i>and <i>false negative </i>rates of the classifier are:<br />$$FPR_i = \Pr_{x \sim D_i}[\hat\ell(x) = 1 | \ell(x) = 0] \ \ \ \ FNR_i = \Pr_{x \sim D_i}[\hat\ell(x) = 0 | \ell(x) = 1].$$<br />And the <i>positive predictive value</i> of the classifier is:<br />$$PPV_i = \Pr_{x \sim D_i}[\ell(x) = 1 | \hat\ell(x)=1].$$</div><div>Satisfying all three fairness constraints just means finding a classifier such that $FPR_A = FPR_B$, $FNR_A = FNR_B$, and $PPV_A = PPV_B$.<br /><br />How should we prove that this is impossible? All three of these quantities are conditional probabilities, so we are essentially obligated to apply Bayes Rule:<br />$$PPV_i =  \Pr_{x \sim D_i}[\ell(x) = 1 | \hat\ell(x)=1] = \frac{ \Pr_{x \sim D_i}[\hat\ell(x)=1 | \ell(x) = 1]\cdot \Pr_{x \sim D_i} [\ell(x) = 1]}{ \Pr_{x \sim D_i}[\hat \ell(x) = 1]}$$<br />But now these quantities on the right hand side are things we have names for. Substituting in, we get:<br />$$PPV_i  = \frac{p_i(1-FNR_i)}{p_i(1-FNR_i) + (1-p_i)FPR_i}$$<br /><br />And so now we see the problem. Suppose we have $FNR_A = FNR_B$ and $FPR_A = FPR_B$. Can we have $PPV_A = PPV_B$? There are only two ways. If $p_A = p_B$, then we are done, because the right hand side is the same for either $i \in \{A,B\}$. But if the base rates are different, then the only way to make these two quantities equal is if $FNR_i = FPR_i = 0$ --- i.e. if our classifier is perfect.<br /><br />The piece of intuition here is that the base rate is our prior belief that $\ell(x) = 1$, before we see the output of the classifier. The positive predictive value is our <i>posterior</i> belief that $\ell(x) = 1$, after we see the output of the classifier. And all we need to know about the classifier in order to apply Bayes rule to derive our posterior from our prior is its false positive rate and its false negative rate --- these fully characterize the "strength of the evidence." Hence: "If our prior probabilities differ, and we see evidence of a positive label of the same strength, then our posterior probabilities will differ as well."<br /><br />Once you realize this, then you can generalize the fairness impossibility result to other settings by making equally obvious statements about probability elsewhere. :-)<br /><br />For example, suppose we generalize the labels to be real valued instead of binary --- so when making decisions, we can model individuals using shades of gray. (e.g. in college admissions, we don't have to model individuals as "qualified" or not, but rather can model talent as a real value.) Lets fix a model for concreteness, but the particulars are not important. (The model here is related to my paper with <a href="https://www.cis.upenn.edu/~kannan/">Sampath Kannan</a> and<a href="http://www.its.caltech.edu/~jziani/"> Juba Ziani </a>on <a href="https://arxiv.org/abs/1808.09004">the downstream effects of affirmative action</a>)<br /><br />Suppose that in population $i$, labels are distributed according to a Gaussian distribution with mean $\mu_i$: $\ell(x) \sim N(\mu_i, 1)$. For an individual from group $i$, we have a test that gives an unbiased estimator of their label, with some standard deviation $\sigma_i$: $\hat \ell(x) \sim N(\ell(x), \sigma_i)$.<br /><br />In a model like this, we have analogues of our fairness desiderata in the binary case:<br /><br /><ul><li><b>Analogue of Error Rate Balance</b><i style="font-weight: bold;">: </i>We would like our test to be equally informative about both populations: $\sigma_A = \sigma_B$. </li><li><b>Analogue of Predictive Parity</b>: Any test score $t$ should induce the same posterior expectation on true labels across populations: $$E_{D_A}[\ell(x) | \hat \ell(x) = t] = E_{D_B}[\ell(x) | \hat \ell(x) = t]$$ </li></ul><div>Can we satisfy both of these conditions at the same time? Because the normal distribution is <i>self conjugate</i> (that's why we chose it!) Bayes Rule simplifies to have a nice closed form, and we can compute our posteriors as follows:</div><div>$$E_{D_i}[\ell(x) | \hat \ell(x) = t] = \frac{\sigma_i^2}{\sigma_i^2 + 1}\cdot \mu_i + \frac{1}{\sigma_i^2 + 1}\cdot t$$</div><div>So there are only two ways we can achieve both properties:</div><div><ol><li>We can of course satisfy both conditions if the prior distributions are the same for both groups: $\mu_A = \mu_B$. Then we can set $\sigma_A = \sigma_B$ and observe that the right hand side of the above expression is identical for $i \in \{A, B\}$.</li><li>We can also satisfy both conditions if the prior means are different, but the signal is perfect: i.e. $\sigma_A = \sigma_B = 0$. (Then both posterior means are just $t$, independent of the prior means). </li></ol></div>But we can see from inspection these are the only two cases. If $\sigma_A = \sigma_B$, but the prior means are different, then the posterior means will be different for every $t$. This is really the same impossibility result as in the binary case: all it is saying is that if I have different priors about different groups, but the evidence I receive has the same strength, then my posteriors will also be different.<br /><br />So the mathematical fact is simple --- but its implications remain deep. It means we have to choose between equalizing a decision maker's posterior about the label of an individual, or providing an equally accurate signal about each individual, and that we cannot have both. Unfortunately, living without either one of these conditions can lead to real harm.<br /><br /></div><div><br /></div></div>







<p class="date">
by Aaron Roth (noreply@blogger.com) <a href="http://aaronsadventures.blogspot.com/2019/02/impossibility-results-in-fairness-as.html"><span class="datestr">at February 26, 2019 08:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4283341625722054774">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html">Problems with a Point: Exploring Math and Computer Science</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
As you can see from Lance's tweet<br />
<br />
<br />
               Problems with a Point: Exploring Math and Computer Science<br />
               by Gasarch and Kruskal<br />
<br />
(ADDED LATER- the World scientific website has more info than amazon and has a table of contents, so here it is: <a href="https://www.worldscientific.com/worldscibooks/10.1142/11261#t=toc">here</a>)<br />
<br />
is now available! The tweet says its $68.00 but that's hardcover- paperback is $38.00 (are covers that expensive) and if you like your books already broken in, there are some used copies for $89.00. Makes sense to me (no it doesn't!). Could be the topic of a blog post (probably already was).<br />
<br />
Okay, so whats in the book?  One of my favorite types of blog posts is when I make a point ABOUT math and then do some math to underscore that point.  I went through all of my blogs (all? No, I doubt I did that) and picked out blogs of that type. With Clyde's help we EXPANDED and POLISHED and GOT THE MATH RIGHT (in some cases I didn't have any math so we had to supply it).<br />
<br />
When I first got a copy (about a month ago) I just couldn't stop reading it. I really like it! This is a non-trivial remark -- often authors get tired of their book, or after a while and wonder things like ``why did I write 300 page on the muffin problem? What was I thinking?'' So the fact that I am very pleased with it is not obvious. Does it mean you will?<br />
<br />
If you ever thought `I wish bill would clean up his posts spelling and grammar AND expand on the math AND make it a more cohesive whole' then buy the book!<br />
<br />
I will in future posts describe more about writing the book, but this is probably my last post where I plug the book.<br />
<br />
bill g.</div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/02/problems-with-point-exploring-math-and.html"><span class="datestr">at February 26, 2019 05:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/023">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/023">TR19-023 |  Smooth and Strong PCPs | 

	Orr Paradise</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Probabilistically checkable proofs (PCPs) can be verified based only on a constant amount of random queries, such that any correct claim has a proof that is always accepted, and incorrect claims are rejected with high probability (regardless of the given alleged proof). We consider two possible features of PCPs:
- A PCP is *strong* if it rejects an alleged proof of a correct claim with probability proportional to its distance from some correct proof of that claim.
- A PCP is *smooth* if each location in a proof is queried with equal probability.

We prove that all sets in $\mathcal{NP}$ have a smooth and strong PCP of polynomial length that can be verified based on a constant number of queries. We do so by following the proof of the PCP theorem of Arora, Lund, Motwani, Sudan and Szegedy (JACM, 1998), providing a stronger analysis of the Hadamard and Reed--Muller based PCPs and a refined PCP composition theorem. In fact, we show that any set in $\mathcal{NP}$ has a smooth strong *canonical* PCP of Proximity (PCPP), meaning that there is an efficiently computable bijection of $\mathcal{NP}$ witnesses to correct proofs.
	
This improves on the recent result of Dinur, Gur and Goldreich (ITCS, 2019) that constructs strong canonical PCPPs that are inherently non-smooth. Our result implies the hardness of approximating the satisfiability of "stable" 3CNF formulae with bounded variable occurrence, proving a hypothesis used in the work of Friggstad, Khodamoradi and Salavatipour (SODA, 2019). Here *stability* means that the number of clauses violated by an assignment is proportional to its distance from a satisfying assignment (in the relative Hamming metric).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/023"><span class="datestr">at February 25, 2019 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=16934">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2019/02/23/karim-adiprasito-the-g-conjecture-for-vertex-decomposible-spheres/">Karim Adiprasito: The g-Conjecture for Vertex Decomposible Spheres</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.files.wordpress.com/2019/02/scott_provan.jpg"><img src="https://gilkalai.files.wordpress.com/2019/02/scott_provan.jpg?w=640" alt="" class="alignnone size-full wp-image-16958" /></a></p>
<p><strong><span style="color: #ff0000;">J Scott Provan </span></strong><span style="color: #ff0000;"><a href="https://stat-or.unc.edu/people/emeritus/j-scott-provan">(site)</a></span></p>
<p><em>The following post was kindly contributed by Karim Adiprasito. (Here is<a href="https://arxiv.org/abs/1812.10454"> the link to Karim’s paper</a>.)</em></p>
<p>So, Gil asked me to say a little bit about my <a href="https://gilkalai.wordpress.com/2018/12/25/amazing-karim-adiprasito-proved-the-g-conjecture-for-spheres/">proof of the <em>g</em>-conjecture</a> (and some other conjectures in discrete geometry) on his blog, and since he bought me <a href="https://gilkalai.files.wordpress.com/2018/05/cubring.png">many</a>  <a href="https://gilkalai.wordpress.com/2018/06/20/beyond-the-g-conjecture-algebraic-combinatorics-of-cellular-spaces-i/">coffees </a>to explain it to him (or if he is to be believed, the department paid), I am happy to oblige.</p>
<p>So, I want to explain a special, but critical case to the proof. It contains the some shadow of the core ideas necessary, but needs some more tricks I will remark on afterwards.</p>
<p>Also, I wanted to take this opportunity to mention something marvelous that I learned from <a href="https://www.ccny.cuny.edu/profiles/leonid-gurvits">Leonid Gurvits</a> recently that increased my own understanding of one of the key tricks used indefinitely. That trick is the following cool lemma.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/image.png"><img src="https://gilkalai.files.wordpress.com/2019/02/image.png?w=640" alt="" class="alignnone size-full wp-image-16959" /></a></p>
<p><span style="color: #ff0000;"><strong>Leonid Gurvits</strong></span></p>
<h2>Perturbation lemma</h2>
<p><strong>PERTURBATION LEMMA:</strong> Consider two linear maps</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=%5Calpha%2C+%5Cbeta%3A+X%5C+%5Clongrightarrow%5C+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha, \beta: X\ \longrightarrow\ Y" class="latex" title="\alpha, \beta: X\ \longrightarrow\ Y" /></p>
<p>of two real vector spaces <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> and <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" />. Assume that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cbeta+%28%5Cker+%5Calpha+%29+%5Ccap+%5Crm%7Bim%7D%7E+%5Calpha+%3D%5C%7B0%5C%7D+%5Csubset+Y.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta (\ker \alpha ) \cap \rm{im}~ \alpha =\{0\} \subset Y." class="latex" title="\beta (\ker \alpha ) \cap \rm{im}~ \alpha =\{0\} \subset Y." /></p>
<p>Then a generic linear combination <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%60%60%2B%22%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha ``+&quot;\beta" class="latex" title="\alpha ``+&quot;\beta" /> of <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cbeta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta" class="latex" title="\beta" />  has kernel<br />
<img src="https://s0.wp.com/latex.php?latex=%5Cker+%28%5Calpha%C2%A0+%60%60%2B%22+%5Cbeta+%29%3D+%5Cker+%5Calpha+%5Ccap+%5Cker+%5Cbeta.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ker (\alpha  ``+&quot; \beta )= \ker \alpha \cap \ker \beta." class="latex" title="\ker (\alpha  ``+&quot; \beta )= \ker \alpha \cap \ker \beta." /></p>
<p>Cool, no? <strong>Proof, then:</strong> Find a subspace <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" /> of <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X" class="latex" title="X" /> such that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha+A%5C+%3D%5C+%5Calpha+X%5Cquad+%5Ctext%7Band%7D%5C+%5Cquad+X%5C+%5Ccong%5C+A+%5Coplus+%5Cker%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha A\ =\ \alpha X\quad \text{and}\ \quad X\ \cong\ A \oplus \ker\alpha" class="latex" title="\alpha A\ =\ \alpha X\quad \text{and}\ \quad X\ \cong\ A \oplus \ker\alpha" /></p>
<p>so that in particular <img src="https://s0.wp.com/latex.php?latex=%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha" class="latex" title="\alpha" /> is injective on <img src="https://s0.wp.com/latex.php?latex=A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A" class="latex" title="A" />. Then, for <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%5Cge+0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon \ge 0" class="latex" title="\epsilon \ge 0" /> small enough, the image of</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Calpha%5C+%2B%5C+%5Cepsilon+%5Cbeta%7B%3A%7D%5C+X%5C+%5Clongrightarrow%5C+Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha\ +\ \epsilon \beta{:}\ X\ \longrightarrow\ Y" class="latex" title="\alpha\ +\ \epsilon \beta{:}\ X\ \longrightarrow\ Y" /></p>
<p>is</p>
<p><img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%5C+%2B%5C+%5Cepsilon+%5Cbeta%29%28A%29%5C+%2B%5C+%5Cbeta%5Cker%5Calpha%5C+%5Csubset%5C+Y.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\alpha\ +\ \epsilon \beta)(A)\ +\ \beta\ker\alpha\ \subset\ Y." class="latex" title="(\alpha\ +\ \epsilon \beta)(A)\ +\ \beta\ker\alpha\ \subset\ Y." /></p>
<p>But if we norm <img src="https://s0.wp.com/latex.php?latex=Y&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y" class="latex" title="Y" /> in any way, then <img src="https://s0.wp.com/latex.php?latex=%28%5Calpha%2B%5Cepsilon+%5Cbeta%29%28A%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(\alpha+\epsilon \beta)(A)" class="latex" title="(\alpha+\epsilon \beta)(A)" /> approximates <img src="https://s0.wp.com/latex.php?latex=%5Calpha+A&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha A" class="latex" title="\alpha A" /> as <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" /> tends to zero, which is linearly independent from <img src="https://s0.wp.com/latex.php?latex=%5Cbeta%5C%2C+%5Cker%5Calpha&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta\, \ker\alpha" class="latex" title="\beta\, \ker\alpha" /> by assumption. <span style="color: #993366;"><strong>WALLA</strong></span></p>
<p>Now, how is this used.</p>
<h2>Face rings</h2>
<p>Let me set up some of the basic objects.</p>
<p>If <img src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta" class="latex" title="\Delta" /> is an abstract simplicial complex on ground-set <img src="https://s0.wp.com/latex.php?latex=%5Bn%5D%3A%3D+%5C%7B1%2C%5Ccdots%2Cn%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="[n]:= \{1,\cdots,n\}" class="latex" title="[n]:= \{1,\cdots,n\}" />, let <img src="https://s0.wp.com/latex.php?latex=I_%5CDelta+%3A%3D+%5Clangle+%5Ctextbf%7Bx%7D%5E%7B%5Ctextbf%7Ba%7D%7D%3A+supp+%28%5Ctextbf%7Ba%7D%29%5Cnotin%5CDelta%5Crangle&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I_\Delta := \langle \textbf{x}^{\textbf{a}}: supp (\textbf{a})\notin\Delta\rangle" class="latex" title="I_\Delta := \langle \textbf{x}^{\textbf{a}}: supp (\textbf{a})\notin\Delta\rangle" /> denote the nonface ideal in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}[\mathbf{x}]" class="latex" title="\mathbb{R}[\mathbf{x}]" />, where <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D%3D%5Cmathbb%7BR%7D%5Bx_1%2C%5Ccdots%2Cx_n%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}[\mathbf{x}]=\mathbb{R}[x_1,\cdots,x_n]" class="latex" title="\mathbb{R}[\mathbf{x}]=\mathbb{R}[x_1,\cdots,x_n]" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%3A%3D+%5Cmathbb%7BR%7D%5B%5Cmathbf%7Bx%7D%5D%2FI_%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}^\ast[\Delta]:= \mathbb{R}[\mathbf{x}]/I_\Delta" class="latex" title="\mathbb{R}^\ast[\Delta]:= \mathbb{R}[\mathbf{x}]/I_\Delta" /> denote the face ring of <img src="https://s0.wp.com/latex.php?latex=%5CDelta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Delta" class="latex" title="\Delta" />. A collection of linear forms <img src="https://s0.wp.com/latex.php?latex=%5CTheta%3D%28%5Ctheta_1%2C%5Ccdots%2C%5Ctheta_l%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Theta=(\theta_1,\cdots,\theta_l)" class="latex" title="\Theta=(\theta_1,\cdots,\theta_l)" /> in the polynomial ring <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5B%5Ctextbf%7Bx%7D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}[\textbf{x}]" class="latex" title="\mathbb{R}[\textbf{x}]" /> is a <strong>partial linear system of parameters</strong> if</p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cdim_%7B%5Crm%7BKrull%7D%7D+%7B%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\dim_{\rm{Krull}} {\mathbb{R}^\ast[\Delta]}" class="latex" title="\dim_{\rm{Krull}} {\mathbb{R}^\ast[\Delta]}" /> <img src="https://s0.wp.com/latex.php?latex=%7B%5CTheta+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{\Theta \mathbb{R}^\ast[\Delta]}" class="latex" title="{\Theta \mathbb{R}^\ast[\Delta]}" /> <img src="https://s0.wp.com/latex.php?latex=%3D%5Cdim_%7B%5Crm%7BKrull%7D%7D+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D-l%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta]-l," class="latex" title="=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta]-l," /></p>
<p>for <img src="https://s0.wp.com/latex.php?latex=%5Cdim_%7B%5Crm%7BKrull%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\dim_{\rm{Krull}}" class="latex" title="\dim_{\rm{Krull}}" /> the Krull dimension. If <img src="https://s0.wp.com/latex.php?latex=l%3D%5Cdim_%7B%5Crm%7BKrull%7D%7D+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D+%3D+%5Cdim+%5CDelta+%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="l=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta] = \dim \Delta +1" class="latex" title="l=\dim_{\rm{Krull}} \mathbb{R}^\ast[\Delta] = \dim \Delta +1" />, then <img src="https://s0.wp.com/latex.php?latex=%5CTheta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Theta" class="latex" title="\Theta" /> is simply a <strong>linear system of parameters</strong>, and the corresponding quotient <img src="https://s0.wp.com/latex.php?latex=A%28%5CDelta%29%3D%7B%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D%2F%7B%5CTheta+%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(\Delta)={\mathbb{R}^\ast[\Delta]}/{\Theta \mathbb{R}^\ast[\Delta]}" class="latex" title="A(\Delta)={\mathbb{R}^\ast[\Delta]}/{\Theta \mathbb{R}^\ast[\Delta]}" /> is called an <strong>Artinian reduction</strong> of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5E%5Cast%5B%5CDelta%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}^\ast[\Delta]" class="latex" title="\mathbb{R}^\ast[\Delta]" />.</p>
<h2>The <em>g</em>-conjecture</h2>
<p>The <em>g</em>-conjecture (as <a href="https://gilkalai.wordpress.com/2009/04/02/eran-nevo-the-g-conjecture-i/">described</a> <a href="https://gilkalai.wordpress.com/2009/04/04/how-the-g-conjecture-came-about/">earlier</a> <a href="https://gilkalai.wordpress.com/tag/g-conjecture/"> in Gil’s blog</a>) is implied by the following property:</p>
<p><strong>(HL)</strong> For every sphere <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> of even dimension <img src="https://s0.wp.com/latex.php?latex=d-1%3D2k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d-1=2k" class="latex" title="d-1=2k" />, there is an Artinian reduction <img src="https://s0.wp.com/latex.php?latex=A%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(S)" class="latex" title="A(S)" /> and a degree one element <img src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell" class="latex" title="\ell" /> such that the map</p>
<p><img src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+%5Cell%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^k(S) \ \xrightarrow{\ \cdot \ell\ }\ A^{k+1}(S) " class="latex" title="A^k(S) \ \xrightarrow{\ \cdot \ell\ }\ A^{k+1}(S) " /></p>
<p>is an isomorphism.</p>
<p>This is quite a reasonable demand. Indeed, Graebe proved that <img src="https://s0.wp.com/latex.php?latex=A%5Ed%28S%29+%5Ccong+%5Cmathbb%7BR%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^d(S) \cong \mathbb{R}" class="latex" title="A^d(S) \cong \mathbb{R}" /> and that the resulting pairing</p>
<p><img src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5Ctimes+A%5E%7Bk%2B1%7D%28S%29%5Crightarrow+%5Cmathbb%7BR%7D+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^k(S) \times A^{k+1}(S)\rightarrow \mathbb{R} " class="latex" title="A^k(S) \times A^{k+1}(S)\rightarrow \mathbb{R} " /></p>
<p>is perfect, so <img src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^k(S)" class="latex" title="A^k(S)" /> and <img src="https://s0.wp.com/latex.php?latex=A%5E%7Bk%2B1%7D%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^{k+1}(S)" class="latex" title="A^{k+1}(S)" /> are isomorphic as vector spaces. We shall call this property <strong>(PD)</strong>, because it is a special case of Poincaré pairing.</p>
<p>(HL) is a special case of the Hard Lefschetz Theorem I prove in my paper, and we will prove it for a subset of all triangulated spheres here. Proving it for all spheres implies the <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="g" class="latex" title="g" />-conjecture (and other conjectures, such as the Grünbaum conjecture), and proving the hard Lefschetz theorem in full generality is not much harder.</p>
<p><a href="https://gilkalai.files.wordpress.com/2019/02/image-1.png"><img src="https://gilkalai.files.wordpress.com/2019/02/image-1.png?w=640" alt="" class="alignnone size-full wp-image-16960" /></a></p>
<p><span style="color: #ff0000;"><strong>Lou Billera</strong></span></p>
<h2>Vertex-decomposable spheres</h2>
<p>Lets recall a cool notion due to Provan and Billera: A pure simplicial <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />-complex is <strong>vertex decomposable</strong> if it is a simplex, or there exists a vertex whose link is vertex decomposable of dimension <img src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d-1" class="latex" title="d-1" /> and its deletion is vertex decomposable of dimension <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />.</p>
<p>We restrict our attention to vertex decomposable spheres and disks and assume the boundary of the link is vertex decomposable as well in every step.</p>
<p><strong>THEOREM:</strong> Vertex decomposable spheres satisfy (HL).</p>
<p>We prove this theorem by induction on dimension, the base case of zero-dimensional spheres <img src="https://s0.wp.com/latex.php?latex=%28k%3D0%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(k=0)" class="latex" title="(k=0)" /> being clear.</p>
<p>Lets label the vertices of <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> in order of their vertex decomposition, from <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> to <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />. Now, <img src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell" class="latex" title="\ell" /> will be a linear combination of indeterminates, so lets assume we have constructed an element <img src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_i" class="latex" title="\ell_i" /> that uses just the first <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> of them, and such that <img src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_i" class="latex" title="\ell_i" /> itself is as close to a Lefschetz element as possible for its kind, that is, the kernel of</p>
<p><img src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+%5Cell_i%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^k(S) \ \xrightarrow{\ \cdot \ell_i\ }\ A^{k+1}(S) " class="latex" title="A^k(S) \ \xrightarrow{\ \cdot \ell_i\ }\ A^{k+1}(S) " /></p>
<p>is the intersection of kernels of the maps</p>
<p><img src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> ranges from <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> to <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />.</p>
<p>We want to construct a map <img src="https://s0.wp.com/latex.php?latex=%5Cell_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_{i+1}" class="latex" title="\ell_{i+1}" /> with this property (which I call the <strong>transversal prime property</strong>}. To this effect, we want to apply the perturbation lemma to the maps <img src="https://s0.wp.com/latex.php?latex=%5Cbeta+x_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\beta x_{i+1}" class="latex" title="\beta x_{i+1}" />, <img src="https://s0.wp.com/latex.php?latex=%5Calpha%3D%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\alpha=\ell_i" class="latex" title="\alpha=\ell_i" />, and with respect to the spaces <img src="https://s0.wp.com/latex.php?latex=X%3DA%5Ek%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="X=A^k(S)" class="latex" title="X=A^k(S)" /> and <img src="https://s0.wp.com/latex.php?latex=Y%3DA%5E%7Bk%2B1%7D%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Y=A^{k+1}(S)" class="latex" title="Y=A^{k+1}(S)" />. Let us denote by <img src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="D" class="latex" title="D" /> the ball given as the union of neighborhoods of the first <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> vertices.</p>
<p>For this, we have to find out the kernel of <img src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_i" class="latex" title="\ell_i" />. But this is the the ideal in <img src="https://s0.wp.com/latex.php?latex=A%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(S)" class="latex" title="A(S)" /> generated by the monomials of faces which are not in the neighborhood of any of the first <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" /> vertices. Lets call it <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="K" class="latex" title="K" />. Lets also look at the image <img src="https://s0.wp.com/latex.php?latex=I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I" class="latex" title="I" /> of <img src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_i" class="latex" title="\ell_i" />, which by Graebe’s theorem is exactly the span of the images of the maps the maps</p>
<p><img src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> ranges from <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> to <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />.</p>
<p>But then, <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7DK+%5Ccap+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i+1}K \cap I" class="latex" title="x_{i+1}K \cap I" /> is <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> in degree <img src="https://s0.wp.com/latex.php?latex=k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k+1" class="latex" title="k+1" /> if and only if <img src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(st_{i+1} \partial D)" class="latex" title="A(st_{i+1} \partial D)" /> is <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" /> in degree <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />. Why is that? Because with respect to the Poincaré pairing, <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7DK+%5Ccap+I&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i+1}K \cap I" class="latex" title="x_{i+1}K \cap I" /> (in degree <img src="https://s0.wp.com/latex.php?latex=k%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k+1" class="latex" title="k+1" />) and <img src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(st_{i+1} \partial D)" class="latex" title="A(st_{i+1} \partial D)" /> (in degree <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />) are dual.<br />
The ring <img src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(st_{i+1} \partial D)" class="latex" title="A(st_{i+1} \partial D)" /> is obtained by taking <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Bst_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}[st_{i+1} \partial D]" class="latex" title="\mathbb{R}[st_{i+1} \partial D]" />, seen as a quotient of <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5BS%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}[S]" class="latex" title="\mathbb{R}[S]" /> and modding out by the ideal generated by the linear system <img src="https://s0.wp.com/latex.php?latex=%5CTheta&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Theta" class="latex" title="\Theta" />. But that is of length <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d" class="latex" title="d" />, even though <img src="https://s0.wp.com/latex.php?latex=st_%7Bi%2B1%7D+%5Cpartial+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="st_{i+1} \partial D" class="latex" title="st_{i+1} \partial D" /> is only of dimension <img src="https://s0.wp.com/latex.php?latex=d-2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d-2" class="latex" title="d-2" />. We can remove the vertex <img src="https://s0.wp.com/latex.php?latex=i%2B1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i+1" class="latex" title="i+1" /> for the price of removing one of the linear forms, but then we have the same issue, having a <img src="https://s0.wp.com/latex.php?latex=%28d-3%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(d-3)" class="latex" title="(d-3)" />-sphere <img src="https://s0.wp.com/latex.php?latex=st_%7Bi%2B1%7D+%5Cpartial+D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="st_{i+1} \partial D" class="latex" title="st_{i+1} \partial D" /> and a system <img src="https://s0.wp.com/latex.php?latex=%5CTheta%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Theta'" class="latex" title="\Theta'" /> of length <img src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d-1" class="latex" title="d-1" />. Still, one too many! Taking a subsystem of length <img src="https://s0.wp.com/latex.php?latex=d-2&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d-2" class="latex" title="d-2" />, we obtain an Artinian reduction for <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}[lk_{i+1} \partial D]" class="latex" title="\mathbb{R}[lk_{i+1} \partial D]" /> via a linear system <img src="https://s0.wp.com/latex.php?latex=%5CTheta%27%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Theta''" class="latex" title="\Theta''" />, but what happens to the additional linear form of <img src="https://s0.wp.com/latex.php?latex=%5CTheta%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Theta'" class="latex" title="\Theta'" /> not in <img src="https://s0.wp.com/latex.php?latex=%5CTheta%27%27&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Theta''" class="latex" title="\Theta''" />? It has to act as a Lefschetz element on <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D%2F%5CTheta%27%27%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbb{R}[lk_{i+1} \partial D]/\Theta''\mathbb{R}[lk_{i+1} \partial D]" class="latex" title="\mathbb{R}[lk_{i+1} \partial D]/\Theta''\mathbb{R}[lk_{i+1} \partial D]" /> if we want</p>
<p><img src="https://s0.wp.com/latex.php?latex=A%28st_%7Bi%2B1%7D+%5Cpartial+D%29%5C+%5Ccong%5C+%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D%2F%5CTheta%27%5Cmathbb%7BR%7D%5Blk_%7Bi%2B1%7D+%5Cpartial+D%5D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A(st_{i+1} \partial D)\ \cong\ \mathbb{R}[lk_{i+1} \partial D]/\Theta'\mathbb{R}[lk_{i+1} \partial D]" class="latex" title="A(st_{i+1} \partial D)\ \cong\ \mathbb{R}[lk_{i+1} \partial D]/\Theta'\mathbb{R}[lk_{i+1} \partial D]" /></p>
<p>to be trivial in degree <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />. But we may assume so by induction! Hence, we can choose <img src="https://s0.wp.com/latex.php?latex=%5Cell_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_{i+1}" class="latex" title="\ell_{i+1}" /> as the generic sum of <img src="https://s0.wp.com/latex.php?latex=%5Cell_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_i" class="latex" title="\ell_i" /> and <img src="https://s0.wp.com/latex.php?latex=x_%7Bi%2B1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x_{i+1}" class="latex" title="x_{i+1}" /> by the perturbation lemma.</p>
<p>So, ultimately, we can construct a map <img src="https://s0.wp.com/latex.php?latex=%5Cell_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_n" class="latex" title="\ell_n" /> with the transversal prime property. But then its kernel is the intersection of the kernels of</p>
<p><img src="https://s0.wp.com/latex.php?latex=A%5Ek%28S%29+%5C+%5Cxrightarrow%7B%5C+%5Ccdot+x_j%5C+%7D%5C+A%5E%7Bk%2B1%7D%28S%29+&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " class="latex" title="A^k(S) \ \xrightarrow{\ \cdot x_j\ }\ A^{k+1}(S) " />,</p>
<p>where <img src="https://s0.wp.com/latex.php?latex=j&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="j" class="latex" title="j" /> ranges from <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" /> to <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />. But that is <img src="https://s0.wp.com/latex.php?latex=0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="0" class="latex" title="0" />.  <strong><span style="color: #993366;">SABABA</span>.</strong></p>
<h2>And beyond?</h2>
<p>Now, we have the Lefschetz theorem for a special class, but that is less than what we want in the end, since vertex decomposable spheres are few and in between (do you see a reason why? there are many). So, what do we do? For a long time, I tried to extend the perturbation lemma to combine more than two maps.<br />
Recently (depending on when Gil puts this post on the blog), I met Leonid Gurvits for the first time on a marvelous little conference at the Simons Institute. I knew that the problem is related to Hall’s Marriage Theorem for operators (I explain this connection a bit further in my paper), but Leonid enlightened this further by pointing me towards several nice papers, starting with <a href="https://arxiv.org/abs/quant-ph/0201022">his work on Quantum Matching Theory</a>. Indeed, finding a good extension to three and more maps would essentially mean that we could also find Hall Marriage Type Theorems for 3-regular hypergraphs, which we know for complexity reasons to be unlikely.</p>
<p>So what can we do instead? Well, it turns out that I only really needed to look at the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-skeleton of <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" /> above, and there is no need to be vertex decomposable. It is enough to find another nicely decomposable <img src="https://s0.wp.com/latex.php?latex=d-1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="d-1" class="latex" title="d-1" />-manifold that contains it the <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="k" class="latex" title="k" />-skeleton of <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S" class="latex" title="S" />, and then use some technical topological tricks to connect the local picture to global homological properties.</p>
<p> </p>
<p> </p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2019/02/23/karim-adiprasito-the-g-conjecture-for-vertex-decomposible-spheres/"><span class="datestr">at February 23, 2019 04:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=15657">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2019/02/22/making-a-mapping-injective/">Making A Mapping Injective</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Finding a set of nearly independent objects</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg"><img width="118" alt="" src="https://rjlipton.files.wordpress.com/2019/02/330px-giuseppe_vitali.jpg?w=118&amp;h=150" class="alignright size-thumbnail wp-image-15658" height="150" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Wikipedia bio <a href="https://en.wikipedia.org/wiki/Giuseppe_Vitali">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Giuseppe Vitali was the mathematician who famously used the Axiom of Choice, in 1905, to give the first example of a non-measurable subset of the real numbers.</p>
<p>
Today I want to discuss another of his results that is a powerful tool.</p>
<p>
The existence of a set that cannot properly be assigned a measure was a surprise at the time, and still is a surprise. It is a wonderful example of the power of the Axiom of Choice. See <a href="https://en.wikipedia.org/wiki/Vitali_set">this</a> for details. </p>
<p>
We are interested in another of his results that is more a theorem about coverings. It is the Vitali covering theorem–see <a href="https://en.wikipedia.org/wiki/Vitali_covering_lemma">this</a>. The theorem shows that a certain type of covering—ah, we will explain the theorem in a moment.</p>
<p>
The power of this theorem is that it can be used to construct various objects in analysis. There are now many applications of this theorem. It is a powerful tool that can be used to prove many nice results. I do not know of any—many?—applications of the existence of a non-measurable set. Do you know any?</p>
<p>
</p><p></p><h2> Making A Mapping Injective </h2><p></p>
<p></p><p>
Let’s look at an application of the Vitali theorem that may be new. But in any case it may help explain what the Vitali theorem is all about.</p>
<p>
Suppose that <img src="https://s0.wp.com/latex.php?latex=%7BF%3AX+%5Crightarrow+Y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F:X \rightarrow Y}" class="latex" title="{F:X \rightarrow Y}" />. We can make the map surjective if we restrict <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> to be equal to <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(X)}" class="latex" title="{F(X)}" />. It is not so simple to make the map injective, but we can in general do that also. </p>
<blockquote><p><b>Theorem 1</b> <em><a name="choice"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> be a surjective function from <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />. Then there is a subset <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is injective from <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />. </em>
</p></blockquote>
<p></p><p>
<em>Proof:</em>  For each <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> select one <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> from the set <img src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F^{-1}(y)}" class="latex" title="{F^{-1}(y)}" /> and place it into <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. Recall <img src="https://s0.wp.com/latex.php?latex=%7BF%5E%7B-1%7D%28y%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F^{-1}(y)}" class="latex" title="{F^{-1}(y)}" /> is the set of <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7BF%28z%29%3Dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(z)=y}" class="latex" title="{F(z)=y}" />.This of course uses the Axiom of Choice to make the choices of which <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> to choose. Then clearly <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> is the required set. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
The difficulty with this trivial theorem is that <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> cannot be controlled easily if it is constructed via the Axiom of Choice. It could be a very complicated set. Our goal is to see how well we can control <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> if we assume that the mapping <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is smooth. </p>
<p>
How can we do better? The answer is quite a bit better if we assume that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is a “nice” function. We give up surjectivity onto <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> but only by a null set.</p>
<blockquote><p><b>Theorem 2</b> <em><a name="injective"></a> Suppose that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is a surjective smooth map from <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> are open subsets of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{{\mathbb R}}" class="latex" title="{{\mathbb R}}" />. Also suppose that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> locally is invertible. Then there is a subset <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> so that </em></p><em>
<ol>
<li>
The complement of <img src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F(S)}" class="latex" title="{F(S)}" /> is a null set. <p></p>
</li><li>
The map <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is injective from <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F(S)}" class="latex" title="{F(S)}" />.
</li></ol>
</em><p><em>That is that for all distinct points <img src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Ba%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\boldsymbol{a}}" class="latex" title="{\boldsymbol{a}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cboldsymbol%7Bb%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\boldsymbol{b}}" class="latex" title="{\boldsymbol{b}}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />, <img src="https://s0.wp.com/latex.php?latex=%7BF%28%5Cboldsymbol%7Ba%7D%29+%5Cneq+F%28%5Cboldsymbol%7Bb%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}" class="latex" title="{F(\boldsymbol{a}) \neq F(\boldsymbol{b})}" />. Moreover the map from <img src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{F(S)}" class="latex" title="{F(S)}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> is smooth. </em>
</p></blockquote>
<p>
</p><p></p><h2> Set Coverings </h2><p></p>
<p></p><p>
How can we prove this theorem? An obvious idea is to do the following. Pick an open interval <img src="https://s0.wp.com/latex.php?latex=%7BU%3D%5Ba%2Cb%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U=[a,b]}" class="latex" title="{U=[a,b]}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7BF%28U%29+%3D+V%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(U) = V}" class="latex" title="{F(U) = V}" /> for an open set in <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" /> and so that <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is injective from <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V}" class="latex" title="{V}" />. Setting <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> clearly works: the map <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is injective on <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. This is far from the large set that we wish to have, but it is a start. The intuition is to select another open interval <img src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U'}" class="latex" title="{U'}" /> that is disjoint from <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> so that again <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F}" class="latex" title="{F}" /> is injective from <img src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U'}" class="latex" title="{U'}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BV%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{V'}" class="latex" title="{V'}" />. We can then add <img src="https://s0.wp.com/latex.php?latex=%7BU%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{U'}" class="latex" title="{U'}" /> to our <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. </p>
<p>
We can continue in this way and collect many open sets that we add to <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. Can we arrange that the union of these sets yield a <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7BF%28S%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(S)}" class="latex" title="{F(S)}" /> is most of <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />? In general the answer is no. Suppose that the intervals are the following: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  [k,k+1.1] " class="latex" title="\displaystyle  [k,k+1.1] " /></p>
<p>for <img src="https://s0.wp.com/latex.php?latex=%7Bk%3D0%2C1%2C2%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k=0,1,2,\dots}" class="latex" title="{k=0,1,2,\dots}" /> Roughly we can only get about half of the space that the intervals cover and keep the chosen intervals disjoint. If we select <img src="https://s0.wp.com/latex.php?latex=%7B+%5Bk%2Ck%2B1.1%5D+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ [k,k+1.1] }" class="latex" title="{ [k,k+1.1] }" /> then we cannot select <img src="https://s0.wp.com/latex.php?latex=%7B%5Bk%2B1%2Ck%2B1%2B1.1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[k+1,k+1+1.1]}" class="latex" title="{[k+1,k+1+1.1]}" /> since 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Bk%2Ck%2B1.1%5D+%5Ccap+%5Bk%2B1%2Ck%2B1%2B1.1%5D+%5Cneq+%5Cemptyset.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. " class="latex" title="\displaystyle  [k,k+1.1] \cap [k+1,k+1+1.1] \neq \emptyset. " /></p>
<p>Vitali’s theorem comes to the rescue. It allows us to avoid his problem, by insisting that intervals have an additional property.</p>
<p>
</p><p></p><h2> The Vitali Covering Theorem </h2><p></p>
<p></p><p>
The trick is to use a refinement of a set cover that allows a disjoint cover to exist for almost all of the target set. The next definition is critical to the Vitali covering theorem. </p>
<blockquote><p><b>Definition 3</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> be a subset of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{{\mathbb R}}" class="latex" title="{{\mathbb R}}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{[a_{\lambda},b_{\lambda}]}" class="latex" title="{[a_{\lambda},b_{\lambda}]}" /> be intervals over <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> in some index set <img src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{I}" class="latex" title="{I}" />. We say these intervals are a <b>cover</b> of <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> proved <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> is a subset of the union of all the intervals. Say the intervals also are a <b>Vitali</b> cover of <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> provided for all points <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> and all <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0}" class="latex" title="{\epsilon &gt; 0}" />, there is an interval <img src="https://s0.wp.com/latex.php?latex=%7B%5Bc%2Cd%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{[c,d]}" class="latex" title="{[c,d]}" /> that contains <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B0+%3C+d-c+%3C+%5Cepsilon%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{0 &lt; d-c &lt; \epsilon}" class="latex" title="{0 &lt; d-c &lt; \epsilon}" />. </em>
</p></blockquote>
<p></p><p>
The Vitali theorem is the following: </p>
<blockquote><p><b>Theorem 4</b> <em> Let <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> be a subset of <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{{\mathbb R}}" class="latex" title="{{\mathbb R}}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Ba_%7B%5Clambda%7D%2Cb_%7B%5Clambda%7D%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{[a_{\lambda},b_{\lambda}]}" class="latex" title="{[a_{\lambda},b_{\lambda}]}" /> be intervals for <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> in some index set <img src="https://s0.wp.com/latex.php?latex=%7BI%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{I}" class="latex" title="{I}" />. Assume that the family is a Vitali cover of <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" />. Then there is a countable subfamily of disjoints intervals in the family so that they cover all of <img src="https://s0.wp.com/latex.php?latex=%7BU%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{U}" class="latex" title="{U}" /> except for possibly a null set. </em>
</p></blockquote>
<p></p><p>
The Vitali theorem can be extended to any finite dimensional space <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^{n}}" class="latex" title="{{\mathbb R}^{n}}" />. Then intervals become disks and so on.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Do you see how to prove Theorem <a href="https://rjlipton.wordpress.com/feed/#injective">2</a> from Vitali’s theorem? The insight is now one can set up a Vitali covering of the space <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />. </p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2019/02/22/making-a-mapping-injective/"><span class="datestr">at February 23, 2019 04:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/022">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/022">TR19-022 |  Circuit Lower Bounds for MCSP from Local Pseudorandom Generators | 

	Valentine Kabanets, 

	Mahdi Cheraghchi, 

	Zhenjian Lu, 

	Dimitrios Myrisiotis</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The Minimum Circuit Size Problem (MCSP) asks if a given truth table of a Boolean function $f$ can be computed by a Boolean circuit of size at most $\theta$, for a given parameter $\theta$. We improve several circuit lower bounds for MCSP, using pseudorandom generators (PRGs) that are local; a PRG is called local if its output bit strings, when viewed as the truth table of a Boolean function, can be computed by a Boolean circuit of small size. We get new and improved lower bounds for MCSP that almost match the best-known lower bounds against several circuit models. 

Specifically, we show that computing MCSP, on functions with a truth table of length $N$, requires

   $N^{3-o(1)}$-size de Morgan formulas, improving the recent $N^{2-o(1)}$ lower bound by Hirahara and Santhanam (CCC, 2017),
 $N^{2-o(1)}$-size formulas over an arbitrary basis or general branching programs (no non-trivial lower bound was known for MCSP against these models), and 
    $2^{\Omega\left(N^{1/(d+2.01)}\right)}$-size depth-$d$ $AC^0$ circuits, improving the superpolynomial lower bound by Allender et al. (SICOMP, 2006).

 
    	The $AC^0$ lower bound stated above matches the best-known $AC^0$ lower bound (for PARITY) up to a small additive constant in the depth. Also, for the special case of depth-$2$ circuits (i.e., CNFs or DNFs), we get an almost optimal lower bound of \(2^{N^{1-o(1)}}\) for MCSP.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/022"><span class="datestr">at February 23, 2019 01:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html">Mutual nearest neighbors versus closest pairs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the 1990s I published a series of papers on data structures for closest pairs. As long as you already know how to maintain dynamic sets of objects of some type, and answer nearest-neighbor queries among them, you can also keep track of the closest pair, and this can be used as a subroutine in many other
computational geometry algorithms. But it turns out that many of those algorithms can now be simplified and sped up by using mutual nearest neighbors (pairs of objects that are each other’s nearest neighbors) instead of closest pairs.</p>

<p>My original motivation for studying these types of problems was to maintain minimum spanning trees of dynamic point sets, using closest red-blue pairs of Euclidean points,<sup id="fnref:aem"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:aem" class="footnote">1</a></sup> <sup id="fnref:ebf"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ebf" class="footnote">2</a></sup> and I later found more applications in hierarchical clustering, greedy matching, traveling salesperson heuristics,<sup id="fnref:fhc"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:fhc" class="footnote">3</a></sup> <sup id="fnref:lazy"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:lazy" class="footnote">4</a></sup> and (with Jeff Erickson) motorcycle graphs and <a href="https://en.wikipedia.org/wiki/Straight_skeleton">straight skeletons</a>.<sup id="fnref:ee"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ee" class="footnote">5</a></sup> But to use these closest pair data structures, you have to pay two logarithmic factors in time complexity over the time for the underlying nearest-neighbor data structure. So they’re not competitive with (uncolored) Euclidean closest pair data structures, which take only logarithmic time in any fixed dimension. Instead they make more sense to use with other distances than Euclidean, with objects more complicated than single points, or with variations like the red-blue closest pair for which the logarithmic-time solution doesn’t work.</p>

<p>For several variations of hierarchical clustering, an alternative and simpler technique has been known for quite a bit longer, based on finding mutual nearest neighbors (pairs of objects that are nearer to each other than to anything else) rather than closest pairs.<sup id="fnref:ben"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:ben" class="footnote">6</a></sup> <sup id="fnref:juan"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:juan" class="footnote">7</a></sup> It’s called the <a href="https://en.wikipedia.org/wiki/Nearest-neighbor_chain_algorithm">nearest neighbor chain algorithm</a>, but really it’s a data structure rather than an algorithm, one that allows you to maintain a dynamic point set and find pairs of mutual nearest neighbors, again based on calls to an underlying nearest neighbor data structure. The idea is to maintain a stack of shorter and shorter pairs of nearest neighbors, until the two objects whose distance is on the top of the stack have nothing nearer – they are mutual nearest neighbors. Whenever you want a pair of neighbors, you look at the top pair, an object  and its nearest neighbor , and ask whether ’s nearest neighbor is . If so, you have found a mutual nearest neighbor pair, and if not you have a new shorter distance to push onto the stack.</p>

<p>One can this in a hierarchical clustering algorithm that repeatedly finds and merges the nearest two clusters, whenever the distance between clusters has a special property: a merged cluster is never closer to other clusters than the closer of the two clusters that was merged. This property implies both that the stack of distances remains valid after the merge, and that mutual nearest neighbors are always safe to merge. If two clusters are mutual nearest neighbors, then the closest-pair clustering algorithm will eventually merge them, because none of its actions can cause them to stop being mutual nearest neighbors. So we might as well merge them immediately once we discover them to be mutual nearest neighbors. (One way to formulate this mathematically is that the set of mutual nearest neighbor pairs merged by the clustering algorithm forms an <a href="https://en.wikipedia.org/wiki/Antimatroid">antimatroid</a>). When this works, you get a clustering algorithm that uses a linear number of nearest neighbor queries, instead of the  queries that you would get using my closest-pair data structures.</p>

<p>In more recent research with UCI student Nil Mamano (finishing his doctorate this year; hire him for a postdoc, he’s good!) we noticed that the nearest neighbor chain algorithm can also be applied to certain <a href="https://11011110.github.io/blog/2017/04/11/stable-grid-matching.html">stable marriage problems with preferences coming from geometric distances</a>.<sup id="fnref:egm"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:egm" class="footnote">8</a></sup> Our latest preprint, “Euclidean TSP, Motorcycle Graphs, and Other New Applications of Nearest-Neighbor Chains” (with Efrat, Frishberg, Goodrich, Kobourov, Mamano, Matias, and Polishchuk, <a href="https://arxiv.org/abs/1902.06875">arXiv:1902.06875</a>) extends this to a much broader set of applications. As well as simplifying and speeding up my previous work on motorcycle graphs and TSP heuristics, we also use nearest neighbor chains in a bigger class of stable matching problems and in an approximate geometric set cover problem. In each case, we need to show either that the problem has an antimatroid-like property (so using mutual nearest neighbors produces the same solution as closest pairs) or that, even when varying from the same solution, it achieves the same quality. It’s not quite true that anything closest pairs can do, mutual nearest neighbors can do better, but it’s close.</p>

<p>Another idea in the paper is that to find (exact!) mutual nearest neighbor pairs one can sometimes get away with using approximate near neighbor structures. This is important if you’re using Euclidean distance, because the time bounds for exact nearest neighbors have the form  for constants  that get very small as  gets large, while approximate nearest neighbors are logarithmic in all dimensions. The idea is to build the stack of shorter distances by asking for a constant number of approximate near neighbors, the th of which is within a constant factor of the distance to the actual th nearest neighbor. By a packing argument for points in Euclidean space, either some two of these points are closer to each other than the distance on the current stack top (in which case you can build the stack one more level) or these approximate neighbors are guaranteed to contain the actual nearest neighbor (in which case you can either detect a mutual nearest neighbor pair or again build the stack).
This idea leads, for instance, to an algorithm for the <a href="https://en.wikipedia.org/wiki/Multi-fragment_algorithm">multi-fragment TSP heuristic</a> that takes time  in Euclidean spaces of any bounded dimension; the best previous time appears to be an -time algorithm (valid in any metric space) from one of my previous papers.<sup id="fnref:fhc:1"><a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fn:fhc" class="footnote">3</a></sup></p>

<div class="footnotes">
  <ol>
    <li id="fn:aem">
      <p>Agarwal, P. K., Eppstein, D., and Matoušek, J., “<a href="https://www.ics.uci.edu/~eppstein/pubs/AgaEppMat-FOCS-92.pdf">Dynamic algorithms for half-space reporting, proximity problems, and geometric minimum spanning trees</a>”, <em>FOCS</em>, 1992, pp. 80–89. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:aem" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:ebf">
      <p>Eppstein, D., “<a href="https://www.ics.uci.edu/~eppstein/pubs/Epp-DCG-95.pdf">Dynamic Euclidean minimum spanning trees and extrema of binary functions</a>”, <em>Discrete Comput. Geom.</em> 13: 111–122, 1995. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ebf" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:fhc">
      <p>Eppstein, D., “Fast hierarchical clustering and other applications of dynamic closest pairs”, <em>SODA</em>, 1998, pp. 619–628, <a href="https://arxiv.org/abs/cs.DS/9912014">arXiv:cs.DS/9912014</a>, <em>J. Experimental Algorithmics</em> 5 (1): 1–23, 2000. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:fhc" class="reversefootnote">↩</a> <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:fhc:1" class="reversefootnote">↩<sup>2</sup></a></p>
    </li>
    <li id="fn:lazy">
      <p>Cardinal, J., and Eppstein, D., “<a href="https://www.siam.org/meetings/alenex04/abstacts/JCardinal.pdf">Lazy algorithms for dynamic closest pair with arbitrary distance measures</a>”, <em>ALENEX</em>, 2004, pp. 112–119. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:lazy" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:ee">
      <p>Eppstein, D., and Erickson, J., “<a href="http://jeffe.cs.illinois.edu/pubs/pdf/cycles.pdf">Raising roofs, crashing cycles, and playing pool: applications of a data structure for finding pairwise interactions</a>”, <em>SoCG</em>, 1998, pp. 58–67, <em>Discrete Comput. Geom.</em> 22 (4): 569–592, 1999. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ee" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:ben">
      <p>Benzécri, J.-P. (1982), “<a href="http://www.numdam.org/item?id=CAD_1982__7_2_209_0">Construction d’une classification ascendante hiérarchique par la recherche en chaîne des voisins réciproques</a>”, Les Cahiers de l’Analyse des Données, 7 (2): 209–218. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:ben" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:juan">
      <p>Juan, J. (1982), “<a href="http://www.numdam.org/item?id=CAD_1982__7_2_219_0">Programme de classification hiérarchique par l’algorithme de la recherche en chaîne des voisins réciproques</a>”, <em>Les Cahiers de l’Analyse des Données</em>, 7 (2): 219–225. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:juan" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:egm">
      <p>Eppstein, D., Goodrich, M. T., and Mamano, N., “Algorithms for stable matching and clustering in a grid”, <a href="https://arxiv.org/abs/1704.02303">arXiv:1704.02303</a>, <em>IWCIA</em> 2017, LNCS 10256 (2017), pp. 117–131. <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html#fnref:egm" class="reversefootnote">↩</a></p>
    </li>
  </ol>
</div>

<p>(<a href="https://mathstodon.xyz/@11011110/101634032916499158">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2019/02/21/mutual-nearest-neighbors.html"><span class="datestr">at February 21, 2019 09:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4944416293302133989">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html">Extra! Extra! Read all about it!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Last weekend I saw the documentary <a href="https://www.imdb.com/title/tt7428030/">Joseph Pulitzer: Voice of the People</a>. Pulitzer, as you probably know from the prize named after him, was a major newspaper publisher in the late 19th and early 20th century. He ran two papers, the St. Louis Post-Dispatch and The New York World. The World at one point took on massive proportions, including sheet music of the latest tunes and dress patterns of new fashion that one could make at home. The World was the Internet of the turn of the 20th century.<br />
<br />
The movie mentioned the many editions of the paper during the day, including the extra edition. An extra edition came out because of some major breaking news story. Back then newspapers would drum up minor stories to sell extra editions but they tended to disappear over time.<br />
<br />
Which brings me to Monday, August 19, 1991. Hard-line members of the communist party of the USSR <a href="https://en.wikipedia.org/wiki/1991_Soviet_coup_d%27%C3%A9tat_attempt">attempted a coup</a> to take over the government from Mikhail Gorbachev. To us in the US, this seemed like the cold war which appeared to be coming to an end might rekindle. At the time I lived in Chicago and on that Monday the Chicago Tribune ran an extra afternoon edition talking about the coup. The return to the cold war didn't happen. Within a couple of days the coup failed and if anything hastened the dissolution of the Soviet Republic.<br />
<br />
That was probably the last of the extra editions. By the time of the next major historical event, ten years and twenty-three days later, we had the Internet and cell phones and one no longer needed a newspaper to tell you the world has changed.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/02/extra-extra-read-all-about-it.html"><span class="datestr">at February 21, 2019 12:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/021">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/021">TR19-021 |  $AC^0[p]$ Lower Bounds and NP-Hardness for Variants of MCSP | 

	Rahul Ilango</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The Minimum Circuit Size Problem (MCSP) asks whether a (given) Boolean function has a circuit of at most a (given) size. Despite over a half-century of study, we know relatively little about the computational complexity of MCSP. We do know that questions about the complexity of MCSP have significant ramifications on longstanding open problems. In a recent development, Golovnev et al. [11] improves the status of unconditional lower bounds for MCSP, showing that MCSP is not in $AC^0[p]$ for any prime $p$. While their results generalize to most "typical" circuit classes, it fails to generalize to the circuit minimization problem for depth-d formulas, denoted ($AC^0_d$)-MCSP. In particular, their result relies on a Lipchitz hypothesis that is unknown (and possibly false) in the case of ($AC^0_d$)-MCSP. Despite this, we show that ($AC^0_d$)-MCSP is not in $AC^0[p]$ by proving even the failure of the Lipchitzness for $AC^0_d$ formulas implies that MAJORITY reduces to ($AC^0_d$)-MCSP under $AC^0$ truth table reductions. Somewhat remarkably, our proof (in the case of non-Lipchitzness) uses completely different techniques than [11]. To our knowledge, this is the first MCSP reduction that uses modular properties of a function's circuit complexity.

We also define MOCSP, an oracle version of MCSP that takes as input a Boolean function $f$, a size threshold $s$, and oracle Boolean functions $f_1, ..., f_t$, and determines whether there is an oracle circuit of size at most $s$ that computes $f$ when given access to $f_1, ... , f_t$. We prove that MOCSP is $NP$-complete under non-uniform $AC^0$ many-one reductions as well as (uniform) $ZPP$ truth table reductions. We also observe that improving this $ZPP$ reduction to a deterministic polynomial-time reduction requires showing $EXP \neq ZPP$ (using theorems of Hitchcock and Pavan [17] and Murray and Williams [22]). Optimistically, these MOCSP results could be a first step towards $NP$-hardness results for MCSP. At the very least, we believe MOCSP clarifies the barriers towards proving hardness for MCSP and provides a useful "testing ground" for questions about MCSP.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/021"><span class="datestr">at February 19, 2019 06:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2019/020">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2019/020">TR19-020 |  On Tseitin formulas, read-once branching programs and treewidth | 

	Ludmila Glinskih, 

	Dmitry Itsykson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on an $n\times n$ grid graph has size at least $2^{\Omega(n)}$. Then using the Excluded Grid Theorem by Robertson and Seymour we show that for arbitrary graph $G(V,E)$ any nondeterministic read-once branching program that computes a satisfiable Tseitin formula based on $G$ has size at least $2^{\Omega(tw(G)^\delta)}$ for all $\delta &lt;1/36$, where $tw(G)$ is the treewidth of $G$ (for planar graphs and some other classes of graphs the statement holds for $\delta=1$). We also show an upper bound $O(|E| 2^{pw(G)})$, where $pw(G)$ is the pathwidth of $G$.

We apply the mentioned results in the analysis of the complexity of derivation in the proof system $OBDD(\land, reordering)$ and show that any $OBDD(\land, reordering)$-refutation of an unsatisfiable Tseitin formula based on a graph $G$ has size at least $2^{\Omega(tw(G)^\delta)}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2019/020"><span class="datestr">at February 19, 2019 06:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-6555947.post-267883685398120378">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/suresh.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://feedproxy.google.com/~r/TheGeomblog/~3/5TqtLogn5Gg/openai-ai-threats-and-norm-building-for.html">OpenAI, AI threats, and norm-building for responsible (data) science</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
All of twitter is .... atwitter?... over the <a href="https://blog.openai.com/better-language-models/">OpenAI announcement</a> and partial non-release of code/documentation for a language model that purports to generate realistic-sounding text from simple prompts. The system actually addresses many NLP tasks, but the one that's drawing the most attention is the deepfakes-like generation of plausible news copy (<a href="https://blog.openai.com/better-language-models/#sample3">here's one sample</a>).<br /><br />Most consternation is over the rapid PR buzz around the announcement, including somewhat breathless headlines (that OpenAI is not responsible for) like<br /><br /><blockquote class="tr_bq"><a href="https://techcrunch.com/2019/02/17/openai-text-generator-dangerous/">OpenAI built a text generator so good, it’s considered too dangerous to release</a></blockquote>or<br /><blockquote class="tr_bq"><a href="https://arstechnica.com/information-technology/2019/02/researchers-scared-by-their-own-work-hold-back-deepfakes-for-text-ai/">Researchers, scared by their own work, hold back “deepfakes for text” AI</a></blockquote>There are concerns that OpenAI is overhyping solid but incremental work, that they're disingenuously allowing for overhyped coverage in the way they released the information, or worse that they're deliberately controlling hype as a publicity stunt.<br /><br />I have nothing useful to add to the discussion above: indeed, see posts by <a href="https://anima-ai.org/2019/02/18/an-open-and-shut-case-on-openai/">Anima Anandkumar,</a> <a href="https://towardsdatascience.com/should-i-open-source-my-model-1c109188b164">Rob Munro</a>, <a href="http://approximatelycorrect.com/2019/02/17/openai-trains-language-model-mass-hysteria-ensues/">Zachary Lipton</a>  and <a href="https://medium.com/@lowe.ryan.t/openais-gpt-2-the-model-the-hype-and-the-controversy-1109f4bfd5e8?sk=bc319cebc22fe0459574544828c84c6d">Ryan Lowe</a> for a comprehensive discussion of the issues relating to OpenAI.  Jack Clark from OpenAI has been engaging in a lot of twitter discussion on this as well.<br /><br />But what I do want to talk about is the larger issues around responsible science that this kerfuffle brings up. Caveat, as Margaret Mitchell puts it in this searing thread.<br /><blockquote class="twitter-tweet"><div lang="en" dir="ltr">It's really hard to watch the GPT-2 conversations unfold like so much else in tech. 1/</div>— MMitchell (@mmitchell_ai) <a href="https://twitter.com/mmitchell_ai/status/1097626427048964098?ref_src=twsrc%5Etfw">February 18, 2019</a></blockquote><br />To understand the kind of "norm-building" that needs to happen here, let's look at two related domains.<br /><br />In computer security, there's a fairly well-established model for finding weaknesses in systems. An exploit is discovered, the vulnerable entity is given a chance to fix it, and then the exploit is revealed , often simultaneously with patches that rectify it. Sometimes the vulnerability isn't easily fixed (see <a href="https://meltdownattack.com/">Meltdown and Spectre</a>). But it's still announced.<br /><br />A defining characteristic of security exploits is that they are targeted, specific and usually suggest a direct patch. The harms might be theoretical, but are still considered with as much seriousness as the exploit warrants.<br /><br />Let's switch to a different domain: biology. Starting from the sequencing of the human genome through the <a href="https://allofus.nih.gov/">million-person precision medicine project </a>to CRISPR and cloning babies, genetic manipulation has provided both invaluable technology for curing disease as well as grave ethical concerns about misuse of the technology. And professional organizations as well as the NIH have (sometimes slowly) risen to the challenge of articulating norms around the use and misuse of such technology.<br /><br />Here, the harms are often more diffuse, and the harms are harder to separate from the benefits. But the harm articulation is often focused on the individual patient, especially given the shadow of abuse that darkens the history of medicine.<br /><br />The harms with various forms of AI/ML technology are myriad and diffuse. They can cause structural damage to society - in the concerns over bias, the ways in which automation affects labor, the way in which fake news can erode trust and a common frame of truth, and so many others - and they can cause direct harm to individuals. And the scale at which these harms can happen is immense.<br /><br />So where are the professional groups, the experts in thinking about the risks of democratization of ML, and all the folks concerned about the harms associated with AI tech? Why don't we have the equivalent of the <a href="https://en.wikipedia.org/wiki/Asilomar_Conference_on_Recombinant_DNA">Asilomar conference on recombinant DNA</a>?<br /><br />I appreciate that OpenAI has at least raised the issue of thinking through the ethical ramifications of releasing technology. But as the furore over their decision has shown, no single imperfect actor can really claim to be setting the guidelines for ethical technology release, and "starting the conversation" doesn't count when (again as Margaret Mitchell points out) these kinds of discussions have been going on in different settings for many years already.<br /><br />Ryan Lowe suggests workshops at major machine learning conferences. That's not a bad idea. But it will attract the people who go to machine learning conferences. It won't bring in the journalists, the people getting SWAT'd (and one case <a href="https://en.wikipedia.org/wiki/2017_Wichita_swatting">killed</a>) by fake news, the women being harassed by trolls online with deep-fake porn images. <br /><br />News is driven by news cycles. Maybe OpenAI's announcement will lead to us thinking more about issues of responsible data science. But let's not pretend these are new, or haven't been studied for a long time, or need to have a discussion "started".<br /><br /><br /><div class="feedflare">
<a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=5TqtLogn5Gg:gbrBsRDQ09k:yIl2AUoC8zA"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=yIl2AUoC8zA" border="0" /></a> <a href="http://feeds.feedburner.com/~ff/TheGeomblog?a=5TqtLogn5Gg:gbrBsRDQ09k:63t7Ie-LG7Y"><img src="http://feeds.feedburner.com/~ff/TheGeomblog?d=63t7Ie-LG7Y" border="0" /></a>
</div><img width="1" alt="" src="http://feeds.feedburner.com/~r/TheGeomblog/~4/5TqtLogn5Gg" height="1" /></div>







<p class="date">
by Suresh Venkatasubramanian (noreply@blogger.com) <a href="http://feedproxy.google.com/~r/TheGeomblog/~3/5TqtLogn5Gg/openai-ai-threats-and-norm-building-for.html"><span class="datestr">at February 19, 2019 04:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
