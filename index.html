<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Ittai Abraham</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="403: forbidden">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at January 20, 2020 12:22 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1295">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2020/01/19/prize-nominations-relevant-to-tcs-due-on-april-1/">Prize nominations relevant to TCS: due on April 1</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Breakthrough Prize committee is now accepting nominations for the <strong>Breakthrough Prize</strong> as well as <strong>New Horizons Prizes</strong> in Mathematics. The New Horizons Prizes are awarded to early-career researchers (Ph.D. within the last 10 years) who have already produced important work. In addition, for the first time, nominations will be taken for the <strong>Maryam Mirzakhani New Frontiers Prize</strong> – an annual $50,000 award that will be presented to early-career women mathematicians who have completed their PhDs within the previous two years.</p>
<p>Further information is available at <a href="https://breakthroughprize.org/Rules/3" rel="nofollow">https://breakthroughprize.org/Rules/3</a>. Nominations for 2021 are due on April 1, 2020.</p>
<p>Please consider nominating deserving candidates. The task of nominating someone for a high-profile award can be daunting, but the CATCS is available to help. Please contact us if you need help with preparing a nomination.</p>
<p> </p></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2020/01/19/prize-nominations-relevant-to-tcs-due-on-april-1/"><span class="datestr">at January 20, 2020 03:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06436">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06436">On Visibility Graphs of Convex Fans and Terrains</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Silva:Andr=eacute=_C=.html">André C. Silva</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06436">PDF</a><br /><b>Abstract: </b>For two points in the closure of a simple polygon $P$, we say that they see
each other in $P$ if the line segment uniting them does not intersect the
exterior of $P$. The visibility graph of $P$ is the graph whose vertex set is
the vertex set of $P$ and two vertices are joined by an edge if they see each
other in $P$.
</p>
<p>The characterization of visibility graphs has been an open problem for
decades, and a significant effort has been made to characterize visibility
graphs of restricted polygon classes. Among them is the convex fan: a simple
polygon with a convex vertex (i.e. whose internal angle in less than 180
degrees) that sees every other point in the closure of the polygon (often
called kernel vertex). We show that visibility graphs of convex fans are
equivalent to visibility graphs of terrains with the addition of a universal
vertex, that is, a vertex that is adjacent to every other vertex.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06436"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06422">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06422">An efficient sampling algorithm for difficult tree pairs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cleary:Sean.html">Sean Cleary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maio:Roland.html">Roland Maio</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06422">PDF</a><br /><b>Abstract: </b>It is an open question whether there exists a polynomial-time algorithm for
computing the rotation distances between pairs of extended ordered binary
trees. The problem of computing the rotation distance between an arbitrary pair
of trees, (S, T), can be efficiently reduced to the problem of computing the
rotation distance between a difficult pair of trees (S', T'), where there is no
known first step which is guaranteed to be the beginning of a minimal length
path. Of interest, therefore, is how to sample such difficult pairs of trees of
a fixed size. We show that it is possible to do so efficiently, and present
such an algorithm that runs in time $O(n^4)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06422"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06407">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06407">Counting difficult tree pairs with respect to the rotation distance problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cleary:Sean.html">Sean Cleary</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Maio:Roland.html">Roland Maio</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06407">PDF</a><br /><b>Abstract: </b>Rotation distance between rooted binary trees is the minimum number of simple
rotations needed to transform one tree into the other. Computing the rotation
distance between a pair of rooted trees can be quickly reduced in cases where
there is a common edge between the trees, or where a single rotation introduces
a common edge. Tree pairs which do not have such a reduction are difficult tree
pairs, where there is no generally known first step. Here, we describe efforts
to count and estimate the number of such difficult tree pairs, and find that
the fraction decreases exponentially fast toward zero. We also describe how
knowing the number of distinct instances of the rotation distance problem is a
helpful factor in making the computations more feasible.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06407"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06316">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06316">Grover's Algorithm and Many-Valued Quantum Logic</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Samuel Hunt, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gadouleau:Maximilien.html">Maximilien Gadouleau</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06316">PDF</a><br /><b>Abstract: </b>As the engineering endeavour to realise quantum computers progresses, we
consider that such machines need not rely on binary as their de facto unit of
information. We investigate Grover's algorithm under a generalised quantum
circuit model, in which the information and transformations can be expressed in
any arity, and analyse the structural and behavioural properties while
preserving the semantics; namely, searching for the unique preimage to an
output a function. We conclude by demonstrating that the generalised procedure
retains $O(\sqrt{N})$ time complexity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06316"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06305">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06305">How fast do quantum walks mix?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakraborty:Shantanav.html">Shantanav Chakraborty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Luh:Kyle.html">Kyle Luh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Roland:J=eacute=r=eacute=mie.html">Jérémie Roland</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06305">PDF</a><br /><b>Abstract: </b>The fundamental problem of sampling from the limiting distribution of quantum
walks on networks, known as \emph{mixing}, finds widespread applications in
several areas of quantum information and computation. Of particular interest in
most of these applications, is the minimum time beyond which the instantaneous
probability distribution of the quantum walk remains close to this limiting
distribution, known as the \emph{quantum mixing time}. However this quantity is
only known for a handful of specific networks. In this letter, we prove an
upper bound on the quantum mixing time for \emph{almost all networks}, i.e.\
the fraction of networks for which our bound holds, goes to one in the
asymptotic limit. To this end, using several results in random matrix theory,
we find the quantum mixing time of Erd\"os-Renyi random networks: networks of
$n$ nodes where each edge exists with probability $p$ independently. For
example for dense random networks, where $p$ is a constant, we show that the
quantum mixing time is $\mathcal{O}\left(n^{3/2 + o(1)}\right)$. Besides
opening avenues for the analytical study of quantum dynamics on random
networks, our work could find applications beyond quantum information
processing. Owing to the universality of Wigner random matrices, our results on
the spectral properties of random graphs hold for general classes of random
matrices that are ubiquitous in several areas of physics. In particular, our
results could lead to novel insights into the equilibration times of isolated
quantum systems defined by random Hamiltonians, a foundational problem in
quantum statistical mechanics.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06305"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06169">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06169">Lower bounds for the maximum number of runners that cause loneliness, and its application to Isolation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chermakani:Deepak_Ponvel.html">Deepak Ponvel Chermakani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06169">PDF</a><br /><b>Abstract: </b>We consider (n+1) runners with given constant unique integer speeds running
along the circumference of a circle whose circumferential length is one, and
all runners starting from the same point. We define and give lower bounds to a
first problem PMAX of finding, for every runner r, the maximum number of
runners that can be simultaneously separated from runner r by a distance of
atleast d. For d=1/(2^(floor(lg(n)))), a lower bound for PMAX is ( n -
((n-1)/floor(lg(n))) ), which makes the fraction of simultaneously separated
runners tend to 1 as n tends to infinity. Next, we define and give upper bounds
to a second problem ISOLATE of finding, for every runner r, the minimum number
of steps needed to isolate r, assuming that the runners that can be
simultaneously separated from r by atleast d, are removed at each step. For
d=1/(2^(floor(lg(n)))), an upper bound for ISOLATE is ( lg(n -
1)/lg(floor(lg(n))) ).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06169"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06159">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06159">A New Fairness Model based on User's Objective for Multi-user Multi-processor Online Scheduling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwibedy:Debasis.html">Debasis Dwibedy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Rakesh.html">Rakesh Mohanty</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06159">PDF</a><br /><b>Abstract: </b>Resources of a multi-user system in multi-processor online scheduling are
shared by competing users in which fairness is a major performance criterion
for resource allocation. Fairness ensures equality in resource sharing among
the users. According to our knowledge, fairness based on the user's objective
has neither been comprehensively studied nor a formal fairness model has been
well defined in the literature. This motivates us to explore and define a new
model to ensure algorithmic fairness with quantitative performance measures
based on optimization of the user's objective. In this paper, we propose a new
model for fairness in Multi-user Multi-processor Online Scheduling
Problem(MUMPOSP). We introduce and formally define quantitative fairness
measures based on user's objective by optimizing makespan for individual user
in our proposed fairness model. We also define the unfairness of deprived users
and absolute fairness of an algorithm. We obtain lower bound results for the
absolute fairness for m identical machines with equal length jobs. We show that
our proposed fairness model can serve as a framework for measuring algorithmic
fairness by considering various optimality criteria such as flow time and sum
of completion times.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06159"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06058">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06058">Understanding the Power of Persistence Pairing via Permutation Test</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cai:Chen.html">Chen Cai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yusu.html">Yusu Wang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06058">PDF</a><br /><b>Abstract: </b>Recently many efforts have been made to incorporate persistence diagrams, one
of the major tools in topological data analysis (TDA), into machine learning
pipelines. To better understand the power and limitation of persistence
diagrams, we carry out a range of experiments on both graph data and shape
data, aiming to decouple and inspect the effects of different factors involved.
To this end, we also propose the so-called \emph{permutation test} for
persistence diagrams to delineate critical values and pairings of critical
values. For graph classification tasks, we note that while persistence pairing
yields consistent improvement over various benchmark datasets, it appears that
for various filtration functions tested, most discriminative power comes from
critical values. For shape segmentation and classification, however, we note
that persistence pairing shows significant power on most of the benchmark
datasets, and improves over both summaries based on merely critical values, and
those based on permutation tests. Our results help provide insights on when
persistence diagram based summaries could be more suitable.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06058"><span class="datestr">at January 20, 2020 02:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06053">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06053">Extending drawings of complete graphs into arrangements of pseudocircles</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arroyo:Alan.html">Alan Arroyo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Richter:R=_Bruce.html">R. Bruce Richter</a>, Matthew Sunohara <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06053">PDF</a><br /><b>Abstract: </b>Motivated by the successful application of geometry to proving the
Harary-Hill Conjecture for "pseudolinear" drawings of $K_n$, we introduce
"pseudospherical" drawings of graphs. A spherical drawing of a graph $G$ is a
drawing in the unit sphere $\mathbb{S}^2$ in which the vertices of $G$ are
represented as points---no three on a great circle---and the edges of $G$ are
shortest-arcs in $\mathbb{S}^2$ connecting pairs of vertices. Such a drawing
has three properties: every edge $e$ is contained in a simple closed curve
$\gamma_e$ such that the only vertices in $\gamma_e$ are the ends of $e$; if
$e\ne f$, then $\gamma_e\cap\gamma_f$ has precisely two crossings; and if $e\ne
f$, then $e$ intersects $\gamma_f$ at most once, either a crossing or an end of
$e$. We use these three properties to define a pseudospherical drawing of $G$.
</p>
<p>Our main result is that, for the complete graph, these three properties are
equivalent to the same three properties but with "exactly two crossings"
replaced by "at most two crossings".
</p>
<p>The proof requires a result in the geometric transversal theory of
arrangements of pseudocircles. This is proved using the surprising result that
the absence of special arcs (coherent spirals) in an arrangement of simple
closed curves characterizes the fact that any two curves in the arrangement
have at most two crossings.
</p>
<p>Our studies provide the necessary ideas for exhibiting a drawing of $K_{10}$
that has no extension to an arrangement of pseudocircles and a drawing of $K_9$
that does extend to an arrangement of pseudocircles, but no such extension has
all pairs of pseudocircles crossing twice.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06053"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.06005">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.06005">Elements of Scheduling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lenstra:Jan_Karel.html">Jan Karel Lenstra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shmoys:David_B=.html">David B. Shmoys</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.06005">PDF</a><br /><b>Abstract: </b>In the winter of 1976, Alexander Rinnooy Kan and Jan Karel Lenstra defended
their PhD theses at the University of Amsterdam. Gene Lawler was on their
committees. It was a natural idea to turn the theses into a textbook on
scheduling. They set out to compile a survey with Ron Graham (1979), but
progress on the book was hampered by the many research opportunities offered by
the field. After David Shmoys joined the team in the mid 1980's, several
chapters were drafted, and the survey was rewritten (1993). Gene passed away in
1994. Colleagues were asked to contribute chapters or to complete existing
drafts. However, by the turn of the century the project was losing its
momentum, and finite convergence to completion fell beyond our reach.
</p>
<p>Over the years, several chapters have been used in the classroom. We continue
to receive requests from colleagues who look for a text on the elements of
scheduling at an advanced undergraduate or early graduate level. This document
is a compilation of what currently exists. We have made a marginal effort in
patching it up at some places but is essentially what was written long ago. We
did make an attempt to include most of the citations in the bibliography.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.06005"><span class="datestr">at January 20, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/005">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/005">TR20-005 |  Hardness Characterisations and Size-Width Lower Bounds for QBF Resolution | 

	Olaf Beyersdorff, 

	Joshua Blinkhorn, 

	Meena Mahajan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We provide a tight characterisation of proof size in resolution for quantified Boolean formulas (QBF) by circuit complexity. Such a characterisation was previously obtained for a hierarchy of QBF Frege systems (Beyersdorff &amp; Pich, LICS 2016), but leaving open the most important case of QBF resolution. Different from the Frege case, our characterisation uses a new version of decision lists as its circuit model, which is stronger than the CNFs the system works with. Our decision list model is well suited to compute countermodels for QBFs.

Our characterisation works for both Q-Resolution and QU-Resolution, which we show to be polynomially equivalent for QBFs of bounded quantifier alternation.

Using our characterisation we obtain a size-width relation for QBF resolution in the spirit of the celebrated result for propositional resolution (Ben-Sasson &amp; Wigderson, J. ACM 2001). However, our result is not just a replication of the propositional relation - intriguingly ruled out  for QBF  in previous research (Beyersdorff et al., ACM ToCL 2018) - but shows a different dependence between size, width, and quantifier complexity.

We demonstrate that our new technique elegantly reproves known QBF hardness results and unifies previous lower-bound techniques in the QBF domain.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/005"><span class="datestr">at January 19, 2020 10:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.05976">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.05976">Generalised Pattern Matching Revisited</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Bartłomiej Dudek, Paweł Gawrychowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Starikovskaya:Tatiana.html">Tatiana Starikovskaya</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.05976">PDF</a><br /><b>Abstract: </b>In the problem of $\texttt{Generalised Pattern Matching}\ (\texttt{GPM})$
[STOC'94, Muthukrishnan and Palem], we are given a text $T$ of length $n$ over
an alphabet $\Sigma_T$, a pattern $P$ of length $m$ over an alphabet
$\Sigma_P$, and a matching relationship $\subseteq \Sigma_T \times \Sigma_P$,
and must return all substrings of $T$ that match $P$ (reporting) or the number
of mismatches between each substring of $T$ of length $m$ and $P$ (counting).
In this work, we improve over all previously known algorithms for this problem
for various parameters describing the input instance:
</p>
<p>* $\mathcal{D}\,$ being the maximum number of characters that match a fixed
character,
</p>
<p>* $\mathcal{S}\,$ being the number of pairs of matching characters,
</p>
<p>* $\mathcal{I}\,$ being the total number of disjoint intervals of characters
that match the $m$ characters of the pattern $P$.
</p>
<p>At the heart of our new deterministic upper bounds for $\mathcal{D}\,$ and
$\mathcal{S}\,$ lies a faster construction of superimposed codes, which solves
an open problem posed in [FOCS'97, Indyk] and can be of independent interest.
</p>
<p>To conclude, we demonstrate first lower bounds for $\texttt{GPM}$. We start
by showing that any deterministic or Monte Carlo algorithm for $\texttt{GPM}$
must use $\Omega(\mathcal{S})$ time, and then proceed to show higher lower
bounds for combinatorial algorithms. These bounds show that our algorithms are
almost optimal, unless a radically new approach is developed.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.05976"><span class="datestr">at January 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.05921">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.05921">Generalized Fitch Graphs III: Symmetrized Fitch maps and Sets of Symmetric Binary Relations that are explained by Unrooted Edge-labeled Trees</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hellmuth:Marc.html">Marc Hellmuth</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Seemann:Carsten_R=.html">Carsten R. Seemann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stadler:Peter_F=.html">Peter F. Stadler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.05921">PDF</a><br /><b>Abstract: </b>Binary relations derived from labeled rooted trees play an import role in
mathematical biology as formal models of evolutionary relationships. The
(symmetrized) Fitch relation formalizes xenology as the pairs of genes
separated by at least one horizontal transfer event. As a natural
generalization, we consider symmetrized Fitch maps, that is, symmetric maps
$\varepsilon$ that assign a subset of colors to each pair of vertices in $X$
and that can be explained by a tree $T$ with edges that are labeled with
subsets of colors in the sense that the color $m$ appears in $\varepsilon(x,y)$
if and only if $m$ appears in a label along the unique path between $x$ and $y$
in $T$. We first give an alternative characterization of the monochromatic case
and then give a characterization of symmetrized Fitch maps in terms of
compatibility of a certain set of quartets. We show that recognition of
symmetrized Fitch maps is NP-complete but FPT in general. In the restricted
case where $|\varepsilon(x,y)|\leq 1$ the problem becomes polynomial, since
such maps coincide with class of monochromatic Fitch maps whose
graph-representations form precisely the class of complete multi-partite
graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.05921"><span class="datestr">at January 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.05671">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.05671">Faster STR-EC-LCS Computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yamada:Kohei.html">Kohei Yamada</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Yuto.html">Yuto Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannai:Hideo.html">Hideo Bannai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Takeda:Masayuki.html">Masayuki Takeda</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.05671">PDF</a><br /><b>Abstract: </b>The longest common subsequence (LCS) problem is a central problem in
stringology that finds the longest common subsequence of given two strings $A$
and $B$. More recently, a set of four constrained LCS problems (called
generalized constrained LCS problem) were proposed by Chen and Chao [J. Comb.
Optim, 2011]. In this paper, we consider the substring-excluding constrained
LCS (STR-EC-LCS) problem. A string $Z$ is said to be an STR-EC-LCS of two given
strings $A$ and $B$ excluding $P$ if, $Z$ is one of the longest common
subsequences of $A$ and $B$ that does not contain $P$ as a substring. Wang et
al. proposed a dynamic programming solution which computes an STR-EC-LCS in
$O(mnr)$ time and space where $m = |A|, n = |B|, r = |P|$ [Inf. Process. Lett.,
2013]. In this paper, we show a new solution for the STR-EC-LCS problem. Our
algorithm computes an STR-EC-LCS in $O(n|\Sigma| + (L+1)(m-L+1)r)$ time where
$|\Sigma| \leq \min\{m, n\}$ denotes the set of distinct characters occurring
in both $A$ and $B$, and $L$ is the length of the STR-EC-LCS. This algorithm is
faster than the $O(mnr)$-time algorithm for short/long STR-EC-LCS (namely, $L
\in O(1)$ or $m-L \in O(1)$), and is at least as efficient as the $O(mnr)$-time
algorithm for all cases.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.05671"><span class="datestr">at January 19, 2020 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.05583">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.05583">Compressing Permutation Groups into Grammars and Polytopes. A Graph Embedding Approach</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jaffke:Lars.html">Lars Jaffke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Oliveira:Mateus_de_Oliveira.html">Mateus de Oliveira Oliveira</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tiwary:Hans_Raj.html">Hans Raj Tiwary</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.05583">PDF</a><br /><b>Abstract: </b>It can be shown that each permutation group $G \sqsubseteq S_n$ can be
embedded, in a well defined sense, in a connected graph with $O(n+|G|)$
vertices. Some groups, however, require much fewer vertices. For instance,
$S_n$ itself can be embedded in the $n$-clique $K_n$, a connected graph with n
vertices. In this work, we show that the minimum size of a context-free grammar
generating a finite permutation group $G \sqsubseteq S_n$ can be upper bounded
by three structural parameters of connected graphs embedding $G$: the number of
vertices, the treewidth, and the maximum degree. More precisely, we show that
any permutation group $G \sqsubseteq S_n$ that can be embedded into a connected
graph with $m$ vertices, treewidth k, and maximum degree $\Delta$, can also be
generated by a context-free grammar of size $2^{O(k\Delta\log\Delta)}\cdot
m^{O(k)}$. By combining our upper bound with a connection between the extension
complexity of a permutation group and the grammar complexity of a formal
language, we also get that these permutation groups can be represented by
polytopes of extension complexity $2^{O(k \Delta\log \Delta)}\cdot m^{O(k)}$.
The above upper bounds can be used to provide trade-offs between the index of
permutation groups, and the number of vertices, treewidth and maximum degree of
connected graphs embedding these groups. In particular, by combining our main
result with a celebrated $2^{\Omega(n)}$ lower bound on the grammar complexity
of the symmetric group $S_n$ we have that connected graphs of treewidth
$o(n/\log n)$ and maximum degree $o(n/\log n)$ embedding subgroups of $S_n$ of
index $2^{cn}$ for some small constant $c$ must have $n^{\omega(1)}$ vertices.
This lower bound can be improved to exponential on graphs of treewidth
$n^{\varepsilon}$ for $\varepsilon&lt;1$ and maximum degree $o(n/\log n)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.05583"><span class="datestr">at January 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.05564">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.05564">Simplification of Indoor Space Footprints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kim:Joon=Seok.html">Joon-Seok Kim</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wenk:Carola.html">Carola Wenk</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.05564">PDF</a><br /><b>Abstract: </b>Simplification is one of the fundamental operations used in geoinformation
science (GIS) to reduce size or representation complexity of geometric objects.
Although different simplification methods can be applied depending on one's
purpose, a simplification that many applications employ is designed to preserve
their spatial properties after simplification. This article addresses one of
the 2D simplification methods, especially working well on human-made structures
such as 2D footprints of buildings and indoor spaces. The method simplifies
polygons in an iterative manner. The simplification is segment-wise and takes
account of intrusion, extrusion, offset, and corner portions of 2D structures
preserving its dominant frame.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.05564"><span class="datestr">at January 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2001.05553">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2001.05553">Exponential quantum communication reductions from generalizations of the Boolean Hidden Matching problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Doriguello:Jo=atilde=o_F=.html">João F. Doriguello</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Montanaro:Ashley.html">Ashley Montanaro</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2001.05553">PDF</a><br /><b>Abstract: </b>In this work we revisit the Boolean Hidden Matching communication problem,
which was the first communication problem in the one-way model to demonstrate
an exponential classical-quantum communication separation. In this problem,
Alice's bits are matched into pairs according to a partition that Bob holds.
These pairs are compressed using a Parity function and it is promised that the
final bit-string is equal either to another bit-string Bob holds, or its
complement. The problem is to decide which case is the correct one. Here we
generalize the Boolean Hidden Matching problem by replacing the parity function
with an arbitrary function $f$. Efficient communication protocols are presented
depending on the sign-degree of $f$. If its sign-degree is less than or equal
to 1, we show an efficient classical protocol. If its sign-degree is less than
or equal to $2$, we show an efficient quantum protocol. We then completely
characterize the classical hardness of all symmetric functions $f$ of
sign-degree greater than or equal to $2$, except for one family of specific
cases. We also prove, via Fourier analysis, a classical lower bound for any
function $f$ whose pure high degree is greater than or equal to $2$. Similarly,
we prove, also via Fourier analysis, a quantum lower bound for any function $f$
whose pure high degree is greater than or equal to $3$. These results give a
large family of new exponential classical-quantum communication separations.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2001.05553"><span class="datestr">at January 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/01/18/when-does-2sat">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/01/18/when-does-2sat.html">When does 2SAT have an integral relaxation?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In the <a href="https://en.wikipedia.org/wiki/2-satisfiability">2-satisfiability problem</a>, or 2SAT, the input is a system of constraints between pairs of Boolean variables, and the problem is to find a truth assignment satisfying all the constraints. Although the usual formulation writes the constraints as disjunctions (Boolean or), it’s convenient and equivalent to use implications instead, where each side of an implication can be either one of the variables or its negation. If you encode the variables as numbers, with  for true and  for false, then the negation of a variable  is  and the implication  can be encoded as the linear inequality . If we forget the restriction that the values are  or , this system of inequalities defines a convex polytope, which can be thought of as a <a href="https://en.wikipedia.org/wiki/Linear_programming_relaxation">relaxation</a> of the given 2SAT problem. Each solution to the 2SAT problem corresponds to a vertex of this polytope but there might be other vertices as well, with fractional coordinates. We don’t want those; it’s more useful to have a polytope <a href="https://en.wikipedia.org/wiki/Integral_polytope">all of whose coordinates are integers</a>, coming from solutions to the underlying 2SAT problem. When does this happen (without adding extra inequalities)?</p>

<p>I’m pretty sure the answer has been known, at least implicitly, for a long time, and that there are no new ideas in the rest of this post. See e.g. the answer to <a href="https://cstheory.stackexchange.com/a/46188/95">this very closely related question on relaxations of the vertex cover problem</a> and note that vertex cover can be formulated as 2SAT, with a variable per vertex and two constraints per edge of the input graph. But when I looked for it, I found it difficult to find references that give the answer explicitly. So here it is. The following conditions are equivalent:</p>

<ul>
  <li>The given 2SAT instance has an integral relaxation.</li>
  <li>The given 2SAT instance has two solutions that are the complements of each other (each variable is true in one of the solutions and false in the other).</li>
  <li>The compatibility graph of the given 2SAT instance is bipartite.</li>
</ul>

<p>Here, the compatibility graph is an undirected graph defined by Feder in “Network Flow and 2-Satisfiability” (<em>Algorithmica</em> 1994). It has a vertex for each literal (a variable or its negation). The two vertices for a variable and its negation are connected by an edge, called a “trivial edge”. Additionally,
for each implication , the two literals  and  cannot both be true, and we add an edge between them.</p>

<p>If the compatibility graph is bipartite, two-color it, make the vertices of one color be true, and make the vertices of the other color be false. Then this gives a solution to the 2SAT instance whose complement is also a solution. So the third condition implies the second condition.</p>

<p>The relaxation of any 2SAT instance contains the point whose coordinates all equal , and if the given instance has an integral relaxation then this point can be represented as a weighted average of integer solutions. An odd cycle in the compatibility graph would prevent that from being possible. For any point in the relaxation, and any literal, we consider the value of the literal to be either its coordinate value (if it represents a variable) or one minus that value (if it represents a negated variable). If some cycle has odd length , then each integer point in the weighted average could only have total value at most  on the literals of the cycle, so their weighted average would also be at most , less than the cycle’s total value of  in the all- solution. So the first condition implies the third condition.</p>

<p>Finally, suppose that there are two complementary solutions, and flip the variables if necessary so that these are the all-false and all-true assignments to the variables. (This flipping simplifies the problem without changing any of the three conditions.) Consider any fractional solution , and construct from it a probability distribution on truth assignments as follows: choose a uniformly random number , set to true the variables whose coordinate value is at least , and set to false the remaining variables.
All truth assignments generated in this way solve the 2SAT problem, because any violation of an implication constraint in the 2SAT problem would translate to a violation of the corresponding coordinate inequality constraint in the relaxation. The given fractional solution  is a weighted average of the resulting collection of 2SAT solutions, where the weight of a solution is the probability of generating it. Therefore, the second condition implies the first condition.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103507316629491293">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/01/18/when-does-2sat.html"><span class="datestr">at January 18, 2020 04:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4536">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4536">From shtetl to Forum</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Today I’m headed to the <a href="https://www.weforum.org/events/world-economic-forum-annual-meeting-2020">50th World Economic Forum in Davos</a>, where on Tuesday I’ll participate in a <a href="https://www.weforum.org/events/world-economic-forum-annual-meeting-2020/sessions/the-quantum-potential">panel discussion</a> on “The Quantum Potential” with Jeremy O’Brien of the quantum computing startup <a href="https://psiquantum.com/">PsiQuantum</a>, and will also host an ask-me-anything session about quantum computational supremacy and Google’s claim to have achieved it.</p>



<p>I’m well aware that this will be unlike any other conference I’ve ever attended: STOC or FOCS it ain’t.  As one example, also speaking on Tuesday—although not conflicting with my QC sessions—will be a real-estate swindler and reality-TV star who’s somehow (alas) the current President of the United States.  Yes, even while his impeachment trial in the Senate gets underway.  <em>Also</em> speaking on Tuesday, a mere hour and a half after him, will be TIME’s Person of the Year, 17-year-old climate activist Greta Thunberg.</p>



<p>In short, this Davos is shaping up to be an epic showdown between two diametrically opposed visions for the future of life on Earth.  And your humble blogger will be right there in the middle of it, to … uhh … explain how quantum computers can sample probability distributions that are classically intractable unless the polynomial hierarchy collapses to the third level.  I feel appropriately sheepish.</p>



<p>Since the experience will be so unusual for me, I’m planning to <strong>“live-blog Davos”</strong>: I’ll be updating this post, all week, with any strange new things that I see or learn.  As a sign of my devotion to you, my loyal readers, I’ll even clothespin my nose and attend Trump’s speech so I can write about it.</p>



<p>And Greta: on the off chance that you happen to read <em>Shtetl-Optimized</em>, let me treat you to a vegan lunch or dinner!  I’d like to try to persuade you of just how essential nuclear power will be to a carbon-free future.  Oh, and if it’s not too much trouble, I’d also like a selfie with you for this blog.  (Alas, a friend pointed out to me that it would probably be easier to meet Trump: unlike Greta, he won’t be swarmed with thousands of fans!)</p>



<p>Anyway, check back here throughout the week for updates.  And if you’re in Davos and would like to meet, please shoot me an email.  And please use the comment section to give me your advice, suggestions, well-wishes, requests, or important messages for me to fail to deliver to the “Davoisie” who run the world.</p>



<p><strong>Update (Jan. 19):</strong> So I’ve arrived in Kloosters, a village in the Swiss Alps close to Davos where I’ll be staying.  (All the hotels in Davos itself were booked by the time I checked.)</p>



<figure class="wp-block-image size-large"><img src="https://www.scottaaronson.com/blog/wp-content/uploads/2020/01/image.png" alt="" class="wp-image-4543" /></figure>



<p>I’d braced myself for the challenge of navigating three different trains through the Alps not knowing German.  In reality, it was like a hundred times easier than public transportation at home.  Every train arrived at the exact right second at the exact platform that was listed, bearing the exact right number, and there were clear visible signs strategically placed at exactly the places where anyone could get confused.  I’d entered Bizarro Opposite World.  I’m surely one of the more absentminded people on earth, as well as one of the more neurotic about being judged by bystanders if I ever admit to being lost, and it was nothing.</p>



<p>Snow!  Once a regular part of my life, now the first I’d seen in several years.  Partly because I now live in Texas, but also because even when we take the kids back to Pennsylvania for ChanuChrismaNewYears, it no longer snows like it did when I was a kid.  If you show my 2-year-old, Daniel, a picture of snow-covered wilderness, he calls it a “beach.”  Daniel’s soon-to-be 7-year-old sister still remembers snow from Boston, but the memory is rapidly fading.  I wonder for how many of the children of the 21st century will snow just be a thing from old books and movies, like typewriters of rotary phones.</p>



<p>The World Economic Forum starts tomorrow afternoon.  In the meantime, though, I thought I’d give an update not on the WEF itself, but on the inflight movie that I watched on my way here.</p>



<p>I watched <a href="https://www.imdb.com/title/tt2066051/">Rocketman</a>, the recent biopic/hagiography about Elton John, though as I watched I found that I kept making comparisons between Elton John and Greta Thunberg.</p>



<p>On the surface, these two <em>might</em> not seem to have a great deal of similarity.</p>



<p>But I gathered that they had this in common: while still teenagers, they saw a chance and they seized it.  And doing so involved taking inner turmoil and then succesfully externalizing it to the whole planet.  Making hundreds of millions of people feel the same emotions that they had felt.  If I’m being painfully honest (how often am I not?), that’s something I’ve always wanted to achieve and haven’t.</p>



<p>Of course, when some of the most intense and distinctive emotions you’ve ever felt revolved around the discovery of quantum query complexity lower bounds … yeah, it might be tough to find more people than could fill a room to relive <em>those</em> emotional journeys with you.  But a child’s joy at discovering numbers like Ackerman(100) (to say nothing of BB(100)), which are so incomprehensibly bigger than \( 9^{9^{9^{9^9}}} \) that I didn’t need to think twice about how many 9’s I put there?  Or the exasperation at those who, yeah, totally get that quantum computers aren’t known to give exponential speedups for NP-complete problems, that’s a really important clarification coming from the theory side, but still, let’s continue to base our entire business or talk or article around the presupposition that quantum computers <strong>do</strong> give exponential speedups for NP-complete problems?  Or even just the type of crush that comes with a ceaseless monologue about what an objectifying, misogynist pig you must be to experience it?  Maybe I could someday make people vicariously experience and understand <em>those</em> emotions–if I could only find the right words.</p>



<p>My point is, this is precisely what Greta did for the burgeoning emotion of existential terror about the Anthropocene—another emotion that’s characterized my over life since childhood.  Not that I ever figured out anything to do about it, with the exception of <a href="https://www.scottaaronson.com/blog/?p=278">Gore/Nader vote-swapping</a>.  By the standards of existential terrors, I consider this terror to be extraordinarily well-grounded.  If Steven Weinberg is scared, who among us has the right to be calm?</p>



<p>The obvious objection to Greta—why should anyone care what a histrionic teenager thinks about a complicated scientific field that thousands of people get PhDs in?—calls for a substantive answer.  So here’s mine.  Like many concerned citizens, I try to absorb some of the research on ocean warming or the collapse of ice sheets and the melting permafrost leading to even more warming or the collapse of ecosystems due to changes in rainfall or bushfires or climate migrations or whatever.  And whenever I do, I’m reminded of Richard Feynman’s remark, during the investigation of the Challenger disaster, that maybe it wasn’t all that interesting for the commission to spend its time reconstructing the exact details of which system caused which other system to malfunction at which millisecond, <strong>after the Space Shuttle had already started exploding.</strong>  The thing was hosed at that point.</p>



<p>Still, even after the 80s and 90s, there remained deep open questions about the eventual shape of the climate crisis, and foremost among them was: how do you get people to stop talking about this crisis in the language of intellectual hypotheticals and meaningless virtue-signalling gestures and “those crazy scientists, who knows what they’ll say tomorrow”?  How does one get people to revert to a more ancient language, the one that was used to win WWII for example, which speaks of courage and duty and heroism and defiance in the jaws of death?</p>



<p>Greta’s origin story—the one where the autistic girl spends months so depressed over climate inaction that she can’t eat or leave her room, until finally, no longer able to bear the psychic burden, she ditches school and carries a handmade protest sign to the front of the Swedish parliament—is not merely a prerequisite to a real contribution.  It <em>is</em> Greta’s real contribution (so far anyway), and by that I don’t mean to diminish it.  The idea was “trivial,” yes, but only in the sense that the wheel, Arabic numerals, or “personal computers will be important” were trivial ideas.  Greta modeled for the rest of the world how they, too, would probably feel about climate change were they able to sync up their lizard brains with their higher brains … and crucially, a substantial segment of the world was already primed to agree with her.  But it needed to see <em>one successful example</em> of a succesful sync between the science and the emotions appropriate to the science, as a crystal needs a seed.</p>



<p>The thesis of Rocketman is that Elton John’s great achievement was not only to invent a new character, but <em>actually to become that character</em>, since only by succesfully fusing the two could he touch the emotions of the masses.  In a similar way, Greta Thunberg’s great accomplishment of her short life has been to make herself into the human race’s first Greta Thunberg.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4536"><span class="datestr">at January 18, 2020 01:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=697">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2020/01/17/what-is-wrong-with-this/">What is wrong with this?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div class="wp-block-image"><figure class="aligncenter size-large"><img src="https://emanueleviola.files.wordpress.com/2020/01/xinfertilitygraph.png?w=350" alt="" class="wp-image-698" /></figure></div></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2020/01/17/what-is-wrong-with-this/"><span class="datestr">at January 17, 2020 06:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19151">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/01/17/amazing-zhengfeng-ji-anand-natarajan-thomas-vidick-john-wright-and-henry-yuen-proved-that-mip-re-and-thus-disproved-connes-1976-embedding-conjecture-and-provided-a-negative-answer-to-tsirelso/">Amazing: Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen proved that MIP* = RE and thus disproved Connes 1976 Embedding Conjecture, and provided a negative answer to Tsirelson’s problem.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A few days ago an <a href="https://arxiv.org/abs/2001.04383">historic 160-page paper with a very short title MIP*=RE</a> was uploaded to the arXive by Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen.  I am thankful to Dorit Aharonov and Alon Rosen for telling me about it. The paper simultaneously settles several major open problems in quantum computational complexity, mathematical foundations of quantum physics, and mathematics. Congratulations to Zhengfeng, Anand, Thomas, John, and Henry!</p>
<div class="embed-twitter">
<blockquote class="twitter-tweet">
<p lang="en" dir="ltr">MIP* = RE, by Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, Henry Yuen: <a href="https://t.co/2Mu8JwmEXj">https://t.co/2Mu8JwmEXj</a> . There is a multiple-entagled-quantum-provers proof system for the Halting Problem, and Connes' Embedding Conjecture is false.</p>
<p>— Ryan O'Donnell (@BooleanAnalysis) <a href="https://twitter.com/BooleanAnalysis/status/1216917564334448643?ref_src=twsrc%5Etfw">January 14, 2020</a></p></blockquote>
<p></p></div>
<p><span style="color: #ff0000;">A</span> <a href="https://twitter.com/BooleanAnalysis/status/1216917564334448643">tweet</a> by <span style="color: #ff0000;">Ryan</span></p>
<p class="title mathjax">The new paper dramatically improved the <a href="https://arxiv.org/abs/1904.05870">2019 resul</a>t by Anand Natarajan, and John Wright asserting that  “NEEXP in MIP*”.</p>
<p>In this post I will talk a little about two corners of this work and neglect many others:  I will describe a few conjectures about infinite groups related to the new result, and I will give a very gentle beginning-of-an-introduction to interactive proofs.  I will also give some useful links to papers, presentations and blog posts.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/01/boristsirelsonstudent.jpg"><img src="https://gilkalai.files.wordpress.com/2020/01/boristsirelsonstudent.jpg?w=181&amp;h=300" alt="" width="181" class="alignnone size-medium wp-image-19162" height="300" /></a></p>
<p><strong><span style="color: #ff0000;">Boris Tsirelson is one of my mathematical heroes. </span></strong><span style="color: #ff0000;">The new paper gives a negative answer to an important problem posed by Tsirelson. (Here is a <a href="https://www.iqoqi-vienna.at/en/blog/article/boris-tsirelson/?fbclid=IwAR1PrVvK0u5XmnFLLoPMzMN3x9rY1WIdp1wrYZ_yYPlqSGRpXDkollYTCR0">great interview</a> with Boris.)</span></p>
<h3>Resources</h3>
<p>My Qstate: a <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">master project</a> (Vidick’s memories of the road since Julia Kempe offered him the problem 14 years ago; with a lot of scientific content). Older related posts on My Qstate  <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">I</a>, <a href="https://mycqstate.wordpress.com/2017/01/16/quid-qpcp/">II,</a> <a href="https://mycqstate.wordpress.com/2014/03/03/workshop-on-quantum-games-and-protocols-at-the-simons/">III</a>.</p>
<p>A Notices AMS article by Vidick: <a href="https://www.ams.org/journals/notices/201910/rnoti-p1618.pdf">From Operator Algebras to Complexity Theory and Back</a>.</p>
<p>Shtetl Optimized: <a href="https://www.scottaaronson.com/blog/?p=4512">MIP*=RE;</a>  GLL (Ken Regan) H<a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/">alting Is Poly-Time Quantum Provable</a> ; Other posts on blogs: <a href="https://windowsontheory.org/2020/01/14/mipre-connes-embedding-conjecture-disproved/">WIT (Boaz Barak)</a>; <a href="https://blog.computationalcomplexity.org/2020/01/quantum-provers-to-infinity-and-beyond.html">CC</a> (Lance Fortnow); WN; Posts on an earlier 2019 result  MIP* contains NEEXP</p>
<p>Quanta Magazine: <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">An article by Kevin Hartnett about an earlier result MIP*=NEEXP</a>; An article about the new result.</p>
<p>Older posts here:  <a href="https://gilkalai.wordpress.com/2012/07/16/some-updates/">about Vidick- 2012 paper</a> (among various updates); a 2008 <a href="https://gilkalai.wordpress.com/2008/08/13/plans-and-updates/">post</a> mentioning sofic groups (among various updates);</p>
<p>Videotaped lectures: from our recent winter school Thomas Vidick on quantum protocols <a href="https://www.youtube.com/watch?v=cggnlw6uWi8&amp;list=PLTn74Qx5mPsS2dqTpEq_2zxq8kWBmPUfb&amp;index=7&amp;t=0s">Video 1</a>, <a href="https://www.youtube.com/watch?v=lkaEurX67ig&amp;list=PLTn74Qx5mPsS2dqTpEq_2zxq8kWBmPUfb&amp;index=11&amp;t=0s">Video 2</a>, <a href="https://www.youtube.com/watch?v=2Uxf9lHU128&amp;list=PLTn74Qx5mPsS2dqTpEq_2zxq8kWBmPUfb&amp;index=16&amp;t=0s">Video3</a>.</p>
<h2>A mathematical context (of one corner of the work) and wish list: stability theory for groups.</h2>
<p>(I am thankful to Alex Lubotzky for telling me about the algebra background.)</p>
<p class="title mathjax"><em>Links: <a href="https://arxiv.org/abs/1712.01052">Finitary approximations of groups and their applications,</a> by Andreas Thom, <a href="https://www.youtube.com/watch?v=1G_asY5rzrc">Andreas’ ICM 2018 videotaped lecture.</a> And a great video: <a href="https://www.youtube.com/watch?v=CPLbkkh7EYk">Best of Andreas Thom</a>. See also this paper <a href="https://arxiv.org/abs/1711.10238">Stability, cohomology vanishing, and non-approximable groups</a> by Marcus De Chiffre, Lev Glebsky, Alex Lubotzky, and Andreas Thom.</em></p>
<p>And (thanks Mikael de la Salle!) a recent Book by Gilles Pisier:<br />
<a href="https://www.math.tamu.edu/~pisier/TPCOS.pdf">Tensor products of <em>C*</em>-algebras and operator spaces; </a><a href="https://www.math.tamu.edu/~pisier/TPCOS.pdf">The Connes-Kirchberg problem</a></p>
<p>The assertion of Connes’ embedding conjecture refuted in the MIP*=RE paper would imply several (<a href="https://mathoverflow.net/a/350559/1532">outrageous</a> :)) stronger conjectures that are still open. One is the conjecture of Connes that every group is “hyperlinear.” Another famous conjecture (an affirmative answer to a question posed by Gromov) is  that every group is sofic. As sofic groups are hyperlinear we can now expect (ever more than before) that non-sofic and even non hyperlinear groups will be found. Here is a rough short explanation what these conjectures are about. <del>(Kirchberg’s conjecture, is another group theoretic question of this nature.)</del></p>
<p>Every finite group is a permutation group and is a linear group. This is not the case for infinite groups and there are various interesting notions of “approximately-permutation-group” (this is “sofic”) and “approximately linear” (this is called “hyperlinear”).</p>
<p>Given a group Γ we want to find a sequence of functions <img src="https://s0.wp.com/latex.php?latex=f_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f_n" class="latex" title="f_n" /></p>
<ol>
<li>From Γ to symmetric groups <img src="https://s0.wp.com/latex.php?latex=S_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S_n" class="latex" title="S_n" />,</li>
<li>or from Γ to the unitary groups <em>U(n).</em></li>
</ol>
<p>Such that asymptotically as <em>n</em> grows these functions are “almost homomorphisms” with respect to certain metrics <em>DIST</em> on <img src="https://s0.wp.com/latex.php?latex=S_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S_n" class="latex" title="S_n" /> or <img src="https://s0.wp.com/latex.php?latex=U%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="U(n)" class="latex" title="U(n)" /> respectively. This means that for every two elements</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=a%2Cb+%5Cin+%5CGamma&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="a,b \in \Gamma" class="latex" title="a,b \in \Gamma" />,</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=DIST%28+f_n%28ab%29%2C+f_n%28a%29f_n%28b%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="DIST( f_n(ab), f_n(a)f_n(b))" class="latex" title="DIST( f_n(ab), f_n(a)f_n(b))" /> tends to zero when <em>n</em> tends to infinity.</p>
<p>Now,</p>
<ol>
<li><strong>Sofic group</strong> refers to the normalized Hamming metric for symmetric groups.</li>
<li><strong>Hyperlinear group</strong> refers to metrics given by the normalized Hilbert-Schmidt norm on the unitary groups</li>
<li><strong>MF-groups, </strong>Again the unitary group but the operator norm this time.</li>
</ol>
<p>And there are various other metrics that were also considered. The assertion of the famous embedding conjecture by Connes on von-Neumann algebras (now refuted by the new result) implies that every group is hyperlinear.</p>
<p><strong><span style="color: #0000ff;">A remaining wish list: Find a non sofic group; find a non-hyperlinear group; <del>refute  Kirchberg’s conjecture (if it was not already refuted)</del>.</span></strong></p>
<h2>Interactive proofs and some computational complexity background.</h2>
<h3>P, NP, IP, MIP</h3>
<p><em>Links: here are slides of  a great talk by Yael Kalai: <a href="https://gilkalai.files.wordpress.com/2020/01/the-evolution-of-proofs-in-computer-science-yael-kalai.pptx">The evolution of proof in computer science;</a> an a <a href="https://windowsontheory.org/2012/09/18/the-evolution-of-proofs/">blog post on this topic</a> by Yael Kalai, and a <a href="https://gilkalai.wordpress.com/2018/01/06/yael-tauman-kalais-icm2018-paper-my-paper-and-cryptography/">post here</a> about Yael’s 2018 ICM paper and lecture.</em></p>
<p>A decision problem is in P if there is a polynomial time algorithm (in terms of the input size) to test if the answer is yes or no.  A decision problem is in NP if there is a proof for a YES answer that can be verified in a polynomial time.</p>
<p>Here are two examples: The question if  graph has a perfect matching is in P. The question if  graph has an Hamiltonian cycle  is in NP. If the answer is yes a prover can give a proof that requires the verifier a polynomial number of steps to verify.</p>
<p>IP is a complexity class based on a notion of interactive proof where, based on a protocol for questions and answers,  the prover can convince the verifier (with arbitrary high probability) that the answer is yes. Following a sequence of startling developments Adi Shamir proved that IP is quite a large complexity space P-space.  When we consider several non-interacting provers (two provers suffice) the computational power denoted by MIP is even larger: László Babai, Lance Fortnow, and Cartsen Lund proved that MIP=NEXP!  NEXP is the class of decision problems where if the answer is yes a prover can give a proof that requires the verifier (at most) an exponential number of steps to verify.</p>
<h3>Enters quantum computation and entanglement</h3>
<p>We replace the model of classical computation with quantum computation. Each of the two provers, Prover1 and Prover2, have access to separate sets of <em>m</em> qubits but they  can prepare in advance a complicated quantum state on those <em>2m</em> qubits. When we run the verification protocol each prover has access only to its <em>m</em> qubits and, like in the classical case,  the two provers cannot communicate. These types of verification protocols represent the complexity class MIP*.  In 2012 and Tsuyoshi Ito and Thomas Vidick proved that MIP* contains NEXP. In <a href="https://gilkalai.wordpress.com/2012/07/16/some-updates/">this 2012 post</a> I reported an unusual seminar we ran on the problem.</p>
<blockquote><p><strong>Interactive quantum lecture:</strong> We had an unususal quantum seminar presentation by Michael Ben-Or on the work <a href="http://arxiv.org/abs/1207.0550">A multi-prover interactive proof for NEXP sound against entangled provers</a> by Tsuyoshi Ito and Thomas Vidick. Michael ran Vidick’s videotaped recent talk on the matter and from time to time he and Dorit acted as a pair of prover and the other audience as verifier. (Michael was one of the authors of the very first paper introducing multi-prover interactive proofs.)</p></blockquote>
<p>Let me mention also a related 2014 paper by Yael Kalai, Ran Raz, and Ron Rothblum: <a href="https://www.microsoft.com/en-us/research/publication/delegate-computations-power-no-signaling-proofs/">How to delegate computations: the power of no-signaling proofs.</a> They considered two provers that are limited by the “non-signaling principle” and showed that the power of interactive proofs is exactly EXP . (Here is a <a href="https://www.youtube.com/watch?v=-FiroQt6yWc">videotaped lecture</a> by Ran Raz.)</p>
<p>In April 2019, Anand Natarajan and John Wright uploaded a paper with a proof that MIP* contain NEEXP. (NEEXP is the class of decision problems where if the answer is yes a prover can give a proof that requires the verifier (at most) doubly exponential number of steps to verify.)</p>
<p>Here is a nice quote from the <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">Harnett’s  quanta paper</a> regarding the Natarajan-Wright breakthrough:</p>
<blockquote><p>Some problems are too hard to solve in any reasonable amount of time. But their solutions are easy to check. Given that, computer scientists want to know: How complicated can a problem be while still having a solution that can be verified?</p>
<p>Turns out, the answer is: Almost unimaginably complicated.</p>
<p>In a paper released in April, two computer scientists <a href="https://arxiv.org/abs/1904.05870" target="_blank" rel="noopener">dramatically increased the number of problems</a> that fall into the hard-to-solve-but-easy-to-verify category. They describe a method that makes it possible to check answers to problems of almost incomprehensible complexity. “It seems insane,” said <a href="http://users.cms.caltech.edu/~vidick/" target="_blank" rel="noopener">Thomas Vidick</a>, a computer scientist at the California Institute of Technology who wasn’t involved in the new work.</p></blockquote>
<p><em>Now with the new result, I wonder if this bold  philosophical interpretation is sensible:  There is a shared quantum state that will allow two non-interacting provers (with unlimited computational power) to convince  a mathematician if a given mathematical statement has a proof, and also to convince a historian or a futurist about any question regarding the past or future evolution of the universe.</em></p>
<h3>What is RE?</h3>
<p>(I forgot to explain what RE is. Here is the description from the paper itself.)</p>
<p>RE is the class of recursively enumerable languages, i.e. languages <em>L</em> such that there<br />
exists a Turing machine <em>M</em> such that <em>x ∈ L</em> if and only if <em>M</em> halts and accepts on input <em>x</em>. Note that, in addition to containing all decidable languages, this class also contains undecidable problems such as the Halting problem, which is to decide whether a given Turing machine eventually halts</p>
<h3>A little more information and links</h3>
<p>The negative answer to Tsirelson problem asserts roughly that there are types of correlations  that can be produced by an infinite quantum systems, but that can’t even be approximated by a finite system. Connes’ 1976 embedding conjecture (now refuted) from the theory of von Neumann algebras asserts that “Every  type <img src="https://s0.wp.com/latex.php?latex=%5CPi_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pi_1" class="latex" title="\Pi_1" /> von Neumann factor embeds in an ultrapower of a hyperfinite <img src="https://s0.wp.com/latex.php?latex=%5CPi_1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Pi_1" class="latex" title="\Pi_1" /> factor.”</p>
<p>The abstract of the new paper mentions a few other works that are important for the new proof.</p>
<p>Anand Natarajan and Thomas Vidick. <a href="https://arxiv.org/abs/1801.03821">Low-degree testing for quantum states, and a quantum entangled games PCP for QMA.</a> (FOCS, 2018.)</p>
<p>Anand Natarajan and John Wright. <a href="https://arxiv.org/abs/1904.05870">NEEXP ⊆ MIP∗</a> (FOCS 2019) (We mentioned it above.)</p>
<p>Joe Fitzsimons, Zhengfeng Ji, Thomas Vidick, and Henry Yuen. <a href="https://arxiv.org/abs/1805.12166">Quantum proof systems</a><br />
<a href="https://arxiv.org/abs/1805.12166">for iterated exponential time, and beyond</a>.</p>
<p>The abstract also mentions two papers about the connections with Tsirelson problem and Connes embedding conjecture</p>
<p>Tobias Fritz. <a href="https://arxiv.org/abs/1008.1168">Tsirelson’s problem and Kirchberg’s conjecture</a>. Reviews in Mathematical<br />
Physics, 24(05):1250012, 2012. (A few enlightening comments by Fritz on SO: <a href="https://www.scottaaronson.com/blog/?p=4512#comment-1828167">I</a>, <a href="https://www.scottaaronson.com/blog/?p=4512#comment-1828412">II</a>)</p>
<p>Marius Junge, Miguel Navascues, Carlos Palazuelos, David Perez-Garcia, Volkher B Scholz, and Reinhard F Werner. <a href="https://arxiv.org/abs/1008.1142">Connes’ embedding problem and Tsirelson’s problem</a>. Journal of Mathematical Physics, 52(1):012102, 2011.</p>
<p>Let me also mention</p>
<p>Narutaka Ozawa.<a href="https://arxiv.org/abs/1212.1700"> About the Connes embedding conjecture</a>. Japanese Journal of Mathematics, 8(1):147–183, 2013.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/01/17/amazing-zhengfeng-ji-anand-natarajan-thomas-vidick-john-wright-and-henry-yuen-proved-that-mip-re-and-thus-disproved-connes-1976-embedding-conjecture-and-provided-a-negative-answer-to-tsirelso/"><span class="datestr">at January 17, 2020 01:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/004">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/004">TR20-004 |  The Power of the Combined Basic LP and Affine Relaxation for Promise CSPs | 

	Joshua Brakensiek, 

	Venkatesan Guruswami, 

	Marcin Wrochna, 

	Stanislav Zivny</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In the field of constraint satisfaction problems (CSP), promise CSPs are an exciting new direction of study. In a promise CSP, each constraint comes in two forms: "strict" and "weak," and in the associated decision problem one must distinguish between being able to satisfy all the strict constraints versus not being able to satisfy all the weak constraints. The most commonly cited example of a promise CSP is the approximate graph coloring problem--which has recently seen exciting progress [BKO19, WZ20] benefiting from a systematic algebraic approach to promise CSPs based on "polymorphisms," operations that map tuples in the strict form of each constraint to tuples in the corresponding weak form.

In this work, we present a simple algorithm which in polynomial time solves the decision problem for all promise CSPs that admit infinitely many symmetric polymorphisms, that is the coordinates are permutation invariant. This generalizes previous work of the first two authors [BG19]. We also extend this algorithm to a more general class of block-symmetric polymorphisms. As a corollary, this single algorithm solves all polynomial-time tractable Boolean CSPs simultaneously. These results give a new perspective on Schaefer's classic dichotomy theorem and shed further light on how symmetries of polymorphisms enable algorithms. Finally, we show that block symmetric polymorphisms are not only sufficient but also necessary for this algorithm to work, thus establishing its precise power.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/004"><span class="datestr">at January 17, 2020 02:50 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4522">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4522">An alternative argument for why women leave STEM: Guest post by Karen Morenz</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong>Scott’s preface:</strong> Imagine that every time you turned your blog over to a certain topic, you got denounced on Twitter and Reddit as a privileged douchebro, entitled STEMlord, counterrevolutionary bourgeoisie, etc. etc.  The sane response would simply be to quit blogging about that topic.  But there’s also an <em>in</em>sane (or masochistic?) response: the response that says, “but if everyone like me stopped talking, we’d cede the field by default to the loudest, angriest voices on all sides—thereby giving those voices exactly what they wanted.  To hell with that!”</p>



<p>A few weeks ago, while I was being attacked for sharing Steven Pinker’s <a href="https://www.scottaaronson.com/blog/?p=4476">guest post</a> about NIPS vs. NeurIPS, I received a beautiful message of support from a PhD student in physical chemistry and quantum computing named <a href="https://ca.linkedin.com/in/karen-morenz-189310112">Karen Morenz</a>.  Besides her strong words of encouragement, Karen wanted to share with me an <a href="https://medium.com/@kjmorenz/is-it-really-just-sexism-an-alternative-argument-for-why-women-leave-stem-cccdf066d8b1">essay</a> she had written on Medium about why too many women leave STEM.</p>



<p>Karen’s essay, I found, marshaled data, logic, and her own experience in support of an insight that strikes me as true and important and underappreciated—one that dovetails with what I’ve heard from many other women in STEM fields, including my wife <a href="https://www.cs.utexas.edu/~danama/">Dana</a>.  So I asked Karen for permission to reprint her essay on this blog, and she graciously agreed.</p>



<p>Briefly: anyone with a brain and a soul wants there to be many more women in STEM.  Karen outlines a realistic way to achieve this shared goal.  Crucially, Karen’s way is <em>not</em> about shaming male STEM nerds for their deep-seated misogyny, their arrogant mansplaining, or their gross, creepy, predatory sexual desires.  Yes, you can go the shaming route (God knows it’s being tried).  If you do, you’ll probably snare many guys who really do deserve to be shamed as creeps or misogynists, along with many more who don’t.  Yet for all your efforts, Karen predicts, you’ll no more solve the original problem of too few women in STEM, than arresting the kulaks solved the problem of lifting the masses out of poverty.</p>



<p>For you still won’t have made a dent in the real issue: namely that, the way we’ve set things up, pursuing an academic STEM career demands fanatical devotion, to the exclusion of nearly everything else in life, between the ages of roughly 18 and 35.  And as long as that’s true, Karen says, the majority of talented women are going to look at academic STEM, in light of all the other great options available to them, and say “no thanks.”  Solving this problem might look like more money for maternity leave and childcare.  It might also look like re-imagining the academic career trajectory itself, to make it easier to rejoin it after five or ten years away.  Way back in 2006, I tried to make this point in a blog post called <a href="https://www.scottaaronson.com/blog/?p=87">Nerdify the world, and the women will follow</a>.  I’m grateful to Karen for making it more cogently than I did.</p>



<p>Without further ado, here’s Karen’s essay. –SA</p>



<h3><strong>Is it really just sexism?  An alternative argument for why women leave STEM</strong></h3>



<p>by Karen Morenz</p>



<p>Everyone knows that you’re not supposed to start your argument with ‘everyone knows,’ but in this case, I think we ought to make an exception:</p>



<p>Everyone knows that STEM (Science, Technology, Engineering and Mathematics) has a problem retaining women (see, for example <a href="https://www.researchgate.net/publication/283809613_Women_in_STEM_Family-Related_Challenges_and_Initiatives" target="_blank" rel="noreferrer noopener">Jean, Payne, and Thompson 2015</a>). We pour money into attracting girls and women to STEM fields. We pour money into recruiting women, training women, and addressing sexism, both overt and subconscious. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5491652/" target="_blank" rel="noreferrer noopener">In 2011</a>, the United States spent nearly $3 billion tax dollars on STEM education, of which roughly one third was spent supporting and encouraging underrepresented groups to enter STEM (including women). And yet, women are still leaving at alarming rates.</p>



<p>Alarming? Isn’t that a little, I don’t know, alarmist? Well, <strong>let’s look at some stats.</strong></p>



<p>A recent report by the <a href="https://journals.sagepub.com/doi/full/10.1177/0894845313483003" target="_blank" rel="noreferrer noopener">National Science Foundation (2011)</a> found that women received 20.3% of the bachelor’s degrees and 18.6% of the PhD degrees in physics in 2008. In chemistry, women earned 49.95% of the bachelor’s degrees but only 36.1% of the doctoral degrees. By comparison, in biology women received 59.8% of the bachelor’s degrees and 50.6% of the doctoral degrees. A <a href="https://cen.acs.org/articles/96/i10/why-cant-the-drug-industry-solve-its-gender-diversity-problem.html" target="_blank" rel="noreferrer noopener">recent article</a> in Chemical and Engineering News showed a chart based on a survey of life sciences workers by Liftstream and MassBio demonstrating how women are vastly underrepresented in science leadership despite earning degrees at similar rates, which I’ve copied below. The story is the same in academia, as you can see on the <a href="https://eige.europa.eu/sites/default/files/garcia_working_paper_5_academic_careers_gender_inequality.pdf" target="_blank" rel="noreferrer noopener">second chart</a> — from comparable or even larger number of women at the student level, we move towards a significantly larger proportion of men at the more and more advanced stages of an academic career.</p>



<figure class="wp-block-image"><img src="https://miro.medium.com/max/700/1*X0Pt4nHwU9JiVN0RDyb1sQ.png" alt="" /></figure>



<figure class="wp-block-image"><img src="https://miro.medium.com/max/697/1*vx6M8mBvhk0pYtNq3B06fg.png" alt="" /></figure>



<p>Although 74% of women in STEM <a href="http://www.ncwit.org/sites/default/files/legacy/pdf/NCWIT_TheFacts_rev2010.pdf" target="_blank" rel="noreferrer noopener">report</a> “loving their work,” half (56%, in fact) leave over the course of their career — largely at the “mid-level” point, when the loss of their talent is most costly as they have just completed training and begun to contribute maximally to the work force.</p>



<p><a href="https://arxiv.org/abs/1810.01511" target="_blank" rel="noreferrer noopener">A study by Dr. Flaherty</a> found that women who obtain faculty position in astronomy spent on average 1 year less than their male counterparts between completing their PhD and obtaining their position — but he concluded that this is because <strong>women leave the field at a rate 3 to 4 times greater than men</strong>, and in particular, if they do not obtain a faculty position quickly, will simply move to another career. So, women and men are hired at about the same rate during the early years of their post docs, but women stop applying to academic positions and drop out of the field as time goes on, pulling down the average time to hiring for women.</p>



<p>There are many more studies to this effect. At this point, <strong>the assertion that women leave STEM at an alarming rate after obtaining PhDs is nothing short of an established fact</strong>. In fact, it’s actually a problem across all academic disciplines, as you can see in <a href="http://blogs.nature.com/news/2012/11/leaky-pipelines-for-canadian-women-in-research.html" target="_blank" rel="noreferrer noopener">this matching chart</a> showing the same phenomenon in humanities, social sciences, and education. The phenomenon has been affectionately dubbed the “leaky pipeline.”</p>



<figure class="wp-block-image"><img src="https://miro.medium.com/max/571/0*koOEWDCY2BBSvZCN" alt="" /></figure>



<p><strong>But hang on a second, maybe there just aren’t enough women qualified for the top levels of STEM? Maybe it’ll all get better in a few years if we just wait around doing nothing?</strong></p>



<p>Nope, sorry. This <a href="http://www.pewsocialtrends.org/2018/01/09/women-and-men-in-stem-often-at-odds-over-workplace-equity/" target="_blank" rel="noreferrer noopener">study</a> says that 41% of highly qualified STEM people are female. And also, it’s clear from the previous charts and stats that a significantly larger number of women are getting PhDs than going on the be professors, in comparison to their male counterparts. <a href="https://cen.acs.org/articles/96/i10/why-cant-the-drug-industry-solve-its-gender-diversity-problem.html" target="_blank" rel="noreferrer noopener">Dr. Laurie Glimcher</a>, when she started her professorship at Harvard University in the early 1980s, remembers seeing very few women in leadership positions. “I thought, ‘Oh, this is really going to change dramatically,’ ” she says. But 30 years later, “it’s not where I expected it to be.” Her experiences are similar to those of other leading female faculty.</p>



<p><strong>So what gives? Why are all the STEM women leaving?</strong></p>



<p>It is widely believed that sexism is the leading problem. A quick google search of “sexism in STEM” will turn up a veritable cornucopia of articles to that effect. And indeed, around 60% of women report experiencing some form of sexism in the last year (<a href="https://journals.sagepub.com/doi/pdf/10.1177/0361684315596162" target="_blank" rel="noreferrer noopener">Robnett 2016</a>). So, that’s clearly not good.</p>



<p>And yet, if you ask leading women researchers like Nobel Laureate in Physics 2018, Professor Donna Strickland, or Canada Research Chair in Advanced Functional Materials (Chemistry), Professor Eugenia Kumacheva, <a href="https://www.bbc.co.uk/sounds/play/p06mrmnt" target="_blank" rel="noreferrer noopener">they</a> <a href="https://www.intermissionmagazine.ca/features/the-scientist-and-the-artist-conversations-with-eugenia-kumacheva-and-fiona-reid/" target="_blank" rel="noreferrer noopener">say</a> that sexism was not a barrier in their careers. Moreover, extensive research has shown that sexism has overall decreased since Professors Strickland and Kumacheva (for example) were starting their careers. Even more interestingly, <a href="https://journals.sagepub.com/doi/pdf/10.1177/0361684315596162" target="_blank" rel="noreferrer noopener">Dr. Rachael Robnett showed</a> that more mathematical fields such as Physics have a greater problem with sexism than less mathematical fields, such as Chemistry, a finding which rings true with the subjective experience of many women I know in Chemistry and Physics. However, as we saw above, women leave the field of Chemistry in greater proportions following their BSc than they leave Physics. On top of that, although 22% of women <a href="http://www.pewsocialtrends.org/2018/01/09/women-and-men-in-stem-often-at-odds-over-workplace-equity/" target="_blank" rel="noreferrer noopener">report</a> experiencing sexual harassment at work, the proportion is the same among STEM and non-STEM careers, and yet women leave STEM careers at a much higher rate than non-STEM careers.</p>



<p>So,it seems that<strong> sexism can not fully explain why women with STEM PhDs are leaving STEM</strong>. At the point when women have earned a PhD, for the most part they have already survived the worst of the sexism. They’ve already proven themselves to be generally thick-skinned and, as anyone with a PhD can attest, very stubborn in the face of overwhelming difficulties. Sexism is frustrating, and it can limit advancement, but it doesn’t fully explain why we have so many women obtaining PhDs in STEM, and then leaving. In fact, at least in the U of T chemistry department, faculty hires are directly proportional to the applicant pool —although the exact number of applicants are not made public, from public information we can see that approximately one in four interview invitees are women, and approximately one in four hires are women. Our hiring committees have received bias training, and it seems that it has been largely successful. That’s not to say that we’re done, but it’s time to start looking elsewhere to explain why there are so few women sticking around.</p>



<p><strong>So why don’t more women apply?</strong></p>



<p>Well, <a href="https://www.theguardian.com/science/2015/dec/14/many-women-in-stem-fields-expect-to-quit-within-five-years-survey-finds" target="_blank" rel="noreferrer noopener">one truly brilliant researcher</a> had the groundbreaking idea of asking women why they left the field. When you ask women why they left, the number one reason they cite is<strong> balancing work/life responsibilities</strong> — which as far as I can tell is a euphemism for family concerns.</p>



<p><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5315093/#FN2" target="_blank" rel="noreferrer noopener">The</a> <a href="http://www.ncwit.org/sites/default/files/legacy/pdf/NCWIT_TheFacts_rev2010.pdf" target="_blank" rel="noreferrer noopener">research</a> <a href="http://blogs.nature.com/news/2012/11/leaky-pipelines-for-canadian-women-in-research.html" target="_blank" rel="noreferrer noopener">is in</a> <a href="http://www.pewsocialtrends.org/2018/01/09/women-and-men-in-stem-often-at-odds-over-workplace-equity/" target="_blank" rel="noreferrer noopener">on</a> <a href="https://eige.europa.eu/sites/default/files/garcia_working_paper_5_academic_careers_gender_inequality.pdf" target="_blank" rel="noreferrer noopener">this</a>. Women who stay in academia expect to marry later, and delay or completely forego having children, and if they do have children, plan to have fewer than their non-STEM counterparts (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5315093/#FN2" target="_blank" rel="noreferrer noopener">Sassler et al 2016</a>, <a href="http://blogs.nature.com/news/2012/11/leaky-pipelines-for-canadian-women-in-research.html" target="_blank" rel="noreferrer noopener">Owens 2012</a>). Men in STEM have no such difference compared to their non-STEM counterparts; they marry and have children about the same ages and rates as their non-STEM counterparts (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5315093/#FN2" target="_blank" rel="noreferrer noopener">Sassler et al 2016</a>). Women leave STEM in droves in their early to mid thirties (<a href="http://www.pewsocialtrends.org/2018/01/09/women-and-men-in-stem-often-at-odds-over-workplace-equity/" target="_blank" rel="noreferrer noopener">Funk and Parker 2018</a>) — the time when women’s fertility begins to decrease, and risks of childbirth complications begin to skyrocket for both mother and child. Men don’t see an effect on their fertility until their mid forties. Of the 56% of women who leave STEM, 50% wind up self-employed or using their training in a not for profit or government, 30% leave to a non-STEM more ‘family friendly’ career, and 20% leave to be stay-at-home moms (<a href="http://www.ncwit.org/sites/default/files/legacy/pdf/NCWIT_TheFacts_rev2010.pdf" target="_blank" rel="noreferrer noopener">Ashcraft and Blithe 2002</a>). Meanwhile, institutions with better childcare and maternity leave policies have twice(!) the number of female faculty in STEM (<a href="https://www.theguardian.com/education/2018/jan/21/better-maternity-leave-could-help-universities-retain-women-study" target="_blank" rel="noreferrer noopener">Troeger 2018</a>). In analogy to the affectionately named “leaky pipeline,” the challenge of balancing motherhood and career has been titled the “maternal wall.”</p>



<p><strong>To understand the so-called maternal wall better, let’s take a quick look at the sketch of a typical academic career.</strong></p>



<p>For the sake of this exercise, let’s all pretend to be me. I’m a talented 25 year old PhD candidate studying Physical Chemistry — I use laser spectroscopy to try to understand atypical energy transfer processes in innovative materials that I hope will one day be used to make vastly more efficient solar panels. I got my BSc in Chemistry and Mathematics at the age of 22, and have published 4 scientific papers in two different fields already (Astrophysics and Environmental Chemistry). I’ve got a big scholarship, and a lot of people supporting me to give me the best shot at an academic career — a career I dearly want. But, I also want a family — maybe two or three kids. Here’s what I can expect if I pursue an academic career:</p>



<p>With any luck, 2–3 years from now I’ll graduate with a PhD, at the age of 27. Academics are expected to travel a lot, and to move a lot, especially in their 20s and early 30s — all of the key childbearing years. I’m planning to go on exchange next year, and then the year after that I’ll need to work hard to wrap up research, write a thesis, and travel to several conferences to showcase my work. After I finish my PhD, I’ll need to undertake one or two post doctoral fellowships, lasting one or two years each, probably in completely different places. During that time, I’ll start to apply for professorships. In order to do this, I’ll travel around to conferences to advertise my work and to meet important leaders in my field, and then, if I am invited for interviews, I’ll travel around to different universities for two or three days at a time to undertake these interviews. This usually occurs in a person’s early 30s — our helpful astronomy guy, Dr. Flaherty, found the average time to hiring was 5 years, so let’s say I’m 32 at this point. If offered a position, I’ll spend the next year or two renovating and building a lab, buying equipment, recruiting talented graduate students, and designing and teaching courses. People work really, really hard during this time and have essentially no leisure time. Now I’m 34. Within usually 5 years I’ll need to apply for tenure. This means that by the time I’m 36, I’ll need to be making significant contributions in my field, and then in the final year before applying for tenure, I will once more need to travel to many conferences to promote my work, in order to secure tenure — if I fail to do so, my position at the university would probably be terminated. <strong>Although many universities offer a “tenure extension” in cases where an assistant professor has had a child, this does not solve all of the problems. </strong>Taking a year off during that critical 5 or 6 year period often means that the research “goes bad” — students flounder, projects that were promising get “scooped” by competitors at other institutions, and sometimes, in biology and chemistry especially, experiments literally go bad. You wind up needing to rebuild much more than just a year’s worth of effort.</p>



<p>At no point during this time do I appear stable enough, career-wise, to take even six months off to be pregnant and care for a newborn. Hypothetical future-me is travelling around, or even moving, conducting and promoting my own independent research and training students. As you’re likely aware, very pregnant people and newborns don’t travel well. And academia has a very individualistic and meritocratic culture. Starting at the graduate level, huge emphasis is based on independent research, and independent contributions, rather than valuing team efforts. This feature of academia is both a blessing and a curse. The individualistic culture means that people have the independence and the freedom to pursue whatever research interests them — in fact this is the main draw for me personally. But it also means that there is often no one to fall back on when you need extra support, and because of biological constraints, this winds up impacting women more than men.</p>



<p>At this point, I need to make sure that you’re aware of some basics of female reproductive biology. According to Wikipedia, the unquestionable source of all reliable knowledge, at age 25, my risk of conceiving a baby with chromosomal abnormalities (including Down’s Syndrome) is 1 in about 1400. By 35, that risk more than quadruples to 1 in 340. At 30, I have a 75% chance of a successful birth in one year, but by 35 it has dropped to 66%, and by 40 it’s down to 44%. Meanwhile, 87 to 94% of women report at least 1 health problem immediately after birth, and 1.5% of mothers have a severe health problem, while 31% have long-term persistent health problems as a result of pregnancy (defined as lasting more than six months after delivery). Furthermore, mothers over the age of 35 are at higher risk for pregnancy complications like preterm delivery, hypertension, superimposed preeclampsia, severe preeclampsia (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4418963/" target="_blank" rel="noreferrer noopener">Cavazos-Rehg et al 2016</a>). Because of factors like these, pregnancies in women over 35 are known as “geriatric pregnancies” due to the drastically increased risk of complications. This tight timeline for births is often called the “biological clock” — if women want a family, they basically need to start before 35. Now, that’s not to say it’s impossible to have a child later on, and in fact some studies show that it has positive impacts on the child’s mental health. But it is riskier.</p>



<figure class="wp-block-image"><img src="https://miro.medium.com/max/270/0*UnDt9Luls2Ic_4BD" alt="" /></figure>



<p>So, women with a PhD in STEM know that they have the capability to make interesting contributions to STEM, and to make plenty of money doing it. They usually marry someone who also has or expects to make a high salary as well. But this isn’t the only consideration. Such highly educated women are usually aware of the biological clock and the risks associated with pregnancy, and are confident in their understanding of statistical risks.</p>



<p>The <a href="https://www.ria.ie/sites/default/files/report_final_version-1_0.pdf" target="_blank" rel="noreferrer noopener">Irish</a> say, “The common challenge facing young women is achieving a satisfactory work-life balance, especially when children are small. From a career perspective, this period of parenthood (which after all is relatively short compared to an entire working life) tends to coincide exactly with the critical point at which an individual’s career may or may not take off. […] All the evidence shows that it is at this point that women either drop out of the workforce altogether, switch to part-time working or move to more family-friendly jobs, which may be less demanding and which do not always utilise their full skillset.”</p>



<p>And in the <a href="https://eige.europa.eu/sites/default/files/garcia_working_paper_5_academic_careers_gender_inequality.pdf" target="_blank" rel="noreferrer noopener">Netherlands</a>, “The research project in Tilburg also showed that women academics have more often no children or fewer children than women outside academia.” Meanwhile in <a href="https://eige.europa.eu/sites/default/files/garcia_working_paper_5_academic_careers_gender_inequality.pdf" target="_blank" rel="noreferrer noopener">Italy</a> “On a personal level, the data show that for a significant number of women there is a trade-off between family and work: a large share of female economists in Italy do not live with a partner and do not have children”</p>



<p>Most jobs available to women with STEM PhDs offer greater stability and a larger salary earlier in the career. Moreover, most non-academic careers have less emphasis on independent research, meaning that employees usually work within the scope of a larger team, and so if a person has to take some time off, there are others who can help cover their workload. <a href="http://www.ncwit.org/sites/default/files/legacy/pdf/NCWIT_TheFacts_rev2010.pdf" target="_blank" rel="noreferrer noopener"><strong>By and large</strong></a><strong>, women leave to go to a career where they will be stable, well funded, and well supported, even if it doesn’t fulfill their passion for STEM — or they leave to be stay-at-home moms or self-employed.</strong></p>



<p>I would presume that if we made academia a more feasible place for a woman with a family to work, we could keep almost all of those 20% of leavers who leave to just stay at home, almost all of the 30% who leave to self-employment, and all of those 30% who leave to more family friendly careers (after all, if academia were made to be as family friendly as other careers, there would be no incentive to leave). Of course, there is nothing wrong with being a stay at home parent — it’s an admirable choice and contributes greatly to our society. <a href="https://www.salary.com/articles/stay-at-home-mom/" target="_blank" rel="noreferrer noopener">One estimate</a> valued the equivalent salary benefit of stay-at-home parenthood at about $160,000/year. <a href="https://www.ssb.no/forskning/discussion-papers/_attachment/113165?_ts=13ea1e1e480" target="_blank" rel="noreferrer noopener">Moreover</a>, children with a stay-at-home parent show long term benefits such as better school performance — something that most academic women would want for their children. <strong>But a lot of people only choose it out of necessity — about half of stay-at-home moms would prefer to be working </strong>(<a href="https://link.springer.com/article/10.1007/s10834-017-9534-7" target="_blank" rel="noreferrer noopener">Ciciolla, Curlee, &amp; Luthar 2017</a>). When the reality is that your salary is barely more than the cost of daycare, then a lot of people wind up giving up and staying home with their kids rather than paying for daycare. In a heterosexual couple it will usually be the woman that winds up staying home since she is the one who needs to do things like breast feed anyways. And so we lose these women from the workforce.</p>



<p>And yet, somehow, during this informal research adventure of mine, most scholars and policy makers seem to be advising that we try to encourage young girls to be interested in STEM, and to address sexism in the workplace, with the implication that this will fix the high attrition rate in STEM women. But from what I’ve found, <strong>the stats don’t back up sexism as the main reason women leave</strong>. There is sexism, and that is a problem, and women do leave STEM because of it — but it’s a problem that we’re already dealing with pretty successfully, and it’s not why the majority of women who have already obtained STEM PhDs opt to leave the field. The whole family planning thing is huge and for some reason, almost totally swept under the rug — mostly because we’re too shy to talk about it, I think.</p>



<p>In fact, I think that the plethora of articles suggesting that the problem is sexism actually contribute to our unwillingness to talk about the family planning problem, because it reinforces the perception that that men in power will not hire a woman for fear that she’ll get pregnant and take time off. <strong>Why would anyone talk about how they want to have a family when they keep hearing that even the mere suggestion of such a thing will limit their chances of being hired?</strong> I personally know women who have avoided bringing up the topic with colleagues or supervisors for fear of professional repercussions. So we spend all this time and energy talking about how sexism is really bad, and very little time trying to address the family planning challenge, because, I guess, as the stats show, if women are serious enough about science then they just give up on the family (except for the really, really exceptional ones who can handle the stresses of both simultaneously).</p>



<p>To be very clear, I’m not saying that sexism is not a problem. What I am saying is that, thanks to the sustained efforts of a large number of people over a long period of time, we’ve reduced the sexism problem to the point where, at least at the graduate level, it is no longer the largest major barrier to women’s advancement in STEM. <strong>Hurray! </strong>That does not mean that we should stop paying attention to the issue of sexism, but does mean that <strong>it’s time to start paying more attention to other issues</strong>, like how to properly support women who want to raise a family while also maintaining a career in STEM.</p>



<p><strong>So what can we do to better support STEM women who want families?</strong></p>



<p>A couple of solutions have been tentatively tested. From a study mentioned above, it’s clear that <strong>providing free and conveniently located childcare makes a colossal difference to women’s choices of whether or not to stay in STEM</strong>, alongside extended and paid maternity leave. <a href="https://cen.acs.org/articles/96/i10/why-cant-the-drug-industry-solve-its-gender-diversity-problem.html" target="_blank" rel="noreferrer noopener">Another</a> popular and successful strategy was implemented by a leading woman in STEM, Laurie Glimcher, a past Harvard Professor in Immunology and now CEO of Dana-Farber Cancer Institute. While working at NIH, <strong>Dr. Glimcher designed a program to provide primary caregivers (usually women) with an assistant or lab technician to help manage their laboratories while they cared for children</strong>. Now, at Dana-Farber Cancer Institute, she has created a similar program to pay for a technician or postdoctoral researcher for assistant professors. In the academic setting, Dr. Glimcher’s strategies are key for helping to alleviate the challenges associated with the individualistic culture of academia without compromising women’s research and leadership potential.</p>



<p>For me personally, I’m in the ideal situation for an academic woman. I graduated my BSc with high honours in four years, and with many awards. I’ve already had success in research and have published several peer reviewed papers. I’ve faced some mild sexism from peers and a couple of TAs, but nothing that’s seriously held me back. My supervisors have all been extremely supportive and feminist, and all of the people that I work with on a daily basis are equally wonderful. Despite all of this support, I’m looking at the timelines of an academic career, and the time constraints of female reproduction, and honestly, I don’t see how I can feasible expect to stay in academia and have the family life I want. And since I’m in the privileged position of being surrounded by supportive and feminist colleagues, I can say it: I’m considering leaving academia, if something doesn’t change, because even though I love it, I don’t see how it can fit in to my family plans.</p>



<p><strong>But wait! All of these interventions are really expensive. Money doesn’t just grow on trees, you know!</strong></p>



<p>It doesn’t in general, but in this case it kind of does — well, actually, we already grew it. We spend billions of dollars training women in STEM. By not making full use of their skills, if we look at only the american economy, <a href="https://journals.sagepub.com/doi/pdf/10.1177/0894845318784745" target="_blank" rel="noreferrer noopener">we are wasting about $1.5 billion USD per year</a> in economic benefits they would have produced if they stayed in STEM. So here’s a business proposal: let’s spend half of that on better family support and scientific assistants for primary caregivers, and keep the other half in profit. Heck, let’s spend 99% — $1.485 billion (in the states alone) on better support. That should put a dent in the support bill, and I’d sure pick up $15 million if I saw it lying around. Wouldn’t you?</p>



<p>By demonstrating that we will support women in STEM who choose to have a family, we will encourage more women with PhDs to apply for the academic positions that they are eminently qualified for. Our institutions will benefit from the wider applicant pool, and our whole society will benefit from having the skills of these highly trained and intelligent women put to use innovating new solutions to our modern day challenges.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4522"><span class="datestr">at January 16, 2020 08:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/01/16/postdoc-at-university-of-alberta-apply-by-august-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/01/16/postdoc-at-university-of-alberta-apply-by-august-31-2020/">Postdoc at University of Alberta (apply by August 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Theory Group in the Dept. of Computing Science at U. of Alberta invites applications for a postdoc position.<br />
The successful applicant is expected to work closely with Zachary Friggstad and Mohammad Salavatipour in the areas of: approximation algorithms, hardness of approximation, combinatorial optimization. For details see <a href="https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf">https://webdocs.cs.ualberta.ca/~mreza/pdf-ad7.pdf</a></p>
<p>Website: <a href="https://webdocs.cs.ualberta.ca/~mreza/">https://webdocs.cs.ualberta.ca/~mreza/</a><br />
Email: mrs@ualberta.ca</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/01/16/postdoc-at-university-of-alberta-apply-by-august-31-2020/"><span class="datestr">at January 16, 2020 07:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/01/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/01/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p>Recently read: Robert Bosch’s <em>Opt Art: From Mathematical Optimization to Visual Design</em>, <a href="https://mathlesstraveled.com/2019/11/16/book-review-opt-art/">as reviewed in <em>The Math Less Traveled</em></a> (<a href="https://mathstodon.xyz/@11011110/103412030032115785"></a>). Some others that are less mathematical: Susan Phillips <em>The City Beneath</em> (the rare book about graffiti where the words are more interesting than the photos); Kelly &amp; Zach Weinersmith’s <em>Soonish</em>; <em>Spectrum 26: The Best in Contemporary Fantastic Art</em>.</p>
  </li>
  <li>
    <p>I’m sad that <a href="https://en.wikipedia.org/wiki/Cambridge_Zero">Cambridge Zero</a> is not a name for the convention that, in writing a decimal number between 0 and 1, the leading 1’s digit is included (e.g. 0.618034, not .618034). (<a href="https://mathstodon.xyz/@11011110/103415602604747766"></a>.)</p>
  </li>
  <li>
    <p><a href="https://www.soue.org.uk/souenews/issue4/wallis.html">John Wallis and the Roof of the Sheldonian Theatre</a> (<a href="https://mathstodon.xyz/@11011110/103423324228262704"></a>, <a href="https://aperiodical.com/2019/11/my-adventures-in-3d-printing-wallis-sheldonian-theatre-roof/">via</a>). It’s an elegant way to build a wide roof out of short beams with no joinery. But the history is somewhat lacking: Similar structures were known much earlier to Leonardo Da Vinci, Villard de Honnecourt, and Sebastiano Serlio. See Sylvie Duvernoy, “<a href="https://doi.org/10.1007/978-3-7643-8728-0_1">An introduction to Leonardo’s lattices</a>”.</p>
  </li>
  <li>
    <p><a href="https://hackeducation.com/2019/12/31/what-a-shitshow">The 100 worst ed-tech debacles of the decade</a> (<a href="https://mathstodon.xyz/@pkra/103427036327542926"></a>).</p>
  </li>
  <li>
    <p><a href="https://www.latimes.com/business/story/2020-01-04/rhapsody-in-blue-copyright-law"><em>Rhapsody in Blue</em> (1924) just reached the public domain, showing the insanity of U.S. copyright law</a> (<a href="https://mathstodon.xyz/@11011110/103432817381841613"></a>).</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2015/11/collages-augustine-kofie/">Geometric collages by Augustine Kofie</a> (<a href="https://mathstodon.xyz/@11011110/103440293167247768"></a>). More at <a href="https://augustinekofie.info/">the artist’s web site</a>.</p>
  </li>
  <li>
    <p><a href="https://math.stackexchange.com/questions/2869725/minimal-surfaces-for-planar-octagons-and-nonagons">How few -gons can make a polyhedron, for different choices of ? </a> (<a href="https://mathstodon.xyz/@11011110/103446222145063436"></a>, <a href="http://www.mathpuzzle.com/">via</a>, <a href="https://mathstodon.xyz/@christianp/103425156116096450">via</a>.)  The answers include an amazing high-genus polyhedron with 12 faces, each of which is an 11-gon, posted Nov 2018 by Ivan Neretin (sadly, with multiple adjacencies for some pairs of faces, dubious by some definitions of polyhedra, rather than having one edge per face pair).</p>
  </li>
  <li>
    <p><a href="https://newsroom.publishers.org/researchers-and-publishers-oppose-immediate-free-distribution-of-peer-reviewed-journal-articles">Information about ACM’s opposition to mandatory open access of publicly-funded research</a> (<a href="https://mathstodon.xyz/@patmorin/103448005171034417"></a>).</p>
  </li>
  <li>
    <p><a href="https://www.sciencemag.org/news/2020/01/russian-journals-retract-more-800-papers-after-bombshell-investigation">Russian Academy of Science cleans house</a> (<a href="https://mathstodon.xyz/@11011110/103457148027652979"></a>, <a href="https://boingboing.net/2020/01/09/antiplagiat.html">via</a>). Their investigation finds 2528 plagiarized papers in 541 Russian-language journals, gets roughly 1/3 of them retracted, and threatens uncooperative journals with de-listing from their indexes. They also recommended blackballing 56 candidates for academy membership over plagiarism and other misbehavior.</p>
  </li>
  <li>
    <p><a href="https://www.vice.com/en_us/article/qjd8j3/the-mta-is-going-after-an-etsy-artist-over-a-new-york-subway-map-it-didnt-make">The New York subway system thinks it has copyright on any stylized geometric map of its system and is sending takedown notices to the artist of the unofficial map used by Wikipedia</a> (<a href="https://mathstodon.xyz/@11011110/103463673345804837"></a>, <a href="https://news.ycombinator.com/item?id=22002272">via</a>). As the article clearly explains, none of the underlying data of the map, the approximate geographic locations of its stations, or the idea of geometric stylization are copyrightable.</p>
  </li>
  <li>
    <p><a href="https://www.thisiscolossal.com/2020/01/paris-musees-free-digital-artworks/">Paris Musées releases 100,000 images of artworks for unrestricted public use</a> (<a href="https://mathstodon.xyz/@11011110/103469315555489525"></a>).</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/how-simple-math-can-cover-even-the-most-complex-holes-20200108/">How simple math can cover even the most complex holes</a> (<a href="https://mathstodon.xyz/@btcprox/103480282462508854"></a>). <em>Quanta</em> on covering all diameter-one shapes with the smallest possible convex region</p>
  </li>
  <li>
    <p><a href="https://arxiv.org/abs/2001.04383">MIP*=RE</a> or, less technically, “<a href="https://www.scottaaronson.com/blog/?p=4512">two entangled provers could convince a polynomial-time verifier than an arbitrary Turing machine halts</a>”  (<a href="https://mathstodon.xyz/@11011110/103483043292500103"></a>, <a href="https://windowsontheory.org/2020/01/14/mipre-connes-embedding-conjecture-disproved/">see also</a>, <a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/">see also</a>). This appears to be a major breakthrough in quantum complexity and <a href="https://en.wikipedia.org/wiki/Connes_embedding_problem">its applications in von Neumann algebra</a>. See also some <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">background from an author</a>.</p>
  </li>
  <li>
    <p><a href="https://socg20.inf.ethz.ch/cgme-cfp.html">Computational Geometry Media Exposition coming in Zurich in late June</a> (<a href="https://mathstodon.xyz/@11011110/103488449029758388"></a>). It’s one of the events associated with the annual Symposium on Computational Geometry, and was formerly called the video review of computational geometry. This year it’s expanding to a much wider range of media. Submission deadline February 21; see link for details.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/01/15/linkage.html"><span class="datestr">at January 15, 2020 10:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16563">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/">Halting Is Poly-Time Quantum Provable</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>How does this intersect David Deutsch’s thoughts in 1985?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/jnvwy/" rel="attachment wp-att-16565"><img src="https://rjlipton.files.wordpress.com/2020/01/jnvwy.png?w=200&amp;h=248" alt="" width="200" class="alignright wp-image-16565" height="248" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop from homepages</font></td>
</tr>
</tbody>
</table>
<p>
Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen (JNVWY) have just posted a <a href="https://arxiv.org/abs/2001.04383">paper</a> titled <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%7D%5E%2A+%3D+%5Cmathsf%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{MIP}^* = \mathsf{RE}}" class="latex" title="{\mathsf{MIP}^* = \mathsf{RE}}" />. The title means that multiple provers sharing quantum entanglement, given any Turing machine <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> and string <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> accepted by <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, can convince a polynomial-time bounded verifier with high probability that <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+L%28M%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \in L(M)}" class="latex" title="{x \in L(M)}" />. The time is polynomial in <img src="https://s0.wp.com/latex.php?latex=%7B%7Cx%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{|x|}" class="latex" title="{|x|}" /> regardless of how long <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> takes to halt on <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />.</p>
<p>
Today we applaud this work and try to convey some short way of apprehending it.</p>
<p>
Yoking a classic undecidable problem to a polynomial-time task is not the only surprise. The proof refutes a conjecture in classical functional analysis that had apparently been widely believed. Thus this story continues the theme of <a href="https://rjlipton.wordpress.com/2009/09/27/surprises-in-mathematics-and-theory/">surprises</a> and possibly working the wrong way on conjectures, as we also just mentioned in our previous <a href="https://rjlipton.wordpress.com/2020/01/12/our-thoughts-on-pnp/">post</a>. The new work subsumes a major <a href="https://arxiv.org/abs/1904.05870">paper</a> last year showing that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%7D%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{MIP}^*}" class="latex" title="{\mathsf{MIP}^*}" /> contains nondeterministic double exponential time (<img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNEEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NEEXP}}" class="latex" title="{\mathsf{NEEXP}}" />), which proves it different from its classical counterpart <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{MIP}}" class="latex" title="{\mathsf{MIP}}" />, which László Babai, Lance Fortnow, and Carsten Lund <a href="https://people.cs.uchicago.edu/~fortnow/papers/mip2.pdf">proved</a> equal to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NEXP}}" class="latex" title="{\mathsf{NEXP}}" />.</p>
<p>
The developments have been covered by Scott Aaronson <a href="https://www.scottaaronson.com/blog/?p=4512">here</a>, Lance <a href="https://blog.computationalcomplexity.org/2020/01/quantum-provers-to-infinity-and-beyond.html">here</a>, Boaz Barak <a href="https://windowsontheory.org/2020/01/14/mipre-connes-embedding-conjecture-disproved/">here</a>, and in a personal way by Vidick <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">here</a>. The new paper weights in at 165 pages. We will give our own snap-summary and try to add a little from the side.</p>
<p>
</p><p></p><h2> A Halting Attempt to Explain </h2><p></p>
<p>The refuted <a href="https://en.wikipedia.org/wiki/Connes_embedding_problem">conjecture</a> was made by the Fields Medalist Alain Connes in a context having no overt involvement of quantum mechanics. In these 2013 <a href="http://mtm.ufsc.br/~daemi/soficworkshop/Course notes/Capraro Lecture 1.pdf">eight</a>–<a href="http://mtm.ufsc.br/~daemi/soficworkshop/Course notes/Capraro Lecture 2.pdf">lecture</a> <a href="http://mtm.ufsc.br/~daemi/soficworkshop/Course notes/Capraro Lecture 3-5.pdf">course</a> <a href="http://mtm.ufsc.br/~daemi/soficworkshop/Course notes/Capraro Lecture 5-8.pdf">notes</a> on the conjecture, the word “quantum” appears only once, to say on page 2 of lecture 1:</p>
<blockquote><p><b> </b> <em> Other very recent discoveries include the fact that Connes’ embedding conjecture is related to an important problem in Quantum Information Theory, the so-called Tsirelson’s problem… </em>
</p></blockquote>
<p></p><p>
The <a href="https://arxiv.org/pdf/0812.4305.pdf">problem</a> of Boris Tsirelson ultimately harks back to the <a href="https://en.wikipedia.org/wiki/Bell's_theorem">theorem</a> of John Bell about correlations that are physically realizable using quantum entanglement but not by any classical physical system. In the <a href="https://en.wikipedia.org/wiki/CHSH_inequality">CHSH game</a> form of Bell’s theorem, our old friends Alice and Bob can win the game over 85% of the time using quantum, only 75% otherwise. They can get this with just one pair of entangled qubits per trial. Tsirelson proved that the 85% (to wit, <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccos%5E2%28%5Cpi%2F8%29+%3D+0.85355%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cos^2(\pi/8) = 0.85355\dots}" class="latex" title="{\cos^2(\pi/8) = 0.85355\dots}" />) is optimal.  In extensions of these games to larger-size cases, the question becomes: what are the gaps between quantum and classical? </p>
<p>
Whether there is a gap of more than a fixed <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon}" class="latex" title="{\epsilon}" /> then feeds into interactive protocols. We can have parties trying to prove these gaps using their own entanglement. Where it gets tricky is when you allow Alice and Bob to use larger and larger quantum states and ask, can they achieve the gap with some large enough state? The limiting behavior of the gaps is complex. What JNVWY proved is that this becomes like a halting problem. Not just a halting problem, <em>the</em> Halting Problem. Yet two quantum provers, working for a given gap that is achievable, can prove this to a polynomial-time classical verifier. This is the magic of the theorem.</p>
<p>
The reduction from halting to the problem about limits and gaps comes before introducing two-prover systems, as is reflected by JNVWY and also in the wonderful introduction of a 2017 <a href="https://arxiv.org/pdf/1703.08618.pdf">paper</a> by William Slofstra which they reference. In advance of saying more about it, we’ll remark that the new work may provide a new dictionary for translating between (i) issues of finite/infinite precision and other continuous matters, and (ii) possible evolutions of a system of finite size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> in discrete steps of time and size, where both are unbounded but (in positive cases) finite.</p>
<p>
</p><p></p><h2> A Flashback? </h2><p></p>
<p></p><p>
The results strikes Dick and me as shedding new light on a <a href="https://en.wikipedia.org/wiki/Church-Turing-Deutsch_principle">principle</a> stated by David Deutsch in a 1985 <a href="https://www.cs.princeton.edu/courses/archive/fall04/cos576/papers/deutsch85.pdf">paper</a>: </p>
<blockquote><p><b> </b> <em> Every finitely realisable physical system can be perfectly simulated by a universal model computing machine operating by finite means. </em>
</p></blockquote>
<p></p><p>
I was a student at Oxford alongside Deutsch in 1984–1985, and I remember more going on than the searchable record seems to reflect. Deutsch believed that his model of a quantum computer could solve the Halting problem in finite time. He gave at least one talk at the Oxford Mathematical Institute on that claim. As far as I know the claim stayed local to Oxford and generated intense discussion led by Robin Gandy, Roger Penrose, and (if I recall) Angus Macintyre and at least one other person who was versed in random physical processes. </p>
<p>
My recollection is that the nub of the technical argument turned on a property of infinite random sequences that, when hashed out, made some associated predicates decidable, so that Deutsch’s functions were classically total computable after all. Thus the hypercomputation claim was withdrawn. </p>
<p>
Now, however, I wonder whether the two-prover system constitutes the kind of “machine” that Deutsch was <em>intuitively</em> thinking of. As I recall, his claim was not deemed wrong from first principles but from how theorems about random sequences interacted with machine model definitions. The theory of interactive provers as computational systems was then in its infancy. Could Deutsch have had some inkling of it? </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Again we congratulate JNVWY on this achievement of a long-term research goal. Looking at the past, does it relate to the discussion of hypercomputation stemming from the 1980s? We mean a stronger connection than treated <a href="https://plato.stanford.edu/entries/qt-quantcomp/#ChurTuriThesDeutPrin">here</a> or in this 2018 <a href="https://arxiv.org/pdf/quant-ph/0110136.pdf">paper</a>.  Is it much different from ones where “the mystery … vanishes when the level of precision is explicitly taken into account” (quoting <a href="https://egtheory.wordpress.com/2014/09/01/falsifiability-and-gandys-variant-of-the-church-turing-thesis/">this</a>). Looking ahead, are there any connection to the physical issues of infinity in finite time that we recently discussed <a href="https://rjlipton.wordpress.com/2019/10/31/hobgoblins-in-our-equations/">here</a>?</p>
<p></p><p><br />
<b>Updates 1/17:</b> Gil Kalai has a <a href="https://gilkalai.wordpress.com/2020/01/17/amazing-zhengfeng-ji-anand-natarajan-thomas-vidick-john-wright-and-henry-yuen-proved-that-mip-re-and-thus-disproved-connes-1976-embedding-conjecture-and-provided-a-negative-answer-to-tsirelso/">post</a> with background on further conjectures impacted by (the failure of) Connes’s conjecture and on quantum prover systems, plus a plethora of links.</p>
<p>
A new <a href="https://www.nature.com/articles/d41586-020-00120-6">article</a> in <i>Nature</i> includes the following quotations:</p>
<ul>
<li>
Alain Connes, after saying he was not (yet) able to digest all the material involved in the proof: “It is amazing that the [embedding] problem went so deep and I never foresaw that!”<p></p>
</li><li>
Tony Cubitt, University College of London: “What’s amazing is that quantum complexity theory has been the key to the proof.”<p></p>
</li><li>
Joseph Fitzsimons, Horizon Quantum Computing: “I thought it would turn out to be one of those complexity-theory questions that might take 100 years to answer.”
</li></ul>
<p>The article and comments on Scott’s blog include interpretations that seem to oppose rather than support Deutsch’s principle on the finiteness of nature.  The tandem of two unlimited provers may not qualify as a “finite machine.”</p>
<p>
There are comments below querying whether the theorem is in first-order arithmetic or how strong a choice axiom it may need.</p>
<p></p><p><br />
[added to first paragraph in second section, added updates]</p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/"><span class="datestr">at January 15, 2020 09:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7627">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/01/15/intro-tcs-recap/">Intro TCS recap</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This semester I taught <a href="https://cs121.boazbarak.org/">another iteration</a> of my “Introduction to Theoretical Computer Science” course, based on my <a href="https://introtcs.org/">textbook in process</a>.  The book was also used in <a href="https://uvatoc.github.io/">University of Virgnia CS 3102</a> by David Evans and Nathan Brunelle.</p>



<p>The main differences I made in the text and course since its <a href="https://windowsontheory.org/2017/07/27/rethinking-the-intro-theory-course/">original version </a>were to make it less “idiosyncratic”: while I still think using programming language terminology is the conceptually “right” way to teach this material, there is a lot to be said for sticking with well-established models. So, I used <strong>Boolean circuits</strong> as the standard model for finite-input non-uniform computation, and <strong>Turing Machines</strong>, as the standard model for unbounded-input uniform computation. (I do talk about the equivalent programming languages view of both models, which can be a more useful perspective for some results, and is also easier to <a href="https://github.com/boazbk/tcscode">work with in code</a>.)</p>



<p>In any course on intro to theoretical CS, there are always beautiful topics that are left on the “cutting room floor”. To partially compensate for that, we had an entirely optional “advanced section” where guest speakers talked about topics such as error correcting codes, circuit lower bounds,  communication complexity, interactive proofs, and more. The TA in charge of this section – amazing sophomore named <a href="https://singerng.github.io/">Noah Singer</a> – wrote <a href="https://windowsontheory.files.wordpress.com/2020/01/cs_121_5_notes_2019-2.pdf">very detailed lecture notes</a>  for this section.</p>



<p>This semester, students in CS 121 could also do an optional project. Many chose to do a video about topics related to the course, here are some examples:</p>



<ul><li>Helen Huang and Phil Labrum: <a href="https://youtu.be/28lsaX7vZho">“Is your brain Turing complete?”</a> </li><li>Dylan Zhou:  <a href="https://youtu.be/bpSBCFDPoXw" target="_blank" rel="noreferrer noopener">Candy Crush</a> is NP complete and <a href="https://youtu.be/zjr-0HhHWHM" target="_blank" rel="noreferrer noopener">Mario Kart tour</a> is PSPACE hard.</li><li>Carolyn Ge, Kavya Kopparapu, and Eric Lin: a 4-part series on theory of machine learning including an interview with Les Valiant: <a href="https://youtu.be/fIbKT0s-Dyw" target="_blank" rel="noreferrer noopener">What is learnability?</a> <a href="https://youtu.be/9-CVk2b8mec" target="_blank" rel="noreferrer noopener">Cryptographic limitations</a>, <a href="https://youtu.be/F8s3QdfJs48" target="_blank" rel="noreferrer noopener">Cryptography and Machine Learning</a>, and <a href="https://youtu.be/LUyDekgRP_8" target="_blank" rel="noreferrer noopener">future possibilities</a>.</li><li>And finally, Christine Cai, April Chen, Zev Nicolai-Scanio, and Grace Tian produced a rap song <a href="https://docs.google.com/document/d/1aeOqdN8ItqSfXFepJXSCrTGaS-aBL1ZFXltw6LAVgZc/edit">“Proof Göds”</a> inspired by the course.</li></ul>



<p>There is much work to still do on both the text and the course. Though the text has improved a lot (we do have <a href="https://github.com/boazbk/tcs/issues">267 closed issues</a> after all) some students still justifiably complained about typos, which can throw off people that are just getting introduced to the topic. I also want to add significantly more solved exercises and examples, since students do find them extremely useful. I need to significantly beef up the NP completeness chapter with more examples of reductions, though I do have Python implementation of <a href="https://github.com/boazbk/tcscode/blob/master/Chap_13_reductions.ipynb">several reductions </a>and the <a href="https://github.com/boazbk/tcscode/blob/master/Lec_17_Cook_Levin.ipynb">Cook Levin theorem</a>.</p>



<p>This type of course is often known as a “great ideas” in computer science, and so in the book I also added a “Big Idea” environment to highlight those. Of course some of those ideas are bigger than others, but I think the list below reflects well the contents of the course:</p>



<ul><li>If we can represent objects of type T as strings, then we can represent tuples of objects of type T as strings as well.</li><li>A <em>function</em> is not the same as a <em>program</em>. A program <em>computes</em> a function.</li><li>Two models are <em>equivalent in power </em> if they can be used to compute  the same set of functions.</li><li><em>Every</em> finite function can be computed by a large enough Boolean  circuit.</li><li>A <em>program</em> is a piece of text, and so it can be fed as input to other  programs.</li><li>Some functions  <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B0%2C1%5C%7D%5En%C2%A0%5Crightarrow%C2%A0%5C%7B0%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:\{0,1\}^n \rightarrow \{0,1\}" class="latex" title="f:\{0,1\}^n \rightarrow \{0,1\}" />  <em>cannot</em> be computed by a Boolean circuit using fewer than exponential (in <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />) number of gates.</li><li>We can precisely define what it means for a function to be computable by<em>  any possible algorithm</em>.</li><li>Using equivalence results such as those between Turing and RAM machines, we can <em>“have our cake and eat it too”</em>: We can use a simpler model such as Turing machines when we want to prove something <em>can’t </em> be done, and use a feature-rich model such as RAM machines when we want to prove something <em>can</em> be done.</li><li>There is a  <em>“universal” </em>algorithm that can evaluate arbitrary algorithms on arbitrary inputs.</li><li>There are some functions that <em>can not</em> be computed by <em>any</em> algorithm.</li><li>If a function <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" /> is uncomputable we can show that another function <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" /> is uncomputable by giving a way to <em>reduce</em> the task of computing <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" /> to computing <img src="https://s0.wp.com/latex.php?latex=H&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="H" class="latex" title="H" />.</li><li>We can use <em>restricted computational models</em> to bypass limitations such as uncomputability of the Halting problem and Rice’s Theorem. Such models can compute only a restricted subclass of functions, but allow to answer at least some <em>semantic questions</em> on programs.</li><li>A <em>proof</em> is just a string of text whose meaning is given by a <em>verification algorithm</em>.</li><li>The running time of an algorithm is not a <em>number</em>, it is a <em>function</em> of the length of the input.</li><li>For a function <img src="https://s0.wp.com/latex.php?latex=F%3A%7B0%2C1%7D%5E%2A+%5Crightarrow+%7B0%2C1%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F:{0,1}^* \rightarrow {0,1}" class="latex" title="F:{0,1}^* \rightarrow {0,1}" /> and <img src="https://s0.wp.com/latex.php?latex=T%3A%5Cmathbb%7BN%7D+%5Crightarrow+%5Cmathbb%7BN%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T:\mathbb{N} \rightarrow \mathbb{N}" class="latex" title="T:\mathbb{N} \rightarrow \mathbb{N}" />, we can formally define what it means for <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" /> to be computable in time at most <img src="https://s0.wp.com/latex.php?latex=T%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T(n)" class="latex" title="T(n)" /> where <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" /> is the size of the input.</li><li>All “reasonable” computational models are equivalent if we only care about the distinction between  polynomial and exponential. (The book immediately notes quantum computers as a possible exception for this.)</li><li>If we have more time, we can compute more functions.</li><li>By “unrolling the loop” we can transform an algorithm that takes <img src="https://s0.wp.com/latex.php?latex=T%28n%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="T(n)" class="latex" title="T(n)" /> steps to compute <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" /> into a circuit that uses <img src="https://s0.wp.com/latex.php?latex=poly%28T%28n%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="poly(T(n))" class="latex" title="poly(T(n))" /> gates to compute the restriction of <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" /> to <img src="https://s0.wp.com/latex.php?latex=%7B0%2C1%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="{0,1}^n" class="latex" title="{0,1}^n" />.</li><li>A <em>reduction</em> <img src="https://s0.wp.com/latex.php?latex=F+%5Cleq_p+G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F \leq_p G" class="latex" title="F \leq_p G" /> shows that <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" /> is “no harder than <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" />” or equivalently that <img src="https://s0.wp.com/latex.php?latex=G&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="G" class="latex" title="G" /> is “no easier than <img src="https://s0.wp.com/latex.php?latex=F&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="F" class="latex" title="F" />“.</li><li>If a <em>single</em> <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BNP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{NP}" class="latex" title="\mathbf{NP}" />-complete has a polynomial-time algorithm, then there is such an algorithm for every decision problem that corresponds to the existence of an <em>efficiently-verifiable</em> solution.</li><li>If <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BP%7D%3D%5Cmathbf%7BNP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{P}=\mathbf{NP}" class="latex" title="\mathbf{P}=\mathbf{NP}" />, we can efficiently solve a fantastic number of decision, search, optimization, counting, and sampling problems from all areas of human endeavors.</li><li>A randomized algorithm outputs the correct value with good probability on <em>every possible input</em>.</li><li>We can <em>amplify</em> the success of randomized algorithms to a value that is arbitrarily close to <img src="https://s0.wp.com/latex.php?latex=1&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1" class="latex" title="1" />.</li><li>There is no <em>secrecy</em> without <em>randomness</em>.</li><li><em>Computational hardness</em> is <em>necessary and sufficient</em> for almost all cryptographic applications.</li><li>Just as we did with classical computation, we can define mathematical models for quantum computation, and represent quantum algorithms as binary strings.</li><li>Quantum computers are not a panacea and are unlikely to solve <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BNP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{NP}" class="latex" title="\mathbf{NP}" /> complete problems, but they can provide exponential speedups to certain <em>structured</em> problems.</li></ul>



<p>These are all ideas that I believe are important for Computer Science undergraduates to be exposed to, but covering all of these does make for a every challenging course, which gets literally mixed reviews from the students, with some loving it and some hating it. (I post all reviews on the course home page.) Running a 200-student class is definitely something that I’m still learning how to do. </p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/01/15/intro-tcs-recap/"><span class="datestr">at January 15, 2020 08:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/01/15/ibm-goldstine-postdoctoral-fellowship-at-ibm-research-apply-by-january-20-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/01/15/ibm-goldstine-postdoctoral-fellowship-at-ibm-research-apply-by-january-20-2020/">IBM Goldstine Postdoctoral Fellowship at IBM Research (apply by January 20, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Update: The Fellowship has been extended to all IBM Research locations, including the Almaden laboratory. The Mathematical Sciences Council of IBM Research invites applications for the Herman Goldstine Memorial Postdoctoral Fellowship for research in mathematical and computer sciences. Areas of interest include theoretical computer science and optimization.</p>
<p>Website: <a href="https://www.research.ibm.com/goldstine/">https://www.research.ibm.com/goldstine/</a><br />
Email: postdoc@us.ibm.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/01/15/ibm-goldstine-postdoctoral-fellowship-at-ibm-research-apply-by-january-20-2020/"><span class="datestr">at January 15, 2020 08:09 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/003">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/003">TR20-003 |  Tight Static Lower Bounds for Non-Adaptive Data Structures | 

	Giuseppe Persiano, 

	Kevin Yeo</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper, we study the static cell probe complexity of non-adaptive data structures that maintain a subset of $n$ points from a universe consisting of $m=n^{1+\Omega(1)}$ points. A data structure is defined to be non-adaptive when the memory locations that are chosen to be accessed during a query depend only on the query inputs and not on the contents of memory. We prove an $\Omega(\log m / \log (sw/n\log m))$ static cell probe complexity lower bound for non-adaptive data structures that solve the fundamental dictionary problem where $s$ denotes the space of the data structure in the number of cells and $w$ is the cell size in bits. Our lower bounds hold for all word sizes including the bit probe model ($w = 1$) and are matched by the upper bounds of Boninger et al. [FSTTCS'17].

Our results imply a sharp dichotomy between dictionary data structures with one round of adaptive and at least two rounds of adaptivity. We show that $O(1)$, or $O(\log^{1-\epsilon}(m))$, overhead dictionary constructions are only achievable with at least two rounds of adaptivity. In particular, we show that many $O(1)$ dictionary constructions with two rounds of adaptivity such as cuckoo hashing are optimal in terms of adaptivity. On the other hand, non-adaptive dictionaries must use significantly more overhead.

Finally, our results also imply static lower bounds for the non-adaptive predecessor problem. Our static lower bounds peak higher than the previous, best known lower bounds of $\Omega(\log m / \log w)$ for the dynamic predecessor problem by Boninger et al. [FSTTCS'17] and Ramamoorthy and Rao [CCC'18] in the natural setting of linear space $s = \Theta(n)$ where each point can fit in a single cell $w = \Theta(\log m)$. Furthermore, our results are stronger as they apply to the static setting unlike the previous lower bounds that only applied in the dynamic setting.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/003"><span class="datestr">at January 15, 2020 02:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6568540622933428053">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/01/quantum-provers-to-infinity-and-beyond.html">Quantum Provers to Infinity and Beyond</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The Internets are buzzing about the new paper <a href="https://arxiv.org/pdf/2001.04383">MIP* = RE</a> by Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright and Henry Yuen. See posts by <a href="https://www.scottaaronson.com/blog/?p=4512">Scott</a>, <a href="https://windowsontheory.org/2020/01/14/mipre-connes-embedding-conjecture-disproved/">Boaz</a>, not to mention a wonderful backstory by <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">Vidick</a> himself and a <a href="https://twitter.com/henryquantum/status/1216936907814375424">tweet stream</a> by Yeun. I'm not an expert enough to verify or even try to explain the proof so I'll just give a brief overview of the result.<br />
<br />
For those not familiar with the classes, RE (recursively enumerable) is the simplest of all complexity classes, a language is in RE if there is some Turing machine M such that x is in L if and only if M on input x accepts. For x not in L, M on x can reject or run forever. The classic halting problem, the set of descriptions of Turing machines that halt on empty input, is RE-complete. To nitpick the notation, it should have been r.e. and even c.e. (computably enumerable), a more <a href="https://blog.computationalcomplexity.org/2004/02/is-it-recursive-computable-or.html">standard notation</a> these days. But given the importance of the result, we can give the authors a pass.<br />
<br />
MIP* is the set of things provable to a classically random polynomial-time verifier by two separated provers with an unlimited number of quantumly entangled qubits. Without the quantum entanglement, MIP = NEXP, nondeterministic exponential time, and last year Natarajan and Wright showed that MIP* could do at least exponentially better in their paper, <a href="https://arxiv.org/abs/1904.05870">NEEXP in MIP*</a>. NEEXP seems large but still only consists of computable sets. RE gets outside of the computable realm.<br />
<br />
I found the first paper more surprising, as it showed that quantum entanglement actually gets more, much more, than classical provers. The second paper does get a much stronger and tight result, and still highly surprising in its own right, as it requires disproving the <a href="https://en.wikipedia.org/wiki/Connes_embedding_problem">Connes' embedding conjecture</a>. In the end we may just consider this one result, as the second paper subsumes the first both in theorem and authors.<br />
<br />
We didn't award the <a href="https://blog.computationalcomplexity.org/2019/12/complexity-year-in-review-2019.html">2019 theorem of the year</a> to Natarajan and Wright, instead opting for a paper that had more, how should I say this, sensitivity. This new paper is certainly the front runner for the 2020 honors, albeit it is only mid-January.</div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/01/quantum-provers-to-infinity-and-beyond.html"><span class="datestr">at January 14, 2020 11:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-5091842844297998945">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2020/01/itcs-2020-reflections.html">ITCS 2020, Reflections</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
I've spent Sunday/Monday at <a href="http://itcs-conf.org/index.html">ITCS</a>, or Innovations in Theoretical Computer Science, where I am giving a talk on this paper on <a href="https://drops.dagstuhl.de/opus/volltexte/2020/11699/">Scheduling with Prediction and the Price of Misprediction</a> (LIPIcs page) (which is one of several recent works on <a href="http://www.eecs.harvard.edu/~michaelm/Talks/ALGO2109.pptx">Algorithms with Predictions</a> (powerpoint slides)).<br /><br />I'm told it's 10 years since ITCS started as a conference, and I was one of the skeptics that really did not think it was a good idea 10 years ago.  So as I'm sitting in the sessions, what do I think now?  What are the pros and cons of ITCS?<br /><br />On the negative side, ITCS is not very big.  It is just over 100 people registered, so it's like a big workshop/small conference size.  (And considering that it's usually held in central places with lots of students, those numbers are buffered by locals.)  Somehow, it's scheduled the 2nd week of January, right after SODA, which seems problematic, and certainly (if it's kept that way) may keep it from getting any larger.  The number of "senior people" around at any one time seemed generally small, a problem for things like "Graduating Bits" (see below).  As ITCS, at least 10 years ago, was supposed to build up to another "premier" TCS conference, focused on "innovative" work, the attendance seems a bit disappointing.<br /><br />On the neutral side, the conference is single-session, and to make that work, talks this year are limited to 12 minutes.  Your mileage may vary on whether you think this is good or bad;  it seems to work.  (My take:  I slightly prefer parallel sessions, because it means there's more times where there's something I want to see, and that's more important than the times where there are two talks at the same time I want to see.  And 12 minutes is certainly workable but maybe a few minutes short.  But again, that's just my opinion.)  This year (and possibly going forward), some papers were accepted without a full talk -- instead they have a 3-minute talk and a poster in a poster session.  Again, it's not clear to me if this is good or bad (though more paper acceptances makes me lean to the good side), but it seemed to work fine and people were happy with it.  (Such papers are considered full publications and treated the same in the proceedings.)<br /><br />On the positive side, the conference seems well run.  It's held in a university building, so no expensive hotel costs;  instead they're generous with food and keep registration costs reasonably low.  They use <a href="https://www.dagstuhl.de/en/publications/lipics">LIPIcs</a>, which provides a good system and approach for publishing papers at low cost.  (Note, I was until recently part of the LIPIcs editorial board, so I'm biased there.)  They seem to be covering their expenses from what I understand.  The business meeting was blessedly short.  They're recording all the talks.  They're doing interesting things like "Graduating Bits" for people who are job-looking (where people graduating or coming out of a postdoc give short talks about their work).<br /><br />In terms of content, it seems really good.  I've seen several good talks and interesting papers.  While I'm not sure how to quantify whether ITCS work is more "innovative" than the work at other major TCS conferences, I do actually think they are noticeably more open at ITCS than other conferences about accepting papers based on the paper's underlying idea rather than on "technical mastery".<br /><br />My thoughts 10 years ago were that ITCS was not a great outcome for the community, and that instead the community should push for:<br /><br />1)  Aiming to do better about opening up the criteria for paper acceptance, including weighing innovation/practical relevance in reviewing papers at FOCS/STOC/SODA.<br />2)  Increasing the number of papers accepted to these conferences, as too many good papers were being rejected.<br /><br />Viewed under this lens, ITCS could, I think, be viewed as a success.  The theory community seems unwilling to expand conferences by accepting more papers.  (I note that while the STOC theory-fest has changed and expanded STOC, it hasn't really seemed to increase attendance, and while the number of accepted papers has increased slightly, it hasn't kept pace with the growth in the field.)  ITCS provides another venue for high-quality theory papers, thereby increasing the number of such papers published each year within the theory community, and I think it is generally viewed as a high-quality conference.  And, as I mentioned, ITCS seems at least somewhat more flexible in its criteria for what is an acceptable paper.  ITCS has, I think, in these regards been a benefit for the theory community.<br /><br />However, despite the success of ITCS, I think it's a band-aid on structural issues in the theory community.  While these issues are complex and many-sided, just comparing with the growth and excitement in the AI community is a little depressing.  Indeed, what I see is AI <i>absorbing</i> significant parts of the theory community;  lots of theory papers now end up at NeurIPS, AAAI, ICML, or AISTATS, because the theory community doesn't seem to have room for them, or doesn't judge them as sufficiently significant.  I view this as a problem for the theory community, the result of the problems I saw 10 years ago for which I didn't think ITCS was the right response.  (Though perhaps it was/is not really viewed as a problem by others;  all of CS, including theory, seems to continue growing;  theory just seems to me to be growing less than it could or should.)<br /><br />To conclude, my thanks and congratulations to those many people that have organized and maintained ITCS over the years;  I appreciate your work, as I think the whole community does.  <br /><br />By the way, I thought it never snowed in Seattle, so I'm confused; what is all the cold white stuff outside?</div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2020/01/itcs-2020-reflections.html"><span class="datestr">at January 14, 2020 08:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7618">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/01/14/mipre-connes-embedding-conjecture-disproved/">MIP*=RE, disproving Connes embedding conjecture.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In an exciting <a href="https://arxiv.org/abs/2001.04383">manuscript just posted on the arxiv</a>, Zhengfeng Ji, Anand Natarajan, Thomas Vidick, John Wright, and Henry Yuen prove that there is a 2-prover quantum protocol (with shared entanglement) for the halting problem. As a consequence they resolve negatively a host of open problems in quantum information theory and operator algebra, including refuting the longstanding <a href="https://en.wikipedia.org/wiki/Connes_embedding_problem">Connes embedding conjecture</a>. See also <a href="https://www.scottaaronson.com/blog/?p=4512">Scott’s post</a> and <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">this blog post</a> of Thomas Vidick discussing his personal history with these questions, that started with his Masters project under Julia Kempe’s supervision 14 years ago.</p>



<p>I am not an expert in this area, and still have to look the paper beyond the first few pages, but find the result astounding. In particular, the common intuition is that since all physical quantities are “nice” function (continuous, differentiable, etc..), we could never distinguish between the case that the universe is infinite or discretized at a fine enough grid.  The new work (as far as I understand) provides a finite experiment that can potentially succeed with probability 1 if the two provers use an infinite amount of shared entangled state, but would succeed with probability at most 1/2 if they use only a finite amount. A priori you would expect that if there is a strategy that succeeds with probability 1 with an infinite entanglement, then you could succeed with probability at least <img src="https://s0.wp.com/latex.php?latex=1-%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="1-\epsilon" class="latex" title="1-\epsilon" /> with a finite entangled state whose dimension depends only on <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\epsilon" class="latex" title="\epsilon" />.</p>



<p>The result was preceded by Ito and Vidick’s 2012 result that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BNEXP%7D+%5Csubseteq+%5Cmathbf%7BMIP%5E%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{NEXP} \subseteq \mathbf{MIP^*}" class="latex" title="\mathbf{NEXP} \subseteq \mathbf{MIP^*}" /> and Natarajan and Wright’s result last year that <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BNEEXP%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{NEEXP}" class="latex" title="\mathbf{NEEXP}" /> (non deterministic <em>double exponential</em> time) is contained in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbf%7BMIP%5E%2A%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathbf{MIP^*}" class="latex" title="\mathbf{MIP^*}" />. This brings to mind Edmonds’ classic quote that:</p>



<blockquote class="wp-block-quote"><p><em>“For practical purposes the difference between algebraic and exponential order is often more crucial than the difference between finite and non-finite”</em></p></blockquote>



<p>sometimes, the difference between double-exponential and infinite turns out to be non-existent.. </p>



<p></p>



<p></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/01/14/mipre-connes-embedding-conjecture-disproved/"><span class="datestr">at January 14, 2020 05:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4512">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4512">MIP*=RE</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong>Another Update (Jan. 16):</strong> Yet another reason to be excited about this result—one that somehow hadn’t occurred to me—is that, as far as I know, it’s the first-ever fully convincing example of a <em>non-relativizing computability result</em>.  See <a href="https://www.scottaaronson.com/blog/?p=4512#comment-1828321">this comment</a> for more.</p>



<p><strong>Update:</strong> If you’re interested in the above topic, then you should probably stop reading this post right now, and switch to <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">this better post</a> by Thomas Vidick, one of the authors of the new breakthrough.  (Or <a href="https://windowsontheory.org/2020/01/14/mipre-connes-embedding-conjecture-disproved/">this</a> by Boaz Barak or <a href="https://blog.computationalcomplexity.org/2020/01/quantum-provers-to-infinity-and-beyond.html">this</a> by Lance Fortnow or <a href="https://rjlipton.wordpress.com/2020/01/15/halting-is-poly-time-quantum-provable/">this</a> by Ken Regan.)  (For background, also see <a href="https://www.ams.org/journals/notices/201910/rnoti-p1618.pdf">Thomas Vidick’s excellent piece</a> for the <em>AMS Notices</em>.)</p>



<p>Still here?  Alright, alright…</p>



<p><a href="https://arxiv.org/abs/2001.04383">Here’s the paper</a>, which weighs in at 165 pages.  The authors are <a href="https://www.uts.edu.au/staff/zhengfeng.ji">Zhengfeng Ji</a>, <a href="http://www.its.caltech.edu/~anataraj/">Anand Natarajan</a>, my former postdoc <a href="http://users.cms.caltech.edu/~vidick/">Thomas Vidick</a>, <a href="https://www.cs.utexas.edu/people/faculty-researchers/john-wright">John Wright</a> (who will be joining the CS faculty here at UT Austin this fall), and my wife Dana’s former student <a href="http://www.henryyuen.net/">Henry Yuen</a>.  Rather than pretending that I can provide intelligent commentary on this opus in the space of a day, I’ll basically just open my comment section to discussion and quote the abstract:</p>



<blockquote class="wp-block-quote"><p>We show that the class MIP* of languages that can be decided by a classical verifier interacting with multiple all-powerful quantum provers sharing entanglement is equal to the class RE of recursively enumerable languages.  Our proof builds upon the quantum low-degree test of (Natarajan and Vidick, FOCS 2018) by integrating recent developments from (Natarajan and Wright, FOCS 2019) and combining them with the recursive compression framework of (Fitzsimons et al., STOC 2019).<br />An immediate byproduct of our result is that there is an efficient reduction from the Halting Problem to the problem of deciding whether a two-player nonlocal game has entangled value 1 or at most 1/2.  Using a known connection, undecidability of the entangled value implies a negative answer to Tsirelson’s problem: we show, by providing an explicit example, that the closure <em>C<sub>qa</sub></em> of the set of quantum tensor product correlations is strictly included in the set <em>C<sub>qc</sub></em> of quantum commuting correlations.  Following work of (Fritz, Rev. Math. Phys. 2012) and (Junge et al., J. Math. Phys. 2011) our results provide a refutation of Connes’ embedding conjecture from the theory of von Neumann algebras. </p></blockquote>



<p>To say it differently (in response to a commenter’s request), some of the major implications are as follows.</p>



<p>(1) There is a protocol by which two entangled provers can convince a polynomial-time verifier of the answer to <em>any computable problem whatsoever</em> (!!), or indeed that a given Turing machine halts.</p>



<p>(2) There is a two-prover game, analogous to the Bell/CHSH game, for which Alice and Bob can do markedly better with a <em>literally infinite</em> amount of entanglement than they can with any finite amount of entanglement.</p>



<p>(3) There is no algorithm even to <em>approximate</em> the entangled value of a two-prover game (i.e., the probability that Alice and Bob win the game, if they use the best possible strategy and as much entanglement as they like). Instead, this problem is equivalent to the halting problem.</p>



<p>(4) There are types of correlations between Alice and Bob that can be produced using infinite entanglement, but that can’t even be approximated using any finite amount of entanglement.</p>



<p>(5) The Connes embedding conjecture, a central conjecture from the theory of operator algebras dating back to the 1970s, is false.</p>



<p>Note that all of these implications—including the ones for pure math and the foundations of quantum physics—were obtained using tools that originated in theoretical computer science, specifically the study of interactive proof systems.</p>



<p>I can remember when the class MIP* was first defined and studied, back around 2003, and people made the point that we didn’t know any reasonable upper bound on the class’s power—not NEXP, not NEEEEXP, not even the set of all computable languages.  Back then, the joke was how far our <em>proof techniques</em> were from what was self-evidently the truth.  I don’t remember a single person who seriously contemplated that two entangled provers could convince a polynomial-time verifier than an arbitrary Turing machine halts.</p>



<p>Still, ever since Natarajan and Wright’s <a href="https://www.quantamagazine.org/computer-scientists-expand-the-frontier-of-verifiable-knowledge-20190523/">NEEXP in MIP*</a> breakthrough last year, all of us in quantum computing theory knew that MIP*=RE was a live possibility—and all through the summer and fall, I heard many hints that such a breakthrough was imminent.</p>



<p>It’s worth pointing out that, with only classical correlations between the provers, MIP gives “merely” the power of NEXP (Nondeterministic Exponential Time), while with arbitrary non-signalling correlations between the provers, the so-called MIP<sub>ns</sub> gives the power of EXP (Deterministic Exponential Time).  So it’s particularly striking that quantum entanglement, which is “intermediate” between classical correlations and arbitrary non-signalling correlations, yields such wildly greater computational power than either of those two.</p>



<p>The usual proviso applies: when I’ve blogged excitedly about preprints with amazing new results, most have stood, but at least two ended up being retracted.  Still, assuming this one stands (as I’m guessing it will), I regard it as <em>easily</em> one of the biggest complexity-theoretic (and indeed computability-theoretic!) surprises so far in this century.  Huge congratulations to the authors on what looks to be a historic achievement.</p>



<p>In unrelated news, for anyone for whom the 165-page MIP* paper is too heavy going (really??), please enjoy this <a href="https://www.youtube.com/watch?v=u1XXjWr5frE">CNBC video on quantum computing</a>, which features several clips of yours truly speaking in front of a fake UT tower.</p>



<p>In other unrelated news, I’m also excited about <a href="https://arxiv.org/abs/1912.12561">this preprint</a> by Avishay Tal, which sets a new record for the largest known separation between quantum query complexity and classical randomized query complexity, making substantial progress toward proving a conjecture by me and Andris Ambainis from 2015.  (Not <em>the</em> “Aaronson-Ambainis Conjecture,” a different conjecture.)</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4512"><span class="datestr">at January 14, 2020 04:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3458">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2020/01/14/ec20-workshops-and-tutorials-call-for-proposals/">EC20 workshops and tutorials: call for proposals</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The <a href="http://ec20.sigecom.org/">ACM EC20 conference</a> to be held on July 13-17, 2020 in Budapest is now <a href="http://ec20.sigecom.org/call-for-contributions/workshops-tutorials/">calling for proposals for tutorials and workshops</a>.  The deadline for submission of such proposals is March 2nd, 2020.</p></div>







<p class="date">
by Noam Nisan <a href="https://agtb.wordpress.com/2020/01/14/ec20-workshops-and-tutorials-call-for-proposals/"><span class="datestr">at January 14, 2020 09:56 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://mycqstate.wordpress.com/?p=1234">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/vidick.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/">A Masters project</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In a <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">previous post</a> I reported on the beautiful <a href="https://arxiv.org/abs/1904.05870">recent result</a> by Natarajan and Wright showing the astounding power of multi-prover interactive proofs with quantum provers sharing entanglement: in letters, <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEEXP%7D+%5Csubseteq+%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{NEEXP} \subseteq \text{MIP}^\star}" class="latex" title="{\text{NEEXP} \subseteq \text{MIP}^\star}" />. In this post I want to report on follow-up work with Ji, Natarajan, Wright, and Yuen, that we just posted to <a href="https://arxiv.org/abs/2001.04383">arXiv</a>. This time however I will tell the story from a personal point of view, with all the caveats that this implies: the “hard science” will be limited (but there could be a hint as to how “science”, to use a big word, “progresses”, to use an ill-defined one), the story is far too long, and it might be mostly of interest to me only. It’s a one-sided story, but that has to be. (In particular below I may at times attribute credit in the form “X had this idea”. This is my recollection only, and it is likely to be inaccurate. Certainly I am ignoring a lot of important threads.) I wrote this because I enjoyed recollecting some of the best moments in the story just as much as some the hardest; it is fun to look back and find meanings in ideas that initially appeared disconnected. Think of it as an example of how different lines of work can come together in unexpected ways; a case for open-ended research. It’s also an antidote against despair that I am preparing for myself: whenever I feel I’ve been stuck on a project for far too long, I’ll come back to this post and ask myself if it’s been 14 years yet — if not, then press on.</p>
<p>It likely comes as a surprise to me only that I am no longer fresh out of the cradle. My academic life started in earnest some 14 years ago, when in the Spring of 2006 I completed my Masters thesis in Computer Science under the supervision of Julia Kempe, at Orsay in France. I had met Julia the previous term: her class on quantum computing was, by far, the best-taught and most exciting course in the Masters program I was attending, and she had gotten me instantly hooked. Julia agreed to supervise my thesis, and suggested that I look into some interesting recent result by Stephanie Wehner that linked the study of entanglement and nonlocality in quantum mechanics to complexity-theoretic questions about interactive proof systems (specifically, this was Stephanie’s <a href="https://arxiv.org/abs/quant-ph/0508201">paper</a> showing that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar+%5Csubseteq+%5Ctext%7BQIP%7D%282%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{XOR-MIP}^\star \subseteq \text{QIP}(2)}" class="latex" title="{\text{XOR-MIP}^\star \subseteq \text{QIP}(2)}" />).</p>
<p>At the time the topic was very new. It had been initiated the previous year with a beautiful <a href="https://arxiv.org/abs/quant-ph/0404076">paper</a> by Cleve et al. (that I have recommended to many a student since!). It was a perfect fit for me: the mathematical aspects of complexity theory and quantum computing connected to my undergraduate background, while the relative concreteness of quantum mechanics (it is a physical theory after all) spoke to my desire for real-world connection (not “impact” or even “application” — just “connection”). Once I got myself up to speed in the area (which consisted of three papers: the two I already mentioned, together with a <a href="https://arxiv.org/abs/cs/0102013">paper</a> by Kobayashi and Matsumoto where they studied interactive proofs with quantum messages), Julia suggested looking into the the “entangled-prover” class <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> introduced in the aforementioned paper by Cleve et al. Nothing was known about this class! Nothing besides the trivial inclusion of single-prover interactive proofs, IP, and the containment in…ALL, the trivial class that contains all languages.<br />
Yet the characterization MIP=NEXP of its classical counterpart by Babai et al. in the 1990s had led to one of the most productive lines of work in complexity of the past few decades, through the PCP theorem and its use from hardness of approximation to efficient cryptographic schemes. Surely, studying <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> had to be a productive direction? In spite of its well-established connection to classical complexity theory, via the formalism of interactive proofs, this was a real gamble. The study of entanglement from the complexity-theoretic perspective was entirely new, and bound to be fraught with difficulty; very few results were available and the existing lines of works, from the foundations of nonlocality to more recent endeavors in device-independent cryptography, provided little other starting point than strong evidence that even the simplest examples came with many unanswered questions. But my mentor was fearless, and far from a novice in terms of defraying new areas, having done pioneering work in areas ranging from quantum random walks to Hamiltonian complexity through adiabatic computation. Surely this would lead to something?</p>
<p>It certainly did. More sleepless nights than papers, clearly, but then the opposite would only indicate dullness. Julia’s question led to far more unexpected consequences than I, or I believe she, could have imagined at the time. I am writing this post to celebrate, in a personal way, the latest step in 15 years of research by dozens of researchers: today my co-authors and I uploaded to the quant-ph arXiv what we consider a complete characterization of the power of entangled-prover interactive proof systems by proving the equality <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star = \text{RE}}" class="latex" title="{\text{MIP}^\star = \text{RE}}" />, the class of all recursively enumerable languages (a complete problem for RE is the halting problem). Without goign too much into the result itself (if you’re interested, we have a long introduction waiting for you), and since this is a personal blog, I will continue on with some personal thoughts about the path that got us there.</p>
<p>When Julia &amp; I started working on the question, our main source of inspiration were the results by Cleve et al. showing that the nonlocal correlations of entanglement had interesting consequences when seen through the lens of interactive proof systems in complexity theory. Since the EPR paper a lot of work in understanding entanglement had already been accomplished in the Physics community, most notably by Mermin, Peres, Bell, and more recently the works in device-indepent quantum cryptography by Acin, Pironio, Scarani and many others stimulated by Ekert’s proposal for quantum key distribution and Mayers and Yao’s idea for “device-independent cryptography”. By then we certainly knew that “spooky action-at-a-distance” did not entail any faster-than-light communication, and indeed was not really “action-at-a-distance” in the first place but merely “correlation-at-a-distance”. What Cleve et al. recognized is that these “spooky correlations-at-a-distance” were sufficiently special so as to not only give numerically different values in “Bell inequalities”, the tool invented by Bell to evidence nonlocality in quantum mechanics, but also have some potentially profound consequences in complexity theory. In particular, examples such as the “Magic Square game” demonstrated that enough correlation could be gained from entanglement so as to defeat basic proof systems whose soundness relied only on the absence of communication between the provers, an assumption that until then had been wrongly equated with the assumption that any computation performed by the provers could be modeled entirely locally. I think that the fallacy of this implicit assumption came as a surprise to complexity theorists, who may still not have entirely internalized it. Yet the perfect quantum strategy for the Magic Square game provides a very concrete “counter-example” to the soundness of the “clause-vs-variable” game for 3SAT. Indeed this game, a reformulation by Aravind and Cleve-Mermin of a Bell Inequality discovered by Mermin and Peres in 1990, can be easily re-framed as a 3SAT system of equations that is <em>not</em> satisfiable and yet is such that the associated two-player clause-vs-variable game has a <em>perfect</em> quantum strategy. It is this observation, made in the paper by Cleve et al., that gave the first strong hint that the use of entanglement in interactive proof systems could make many classical results in the area go awry.</p>
<p>By importing the study of non-locality into complexity theory Cleve et al. immediately brought it into the realm of asymptotic analysis. Complexity theorists don’t study fixed objects, they study families of objects that tend to have a uniform underlying structure and whose interesting properties manifest themselves “in the limit”. As a result of this new perspective focus shifted from the study of single games or correlations to infinite families thereof. Some of the early successes of this translation include the “unbounded violations” that arose from translating asymptotic separations in communication complexity to the language of Bell inequalities and correlations (e.g. this <a href="https://arxiv.org/abs/1012.5043">paper</a>). These early successes attracted the attention of some physicists working in foundations as well as some mathematical physicists, leading to a productive exploration that combined tools from quantum information, functional analysis and complexity theory.</p>
<p>The initial observations made by Cleve et al. had pointed to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> as a possibly interesting complexity class to study. Rather amazingly, nothing was known about it! They had shown that under strong restrictions on the verifier’s predicate (it should be an XOR of two answer bits), a collapse took place: by the work of Hastad, XOR-MIP equals NEXP, but <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BXOR-MIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{XOR-MIP}^\star}" class="latex" title="{\text{XOR-MIP}^\star}" /> is included in EXP. This seemed very fortuitous (the inclusion is proved via a connection with semidefinite programming that seems tied to the structure of XOR-MIP protocols): could entanglement induce a collapse of the entire, unrestricted class? We thought (at this point mostly Julia thought, because I had no clue) that this ought not to be the case, and so we set ourselves to show that the equality <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star=\text{NEXP}}" class="latex" title="{\text{MIP}^\star=\text{NEXP}}" />, that would directly parallel Babai et al.’s characterization MIP=NEXP, holds. We tried to show this by introducing techniques to “immunize” games against entanglement: modify an interactive proof system so that its structure makes it “resistant” to the kind of “nonlocal powers” that can be used to defeat the clause-vs-variable game (witness the Magic Square). This was partially successful, and led to one of the papers I am most proud of — I am proud of it because I think it introduced elementary techniques (such as the use of the Cauchy-Schwarz inequality — inside joke — more seriously, basic things such as “prover-switching”, “commutation tests”, etc.) that are now routine manipulations in the area. The paper was a hard sell! It’s good to remember the first rejections we received. They were not unjustified: the main point of criticism was that we were only able to establish a hardness result for exponentially small completeness-soundness gap. A result for such a small gap in the classical setting follows directly from a very elementary analysis based on the Cook-Levin theorem. So then why did we have to write so many pages (and so many applications of Cauchy-Schwarz!) to arrive at basically the same result (with a <img src="https://s0.wp.com/latex.php?latex=%7B%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{^\star}" class="latex" title="{^\star}" />)?</p>
<p>Eventually we got lucky and the paper was accepted to a conference. But the real problem, of establishing any non-trivial lower bound on the class <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> with constant (or, in the absence of any parallel repetition theorem, inverse-polynomial) completeness-soundness gap, remained. By that time I had transitioned from a Masters student in France to a graduate student in Berkeley, and the problem (pre-)occupied me during some of the most difficult years of my Ph.D. I fully remember spending my first year entirely thinking about this (oh and sure, that systems class I had to pass to satisfy the Berkeley requirements), and then my second year — yet, getting nowhere. (I checked the arXiv to make sure I’m not making this up: two full years, no posts.) I am forever grateful to my fellow student Anindya De for having taken me out of the cycle of torture by knocking on my door with one of the most interesting questions I have studied, that led me into quantum cryptography and quickly resulted in an enjoyable <a href="https://arxiv.org/abs/0911.4680">paper</a>. It was good to feel productive again! (Though the paper had fun reactions as well: after putting it on the arXiv we quickly heard from experts in the area that we had solved an irrelevant problem, and that we better learn about information theory — which we did, eventually leading to another <a href="https://arxiv.org/abs/0912.5514">paper</a>, etc.) The project had distracted me and I set interactive proofs aside; clearly, I was stuck.</p>
<p>About a year later I visited IQC in Waterloo. I don’t remember in what context the visit took place. What I do remember is a meeting in the office of Tsuyoshi Ito, at the time a postdoctoral scholar at IQC. Tsuyoshi asked me to explain our result with Julia. He then asked a very pointed question: the bedrock for the classical analysis of interactive proof systems is the “linearity test” of Blum-Luby-Rubinfeld (BLR). Is there any sense in which we could devise a quantum version of that test?</p>
<p>What a question! This was great. At first it seemed fruitless: in what sense could one argue that quantum provers apply a “linear function”? Sure, quantum mechanics is linear, but that is besides the point. The linearity is a property of the prover’s answers as a function of their question. So what to make of the quantum state, the inherent randomness, etc.?</p>
<p>It took us a few months to figure it out. Once we got there however, the answer was relatively simple — the prover should be making a question-independent measurement that returns a linear function that it applies to its question in order to obtain the answer returned to the verifier — and it opened the path to our subsequent <a href="https://arxiv.org/abs/1207.0550">paper</a> showing that the inclusion of NEXP in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> indeed holds. Tsuyoshi’s question about linearity testing had allowed us to make the connection with PCP techniques; from there to MIP=NEXP there was only one step to make, which is to analyze multi-linearity testing. That step was suggested by my Ph.D. advisor, Umesh Vazirani, who was well aware of the many pathways towards the classical PCP theorem, since the theorem had been obtained in great part by his former student Sanjeev Arora. It took a lot of technical work, yet conceptually a single question from my co-author had sufficed to take me out of a 3-year slumber.</p>
<p>This was in 2012, and I thought we were done. For some reason the converse inclusion, of <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> in NEXP, seemed to resist our efforts, but surely it couldn’t resist much longer. Navascues et al. had introduced a hierarchy of semidefinite programs that seemed to give the right answer (technically they could only show convergence to a relaxation, the commuting value, but that seemed like a technicality; in particular, the values coincide when restricted to finite-dimensional strategies, which is all we computer scientists cared about). There were no convergence bounds on the hierarchy, yet at the same time commutative SDP hierarchies were being used to obtain very strong results in combinatorial optimization, and it seemed like it would only be a matter of time before someone came up with an analysis of the quantum case. (I had been trying to solve a related “dimension reduction problem” with Oded Regev for years, and we were making no progress; yet it seemed <em>someone</em> ought to!)</p>
<p>In Spring 2014 during an open questions session at a <a href="https://simons.berkeley.edu/workshops/qhc2014-1">workshop</a> at the Simons Institute in Berkeley Dorit Aharonov suggested that I ask the question of the possible inclusion of QMA-EXP, the exponential-sized-proofs analogue of QMA, in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />. A stronger result than the inclusion of NEXP (under assumptions), wouldn’t it be a more natural “fully quantum” analogue of MIP=NEXP? Dorit’s suggestion was motivated by research on the “quantum PCP theorem”, that aims to establish similar hardness results in the realm of the local Hamiltonian problem; see e.g. <a href="https://mycqstate.wordpress.com/2014/10/31/quantum-pcp-conjectures/">this post</a> for the connection. I had no idea how to approach the question — I also didn’t really believe the answer could be positive — but what can you do, if Dorit asks you something… So I reluctantly went to the board and asked the question. Joe Fitzsimons was in the audience, and he immediately picked it up! Joe had the fantastic ideas of using quantum error-correction, or more specifically secret-sharing, to distribute a quantum proof among the provers. His enthusiasm overcame my skepticism, and we eventually <a href="https://arxiv.org/abs/1409.0260">showed</a> the desired inclusion. Maybe <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> <em>was</em> bigger than <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BNEXP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{NEXP}}" class="latex" title="{\text{NEXP}}" /> after all.</p>
<p>Our result, however, had a similar deficiency as the one with Julia, in that the completeness-soundness gap was exponentially small. Obtaining a result with a constant gap took 3 years of couple more years of work and the fantastic energy and insights of a Ph.D. student at MIT, Anand Natarajan. Anand is the first person I know of to have had the courage to dive in to the most technical aspects of the analysis of the aforementioned results, while also bringing in the insights of a “true quantum information theorist” that were supported by Anand’s background in Physics and upbringing in the group of Aram Harrow at MIT. (In contrast I think of myself more as a “raw” mathematician; I don’t really understand quantum states other than as psd matrices…not that I understand math either of course; I suppose I’m some kind of a half-baked mish-mash.) Anand had many ideas but one of the most beautiful ones led to what he poetically called the “Pauli braiding test”, a “truly quantum” analogue of the BLR linearity test that amounts to doing <em>two</em> linearity tests in conjugate bases and piecing the results together into a robust test for <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />-qubit entanglement (I wrote about our work on this <a href="https://mycqstate.wordpress.com/2017/06/28/pauli-braiding/">here</a>).</p>
<p>At approximately the same time Zhengfeng Ji had another wonderful idea, that was in some sense orthogonal to our work. (My interpretation of) Zhengfeng’s idea is that one can see an interactive proof system as a computation (verifier-prover-verifier) and use Kitaev’s circuit-to-Hamiltonian construction to transform the entire computation into a “quantum CSP” (in the same sense that the local Hamiltonian problem is a quantum analogue of classical constraint satisfaction problems (CSP)) that could then itself be verified by a quantum multi-prover interactive proof system…with exponential gains in efficiency! Zhengfeng’s result implied an exponential improvement in complexity compared to the result by Julia and myself, showing inclusion of NEEXP, instead of NEXP, in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />. However, Zhengfeng’s technique suffered from the same exponentially small completeness-soundness gap as we had, so that the best lower bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> per se remained NEXP.</p>
<p>Both works led to follow-ups. With Natarajan we promoted the Pauli braiding test into a “<a href="https://arxiv.org/abs/1801.03821">quantum low-degree test</a>” that allowed us to show the inclusion of QMA-EXP into <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />, with constant gap, thereby finally answering the question posed by Aharonov 4 years after it was asked. (I should also say that by then all results on <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> started relying on a sequence of parallel repetition results shown by Bavarian, Yuen, and others; I am skipping this part.) In parallel, with Ji, Fitzsimons, and Yuen we showed that Ji’s compression technique could be “iterated” an arbitrary number of times. In fact, by going back to “first principles” and representing verifiers uniformly as Turing machines we realized that the compression technique could be used iteratively to (up to small caveats) give a new proof of the fact (first <a href="https://arxiv.org/abs/1703.08618">shown</a> by Slofstra using an embedding theorem for finitely presented group) that the zero-gap version of <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> contains the halting problem. In particular, the entangled value is uncomputable! This was not the first time that uncomputability crops in to a natural problem in quantum computing (e.g. the <a href="https://arxiv.org/abs/1502.04573">spectral gap paper</a>), yet it still surprises when it shows up. Uncomputable! How can anything be uncomputable!</p>
<p>As we were wrapping up our paper Henry Yuen realized that our “iterated compression of interactive proof systems” was likely optimal, in the following sense. Even a mild improvement of the technique, in the form of a slower closing of the completeness-soundness gap through compression, would yield a much stronger result: undecidability of the constant-gap class <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />. It was already known by work of Navascues et al., Fritz, and others, that such a result would have, if not surprising, certainly consequences that seemed like they would be taking us out of our depth. In particular, undecidability of any language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> would imply a negative resolution to a series of equivalent conjectures in functional analysis, from Tsirelson’s problem to Connes’ Embedding Conjecture through Kirchberg’s QWEP conjecture. While we liked our result, I don’t think that we believed it could resolve any conjecture(s) in functional analysis.</p>
<p>So we moved on. At least I moved on, I did some cryptography for a change. But Anand Natarajan and his co-author John Wright did not stop there. They had the last major insight in this story, which underlies their recent STOC best paper described in the previous <a href="https://mycqstate.wordpress.com/2019/04/14/randomness-and-interaction-entanglement-ups-the-game/">post</a>. Briefly, they were able to combine the two lines of work, by Natarajan &amp; myself on low-degree testing and by Ji et al. on compression, to obtain a compression that is specially tailored to the existing <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> protocol for NEXP and compresses that protocol without reducing its completeness-soundness gap. This then let them show Ji’s result that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" /> contains NEEXP, but this time with constant gap! The result received well-deserved attention. In particular, it is the first in this line of works to not suffer from any caveats (such as a closing gap, or randomized reductions, or some kind of “unfair” tweak on the model that one could attribute the gain in power to), and it implies an unconditional separation between MIP and <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star}" class="latex" title="{\text{MIP}^\star}" />.</p>
<p>As they were putting the last touches on their result, suddenly something happened, which is that a path towards a much bigger result opened up. What Natarajan &amp; Wright had achieved is a one-step gapless compression. In our iterated compression paper we had observed that iterated gapless compression would lead to <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar%3D%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star=\text{RE}}" class="latex" title="{\text{MIP}^\star=\text{RE}}" />, implying negative answers to the aforementioned conjectures. So then?</p>
<p>I suppose it took some more work, but in some way all the ideas had been laid out in the previous 15 years of work in the complexity of quantum interactive proof systems; we just had to put it together. And so a decade after the characterization <a href="https://arxiv.org/abs/0907.4737">QIP = PSPACE</a> of single-prover quantum interactive proof systems, we have arrived at a characterization of quantum multiprover interactive proof systems, <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctext%7BMIP%7D%5E%5Cstar+%3D+%5Ctext%7BRE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\text{MIP}^\star = \text{RE}}" class="latex" title="{\text{MIP}^\star = \text{RE}}" />. With one author in common between the two papers: congratulations Zhengfeng!</p>
<p>Even though we just posted a paper, in a sense there is much more left to do. I am hopeful that our complexity-theoretic result will attract enough interest from the mathematicians’ community, and especially operator algebraists, for whom CEP is a central problem, that some of them will be willing to devote time to understanding the result. I also recognize that much effort is needed on our own side to make it accessible in the first place! I don’t doubt that eventually complexity theory will not be needed to obtain the purely mathematical consequences; yet I am hopeful that some of the ideas may eventually find their way into the construction of interesting mathematical objects (such as, who knows, a non-hyperlinear group).</p>
<p>That was a good Masters project…thanks Julia!</p></div>







<p class="date">
by Thomas <a href="https://mycqstate.wordpress.com/2020/01/14/a-masters-project/"><span class="datestr">at January 14, 2020 01:32 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-3743356831833676109">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/01/what-would-you-do-if-you-showed-pnp-i.html">What would you do if you showed P=NP? I would reread Factor Man by Matt Ginsberg</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Lance has often said (and also in <a href="https://blog.computationalcomplexity.org/2020/01/silicon-valley-ethics.html">this</a>) that if P=NP that would be great for the world: much more efficient ways to build things, science could be done better, etc, and that is much more important than that modern crypto would no longer work. We now have the technology to do private key really well--- like a thumb drive that has a billion bits for 1-time pads.<br />
<br />
I agree that the world would be better off in some ways, I wonder how much damage would be done in the transition period from public to private key. Would the world recover enough to reap the benefits of P=NP?<br />
<br />
First think of what YOU would do if you showed P=NP (and lets assume your algorithm is either reasonable or could be made reasonable with some time and effort).<br />
<br />
The novel <i>Factor Man  </i>is about what someone who has solved P=NP does. I won't tell you how it goes, but they deal with the issue intelligently. So if I solved P=NP then I would first re-read it, and think through if I would do that, or modify what is done, or what.  Its a good start.<br />
<br />
I reviewed the book in SIGACT News or you can read my review <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/factorman.pdf">here</a><br />
<br />
On a slightly diff note, here is the latest argument I've heard for why P=NP:<br />
<br />
Planar 2-coloring is in P<br />
<br />
Planar 4-coloring is in P<br />
<br />
So<br />
<br />
Planar 3-coloring should be in P.<br />
<br />
This was said by a very good math/cs ugrad at UMCP. I do not know if he was kidding.<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/01/what-would-you-do-if-you-showed-pnp-i.html"><span class="datestr">at January 14, 2020 01:28 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2020/01/14/socal-theory-day-2020/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2020/01/14/socal-theory-day-2020/">SoCal Theory Day 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
January 20, 2020 UC Riverside https://www.cs.ucr.edu/~silas/ An all day event to celebrate the TCS research community in Southern California</div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2020/01/14/socal-theory-day-2020/"><span class="datestr">at January 14, 2020 12:51 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://bit-player.org/?p=2222">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/hayes.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://bit-player.org/2020/the-teetering-towers-of-abstraction">The Teetering Towers of Abstraction</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://bit-player.org" title="bit-player">bit-player</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Abstraction is an abstraction. You can’t touch it or taste it or photograph it. You can barely talk about it without resorting to metaphors and analogies. Yet this ghostly concept is an essential tool in both mathematics and computer science. Oddly, it seems to inspire quite different feelings and responses in those two fields. I’ve been wondering why.</p>
<p>In mathematics abstraction serves as a kind of stairway to heaven—as well as a test of stamina for those who want to get there. <img src="http://bit-player.org/wp-content/uploads/2019/11/west-stairs-to-Grandview-Park-2017-10-28.jpg" height="" width="340" alt="West stairs to Grandview Park 2017-10-28" border="0" class="alignright" />West stairs to Grand View Park, San Francisco, October 2017. You begin the climb at an early age, at ground level, with things that are not at all abstract. Jelly beans, for example.  You learn the important life lesson that if you have <img width="39" alt="five jelly beans" src="http://bit-player.org/wp-content/uploads/2019/11/five-jelly-beans-32-by-89.png" border="0" height="14" /> and you eat <img width="23" alt="three jelly beans" src="http://bit-player.org/wp-content/uploads/2019/11/three-jelly-beans-32-by-53.png" border="0" height="14" />, you will have only <img width="16" alt="two jelly beans" src="http://bit-player.org/wp-content/uploads/2019/11/two-jelly-beans-32-by-36.png" border="0" height="14" /> left. After absorbing this bitter truth, you are invited to climb the stairs of ab­straction as far as the first landing, where you replace the tasty tangible jelly beans with sugar-free symbols: \(5 - 3 = 2\).</p>
<p>Some years later you reach higher ground. The sym­bols represent­ing par­tic­ular numbers give way to the \(x\)s and \(y\)s that stand for quantities yet to be determined. They are symbols for sym­bols. Later still you come to realize that this algebra business is not just about “solving for \(x\),” for finding a specific number that corresponds to a specific letter. It’s a magical device that allows you to make blanket statements encompassing <em>all</em> numbers: \(x^2 - 1 = (x + 1)(x - 1)\) is true for any value of \(x\).</p>
<p>Continuing onward and upward, you learn to manipulate symbolic expressions in various other ways, such as differentiating and integrating them, or constructing functions of functions of functions. Keep climbing the stairs and eventually you’ll be introduced to areas of mathematics that openly boast of their abstractness. There’s <em>abstract algebra</em>, where you build your own collections of numberlike things: groups, fields, rings, vector spaces. <img src="http://bit-player.org/wp-content/uploads/2019/11/Orlin-abstractions-of-abstractions.jpg" height="301" width="400" alt="Ben Orlin cartoon: 'Sorry, I only do abstractions, not numbers.' 'But numbers are abstractions.' 'Let me clarify: I only do abstractions of abstractions of abstractions'.jpg" border="0" class="alignleft" />Cartoon by Ben Orlin, <a href="https://mathwithbaddrawings.com/2017/01/11/why-are-mathematicians-so-bad-at-arithmetic/">mathwithbaddrawings.com</a>, reprinted under <a href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons license.</a>Another route up the stairway takes you to <em>category theory</em>, where you’ll find a collection of ideas with the disarming label <em>ab­stract nonsense</em>.</p>
<p>Not everyone is filled with admiration for this Jenga tower of abstrac­tions teetering atop more abstrac­tions. Con­sider Andrew Wiles’s proof of Fermat’s last theorem, and its reception by the public. The theorem, first stated by Pierre de Fermat in the 1630s, makes a simple claim about powers of integers: If \(x, y, z, n\) are all integers greater than \(0\), then \(x^n + y^n = z^n\) has solutions only if \(n \le 2\). The proof of this claim, published in the 1990s, is not nearly so simple. Wiles (with contributions from Richard Taylor) went on a scavenger hunt through much of modern mathematics, collecting a truckload of tools and spare parts needed to make the proof work: elliptic curves, modular forms, Galois groups, functions on the complex plane, <em>L</em>-series. It is truly a <em>tour de force</em>.</p>
<p>Diagram (borrowed from Kenneth A. Ribet and Brian Hayes, “<a href="http://bit-player.org/wp-content/extras/bph-publications/AmSci-1994-03-Ribet-Hayes-Fermats-Last-Theorem.pdf">Fermat’s Last Theorem and Modern Arithmetic</a>“) outlines the overall strategy of the Wiles proof. If you had a counterexample to FLT, you could construct an elliptic curve <em>E</em> with certain properties. But the properties deduced on the left and right branches of the diagram turn out to be inconsistent, implying that <em>E</em> does not exist, nor does the counter­example that gave rise to it.<img src="http://bit-player.org/wp-content/uploads/2019/11/1994-03-Fermat-F11-L-series-updated-2019.svg" height="" width="550" alt="Outline of the Wiles-Taylor proof of Fermat's last theorem" border="0" class="centered" /></p>
<p class="indent">Is all that heavy machinery really needed to prove such an innocent-looking state­ment? Many people yearn for a simpler and more direct proof, ideally based on methods that would have been available to Fermat himself. Ken Ribet will be presenting “A 2020 View of Fermat’s Last Theorem” at the Joint Mathematics Meetings later this week. In a <a href="https://www.ams.org/journals/notices/202001/rnoti-p82.pdf">preview</a> of the talk, he notes that advances made since 1994 allow a more succinct statement of the proof. But those recent advances are no easier to understand than the original proof.At least nine attempts to construct an elementary proof have been posted on the arXiv in the past 20 years, and there are lots more elsewhere. I think the sentiment motivating much of this work is, “You shouldn’t be allowed to prove a theorem I care about with methods I don’t understand.” Marilyn vos Savant, the <em>Parade</em> columnist, takes an even more <a href="https://us.macmillan.com/books/9780312106577">extreme position</a>, arguing that Wiles strayed so far from the subject matter of the theorem as to make his proof invalid. (For a critique of her critique, see <a href="https://www.jstor.org/stable/2975048?seq=1">Boston and Granville</a>.)</p>
<p>Almost all of this grumbling about illegimate methods and excess complexity comes from outside the  community of research mathematicians. Insiders see the Wiles proof differently. For them, the wide-ranging nature of the proof is actually what’s most important. The main accomp­lishment, in this view, was cementing a connection between those far-flung areas of mathematics; resolving FLT was just a bonus.</p>
<p>Yet even mathematicians can have misgivings about the intricacy of math­ematical arguments and the ever-taller skyscrapers of abstraction. <a href="http://oro.open.ac.uk/2818/">Jeremy Gray</a>, a historian of mathematics, believes anxiety over abstraction was already rising in the 19th century, when mathematics seemed to be “moving away from reality, into worlds of arbitrary dimension, for example, and into the habit of supplanting intuitive concepts (curves that touch, neighboring points, velocity) with an opaque language of mathematical analysis that bought rigor at a high cost in intelligibility.”</p>
<p>Quite apart from these comments on abstraction, the thesis is well worth reading. It offers alternating sections of “mathsplaining” and “laysplaining.” See also a <a href="http://digitaleditions.walsworthprintgroup.com/publication/?m=7656&amp;l=1#{%22issue_id%22:%22566588%22,%22page%22:%2250%22}">review in <em>MAA Focus</em></a> by Adriana Salerno. The thesis was to be published in book form last fall by Birkhäuser, but the book doesn’t seem to be available yet.For a view of abstraction in contemporary mathematics, we have a vivid image from Piper Harron, a young mathematician who wrote an <a href="http://www.theliberatedmathematician.com/math/">extraordinarily candid PhD thesis in 2016</a>. The introductory chapter begins, “The hardest part about math is the level of abstraction required.” She goes on to explain:</p>
<blockquote class="undent"><p>I like to imagine abstraction (abstractly ha ha ha) as pulling the strings on a marionette. The marionette, being “real life,” is easily accessible. Everyone understands the marionette whether it’s walking or dancing or fighting. We can see it and it makes sense. But watch instead the hands of the puppeteers. Can you look at the hand movements of the puppeteers and know what the marionette is doing?… Imagine it gets worse. Much, much worse. Imagine that the marionettes we see are controlled by marionettoids we don’t see which are in turn controlled by pre-puppeteers which are finally controlled by actual puppeteers.</p></blockquote>
<p>Keep all those puppetoids in mind. I’ll be coming back to them, but first I want to shift my attention to computer science, where the towers of abstraction are just as tall and teetery, but somehow less scary.</p>
<hr />
<p>Suppose your computer is about to add two numbers…. No, wait, there’s no need to suppose or imagine. In the orange panel below, type some numbers into the \(a\) and \(b\) boxes, then press the “+” button to get the sum in box \(c\). Now, please describe what’s happening inside the machine as that computation is performed.</p>
<div style="width: 230px; height: 97px; border: 1px solid black; margin: 10px auto; background-color: coral;" id="adder-box">
	<input style="width: 150px; height: 18px; text-align: right; font-family: monospace; font-size: 12pt;" type="text" id="aInput" /><p></p>
<div style="font-size: 14pt;">a</div>
<p>	<button id="plus-button">+</button><br />
	<input style="width: 150px; height: 18px; text-align: right; font-family: monospace; font-size: 12pt;" type="text" id="bInput" /></p>
<div style="font-size: 14pt;">b</div>
<div style="width: 185px; height: 0px; border: 0.5px solid black;" id="rule"></div>
<div style="width: 163px; height: 22px; border: 1px solid #0000002e; text-align: right; background-color: white; font-size: 12pt; font-family: monospace; line-height: 18pt; padding-right: 1px;" id="output"></div>
<div style="font-size: 14pt;">c</div>
</div>
<p class="indent">You can probably guess that somewhere behind the curtains there’s a fragment of code that looks like <code>c = a + b</code>. And, indeed, that statement appears verbatim in the JavaScript program that’s triggered when you click on the plus button. But if you were to go poking around among the circuit boards under the keyboard of your laptop, you wouldn’t find anything resembling that sequence of symbols. The program statement is a high-level abstraction. If you really want to know what’s going on inside the computing engine, you need to dig deeper—down to something as tangible as a jelly bean.</p>
<p>How about an electron? In truth, electrons are not so tangible. The proper mental image is not a hard sphere like a BB but a diffuse probability distribution. In other words, the electron itself is an abstraction.During the computation, clouds of electrons drift through the machine’s circuitry, like swarms of migrating butterflies. Their movements are regulated by the switching action of transistors, and the transistors in turn are controlled by the moving electrons. It is this dance of the electrons that does the arithmetic and produces an answer. Yet it would be madness to describe the evaluation of <code>c = a + b</code> by tracing the motions of all the electrons (perhaps \(10^{23}\) of them) through all the transistors (perhaps \(10^{11}\)).</p>
<p>To understand how electrons are persuaded to do arithmetic for us, we need to introduce a whole sequence of abstractions.</p>
<ul>
<li>First, step back from the focus on individual electrons, and reformulate the problem in terms of continuous quantities: voltage, current, capacitance, inductance.</li>
<li>Replace the physical transistors, in which voltages and currents change smoothly, with idealized devices that instantly switch from totally off to fully on.</li>
<li>Interpret the two states of a transistor as logical values (<em>true</em> and <em>false</em>) or as numerical values (\(1\) and \(0\)).</li>
<li>Organize groups of transistors into “gates” that carry out basic functions of Boolean logic, such as <span style="font-variant: small-caps;">and</span>, <span style="font-variant: small-caps;">or</span>, and <span style="font-variant: small-caps;">not</span>.</li>
<li>Assemble the gates into larger functional units, including adders, multipliers, comparators, and other components for doing base-\(2\) arithmetic.</li>
<li>Build higher-level modules that allow the adders and such to be operated under the control of a program. This is the conceptual level of the instruction-set architecture, defining the basic operation codes (<em>add, shift, jump</em>, etc.) recognized by the computer hardware.</li>
<li>Graduating from hardware to software, design an operating system, a collection of services and interfaces for abstract objects such as files, input and output channels, and concurrent processes.</li>
<li>Create a compiler or interpreter that knows how to translate programming language statements such as <code>c = a + b</code> into sequences of machine instructions and operating-system requests.</li>
</ul>
<p class="indent">From the point of view of most programmers, the abstractions listed above represent computational <em>infrastructure</em>: They lie beneath the level where you do most of your thinking—the level where you describe the algorithms and data structures that solve your problem. But computational abstractions are also a tool for building <em>superstructure</em>, for creating new functions beyond what the operating system and the programming language provide. For example, if your programming language handles only numbers drawn from the real number line, you can write procedures for doing arithmetic with complex numbers, such as \(3 + 5i\). (Go ahead, try it in the orange box above.) And, in analogy with the mathematical practice of defining functions of functions, we can build compiler compilers and schemes for metaprogramming—programs that act on other programs.</p>
<p>In both mathematics and computation, rising through the various levels of abstraction gives you a more elevated view of the landscape, with wider scope but less detail. Even if the process is essentially the same in the two fields, however, it doesn’t feel that way, at least to me. In mathematics, abstraction can be a source of anxiety; in computing, it is nothing to be afraid of. In math, you must take care not to tangle the puppet strings; in computing, abstractions are a defense against such confusion. For the mathematician, abstraction is an intellectual challenge; for the programmer, it is an aid to clear thinking.</p>
<p>Why the difference? How can abstraction have such a friendly face in computation and such a stern mien in math? One possible answer is that computation is just plain easier than mathematics. In speaking of “computation,” what I have in mind is the design of algorithms and data structures suitable for a machine we can build out of material components. If you are playing with Turing machines and other toys of theoretical computer science, the game is altogether different. But in my view theoretical computer science is just a funny-looking branch of mathematics. (With apologies to those of my friends who grimace to hear me say it.) Anything that fits into the computer is necessarily discrete and finite. In principle, any computer program could be reduced to a big table mapping all possible inputs to the corresponding outputs. Mathematics is invulnerable to this kind of trivialization by brute force. It has infinities hiding under the bed and lurking behind the closet door, and that’s what makes it both fun and frightening.</p>
<p>Another possible explanation is that computer systems are engineered artifacts; we can build them to our own specifications. If a concept is just too hairy for the human mind to master, we can break it down into simpler pieces. Math is not so complaisant—not even for those who hold that mathematical objects are invented rather than discovered. We can’t just design number theory so that the Riemann hypothesis will be true.</p>
<p>But I think the crucial distinction between math abstractions and computer abstractions lies elsewhere. It’s not in the abstractions themselves but in the boundaries between them.</p>
<hr />
<p>Warning from the abstraction police on the office door of Radhika Nagpal, Harvard University. (Photographed November 2013.)<img src="http://bit-player.org/wp-content/uploads/2019/12/abstraction-barrier-doorway-3402.jpg" height="472" width="640" alt="Abstraction barrier doorway 3402" border="0" class="centered" /></p>
<p>I believe I first encountered the term <em>abstraction barrier</em> in Abelson and Sussman’s <a href="https://web.mit.edu/alexmv/6.037/sicp.pdf">Structure and Inter­pretation of Computer Programs</a>, circa 1986. The underlying idea is surely older; it’s implicit in the “structured programming” literature of the 1960s and 70s. But <em>SICP</em> still offers the clearest and most compelling introduction.In building computer systems, we are urged to compartmentalize, to create self-contained and sealed-off modules—black boxes whose inner workings are concealed from outside observers. In this world, <em>information hiding</em> is considered a virtue, not an impeachable offense. If a design has a layered structure, with abstractions piled one atop the other, the layers are separated by  <em>abstraction barriers</em>. A high-level module can reach across the barrier to make use of procedures from lower levels, but it won’t know anything about the implementation of those procedures. When you are writing programs in Lisp or Python, you shouldn’t need to think about how the  operating system carries out its chores; and when you’re writing routines for the operating system, you needn’t think about the physics of electrons meandering through the crystal lattice of a semiconductor. Each level of the hierarchy can be treated (almost) independently.</p>
<p>Mathematics also has its abstraction barriers, although I’ve never actually heard the term used by mathematicians. A notable example comes from Giuseppe Peano’s formulation of the foundations of arithmetic, circa 1900. Peano posits the existence of a number \(0\), and a function called <em>successor</em>, \(S(n)\), which takes a number \(n\) and returns the next number in the counting sequence. Thus the natural numbers begin \(0, S(0), S(S(0)), S(S(S(0)))\), and so on. Peano deliberately refrains from saying anything more about what these numbers look like or how they work. They might be implemented as sets, with \(0\) being the empty set and successor the operation of adjoining an element to a set. Or they could be unary lists: (), (|), (||), (|||), . . . The most direct approach is to use <a href="https://en.wikipedia.org/wiki/Church_encoding">Church numerals</a>, in which the successor function itself serves as a counting token, and the number \(n\) is represented by \(n\) nested applications of \(S\).</p>
<p>From these minimalist axioms we can define the rest of arithmetic, starting with addition. In calculating \(a + b\), if \(b\) happens to be \(0\), the problem is solved: \(a + 0 = a\). If \(b\) is <em>not</em> \(0\), then it must be the successor of some number, which we can call \(c\). Then \(a + S(c) = S(a + c)\). Notice that this definition doesn’t depend in any way on how the number \(0\) and the successor function are represented or implemented. Under the hood, we might be working with sets or lists or abacus beads; it makes no difference. An abstraction barrier separates the levels. From addition you can go on to define multiplication, and then exponentiation, and again abstraction barriers protect you from the lower-level details. There’s never any need to think about how the successor function works, just as the computer programmer doesn’t think about the flow of electrons.</p>
<p>The importance of not thinking was stated eloquently by Alfred North Whitehead, more than a century ago:</p>
<blockquote><p>Alfred North Whitehead, <em><a href="http://www.gutenberg.org/ebooks/41568">An Introduction of Mathematics</a></em>, 1911, pp. 45–46.It is a profoundly erroneous truism, repeated by all copybooks and by eminent people when they are making speeches, that we should cultivate the habit of thinking of what we are doing. The precise opposite is the case. Civilisation advances by extending the number of important operations which we can perform without thinking about them. Operations of thought are like cavalry charges in a battle—they are strictly limited in number, they require fresh horses, and must only be made at decisive moments.</p></blockquote>
<hr />
<p>If all of mathematics were like the Peano axioms, we would have a watertight structure, compartmentalized by lots of leakproof abstraction barriers. And abstraction would probably not be considered “the hardest part about math.” But, of course, Peano described only the tiniest corner of mathematics. We also have the puppet strings.</p>
<p>In Piper Harron’s unsettling vision, the puppeteers high above the stage pull strings that control the pre-puppeteers, who in turn operate the marionettoids, who animate the marionettes. Each of these agents can be taken as representing a level of abstraction. The problem is, we want to follow the action at both the top and the bottom of the hierarchy, and possibly at the middle levels as well. The commands coming down from the puppeteers on high embody the abstract ideas that are needed to build theorems and proofs, but the propositions to be proved lie at the level of the marionettes. There’s no separating these levels; the puppet strings tie them together.</p>
<p>In the case of Fermat’s Last Theorem, you might choose to view the Wiles proof as nothing more than an elevated statement about elliptic curves and modular forms, but the proof is famous for something else—for what it tells us about the elementary equation \(x^n + y^n = z^n\). Thus the master puppeteers work at the level of algebraic geometry, but our eyes are on the dancing marionettes of simple number theory. What I’m suggesting, in other words, is that abstraction barriers in mathematics sometimes fail because events on both sides of the barrier make simultaneous claims on our interest. </p>
<p>In computer science, the programmer can ignore the trajectories of the electrons because those details really are of no consequence. Indeed, the electronic guts of the computing machinery could be ripped out and replaced by fluidic devices or fiber optics or hamsters in exercise wheels, and that brain transplant would have no effect on the outcome of the computation. Few areas of mathematics can be so cleanly floated away and rebuilt on a new foundation.</p>
<p>Can this notion of leaky abstraction barriers actually explain why higher mathematics looks so intimidating to most of the human population? It’s surely not the whole story, but maybe it has a role.</p>
<p>In closing I would like to point out an analogy with a few other areas of science, where problems that cross abstraction barriers seem to be particularly difficult. Physics, for example, deals with a vast range of spatial scales. At one end of the spectrum are the quarks and leptons, which rattle around comfortably inside a particle with a radius of \(10^{-15}\) meter; at the other end are galaxy clusters spanning \(10^{24}\) meters. In most cases, effective abstraction barriers separate these levels. When you’re studying celestial mechanics, you don’t have to think about the atomic composition of the planets. Conversely, if you are looking at the interactions of elementary particles, you are allowed to assume they will behave the same way anywhere in the universe. But there are a few areas where the barriers break down. For example, near a critical point where liquid and gas phases merge into an undifferentiated fluid, forces at all scales from molecular to macroscopic become equally important. Turbulent flow is similar, with whirls upon whirls upon whirls. It’s not a coincidence that critical phenomena and turbulence are notoriously difficult to describe.</p>
<p>Biology also covers a wide swath of territory, from molecules and single cells to whole organisms and ecosystems on a planetary scale. Again, abstraction barriers usually allow the biologist to focus on one realm at a time. To understand a predator-prey system you don’t need to know about the structure of cytochrome <em>c</em>. But the barriers don’t always hold. Evolution spans all these levels. It depends on molecular events (mutations in DNA), and determines the shape and fate of the entire tree of life. We can’t fully grasp what’s going on in the biosphere without keeping all these levels in mind at once.</p>

<p></p></div>







<p class="date">
by Brian Hayes <a href="http://bit-player.org/2020/the-teetering-towers-of-abstraction"><span class="datestr">at January 13, 2020 11:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/01/13/postdoctoral-fellow-at-university-of-texas-at-austin-apply-by-june-1-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/01/13/postdoctoral-fellow-at-university-of-texas-at-austin-apply-by-june-1-2020/">Postdoctoral Fellow at University of Texas at Austin (apply by June 1, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Computer Science Department at UT Austin invites applications for a Postdoctoral Fellow in theoretical computer science for the 2020-21 academic year. The Fellow will work with Dana Moshkovitz and David Zuckerman on pseudorandomness and computational complexity. Review of applicants will begin on January 15, but applications will be accepted until the position is filled.</p>
<p>Website: <a href="https://utaustin.wd1.myworkdayjobs.com/UTstaff/job/UT-MAIN-CAMPUS/Postdoctoral-Fellow_R_00006957">https://utaustin.wd1.myworkdayjobs.com/UTstaff/job/UT-MAIN-CAMPUS/Postdoctoral-Fellow_R_00006957</a><br />
Email: maguilar@cs.utexas.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/01/13/postdoctoral-fellow-at-university-of-texas-at-austin-apply-by-june-1-2020/"><span class="datestr">at January 13, 2020 02:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
