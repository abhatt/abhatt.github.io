<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at December 03, 2020 11:38 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/180">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/180">TR20-180 |  Shrinkage under Random Projections, and Cubic Formula Lower Bounds for $\mathbf{AC}^0$ | 

	Yuval Filmus, 

	Or Meir, 

	Avishay Tal</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Håstad showed that any De Morgan formula (composed of AND, OR and NOT gates) shrinks by a factor of $O(p^{2})$ under a random restriction that leaves each variable alive independently with probability $p$ [SICOMP, 1998]. Using this result, he gave an $\widetilde{\Omega}(n^{3})$ formula size lower bound for the Andreev function, which, up to lower order improvements, remains the state-of-the-art lower bound for any explicit function.

  In this work, we extend the shrinkage result of Håstad to hold under a far wider family of random restrictions and their generalization — random projections. Based on our shrinkage results, we obtain an $\widetilde{\Omega}(n^{3})$ formula size lower bound for an explicit function computed in $\mathbf{AC}^0$. This improves upon the best known formula size lower bounds for $\mathbf{AC}^0$, that were only quadratic prior to our work. In addition, we prove that the KRW conjecture [Karchmer et al., Computational Complexity 5(3/4), 1995] holds for inner functions for which the unweighted quantum adversary bound is tight. In particular, this holds for inner functions with a tight Khrapchenko bound.

  Our random projections are tailor-made to the function's structure so that the function maintains structure even under projection --- using such projections is necessary, as standard random restrictions simplify $\mathbf{AC}^0$ circuits. In contrast, we show that any De Morgan formula shrinks by a quadratic factor under our random projections, allowing us to prove the cubic lower bound.

  Our proof techniques build on the proof of Håstad for the simpler case of balanced formulas. This allows for a significantly simpler proof at the cost of slightly worse parameters. As such, when specialized to the case of $p$-random restrictions, our proof can be used as an exposition of Håstad's result.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/180"><span class="datestr">at December 03, 2020 02:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17821">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/">Too Long, Didn’t Read</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>How to summarize papers</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/all-8/" rel="attachment wp-att-17825"><img width="200" alt="" src="https://rjlipton.files.wordpress.com/2020/12/all.png?w=200&amp;h=134" class="alignright wp-image-17825" height="134" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Top row: Cohan, Weld. Bottom: Cachola, Lo.</font></td>
</tr>
</tbody>
</table>
<p>
Isabel Cachola, Kyle Lo, Arman Cohan, Daniel Weld are the authors of a recent <a href="https://arxiv.org/abs/2004.15011">paper</a> on summarizing papers. They are all connected in various way to the <a href="https://allenai.org/papers">Allen Institute</a> for Artificial Intelligence. </p>
<p>
Today we take a moment to try out the <a href="https://scitldr.apps.allenai.org/">webtool</a> that comes with their paper.  It is noted also in a <a href="https://www.nature.com/articles/d41586-020-03277-2">news item</a> last week in <i>Nature</i>.</p>
<p>
They have created a program that reads a science article and outputs a single sentence that summarizes its content. Their goal is to help researchers search through the huge number of published papers faster than looking at abstracts. The software utilizes neural networks trained on many examples. </p>
<p>
For example: Their own <a href="https://arxiv.org/abs/2004.15011">paper</a> has for its abstract:</p>
<blockquote><p><b> </b> <em> We introduce TLDR generation, a new form of extreme summarization, for scientific papers. TLDR generation involves high source compression and requires expert background knowledge and understanding of complex domain-specific language. To facilitate study on this task, we introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers. SCITLDR contains both author-written and expert-derived TLDRs, where the latter are collected using a novel annotation protocol that produces high-quality summaries while minimizing annotation burden. We propose CATTS, a simple yet effective learning strategy for generating TLDRs that exploits titles as an auxiliary training signal. CATTS improves upon strong baselines under both automated metrics and human evaluations. </em>
</p></blockquote>
<p></p><p>
And this becomes:</p>
<blockquote><p><b> </b> <em> “We introduce SCITLDR, a new multi-target dataset of 5.4K TLDRs over 3.2K papers.” </em>
</p></blockquote>
<p></p><p>
Not so impressive, but more on their program shortly.</p>
<p>
</p><p></p><h2> Another Tryout </h2><p></p>
<p></p><p>
Perhaps the big news this week is an advance on protein folding by Google DeepMind, the same team whose work on <a href="https://rjlipton.wordpress.com/2016/03/11/stonefight-at-the-goke-corral/">AlphaGo</a> and <a href="https://rjlipton.wordpress.com/2017/12/17/truth-from-zero/">AlphaZero</a> we have covered. Sure enough, their new system is called <a href="https://en.wikipedia.org/wiki/AlphaFold">AlphaFold</a>—actually, AlphaFold2. See <a href="https://en.wikipedia.org/wiki/Protein_folding">here</a> for basic information: </p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/fold-2/" rel="attachment wp-att-17826"><img width="500" alt="" src="https://rjlipton.files.wordpress.com/2020/12/fold.png?w=500&amp;h=222" class="aligncenter wp-image-17826" height="222" /></a></p>
<p></p><p><br />
The detailed <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">announcement</a> on the DeepMind <a href="https://deepmind.com/blog">blog</a> says:</p>
<blockquote><p><b> </b> <em> Until we’ve published a paper on this work, please cite: “High Accuracy Protein Structure Prediction Using Deep Learning,” John Jumper [et al.]. In Fourteenth Critical Assessment of Techniques for Protein Structure Prediction (Abstract Book), 30 November – 4 December 2020. Retrieved from <a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a></em>.
</p></blockquote>
<p>The link under “<a href="https://predictioncenter.org/casp14/doc/CASP14_Abstracts.pdf">here</a>” goes to a long book of abstracts. Among them, there is a <a href="https://www.nature.com/articles/s41586-019-1923-7">paper</a> last January in <em>Nature</em> with many of the same authors, though Jumper not as first author. Using its abstract, we got:</p>
<blockquote><p><b> </b> <em> “We train a neural network to make accurate predictions of the distances between pairs of residues, which convey more information about the structure than contact predictions.” </em>
</p></blockquote>
<p></p><p>
The abstracts book has the abstract for the current paper:</p>
<blockquote><p><b> </b> <em> In the CASP14 experiment, we deployed AlphaFold 2. This new system uses a different deep learning method than CASP13 AlphaFold, and it produces much more accurate protein structures and estimates of model accuracy. The training data for the system is publicly available and similar to that used for CASP13 AlphaFold. </em>
</p></blockquote>
<p></p><p>
This is already short, but with SCITLDR it becomes:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a new deep learning system that produces much more accurate protein structures and” </em>
</p></blockquote>
<p></p><p>
The dangling “and” is a little mystifying. SCITLDR has optional fields for <i>Introduction</i> and <i>Conclusions</i>. The entry in the abstracts book has a body titled “Methods,” whose last subsection “T1064” reads like a conclusion, so we added them as such. We cleaned up the paste from PDF to have normal line breaks. After a few seconds, we obtained:</p>
<blockquote><p><b> </b> <em> “In the CASP14 experiment, we deployed AlphaFold 2.0, a novel attention-based deep learning architecture that produces accurate protein structures” </em>
</p></blockquote>
<p></p><p>
The DeepMind announcement poses a further challenge: how to glean an important paper that for now exists only as a blog post. The first paragraph of their <a href="https://deepmind.com/blog/article/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology">post</a> is boldfaced and reads like an abstract:</p>
<blockquote><p><b> </b> <em> Proteins are essential to life, supporting practically all its functions. They are large complex molecules, made up of chains of amino acids, and what a protein does largely depends on its unique 3D structure. Figuring out what shapes proteins fold into is known as the “protein folding problem,” and has stood as a grand challenge in biology for the past 50 years. In a major scientific advance, the latest version of our AI system AlphaFold has been recognised as a solution to this grand challenge by the organisers of the biennial Critical Assessment of protein Structure Prediction (CASP). This breakthrough demonstrates the impact AI can have on scientific discovery and its potential to dramatically accelerate progress in some of the most fundamental fields that explain and shape our world. </em>
</p></blockquote>
<p></p><p>
It becomes: </p>
<blockquote><p><b> </b> <em> “AlphaFold has been recognized as a solution to this grand challenge by the organizers of the Critical Assessment of protein Structure Prediction (CASP)” </em>
</p></blockquote>
<p></p><p>
Pretty good—do you agree?</p>
<p>
</p><p></p><h2> Even Faster </h2><p></p>
<p></p><p>
Both Ken and I are fans of the <a href="https://en.wikipedia.org/wiki/The_Mathematical_Experience">book</a> <em>The Mathematical Experience</em> by Philip Davis and Reuben Hersch. The following passage, from the chapter “The Ideal Mathematician,” describes how one writes a paper, but Ken has always taken it to describe the swiftness needed to read a paper:</p>
<blockquote><p><b> </b> <em> The intended readers (all twelve of them) can decode the formal presentation, detect the new idea hidden in lemma 4, ignore the routine and uninteresting calculations of lemmas 1, 2, 3, 5, 6, 7, and see what the author is doing and why he does it. </em>
</p></blockquote>
<p></p><p>
Nowadays we pore through papers as they appear on arXiv. For most, we just scan the titles. For others, we go to the main page with the abstract. For some, we click on the PDF to read the paper. This may be the greatest exercise in freedom of intellect we have our professional lives, but it is also an exercise in speed. We who do research in time complexity need to minimize our own time. </p>
<p>
</p><p></p><h2> Some CS Examples </h2><p></p>
<p></p><p>
Another way to say this: we all need to read through the literature faster and more precisely. Here are a few examples of their one sentence abstracts for theory papers from the SCITLDR program. Rate them by seeing if you can match the summarizes with the papers.</p>
<p></p><p><br />
Here are the one sentence summaries: </p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <p></p>
</li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <p></p>
</li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <p></p>
</li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <p></p>
</li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <p></p>
</li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <p></p>
</li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .”
</li></ol>
<p></p><p><br />
Match them to the paper titles: </p>
<ol>
<li>
The complexity of theorem-proving procedures <p></p>
</li><li>
Some connections between nonuniform and uniform complexity classes <p></p>
</li><li>
Finite Automata and Their Decision Problem <p></p>
</li><li>
A Machine-Independent theory of the Complexity of Recursive Functions <p></p>
</li><li>
Some connections between nonuniform and uniform complexity classes <p></p>
</li><li>
The Knowledge Complexity Of Interactive Proof Systems <p></p>
</li><li>
The primes contain arbitrarily long arithmetic progressions
</li></ol>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p>The papers:</p>
<ol>
<li>
“Finite automata are considered in this paper as instruments for classifying finite tapes.” <a href="http://www.cse.chalmers.se/~coquand/AUTOMATA/rs.pdf">1</a><p></p>
<p></p></li><li>
“The number of steps required to compute a function depends, in general, on the type of computer that is used, on the choice of computer program” <a href="http://port70.net/~nsz/articles/classic/blum_complexity_1976.pdf">2</a><p></p>
<p></p></li><li>
“In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are” <a href="https://dl.acm.org/doi/10.1145/146585.146609">3</a><p></p>
<p></p></li><li>
“In this paper a computational complexity theory of the “knowledge” contained in a proof is developed.” <a href="http://crypto.cs.mcgill.ca/~crepeau/COMP647/2007/TOPIC02/GMR89.pdf">4</a><p></p>
<p></p></li><li>
“It is shown that any recognition problem solved by a polynomial time-bounded nondeterministic Turing machine can be “reduced” <a href="https://dl.acm.org/doi/10.1145/800157.805047">5</a><p></p>
<p></p></li><li>
“We prove that there are arbitrarily long arithmetic progressions of primes.” <a href="https://arxiv.org/abs/math/0404188">6</a><p></p>
<p></p></li><li>
“Nonuniform Upper Bounds: The Converse Direction of the Nonuniform Complexity Bounds .” <a href="https://dl.acm.org/doi/10.1145/800141.804678">7</a>
</li></ol>
<p>
The answers in brief: <b>a-5, b-7,c-1,d-2,e-3,f-4,g-6</b>.</p>
<p></p><p><br />
[fixed blog formatting issues, fixed paper ascription in the intro]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/12/02/too-long-didnt-read/"><span class="datestr">at December 02, 2020 10:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/179">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/179">TR20-179 |  Decoding Multivariate Multiplicity Codes on Product Sets | 

	Mrinal Kumar, 

	Siddharth Bhandari, 

	Prahladh Harsha, 

	Madhu Sudan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The multiplicity Schwartz-Zippel lemma bounds the total multiplicity of zeroes of a multivariate polynomial on a product set. This lemma motivates the multiplicity codes of Kopparty, Saraf and Yekhanin [J. ACM, 2014], who showed how to use this lemma to construct high-rate locally-decodable codes. However, the algorithmic results about these codes crucially rely on the fact that the polynomials are evaluated on a vector space and not an arbitrary product set. 

In this work, we show how to decode multivariate multiplicity codes of large multiplicities in polynomial time over finite product sets (over fields of large characteristic and zero characteristic).  Previously such decoding algorithms were not known even for a positive fraction of errors. In contrast, our work goes all the way to the distance of the code and in particular exceeds both the unique decoding bound and the Johnson bound. For errors exceeding the Johnson bound, even combinatorial list-decodablity of these codes was not known.

Our algorithm is an application of the classical polynomial method directly to the multivariate setting. In particular, we do not rely on a reduction from the multivariate to the univariate case as is typical of many of the existing results on decoding codes based on multivariate polynomials.  However, a vanilla application of the polynomial method in the multivariate setting does not yield a polynomial upper bound on the list size. We obtain a polynomial bound on the list size by taking an alternative view of multivariate multiplicity codes. In this view,  we glue all the partial derivatives of the same order  together  using a fresh set $\mathbf{z}$ of variables.  We then apply the polynomial method by viewing this as a problem over the field $\mathbb{F}(\mathbf{z})$ of rational functions in $\mathbf{z}$.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/179"><span class="datestr">at December 02, 2020 03:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/">Tenure-track assistant professors at Rochester Institute of Technology (apply by January 2, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at the Rochester Institute of Technology invites applications for full-time tenure-track assistant professor positions starting in Fall 2021. We are looking to hire in all areas of computer science that strengthen our department.</p>
<p>Website: <a href="https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291">https://sjobs.brassring.com/TGnewUI/Search/Home/Home?partnerid=25483&amp;siteid=5291#jobDetails=1534060_5291</a><br />
Email: csfacsearch@cs.rit.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/02/tenure-track-assistant-professors-at-rochester-institute-of-technology-apply-by-january-2-2021/"><span class="datestr">at December 02, 2020 01:44 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00738">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00738">Searching, Sorting, and Cake Cutting in Rounds</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Br=acirc=nzei:Simina.html">Simina Brânzei</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Paparas:Dimitris.html">Dimitris Paparas</a>, Nicholas J. Recker <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00738">PDF</a><br /><b>Abstract: </b>We study sorting and searching in rounds, motivated by a cake cutting
problem. The search problem we consider is: we are given an array $x = (x_1,
\ldots, x_n)$ and an element $z$ promised to be in the array. We have access to
an oracle that answers comparison queries: "How is $x_i$ compared to $x_j$?",
where the answer can be "$&lt;$", "$=$", or "$&gt;$". The goal is to find the
location of $z$ with success probability at least $p \in [0,1]$ in at most $k$
rounds of interaction with the oracle. The problem is called ordered or
unordered search, depending on whether the array $x$ is sorted or unsorted,
respectively.
</p>
<p>For ordered search, we show the expected query complexity of randomized
algorithms is $\Theta\bigl(k\cdot p \cdot n^{1/k}\bigr)$ in the worst case. In
contrast, the expected query complexity of deterministic algorithms searching
for a uniformly random element is $\Theta\bigl(k\cdot p^{1/k} \cdot
n^{1/k}\bigr)$. The uniform distribution is the worst case for deterministic
algorithms.
</p>
<p>For unordered search, the expected query complexity of randomized algorithms
is $np\bigl(\frac{k+1}{2k}\bigr) \pm 1$ in the worst case, while the expected
query complexity of deterministic algorithms searching for a uniformly random
element is $np \bigl(1 - \frac{k-1}{2k}p \bigr) \pm 1$.
</p>
<p>We also discuss the connections of these search problems to the rank query
model, where the array $x$ can be accessed via queries of the form "Is
rank$(x_i) \leq k$?". Unordered search is equivalent to Select with rank
queries (given $q$, find $x_i$ with rank $q$) and ordered search to Locate with
rank queries (given $x_i$, find its rank). We show an equivalence between
sorting with rank queries and proportional cake cutting with contiguous pieces
for any number of rounds, as well as an improved lower bound for deterministic
sorting in rounds with rank queries.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00738"><span class="datestr">at December 02, 2020 10:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00704">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00704">Lower Bounds for Semialgebraic Range Searching and Stabbing Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Afshani:Peyman.html">Peyman Afshani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheng:Pingan.html">Pingan Cheng</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00704">PDF</a><br /><b>Abstract: </b>In the semialgebraic range searching problem, we are to preprocess $n$ points
in $\mathbb{R}^d$ s.t. for any query range from a family of constant complexity
semialgebraic sets, all the points intersecting the range can be reported or
counted efficiently. When the ranges are composed of simplices, the problem can
be solved using $S(n)$ space and with $Q(n)$ query time with $S(n)Q^d(n) =
\tilde{O}(n^d)$ and this trade-off is almost tight. Consequently, there exists
low space structures that use $\tilde{O}(n)$ space with $O(n^{1-1/d})$ query
time and fast query structures that use $O(n^d)$ space with $O(\log^{d} n)$
query time. However, for the general semialgebraic ranges, only low space
solutions are known, but the best solutions match the same trade-off curve as
the simplex queries. It has been conjectured that the same could be done for
the fast query case but this open problem has stayed unresolved.
</p>
<p>Here, we disprove this conjecture. We give the first nontrivial lower bounds
for semilagebraic range searching and related problems. We show that any data
structure for reporting the points between two concentric circles with $Q(n)$
query time must use $S(n)=\Omega(n^{3-o(1)}/Q(n)^5)$ space, meaning, for
$Q(n)=O(\log^{O(1)}n)$, $\Omega(n^{3-o(1)})$ space must be used. We also study
the problem of reporting the points between two polynomials of form
$Y=\sum_{i=0}^\Delta a_i X^i$ where $a_0, \cdots, a_\Delta$ are given at the
query time. We show $S(n)=\Omega(n^{\Delta+1-o(1)}/Q(n)^{\Delta^2+\Delta})$. So
for $Q(n)=O(\log^{O(1)}n)$, we must use $\Omega(n^{\Delta+1-o(1)})$ space. For
the dual semialgebraic stabbing problems, we show that in linear space, any
data structure that solves 2D ring stabbing must use $\Omega(n^{2/3})$ query
time. This almost matches the linearization upper bound. For general
semialgebraic slab stabbing problems, again, we show an almost tight lower
bounds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00704"><span class="datestr">at December 02, 2020 10:56 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00689">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00689">Dynamic Weighted Matching with Heterogeneous Arrival and Departure Rates</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Collina:Natalie.html">Natalie Collina</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Immorlica:Nicole.html">Nicole Immorlica</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leyton=Brown:Kevin.html">Kevin Leyton-Brown</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lucier:Brendan.html">Brendan Lucier</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Newman:Neil.html">Neil Newman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00689">PDF</a><br /><b>Abstract: </b>We study a dynamic non-bipartite matching problem. There is a fixed set of
agent types, and agents of a given type arrive and depart according to
type-specific Poisson processes. The value of a match is determined by the
types of the matched agents. We present an online algorithm that is
(1/6)-competitive with respect to the value of the optimal-in-hindsight policy,
for arbitrary weighted graphs. This is the first result to achieve a constant
competitive ratio when both arrivals and departures are random and unannounced.
Our algorithm treats agents heterogeneously, interpolating between immediate
and delayed matching in order to thicken the market while still matching
valuable agents opportunistically.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00689"><span class="datestr">at December 02, 2020 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00675">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00675">Topological Learning for Brain Networks</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Songdechakraiwut:Tananun.html">Tananun Songdechakraiwut</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chung:Moo_K=.html">Moo K. Chung</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00675">PDF</a><br /><b>Abstract: </b>This paper proposes a novel topological learning framework that can integrate
networks of different sizes and topology through persistent homology. This is
possible through the introduction of a new topological loss function that
enables such challenging task. The use of the proposed loss function bypasses
the intrinsic computational bottleneck associated with matching networks. We
validate the method in extensive statistical simulations with ground truth to
assess the effectiveness of the topological loss in discriminating networks
with different topology. The method is further applied to a twin brain imaging
study in determining if the brain network is genetically heritable. The
challenge is in overlaying the topologically different functional brain
networks obtained from the resting-state functional magnetic resonance imaging
(fMRI) onto the template structural brain network obtained through the
diffusion tensor imaging (DTI).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00675"><span class="datestr">at December 02, 2020 10:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00589">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00589">Train Tracks with Gaps: Applying the Probabilistic Method to Trains</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00589">PDF</a><br /><b>Abstract: </b>We identify a tradeoff curve between the number of wheels on a train car, and
the amount of track that must be installed in order to ensure that the train
car is supported by the track at all times. The goal is to build an elevated
track that covers some large distance $\ell$, but that consists primarily of
gaps, so that the total amount of feet of train track that is actually
installed is only a small fraction of $\ell$. In order so that the train track
can support the train at all points, the requirement is that as the train
drives across the track, at least one set of wheels from the rear quarter and
at least one set of wheels from the front quarter of the train must be touching
the track at all times.
</p>
<p>We show that, if a train car has $n$ sets of wheels evenly spaced apart in
its rear and $n$ sets of wheels evenly spaced apart in its front, then it is
possible to build a train track that supports the train car but uses only
$\Theta( \ell / n )$ feet of track. We then consider what happens if the wheels
on the train car are not evenly spaced (and may even be configured
adversarially). We show that for any configuration of the train car, with $n$
wheels in each of the front and rear quarters of the car, it is possible to
build a track that supports the car for distance $\ell$ and uses only
$O\left(\frac{\ell \log n}{n}\right)$ feet of track. Additionally, we show that
there exist configurations of the train car for which this tradeoff curve is
asymptotically optimal. Both the upper and lower bounds are achieved via
applications of the probabilistic method.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00589"><span class="datestr">at December 02, 2020 10:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00511">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00511">Best Fit Bin Packing with Random Order Revisited</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a>, Arindam Khan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Ladewig:Leon.html">Leon Ladewig</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00511">PDF</a><br /><b>Abstract: </b>Best Fit is a well known online algorithm for the bin packing problem, where
a collection of one-dimensional items has to be packed into a minimum number of
unit-sized bins. In a seminal work, Kenyon [SODA 1996] introduced the
(asymptotic) random order ratio as an alternative performance measure for
online algorithms. Here, an adversary specifies the items, but the order of
arrival is drawn uniformly at random. Kenyon's result establishes lower and
upper bounds of 1.08 and 1.5, respectively, for the random order ratio of Best
Fit. Although this type of analysis model became increasingly popular in the
field of online algorithms, no progress has been made for the Best Fit
algorithm after the result of Kenyon.
</p>
<p>We study the random order ratio of Best Fit and tighten the long-standing gap
by establishing an improved lower bound of 1.10. For the case where all items
are larger than 1/3, we show that the random order ratio converges quickly to
1.25. It is the existence of such large items that crucially determines the
performance of Best Fit in the general case. Moreover, this case is closely
related to the classical maximum-cardinality matching problem in the fully
online model. As a side product, we show that Best Fit satisfies a monotonicity
property on such instances, unlike in the general case.
</p>
<p>In addition, we initiate the study of the absolute random order ratio for
this problem. In contrast to asymptotic ratios, absolute ratios must hold even
for instances that can be packed into a small number of bins. We show that the
absolute random order ratio of Best Fit is at least 1.3. For the case where all
items are larger than 1/3, we derive upper and lower bounds of 21/16 and 1.2,
respectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00511"><span class="datestr">at December 02, 2020 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00497">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00497">Improved Online Algorithms for Knapsack and GAP in the Random Order Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a>, Arindam Khan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Ladewig:Leon.html">Leon Ladewig</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00497">PDF</a><br /><b>Abstract: </b>The knapsack problem is one of the classical problems in combinatorial
optimization: Given a set of items, each specified by its size and profit, the
goal is to find a maximum profit packing into a knapsack of bounded capacity.
In the online setting, items are revealed one by one and the decision, if the
current item is packed or discarded forever, must be done immediately and
irrevocably upon arrival. We study the online variant in the random order model
where the input sequence is a uniform random permutation of the item set.
</p>
<p>We develop a randomized (1/6.65)-competitive algorithm for this problem,
outperforming the current best algorithm of competitive ratio 1/8.06
[Kesselheim et al. SIAM J. Comp. 47(5)]. Our algorithm is based on two new
insights: We introduce a novel algorithmic approach that employs two given
algorithms, optimized for restricted item classes, sequentially on the input
sequence. In addition, we study and exploit the relationship of the knapsack
problem to the 2-secretary problem.
</p>
<p>The generalized assignment problem (GAP) includes, besides the knapsack
problem, several important problems related to scheduling and matching. We show
that in the same online setting, applying the proposed sequential approach
yields a (1/6.99)-competitive randomized algorithm for GAP. Again, our proposed
algorithm outperforms the current best result of competitive ratio 1/8.06
[Kesselheim et al. SIAM J. Comp. 47(5)].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00497"><span class="datestr">at December 02, 2020 10:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00488">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00488">New Results for the $k$-Secretary Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Albers:Susanne.html">Susanne Albers</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Ladewig:Leon.html">Leon Ladewig</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00488">PDF</a><br /><b>Abstract: </b>Suppose that $n$ items arrive online in random order and the goal is to
select $k$ of them such that the expected sum of the selected items is
maximized. The decision for any item is irrevocable and must be made on arrival
without knowing future items. This problem is known as the $k$-secretary
problem, which includes the classical secretary problem with the special case
$k=1$. It is well-known that the latter problem can be solved by a simple
algorithm of competitive ratio $1/e$ which is optimal for $n \to \infty$.
Existing algorithms beating the threshold of $1/e$ either rely on involved
selection policies already for $k=2$, or assume that $k$ is large.
</p>
<p>In this paper we present results for the $k$-secretary problem, considering
the interesting and relevant case that $k$ is small. We focus on simple
selection algorithms, accompanied by combinatorial analyses. As a main
contribution we propose a natural deterministic algorithm designed to have
competitive ratios strictly greater than $1/e$ for small $k \geq 2$. This
algorithm is hardly more complex than the elegant strategy for the classical
secretary problem, optimal for $k=1$, and works for all $k \geq 1$. We derive
its competitive ratios for $k \leq 100$, ranging from $0.41$ for $k=2$ to
$0.75$ for $k=100$.
</p>
<p>Moreover, we consider an algorithm proposed earlier in the literature, for
which no rigorous analysis is known. We show that its competitive ratio is
$0.4168$ for $k=2$, implying that the previous analysis was not tight. Our
analysis reveals a surprising combinatorial property of this algorithm, which
might be helpful to find a tight analysis for all $k$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00488"><span class="datestr">at December 02, 2020 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00464">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00464">(k, l)-Medians Clustering of Trajectories Using Continuous Dynamic Time Warping</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Brankovic:Milutin.html">Milutin Brankovic</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchin:Kevin.html">Kevin Buchin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Klaren:Koen.html">Koen Klaren</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nusser:Andr=eacute=.html">André Nusser</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Popov:Aleksandr.html">Aleksandr Popov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wong:Sampson.html">Sampson Wong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00464">PDF</a><br /><b>Abstract: </b>Due to the massively increasing amount of available geospatial data and the
need to present it in an understandable way, clustering this data is more
important than ever. As clusters might contain a large number of objects,
having a representative for each cluster significantly facilitates
understanding a clustering. Clustering methods relying on such representatives
are called center-based. In this work we consider the problem of center-based
clustering of trajectories.
</p>
<p>In this setting, the representative of a cluster is again a trajectory. To
obtain a compact representation of the clusters and to avoid overfitting, we
restrict the complexity of the representative trajectories by a parameter l.
This restriction, however, makes discrete distance measures like dynamic time
warping (DTW) less suited.
</p>
<p>There is recent work on center-based clustering of trajectories with a
continuous distance measure, namely, the Fr\'echet distance. While the
Fr\'echet distance allows for restriction of the center complexity, it can also
be sensitive to outliers, whereas averaging-type distance measures, like DTW,
are less so. To obtain a trajectory clustering algorithm that allows
restricting center complexity and is more robust to outliers, we propose the
usage of a continuous version of DTW as distance measure, which we call
continuous dynamic time warping (CDTW). Our contribution is twofold:
</p>
<p>1. To combat the lack of practical algorithms for CDTW, we develop an
approximation algorithm that computes it.
</p>
<p>2. We develop the first clustering algorithm under this distance measure and
show a practical way to compute a center from a set of trajectories and
subsequently iteratively improve it.
</p>
<p>To obtain insights into the results of clustering under CDTW on practical
data, we conduct extensive experiments.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00464"><span class="datestr">at December 02, 2020 10:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00356">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00356">Better Fewer but Better: Community Search with Outliers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bonchi:Francesco.html">Francesco Bonchi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Severini:Lorenzo.html">Lorenzo Severini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sozio:Mauro.html">Mauro Sozio</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00356">PDF</a><br /><b>Abstract: </b>Given a set of vertices in a network, that we believe are of interest for the
application under analysis, community search is the problem of producing a
subgraph potentially explaining the relationships existing among the vertices
of interest. In practice this means that the solution should add some vertices
to the query ones, so to create a connected subgraph that exhibits some
"cohesiveness" property. This problem has received increasing attention in
recent years: while several cohesiveness functions have been studied, the bulk
of the literature looks for a solution subgraphs containing all the query
vertices. However, in many exploratory analyses we might only have a reasonable
belief about the vertices of interest: if only one of them is not really
related to the others, forcing the solution to include all of them might hide
the existence of much more cohesive and meaningful subgraphs, that we could
have found by allowing the solution to detect and drop the outlier vertex. In
this paper we study the problem of community search with outliers, where we are
allowed to drop up to $k$ query vertices, with $k$ being an input parameter. We
consider three of the most used measures of cohesiveness: the minimum degree,
the diameter of the subgraph and the maximum distance with a query vertex. By
optimizing one and using one of the others as a constraint we obtain three
optimization problems: we study their hardness and we propose different exact
and approximation algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00356"><span class="datestr">at December 02, 2020 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00330">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00330">Time-Space Lower Bounds for Simulating Proof Systems with Quantum and Randomized Verifiers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Abhijit Mudigonda, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williams:R=_Ryan.html">R. Ryan Williams</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00330">PDF</a><br /><b>Abstract: </b>A line of work initiated by Fortnow in 1997 has proven model-independent
time-space lower bounds for the $\mathsf{SAT}$ problem and related problems
within the polynomial-time hierarchy. For example, for the $\mathsf{SAT}$
problem, the state-of-the-art is that the problem cannot be solved by
random-access machines in $n^c$ time and $n^{o(1)}$ space simultaneously for $c
&lt; 2\cos(\frac{\pi}{7}) \approx 1.801$.
</p>
<p>We extend this lower bound approach to the quantum and randomized domains.
Combining Grover's algorithm with components from $\mathsf{SAT}$ time-space
lower bounds, we show that there are problems verifiable in $O(n)$ time with
quantum Merlin-Arthur protocols that cannot be solved in $n^c$ time and
$n^{o(1)}$ space simultaneously for $c &lt; \frac{3+\sqrt{3}}{2} \approx 2.366$, a
super-quadratic time lower bound. This result and the prior work on
$\mathsf{SAT}$ can both be viewed as consequences of a more general formula for
time lower bounds against small-space algorithms, whose asymptotics we study in
full.
</p>
<p>We also show lower bounds against randomized algorithms: there are problems
verifiable in $O(n)$ time with (classical) Merlin-Arthur protocols that cannot
be solved in $n^c$ randomized time and $O(\log n)$ space simultaneously for $c
&lt; 1.465$, improving a result of Diehl. For quantum Merlin-Arthur protocols, the
lower bound in this setting can be improved to $c &lt; 1.5$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00330"><span class="datestr">at December 02, 2020 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00292">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00292">Comb inequalities for typical Euclidean TSP instances</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pegden:Wesley.html">Wesley Pegden</a>, Anish Sevekari <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00292">PDF</a><br /><b>Abstract: </b>We prove that even in average case, the Euclidean Traveling Salesman Problem
exhibits an integrality gap of $(1+\epsilon)$ for $\epsilon&gt;0$ when the
Held-Karp Linear Programming relaxation is augmented by all comb inequalities
of bounded size. This implies that large classes of branch-and-cut algorithms
take exponential time for the Euclidean TSP, even on random inputs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00292"><span class="datestr">at December 02, 2020 10:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00193">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00193">Lightweight Encryption for the Low Powered IoT Devices</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Usman:Muhammad.html">Muhammad Usman</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00193">PDF</a><br /><b>Abstract: </b>The internet of things refers to the network of devices connected to the
internet and can communicate with each other. The term things is to refer
non-conventional devices that are usually not connected to the internet. The
network of such devices or things is growing at an enormous rate. The security
and privacy of the data flowing through these things is a major concern. The
devices are low powered and the conventional encryption algorithms are not
suitable to be employed on these devices. In this correspondence a survey of
the contemporary lightweight encryption algorithms suitable for use in the IoT
environment has been presented.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00193"><span class="datestr">at December 02, 2020 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00127">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00127">The Variable-Processor Cup Game</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kuszmaul:William.html">William Kuszmaul</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Westover:Alek.html">Alek Westover</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00127">PDF</a><br /><b>Abstract: </b>The problem of scheduling tasks on $p$ processors so that no task ever gets
too far behind is often described as a game with cups and water. In the
$p$-processor cup game on $n$ cups, there are two players, a filler and an
emptier, that take turns adding and removing water from a set of $n$ cups. In
each turn, the filler adds $p$ units of water to the cups, placing at most $1$
unit of water in each cup, and then the emptier selects $p$ cups to remove up
to $1$ unit of water from. The emptier's goal is to minimize the backlog, which
is the height of the fullest cup.
</p>
<p>The $p$-processor cup game has been studied in many different settings,
dating back to the late 1960's. All of the past work shares one common
assumption: that $p$ is fixed. This paper initiates the study of what happens
when the number of available processors $p$ varies over time, resulting in what
we call the \emph{variable-processor cup game}.
</p>
<p>Remarkably, the optimal bounds for the variable-processor cup game differ
dramatically from its classical counterpart. Whereas the $p$-processor cup has
optimal backlog $\Theta(\log n)$, the variable-processor game has optimal
backlog $\Theta(n)$. Moreover, there is an efficient filling strategy that
yields backlog $\Omega(n^{1 - \epsilon})$ in quasi-polynomial time against any
deterministic emptying strategy.
</p>
<p>We additionally show that straightforward uses of randomization cannot be
used to help the emptier. In particular, for any positive constant $\Delta$,
and any $\Delta$-greedy-like randomized emptying algorithm $\mathcal{A}$, there
is a filling strategy that achieves backlog $\Omega(n^{1 - \epsilon})$ against
$\mathcal{A}$ in quasi-polynomial time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00127"><span class="datestr">at December 02, 2020 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00086">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00086">Bridging the Gap Between Tree and Connectivity Augmentation: Unified and Stronger Approaches</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Federica Cecchetto, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Traub:Vera.html">Vera Traub</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zenklusen:Rico.html">Rico Zenklusen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00086">PDF</a><br /><b>Abstract: </b>We consider the Connectivity Augmentation Problem (CAP), a classical problem
in the area of Survivable Network Design. It is about increasing the
edge-connectivity of a graph by one unit in the cheapest possible way. More
precisely, given a $k$-edge-connected graph $G=(V,E)$ and a set of extra edges,
the task is to find a minimum cardinality subset of extra edges whose addition
to $G$ makes the graph $(k+1)$-edge-connected. If $k$ is odd, the problem is
known to reduce to the Tree Augmentation Problem (TAP) -- i.e., $G$ is a
spanning tree -- for which significant progress has been achieved recently,
leading to approximation factors below $1.5$ (the currently best factor is
$1.458$). However, advances on TAP did not carry over to CAP so far. Indeed,
only very recently, Byrka, Grandoni, and Ameli (STOC 2020) managed to obtain
the first approximation factor below $2$ for CAP by presenting a
$1.91$-approximation algorithm based on a method that is disjoint from recent
advances for TAP.
</p>
<p>We first bridge the gap between TAP and CAP, by presenting techniques that
allow for leveraging insights and methods from TAP to approach CAP. We then
introduce a new way to get approximation factors below $1.5$, based on a new
analysis technique. Through these ingredients, we obtain a
$1.393$-approximation algorithm for CAP, and therefore also TAP. This leads to
the currently best approximation result for both problems in a unified way, by
significantly improving on the above-mentioned $1.91$-approximation for CAP and
also the previously best approximation factor of $1.458$ for TAP by Grandoni,
Kalaitzis, and Zenklusen (STOC 2018). Additionally, a feature we inherit from
recent TAP advances is that our approach can deal with the weighted setting
when the ratio between the largest to smallest cost on extra links is bounded,
in which case we obtain approximation factors below $1.5$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00086"><span class="datestr">at December 02, 2020 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2012.00079">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2012.00079">Integer Programming and Incidence Treedepth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eiben:Eduard.html">Eduard Eiben</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ganian:Robert.html">Robert Ganian</a>, Dušan Knop, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ordyniak:Sebastian.html">Sebastian Ordyniak</a>, Michał Pilipczuk, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wrochna:Marcin.html">Marcin Wrochna</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2012.00079">PDF</a><br /><b>Abstract: </b>Recently a strong connection has been shown between the tractability of
integer programming (IP) with bounded coefficients on the one side and the
structure of its constraint matrix on the other side. To that end, integer
linear programming is fixed-parameter tractable with respect to the primal (or
dual) treedepth of the Gaifman graph of its constraint matrix and the largest
coefficient (in absolute value). Motivated by this, Kouteck\'y, Levin, and Onn
[ICALP 2018] asked whether it is possible to extend these result to a more
broader class of integer linear programs. More formally, is integer linear
programming fixed-parameter tractable with respect to the incidence treedepth
of its constraint matrix and the largest coefficient (in absolute value)?
</p>
<p>We answer this question in negative. In particular, we prove that deciding
the feasibility of a system in the standard form, ${A\mathbf{x} = \mathbf{b}},
{\mathbf{l} \le \mathbf{x} \le \mathbf{u}}$, is $\mathsf{NP}$-hard even when
the absolute value of any coefficient in $A$ is 1 and the incidence treedepth
of $A$ is 5. Consequently, it is not possible to decide feasibility in
polynomial time even if both the assumed parameters are constant, unless
$\mathsf{P}=\mathsf{NP}$. Moreover, we complement this intractability result by
showing tractability for natural and only slightly more restrictive settings,
namely: (1) treedepth with an additional bound on either the maximum arity of
constraints or the maximum number of occurrences of variables and (2) the
vertex cover number.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2012.00079"><span class="datestr">at December 02, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1814">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/12/01/motwani-postdoc-announced/">Motwani Postdoc Announced</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>After discussing <a href="https://theorydish.blog/2020/11/16/hiring-postdocs/">postdoc opportunities with me</a> and the <a href="https://toc4fairnesses.org/postdoc-opportunities/">opportunities as part of the Simons Collaboration on the Theory of Algorithmic Fairness</a>, let me conclude with postdoc opportunities with Stanford theory group:</p>



<p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>



<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17685">https://academicjobsonline.org/ajo/jobs/17685</a><br />Email: theory.stanford@gmail.com</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/12/01/motwani-postdoc-announced/"><span class="datestr">at December 01, 2020 06:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/12/01/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/12/01/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2020/">Motwani Postdoctoral Fellowship at Stanford Computer Science (apply by December 15, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The theory group at Stanford invites applications for the Motwani postdoctoral fellowship in theoretical computer science. Information and application instructions below. Applications will be accepted until the positions are filled, but review of applicants will begin after Dec 15.</p>
<p>Website: <a href="https://academicjobsonline.org/ajo/jobs/17685">https://academicjobsonline.org/ajo/jobs/17685</a><br />
Email: theory.stanford@gmail.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/12/01/motwani-postdoctoral-fellowship-at-stanford-computer-science-apply-by-december-15-2020/"><span class="datestr">at December 01, 2020 12:48 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1809">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/11/30/postdoc-opportunities-in-algorithmic-fairness/">Postdoc Opportunities in Algorithmic Fairness</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://theorydish.blog/2020/11/16/hiring-postdocs/">As promised</a>, more postdoctoral positions now available for 2021</p>



<p>The <a href="https://www.simonsfoundation.org/2020/06/18/foundation-announces-simons-collaboration-on-the-theory-of-algorithmic-fairness/">Simons Collaboration on the Theory of Algorithmic Fairness</a> seek highly qualified candidates (within five years of the award of their PhD) for a postdoctoral research position. Appointments will begin Summer or Fall 2021.</p>



<p>This multi-year program will host several postdoctoral researchers working on modeling and theoretical work understanding (a) the sources of discriminatory behavior of algorithms, and (b) how best to mitigate such impacts.</p>



<p>Descriptions of the scientific agendas of this research collaboration can be found at <a href="https://toc4fairnesses.org/" target="_blank" rel="noreferrer noopener">https://toc4fairnesses.org/</a>.</p>



<p>Fellows will be able to collaborate broadly, including with researchers at partner institutions: Stanford University, Toyota Institute of Technology at Chicago, Massachusetts Institute of Technology, Harvard University, UC Berkeley, Cornell University,  Hebrew University of Jerusalem, Weizmann Institute of Science, University of Toronto,  University of Washington, and University of Pennsylvania.</p>



<p> The anticipated term for a fellowship is one or two years – to be decided at the time of appointment, with the possibility of extension based on mutual agreement. In addition to competitive salary and benefits, the fellowship also includes funding for independent travel to workshops, conferences and other universities and research labs.</p>



<p>In order to apply, please email a CV, research statement, and have two reference letters sent to <a href="mailto:jamiemmt@cs.washington.edu" target="_blank" rel="noreferrer noopener">jamiemmt@cs.washington.edu</a>. Applications and reference letters are due Dec. 31, 2020, though we will consider applications which arrive after that date. Decisions will be made in February.</p>



<p>Jamie Morgenstern, chair of the postdoctoral search committee<br />Simons Collaboration on the Foundations of Fairness in Machine Learning</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/11/30/postdoc-opportunities-in-algorithmic-fairness/"><span class="datestr">at November 30, 2020 09:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/11/30/faculty-at-university-of-california-santa-cruz-apply-by-january-12-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/11/30/faculty-at-university-of-california-santa-cruz-apply-by-january-12-2021/">Faculty at University of California, Santa Cruz (apply by January 12, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Computer Science &amp; Engineering department at UC Santa Cruz is recruiting for six junior faculty positions, two in theoretical computer science, two in applied machine learning, and two in experimental systems.<br />
(The TCS position URL is given below. For the others, look at the open recruitments in Computer Science and Engineering.)</p>
<p>Website: <a href="https://recruit.ucsc.edu/JPF00962">https://recruit.ucsc.edu/JPF00962</a><br />
Email: C. Seshadhri</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/11/30/faculty-at-university-of-california-santa-cruz-apply-by-january-12-2021/"><span class="datestr">at November 30, 2020 09:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/11/30/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/11/30/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://scholar.google.com/scholar?q=%22Appiled+Superconductivity%22">An amusing if minor repeated typo in the literature: “appiled superconductivity</a> (<a href="https://mathstodon.xyz/@11011110/105224219465552642">\(\mathbb{M}\)</a>). I think its 177 Google Scholar hits are the fault of IEEE, which spells <em>Trans. on Applied Superconductivity</em> correctly on its site but misspells it repeatedly in the doi database. So if you get your citations from doi metadata, you will get this error. You can see the metadata for an example by <code class="language-plaintext highlighter-rouge">curl -LH "Accept: application/x-bibtex" https://doi.org/10.1109/TASC.2005.849553</code>.</p>
  </li>
  <li>
    <p><a href="https://post.lurk.org/@crickxson/105199692913412250">A map of the percentages of female researchers in Europe</a>. The numbers are highest in the Baltics and Balkans; the discussion thread suggests that there’s a negative correlation with pay.</p>
  </li>
  <li>
    <p><a href="https://news.ycombinator.com/item?id=25149206">YouTube no longer an acceptable platform for course lecture or academic talk content</a> (<a href="https://mathstodon.xyz/@11011110/105238898515120908">\(\mathbb{M}\)</a>). Unless, of course, you and your university are comfortable with your students or other audience members being subject to advertisements that interrupt the lectures and are beyond your control both in their placement and content.</p>
  </li>
  <li>
    <p><a href="https://www.quantamagazine.org/geometry-reveals-how-the-world-is-assembled-from-cubes-20201119/">Scientists uncover the universal geometry of geology</a> (<a href="https://mathstodon.xyz/@11011110/105241748181882434">\(\mathbb{M}\)</a>). This is all a bit mystic and breathless and woo, but what <em>Quanta</em> really seems to mean to is that if you subdivide space by randomly recursively splitting by planes (sort of like a 3d <a href="https://en.wikipedia.org/wiki/Gilbert_tessellation">Gilbert tessellation</a>) then the average number of sides per bottom-level polyhedron is six.</p>
  </li>
  <li>
    <p><a href="https://cameroncounts.wordpress.com/2020/11/19/a-paradox-and-where-it-led/">A paradox, and where it led</a> (<a href="https://mathstodon.xyz/@11011110/105249285864846993">\(\mathbb{M}\)</a>). Peter Cameron looks at the inclusion graphs of countable models of not-well-founded set theories. The well-founded ones are all the Rado graph, but without foundation the results are more varied.</p>
  </li>
  <li>
    <p><a href="https://theconversation.com/curved-origami-offers-a-creative-route-to-making-robots-and-other-mechanical-devices-150253">Curved origami robot grippers with tunable stiffness</a> (<a href="https://mathstodon.xyz/@11011110/105260956314627650">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://blog.archive.org/2020/11/23/foss-wins-again-free-and-open-source-communities-comes-through-on-19th-century-newspapers-and-books-and-periodicals/">Archive.org improves accuracy of OCR and compression of PDF on its huge collection of old scanned printed documents by switching to open-source software</a> (<a href="https://mathstodon.xyz/@11011110/105264347147907544">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://hackers.town/@_cr0_tab/105165210380388504">Four common mathematical means of two quantities in a single compass-and-straightedge construction</a>.</p>
  </li>
  <li>
    <p><a href="http://cstaecker.fairfield.edu/~cstaecker/machines/graphsheets.html">More different kinds of graph paper than you might have even thought possible</a> (<a href="https://mathstodon.xyz/@11011110/105275252021160077">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://renato.athaydes.com/posts/comparing-jvm-alternatives-to-js.html">Comparison of six ways to get your old Java applets running again on the modern web</a> (<a href="https://mathstodon.xyz/@11011110/105284817164400009">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=19714924">via</a>). I have a couple of old defunct ones that I’m tempted to try this on…</p>
  </li>
  <li>
    <p><a href="https://mathstodon.xyz/@jsiehler/105288859971030412">New names for special types of hexagon: “squashogon”, “boltogon”, “extremely irregular hexagon”, and “treeah star”</a>. Boltogons are the zigzag 180-degree symmetric ones.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Wikipedia:Wikipedia_Signpost/2020-11-29/Essay">Some tips for avoiding sexist language when writing about women</a> (<a href="https://mathstodon.xyz/@11011110/105298265490259050">\(\mathbb{M}\)</a>). This is from 2015, when singular “they” was more controversial, and mostly aimed at Wikipedia editing, but it was recently reprinted in the Wikipedia <em>Signpost</em>, and I think it is still topical more generally.)</p>
  </li>
  <li>
    <p><a href="https://www.ams.org/journals/notices/202011/rnoti-p1780.pdf">The place of blogs in the modern math world, Katherine Thompson, <em>Notices of the AMS</em></a> (<a href="https://mathstodon.xyz/@11011110/105301116392488191">\(\mathbb{M}\)</a>). “Clearly, mathematicians are using blogs. … And yet despite all of the work that goes into blogs, the mathematical community has no idea what to make of them—even at the most basic level like citation.”</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/11/30/linkage.html"><span class="datestr">at November 30, 2020 06:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/178">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/178">TR20-178 |  Reciprocal Inputs in Arithmetic and Tropical Circuits | 

	Stasys Jukna, 

	Hannes Seiwert, 

	Igor Sergeev</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
It is known that the size of monotone arithmetic $(+,\ast)$ circuits can be  exponentially decreased by allowing just one division  "at the very end," at the output gate. A natural question is: can the size of $(+,\ast)$ circuits be substantially  reduced if we allow divisions "at the very beginning," that is, if besides  nonnegative real constants and variables $x_1,\ldots,x_n$, the circuits can also use their reciprocals $1/x_1,\ldots,1/x_n$ as inputs. We answer this question in the negative: the gain in circuit size is  then always at most quadratic.


Over tropical $(\min,+)$ and $(\max,+)$ semirings, division turns into subtraction; so, reciprocal inputs are then $-x_1,\ldots,-x_n$.  We give the same negative answer also for tropical circuits. The question of whether reciprocal inputs can substantially speed up tropical $(\min,+,\max)$ circuits, using both $\min$ and $\max$ gates, remains open.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/178"><span class="datestr">at November 30, 2020 05:48 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/11/30/tenure-track-assistant-professors-at-aalto-university-apply-by-january-10-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/11/30/tenure-track-assistant-professors-at-aalto-university-apply-by-january-10-2021/">Tenure Track Assistant Professors at Aalto University (apply by January 10, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at Aalto University invites applications for tenure-track positions at the Assistant Professor level. We are a diverse community welcoming applications in ALL AREAS of Computer Science.</p>
<p>Our CS Theory group (<a href="https://research.cs.aalto.fi/theory/">https://research.cs.aalto.fi/theory/</a>) has e.g. received the best paper awards in FOCS 2019 and ICALP 2017, as well as ERC starting grants in 2014 and 2017.</p>
<p>Website: <a href="https://www.aalto.fi/en/open-positions/tenure-track-assistant-professors-in-computer-science">https://www.aalto.fi/en/open-positions/tenure-track-assistant-professors-in-computer-science</a><br />
Email: laura.kuusisto-noponen@aalto.fi</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/11/30/tenure-track-assistant-professors-at-aalto-university-apply-by-january-10-2021/"><span class="datestr">at November 30, 2020 03:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/11/30/research-associate-postdoc-at-university-of-edinburgh-apply-by-january-6-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/11/30/research-associate-postdoc-at-university-of-edinburgh-apply-by-january-6-2021/">Research Associate (Postdoc) at University of Edinburgh (apply by January 6, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Applications are invited for research associate positions in Algorithms and Complexity, funded by the European Research Council (ERC) starting grant “New Approaches to Counting and Sampling” (NACS), led by Dr. Heng Guo in the School of Informatics, University of Edinburgh.</p>
<p>Website: <a href="https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/">https://elxw.fa.em3.oraclecloud.com/hcmUI/CandidateExperience/en/sites/CX_1001/job/123/</a><br />
Email: hguo@inf.ed.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/11/30/research-associate-postdoc-at-university-of-edinburgh-apply-by-january-6-2021/"><span class="datestr">at November 30, 2020 10:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/11/30/postdoc-at-technion-israel-institute-of-technology-apply-by-march-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/11/30/postdoc-at-technion-israel-institute-of-technology-apply-by-march-1-2021/">postdoc at Technion Israel Institute of Technology (apply by March 1, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Looking for excellent post graduate researchers for a yearlong postdoc position at the Computer Science Department at Technion. Main research theme is intersection of theoretical computer science with learning, information and data.</p>
<p>Website: <a href="https://nailon.net.technion.ac.il/openings/">https://nailon.net.technion.ac.il/openings/</a><br />
Email: mayasidis@cs.technion.ac.il</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/11/30/postdoc-at-technion-israel-institute-of-technology-apply-by-march-1-2021/"><span class="datestr">at November 30, 2020 07:43 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-1036999202735486243">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/11/james-randi-magicians-author-skeptic.html">James Randi, Magicians-Author-Skeptic, passed away at the age of 92</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><br /></p><p>James The Amazing Randi died on October 20, 2020, at the age of 92. He is survived by</p><p>his husband Jose Alvarez.  His Wikipedia page is <a href="https://en.wikipedia.org/wiki/James_Randi">here</a></p><div> </div><div>A few Randi Points:</div><div><br /></div><div><div><br /></div><div>0) Wikipedia lists his careers as Magician, Author, Skeptic. I didn't know that skeptic was a career.</div><div><br /></div><div>1) Randi debunked many paranormal claims, though he did not like the term <i>debunke</i>r. He preferred <i>investigator</i>.</div><div><br /></div><div>2) Martin Gardner and James Randi founded the</div><div><br /></div><div><i>Committee for Scientific Investigation of Claims of the Paranormal.</i></div><div><br /></div><div>which publishes</div><div><br /></div><div><i>The Skeptical Inquirer</i>: see <a href="https://skepticalinquirer.org/?gclid=Cj0KCQjwuL_8BRCXARIsAGiC51AlnsnROpbKH-O1K-3WoumIXHGLAACCVDxByb2lFy0rkKunUHblUOAaAmUmEALw_wcB">here</a>  </div></div><div><br /></div><div><div><br /></div><div>3) The internet is both a place where unchecked claims of paranormal activity (and more dangerous lies) can grow faster than in an earlier time, but also a place where magazines like The Skeptical Inquirer, and fact-checking websites, can help check the unchecked claims. What is winning? I leave that as an exercise for the reader. </div><div><br /></div><div>4) I suspect most (all?) people reading this blog do not believe in astrology, UFO's, ESP, or other crank theories. Hence I was surprised to read that Alan Turing thought the evidence for  ESP was <i>overwhelming. </i>This was mentioned in passing in his paper on The Turing Test (called there <i>The</i> <i>Imitation Game</i>) as something the Turing Test will have to account for. I've tried to find out why he believed this, without success. Some websites mentioned that belief in the paranormal was more... normal in those days. One suggested that after the counter-intuitive theories of quantum mechanics and relatively were out there, other counter-intuitive theories took hold, like ESP.  Even so, what was the evidence he was referring to?</div><div><br /></div><div>5) Claims that<i>  I was abducted by a UFO</i> or <i>I saw a UFO</i> have decreased since people now have cell phones so ALWAYS have a way to take pictures. Also rumors like (I had heard this one)</div><div><br /></div><div><i>There is an alternative ending to the movie BLAH which made is way to a few DVDs by mistake.</i></div><div><br /></div><div>are no longer made since IF true you could EASILY produce evidence of such (post to you tube or elsewhere).</div><div><br /></div><div>6) The term<i> skeptic</i> just means someone who doubts something, and is not necc a positive things.</div><div><br /></div><div><i>I am a skeptic when it comes go Global Warming</i></div><div><br /></div><div>being one example.</div></div><div><br /></div><div><div>Randi largely debunked things that were obviously false and not-political. (That the very existence of Global Warming is political is  appalling. At some future point the question of whether or not we ever got to the moon will be political: Something done by big government that worked is impossible, hence it did not happen. See Scott's Blog on disbelief that we ever went to the moon <a href="https://www.scottaaronson.com/blog/?p=4267">here</a>. And people like Randi will need to debunk the notion that the moon landing was faked.) </div><div><br /></div><div>7) Back to Turing- There is a large diff between believing in ESP and believing in astrology.</div><div><br /></div><div>For ESP Turing mentioned <i>overwhelming evidence. </i> While he was WRONG, he did see the need to HAVE evidence. And note that ESP CAN be tested and found to NOT be true. Also note that it is plausible (though I really doubt it) that some humans somehow have some level of ESP. Astrology has NO redeeming value or hope whatsoever. (I am reminded that in Martin Gardner's book <i>Fads and Fallacies in the name of science </i>he noted that most people would say things like `YES, I liked your debunking of A, but you are wrong about B--- B is for real!')</div><div><br /></div><div>UFO's: I do not believe that aliens have come here and abducted people or left crop circles or anything of the sort. The intelligent question of  <i>is there intelligent life in the universe  </i>is quite another matter.</div><div><br /></div><div>7) When I saw magicians as a kid (1960's) I knew that it was all tricks- though very skillful tricks which were impressive. Sometimes they would indicate that it was <i>real magic </i>but I did not know what they meant. Since then I have learned that in an earlier time it was common that magicians claimed they used  <i>real magic</i>.  I still don't quite know what that means, which is just as well since it does not exist.</div><div><br /></div><div>8) Randi has been sued by people whose tricks he has debunked. Randi seems to have always won.  I say <i>seems to </i> since legal cases are not as clear cut as mathematics.  I also looked up Uri Geller. He has sued A LOT of people, and not just people who deny his claims. Thinks like using his likeness  without permission  (he may have a point there). Very hard to tell how he is doing on balance.</div><div><br /></div><div>9) According to Wikipedia Randi dropped out of High School. I assume he learned A LOT on his own.</div><div><br /></div><div>(Trivia-- who was the last president who did not have a college degree? I will answer at the end.)</div><div><br /></div><div>10) This seems like a paradox... or something (quoted from Wikipedia):</div></div><div><br /></div><div><div>BEGIN</div><div><br /></div><div>Randi has been accused of actually using <i>psychic powers</i> to perform acts such as spoon bending. According to James Alcock, at a meeting where Randi was duplicating the performances of Uri Geller, a professor from the University at Buffalo shouted out that Randi was a fraud.  Randi said: "<i>Yes, indeed</i>, <i>I'm a trickste</i>r, <i>I'm a cheat, I'm a charlatan, that's what I do for a living. Everything I've done here was by trickery</i>. The professor shouted back:</div><div><br /></div><div><i>That's not what I mean. You're a fraud because you're pretending to do these things through trickery, but you're actually using psychic powers and misleading us by not admitting it.</i></div><div><br /></div><div>A similar event involved Senator Claiborne Pell, a confirmed believer in psychic phenomena.  When Randi personally demonstrated to Pell that he could reveal—by simple trickery—a concealed drawing that had been secretly made by the senator, Pell refused to believe that it was a trick, saying: "<i>I think</i> <i>Randi may be a </i><i>psychic and doesn't realize it</i>." Randi consistently denied having any paranormal powers or abilities.</div><div><br /></div><div>END</div><div><br /></div><div>Reminds me of <a href="https://blog.computationalcomplexity.org/2013/06/fraud-or-not.html">this</a> blog entry where I speculate about someone who codes up a great new classical  factoring algorithm and claims he has a quantum computer, or someone who has a working quantum computer and claims its a great new classical factoring algorithm. </div><div><br /></div><div><br /></div><div>11) The last president who did not have a college degree: Harry Truman.</div></div><div><br /></div><div><br /></div><div><br /></div></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/11/james-randi-magicians-author-skeptic.html"><span class="datestr">at November 30, 2020 04:36 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-5616947953323689751">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2020/11/adapt-designing-activity-informed-viral.html">ADAPT:  Designing Activity-Informed Viral Diagnostic Assays</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><span style="font-size: small;">I wanted to give a pointer to a <a href="https://www.biorxiv.org/content/10.1101/2020.11.28.401877v1" target="_blank" rel="nofollow">new preprint on bioRxiv</a> on developing diagnostic assays for viruses, by (first author) <a href="https://www.haydenmetsky.com/" target="_blank" rel="nofollow">Hayden Metsky</a> (and others!) out of the <a href="https://www.sabetilab.org/" target="_blank" rel="nofollow">Sabeti Lab</a> at the Broad Institute (that I've been a bit involved with).  Hayden, who somehow is both a computer science PhD and an expert in virology, has devised a novel software pipeline for developing diagnostics that are designed from the start to deal with genomic diversity (a virus evolves to have many somewhat different variants) and the challenge of false matches (you don't want to get false positives from matching some other different virus) -- also known as sensitivity and specificity.  Algorithmically, he uses machine learning to determine scores for possible tests for matches to small pieces of the genome, or probes, and utilizes locality-sensitive hashing, combinatorial optimization algorithms for submodular maximization, and sharding pattern matching across tries as substages in the overall design.  </span></p><div style="font-size: small;" class="gmail_default">I am always excited to see algorithmic ideas being used to solve real-world problems, and this is a deep and difficult example of the "algorithmic lens"  at work.  I am optimistically hopeful that this type of technology will help drive the development of viral diagnostic and monitoring methods forward.     </div><div class="yj6qo"></div><div style="font-size: small;" class="gmail_default adL"><br style="background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif;" /></div><div style="font-size: small;" class="gmail_default adL">Some additional pointers:  <a href="https://github.com/broadinstitute/adapt" target="_blank" rel="nofollow">to code</a>, <a href="https://adapt.sabetilab.org/covid-19/" target="_blank" rel="nofollow">to some array designs for SARS-CoV-2</a>, and <a href="https://twitter.com/haydenmetsky/status/1333121522127548416" target="_blank" rel="nofollow">Hayden's twitter thread describing the work</a>.  </div></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2020/11/adapt-designing-activity-informed-viral.html"><span class="datestr">at November 30, 2020 03:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/177">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/177">TR20-177 |  Counting Subgraphs in Degenerate Graphs | 

	Lior Gishboliner, 

	Asaf Shapira, 

	Yevgeny Levanzov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We consider the problem of counting the number of copies of a fixed graph $H$ within an input graph $G$. This is one of the most well-studied algorithmic graph problems, with many theoretical and practical applications. We focus on solving this problem when the input $G$ has {\em bounded degeneracy}. This is a rich family of graphs, containing all graphs without a fixed minor (e.g. planar graphs), as well as graphs generated by various random processes (e.g. preferential attachment graphs). We say that $H$ is {\em easy} if there is a linear-time algorithm for counting the number of copies of $H$ in an input $G$ of bounded degeneracy. A seminal result of Chiba and Nishizeki from '85 states that every $H$ on at most 4 vertices is easy. Bera, Pashanasangi, and Seshadhri recently extended this to all $H$ on 5 vertices, and further proved that for every $k &gt; 5$ there is a $k$-vertex $H$ which is not easy. They left open the natural problem of characterizing all easy graphs $H$. 
		
Bressan has recently introduced a framework for counting subgraphs in degenerate graphs, from which one can extract a sufficient condition for a graph $H$ to be  easy. Here we show that this sufficient condition is also necessary, thus fully answering the Bera--Pashanasangi--Seshadhri problem. We further resolve two closely related problems; namely characterizing the graphs that are easy with respect to counting induced copies, and with respect to counting homomorphisms. Our proofs rely on several novel approaches for proving hardness results in the context of subgraph-counting.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/177"><span class="datestr">at November 29, 2020 04:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2020-11-29-the-lock-commit-paradigm/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2020-11-29-the-lock-commit-paradigm/">The Lock-Commit Paradigm</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this post, we explore the Lock-Commit paradigm for consensus protocols. This approach is probably the most celebrated and widely used technique for reaching consensus in a safe manner. This approach is one of the key techniques in DLS88 and Lamport’s Paxos. We exemplify this paradigm by showing a single...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2020-11-29-the-lock-commit-paradigm/"><span class="datestr">at November 29, 2020 01:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/11/27/study-triangular-bottle">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/11/27/study-triangular-bottle.html">Study of a triangular bottle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>We acquired this small blue glass bottle nearly 15 years ago, as a prop for a Harry Potter themed birthday party. For much of the time since then it’s been decorating our bathroom window with several other blue bottles. Like most bottles these days, it’s molded rather than blown, but a little roughly so the welding seams are more visible than they usually are on wine or liquor bottles.</p>

<div><table style="margin-left: auto; margin-right: auto;">
<tbody><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img width="240" style="border-style: solid; border-color: black;" alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/1-m.jpg" /></td>
<td style="padding: 10px;"><img width="360" style="border-style: solid; border-color: black;" alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/2-m.jpg" /></td>
</tr><tr style="text-align: center; vertical-align: middle;">
<td style="padding: 10px;"><img width="280" style="border-style: solid; border-color: black;" alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/3-m.jpg" /></td>
<td style="padding: 10px;"><img width="300" style="border-style: solid; border-color: black;" alt="Triangular blue glass bottle" src="http://www.ics.uci.edu/~eppstein/pix/triangularbottle/4-m.jpg" /></td>
</tr></tbody></table></div>

<p>As you can see, it has an unusual triangular cross-section. The final image, with a Reuleaux triangle overlaid, shows that the curvature of this cross-section is less than a Reuleaux triangle would have. I don’t think its outline was chosen with any particular mathematics in mind, but only (as so many other curved triangles) to make an interesting shape.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/105286711285736529">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/11/27/study-triangular-bottle.html"><span class="datestr">at November 27, 2020 06:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=20494">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/11/27/recent-progress-on-high-dimensional-turan-type-problems-by-andrey-kupavskii-alexandr-polyanskii-istvan-tomon-and-dmitriy-zakharov-and-by-jason-long-bhargav-narayanan-and-corrine-yap/">Recent progress on high dimensional Turan-Type problems by Andrey Kupavskii, Alexandr Polyanskii, István Tomon, and Dmitriy Zakharov and by Jason Long, Bhargav Narayanan, and Corrine Yap.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h3>The extremal number for surfaces</h3>



<h3>Andrey Kupavskii, Alexandr Polyanskii, István Tomon, Dmitriy Zakharov: <a href="https://arxiv.org/abs/2010.07191">The extremal number of surfaces</a></h3>



<p></p><p><strong>Abstract:</strong> In 1973, Brown, Erdős and Sós proved that if <img src="https://s0.wp.com/latex.php?latex=%5Ccal+H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\cal H" class="latex" title="\cal H" /> is a 3-uniform hypergraph on <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" title="n" /> vertices which contains no triangulation of the sphere, then <img src="https://s0.wp.com/latex.php?latex=%5Ccal+H&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\cal H" class="latex" title="\cal H" />  has at most <img src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B5%2F2%7D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="O(n^{5/2})" class="latex" title="O(n^{5/2})" /> edges, and this bound is the best possible up to a constant factor. Resolving a conjecture of Linial, also reiterated by Keevash, Long, Narayanan, and Scott, we show that the same result holds for triangulations of the torus. Furthermore, we extend our result to every closed orientable surface <img src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\cal S" class="latex" title="\cal S" />.</p> <p><span style="color: #0000ff;"><strong>Remarks:</strong> </span></p> <p><span style="color: #0000ff;">1) When <img src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\cal S" class="latex" title="\cal S" /> is fixed Nati proved that there is a simplicial complex with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" title="n" /> vertices and <img src="https://s0.wp.com/latex.php?latex=c+n%5E%7B5%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="c n^{5/2}" class="latex" title="c n^{5/2}" /> 2-faces that does not contain a triangulation of <img src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\cal S" class="latex" title="\cal S" />. </span></p> <p><span style="color: #0000ff;">2) It is not known if there is an example with <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" title="n" /> vertices and <img src="https://s0.wp.com/latex.php?latex=c+n%5E%7B5%2F2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="c n^{5/2}" class="latex" title="c n^{5/2}" /> 2-faces which does not contain a triangulation of any orientable closed surface <img src="https://s0.wp.com/latex.php?latex=%5Ccal+S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\cal S" class="latex" title="\cal S" />. </span></p> <p><span style="color: #0000ff;">We can ask the same question also for pseudomanifolds. What is the number of edges that guarantees a subcomplex with the property that every 1-face is included in precisely two 2-faces.</span></p> <p><span style="color: #0000ff;">3) Nati conjectured that for every 2-dimensional simplicial complex <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="S" class="latex" title="S" /> there is a constant <img src="https://s0.wp.com/latex.php?latex=C_S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="C_S" class="latex" title="C_S" /> such that a 2-dimensional simplicial complex with $n$ vertices and $C_Sn^{5/2}$ 2-faces always contains a homeomorph of <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="S" class="latex" title="S" />. The paper  by Andrey, Alexandr, István, and Dmitriy asserts that proving the exponent 5/2 for the real projective space will imply the same exponent for all nonorientable closed surfaces. </span></p> <p><span style="color: #0000ff;">4) The paper also mentions an unpublished result by Friedgut and Linial that <img src="https://s0.wp.com/latex.php?latex=n%5E%7B8%2F9%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n^{8/9}" class="latex" title="n^{8/9}" /> 2-faces suffice for a torus. <br /></span></p> <p><span style="color: #008000;">5) Here is another problem I am curious about: How many 2-faces guarantee a subcomplex K with <img src="https://s0.wp.com/latex.php?latex=H_2%28K%29+%5Cne+0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="H_2(K) \ne 0" class="latex" title="H_2(K) \ne 0" /> and <img src="https://s0.wp.com/latex.php?latex=H_1%28K%29%3D0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="H_1(K)=0" class="latex" title="H_1(K)=0" />?  (You can choose the field of coefficients.)  Without the second requirement the answer is roughly <img src="https://s0.wp.com/latex.php?latex=n%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n^2" class="latex" title="n^2" />. </span></p> <h2>Universal exponent for homeomorphs.</h2> <h3><strong>Nati’s Problem 2:</strong> Given a <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k" class="latex" title="k" />-dimensional-complex <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="S" class="latex" title="S" />, how many facets can a  <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k" class="latex" title="k" />-complex on <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n" class="latex" title="n" /> vertices have if it contains no topological copy of <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="S" class="latex" title="S" />? (Topological copy = homeomorphic image)</h3> <p>Jason Long, Bhargav Narayanan, and Corrine Yap:  <a href="https://arxiv.org/abs/2011.08167">Simplicial homeomorphs and trace-bounded hypergraphs </a></p><p></p>


<p><strong>Abstract:</strong> Our first main result is a uniform bound, in every dimension <img src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb+N&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k \in \mathbb N" class="latex" title="k \in \mathbb N" />, on the topological Turán numbers of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k" class="latex" title="k" />-dimensional simplicial complexes: for each <img src="https://s0.wp.com/latex.php?latex=k+%5Cin+%5Cmathbb+N&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k \in \mathbb N" class="latex" title="k \in \mathbb N" />, there is a <img src="https://s0.wp.com/latex.php?latex=%5Clambda_k+%5Cge+k%5E%7B-2k%5E2%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\lambda_k \ge k^{-2k^2}" class="latex" title="\lambda_k \ge k^{-2k^2}" /> such that for any <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k" class="latex" title="k" />-dimensional simplicial complex <img src="https://s0.wp.com/latex.php?latex=S&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="S" class="latex" title="S" />, every <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k" class="latex" title="k" />-complex on <img src="https://s0.wp.com/latex.php?latex=n+%5Cge+n_0%28S%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n \ge n_0(S)" class="latex" title="n \ge n_0(S)" /> vertices with at least <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bk%2B1-%5Clambda_k%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="n^{k+1-\lambda_k}" class="latex" title="n^{k+1-\lambda_k}" />  facets contains a homeomorphic copy of S.</p>
<p>This was previously known only in dimensions one and two, both by highly dimension-specific arguments: the existence of <img src="https://s0.wp.com/latex.php?latex=%5Clambda_1&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\lambda_1" class="latex" title="\lambda_1" /> is a result of Mader from 1967, and the existence of <img src="https://s0.wp.com/latex.php?latex=%5Clambda_2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\lambda_2" class="latex" title="\lambda_2" /> was suggested by Linial in 2006 and recently proved by Keevash-Long-Narayanan-Scott.</p>
<p>Jason Long, Bhargav Narayanan, and Corrine Yap deduce this theorem  from a very interesting purely combinatorial result about trace-bounded hypergraphs.</p>
<p>Here is the link to the aforementioned paper Peter Keevash, Jason Long, Bhargav Narayanan, and Alex Scott: <a href="https://arxiv.org/abs/2004.02657">A universal exponent for homeomorphs</a>. The main theorem asserts that <img src="https://s0.wp.com/latex.php?latex=%5Clambda_2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\lambda_2" class="latex" title="\lambda_2" /> can be taken to be <strong>14/5</strong>.</p>
<p>Let me also mention a 2018 result by  Agelos Georgakopoulos, John Haslegrave, Richard Montgomery, and Bhargav Narayanan  in their 2018 paper <a href="https://arxiv.org/abs/1808.06864">Spanning surfaces in 3-graphs</a> where they prove a topological extension of Dirac’s theorem about Hamiltonian cycles in graphs proposed by Gowers in 2005.</p>
<p><span style="color: #0000ff;">Finally, finding the correct value for <img src="https://s0.wp.com/latex.php?latex=%5Clambda_k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="\lambda_k" class="latex" title="\lambda_k" /> would be very interesting.</span></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/11/27/recent-progress-on-high-dimensional-turan-type-problems-by-andrey-kupavskii-alexandr-polyanskii-istvan-tomon-and-dmitriy-zakharov-and-by-jason-long-bhargav-narayanan-and-corrine-yap/"><span class="datestr">at November 27, 2020 12:12 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=522">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/11/27/tcs-talk-wednesday-december-2-yang-liu-stanford-university/">TCS+ talk: Wednesday, December 2 — Yang Liu, Stanford University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>We hope you are all doing well and, in the case of our US audience, are slowly emerging from a comfortable Thanksgiving food-induced stupor! Our last TCS+ talk of the semester will take place this coming Wednesday, December 2nd at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>Yang Liu</strong> from Stanford University will speak about “<em>Faster Algorithms for Unit Maximum Flow</em>” (abstract below). </p>



<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>



<p class="wp-block-quote">Abstract: The maximum flow problem is one of the most well-studied problems in combinatorial optimization, encompassing a broad range of cut, matching, and scheduling problems. Here we present a recent line of work obtaining provably faster algorithms for solving the maximum flow problem using interior point methods. In particular, we show how to solve the maximum flow problem in <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="m" class="latex" title="m" />-edge unit capacity graphs in time almost <img src="https://s0.wp.com/latex.php?latex=m%5E%7B4%2F3%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="m^{4/3}" class="latex" title="m^{4/3}" />, improving over the breakthrough <img src="https://s0.wp.com/latex.php?latex=m%5E%7B10%2F7%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="m^{10/7}" class="latex" title="m^{10/7}" /> time algorithm of Mądry.<br /><br />This is based on joint work with Aaron Sidford (<a href="https://arxiv.org/abs/1910.14276">arxiv.org/abs/1910.14276</a>, <a href="https://arxiv.org/abs/2003.08929">arxiv.org/abs/2003.08929</a>).</p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/11/27/tcs-talk-wednesday-december-2-yang-liu-stanford-university/"><span class="datestr">at November 27, 2020 09:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2020/11/27/reg_dl_not_norm/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2020/11/27/reg_dl_not_norm/">Can implicit regularization in deep learning be explained by norms?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>This post is based on my <a href="https://arxiv.org/pdf/2005.06398.pdf">recent paper</a> with <a href="https://noamrazin.github.io/">Noam Razin</a> (to appear at NeurIPS 2020), studying the question of whether norms can explain implicit regularization in deep learning.
TL;DR: we argue they cannot.</p>

<h2 id="implicit-regularization--norm-minimization">Implicit regularization = norm minimization?</h2>

<p>Understanding the implicit regularization induced by gradient-based optimization is possibly the biggest challenge facing theoretical deep learning these days.
In classical machine learning we typically regularize via norms, so it seems only natural to hope that in deep learning something similar is happening under the hood, i.e. the implicit regularization strives to find minimal norm solutions.
This is actually the case in the simple setting of overparameterized linear regression $-$ there, by a folklore analysis (cf. <a href="https://openreview.net/pdf?id=Sy8gdB9xx">Zhang et al. 2017</a>), gradient descent (and any other reasonable gradient-based optimizer) initialized at zero is known to converge to the minimal Euclidean norm solution.
A spur of recent works (see <a href="https://arxiv.org/pdf/2005.06398.pdf">our paper</a> for a thorough review) has shown that for various other models an analogous result holds, i.e. gradient descent (when initialized appropriately) converges to solutions that minimize a certain (model-dependent) norm.
On the other hand, as discussed last year in posts by <a href="http://www.offconvex.org/2019/06/03/trajectories/">Sanjeev</a> as well as <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">Wei and myself</a>, mounting theoretical and empirical evidence suggest that it may not be possible to generally describe implicit regularization in deep learning as minimization of norms.
Which is it then?</p>

<h2 id="a-standard-test-bed-matrix-factorization">A standard test-bed: matrix factorization</h2>

<p>A standard test-bed for theoretically studying implicit regularization in deep learning is <em>matrix factorization</em> $-$ matrix completion via linear neural networks.
Wei and I already presented this model in our <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">previous post</a>, but for self-containedness I will do so again here.</p>

<p>In <em>matrix completion</em>, we are given entries $\{ M_{i, j} : (i, j) \in \Omega \}$ of an unknown matrix $M$, and our job is to recover the remaining entries.
This can be seen as a supervised learning (regression) problem, where the training examples are the observed entries of $M$, the model is a matrix $W$ trained with the loss:
[
\qquad \ell(W) = \sum\nolimits_{(i, j) \in \Omega} (W_{i, j} - M_{i, j})^2 ~, \qquad\qquad \color{purple}{\text{(1)}}
]
and generalization corresponds to how similar $W$ is to $M$ in the unobserved locations.
In order for the problem to be well-posed, we have to assume something about $M$ (otherwise the unobserved locations can hold any values, and guaranteeing generalization is impossible).
The standard assumption (which has many <a href="https://en.wikipedia.org/wiki/Matrix_completion#Applications">practical applications</a>) is that $M$ has low rank, meaning the goal is to find, among all global minima of the loss $\ell(W)$, one with minimal rank.
The classic algorithm for achieving this is <a href="https://en.wikipedia.org/wiki/Matrix_norm#Schatten_norms"><em>nuclear norm</em></a> minimization $-$ a convex program which, given enough observed entries and under certain technical assumptions (“incoherence”), recovers $M$ exactly (cf. <a href="https://statweb.stanford.edu/~candes/papers/MatrixCompletion.pdf">Candes and Recht</a>).</p>

<p>Matrix factorization represents an alternative, deep learning approach to matrix completion.
The idea is to use a <em>linear neural network</em> (fully-connected neural network with linear activation), and optimize the resulting objective via gradient descent (GD).
More specifically, rather than working with the loss $\ell(W)$ directly, we choose a depth $L \in \mathbb{N}$, and run GD on the <em>overparameterized objective</em>:
[
\phi ( W_1 , W_2 , \ldots , W_L ) := \ell ( W_L W_{L - 1} \cdots W_1) ~. ~~\qquad~ \color{purple}{\text{(2)}}
]
Our solution to the matrix completion problem is then:
[
\qquad\qquad W_{L : 1} := W_L W_{L - 1} \cdots W_1 ~, \qquad\qquad\qquad \color{purple}{\text{(3)}}
] 
which we refer to as the <em>product matrix</em>.
While (for $L \geq 2$) it is possible to constrain the rank of $W_{L : 1}$ by limiting dimensions of the parameter matrices $\{ W_j \}_j$, from an implicit regularization standpoint, the case of interest is where rank is unconstrained (i.e. dimensions of $\{ W_j \}_j$ are large enough for $W_{L : 1}$ to take on any value).
In this case there is <em>no explicit regularization</em>, and the kind of solution GD will converge to is determined implicitly by the parameterization.
The degenerate case $L = 1$ is obviously uninteresting (nothing is learned in the unobserved locations), but what happens when depth is added ($L \geq 2$)?</p>

<p>In their <a href="https://papers.nips.cc/paper/2017/file/58191d2a914c6dae66371c9dcdc91b41-Paper.pdf">NeurIPS 2017 paper</a>, Gunasekar et al. showed empirically that with depth $L = 2$, if GD is run with small learning rate starting from near-zero initialization, then the implicit regularization in matrix factorization tends to produce low-rank solutions (yielding good generalization under the standard assumption of $M$ having low rank).
They conjectured that behind the scenes, what takes place is the classic nuclear norm minimization algorithm:</p>

<blockquote>
  <p><strong>Conjecture 1 (<a href="https://papers.nips.cc/paper/7195-implicit-regularization-in-matrix-factorization.pdf">Gunasekar et al. 2017</a>; informally stated):</strong>
GD (with small learning rate and near-zero initialization) over a depth $L = 2$ matrix factorization finds solution with minimum nuclear norm.</p>
</blockquote>

<p>Moreover, they were able to prove the conjecture in a certain restricted setting, and others (e.g. <a href="http://proceedings.mlr.press/v75/li18a/li18a.pdf">Li et al. 2018</a>) later derived proofs for additional specific cases.</p>

<p>Two years after Conjecture 1 was made, in a <a href="https://papers.nips.cc/paper/2019/file/c0c783b5fc0d7d808f1d14a6e9c8280d-Paper.pdf">NeurIPS 2019 paper</a> with Sanjeev, Wei and Yuping Luo, we presented empirical and theoretical evidence (see <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">previous blog post</a> for details) which led us to hypothesize the opposite, namely, that for any depth $L \geq 2$, the implicit regularization in matrix factorization can <em>not</em> be described as minimization of a norm:</p>

<blockquote>
  <p><strong>Conjecture 2 (<a href="https://papers.nips.cc/paper/2019/file/c0c783b5fc0d7d808f1d14a6e9c8280d-Paper.pdf">Arora et al. 2019</a>; informally stated):</strong>
Given a depth $L \geq 2$ matrix factorization, for any norm $\|{\cdot}\|$, there exist matrix completion tasks on which GD (with small learning rate and near-zero initialization) finds solution that does not minimize $\|{\cdot}\|$.</p>
</blockquote>

<p>Due to technical subtleties in their formal statements, Conjectures 1 and 2 do not necessarily contradict.
However, they represent opposite views on the question of whether or not norms can explain implicit regularization in matrix factorization.
The goal of my recent work with <a href="https://noamrazin.github.io/">Noam</a> was to resolve this open question.</p>

<h2 id="implicit-regularization-can-drive-all-norms-to-infinity">Implicit regularization can drive all norms to infinity</h2>

<p>The main result in our <a href="https://arxiv.org/pdf/2005.06398.pdf">paper</a> is a proof that there exist simple matrix completion settings where the implicit regularization in matrix factorization drives <strong><em>all norms towards infinity</em></strong>.
By this we affirm Conjecture 2, and in fact go beyond it in the following sense:
<em>(i)</em> not only is each norm disqualified by some setting, but there are actually settings that jointly disqualify all norms;
and
<em>(ii)</em> not only are norms not necessarily minimized, but they can grow towards infinity.</p>

<p>The idea behind our analysis is remarkably simple.
We prove the following:</p>

<blockquote>
  <p><strong>Theorem (informally stated):</strong>
During GD over matrix factorization (i.e. over $\phi ( W_1 , W_2 , \ldots , W_L)$ defined by Equations $\color{purple}{\text(1)}$ and $\color{purple}{\text(2)}$), if learning rate is sufficiently small and initialization sufficiently close to the origin, then the determinant of the product matrix $W_{1: L}$ (Equation $\color{purple}{\text(3)}$) doesn’t change sign.</p>
</blockquote>

<p>A corollary is that if $\det ( W_{L : 1} )$ is positive at initialization (an event whose probability is $0.5$ under any reasonable initialization scheme), then it stays that way throughout.
This seemingly benign observation has far-reaching implications.
As a simple example, consider the following matrix completion problem ($*$ here stands for unobserved entry):
[
\qquad\qquad
\begin{pmatrix}
* &amp; 1 \newline
1 &amp; 0 
\end{pmatrix}
~. \qquad\qquad \color{purple}{\text{(4)}}
]
Every solution to this problem, i.e. every matrix that agrees with its observations, must have determinant $-1$.
It is therefore only logical to expect that when solving the problem using matrix factorization, the determinant of the product matrix $W_{L : 1}$ will converge to $-1$.
On the other hand, we know that (with probability $0.5$ over initialization) $\det ( W_{L : 1} )$ is always positive, so what is going on?
This conundrum can only mean one thing $-$ as $W_{L : 1}$ fits the observations, its value in the unobserved location (i.e. $(W_{L : 1})_{11}$) diverges to infinity, which implies that <em>all norms grow to infinity!</em></p>

<p>The above idea goes way beyond the simple example given in Equation $\color{purple}{\text(4)}$.
We use it to prove that in a wide array of matrix completion settings, the implicit regularization in matrix factorization leads norms to <em>increase</em>.
We also demonstrate it empirically, showing that in such settings unobserved entries grow during optimization.
Here’s the result of an experiment with the setting of Equation $\color{purple}{\text(4)}$:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/reg_dl_not_norm_mf_exp.png" style="width: 300px;" />
<br />
<i><b>Figure 1:</b> 
Solving matrix completion problem defined by Equation $\color{purple}{\text(4)}$ using matrix factorization leads absolute value of unobserved entry to increase (which in turn means norms increase) as loss decreases.
</i>
</div>

<h2 id="what-is-happening-then">What is happening then?</h2>

<p>If the implicit regularization in matrix factorization is not minimizing a norm, what is it doing?
While a complete theoretical characterization is still lacking, there are signs that a potentially useful interpretation is <strong><em>minimization of rank</em></strong>.
In our aforementioned <a href="https://papers.nips.cc/paper/2019/file/c0c783b5fc0d7d808f1d14a6e9c8280d-Paper.pdf">NeurIPS 2019 paper</a>, we derived a dynamical characterization (and showed supporting experiments) suggesting that matrix factorization is implicitly conducting some kind of greedy low-rank search (see <a href="http://www.offconvex.org/2019/07/10/trajectories-linear-nets/">previous blog post</a> for details).
This phenomenon actually facilitated a new autoencoding architecture suggested in a recent <a href="https://arxiv.org/pdf/2010.00679.pdf">empirical paper</a> (to appear at NeurIPS 2020) by Yann LeCun and his team at Facebook AI.
Going back to the example in Equation $\color{purple}{\text(4)}$, notice that in this matrix completion problem all solutions have rank $2$, but it is possible to essentially minimize rank to $1$ by taking (absolute value of) unobserved entry to infinity.
As we’ve seen, this is exactly what the implicit regularization in matrix factorization does!</p>

<p>Intrigued by the rank minimization viewpoint, <a href="https://noamrazin.github.io/">Noam</a> and I empirically explored an extension of matrix factorization to <em>tensor factorization</em>.
Tensors can be thought of as high dimensional arrays, and they admit natural factorizations similarly to matrices (two dimensional arrays).
We found that on the task of <em>tensor completion</em> (defined analogously to matrix completion $-$ see Equation $\color{purple}{\text(1)}$ and surrounding text), GD on a tensor factorization tends to produce solutions with low rank, where rank is defined in the context of tensors (for a formal definition, and a general intro to tensors and their factorizations, see this <a href="http://www.kolda.net/publication/TensorReview.pdf">excellent survey</a> by Kolda and Bader).
That is, just like in matrix factorization, the implicit regularization in tensor factorization also strives to minimize rank!
Here’s a representative result from one of our experiments:</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/reg_dl_not_norm_tf_exp.png" style="width: 700px;" />
<br />
<i><b>Figure 2:</b> 
In analogy with matrix factorization, the implicit regularization of tensor factorization (high dimensional extension) strives to find a low (tensor) rank solution.
Plots show reconstruction error and (tensor) rank of final solution on multiple tensor completion problems differing in the number of observations.
GD over tensor factorization is compared against "linear" method $-$ GD over direct parameterization of tensor initialized at zero (this is equivalent to fitting observations while placing zeros in unobserved locations).
</i>
<br />
<br />
</div>

<p>So what can tensor factorizations tell us about deep learning?
It turns out that, similarly to how matrix factorizations correspond to prediction of matrix entries via linear neural networks, tensor factorizations can be seen as prediction of tensor entries with a certain type of <em>non-linear</em> neural networks, named <em>convolutional arithmetic circuits</em> (in my PhD I worked a lot on analyzing the expressive power of these models, as well as showing that they work well in practice $-$ see this <a href="https://arxiv.org/pdf/1705.02302.pdf">survey</a> for a soft overview).</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/reg_dl_not_norm_mf_lnn_tf_cac.png" style="width: 900px;" />
<br />
<i><b>Figure 3:</b> 
The equivalence between matrix factorizations and linear neural networks extends to an equivalence between tensor factorizations and a certain type of non-linear neural networks named convolutional arithmetic circuits.
</i>
<br />
<br />
</div>

<p>Analogously to how the input-output mapping of a linear neural network can be thought of as a matrix, that of a convolutional
arithmetic circuit is naturally represented by a tensor.
The experiment reported in Figure 2 (and similar ones presented in <a href="https://arxiv.org/pdf/2005.06398.pdf">our paper</a>) thus provides a second example of a neural network architecture whose implicit regularization strives to lower a notion of rank for its input-output mapping.
This leads us to believe that implicit rank minimization may be a general phenomenon, and developing notions of rank for input-output mappings of contemporary models may be key to explaining generalization in deep learning.</p>

<p><a href="http://www.cohennadav.com/">Nadav Cohen</a></p></div>







<p class="date">
<a href="http://offconvex.github.io/2020/11/27/reg_dl_not_norm/"><span class="datestr">at November 27, 2020 09:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-267315146714574732">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2020/11/tcs-connections-questionnaire.html">TCS Connections Questionnaire</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I wanted to link to a survey that is up entitled <a href="https://docs.google.com/forms/d/e/1FAIpQLSeubLuaICwNvHfHto7nBDw_gwkrqKdo-_Fjyz7XZONJ0tJRoA/viewform" target="_blank" rel="nofollow">Committee on TCS Connections Questionnaire</a>.  They are examining modifying approaches to publishing in the theoretical computer science community, and they are focusing on FOCS/STOC.</p><p>I personally approve of the idea of the committee, though I admit I am concerned that it's too little, too late.  For years, FOCS/STOC has been a culture concerned with some sense of "prestige" -- the number of accepted papers has to be kept low, because we want people outside of theory to take FOCS/STOC as an imprimatur for the top theory work.  Because of this, FOCS/STOC has stayed essentially the same size, while the field (whether you view the field as TCS or computer science writ large) has expanded.  This has led to a proliferation of additional conferences (ITCS, HALG, various theory workshops...) that reduce the importance of FOCS/STOC and their role in creating community cohesion.  It has also led to other areas (most notably AI) becoming the home to work that should be quite at home in major TCS conferences.  </p><p>I don't think FOCS/STOC is what is used to be (the central home for theory results, when theory was smaller) or what it has supposedly wanted to be (the home for the best theory results).  I think it makes a lot of sense to stop and think about what they should be for the future.  Hence the survey is important, and I encourage the theoretical computer science community to respond.  I'm not sure, though, that there are great answers -- external forces, and the community's general aversion to change, may mean that there is not much to be done.  </p></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2020/11/tcs-connections-questionnaire.html"><span class="datestr">at November 26, 2020 03:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/176">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/176">TR20-176 |  Outcome Indistinguishability | 

	Cynthia Dwork, 

	Michael Kim, 

	Omer Reingold, 

	Guy Rothblum, 

	Gal Yona</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Prediction algorithms assign numbers to individuals that are popularly understood as individual ``probabilities''---what is the probability of 5-year survival after cancer diagnosis?---and which increasingly form the basis for life-altering decisions. Drawing on an understanding of computational indistinguishability developed in complexity theory and cryptography, we introduce Outcome Indistinguishability. Predictors that are Outcome Indistinguishable yield a generative model for outcomes that cannot be efficiently refuted on the basis of the real-life observations produced by Nature.

We investigate a hierarchy of Outcome Indistinguishability definitions, whose stringency increases with the degree to which distinguishers may access the predictor in question. Our findings reveal that Outcome Indistinguishability behaves qualitatively differently than previously studied notions of indistinguishability. First, we provide constructions at all levels of the hierarchy. Then, leveraging recently-developed machinery for proving average-case fine-grained hardness, we obtain lower bounds on the complexity of the more stringent forms of Outcome Indistinguishability. This hardness result provides the first scientific grounds for the political argument that, when inspecting algorithmic risk prediction instruments, auditors should be granted oracle access to the algorithm, not simply historical predictions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/176"><span class="datestr">at November 26, 2020 04:54 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5114">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5114">Happy Thanksgiving Y’All!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>While a lot of pain is still ahead, this year I’m thankful that a dark chapter in American history might be finally drawing to a close.  I’m thankful that the mRNA vaccines actually work.  I’m thankful that my family has remained safe, and I’m thankful for all the essential workers who’ve kept our civilization running.</p>



<p>A few things:</p>



<ol><li>Friend-of-the-blog <a href="https://people.eecs.berkeley.edu/~minilek/">Jelani Nelson</a> asked me to advertise an important <a href="https://docs.google.com/forms/d/e/1FAIpQLSeubLuaICwNvHfHto7nBDw_gwkrqKdo-_Fjyz7XZONJ0tJRoA/viewform">questionnaire for theoretical computer scientists</a>, about what the future of STOC and FOCS should look like (for example, should they become all virtual?).  It only takes 2 or 3 minutes to fill out (I just did).<br /></li><li>Here’s a <a href="https://www.youtube.com/watch?v=Uy5fvwdw8x4">podcast</a> that I recently did with UT Austin undergraduate Dwarkesh Patel.  (As usual, I recommend 2x speed to compensate for my verbal tics.)<br /></li><li>Feel free to use the comments on this post to talk about recent progress in quantum computing or computational complexity!  Like, I dunno, a <a href="http://arxiv.org/pdf/2011.09495.pdf">(sub)exponential black-box speedup for the adiabatic algorithm</a>, or <a href="http://arxiv.org/pdf/2011.12277.pdf">anti-concentration for log-depth random quantum circuits</a>, or an <a href="https://arxiv.org/pdf/2011.10908.pdf">improved shadow tomography procedure</a>, or a <a href="https://arxiv.org/pdf/2011.03185.pdf">quantum algorithm for nonlinear differential equations</a>, or a <a href="https://arxiv.org/abs/2011.09093">barrier to proving strong 3-party parallel repetition</a>, or <a href="https://arxiv.org/pdf/2009.11514.pdf">equivalence of one-way functions and time-bounded Kolmogorov complexity</a>, or <a href="https://arxiv.org/abs/1906.10837">turning any hard-on-average NP problem into one that’s guaranteed to have solutions</a>.<br /></li><li>It’s funny how quantum computing, P vs. NP, and so forth can come to feel like just an utterly mundane day job, not something anyone outside a small circle could possibly want to talk about while the fate of civilization hangs in the balance.  Sometimes it takes my readers to remind me that not only are these topics what brought most of you here in the first place, they’re also awesome!  So, I’ll mark that down as one more thing to be thankful for.</li></ol>



<p></p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5114"><span class="datestr">at November 26, 2020 02:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
