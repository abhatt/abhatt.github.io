<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at April 15, 2020 10:21 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/046">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/046">TR20-046 |  A Robust Version of Heged\H{u}s&amp;#39;s Lemma, with Applications | 

	Srikanth Srinivasan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Heged\H{u}s's lemma is the following combinatorial statement regarding polynomials over finite fields. Over a field $\mathbb{F}$ of characteristic $p &gt; 0$ and for $q$ a  power of $p$, the lemma says that any multilinear polynomial $P\in \mathbb{F}[x_1,\ldots,x_n]$ of degree less than $q$ that vanishes at all points in $\{0,1\}^n$ of Hamming weight $k\in [q,n-q]$ must also vanish at all points in $\{0,1\}^n$ of weight $k + q$. This lemma was used by Heged\H{u}s (2009) to give a solution to \emph{Galvin's problem}, an extremal problem about set systems; by Alon, Kumar and Volk (2018) to improve the best-known multilinear circuit lower bounds; and by Hrube\v{s}, Ramamoorthy, Rao and Yehudayoff (2019) to prove optimal lower bounds against depth-$2$ threshold circuits for computing some symmetric functions. 
		
		In this paper, we formulate a robust version of Heged\H{u}s's lemma. Informally, this version says that if a polynomial of degree $o(q)$ vanishes at most points of weight $k$, then it vanishes at many points of weight $k+q$. We prove this lemma and give the following three different applications.
		
		1. Degree lower bounds for the coin problem: The \emph{$\delta$-Coin Problem} is the problem of distinguishing between a coin that is heads with probability $((1/2) + \delta)$ and a coin that is heads with probability $1/2$. We show that over a field of positive (fixed) characteristic, any polynomial that solves the $\delta$-coin problem with error $\varepsilon$ must have degree $\Omega(\frac{1}{\delta}\log(1/\varepsilon)),$ which is tight up to constant factors.
		
		2. Probabilistic degree lower bounds: The \emph{Probabilistic degree} of a Boolean function is the minimum $d$ such that there is a random polynomial of degree $d$ that agrees with the function at each point with high probability. We give tight lower bounds on the probabilistic degree of \emph{every} symmetric Boolean function over positive (fixed) characteristic. As far as we know, this was not known even for some very simple functions such as unweighted Exact Threshold functions, and constant error.
		
		3. A robust version of the combinatorial result of Heged\H{u}s (2009) mentioned above.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/046"><span class="datestr">at April 15, 2020 04:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/045">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/045">TR20-045 |  Learning sums of powers of low-degree polynomials in the non-degenerate case | 

	Ankit Garg, 

	Neeraj Kayal, 

	Chandan Saha</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We develop algorithms for writing a polynomial as sums of powers of low degree polynomials. Consider an $n$-variate degree-$d$ polynomial $f$ which can be written as
$$f = c_1Q_1^{m} + \ldots + c_s Q_s^{m},$$
where each $c_i\in \mathbb{F}^{\times}$, $Q_i$ is a homogeneous polynomial of degree $t$, and $t m = d$. In this paper, we give a $\text{poly}((ns)^t)$-time learning algorithm for finding the $Q_i$'s given (black-box access to) $f$, if the $Q_i's$ satisfy certain non-degeneracy conditions and $n$ is larger than $d^2$. The set of degenerate $Q_i$'s (i.e., inputs for which the algorithm does not work) form a non-trivial variety and hence if the $Q_i$'s are chosen according to any reasonable (full-dimensional) distribution, then they are non-degenerate with high probability (if $s$ is not too large). This problem generalizes symmetric tensor decomposition, which corresponds to the $t = 1$ case and is widely studied, having many applications in machine learning. Our algorithm (for $t=2$) allows us to solve the moment problem for mixtures of zero-mean Gaussians in the non-degenerate case.

Our algorithm is based on a scheme for obtaining a learning algorithm for an arithmetic circuit model from a lower bound for the same model, provided certain non-degeneracy conditions hold. The scheme reduces the learning problem to the problem of decomposing two vector spaces under the action of a set of linear operators, where the spaces and the operators are derived from the input circuit and the complexity measure used in a typical lower bound proof. The non-degeneracy conditions are certain restrictions on how the spaces decompose. Such a scheme is present in a rudimentary form in an earlier work of Kayal and Saha. Here, we make it more general and detailed, and potentially applicable to learning other circuit models.

An exponential lower bound for the representation above (also known as homogeneous $\Sigma \wedge \Sigma \Pi^{[t]}$ circuits) is known using the shifted partials measure. However, the number of linear operators in shifted partials is exponential and also the non-degeneracy condition emerging out of this measure is unlikely to be satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit when the number of variables is large with respect to the degree. We bypass this hurdle by proving a lower bound (which is nearly as strong as the previous bound) using a novel variant of the partial derivatives measure, namely affine projections of partials (APP). The non-degeneracy conditions appearing from this new measure are satisfied by a random $\Sigma \wedge \Sigma \Pi^{[t]}$ circuit. The APP measure could be of independent interest for proving other lower bounds.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/045"><span class="datestr">at April 15, 2020 07:50 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16931">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/">John Horton Conway 1937–2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>An appreciation</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg"><img src="https://rjlipton.files.wordpress.com/2020/04/johnhortonconway1987.jpg?w=192&amp;h=240" alt="" width="192" class="alignright wp-image-16933" height="240" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Names for large numbers <a href="https://sites.google.com/site/largenumbers/home/2-4/6">source</a></font></td>
</tr>
</tbody>
</table>
<p>
John Horton Conway just passed away from complications of COVID-19. We are all saddened by this news, and we hope you all are doing your best to stay safe and help others cope.</p>
<p>
Today Ken and I thought we would reflect on some of Conway’s many contributions and emphasize three in which we see connections to computational complexity. </p>
<p>
Conway was a Fellow of the Royal Society, and was the first recipient of the London Mathematical Society’s Pólya Prize. His nomination to the Royal Society reads:</p>
<blockquote><p><b> </b> <em> A versatile mathematician who combines a deep combinatorial insight with algebraic virtuosity, particularly in the construction and manipulation of “off-beat” algebraic structures which illuminate a wide variety of problems in completely unexpected ways. He has made distinguished contributions to the theory of finite groups, to the theory of knots, to mathematical logic (both set theory and automata theory) and to the theory of games (as also to its practice). </em>
</p></blockquote>
<p>
</p><p></p><h2> A Life Force </h2><p></p>
<p></p><p>
Conway may be most noted for his game of <a href="https://en.wikipedia.org/wiki/Conway%27s_Game_of_Life">Life</a>. This is a two-dimensional cellular automaton. Conway invented it in 1970, which he rounded up from 1969. The game—and Martin Gardner’s 1970 column on it in <em>Scientific American</em>—made him famous in the wider community. The website <a href="https://www.conwaylife.com/">conwaylife.com</a> and <a href="https://catagolue.appspot.com/home">several</a> <a href="https://tebs-game-of-life.com/">others</a> link to more information than we could digest in a lifetime.</p>
<p>
We want to emphasize instead how Conway was a special force in mathematics. He applied an almost elementary approach to deep hard problems of mathematics. This is a unique combination. There have been mathematicians who worked on deep problems and also on recreational math, but few who established integral flows across the boundary between them. Conway infused both with magic in a way conveyed by an iconic photograph of his Princeton office in 1993:</p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg"><img src="https://rjlipton.files.wordpress.com/2020/04/conwayoffice.jpg?w=450&amp;h=270" alt="" width="450" class="aligncenter wp-image-16934" height="270" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2"><i>Guardian<i> via Dith Pran, <i>NY Times</i> <a href="https://www.theguardian.com/science/2015/jul/23/john-horton-conway-the-most-charismatic-mathematician-in-the-world">source</a> </i></i></font>
</td>
</tr>
</tbody></table>
<p>
What Ken remembers is how accessible Conway was <em>outside</em> his office. “I know I met him at least once while I was an undergraduate at Princeton in 1979 or 1980, though this is overlaid by a memory of finding just him and a few others in the Fine Hall tea room when I was there for my tenth reunion in 1991. My most evocative memory is when Conway gave an evening talk to the undergraduate mathematics club at Oxford when I was there sometime after 1981. It was relatively sparsely attended, perhaps because it was literally a dark and stormy winter night. But after his lecture we all got to huddle around him for another hour in the tea room as he regaled us with stories and mathematical problems.” </p>
<p>
We also remember that Conway was one of Andrew Wiles’s main confidants during the months before Wiles announced his proof of Fermat’s Last Theorem in June 1993. Here is a <a href="https://www.pbs.org/wgbh/nova/transcripts/2414proof.html">transcript</a> of a PBS Nova documentary on the proof in which Conway appears prominently. Ken has picked out two of Conway’s other contributions that we feel may have untapped use for research in complexity theory.</p>
<p>
</p><p></p><h2> Conway’s Numbers </h2><p></p>
<p></p><p>
One of this blog’s “invariants” is first-name last-name style, thus “Godfrey Hardy” not “G.H. Hardy.” But we make an exception in Conway’s case. Partly this owes to how his initials were amplified by Donald Knuth in his novella <em>Surreal Numbers</em>:</p>
<blockquote><p><b> </b> <em> In the beginning, everything was void, and J.H.W.H. Conway began to create numbers. </em>
</p></blockquote>
<p></p><p>
Besides the void (that is, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset}" class="latex" title="{\emptyset}" />), the creation uses the idea of a <em>left set</em> <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and a <em>right set</em> <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. Every number has the form <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L~|~R \rangle}" class="latex" title="{\langle L~|~R \rangle}" />. The initial number is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clangle+%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. " class="latex" title="\displaystyle  \langle \emptyset ~|~ \emptyset\rangle = 0. " /></p>
<p>
Once a number is generated, it can be in the <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> or <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> of other numbers. Thus, next come </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Clangle+0+%7E%7C%7E+%5Cemptyset+%5Crangle+%26%3D%26+1%5C%5C+%5Clangle+%5Cemptyset+%7E%7C%7E+0+%5Crangle+%26%3D%26+-1.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  \langle 0 ~|~ \emptyset \rangle &amp;=&amp; 1\\ \langle \emptyset ~|~ 0 \rangle &amp;=&amp; -1. \end{array} " /></p>
<p>
You might think of <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle 0 ~|~ 0 \rangle}" class="latex" title="{\langle 0 ~|~ 0 \rangle}" /> next, but it violates the invariant </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cforall+%5Cell+%5Cin+L%29%28%5Cforall+r+%5Cin+R%29%5Cneg+%28r+%5Cleq+%5Cell%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). " class="latex" title="\displaystyle  (\forall \ell \in L)(\forall r \in R)\neg (r \leq \ell). " /></p>
<p>which defines an <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L%7E%7C%7ER+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L~|~R \rangle}" class="latex" title="{\langle L~|~R \rangle}" /> <em>form</em> to be a <em>number</em>. </p>
<p>
The relation <img src="https://s0.wp.com/latex.php?latex=%7B%5Cleq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\leq}" class="latex" title="{\leq}" /> is inductively defined for <img src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+%5Clangle+L_a+%7E%7C%7E+R_a+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a = \langle L_a ~|~ R_a \rangle}" class="latex" title="{a = \langle L_a ~|~ R_a \rangle}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb+%3D+%5Clangle+L_b+%7E%7C%7E+R_b+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b = \langle L_b ~|~ R_b \rangle}" class="latex" title="{b = \langle L_b ~|~ R_b \rangle}" /> by </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Cleq+b+%5Cquad%5Cequiv%5Cquad+%28%5Cforall+%5Cell_a+%5Cin+L_a%29%28%5Cforall+r_b+%5Cin+R_b%29%5Cneg%28b+%5Cleq+%5Cell_a+%5C%3B%5Clor%5C%3B+r_b+%5Cleq+a%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). " class="latex" title="\displaystyle  a \leq b \quad\equiv\quad (\forall \ell_a \in L_a)(\forall r_b \in R_b)\neg(b \leq \ell_a \;\lor\; r_b \leq a). " /></p>
<p>
That is, no member of the left-set of <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> “bumps” <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> (in the sense of rowing races) and <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> does not bump any member of the right-set of <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" />.  Note that <img src="https://s0.wp.com/latex.php?latex=%7BR_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R_a}" class="latex" title="{R_a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BL_b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_b}" class="latex" title="{L_b}" /> are not involved—they already behave correctly owing to the invariant. The numbers <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a,b}" class="latex" title="{a,b}" /> are equal if <img src="https://s0.wp.com/latex.php?latex=%7Ba+%5Cleq+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a \leq b}" class="latex" title="{a \leq b}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb+%5Cleq+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b \leq a}" class="latex" title="{b \leq a}" /> both hold. The rule for addition is </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%2B+b+%3D+%5Clangle+%28L_a+%5Cboxplus+b%29+%5Ccup+%28a+%5Cboxplus+L_b%29+%7E%7C%7E+%28a+%5Cboxplus+R_b%29+%5Ccup+%28R_a+%5Cboxplus+b%29+%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, " class="latex" title="\displaystyle  a + b = \langle (L_a \boxplus b) \cup (a \boxplus L_b) ~|~ (a \boxplus R_b) \cup (R_a \boxplus b) \rangle, " /></p>
<p>
where <img src="https://s0.wp.com/latex.php?latex=%7BL_a+%5Cboxplus+b+%3D+%5C%7B%5Cell_a+%2B+b%3A+%5Cell_a+%5Cin+L_a%5C%7D+%3D+b+%5Cboxplus+L_a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}" class="latex" title="{L_a \boxplus b = \{\ell_a + b: \ell_a \in L_a\} = b \boxplus L_a}" /> and so on. The logical rule <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset+%5Cboxplus+a+%3D+%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset \boxplus a = \emptyset}" class="latex" title="{\emptyset \boxplus a = \emptyset}" /> for any <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> makes the definition of addition well-founded. This yields the numerical fact </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0+%2B+0+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%7E%7C%7E+%28%5Cemptyset+%5Cboxplus+0%29+%5Ccup+%280+%5Cboxplus+%5Cemptyset%29+%5Crangle+%3D+%5Clangle%5Cemptyset+%7E%7C%7E+%5Cemptyset%5Crangle+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. " class="latex" title="\displaystyle  0 + 0 = \langle (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) ~|~ (\emptyset \boxplus 0) \cup (0 \boxplus \emptyset) \rangle = \langle\emptyset ~|~ \emptyset\rangle = 0. " /></p>
<p>
It is immediate that <img src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+}" class="latex" title="{+}" /> is commutative. There is also a rule for multiplication but addition gives us enough to talk about here.</p>
<p>
</p><p></p><h2> Redundancy and Simplicity </h2><p></p>
<p></p><p>
It is straightforward to compute that <img src="https://s0.wp.com/latex.php?latex=%7B0+%2B+1+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 + 1 = 1}" class="latex" title="{0 + 1 = 1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B-1+%2B+0+%3D+-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1 + 0 = -1}" class="latex" title="{-1 + 0 = -1}" />. Now consider: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++-1+%2B+1+%3D+%5Clangle+%28%5Cemptyset+%5Cboxplus+1%29+%5Ccup+%28-1+%5Cboxplus+%5C%7B0%5C%7D%29+%7E%7C%7E+%28-1+%5Cboxplus+%5Cemptyset+%29+%5Ccup+%28%5C%7B0%5C%7D+%5Cboxplus+1%29%5Crangle+%3D+%5Clangle+-1+%7E%7C%7E+1%5Crangle.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. " class="latex" title="\displaystyle  -1 + 1 = \langle (\emptyset \boxplus 1) \cup (-1 \boxplus \{0\}) ~|~ (-1 \boxplus \emptyset ) \cup (\{0\} \boxplus 1)\rangle = \langle -1 ~|~ 1\rangle. " /></p>
<p>This is a legal number. You can check that the relations <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle -1 ~|~ 1\rangle \leq 0}" class="latex" title="{\langle -1 ~|~ 1\rangle \leq 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 \leq \langle -1 ~|~ 1\rangle}" class="latex" title="{0 \leq \langle -1 ~|~ 1\rangle}" /> both hold. Thus—as a number rather than a “form”—the number <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+-1+%7E%7C%7E+1%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle -1 ~|~ 1\rangle}" class="latex" title="{\langle -1 ~|~ 1\rangle}" /> equals <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />. </p>
<p>
That seems to make sense since <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> is the average of <img src="https://s0.wp.com/latex.php?latex=%7B-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{-1}" class="latex" title="{-1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, but now compute <img src="https://s0.wp.com/latex.php?latex=%7B2+%3D+1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2 = 1 + 1}" class="latex" title="{2 = 1 + 1}" /> as a formal Conway number and consider <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3D+%5Clangle+-1+%7E%7C%7E+2%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c = \langle -1 ~|~ 2\rangle}" class="latex" title="{c = \langle -1 ~|~ 2\rangle}" />. This also satisfies the relations <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cleq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c \leq 0}" class="latex" title="{c \leq 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 \leq c}" class="latex" title="{0 \leq c}" />, so <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> must likewise equal <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />. Thus <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L ~|~ R \rangle}" class="latex" title="{\langle L ~|~ R \rangle}" /> is not some kind of numerical interpolation between <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. The interpretation that grabbed my imagination as a teenager in 1976 is that:</p>
<blockquote><p><b> </b> <em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\langle L ~|~ R \rangle}" class="latex" title="{\langle L ~|~ R \rangle}" /> equals the <b>simplest</b> number that is between <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" />. </em>
</p></blockquote>
<p></p><p>
This is especially evocative in cases like <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+1+%7E%7C%7E+%5Cemptyset+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle 1 ~|~ \emptyset \rangle}" class="latex" title="{\langle 1 ~|~ \emptyset \rangle}" />, which is what one gets by computing <img src="https://s0.wp.com/latex.php?latex=%7B1+%2B+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 + 1}" class="latex" title="{1 + 1}" />. In general, <img src="https://s0.wp.com/latex.php?latex=%7Bm%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m+1}" class="latex" title="{m+1}" /> is the simplest number between <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset}" class="latex" title="{\emptyset}" />. Conway made this a theorem by giving each number a set-theoretic ordinal for its “time of generation” and proved that <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+L+%7E%7C%7E+R+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle L ~|~ R \rangle}" class="latex" title="{\langle L ~|~ R \rangle}" /> always equals a (the) least-ordinal number <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cleq+c+%5Cleq+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell \leq c \leq r}" class="latex" title="{\ell \leq c \leq r}" /> for every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%5Cin+L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell \in L}" class="latex" title="{\ell \in L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \in R}" class="latex" title="{r \in R}" />. </p>
<p>
Conway’s rules allow <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BR%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R}" class="latex" title="{R}" /> to be infinite sets—any sets of numbers built by the rules of set theory. Then not only do all real numbers emerge at ordinal times, so do infinitesimals and further richness of structure. We should remember that Conway began as a set theorist with a dissertation under Harold Davenport titled <em>Homogeneous ordered sets</em>. All Conway numbers with finite creation times are dyadic rational numbers, which may seem trivial from the standpoint of set theory, but those are akin to binary strings. </p>
<p>
What became magic was how Conway’s rules characterize <em>games</em>. Through games we can also interpret forms like <img src="https://s0.wp.com/latex.php?latex=%7B%5Clangle+0+%7E%7C%7E+0+%5Crangle%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\langle 0 ~|~ 0 \rangle}" class="latex" title="{\langle 0 ~|~ 0 \rangle}" /> that are not numbers. I did not know about complexity when I purchased Conway’s <a href="https://en.wikipedia.org/wiki/On_Numbers_and_Games">book</a> <em>On Numbers and Games</em> around 1980, let alone the connections between games and complexity. The book has a lot of depth that might be useful to complexity theory. To quote Peter Sarnak, per this <a href="https://www.ias.edu/ideas/2015/roberts-john-horton-conway">article</a> by Conway’s biographer Siobhan Roberts on Conway’s meeting with Kurt Gödel:</p>
<blockquote><p><b> </b> <em> The surreal numbers will be applied. It’s just a question of how and when. </em>
</p></blockquote>
<p>
</p><p>
</p><p>
</p><p></p><h2> Modular Programming </h2><p></p>
<p></p><p>
Most of us know that the conditional-jump instruction</p>
<p>
<font size="+1"><tt><b><br />
if (x == 0) goto k<br />
</b></tt></font></p>
<p></p><p><br />
where <tt><b>k</b></tt> is the label of another instruction, creates a universal programming language when added to the usual programming primitives of assignment, sequencing, and simple arithmetic. Conway was a maven of the “modular-jump”:</p>
<p>
<font size="+1"><tt><b><br />
if (x == 0 mod m) goto k.<br />
</b></tt></font></p>
<p></p><p><br />
In complexity theory we know that mod-<img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> gates having 0-1 inputs define the idea of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}}" class="latex" title="{\mathsf{ACC}}" /> circuits, with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}^0}" class="latex" title="{\mathsf{ACC}^0}" /> denoting problems solved by families of these circuits having fixed depth and polynomial size. If we don’t insist on fixed depth and unary inputs, we get modular programs. They are more complex than <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}^0}" class="latex" title="{\mathsf{ACC}^0}" /> circuits, but we can learn from what can be done <em>concretely</em> with them.</p>
<p>
Conway created a particular form of modular programs in a language he called <a href="https://link.springer.com/chapter/10.1007/978-1-4612-4808-8_2">FRACTRAN</a>. A program is just a list of positive fractions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Ba_r%7D%7Bb_r%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{a_r}{b_r}}" class="latex" title="{\frac{a_r}{b_r}}" /> in lowest terms. The input is an integer <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> held in a separate register. Each fraction represents the code line</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Ctext%7Bif+%7D+%28n%2Aa_r+%5Cequiv+0+%5Cpmod%7Bb_r%7D%29+%5C%7B+n+%3D+n%5Cfrac%7Ba_r%7D%7Bb_r%7D%3B+%5Ctext%7Bgoto+start%7D+%5C%7D%3B+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; " class="latex" title="\displaystyle  \text{if } (n*a_r \equiv 0 \pmod{b_r}) \{ n = n\frac{a_r}{b_r}; \text{goto start} \}; " /></p>
<p>
In other words, each iteration takes the first fraction <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{nf}" class="latex" title="{nf}" /> is an integer and updates <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bnf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{nf}" class="latex" title="{nf}" />; if there is no such fraction then the program exits and outputs <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />.</p>
<p>
For example, the following FRACTRAN program given in Wikipedia’s <a href="https://en.wikipedia.org/wiki/FRACTRAN">article</a> implicitly computes integer division: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B91%7D%7B66%7D%2C%7E%5Cfrac%7B11%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B33%7D%2C%7E%5Cfrac%7B85%7D%7B11%7D%2C%7E%5Cfrac%7B57%7D%7B119%7D%2C%7E%5Cfrac%7B17%7D%7B19%7D%2C%7E%5Cfrac%7B11%7D%7B17%7D%2C%7E%5Cfrac%7B1%7D%7B3%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. " class="latex" title="\displaystyle  \left[\frac{91}{66},~\frac{11}{13},~\frac{1}{33},~\frac{85}{11},~\frac{57}{119},~\frac{17}{19},~\frac{11}{17},~\frac{1}{3}\right]. " /></p>
<p>The notation is unary: The input <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> has the form <img src="https://s0.wp.com/latex.php?latex=%7B2%5En+3%5Ed+11%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n 3^d 11}" class="latex" title="{2^n 3^d 11}" /> and the ouput is <img src="https://s0.wp.com/latex.php?latex=%7B5%5Eq+7%5Er%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5^q 7^r}" class="latex" title="{5^q 7^r}" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+qd+%2B+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = qd + r}" class="latex" title="{n = qd + r}" /> with remainder <img src="https://s0.wp.com/latex.php?latex=%7Br+%3C+d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r &lt; d}" class="latex" title="{r &lt; d}" />. This already hints the fact that FRACTRAN is a universal programming language. Powers of primes serve as memory registers. The following program computes the Hamming weight <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> of the binary expansion of a natural number <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> encoded as <img src="https://s0.wp.com/latex.php?latex=%7B2%5Ex%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^x}" class="latex" title="{2^x}" />, returning the value <img src="https://s0.wp.com/latex.php?latex=%7B13%5Ek%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{13^k}" class="latex" title="{13^k}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B33%7D%7B20%7D%2C%7E%5Cfrac%7B5%7D%7B11%7D%2C%7E%5Cfrac%7B13%7D%7B10%7D%2C%7E%5Cfrac%7B1%7D%7B5%7D%2C%7E%5Cfrac%7B2%7D%7B3%7D%2C%7E%5Cfrac%7B10%7D%7B7%7D%2C%7E%5Cfrac%7B7%7D%7B2%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. " class="latex" title="\displaystyle  \left[\frac{33}{20},~\frac{5}{11},~\frac{13}{10},~\frac{1}{5},~\frac{2}{3},~\frac{10}{7},~\frac{7}{2}\right]. " /></p>
<p>This might help bridge to our notions of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}}" class="latex" title="{\mathsf{ACC}}" />. The Wikipedia article does a good job of de-mystifying the fractions in terms of their actions on the prime-power registers under the unary-style encoding. We wonder what happens when we try to work directly with binary encodings. </p>
<p>
</p><p></p><h2> The Collatz Example </h2><p></p>
<p></p><p>
The famous “<img src="https://s0.wp.com/latex.php?latex=%7B3n%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3n+1}" class="latex" title="{3n+1}" />” problem of Lothar Collatz is a case in point. It iterates the function </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++T%28n%29+%3D+%5Cbegin%7Bcases%7D+%5Cfrac%7B3n%2B1%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+odd%7D+%5C%5C+%5Cfrac%7Bn%7D%7B2%7D+%26+%5Ctext%7Bif+%7D+n+%5Ctext%7B+is+even%7D+%5Cend%7Bcases%7D++&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  " class="latex" title="\displaystyle  T(n) = \begin{cases} \frac{3n+1}{2} &amp; \text{if } n \text{ is odd} \\ \frac{n}{2} &amp; \text{if } n \text{ is even} \end{cases}  " /></p>
<p>The following FRACTRAN program <a href="https://hal.inria.fr/hal-00958971/document">given</a> by Kenneth Monks iterates <img src="https://s0.wp.com/latex.php?latex=%7BT%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{T(n)}" class="latex" title="{T(n)}" /> under the unary encoding <img src="https://s0.wp.com/latex.php?latex=%7B2%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2^n}" class="latex" title="{2^n}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%5B%5Cfrac%7B1%7D%7B11%7D%2C%7E%5Cfrac%7B136%7D%7B15%7D%2C%7E%5Cfrac%7B5%7D%7B17%7D%2C%7E%5Cfrac%7B4%7D%7B5%7D%2C%7E%5Cfrac%7B26%7D%7B21%7D%2C%7E%5Cfrac%7B7%7D%7B13%7D%2C%7E%5Cfrac%7B1%7D%7B7%7D%2C%7E%5Cfrac%7B33%7D%7B4%7D%2C%7E%5Cfrac%7B5%7D%7B2%7D%2C%7E%5Cfrac%7B7%7D%7B1%7D%5Cright%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. " class="latex" title="\displaystyle  \left[\frac{1}{11},~\frac{136}{15},~\frac{5}{17},~\frac{4}{5},~\frac{26}{21},~\frac{7}{13},~\frac{1}{7},~\frac{33}{4},~\frac{5}{2},~\frac{7}{1}\right]. " /></p>
<p>Note that since the last fraction is an integer the program runs forever. If <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 1}" class="latex" title="{n = 1}" /> so that the input is <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />, it would go <img src="https://s0.wp.com/latex.php?latex=%7B2+%5Crightarrow+5+%5Crightarrow+4+%5Crightarrow+33+%5Crightarrow+3+%5Crightarrow+21+%5Crightarrow+26+%5Crightarrow+14+%5Crightarrow+2+%5Ccdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}" class="latex" title="{2 \rightarrow 5 \rightarrow 4 \rightarrow 33 \rightarrow 3 \rightarrow 21 \rightarrow 26 \rightarrow 14 \rightarrow 2 \cdots}" /> and thus cycle, unless we stop it. The powers of <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> that appear in its output give the desired sequence. </p>
<p>
More natural to us, however, is the following modular program—which can use binary or any notation:</p>
<p>
<font size="+1"><tt><b><br />
start: if (n == 1) { halt; }<br />
if (n == 0 mod 2) { goto div; }<br />
n = 3*n + 1;<br />
div: n = n/2;<br />
goto start;<br />
</b></tt></font></p>
<p></p><p><br />
One can generalize the Collatz problem to moduli <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m &gt; 2}" class="latex" title="{m &gt; 2}" />. For each <img src="https://s0.wp.com/latex.php?latex=%7Bk+%3C+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k &lt; m}" class="latex" title="{k &lt; m}" /> we have a linear transformation <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cmapsto+c_k+n+%2B+d_k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \mapsto c_k n + d_k}" class="latex" title="{n \mapsto c_k n + d_k}" /> that always gives an integer value when <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cequiv+k+%5Cpmod%7Bm%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \equiv k \pmod{m}}" class="latex" title="{n \equiv k \pmod{m}}" />. We want to know about the orbits of numbers <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> under this iteration.</p>
<p>
In fact, this is exactly what FRACTRAN does. Take <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> to be the least common multiple of the denominators <img src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_r}" class="latex" title="{b_r}" /> in a FRACTRAN program <img src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cfrac%7Ba_r%7D%7Bb_r%7D%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[\frac{a_r}{b_r}]}" class="latex" title="{[\frac{a_r}{b_r}]}" />. Then for each <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> we can list the remainders <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> that are multiples of <img src="https://s0.wp.com/latex.php?latex=%7Bb_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b_r}" class="latex" title="{b_r}" /> and we get <img src="https://s0.wp.com/latex.php?latex=%7Bc_k+%3D+%5Cfrac%7Ba_r%7D%7B%5Cgcd%28k%2Cm%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_k = \frac{a_r}{\gcd(k,m)}}" class="latex" title="{c_k = \frac{a_r}{\gcd(k,m)}}" />, with <img src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_k = 0}" class="latex" title="{d_k = 0}" />. The Turing-universality of FRACTRAN then proves a general theorem Conway stated in 1972:</p>
<blockquote><p><b>Theorem 1</b> <em> Generalized Collatz-type problems for moduli <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3E+2%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{m &gt; 2}" class="latex" title="{m &gt; 2}" /> are undecidable. </em>
</p></blockquote>
<p></p><p>
<a href="https://link.springer.com/chapter/10.1007/978-3-540-72504-6_49">Several</a> <a href="http://julienmalka.me/collatz.pdf">followup</a> <a href="https://www.maa.org/sites/default/files/pdf/upload_library/22/Ford/Lagarias3-23.pdf">papers</a> have proved stronger and more particular forms of the undecidability. The paper by Monks linked above leverages the unary encoding to show that having <img src="https://s0.wp.com/latex.php?latex=%7Bd_k+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d_k = 0}" class="latex" title="{d_k = 0}" /> is essentially without loss of generality for universality; it is titled “<img src="https://s0.wp.com/latex.php?latex=%7B3x%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{3x+1}" class="latex" title="{3x+1}" /> Minus the <img src="https://s0.wp.com/latex.php?latex=%7B%2B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{+}" class="latex" title="{+}" />.” </p>
<p>
Having digested universality, it is natural to wonder about complexity. Can we use modular programming to achieve stronger connections between number theory and complexity classes—classes above the level of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BACC%7D%5E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{ACC}^0}" class="latex" title="{\mathsf{ACC}^0}" />, say? One possible mode of connection is exemplified by this <a href="https://www.researchgate.net/publication/220994869_One_Binary_Horn_Clause_is_Enough">paper</a> from STACS 1994, which both Dick and I attended. We wonder whether the kind of connection noted by Terry Tao in his <a href="https://terrytao.wordpress.com/2020/04/12/john-conway/">tribute</a> to Conway can also smooth the way to understanding <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BMIP%5E%2A+%3D+RE%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{MIP^* = RE}}" class="latex" title="{\mathsf{MIP^* = RE}}" />.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Conway posed many open problems himself. Here is a <a href="https://oeis.org/A248380/a248380.pdf">list</a> of five for which he posted cash rewards in the manner of Paul Erdős. The fifth was recently solved. The fourth can be stated in one sentence:</p>
<blockquote><p><b> </b> <em> If a set of points in the plane intersects every convex region of area 1, then must it have pairs of points at arbitrarily small distances? </em>
</p></blockquote>
<p></p><p>
Our condolences go out to his family and all who were enthralled by him in the mathematical world. We could talk endlessly about his impact on mathematics education—even about simple things like how to <a href="https://mathscinet.ams.org/mathscinet-getitem?mr=3111964">prove</a> that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{2}}" class="latex" title="{\sqrt{2}}" /> is irrational—or try to tangle with his <a href="https://en.wikipedia.org/wiki/Monstrous_moonshine">applications</a> of the “Monster” group to modular forms, but those must be for another time. Also see Scott Aaronson’s <a href="https://www.scottaaronson.com/blog/?p=4732">tribute</a> and its comments section for many more stories and items.</p>
<p></p><p><br />
[some small word and format changes, added link to Scott and may add others as time allows]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2020/04/14/john-horton-conway-1937-2020/"><span class="datestr">at April 14, 2020 08:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://kamathematics.wordpress.com/?p=49">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kamath.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/">A Primer on Private Statistics – Part I</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>By <a href="http://www.gautamkamath.com/">Gautam Kamath</a> and <a href="http://www.ccs.neu.edu/home/jullman/">Jonathan Ullman</a></p>
<p>Differentially private statistics is a very lively research area, and has seen a lot of activity in the last couple years. While the phrasing is a slight departure from previous work which focused on estimation with worst-case datasets, it turns out that the differences are often superficial. In a short series of blog posts, we hope to educate readers on some of the recent advancements in this area, as well as shed light on some of the connections between the old and the new. We’ll describe the settings, cover a couple of technical examples, and give pointers to some other directions in the area. Thanks to <a href="https://cs-people.bu.edu/ads22/">Adam Smith</a> for helping kick off this project, <a href="http://www.cs.columbia.edu/~ccanonne/">Clément Canonne</a>, <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a>, and <a href="http://www.thomas-steinke.net/">Thomas Steinke</a> for helpful comments, and <a href="https://lucatrevisan.github.io/">Luca Trevisan</a> for his <a href="https://lucatrevisan.wordpress.com/latex-to-wordpress/">LaTeX2WP script</a>.</p>
<p><b>1. Introduction </b></p>
<p>Statistics and machine learning are now ubiquitous in data analysis. Given a dataset, one immediately wonders what it allows us to infer about the underlying population. However, modern datasets don’t exist in a vacuum: they often contain sensitive information about the individuals they represent. Without proper care, statistical procedures will result in gross violations of privacy. Motivated by the shortcomings of ad hoc methods for data anonymization, Dwork, McSherry, Nissim, and Smith introduced the celebrated notion of differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>].</p>
<p>From its inception, some of the driving motivations for differential privacy were applications in statistics and the social sciences, notably disclosure limitation for the US Census. And yet, the lion’s share of differential privacy research has taken place within the computer science community. As a result, the specific applications being studied are often not formulated using statistical terminology, or even as statistical problems. Perhaps most significantly, much of the early work in computer science (though definitely not all) focus on estimating some property <em>of a dataset</em> rather than estimating some property <em>of an underlying population</em>.</p>
<p>Although the earliest works exploring the interaction between differential privacy and classical statistics go back to at least 2009 [<a href="https://kamathematics.wordpress.com/feed/#VS09">VS09</a>,<a href="https://kamathematics.wordpress.com/feed/#FRY10">FRY10</a>], the emphasis on differentially private statistical inference in the computer science literature is somewhat more recent. However, while earlier results on differential privacy did not always formulate problems in a statistical language, statistical inference was a key motivation for most of this work. As a result many of the techniques that were developed have direct applications in statistics, for example establishing minimax rates for estimation problems.</p>
<p>The purpose of this series of blog posts is to highlight some of those results in the computer science literature, and present them in a more statistical language. Specifically, we will discuss:</p>
<ul>
<li>Tight minimax lower bounds for privately estimating the mean of a multivariate distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" />, using the technique of <em>tracing attacks</em> developed in [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>,<a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>].
<p> </p>
</li>
<li>Upper bounds for estimating a distribution in Kolmogorov distance, using the ubiquitous <em>binary-tree mechanism</em> introduced in [<a href="https://kamathematics.wordpress.com/feed/#DNPR10">DNPR10</a>,<a href="https://kamathematics.wordpress.com/feed/#CSS11">CSS11</a>].</li>
</ul>
<p>In particular, we hope to encourage computer scientists working on differential privacy to pay more attention to the applications of their methods in statistics, and share with statisticians many of the powerful techniques that have been developed in the computer science literature.</p>
<p> </p>
<p><b> 1.1. Formulating Private Statistical Inference </b></p>
<p>Essentially every differentially private statistical estimation task can be phrased using the following setup. We are given a dataset <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C+%5Cdots%2C+X_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1, \dots, X_n)}" class="latex" title="{X = (X_1, \dots, X_n)}" /> of size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, and we wish to design an algorithm <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Cin+%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \in \mathcal{M}}" class="latex" title="{M \in \mathcal{M}}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}}" class="latex" title="{\mathcal{M}}" /> is the class of mechanisms that are both:</p>
<ol>
<li>differentially private, and</li>
<li>accurate, either in expectation or with high probability, according to some task-specific measure.</li>
</ol>
<p>A few comments about this framework are in order. First, although the accuracy requirement is stochastic in nature (i.e., an algorithm might not be accurate depending on the randomness of the algorithm and the data generation process), the privacy requirement is worst-case in nature. That is, the algorithm must protect privacy for every dataset <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, even those we believe are very unlikely.</p>
<p>Second, the accuracy requirement is stated rather vaguely. This is because the notion of accuracy of an algorithm is slightly more nuanced, depending on whether we are concerned with <em>empirical</em> or <em>population</em> statistics. A particular emphasis of these blog posts is to explore the difference (or, as we will see, the lack of a difference) between these two notions of accuracy. The former estimates a quantity of the observed dataset, while the latter estimates a quantity of an unobserved distribution which is assumed to have generated the dataset.</p>
<p>More precisely, the former can be phrased in terms of empirical loss, of the form:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BX+%5Cin+%5Cmathcal%7BX%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_M%28%5Cell%28M%28X%29%2C+f%28X%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " class="latex" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{X \in \mathcal{X}}~\mathop{\mathbb E}_M(\ell(M(X), f(X))), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}}" class="latex" title="{\mathcal{M}}" /> is some class of <em>randomized estimators</em> (e.g., differentially private estimators), <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{X}}" class="latex" title="{\mathcal{X}}" /> is some class of <em>datasets</em>, <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> is some quantity of interest, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> is some <em>loss function</em>. That is, we’re looking to find an estimator that has small expected loss on <em>any dataset</em> in some class.</p>
<p>In contrast, statistical minimax theory looks at statements about population loss, of the form:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D%7D%7E%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D%7E%5Cmathop%7B%5Cmathbb+E%7D_%7BX+%5Csim+P%2C+M%7D%28%5Cell%28M%28X%29%2Cf%28P%29%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " class="latex" title="\displaystyle \min_{M \in \mathcal{M}}~\max_{P \in \mathcal{P}}~\mathop{\mathbb E}_{X \sim P, M}(\ell(M(X),f(P))), " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> is some family of <em>distributions</em> over datasets (typically consisting of i.i.d. samples). That is, we’re looking to find an estimator that has small expected loss on random data from <em>any distribution</em> in some class. In particular, note that the randomness in this objective additionally includes the data generating procedure <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim P}" class="latex" title="{X \sim P}" />.</p>
<p>These two formulations are formally very different in several ways. First, the empirical formulation requires an estimator to have small loss on <em>worst-case</em> datasets, whereas the statistical formulation only requires the estimator to have small loss <em>on average</em> over datasets drawn from certain distributions. Second, the statistical formulation requires that we estimate the unknown quantity <img src="https://s0.wp.com/latex.php?latex=%7Bf%28P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(P)}" class="latex" title="{f(P)}" />, and thus necessitates a solution to the non-private estimation problem. On the other hand, the empirical formulation only asks us to estimate the known quantity <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" />, and thus if there were no privacy constraint it would always be possible to compute <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" /> exactly. Third, typically in the statistical formulation, we require that the dataset is drawn i.i.d., which means that we are more constrained when proving lower bounds for estimation than we are in the empirical problem.</p>
<p>However, in practice (more precisely, in the practice of doing theoretical research), these two formulations are more alike than they are different, and results about one formulation often imply results about the other formulation. On the algorithmic side, classical statistical results will often tell us that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28f%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(f(X),f(P))}" class="latex" title="{\ell(f(X),f(P))}" /> is small, in which case algorithms that guarantee <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28X%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(M(X),f(X))}" class="latex" title="{\ell(M(X),f(X))}" /> is small also guarantee <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%28M%28X%29%2Cf%28P%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell(M(X),f(P))}" class="latex" title="{\ell(M(X),f(P))}" /> is small.</p>
<p>Moreover, typical lower bound arguments for empirical quantities are often statistical in nature. These typically involving constructing some simple “hard distribution” over datasets such that no private algorithm can estimate well on average for this distribution, and thus these lower bound arguments also apply to estimating population statistics for some simple family of distributions. We will proceed to give some examples of estimation problems that were originally studied by computer scientists with the empirical formulation in mind. These results either implicitly or explicitly provide solutions to the corresponding population versions of the same problems—our goal is to spell out and illustrate these connections.</p>
<p><b>2. DP Background </b></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2CX_2%2C%5Cdots%2CX_n%29+%5Cin+%5Cmathcal%7BX%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" class="latex" title="{X = (X_1,X_2,\dots,X_n) \in \mathcal{X}^n}" /> be a collection of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> samples where each individual sample comes from the domain <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BX%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{X}}" class="latex" title="{\mathcal{X}}" />. We say that two samples <img src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27+%5Cin+%5Cmathcal%7BX%7D%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,X' \in \mathcal{X}^*}" class="latex" title="{X,X' \in \mathcal{X}^*}" /> are <em>adjacent</em>, denoted <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim X'}" class="latex" title="{X \sim X'}" />, if they differ on at most one individual sample. Intuitively, a randomized algorithm <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, which is often called a <em>mechanism</em> for historical reasons, is <em>differentially private</em> if the distribution of <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X')}" class="latex" title="{M(X')}" /> are similar for every pair of adjacent samples <img src="https://s0.wp.com/latex.php?latex=%7BX%2CX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X,X'}" class="latex" title="{X,X'}" />.</p>
<blockquote>
<p><b>Definition 1 ([<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> A mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" /> is <em><img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private</em> if for every pair of adjacent datasets <img src="https://s0.wp.com/latex.php?latex=%7BX+%5Csim+X%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X \sim X'}" class="latex" title="{X \sim X'}" />, and every (measurable) <img src="https://s0.wp.com/latex.php?latex=%7BR+%5Csubseteq+R%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{R \subseteq R}" class="latex" title="{R \subseteq R}" /> </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%29+%5Cin+R%29+%5Cleq+e%5E%7B%5Cepsilon%7D+%5Ccdot+%5Cmathop%7B%5Cmathbb+P%7D%28M%28X%27%29+%5Cin+R%29+%2B+%5Cdelta.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " class="latex" title="\displaystyle \mathop{\mathbb P}(M(X) \in R) \leq e^{\epsilon} \cdot \mathop{\mathbb P}(M(X') \in R) + \delta. " /></p>
<p> </p>
</blockquote>
<p>We let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{M}_{\epsilon,\delta}}" class="latex" title="{\mathcal{M}_{\epsilon,\delta}}" /> denote the set of mechanisms that satisfy <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy.</p>
<blockquote>
<p><b>Remark 1</b> <em> To simplify notation, and to maintain consistency with the literature, we adopt the convention of defining the mechanism only for a fixed sample size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. What this means in practice is that the mechanisms we describe treat the sample size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is <em>public information</em> that need not be kept private. While one could define a more general model where <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> is not fixed, it wouldn’t add anything to this discussion other than additional complexity. </em></p>
</blockquote>
<blockquote>
<p><b>Remark 2</b> <em> In these blog posts, we stick to the most general formulation of differential privacy, so-called <em>approximate differential privacy</em>, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" /> essentially because this is the notion that captures the widest variety of private mechanisms. Almost all of what follows would apply equally well, with minor technical modifications, to slightly stricter notions of <em>concentrated differential privacy [</em><a href="https://kamathematics.wordpress.com/feed/#DR16">DR16</a>, <a href="https://kamathematics.wordpress.com/feed/#BS16">BS16</a>, <a href="https://kamathematics.wordpress.com/feed/#BDRS18">BDRS18</a>], Rényi differential privacy [<a href="https://kamathematics.wordpress.com/feed/#Mir17">Mir17</a>], or <em>Gaussian differential privacy [<a href="https://kamathematics.wordpress.com/feed/#DRS19">DRS19</a>]</em>. While so-called <em>pure differential privacy</em>, i.e. <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,0)}" class="latex" title="{(\epsilon,0)}" />-differential privacy has also been studied extensively, this notion is artificially restrictive and excludes many differentially private mechanisms. </em></p>
</blockquote>
<p>A key property of differential privacy that helps when desinging efficient estimators is <em>closure under postprocessing</em>:</p>
<blockquote>
<p><b>Lemma 2 (Post-Processing [<a href="https://kamathematics.wordpress.com/feed/#DMNS06">DMNS06</a>])</b><em> <a name="lempost-processing"></a> If <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%5Cmathcal%7BR%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" class="latex" title="{M \colon \mathcal{X}^n \rightarrow \mathcal{R}}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private and <img src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccolon+%5Cmathcal%7BR%7D+%5Crightarrow+%5Cmathcal%7BR%7D%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" class="latex" title="{M' \colon \mathcal{R} \rightarrow \mathcal{R}'}" /> is any randomized algorithm, then <img src="https://s0.wp.com/latex.php?latex=%7BM%27+%5Ccirc+M%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M' \circ M}" class="latex" title="{M' \circ M}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private. </em></p>
</blockquote>
<p>The estimators we present in this work will use only one tool for achieving differential privacy, the <em>Gaussian Mechanism</em>.</p>
<blockquote>
<p><b>Lemma 3 (Gaussian Mechanism)</b> <em> <a name="lemgauss-mech"></a> Let <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5Cmathcal%7BX%7D%5En+%5Crightarrow+%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" class="latex" title="{f \colon \mathcal{X}^n \rightarrow {\mathbb R}^d}" /> be a function and let </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5CDelta_%7Bf%7D+%3D+%5Csup_%7BX%5Csim+X%27%7D+%5C%7C+f%28X%29+-+f%28X%27%29+%5C%7C_2+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " class="latex" title="\displaystyle \Delta_{f} = \sup_{X\sim X'} \| f(X) - f(X') \|_2 " /></p>
<p>denote its <em><img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2}" class="latex" title="{\ell_2}" />-sensitivity</em>. The <em>Gaussian mechanism</em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X%29+%3D+f%28X%29+%2B+%5Cmathcal%7BN%7D%5Cleft%280+%2C+%5Cfrac%7B2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2%7D+%5Ccdot+%5CDelta_%7Bf%7D%5E2+%5Ccdot+%7B%5Cmathbb+I%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " class="latex" title="\displaystyle M(X) = f(X) + \mathcal{N}\left(0 , \frac{2 \log(2/\delta)}{\epsilon^2} \cdot \Delta_{f}^2 \cdot {\mathbb I}_{d \times d} \right) " /></p>
<p><em> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy. </em></p>
</blockquote>
<p><b>3. Mean Estimation in <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" /> </b></p>
<p>Let’s take a dive into the problem of <em>private mean estimation</em> for some family <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> of multivariate distributions over <img src="https://s0.wp.com/latex.php?latex=%7B%7B%5Cmathbb+R%7D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{\mathbb R}^d}" class="latex" title="{{\mathbb R}^d}" />. This problem has been studied for various families <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> and various choices of loss function. Here we focus on perhaps the simplest variant of the problem, in which <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> contains distributions of bounded support <img src="https://s0.wp.com/latex.php?latex=%7B%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[\pm 1]^d}" class="latex" title="{[\pm 1]^d}" /> and the loss is the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2^2}" class="latex" title="{\ell_2^2}" /> error. We emphasize, however, that the methods we discuss here are quite versatile and can be used to derive minimax bounds for other variants of the mean-estimation problem.</p>
<p>Note that, by a simple argument, the non-private minimax rate for this class is achieved by the empirical mean, and is</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| \overline{X} - \mu\|_2^2) = \frac{d}{n}. \ \ \ \ \ (1)" /></p>
<p>The main goal of this section is to derive the minimax bound <a name="eqRd-minimax"></a></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cfrac%7B1%7D%7Bn%7D%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Ctilde%5CTheta%5Cleft%28%5Cfrac%7Bd%5E2%7D%7B%5Cepsilon%5E2+n%5E2%7D%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" class="latex" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\frac{1}{n}}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \frac{d}{n} + \tilde\Theta\left(\frac{d^2}{\epsilon^2 n^2}\right). \ \ \ \ \ (2)" /></p>
<p><a name="eqRd-minimax"></a> Recall that <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde+%5CTheta%28f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde \Theta(f(n))}" class="latex" title="{\tilde \Theta(f(n))}" /> refers to a function which is both <img src="https://s0.wp.com/latex.php?latex=%7BO%28f%28n%29+%5Clog%5E%7Bc_1%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(f(n) \log^{c_1} f(n))}" class="latex" title="{O(f(n) \log^{c_1} f(n))}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28f%28n%29+%5Clog%5E%7Bc_2%7D+f%28n%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(f(n) \log^{c_2} f(n))}" class="latex" title="{\Omega(f(n) \log^{c_2} f(n))}" /> for some constants <img src="https://s0.wp.com/latex.php?latex=%7Bc_1%2C+c_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_1, c_2}" class="latex" title="{c_1, c_2}" />. The proof of this lower bound is based on <em>robust tracing attacks</em>, also called <em>membership inference attacks</em>, which were developed in a chain of papers [<a href="https://kamathematics.wordpress.com/feed/#BUV14">BUV14</a>, <a href="https://kamathematics.wordpress.com/feed/#DSSUV15">DSSUV15</a>, <a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>, <a href="https://kamathematics.wordpress.com/feed/#SU17b">SU17b</a>, <a href="https://kamathematics.wordpress.com/feed/#KLSU19">KLSU19</a>]. We remark that this lower bound is almost identical to the minimax bound for mean estimation proven in the much more recent work of Cai, Wang, and Zhang [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>], but it lacks tight dependence on the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, which we discuss in the following remark.</p>
<blockquote>
<p><b>Remark 3</b> <em> The choice of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3D+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta = 1/n}" class="latex" title="{\delta = 1/n}" /> in <a href="https://kamathematics.wordpress.com/feed/#eqRd-minimax">(2)</a> may look strange at first. For the upper bound this choice is arbitrary—as we will see, we can upper bound the rate for any <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &gt; 0}" class="latex" title="{\delta &gt; 0}" /> at a cost of a factor of <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog%281%2F%5Cdelta%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(\log(1/\delta))}" class="latex" title="{O(\log(1/\delta))}" />. The lower bound applies only when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cleq+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \leq 1/n}" class="latex" title="{\delta \leq 1/n}" />. Note that the rate is qualitatively different when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \gg 1/n}" class="latex" title="{\delta \gg 1/n}" />. However, we emphasize that <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy is not a meaningful privacy notion unless <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \ll 1/n}" class="latex" title="{\delta \ll 1/n}" />. In particular, the mechanism that randomly outputs <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta n}" class="latex" title="{\delta n}" /> elements of the sample satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%280%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(0,\delta)}" class="latex" title="{(0,\delta)}" />-differential privacy. However, when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cgg+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \gg 1/n}" class="latex" title="{\delta \gg 1/n}" />, this mechanism completely violates the privacy of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cgg+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\gg 1}" class="latex" title="{\gg 1}" /> person in the dataset. Moreover, taking the empirical mean of these <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta n}" class="latex" title="{\delta n}" /> samples gives rate <img src="https://s0.wp.com/latex.php?latex=%7Bd%2F%5Cdelta+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d/\delta n}" class="latex" title="{d/\delta n}" />, which would violate our lower bound when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> is large enough. On the other hand, we would expect the minimax rate to become slower when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%5Cll+1%2Fn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta \ll 1/n}" class="latex" title="{\delta \ll 1/n}" />. This expectation is, in fact, correct, however the proof we present does not give the tight dependence on the parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />. See [<a href="https://kamathematics.wordpress.com/feed/#SU17a">SU17a</a>] for a refinement that can obtain the right dependence on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, and [<a href="https://kamathematics.wordpress.com/feed/#CWZ19">CWZ19</a>] for the details of how to apply this refinement in the i.i.d. setting. </em></p>
</blockquote>
<p><b> 3.1. A Simple Upper Bound </b></p>
<blockquote>
<p><b>Theorem 4</b> <em> For every <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n \in {\mathbb N}}" class="latex" title="{n \in {\mathbb N}}" />, and every <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%2C%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon,\delta &gt; 0}" class="latex" title="{\epsilon,\delta &gt; 0}" />, there exists an <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private private mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> such that <a name="eqmean-est-ub"></a></em></p>
<p><em><em><a name="eqmean-est-ub"></a></em></em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%5Cleq+%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%283%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" class="latex" title="\displaystyle \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P}(\| M(X_{1 \cdots n}) - \mu \|_2^2) \leq \frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \ \ \ \ \ (3)" /></p>
<p><em><a name="eqmean-est-ub"></a></em></p>
<p><em><a name="eqmean-est-ub"></a> </em></p>
</blockquote>
<p><em>Proof:</em> Define the mechanism</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+M%28X_%7B1+%5Ccdots+n%7D%29+%3D+%5Coverline%7BX%7D+%2B+%5Cmathcal%7BN%7D%5Cleft%280%2C+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D+%5Ccdot+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D+%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%284%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" class="latex" title="\displaystyle M(X_{1 \cdots n}) = \overline{X} + \mathcal{N}\left(0, \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2} \cdot \mathbb{I}_{d \times d} \right). \ \ \ \ \ (4)" /></p>
<p>This mechanism satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differential privacy by Lemma <a href="https://kamathematics.wordpress.com/feed/#lemgauss-mech">3</a>, noting that for any pair of adjacent samples <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{1 \cdots n}}" class="latex" title="{X_{1 \cdots n}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX%27_%7B1+%5Ccdots+n%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'_{1 \cdots n}}" class="latex" title="{X'_{1 \cdots n}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7C+%5Coverline%7BX%7D+-+%5Coverline%7BX%7D%27%5C%7C_2%5E2+%5Cleq+%5Cfrac%7Bd%7D%7Bn%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" class="latex" title="{\| \overline{X} - \overline{X}'\|_2^2 \leq \frac{d}{n^2}}" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma%5E2+%3D+%5Cfrac%7B2+d+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cvarepsilon%5E2+n%5E2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" class="latex" title="{\sigma^2 = \frac{2 d \log(2/\delta)}{\varepsilon^2 n^2}}" />. Note that since the Gaussian noise has mean <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and is independent of <img src="https://s0.wp.com/latex.php?latex=%7B%5Coverline%7BX%7D+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\overline{X} - \mu}" class="latex" title="{\overline{X} - \mu}" />, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Coverline%7BX%7D+-+%5Cmu+%5C%7C_2%5E2%29+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%5Cleq%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Coverline%7BX%7D+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+%5Cmathcal%7BN%7D%280%2C+%5Csigma%5E2+%5Cmathbb%7BI%7D_%7Bd+%5Ctimes+d%7D%29+%5C%7C_2%5E2+%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Csigma%5E2+d+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7Bn%7D+%2B+%5Cfrac%7B2+d%5E2+%5Clog%282%2F%5Cdelta%29%7D%7B%5Cepsilon%5E2+n%5E2%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \mu \|_2^2) ={} &amp;\mathop{\mathbb E}(\| \overline{X} - \mu \|_2^2) + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ \leq{} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| M(X_{1 \cdots n}) - \overline{X} \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \mathop{\mathbb E}(\| \mathcal{N}(0, \sigma^2 \mathbb{I}_{d \times d}) \|_2^2 ) \\ ={} &amp;\frac{d}{n} + \sigma^2 d \\ ={} &amp;\frac{d}{n} + \frac{2 d^2 \log(2/\delta)}{\epsilon^2 n^2}. \end{array} " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p> </p>
<p><b> 3.2. Minimax Lower Bounds via Tracing </b></p>
<blockquote>
<p><b>Theorem 5</b> <em> <a name="thmmean-lb"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bn%2C+d+%5Cin+%7B%5Cmathbb+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n, d \in {\mathbb N}}" class="latex" title="{n, d \in {\mathbb N}}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\epsilon &gt; 0}" class="latex" title="{\epsilon &gt; 0}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3C+1%2F96n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta &lt; 1/96n}" class="latex" title="{\delta &lt; 1/96n}" />, if <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" /> is the class of all product distributions on <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}^{d}}" class="latex" title="{\{\pm 1\}^{d}}" />, then for some constant <img src="https://s0.wp.com/latex.php?latex=%7BC+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C &gt; 0}" class="latex" title="{C &gt; 0}" />, </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmin_%7BM+%5Cin+%5Cmathcal%7BM%7D_%7B%5Cepsilon%2C%5Cdelta%7D%7D+%5Cmax_%7BP+%5Cin+%5Cmathcal%7BP%7D%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7BX_%7B1+%5Ccdots+n%7D+%5Csim+P%2CM%7D%28%5C%7C+M%28X_%7B1+%5Ccdots+n%7D%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+%5COmega%5Cleft%28%5Cmin+%5Cleft%5C%7B+%5Cfrac%7Bd%5E2%7D%7B+%5Cepsilon%5E2+n%5E2%7D%2C+d+%5Cright%5C%7D%5Cright%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " class="latex" title="\displaystyle \min_{M \in \mathcal{M}_{\epsilon,\delta}} \max_{P \in \mathcal{P}} \mathop{\mathbb E}_{X_{1 \cdots n} \sim P,M}(\| M(X_{1 \cdots n}) - \mu \|_2^2) = \Omega\left(\min \left\{ \frac{d^2}{ \epsilon^2 n^2}, d \right\}\right). " /></p>
<p> </p>
</blockquote>
<p>Note that it is trivial to achieve error <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> for any distribution using the mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B1+%5Ccdots+n%7D%29+%5Cequiv+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{1 \cdots n}) \equiv 0}" class="latex" title="{M(X_{1 \cdots n}) \equiv 0}" />, so the result says that the error must be <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28d%5E2%2F%5Cepsilon%5E2+n%5E2%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Omega(d^2/\epsilon^2 n^2)}" class="latex" title="{\Omega(d^2/\epsilon^2 n^2)}" /> whenever this error is significantly smaller than the trivial error of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />.</p>
<p><b>Tracing Attacks.</b></p>
<p>Before giving the formal proof, we will try to give some intuition for the high-level proof strategy. The proof can be viewed as constructing a <em>tracing attack </em>[<a href="https://kamathematics.wordpress.com/feed/#DSSU17">DSSU17</a>] (sometimes called a <em>membership inference attack</em>) of the following form. There is an attacker who has the data of some individual <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> chosen in one of the two ways: either <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a random element of the sample <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, or <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is an independent random sample from the population <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" />. The attacker is given access to the true distribution <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> and the outcome of the mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" />, and wants to determine which of the two is the case. If the attacker can succeed, then <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> cannot be differentially private. To understand why this is the case, if <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a member of the dataset, then the attacker should say <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is in the dataset, but if we consider the adjacent dataset <img src="https://s0.wp.com/latex.php?latex=%7BX%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'}" class="latex" title="{X'}" /> where we replace <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> with some independent sample from <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" />, then the attacker will now say <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is independent of the dataset. Thus, <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X')}" class="latex" title="{M(X')}" /> cannot be close in the sense required by differential privacy.</p>
<p>Thus, the proof works by constructing a test statistic <img src="https://s0.wp.com/latex.php?latex=%7BZ+%3D+Z%28M%28X%29%2CY%2CP%29%2C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z = Z(M(X),Y,P),}" class="latex" title="{Z = Z(M(X),Y,P),}" /> that the attacker can use to distinguish the two possibilities for <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" />. In particular, we show that there is a distribution over populations <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z)}" class="latex" title="{\mathop{\mathbb E}(Z)}" /> is small when <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is independent of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, but for <em>every</em> sufficiently accurate mechanism <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z)}" class="latex" title="{\mathop{\mathbb E}(Z)}" /> is large when <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> is a random element of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />.</p>
<p><b>Proof of Theorem <a href="https://kamathematics.wordpress.com/feed/#thmmean-lb">5</a>.</b></p>
<p>We start by constructing a “hard distribution” over the family of product distributions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathcal%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathcal{P}}" class="latex" title="{\mathcal{P}}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%3D+%28%5Cmu%5E1%2C%5Cdots%2C%5Cmu%5Ed%29+%5Cin+%5B-1%2C1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" class="latex" title="{\mu = (\mu^1,\dots,\mu^d) \in [-1,1]^d}" /> consist of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> independent draws from the uniform distribution on <img src="https://s0.wp.com/latex.php?latex=%7B%5B-1%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[-1,1]}" class="latex" title="{[-1,1]}" /> and let <img src="https://s0.wp.com/latex.php?latex=%7BP_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_{\mu}}" class="latex" title="{P_{\mu}}" /> be the product distribution over <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%5Cpm+1%5C%7D%5E%7Bd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{\pm 1\}^{d}}" class="latex" title="{\{\pm 1\}^{d}}" /> with mean <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Csim+P_%7B%5Cmu%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_1,\dots,X_n \sim P_{\mu}}" class="latex" title="{X_1,\dots,X_n \sim P_{\mu}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX+%3D+%28X_1%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X = (X_1,\dots,X_n)}" class="latex" title="{X = (X_1,\dots,X_n)}" />.</p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7BM+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5E%7Bn+%5Ctimes+d%7D+%5Crightarrow+%5B%5Cpm+1%5D%5Ed%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" class="latex" title="{M \colon \{\pm 1\}^{n \times d} \rightarrow [\pm 1]^d}" /> be any <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cepsilon%2C%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\epsilon,\delta)}" class="latex" title="{(\epsilon,\delta)}" />-differentially private mechanism and let</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%3D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5C%7C+M%28X%29+-+%5Cmu%5C%7C_2%5E2+%29+%5C+%5C+%5C+%5C+%5C+%285%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" class="latex" title="\displaystyle \alpha^2 = \mathop{\mathbb E}_{\mu,X,M}(\| M(X) - \mu\|_2^2 ) \ \ \ \ \ (5)" /></p>
<p>be its expected loss. We will prove the desired lower bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" />.</p>
<p>For every element <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, we define the random variables</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+Z_i+%3D+Z_i%28M%28X%29%2CX_i%2C%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle+%5C%5C+Z%27_%7Bi%7D+%3D+Z%27_i%28M%28X_%7B%5Csim+i%7D%29%2C+X_i%2C+%5Cmu%29+%3D+%5Cleft%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " class="latex" title="\displaystyle Z_i = Z_i(M(X),X_i,\mu) = \left\langle M(X) - \mu, X_i - \mu \right\rangle \\ Z'_{i} = Z'_i(M(X_{\sim i}), X_i, \mu) = \left\langle M(X_{\sim i}) - \mu, X_i - \mu \right\rangle, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7BX_%7B%5Csim+i%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_{\sim i}}" class="latex" title="{X_{\sim i}}" /> denotes <img src="https://s0.wp.com/latex.php?latex=%7B%28X_1%2C%5Cdots%2CX%27_i%2C%5Cdots%2CX_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X_1,\dots,X'_i,\dots,X_n)}" class="latex" title="{(X_1,\dots,X'_i,\dots,X_n)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BX%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X'_i}" class="latex" title="{X'_i}" /> is an independent sample from <img src="https://s0.wp.com/latex.php?latex=%7BP_%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P_\mu}" class="latex" title="{P_\mu}" />. Our goal will be to show that, privacy and accuracy imply both upper and lower bounds on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_i+Z_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_i Z_i)}" class="latex" title="{\mathop{\mathbb E}(\sum_i Z_i)}" /> that depend on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />, and thereby obtain a bound on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" />.</p>
<p>The first claim says that, when <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" /> is <em>not</em> in the sample, then the likelihood random variable has mean <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> and variance controlled by the expected <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell_2%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell_2^2}" class="latex" title="{\ell_2^2}" /> error of the mechanism.</p>
<blockquote>
<p><b>Claim 1</b> <em> <a name="clmmean-lb-1"></a> For every <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(Z'_i) = 0}" class="latex" title="{\mathop{\mathbb E}(Z'_i) = 0}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" class="latex" title="{\mathrm{Var}(Z'_i) \leq 4\alpha^2}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7CZ%27_i%5C%7C_%5Cinfty+%5Cleq+4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\|Z'_i\|_\infty \leq 4d}" class="latex" title="{\|Z'_i\|_\infty \leq 4d}" />. </em></p>
</blockquote>
<p><em>Proof:</em> Conditioned on any value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />, <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{\sim i})}" class="latex" title="{M(X_{\sim i})}" /> is independent from <img src="https://s0.wp.com/latex.php?latex=%7BX_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i}" class="latex" title="{X_i}" />. Moreover, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28X_i+-+%5Cmu%29+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(X_i - \mu) = 0}" class="latex" title="{\mathop{\mathbb E}(X_i - \mu) = 0}" />, so we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28%5Clangle+M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Crangle%29%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28X_i+-+%5Cmu%29+%5Cright+%5Crangle+%29+%5C%5C+%3D+%26%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cleft%5Clangle+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%2CM%7D%28M%28X_%7B%5Csim+i%7D%29+-+%5Cmu%29%2C+0+%5Cright+%5Crangle+%29+%5C%5C+%3D+%260.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} &amp;\mathop{\mathbb E}_{\mu,X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle) \\ = &amp;\mathop{\mathbb E}_{\mu}(\mathop{\mathbb E}_{X,M}(\langle M(X_{\sim i}) - \mu, X_i - \mu \rangle)) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), \mathop{\mathbb E}_{X,M}(X_i - \mu) \right \rangle ) \\ = &amp;\mathop{\mathbb E}_{\mu}(\left\langle \mathop{\mathbb E}_{X,M}(M(X_{\sim i}) - \mu), 0 \right \rangle ) \\ = &amp;0. \end{array} " /></p>
<p>For the second part of the claim, since <img src="https://s0.wp.com/latex.php?latex=%7B%28X_i+-+%5Cmu%29%5E2+%5Cleq+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(X_i - \mu)^2 \leq 4}" class="latex" title="{(X_i - \mu)^2 \leq 4}" />, we have <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathrm%7BVar%7D%28Z%27_i%29+%5Cleq+4+%5Ccdot+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D+4%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" class="latex" title="{\mathrm{Var}(Z'_i) \leq 4 \cdot \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) = 4\alpha^2}" />. The final part of the claim follows from the fact that every entry of <img src="https://s0.wp.com/latex.php?latex=%7BM%28X_%7B%5Csim+i%7D%29+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X_{\sim i}) - \mu}" class="latex" title="{M(X_{\sim i}) - \mu}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BX_i+-+%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_i - \mu}" class="latex" title="{X_i - \mu}" /> is bounded by <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> in absolute value, and <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_i}" class="latex" title="{Z'_i}" /> is a sum of <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" /> such entries, so its absolute value is always at most <img src="https://s0.wp.com/latex.php?latex=%7B4d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{4d}" class="latex" title="{4d}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>The next claim says that, because <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is differentially private, <img src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_i}" class="latex" title="{Z_i}" /> has similar expectation to <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_i}" class="latex" title="{Z'_i}" />, and thus its expectation is also small.</p>
<blockquote>
<p><b>Claim 2</b> <em><a name="clmmean-lb-2"></a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" class="latex" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \leq 4n\alpha \epsilon + 8n \delta d.}" /> </em></p>
</blockquote>
<p><em>Proof:</em> The proof is a direct calculation using the following inequality, whose proof is relatively simple using the definition of differential privacy:</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+%5Cmathop%7B%5Cmathbb+E%7D%28Z%27_i%29+%2B+2%5Cepsilon+%5Csqrt%7B%5Cmathrm%7BVar%7D%28Z%27_i%29%7D+%2B+2%5Cdelta+%5C%7C+Z%27_i+%5C%7C_%5Cinfty.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " class="latex" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq \mathop{\mathbb E}(Z'_i) + 2\epsilon \sqrt{\mathrm{Var}(Z'_i)} + 2\delta \| Z'_i \|_\infty. " /></p>
<p>Given the inequality and Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-1">1</a>, we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D%28Z_i%29+%5Cleq+0+%2B+%282%5Cepsilon%29%282%5Calpha%29+%2B+%282%5Cdelta%29%282d%29+%3D+4%5Cepsilon+%5Calpha+%2B+8+%5Cdelta+d+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " class="latex" title="\displaystyle \mathop{\mathbb E}(Z_i) \leq 0 + (2\epsilon)(2\alpha) + (2\delta)(2d) = 4\epsilon \alpha + 8 \delta d . " /></p>
<p>The claim now follows by summing over all <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>The final claim says that, because <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> is accurate, the expected sum of the random variables <img src="https://s0.wp.com/latex.php?latex=%7BZ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_i}" class="latex" title="{Z_i}" /> is large.</p>
<blockquote>
<p><b>Claim 3</b> <em> <a name="clmmean-lb-3"></a> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%5Cgeq+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" class="latex" title="{\mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) \geq \frac{d}{3} - \alpha^2.}" /> </em></p>
</blockquote>
<p>The proof relies on the following key lemma, whose proof we omit.</p>
<blockquote>
<p><b>Lemma 6 (Fingerprinting Lemma [<a href="https://kamathematics.wordpress.com/feed/#BSU17">BSU17</a>])</b><em> <a name="lemfp"></a> If <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu+%5Cin+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu \in [\pm 1]}" class="latex" title="{\mu \in [\pm 1]}" /> is sampled uniformly, <img src="https://s0.wp.com/latex.php?latex=%7BX_1%2C%5Cdots%2CX_n+%5Cin+%5C%7B%5Cpm+1%5C%7D%5E%7Bn%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" class="latex" title="{X_1,\dots,X_n \in \{\pm 1\}^{n}}" /> are sampled independently with mean <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />, and <img src="https://s0.wp.com/latex.php?latex=%7Bf+%5Ccolon+%5C%7B%5Cpm+1%5C%7D%5En+%5Crightarrow+%5B%5Cpm+1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" class="latex" title="{f \colon \{\pm 1\}^n \rightarrow [\pm 1]}" /> is any function, then </em></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i+-+%5Cmu%29%29+%5Cgeq+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29%5E2%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " class="latex" title="\displaystyle \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^{n} (X_i - \mu)) \geq \frac{1}{3} - \mathop{\mathbb E}_{\mu,X}((f(X) - \mu)^2). " /></p>
<p> </p>
</blockquote>
<p>The lemma is somewhat technical, but for intuition, consider the case where <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Csum_%7Bi%7D+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X) = \frac{1}{n}\sum_{i} X_i}" class="latex" title="{f(X) = \frac{1}{n}\sum_{i} X_i}" /> is the empirical mean. In this case we have</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brcl%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%2CX%7D%28%28f%28X%29+-+%5Cmu%29+%5Ccdot+%5Csum_%7Bi%3D1%7D%5En+%28X_i+-+%5Cmu%29%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cfrac%7B1%7D%7Bn%7D+%5Csum_i+%5Cmathop%7B%5Cmathbb+E%7D_%7BX%7D%28+%28X_i+-+%5Cmu%29%5E2%29+%29+%3D%7B%7D+%5Cmathop%7B%5Cmathbb+E%7D_%7B%5Cmu%7D%28%5Cmathrm%7BVar%7D%28X_i%29%29+%3D+%5Cfrac%7B1%7D%7B3%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " class="latex" title="\displaystyle \begin{array}{rcl} \mathop{\mathbb E}_{\mu,X}((f(X) - \mu) \cdot \sum_{i=1}^n (X_i - \mu)) ={} \mathop{\mathbb E}_{\mu}(\frac{1}{n} \sum_i \mathop{\mathbb E}_{X}( (X_i - \mu)^2) ) ={} \mathop{\mathbb E}_{\mu}(\mathrm{Var}(X_i)) = \frac{1}{3}. \end{array} " /></p>
<p>The lemma says that, when <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" /> is sampled this way, then any modification of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> that reduces the correlation between <img src="https://s0.wp.com/latex.php?latex=%7Bf%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(X)}" class="latex" title="{f(X)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_i+X_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_i X_i}" class="latex" title="{\sum_i X_i}" /> will increase the mean-squared-error of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> proportionally.</p>
<p>We now prove Claim <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a>.</p>
<p><em>Proof:</em> We can apply the lemma to each coordinate of the estimate <img src="https://s0.wp.com/latex.php?latex=%7BM%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M(X)}" class="latex" title="{M(X)}" />.</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cbegin%7Barray%7D%7Brll%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+Z_i%29+%3D%7B%7D+%26%5Cmathop%7B%5Cmathbb+E%7D%28%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%5Cleft%5Clangle+M%28X%29+-+%5Cmu%2C+X_i+-+%5Cmu+%5Cright%5Crangle%29+%5C%5C+%3D%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5Ccdot+%5Csum_%7Bi%3D1%7D%5E%7Bn%7D+%28X_i%5Ej+-+%5Cmu%5Ej%29%29+%5C%5C+%5Cgeq%7B%7D+%26%5Csum_%7Bj%3D1%7D%5E%7Bd%7D+%5Cleft%28+%5Cfrac%7B1%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%28M%5Ej%28X%29+-+%5Cmu%5Ej%29%5E2%29+%5Cright%29+%5C%5C+%3D%7B%7D+%26%5Cfrac%7Bd%7D%7B3%7D+-+%5Cmathop%7B%5Cmathbb+E%7D%28%5C%7C+M%28X%29+-+%5Cmu+%5C%7C_2%5E2%29+%3D%7B%7D+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " class="latex" title="\displaystyle \begin{array}{rll} \mathop{\mathbb E}(\sum_{i=1}^{n} Z_i) ={} &amp;\mathop{\mathbb E}(\sum_{i=1}^{n} \left\langle M(X) - \mu, X_i - \mu \right\rangle) \\ ={} &amp;\sum_{j=1}^{d} \mathop{\mathbb E}((M^j(X) - \mu^j)\cdot \sum_{i=1}^{n} (X_i^j - \mu^j)) \\ \geq{} &amp;\sum_{j=1}^{d} \left( \frac{1}{3} - \mathop{\mathbb E}((M^j(X) - \mu^j)^2) \right) \\ ={} &amp;\frac{d}{3} - \mathop{\mathbb E}(\| M(X) - \mu \|_2^2) ={} \frac{d}{3} - \alpha^2. \end{array} " /></p>
<p>The inequality is Lemma <a href="https://kamathematics.wordpress.com/feed/#lemfp">6</a>. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>Combining Claims <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-2">2</a> and <a href="https://kamathematics.wordpress.com/feed/#clmmean-lb-3">3</a> gives</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+%5Cleq+4n%5Calpha+%5Cepsilon+%2B+8n+%5Cdelta+d.+%5C+%5C+%5C+%5C+%5C+%286%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" class="latex" title="\displaystyle \frac{d}{3} - \alpha^2 \leq 4n\alpha \epsilon + 8n \delta d. \ \ \ \ \ (6)" /></p>
<p>Now, if <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \geq \frac{d}{6}}" class="latex" title="{\alpha^2 \geq \frac{d}{6}}" /> then we’re done, so we’ll assume that <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cleq+%5Cfrac%7Bd%7D%7B6%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \leq \frac{d}{6}}" class="latex" title="{\alpha^2 \leq \frac{d}{6}}" />. Further, by our assumption on the value of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" />, <img src="https://s0.wp.com/latex.php?latex=%7B8n+%5Cdelta+d+%5Cleq+%5Cfrac%7Bd%7D%7B12%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{8n \delta d \leq \frac{d}{12}}" class="latex" title="{8n \delta d \leq \frac{d}{12}}" />. In this case we can rearrange terms and square both sides to obtain</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+%5Calpha%5E2+%5Cgeq%7B%7D+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B3%7D+-+%5Calpha%5E2+-+8+n%5Cdelta+d%5Cright%29%5E2+%5Cgeq+%5Cfrac%7B1%7D%7B16+%5Cepsilon%5E2+n%5E2%7D+%5Cleft%28%5Cfrac%7Bd%7D%7B12%7D%5Cright%29%5E2+%3D+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D.+%5C+%5C+%5C+%5C+%5C+%287%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" class="latex" title="\displaystyle \alpha^2 \geq{} \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{3} - \alpha^2 - 8 n\delta d\right)^2 \geq \frac{1}{16 \epsilon^2 n^2} \left(\frac{d}{12}\right)^2 = \frac{d^2}{2304 \epsilon^2 n^2}. \ \ \ \ \ (7)" /></p>
<p>Combining the two cases for <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2}" class="latex" title="{\alpha^2}" /> gives <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%5E2+%5Cgeq+%5Cmin%5C%7B+%5Cfrac%7Bd%7D%7B6%7D%2C+%5Cfrac%7Bd%5E2%7D%7B2304+%5Cepsilon%5E2+n%5E2%7D+%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" class="latex" title="{\alpha^2 \geq \min\{ \frac{d}{6}, \frac{d^2}{2304 \epsilon^2 n^2} \}}" />, as desired.</p>
<p><b>Bibliography</b></p>
<p>[BDRS18]<a name="BDRS18"></a> Mark Bun, Cynthia Dwork, Guy N. Rothblum, and Thomas Steinke. Composable and versatile privacy via truncated CDP. STOC ’18.</p>
<p>[BS16]<a name="BS16"></a> Mark Bun and Thomas Steinke. Concentrated differential privacy: Simplifications, extensions, and lower bounds. TCC ’16-B.</p>
<p>[BSU17]<a name="BSU17"></a> Mark Bun, Thomas Steinke, and Jonathan Ullman. Make up your mind: The price of online queries in differential privacy. SODA ’17.</p>
<p>[BUV14]<a name="BUV14"></a> Mark Bun, Jonathan Ullman, and Salil Vadhan. Fingerprinting codes and the price of approximate differential privacy. STOC ’14.</p>
<p>[CSS11]<a name="CSS11"></a> T-H Hubert Chan, Elaine Shi, and Dawn Song. Private and continual release of statistics. ACM Transactions on Information and System Security, 14(3):26, 2011.</p>
<p>[CWZ19]<a name="CWZ19"></a> T. Tony Cai, Yichen Wang, and Linjun Zhang. The cost of privacy: Optimal rates of convergence for parameter estimation with differential privacy. arXiv, 1902.04495, 2019.</p>
<p>[DMNS06]<a name="DMNS06"></a> Cynthia Dwork, Frank McSherry, Kobbi Nissim, and Adam Smith. Calibrating noise to sensitivity in private data analysis. TCC ’06.</p>
<p>[DNPR10]<a name="DNPR10"></a> Cynthia Dwork, Moni Naor, Toniann Pitassi, and Guy N. Rothblum. Differential privacy under continual observation. STOC ’10.</p>
<p>[DR16]<a name="DR16"></a> Cynthia Dwork and Guy N. Rothblum. Concentrated differential privacy. arXiv, 1603.01887, 2016.</p>
<p>[DRS19]<a name="DRS19"></a> Jinshuo Dong, Aaron Roth, and Weijie J. Su. Gaussian differential privacy. arXiv, 1905.02383, 2019.</p>
<p>[DSSU17]<a name="DSSU17"></a> Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman, and Salil Vadhan. Robust traceability from trace amounts. FOCS ’15.</p>
<p>[DSSUV15]<a name="DSSUV15"></a> Cynthia Dwork, Adam Smith, Thomas Steinke, and Jonathan Ullman. Exposed! a survey of attacks on private data. Annual Review of Statistics and Its Application, 4:61–84, 2017.</p>
<p>[FRY10]<a name="FRY10"></a> Stephen E. Fienberg, Alessandro Rinaldo, and Xiaolin Yang. Differential privacy and the risk-utility tradeoff for multi-dimensional contingency tables. PSD ’10.</p>
<p>[KLSU19]<a name="KLSU19"></a> Gautam Kamath, Jerry Li, Vikrant Singhal, and Jonathan Ullman. Privately learning high-dimensional distributions. COLT ’19.</p>
<p>[Mir17]<a name="Mir17"></a> Ilya Mironov. Rényi differential privacy. CSF ’17.</p>
<p>[SU17a]<a name="SU17a"></a> Thomas Steinke and Jonathan Ullman. Between pure and approximate differential privacy. Journal of Privacy and Confidentiality, 7(2), 2017.</p>
<p>[SU17b]<a name="SU17b"></a> Thomas Steinke and Jonathan Ullman. Tight lower bounds for differentially private selection. FOCS ’17.</p>
<p>[VS09]<a name="VS09"></a> Duy Vu and Aleksandra Slavković. Differential privacy for clinical trial data: Preliminary evaluations. ICDMW ’09.</p>


<p></p></div>







<p class="date">
by Gautam <a href="https://kamathematics.wordpress.com/2020/04/14/a-primer-on-private-statistics-part-i/"><span class="datestr">at April 14, 2020 02:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=43">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/">Friday, April 17 — Shachar Lovett from UC San Diego</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The third Foundations of Data Science virtual talk will take place next Friday, April 17th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Shachar Lovett</strong> from UC San Diego will speak about “<em>The power of asking more informative questions about the data</em>”.</p>



<p><strong>Abstract</strong>: Many supervised learning algorithms (such as deep learning) need a large collection of labelled data points in order to perform well. However, what is easy to get are large amounts of unlabelled data. Labeling data is an expensive procedure, as it usually needs to be done manually, often by a domain expert. Active learning provides a mechanism to bridge this gap. Active learning algorithms are given a large collection of unlabelled data points. They need to smartly choose a few data points to query their label. The goal is then to automatically infer the labels of many other data points.</p>



<p>In this talk, we will explore the option of giving active learning algorithms additional power, by allowing them to have richer interaction with the data. We will see how allowing for even simple types of queries, such as comparing two data points, can exponentially improve the number of queries needed in various settings. Along the way, we will see interesting connections to both geometry and combinatorics, and a surprising application to fine grained complexity.</p>



<p>Based on joint works with Daniel Kane, Shay Moran and Jiapeng Zhang.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/04/11/friday-april-17-shachar-lovett-from-uc-san-diego/"><span class="datestr">at April 11, 2020 08:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16921">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/04/10/nina-balcan-wins/">Nina Balcan Wins</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Congrats and More</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/10/nina-balcan-wins/unknown-137/" rel="attachment wp-att-16924"><img width="170" alt="" class="alignright  wp-image-16924" src="https://rjlipton.files.wordpress.com/2020/04/unknown.jpeg?w=170" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ CMU ]</font></td>
</tr>
</tbody>
</table>
<p>
Nina Balcan is a leading researcher in the theory of machine learning. Nina is at Carnegie-Mellon and was previously at Georgia Tech—it was a major loss to have her leave Tech.</p>
<p>
Today we applaud her winning the ACM Hopper Award.<br />
<span id="more-16921"></span></p>
<p>
ACM President Cherri Pancake <a href="https://www.ml.cmu.edu/news/news-archive/2020/april/machine-learning-professor-balcan-receives-acm-grace-hopper-award.html">says</a>: </p>
<blockquote><p><b> </b> <em> Although she is still in the early stages of her career, she has already established herself as the world leader in the theory of how AI systems can learn with limited supervision. More broadly, her work has realigned the foundations of machine learning, and consequently ushered in many new applications that have brought about leapfrog advances in this exciting area of artificial intelligence. </em>
</p></blockquote>
<p>
</p><p></p><h2> The Hopper Award </h2><p></p>
<p></p><p>
The ACM Grace Murray Hopper <a href="https://awards.acm.org/hopper/award-winners">Award</a> is given to: An outstanding young computer professional, on the basis of a single major contribution before the age of 35. Here are five of the most recent winners: </p>
<ul>
<li>
Constantinos Daskalakis, 	(<a href="https://awards.acm.org/award_winners/daskalakis_4121823">2018</a>)	 <p></p>
</li><li>
Michael Freedman, 		(<a href="https://awards.acm.org/award_winners/freedman_6665293">2018</a>)	 <p></p>
</li><li>
Amanda Randles, 		(<a href="https://awards.acm.org/award_winners/randles_0365390">2017</a>)	 <p></p>
</li><li>
Jeffrey Heer, 			(<a href="https://awards.acm.org/award_winners/heer_1520709">2016</a>)	 <p></p>
</li><li>
Brent Waters,			(<a href="https://awards.acm.org/award_winners/waters_3058089.cfm">2015</a>)
</li></ul>
<p>
</p><p></p><h2> Nina’s Contribution </h2><p></p>
<p></p><p>
The Hopper award says it is for a “single” major contribution. I believe that Nina is almost a disproof of this statement: I fail to see how she only did one major contribution. In fact, the <a href="https://awards.acm.org/hopper">citation</a> lists three. In any event I thought we might look at one of her top results on learning. It is a <a href="http://www.cs.cmu.edu/~ninamf/papers/agnostic-active.pdf">paper</a> from 2006 with over 400 citations. The ttile is “Agnostic Active Learning” and is joint with Alina Beygelzimer and John Langford.</p>
<p>
<em>Active learning</em> follows a classic idea in computer theory: Making a protocol interactive can often decrease the cost, and almost always makes the protocol more complex to understand. In active learning one is given unlabeled examples. As usual the goal is to classify the samples. However, as the samples are unlabelled, the learning can ask for labels for elected samples—this is the active part of the learning. As you might imagine asking for labels has a cost, so the learner strives to ask for the fewest labels possible. </p>
<p>
The savings can be large when the labels are perfect—that is, noise-free. In general it is much more complex to understand when active learning helps. Nina’s work found examples where noise can be tamed. Her award citation says:</p>
<blockquote><p><b> </b> <em> Balcan established performance guarantees for active learning that hold even in challenging cases when “noise” is present in the data. These guarantees hold under arbitrary forms of noise, that is, anything that distorts or corrupts the data. This can include anything from a blurry photo, a unit of data that is improperly labeled, meaningless information, or data that the algorithm cannot interpret. </em>
</p></blockquote>
<p></p><p>
See her papers for the details. </p>
<p>
</p><p></p><h2> Other Awards </h2><p></p>
<p></p><p>
There are various awards for computer scientists, many are from the ACM. Since Alan Perlis won the first Turing award, there have been 69 more winners. Only three have been women:</p>
<ul>
<li>
Shafi Goldwasser, (2012) <p></p>
</li><li>
Barbara Liskov, (2008) <p></p>
</li><li>
Frances Allen, (2006)
</li></ul>
<p>Here is another quote from the president of the ACM: </p>
<blockquote><p><b> </b> <em> We typically receive one woman nominee [for the Turing Award] every five years. It’s very disturbing. </em>
</p></blockquote>
<p></p><p>
The number of nominations is too small. There are plenty of strong women candidates for the Turing award, and for other awards. We need to do a better job. See <a href="https://slate.com/technology/2020/01/turing-award-acm-women-recipients.html">this</a> for more thoughts on this issue.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We do not know about the situation with nominations for the Hopper Award. Nina is only the seventh woman to win since 1971, but four of the last ten Hopper Award winners have been women. How can we recognize more women under 35 who are doing great work?</p>
<p>
Again we congratulate Nina Balcan on her richly deserved honor. </p>
<p>[Fixed typo “Congrats” ]</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/04/10/nina-balcan-wins/"><span class="datestr">at April 10, 2020 01:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7686">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/04/09/experts-shmexperts/">Experts shmexperts</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>(If you’re not already following him, I highly recommend reading <a href="https://lucatrevisan.wordpress.com/">Luca Trevisan’s dispatches from Milan</a>, much more interesting than what I write below.)</em></p>



<p>On the topic of my <a href="https://windowsontheory.org/2020/04/04/in-defense-of-expertise/">last post</a>, Ross Douthat writes in the New York Times that <a href="https://www.nytimes.com/2020/04/07/opinion/coronavirus-science-experts.html?smid=fb-share&amp;fbclid=IwAR1KIcMblvNsaKaAQTh2vCpB2yARYL8O5TVy9j3ZxSqsXsRAMK2GGcvF81o">“In the fog of coronavirus, there are no experts”</a>, even citing <a href="https://www.scottaaronson.com/blog/?p=4695">Scott Aaronson’s post</a>. Both Aaronson and Douthat make the point that the COVID-19 crisis is so surprising and unprecedented, and experts were so much in the dark, that there is no reason to trust them over non expert “common sense” or “armchair epidemiologists”. <br /><br />It’s true that the “expert models” have significant uncertainty, hardwired constants, noisy data, and dubious assumptions. It is also true that many countries (especially those that didn’t learn from the 2003 SARS epidemic) bungled their initial response. But do we really need to challenge the notion of expertise itself? To what extent was this pandemic not predicted by experts or progressed in ways defying their expectations?</p>



<p>Here is what some of these experts and institutions were saying in the recent past:</p>



<p><em>“The thing I’m most concerned about … is the emergence of a new virus that the body doesn’t have any background experience with, that is very transmissible, highly transmissible from person to person, and has a high degree of morbidity and mortality … a respiratory illness that can spread even before someone is so sick that you want to keep them in bed.”</em>  <a href="https://fivethirtyeight.com/features/dr-fauci-has-been-dreading-a-pandemic-like-covid-19-for-years/">Dr. Anthoni Fauci, 2019</a>.</p>



<p><em>“High-impact respiratory pathogens … pose particular global risks … [they] are spread via respiratory droplets; they can infect a large number of people very quickly and with today’s transportation infrastructure, move rapidly across multiple geographies. … There is insufficient R&amp;D investment and planning for innovative vaccine development and manufacture, broad-spectrum antivirals, … In addition, such a pandemic requires advance planning across multiple sectors … Epidemic control costs would completely overwhelm the current financing arrangements for emergency response.” </em><a href="https://apps.who.int/gpmb/assets/annual_report/GPMB_annualreport_2019.pdf">WHO world at risk report</a>, 2019.</p>



<p><em>“respiratory transmission …. is the transmission route posing the greatest pandemic risk   … [since it] can occur with coughing or simply breathing (in aerosol transmission), making containment much more challenging. …  If a pathogen is capable of causing asymptomatic or mildly symptomatic infections that either do not or only minimally interrupt activities of daily living, many individuals may be exposed. Viruses that cause the common cold, including coronaviruses, have this attribute.”</em> <a href="https://apps.who.int/gpmb/assets/thematic_papers/tr-6.pdf">JHU report</a>, 2019.</p>



<p>As an experiment, I also tried to compare the response of experts and “contrarians” in real time as the novel coronavirus was discovered, trying to see if it’s really the case that, as Douthat says, <em>“up until mid-March you were better off trusting the alarmists of anonymous Twitter than the official pronouncements from the custodians of public health”</em>.  I chose both experts and contrarians that are active on Twitter. I was initially planning to look at several people but due to laziness am just taking Imperial college’s <a href="https://twitter.com/Imperial_JIDEA/">J-IDEA institute</a> for the expert, and <a href="https://twitter.com/robinhanson">Robin Hanson</a> for the contrarian.  I also looked at <a href="https://twitter.com/DouthatNYT">Douthat’s twitter feed</a>, to see if he followed his own advice. Initially I thought I would go all the way to March but have no time so just looked at the period from January 1 till February 14th. I leave any conclusions to the reader.</p>



<h2><strong>January 1-19:</strong> </h2>



<p>(Context: novel coronavirus confirmed in Wuhan, initially unclear if there is human to human transmission – this was confirmed by China on January 20 though suspected before.)</p>



<p>Here is one of the many tweets by Imperial from this period:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Substantial human to human transmission cannot be ruled out – size of novel <a href="https://twitter.com/hashtag/coronavirus?src=hash&amp;ref_src=twsrc%5Etfw">#coronavirus</a> in Wuhan outbreak likely over 1700 cases. <a href="https://twitter.com/MailOnline?ref_src=twsrc%5Etfw">@MailOnline</a> on <a href="https://twitter.com/MRC_Outbreak?ref_src=twsrc%5Etfw">@MRC_Outbreak</a>, <a href="https://twitter.com/Imperial_JIDEA?ref_src=twsrc%5Etfw">@Imperial_JIDEA</a>, <a href="https://twitter.com/imperialcollege?ref_src=twsrc%5Etfw">@imperialcollege</a> report today.<a href="https://t.co/Iq4hBmx4JL">https://t.co/Iq4hBmx4JL</a> <a href="https://t.co/3n5OMPYNdL">pic.twitter.com/3n5OMPYNdL</a></p>— J-IDEA (@Imperial_JIDEA) <a href="https://twitter.com/Imperial_JIDEA/status/1218295967683874816?ref_src=twsrc%5Etfw">January 17, 2020</a></blockquote></div>
</div></figure>



<p>I didn’t see any tweets from Hanson or Douthat on this topic.</p>



<h2><strong>January 20-31:</strong> </h2>



<p>(Context: first confirmed cases in several countries, including the US, WHO declares emergency in Jan 30, US restricts travel from China on Jan 31. By then there are about 10K confirmed cases and 213 deaths worldwide.)</p>



<p>On January 25th Imperial college estimated the novel coronavirus “R0” parameter as 2.6:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">UPDATE: Transmissibility estimates of <a href="https://twitter.com/hashtag/coronavirus?src=hash&amp;ref_src=twsrc%5Etfw">#coronavirus</a> <a href="https://twitter.com/hashtag/2019nCoV?src=hash&amp;ref_src=twsrc%5Etfw">#2019nCoV</a> at 2.6<br /><br />Identification &amp; testing potential cases to be as extensive as permitted by healthcare &amp; testing capacity<br /><br /><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f530.png" alt="🔰" style="height: 1em;" class="wp-smiley" /><a href="https://t.co/7zpZzG2JOs">https://t.co/7zpZzG2JOs</a><a href="https://twitter.com/neil_ferguson?ref_src=twsrc%5Etfw">@neil_ferguson</a> <a href="https://twitter.com/dr_anne_cori?ref_src=twsrc%5Etfw">@dr_anne_cori</a> <a href="https://twitter.com/SRileyIDD?ref_src=twsrc%5Etfw">@SRileyIDD</a> <a href="https://twitter.com/MarcBaguelin?ref_src=twsrc%5Etfw">@MarcBaguelin</a> <a href="https://twitter.com/IlariaDorigatti?ref_src=twsrc%5Etfw">@IlariaDorigatti</a> <a href="https://t.co/nmhjWsWpfa">pic.twitter.com/nmhjWsWpfa</a></p>— J-IDEA (@Imperial_JIDEA) <a href="https://twitter.com/Imperial_JIDEA/status/1221033477824532480?ref_src=twsrc%5Etfw">January 25, 2020</a></blockquote></div>
</div></figure>



<p>Hanson tweeted approvingly about China’s response and that this situation might help the “more authoritarian” U.S. presidential candidate:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Seems to me the "parasite stress hypothesis of authoritarianism" suggests that if this China Coronavirus ends up being a big deal, that would push US voters toward the more authoritarian presidential candidate. Which one is that?<a href="https://t.co/cWmV2WkroJ">https://t.co/cWmV2WkroJ</a><a href="https://t.co/ysNiZIkfYD">https://t.co/ysNiZIkfYD</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1222184281050697728?ref_src=twsrc%5Etfw">January 28, 2020</a></blockquote></div>
</div></figure>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">I doubt we in US would be as fast to restrict travel in the face of such a still-small pandemic. If so, China is to be praised for their better abilities to coordinate in the face of such threats.<a href="https://t.co/Lro5kGVTvz">https://t.co/Lro5kGVTvz</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1220704857922985984?ref_src=twsrc%5Etfw">January 24, 2020</a></blockquote></div>
</div></figure>



<p>Still no tweet from Douthat on this topic though he did say in January 29th that compared to issues in the past the U.S.’s problems in the 2020’s are “problem of decadence” rather than any crisis like the late 1970’s:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Belated, yes, America's problems in '20 are problems of decadence rather than late-1970s crisis, and economically '16 might have been a better year to gamble on Bernie …<a href="https://t.co/3DaHWXC1k0">https://t.co/3DaHWXC1k0</a></p>— Ross Douthat (@DouthatNYT) <a href="https://twitter.com/DouthatNYT/status/1222566830642024448?ref_src=twsrc%5Etfw">January 29, 2020</a></blockquote></div>
</div></figure>



<h2><strong>February 1-14: </strong></h2>



<p>(Context: Diamond princess cruise ship quaranteed, disease gets COVID-19 official name, first death in Europe)</p>



<p>Imperial continues to tweet extensively, including the following early estimates of the case fatality rates:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">UPDATE: <a href="https://twitter.com/hashtag/coronavirus?src=hash&amp;ref_src=twsrc%5Etfw">#coronavirus</a> <a href="https://twitter.com/hashtag/2019nCoV?src=hash&amp;ref_src=twsrc%5Etfw">#2019nCoV</a> Severity<br /><br /><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/27a1.png" alt="➡" style="height: 1em;" class="wp-smiley" />Estimated fatality ratio for infections 1%<br /><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/27a1.png" alt="➡" style="height: 1em;" class="wp-smiley" />Estimated CFR for travellers outside mainland China (mix severe &amp; milder cases) 1%-5%<br /><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/27a1.png" alt="➡" style="height: 1em;" class="wp-smiley" />Estimated CFR for detected cases in Hubei (severe cases) 18%<br /><br /><img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f530.png" alt="🔰" style="height: 1em;" class="wp-smiley" /><a href="https://t.co/7zpZzG2JOs">https://t.co/7zpZzG2JOs</a> <a href="https://t.co/gtmzq1vOhq">pic.twitter.com/gtmzq1vOhq</a></p>— J-IDEA (@Imperial_JIDEA) <a href="https://twitter.com/Imperial_JIDEA/status/1226766907396718597?ref_src=twsrc%5Etfw">February 10, 2020</a></blockquote></div>
</div></figure>



<p>Robin Hanson correctly realizes this is going to spread wide:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Look at this table and tell me is isn't all over China now, beyond recall: <a href="https://t.co/Ne9UgDlx9G">pic.twitter.com/Ne9UgDlx9G</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1227701511469387777?ref_src=twsrc%5Etfw">February 12, 2020</a></blockquote></div>
</div></figure>



<p>Hanson tweets quite a lot about this, including potential social implications. Up to February 13th there is nothing too “contrarian” at this point, but also no information that could not be gotten from the experts:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">My poll so far estimates ~40% chance that <a href="https://twitter.com/hashtag/COVID19?src=hash&amp;ref_src=twsrc%5Etfw">#COVID19</a> infects large % of world. So seems worth it for social scientists to ask themselves: using social sci, what non-obvious predictions can we make about social outcomes in that case?</p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1227656071021334528?ref_src=twsrc%5Etfw">February 12, 2020</a></blockquote></div>
</div></figure>



<p>In February 14 Hansons makes a very contrarian position when he proposes “controlled infection” as a solution:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">Though it is a disturbing &amp; extreme option, we should seriously consider deliberately infecting folks with coronavirus, to spread out the number of critically ill people over time, and to ensure that critical infrastructure remains available to help sick. <a href="https://t.co/giIfo8z8v0">https://t.co/giIfo8z8v0</a></p>— Robin Hanson (@robinhanson) <a href="https://twitter.com/robinhanson/status/1228400896507367424?ref_src=twsrc%5Etfw">February 14, 2020</a></blockquote></div>
</div></figure>



<p>To the anticipated “you first” objection he responds <em>“I proposed compensating volunteers via cash or medical priority for associates, &amp; I’d seriously consider such offers.”</em>.  He doesn’t mention that he is much less strapped for cash than some of the would be “volunteers”. </p>



<p>Still no tweet from Douthat about COVID-19 though he does write that we live in an “age of decadence”:</p>



<figure class="wp-block-embed-twitter wp-block-embed is-type-rich"><div class="wp-block-embed__wrapper">
<div class="embed-twitter"><blockquote class="twitter-tweet"><p lang="en" dir="ltr">My Sunday essay excerpts my new book: The Age of Decadence: <a href="https://t.co/3cvLqNVQpv">https://t.co/3cvLqNVQpv</a></p>— Ross Douthat (@DouthatNYT) <a href="https://twitter.com/DouthatNYT/status/1225908487198330880?ref_src=twsrc%5Etfw">February 7, 2020</a></blockquote></div>
</div></figure>



<p></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/04/09/experts-shmexperts/"><span class="datestr">at April 09, 2020 07:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/044">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/044">TR20-044 |  Cryptography from Information Loss | 

	Marshall Ball, 

	Elette Boyle, 

	Akshay Degwekar, 

	Apoorvaa Deshpande, 

	Alon Rosen, 

	Vinod Vaikuntanathan, 

	Prashant Vasudevan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Reductions between problems, the mainstay of theoretical computer science, efficiently map an instance of one problem to an instance of another in such a way that solving the latter allows solving the former. The subject of this work is ``lossy'' reductions, where the reduction loses some information about the input instance. We show that such reductions, when they exist, have interesting and powerful consequences for lifting hardness into ``useful'' hardness, namely cryptography.

Our first, conceptual, contribution is a definition of lossy reductions in the language of mutual information. Roughly speaking, our definition says that a reduction $C$ is $t$-lossy if, for any distribution $X$ over its inputs, the mutual information $I(X;C(X)) \leq t$. Our treatment generalizes a variety of seemingly related but distinct notions such as worst-case to average-case reductions, randomized encodings (Ishai and Kushilevitz, FOCS 2000), homomorphic computations (Gentry, STOC 2009), and instance compression (Harnik and Naor, FOCS 2006).

We then proceed to show several consequences of lossy reductions:

1. We say that a language $L$ has an $f$-reduction to a language $L'$ for a Boolean function $f$ if there is a (randomized) polynomial-time algorithm $C$ that takes an $m$-tuple of strings $X = (x_1,\ldots,x_m)$, with each $x_i\in\{0,1\}^n$, and outputs a string $z$ such that with high probability, L'(z) = f(L(x_1),L(x_2),...,L(x_m))
        
2. Suppose a language $L$ has an $f$-reduction $C$ to $L'$ that is $t$-lossy. Our first result is that one-way functions exist if $L$ is worst-case hard and one of the following conditions holds:
   - $f$ is the OR function, $t \leq m/100$, and $L'$ is the same as $L$
   - $f$ is the Majority function, and $t \leq m/100$
   - $f$ is the OR function, $t \leq O(m\log{n})$, and the reduction has no error

This improves on the implications that follow from combining (Drucker, FOCS 2012) with (Ostrovsky and Wigderson, ISTCS 1993) that result in auxiliary-input one-way functions.

3. Our second result is about the stronger notion of $t$-compressing $f$-reductions -- reductions that only output $t$ bits. We show that if there is an average-case hard language $L$ that has a $t$-compressing Majority reduction to some language for $t=m/100$, then there exist collision-resistant hash functions.

This improves on the result of (Harnik and Naor, STOC 2006), whose starting point is a cryptographic primitive (namely, one-way functions) rather than average-case hardness, and whose assumption is a compressing OR-reduction of SAT (which is now known to be false unless the polynomial hierarchy collapses).

Along the way, we define a non-standard one-sided notion of average-case hardness, which is the notion of hardness used in the second result above, that may be of independent interest.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/044"><span class="datestr">at April 08, 2020 07:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3470">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2020/04/07/call-for-papers-the-2nd-workshop-on-behavioral-economics-and-computation/">Call for Papers: The 2nd Workshop on Behavioral Economics and Computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<div><span><a href="https://sites.google.com/view/behavioralec2020/">https://sites.google.com/view/behavioralec2020/</a><br />
July 17, 2020, Budapest, Hungary<br />
At the 21st ACM Conference on Economics and Computation (ACM EC ’20)</span></div>
<div><span>**In the event the in-person conference does not happen due to the COVID-19 pandemic, we will hold the workshop virtually.</span></div>
<div></div>
<div><strong><span style="color: #ff0000;">SUBMISSIONS DUE May 18, 2020, 11:59pm PDT.</span></strong></div>
<div></div>
<div></div>
<div><strong>Call for Papers: the 2nd Workshop on Behavioral Economics and Computation</strong></div>
<div></div>
<div><span>We solicit research contributions and participants for the 2nd Workshop on Behavioral Economics and Computation, to be held in conjunction with the Twenty-First ACM Conference on Economics and Computation (ACM EC ’20). </span></div>
<div></div>
<div><span>Based on the successful workshop last year, we aim to bring together again researchers and practitioners from diverse subareas of EC, who are interested in the intersection of human economic behavior and computation, to share new results and to discuss future directions for behavioral research related to economics and computation. It will be a full-day workshop, and will feature invited speakers, contributed paper presentations and a panel discussion. </span></div>
<div></div>
<div><span>The gap between rationality-based analysis that assumes utility-maximizing agents and actual human behavior in the real world has been well recognized in economics, psychology and other social sciences. In recent years, there has been growing interest in conducting behavioral research across many of the sub-areas related to economics and computation to address this gap. In one direction, some of these studies leverage insights on human decision making from the behavioral economics and psychology literature to study economic and computational systems with human users. In the other direction, computational tools are used to study and gain insights on human behavior and a data-driven approach is used to learn behavior models from user-generated data.</span></div>
<div><span><br />
The 2nd Behavioral EC workshop aims to provide a venue for researchers and practitioners from diverse fields, including but not limited to computer science, economics, psychology and sociology, to exchange ideas related to behavioral research in economics and computation. In addition to sharing new results, we hope the workshop will foster a lively discussion of future directions and methodologies for behavioral research related to economics and computation as well as fruitful cross-pollination of behavioral economics, cognitive psychology and computer science. </span></div>
<div><span><br />
We welcome studies at the intersection of economic behavior and computation from a rich set of theoretical, experimental and empirical perspectives. The topics of interest for the workshop are behavioral research in all settings covered by EC, including but not limited to:</span></div>
<ul>
<li><span>Behavioral mechanism design and applied mechanism design</span></li>
<li><span>Boundedly-rational models of economic decision making</span></li>
<li><span>Empirical studies of human economic behavior</span></li>
<li><span>Model evaluation and selection based on behavioral data</span></li>
<li><span>Data-driven modelling</span></li>
<li><span>Online prediction markets, online experiments, and crowdsourcing platforms</span></li>
<li><span>Hybrid human-machine systems</span></li>
<li><span>Models and experiments about social considerations (e.g. fairness and trust) in decision making</span></li>
<li><span>Methods for behavioral EC: information aggregation, probability elicitation, quality control</span></li>
</ul>
<div></div>
<div></div>
<div><span><strong>Submission Instructions</strong><br />
</span></div>
<div></div>
<div><span style="color: #ff0000;">Submission deadline: May 18, 2020, 11:59pm PDT.</span></div>
<div><span style="color: #ff0000;">Notification: June 11, 2020</span></div>
<div></div>
<div><span>All submissions will be peer reviewed. We will give priority to new (unpublished) research papers but will also consider ongoing research and recently published papers that may be of interest to the workshop audience. For submissions of published papers, authors must clearly state the venue of publication. Position papers and panel discussion proposals are also welcome. Papers will be reviewed for relevance, significance, originality, research contribution, and likelihood to catalyze discussion. </span></div>
<div><span><br />
Submissions can be in any format and any length. We recommend the EC submission format. </span><span>The workshop will not have archival proceedings but will post accepted papers on the workshop website. At least one author of each accepted paper will be expected to attend and present their findings at the workshop.<p></p>
<p></p></span></div>
<div><span>Submissions should be uploaded to Easychair no later than May 18th, 2020, 11:59pm PDT. </span></div>
<div></div>
<div></div>
<div><span><strong>Organizing Committee</strong><br />
</span></div>
<div><span><br />
Yiling Chen, Harvard University<br />
Dan Goldstein, Microsoft Research<br />
Kevin Leyton-Brown, University of British Columbia<br />
Shengwu Li, Harvard University<br />
Gali Noti, Hebrew University</span></div>
<div></div>
<div><span><br />
<strong>More Information</strong><br />
</span></div>
<div><span><br />
For more information or questions, visit the workshop website:<br />
<a href="https://sites.google.com/view/behavioralec2020/">https://sites.google.com/view/behavioralec2020/</a><br />
or email the organizing committee: <a href="mailto:behavioralec2020@easychair.org">behavioralec2020@easychair.org</a></span></div>
			<div id="atatags-26942-5e8be264da029"></div></div>







<p class="date">
by Kevin Leyton-Brown <a href="https://agtb.wordpress.com/2020/04/07/call-for-papers-the-2nd-workshop-on-behavioral-economics-and-computation/"><span class="datestr">at April 07, 2020 02:15 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/04/06/professorship-in-theoretical-computer-science-at-university-of-copenhagen-apply-by-may-24-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/04/06/professorship-in-theoretical-computer-science-at-university-of-copenhagen-apply-by-may-24-2020/">Professorship in Theoretical Computer Science at University of Copenhagen (apply by May 24, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>University of Copenhagen is seeking candidates for a full professorship in Theoretical Computer Science. More specifically, we are inviting exceptional candidates from the broad fields of algorithms, complexity, and cryptography including privacy. The application deadline is May 24, 2020. Enquiries are welcome and may be sent to Mikkel Thorup (mthorup@di.ku.dk) or Mads Nielsen (madsn@di.ku.dk).</p>
<p>Website: <a href="https://candidate.hr-manager.net/ApplicationInit.aspx/?cid=1307&amp;departmentId=18971&amp;ProjectId=151668">https://candidate.hr-manager.net/ApplicationInit.aspx/?cid=1307&amp;departmentId=18971&amp;ProjectId=151668</a><br />
Email: mthorup@di.ku.dk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/04/06/professorship-in-theoretical-computer-science-at-university-of-copenhagen-apply-by-may-24-2020/"><span class="datestr">at April 06, 2020 07:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16911">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/04/05/not-as-easy-as-abc/">Not As Easy As ABC</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><em>Is the claimed proof of the ABC conjecture correct?</em><br />
<font color="#000000"></font></p><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/05/not-as-easy-as-abc/screen-shot-2020-04-05-at-8-22-38-pm/" rel="attachment wp-att-16914"><img src="https://rjlipton.files.wordpress.com/2020/04/screen-shot-2020-04-05-at-8.22.38-pm.png?w=300&amp;h=238" alt="" width="300" class="alignright size-medium wp-image-16914" height="238" /></a><p></p>
<p>
<font color="#0044cc">
</font></p></td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">[ Photo courtesy of Kyodo University ]</font></td>
</tr>
</tbody>
</table>
<p>
Shinichi Mochizuki is about to have his proof of the ABC conjecture <a href="https://futurism.com/the-byte/mathematicians-shocked-paper-published">published</a> in a journal. The proof needs more than a ream of paper—that is, it is over 500 pages long. </p>
<p>
Today I thought we would discuss his claimed proof of this famous conjecture.</p>
<p>
The decision to published is also discussed in an <a href="https://www.nature.com/articles/d41586-020-00998-2">article</a> in <em>Nature</em>. Some of the discussion we have seen <a href="https://www.math.columbia.edu/~woit/wordpress/?p=11709">elsewhere</a> has been about personal factors. We will just comment briefly on the problem, the proof, and how to tell if a proof has problems. </p>
<p>
</p><p></p><h2> The Problem </h2><p></p>
<p></p><p>
Number theory is hard because addition and multiplication do not play well together. Adding numbers is not too complex by its self; multiplication by its self is also not too hard. For those into formal logic the theory of addition for example is decidable. So in principle there is no hard problem that only uses addition. None. A similar point follows for multiplication. </p>
<p>
But together addition and multiplication is hard. Of course Kurt Gödel proved that the formal theory of arithmetic is hard. It is not complete, for example. There must be statements about addition and multiplication that are unprovable in Peano Arithmetic. </p>
<p>
The ABC conjecture states a property that is between addition and multiplication. Suppose that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A+%2B+B+%3D+C%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  A + B = C, " class="latex" title="\displaystyle  A + B = C, " /></p>
<p>for some integers <img src="https://s0.wp.com/latex.php?latex=%7B1+%5Cle+A+%5Cle+B+%5Cle+C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1 \le A \le B \le C}" class="latex" title="{1 \le A \le B \le C}" />. Then 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+ABC+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le ABC " class="latex" title="\displaystyle  C \le ABC " /></p>
<p>is trivial. The ABC conjecture says that one can do better and get 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+F%28ABC%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le F(ABC), " class="latex" title="\displaystyle  C \le F(ABC), " /></p>
<p>for a function <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(X)}" class="latex" title="{F(X)}" /> that is sometimes much smaller than <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. The function <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(X)}" class="latex" title="{F(X)}" /> depends not on the size of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> but on the multiplicative structure of <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. That is the function depends on the multiplicative structure of the integers. Note, the bound 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+ABC+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le ABC " class="latex" title="\displaystyle  C \le ABC " /></p>
<p>only needed that <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B,C}" class="latex" title="{A,B,C}" /> were numbers larger than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. The stronger bound 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+F%28ABC%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le F(ABC), " class="latex" title="\displaystyle  C \le F(ABC), " /></p>
<p>relies essentially on the finer structure of the integers. </p>
<p>
Roughly <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(X)}" class="latex" title="{F(X)}" /> operates as follows: Compute all the primes <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> that divide <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" /> be the product of all these primes. Then <img src="https://s0.wp.com/latex.php?latex=%7BF%28X%29+%5Cle+Q%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(X) \le Q^{2}}" class="latex" title="{F(X) \le Q^{2}}" /> works: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+Q%5E%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le Q^{2}. " class="latex" title="\displaystyle  C \le Q^{2}. " /></p>
<p>The key point is: <i>Even if <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7B100%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^{100}}" class="latex" title="{p^{100}}" />, for example, divides <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" />, we only include <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> in the product <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" />.</i> This is where the savings all comes from. This is why the ABC conjecture is hard: repeated factors are thrown away.</p>
<p>
Well not exactly, there is a constant missing here, the bound is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+%5Calpha+Q%5E%7B2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le \alpha Q^{2} " class="latex" title="\displaystyle  C \le \alpha Q^{2} " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha&gt;0}" class="latex" title="{\alpha&gt;0}" /> is a universal constant. We can replace <img src="https://s0.wp.com/latex.php?latex=%7BQ%5E%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q^{2}}" class="latex" title="{Q^{2}}" /> by a smaller number—the precise statement can be found <a href="https://en.wikipedia.org/wiki/Abc_conjecture">here</a>. This is the ABC conjecture. </p>
<p>
The point here is that in many cases <img src="https://s0.wp.com/latex.php?latex=%7BF%28ABC%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{F(ABC)}" class="latex" title="{F(ABC)}" /> is vastly smaller than <img src="https://s0.wp.com/latex.php?latex=%7BABC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ABC}" class="latex" title="{ABC}" /> and so that inequality 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+F%28ABC%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le F(ABC), " class="latex" title="\displaystyle  C \le F(ABC), " /></p>
<p>is much better than the obvious one of 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++C+%5Cle+ABC.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  C \le ABC. " class="latex" title="\displaystyle  C \le ABC. " /></p>
<p>For example, suppose that one wishes to know if 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++5%5E%7Bz%7D+%3D+2%5E%7Bx%7D+%2B+3%5E%7By%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  5^{z} = 2^{x} + 3^{y}, " class="latex" title="\displaystyle  5^{z} = 2^{x} + 3^{y}, " /></p>
<p>is possible. The ABC conjecture shows that this cannot happen for <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> large enough. Note 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F%282%5E%7Bx%7D+3%5E%7By%7D+5%5E%7Bz%7D%29+%3D+30+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F(2^{x} 3^{y} 5^{z}) = 30 " class="latex" title="\displaystyle  F(2^{x} 3^{y} 5^{z}) = 30 " /></p>
<p>for positive integers <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x,y,z}" class="latex" title="{x,y,z}" />.</p>
<p>
</p><p></p><h2> Is He Correct? </h2><p></p>
<p></p><p>
Eight years ago Mochizuki announced his <a href="http://www.kurims.kyoto-u.ac.jp/~motizuki/papers-english.html">proof</a>. Now it is about to be published in a journal. He is famous for work in part of number theory. He solved a major open problem there years ago. This gave him instant credibility and so his claim of solving the ABC conjecture was taken seriously. </p>
<p>
For example, one of his papers is <a href="https://www.math.uni-bielefeld.de/documenta/vol-kato/mochizuki.dm.pdf">The Absolute Anabelian Geometry of Canonical Curves</a>. The paper says: </p>
<blockquote><p><b> </b> <em> How much information about the isomorphism class of the variety <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> is contained in the knowledge of the étale fundamental group? </em>
</p></blockquote>
<p></p><p>
A glance at this paper shows that it is for specialists only. But it does seem to be math of the type that we see all the time. And indeed the proof in his paper is long believed to be correct. This is in sharp contrast to his proof of the ABC conjecture. </p>
<p>
</p><p></p><h2> Indicators of Correctness </h2><p></p>
<p></p><p>
The question is: Are there ways to detect if a proof is (in)correct? Especially <a href="https://en.wikipedia.org/wiki/List_of_long_mathematical_proofs">long</a> proofs? Are there ways that rise above just checking the proof line by line? By the way:</p>
<blockquote><p><b> </b> <em> The length of unusually long proofs has increased with time. As a rough rule of thumb, 100 pages in 1900, or 200 pages in 1950, or 500 pages in 2000 is unusually long for a proof. </em>
</p></blockquote>
<p></p><p>
There are some ways to gain confidence. Here are some in my opinion that are useful.</p>
<ol>
<li>
Is the proof understood by the experts? <p></p>
</li><li>
Has the proof been generalized? <p></p>
</li><li>
Have new proofs been found? <p></p>
</li><li>
Does the proof have a clear roadmap?
</li></ol>
<p>
The answer to the first question (1) seems to be no for the ABC proof. At least two world experts have raised concerns—see this <a href="https://www.quantamagazine.org/titans-of-mathematics-clash-over-epic-proof-of-abc-conjecture-20180920/">article</a> in <em>Quanta</em>—that appear serious. The proof has not yet been generalized. This is an important milestone for any proof. Andrew Wiles famous proof that the Fermat equation 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7Bp%7D+%2B+y%5E%7Bp%7D+%3D+z%5E%7Bp%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^{p} + y^{p} = z^{p}, " class="latex" title="\displaystyle  x^{p} + y^{p} = z^{p}, " /></p>
<p>has no solutions in integers for <img src="https://s0.wp.com/latex.php?latex=%7Bxyz+%5Cneq+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{xyz \neq 0}" class="latex" title="{xyz \neq 0}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bp+%5Cge+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p \ge 3}" class="latex" title="{p \ge 3}" /> a prime has been extended. This certainly adds confidence to our belief that it is correct.</p>
<p>
Important problems eventually get other proofs. This can take some time. But there is almost always success in finding new and different proofs. Probably it is way too early for the ABC proof, but we can hope. Finally the roadmap issue: This means does the argument used have a nice logical flow. Proofs, even long proofs, often have a logic flow that is not too complex. A proof that says: Suppose there is a object <img src="https://s0.wp.com/latex.php?latex=%7BX%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X}" class="latex" title="{X}" /> with this property. Then it follows that there must be an object <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\dots}" class="latex" title="{\dots}" /> Is more believable than one with a much more convoluted logical flow. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Ivan Fesenko of Nottingham has written an <a href="https://www.maths.nottingham.ac.uk/plp/pmzibf/rpp.pdf">essay</a> about the proof and the decision to publish. Among factors he notes is “the potential lack of mathematical infrastructure and language to communicate novel concepts and methods”—noting the steep learning curve of trying to grasp the language and framework in which Mochizuki has set his proof. Will the decision to publish change the dynamics of this effort?</p>
<p>[Fixed typo]</p></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/04/05/not-as-easy-as-abc/"><span class="datestr">at April 06, 2020 02:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/043">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/043">TR20-043 |  A combinatorial MA-complete problem | 

	Dorit Aharonov, 

	Alex Bredariol Grilo</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Despite the interest in the complexity class MA, the randomized analog of NP, there is just a couple of known natural (promise-)MA-complete problems, the first due to Bravyi and Terhal (SIAM Journal of Computing 2009) and the second due to Bravyi (Quantum Information and Computation 2015). Surprisingly, both problems are stated using terminology from quantum computation. This fact makes it hard for classical complexity theorists to study these problems, and prevents possible progress, e.g., on the important question of derandomizing MA.

In this note we define a natural combinatorial problem called SetCSP and prove its MA-completeness. The problem generalizes the constraint satisfaction problem (CSP) into constraints on sets of strings. This note is, in fact, a combination of previously known works: the brilliant work of Bravyi and Terhal, together with an observation made in our previous work (Aharonov and Grilo, FOCS 2019) that a restricted case of the Bravyi and Terhal's MA complete problem (namely, the uniform case) is already complete, and moreover, that this restricted case can be stated using a classical, combinatorial description. Here we flesh out this observation.

This note, along with a translation of the main result of Aharonov and Grilo to the SetCSP language, implies that finding a gap-amplification procedure for SetCSP problems (namely a generalization to SetCSPs of the gap-amplification used in Dinur's PCP proof) would imply MA=NP. This would provide a resolution of the major problem of derandomizing MA; in fact, the problem of finding gap-amplification for SetCSP is in fact equivalent to the MA=NP problem.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/043"><span class="datestr">at April 05, 2020 07:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=413">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/04/04/tcs-talk-wednesday-april-8-ramon-van-handel-princeton/">TCS+ talk: Wednesday, April 8 — Ramon van Handel, Princeton</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, April 8th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Ramon van Handel</strong> from Princeton will speak about how “<em>Rademacher type and Enflo type coincide</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. (The link will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to join, until the maximum capacity of 300 seats is reached.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: In Banach space theory, Rademacher type is an important invariant that controls many geometric and probabilistic properties of normed spaces. It is of considerable interest in various settings to understand to what extent such powerful tools extend to general metric spaces. A natural metric analogue of Rademacher type was proposed by Enflo in the 1960s-70s, and has found a number of interesting applications. Despite much work in the intervening years, however, the relationship between Rademacher type and Enflo type has remained unclear. This basic question is settled in joint work with Paata Ivanisvili and Sasha Volberg: in the setting of Banach spaces, Rademacher type and Enflo type coincide. The proof is based on a very simple but apparently novel insight on how to prove dimension-free inequalities on the Boolean cube. I will not assume any prior background in Banach space theory in the talk.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/04/04/tcs-talk-wednesday-april-8-ramon-van-handel-princeton/"><span class="datestr">at April 04, 2020 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7673">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/04/04/in-defense-of-expertise/">In defense of expertise</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Scott Aaronson blogged in <a href="https://www.scottaaronson.com/blog/?p=4695">defense of “armchair epidemiology”</a>. Scott makes several points I agree with, but he also advocates that rather than discounting ideas from “contrarians” who have no special expertise in the matter, each one of us should evaluate the input of such people on its merits.</p>



<p>I disagree. I can judge on their merits the validity of a proposed P vs NP proof or a quantum algorithm for SAT, but I have seen time and again smart and educated non-experts misjudge such proposals. As much as I’d like to think otherwise, I would probably be fooled just as easily by a well-presented proposal in area X that “brushes under the rug” subtleties that experts in X would immediately notice.</p>



<p>This is not to say that non experts should stay completely out of the matter. Just like scientific journalists such as Erica Klarreich and Kevin Hartnett of quanta can do a great job of explaining computer science topics to lay audience, so can other well-read people serve as “signal boosters” and highlight works of experts in epidemiology. Journalist Helen Branswell of <a href="https://www.statnews.com/">stat news</a> has been following the <a href="https://www.nytimes.com/2020/03/30/business/media/stat-news-boston-coronavirus.html">novel coronavirus since January 4th</a>. </p>



<p>The difference is that these journalists don’t pretend to see what the experts are missing but rather to highlight and simplify the works that experts are already doing. This is unlike “contrarians” such as Robin Hanson that do their own analysis on a spreadsheet and come up with a “home brewed” policy proposal such as <a href="http://www.overcomingbias.com/2020/02/consider-controlled-infection.html">deliberate infection</a> or <a href="http://www.overcomingbias.com/2020/03/variolation-may-cut-covid19-deaths-3-30x.html">variolation</a> (with “hero hotels” in which people go to be deliberately infected). I am not saying that such proposals are necessarily wrong, but I am saying that I (or anyone else without the experience in this field) am not qualified to judge them. Even if they did “make sense” to me (they don’t) I would not feel any more confident in judging them than I would in reviewing a paper in astronomy. There is a reason why Wikipedia has a <a href="https://en.wikipedia.org/wiki/Wikipedia:No_original_research">“no original research”</a> policy.</p>



<p>Moreover, the attitude of dismissing expertise can be dangerous, whether it comes in the form of <a href="https://en.wikipedia.org/wiki/Teach_the_Controversy">“teach the debate”</a> in the context of evolution, or <a href="https://en.wikipedia.org/wiki/Climatic_Research_Unit_email_controversy">“ClimateGate”</a> in the context of climate change. Unlike the narrative of few brave “dissenters” or “contrarians”, in the case of COVID-19, experts as well as the world health organization have been literally sounding the alarm (see also <a href="https://www.nytimes.com/article/coronavirus-timeline.html">timeline</a>, as well as this NPR story on the <a href="https://www.npr.org/2020/04/03/826945368/how-the-united-states-failed-to-see-the-coronavirus-crisis-coming">US response</a>). Yes, some institutions, and especially the U.S., failed in several aspects (most importantly in the early production of testing). But one of the most troubling aspects is the constant sense of  <a href="https://www.nytimes.com/2020/04/03/us/politics/coronavirus-trump-medical-advisers.html">“daylight”</a>  and <a href="https://www.politico.com/news/2020/02/26/trump-backers-coronavirus-conspiracy-117781">distrust</a> between the current U.S. administration and its own medical experts. Moreover, the opinions of people such as  <a href="https://www.newyorker.com/news/q-and-a/the-contrarian-coronavirus-theory-that-informed-the-trump-administration">law professor Richard Epstein</a> are listened to even when they are far out of their depth. It is one thing to entertain the opinion of non-expert contrarians when we have all the time in the world to debate, discuss and debunk. It’s quite another to do so in the context of a fast-moving health emergency.  COVID-19 is an emergency that has medical, social, economical, and technological aspects, but it would best be addressed if each person contributes according to their skill set and collaborates with people of complementary backgrounds.</p>



<p></p>



<p></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/04/04/in-defense-of-expertise/"><span class="datestr">at April 04, 2020 04:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=2445">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/computer-aided-analyses/">Computer-aided analyses in optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">In this blog post, I want to illustrate how computers can be great allies in designing (and verifying) convergence proofs for first-order optimization methods. This task can be daunting, and highly non-trivial, but nevertheless usually unavoidable when performing complexity analyses. A notable example is probably the convergence analysis of the stochastic average gradient (SAG) [<a href="https://arxiv.org/pdf/1309.2388.pdf">1</a>], whose original proof was computer assisted.</p>



<p class="justify-text">To this end, we will mostly spend time on what is referred to as <em>performance estimation problems</em> (PEPs), introduced by Yoel Drori and Marc Teboulle [<a href="https://link.springer.com/article/10.1007/s10107-013-0653-0">2</a>]. Performance estimation is also closely related to the topic of <em>integral quadratic constraints</em> (IQCs), introduced in the context of optimization by Laurent Lessard, Benjamin Recht and Andrew Packard [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>]. In terms of presentations, IQCs  leverages control theory, whereas PEPs might seem more natural in the optimization community. This blog post essentially presents PEPs from the point of view of [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>], instantiated on a running example.</p>



<h2>Overview, motivations</h2>



<p class="justify-text">First-order methods for continuous optimization belong to the large panel of algorithms that are usually approached via worst-case analyses. In this context, analyses rely on combining inequalities (that are due to assumptions on the problem classes), in potentially long, non-intuitive, and technical, proofs. For the insiders, those proofs all look very similar. For the outsiders, those proofs all look rather repelling, technical (long pages of chained inequalities), probably not interesting, and like computer codes: usually intuitive mostly for their authors.</p>



<p class="justify-text">In what follows, I want to show how (and why) those proofs are indeed all very similar. On the way, I want to emphasize how those combinations of inequalities are related to the “true essence” of worst-case analyses (which rely on computing worst-case scenarios), and to provide examples on how to constructively obtain them.</p>



<p class="justify-text">We take the stand of illustrating the PEP approach on a single iteration of gradient descent, as it essentially contains all necessary ingredients to understand the methodology in other contexts as well. Certain details of the following text are (probably unavoidably) a bit technical. However, going through the detailed computations is not essential, and the text should contain the necessary ingredients for understanding the essence of the methodology.</p>



<h2>Running example: gradient descent</h2>



<p class="justify-text">Let us consider a naive, but standard, example: unconstrained convex minimization $$x_\star= \underset{x\in\mathbb{R}^d}{\mathrm{arg min}} f(x)$$with gradient descent: \(x_{k+1}=x_k-\gamma \nabla f(x_k)\). Let us assume \(f(\cdot)\) to be continuously differentiable, to have a \(L\)-Lipschitz gradient (a.k.a., \(L\)-smoothness), and to be \(\mu\)-strongly convex. Those functions satisfy, for all \(x,y\in\mathbb{R}^d\):<br />– strong convexity, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Definition 2.1.2]: $$\tag{1}f(x) \geqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{\mu}{2} \lVert x-y\rVert^2,$$- smoothness, see e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.5]: $$\tag{2} f(x) \leqslant      f(y)+\langle{\nabla f(y)}; {x-y}\rangle+\tfrac{L}{2}\lVert x-y\rVert^2.$$Let us recall that in the case of twice continuously differentiable functions, smoothness and strong convexity amount to requiring  that $$\mu I \preccurlyeq \nabla^2 f(x) \preccurlyeq L I,$$ for some \(0&lt; \mu&lt;L&lt; \infty\) and for all \(x\in\mathbb{R}^d\) (in other words, all eigenvalues of \(\nabla^2 f(x)\) are between \(\mu\) and \(L\)). In what follows, we denote by \(\mathcal{F}_{\mu,L}\) the class of \(L\)-smooth \(\mu\)-strongly convex functions (irrespective of the dimension \(d\)).</p>



<div class="wp-block-group"><div class="wp-block-group__inner-container">
<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://www.di.ens.fr/~ataylor/BlogPost/SmoothStronglyConvex.png" alt="" width="473" height="204" />Figure 1: the blue function is \(L\)-smooth and \(\mu\)-strongly convex (it is possible to create respectively global upper and lower quadratic bounds from every \(x\in\mathbb{R}^d\) with respectively curvatures \(L\) and \(\mu\)).</figure></div>
</div></div>



<p class="justify-text">In this context, convergence of gradient descent can be studied in many ways. Here, for the sake of the example, we will do it in terms of two base quantities: distance to optimality \(\lVert x_k-x_\star\rVert\), and function value accuracy \(f(x_k)-f(x_\star)\). There are, of course, infinitely many other possibilities, such as gradient norm \(\rVert \nabla f(x_k)\lVert\), Bregman divergence \(f(x_\star)-f(x_k)-\langle{\nabla f(x_k)};{x_\star-x_k}\rangle\), or even best function value observed throughout the iterations \(\min_{0\leq i\leq k} \{f(x_i)-f(x_\star)\}\): the reader can adapt the lines below for his/her favorite criterion. </p>



<p class="justify-text">For later reference, let us provide another inequality that is known to  hold for all \(x,y\in\mathbb{R}^d\) for any \(L\)-smooth \( \mu\)-strongly convex function: <br />– bound on inner product, see, e.g., [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>,  Theorem 2.1.11]: $$\langle{\nabla f(x)-\nabla f(y)};{x-y}\rangle  \geqslant        \tfrac{1}{L+\mu} \lVert{\nabla f(x)-\nabla f(y)}\rVert^2+\tfrac{\mu  L}{L+\mu}\lVert{x-y}\rVert^2.\tag{3}$$ In the case \(\mu=0\) this inequality is known as “cocoercivity”. This (perhaps mysterious) inequality happens to play an important role in convergence proofs.</p>



<h3>A standard convergence result</h3>



<p class="justify-text">Let us start by stating two known results along with their simple proofs (see, e.g.,  [<a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">5</a>, Theorem 2.1.14] or [6, Section 1.4.2, Theorems 2 &amp; 3]):<br />– convergence in distance:  $$\begin{array}{rl}    \rVert{x_{k+1}-x_\star}\lVert^2&amp;= \lVert{x_k-x_\star}\rVert^2+\gamma^2\lVert{\nabla f(x_k)}\rVert-2\gamma\langle{\nabla f(x_k)};{x_k-x_\star}\rangle \\ \     &amp; \leqslant      \left(1-\tfrac{2\gamma L \mu}{L+\mu}\right)\lVert{x_k-x_\star}\rVert^2+\gamma\left(\gamma-\tfrac2{L+\mu}\right)\lVert{\nabla f(x_k)}\rVert^2, \end{array} $$ where the second line follows from smoothness and strong convexity of \(f\) via the bound (3) on the inner product (with \(x=x_k\) and \(y=x_\star\)). For the particular choice \(\gamma=\tfrac2{L+\mu}\), the second term on the right hand side disappears, and we end up with<br />     $$\lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^2\lVert{x_k-x_\star}\rVert^2,$$ which, following from \(0&lt;\mu&lt;L&lt;\infty\), satisfies \(0&lt; \tfrac{L-\mu}{L+\mu}&lt;1\), hence proving linear convergence of gradient descent in this setup, by recursively applying the previous inequality: $$ \lVert{x_{k}-x_\star}\rVert^2 \leqslant      \left(\tfrac{L-\mu}{L+\mu}\right)^{2k}\lVert{x_0-x_\star}\rVert^2.$$ – Convergence in function values: one can simply use the result in distance along with the previous basic inequalities (1) and (2) characterizing smoothness and strong convexity (both with \(y=x_\star\)):<br />     $$f(x_k)-f(x_\star) \leqslant \hspace{-.15cm}\tfrac{L}{2}\hspace{-.1cm}\rVert{x_k-x_\star}\lVert^2  \leqslant  \hspace{-.15cm}    \tfrac{L}{2}\hspace{-.1cm}\left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k} \rVert{x_0-x_\star}\lVert^2 \leqslant  \hspace{-.15cm}     \tfrac{L}{\mu}\hspace{-.1cm} \left(\tfrac{L-\mu}{L+\mu}\right)^{\hspace{-.1cm}2k}(f(x_0)-f(x_\star)).$$  It is also possible to directly look for convergence in terms of function values, but it is then usually unclear in the literature what inequalities to use, and I am not aware of any such proof leading to the same rate without the leading \(\tfrac{L}{\mu}\) (except the proof presented below).</p>



<p class="justify-text">At this point, even in this toy example, a few very legitimate questions can be raised:<br />– can we improve anything? Can gradient descent really behaves like that on this class of functions?<br />– How could we have guessed the inequality to use, and the shape of the corresponding proof? Obviously, the obscure fact is to arrive to inequality (1).  Therefore, is there a principled way for choosing the right inequalities to use, for example for studying convergence in terms of other quantities, such as  function values?<br />– Is this the unique way to arrive to the desired result? If yes, how likely are we to find such proofs for more complicated cases (algorithms and/or function class)?</p>



<p class="justify-text">For the specific step size choice \(\gamma=\tfrac2{L+\mu}\), a partial answer to the first question is obtained by the observation that the rate is actually achieved on the quadratic function<br /> $$f(x)=\tfrac12 \, x^\top \begin{bmatrix}<br /> L &amp; 0\\ 0 &amp; \mu<br /> \end{bmatrix}x.$$ The following lines precisely target the missing answers.</p>



<h2>Worst-case analysis through worst-case scenarios</h2>



<p class="justify-text">Let us start by rephrasing our goal, and restrict ourselves to the study of a single iteration. We fix our target to finding the smallest possible value of \(\rho\) such that the inequality<br /> $$ \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant       \rho^2 \lVert{x_k-x_\star}\rVert^2 $$ is valid for all \(x_k\) and \(x_{k+1}=x_k-\gamma \nabla f(x_k)\) (hence \(\rho\) is a function of \(\gamma\)). In other words, our goal is to solve<br />$$ \rho^2(\gamma):= \sup \left\{ \frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0\right\}.$$<br />Alternatively, we could be interested in studying convergence in other forms: for function values, we could target to solve the slightly modified problem:<br /> $$ \sup  \left\{ \frac{f(x_{k+1})-f(x_\star)}{f(x_{k})-f(x_\star)}\, \big|\, f\in\mathcal{F}_{\mu,L},\, x_{k+1}=x_k-\gamma \nabla f(x_k),\, \nabla f(x_\star)=0 \right\}.$$ It turns out that in both cases, the problem can be solved both numerically to high precision, and analytically, and that the answer is \(\rho^2(\gamma)=\max\{(1-\mu\gamma)^2,(1-L\gamma)^2\}\).</p>



<p class="justify-text">The only thing we did, so far, was to explicitly reformulate the problem of finding the best (smallest) convergence rate as the problem of finding the worst-case scenario, nothing more. In what follows, some parts might become slightly technical, but the overall idea is only to reformulate this problem of finding the worst-case scenarios, for solving it.</p>



<h3>Dealing with an infinite-dimensional variable: the function \(f\)</h3>



<p class="justify-text">The first observation is that the problem of computing \(\rho\) is stated as an infinite-dimensional optimization problem: we are looking for the worst possible problem instance (a function \(f\) and an initial point \(x_k\)) within a predefined class of problems. The first step we take to work around this is to reformulate it in the following equivalent  form (note that we maximize also over the dimension \(d\)—we discuss later how to remove it):<br />$$\begin{array}{rl} \rho^2:= \underset{f,\, x_k,\,x_\star,\, g_k,\,d}{\sup} &amp;\displaystyle \frac{\lVert{x_{k}-\gamma g_k-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\\<br /> \text{s.t. }    &amp; \exists f\in\mathcal{F}_{\mu,L}:\, g_k= \nabla f(x_k),\, 0=\nabla f(x_\star).<br />\end{array}$$<br />This problem intrinsically does not look better (it contains an  existence constraint), but it allows using mathematical tools which are referred to as  <em>interpolation,</em> or <em>extension</em>, theorems [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1603.00241.pdf">7</a>, <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">8</a>]. The problem is depicted on Figure 2:</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://www.di.ens.fr/~ataylor/BlogPost/Interpolation.png" alt="" width="490" height="209" />Figure 2: discrete interpolation (or extension) problem: given a set of triplets \(\{(\text{coordinate}, \text{gradient}, \text{function value})\}\) can we recover a function within a determined class that explains those triplets?</figure></div>



<p class="justify-text">It turns out that convex interpolation (that is, neglecting smoothness and strong convexity) is actually rather simple:</p>



<ul class="justify-text"><li>given a convex function and an index set \(I\), any set of samples \(\{(x_i,g_i,f_i)\}_{i\in I}\) of the form \(\{(\text{coordinate}, \text{(sub)gradient}, \text{function value})\}\)) satisfies, for all \(i,j\in I\): $$f_i \geqslant      f_j+\langle g_j; x_i-x_j\rangle,$$ by definition of subgradient, as illustrated on Figure 3.</li></ul>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img src="https://www.di.ens.fr/~ataylor/BlogPost/SamplingCvx.png" alt="" width="485" height="205" />Figure 3: sampling from a convex function.</figure></div>



<ul class="justify-text"><li>In the other direction, given a set of triplets \(\{(x_i,g_i,f_i)\}_{i\in I}\) satisfying the previous inequality for all pairs \(i,j\in I\), one can simply recover a  convex function by the following construction: $$f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\},$$ which is depicted on Figure 4.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://www.di.ens.fr/~ataylor/BlogPost/InterpolateCvx.png" alt="" width="487" height="207" />Figure 4: some set \(\{(x_i,g_i,f_i)\}_{i\in I}\) and its piecewise affine interpolant \(f(x)=\underset{i\in I}{\max}\{ f_i+\langle g_i;x-x_i\rangle\}\).</figure></div>



<ul class="justify-text"><li>Formally, the reasoning allows arriving to the following “convex interpolation” (or “convex extension”) result, where we denote the set of (closed, proper) convex functions by \(\mathcal{F}_{0,\infty}\) (to be understood as \(L\)-smooth \(\mu\)-strongly convex functions with \(\mu=0\) and \(L=\infty\)): $$\begin{array}{c}\exists f\in\mathcal{F}_{0,\infty}: \,  g_k\in\partial f(x_k) \text{ and } f_k=f(x_k) \ \ \forall k\in  I\\ \Leftrightarrow\\ f_i \geqslant       f_j+\langle{g_j};{x_i-x_j}\rangle\quad \forall i,j\in I,\end{array}$$ where \(\partial f(x)\) denotes the subdifferential of \(f\) at \(x\).</li></ul>



<p class="justify-text">In the next section, we use a similar interpolation result for taking smoothness and strong convexity into account. The result is a bit more technical, but follows from similar constructions as those for convex interpolation—the main difference being that the interpolation is done on the Fenchel conjugate instead, in order to incorporate smoothness, see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Section 2].</p>



<h3>Reformulation through convex interpolation</h3>



<p class="justify-text">Back to the problem of computing worst-case scenarios, we can now reformulate the existence constraint <em>exactly</em> using the following result (see [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>,  Theorem 4]): let \(I\) be a finite index set and let \( S=\{(x_i,g_i,f_i)\}_{i\in I}\) be a set of triplets, then<br />  $$\begin{array}{c}\exists f\in\mathcal{F}_{\mu,L}: \,  g_i=\nabla f(x_i) \text{ and } f_i=f(x_i) \text{ for all } i\in  I\\ \Leftrightarrow\\  f_i \geqslant      f_j+\langle{g_j};{x_i-x_j}\rangle+\frac{1}{2L}\lVert{g_i-g_j}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_i-x_j-\frac{{1}}{L}(g_i-g_j)}\rVert^2  \,\,\, \forall i,j\in I.\end{array}$$ Therefore, the previous problem can be reformulated as (recalling that \(g_\star=0\))<br />$$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle\frac{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}{\rVert{x_k-x_\star}\lVert^2}\\<br />      \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br />      &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2.<br />\end{array}$$ </p>



<h3>Quadratic reformulation</h3>



<p class="justify-text">The next step is to remove the ratio appearing in the objective function, which we do via an homogeneity argument, as follows.</p>



<p class="justify-text">Starting from a feasible point, scale \(x_k,\,x_\star,g_k\) by some \(\alpha&gt;0\) and \(f_k,\,f_\star\) by \(\alpha^2\) and observe it does not change the value of the objective, while still being a feasible point. Therefore, the problem can be reformulated as a nonconvex QCQP (quadratically constrained quadratic program): $$  \begin{array}{rl} \underset{{f_k,\,f_\star,\, x_k,\,x_\star,\, g_k,\,d}} {\sup}&amp;\displaystyle{\rVert{x_{k}-\gamma  g_k-x_\star}\lVert^2}\\<br />       \text{s.t. }    &amp; f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\<br />       &amp; f_k \geqslant      f_\star+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2\\ &amp;{\rVert{x_k-x_\star}\lVert^2} \leqslant      1,<br /> \end{array}$$  which is quadratic in \(x_k\), \(x_\star\) and  \(g_k\), and linear in \(f_\star\) and \(f_k\). Actually, in the current form, nonconvexity comes from the term “\(\langle{g_k};{x_\star-x_k}\rangle\)” in the second constraint (and from the objective, due to maximization). It turns out that this problem can be reformulated <em>losslessly</em> using semidefinite programming (this is due to the maximization over \(d\), as commented at the end of the next section). </p>



<h3>Semidefinite reformulation</h3>



<p class="justify-text">At the end of this section, we will be able to compute, numerically, the values of the rate \(\rho^2(\gamma)\) for given values of the parameters \(\mu,\,L\), and \(\gamma\).</p>



<p class="justify-text">The last step in the reformulation goes as follows: the previous problem can be reformulated as a semidefinite program, as it is linear in terms of the entries of the following Gram matrix<br />$$G = \begin{pmatrix}<br />     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle \\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2<br />     \end{pmatrix}\succcurlyeq 0,$$ and in terms of the function values \(f_k\) and \(f_\star\). From those variables, one reformulate the previous problem as $$\begin{array}{rl} \underset{f_k,\,f_\star,\, G\succeq 0}{\sup} \, &amp;{\mathrm{Tr} (A_\text{num} G)}\\<br />      \text{s.t. }    &amp; f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0\\<br />      &amp;  f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0 \\<br />      &amp;\mathrm{Tr} (A_\text{denom} G) \leqslant      1,\end{array}$$ which is a gentle semidefinite program where we picked matrices \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) for encoding the previous terms. That is, we choose those matrices such that<br /> $$\begin{array}{rl}<br />\mathrm{Tr}(A_{\text{denom}} G)&amp;=\lVert{x_k-x_\star}\rVert^2,\\  \mathrm{Tr}(A_{\text{num}} G)&amp;=\lVert{x_k-\gamma g_k-x_\star}\rVert^2,\\ \mathrm{Tr}(A_1G)&amp;=\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2,\\ \mathrm{Tr}(A_2G)&amp;=\tfrac{1}{2L}\lVert g_k\rVert^2+\tfrac{\mu}{2(1-\mu/L)}\lVert x_k-x_\star-\tfrac1L g_k\rVert^2.\end{array}$$ One possibility is to choose \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\) as symmetric matrices, as follows: $$\begin{array}{cc}<br /> A_{\text{denom}}=\begin{pmatrix}     1 &amp; 0\\ 0 &amp; 0     \end{pmatrix}, &amp; A_{\text{num}}=\begin{pmatrix}     1 &amp; -\gamma\\ -\gamma &amp; \gamma^2     \end{pmatrix}, \\ A_1=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac12-\tfrac{\mu}{2(L-\mu)} \\ -\tfrac12-\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)}\end{pmatrix}, &amp;  A_2=\begin{pmatrix}\tfrac{\mu}{2(1-\mu/L)} &amp; -\tfrac{\mu}{2(L-\mu)} \\ -\tfrac{\mu}{2(L-\mu)} &amp; \tfrac{1}{2L}+\tfrac{\mu}{2L(L-\mu)} \end{pmatrix}.\end{array}$$</p>



<p class="justify-text">All those steps can be carried out in the exact same way for the problem of computing the convergence rate for function values, reaching a similar problem with \(6\) inequality constraints instead—because interpolation conditions have to be imposed on all pairs of points in a set of \(3\) points: \(x_k\), \(x_{k+1}\) and \(x_\star\), instead of only \(2\) for the distance problem. The objective function is then \(f_{k+1}-f_\star\), the de-homogenization constraint (arising from the denominator of the objective function) is \(f_{k}-f_\star \leqslant     1\), and the Gram matrix is \(3\times 3\):<br />$$G=\begin{pmatrix}<br />     \lVert{x_k-x_\star}\rVert^2 &amp; \langle{g_k};{x_k-x_\star}\rangle&amp; \langle{g_{k+1}};{x_k-x_\star}\rangle\\ \langle{g_k};{x_k-x_\star}\rangle &amp; \lVert{g_k}\rVert^2 &amp; \langle{g_k};{g_{k+1}}\rangle \\<br />     \langle{g_{k+1}};{x_k-x_\star}\rangle &amp; \langle{g_{k+1}};{g_k}\rangle &amp; \lVert{g_{k+1}}\rVert^2<br />     \end{pmatrix}\succcurlyeq 0, $$ and the function values variables are \(f_k\), \(f_{k+1}\) and \(f_\star\).</p>



<p class="justify-text">We provide the numerical optimal values of those semidefinite programs on Figure 5 for both convergence in distances and in function values. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://www.di.ens.fr/~ataylor/BlogPost/ObjectiveValues.png" alt="" width="534" height="324" />Figure 5: worst-cases of the ratio \(\frac{\lVert{x_{k+1}-x_\star}\rVert^2}{\lVert{x_k-x_\star}\rVert^2}\) (red) and \(\frac{f(x_{k+1})-f_\star}{f(x_k)-f_\star}\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match exactly the expected \(\max\{(1-\gamma L)^2,(1-\gamma\mu)^2\}\) in both cases. Note that the corresponding SDPs can be solved both for “good and bad” choices of step sizes: if the step size is chosen wisely then \(\rho(\gamma)&lt;1\), and otherwise \(\rho(\gamma)\geqslant 1\). The SDP confirms the common knowledge that \(\gamma\in (0,2/L)\Rightarrow \rho(\gamma)&lt; 1\). Numerical values obtained through YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p class="justify-text">As a conclusion for this section, let us note that we showed how to compute the “best” rates that are dimension independent. In general, requiring the iterates and gradient (e.g., \(x_k\) and \(g_k\) for the problem in terms of distance, and \(x_k\), \(g_k\) and \(g_{k+1}\) for function values, and potentially more vectors when dealing with more complex settings) to lie in \(\mathbb{R}^d\) is equivalent to adding a rank constraint in the SDP. </p>



<h2>Duality between worst-case scenarios and combinations of inequalities</h2>



<p class="justify-text">Any feasible point to the previous SDP corresponds to a <em>lower bound</em>: a sampled version of a potentially difficult function for gradient descent. If we want to find <em>upper bounds</em> on the rate, a natural way to proceed is to go to the dual side of the previous SDPs, where any feasible point will naturally correspond to an upper bound on the convergence rate (by <em>weak duality</em>). As the primal problems were SDPs, their Lagrangian duals are SDPs as well. Let us associate one multiplier per constraint: $$ \begin{array}{rl}<br />f_k-f_\star+\mathrm{Tr} (A_1 G)\leqslant 0&amp;:\lambda_1\\<br />f_\star-f_k+\mathrm{Tr} (A_2 G)\leqslant 0&amp;:\lambda_2\\<br />\mathrm{Tr}(A_\text{denom} G) \leqslant 1&amp;: \tau.<br />\end{array}$$The dual is then<br />$$\begin{array}{rl}<br /> \underset{\tau,\,\lambda_1,\,\lambda_2}{\min} &amp; \, \tau \\<br /> \text{s.t. } &amp; \lambda_1=\lambda_2,\\<br /> &amp; S:=A_\text{num}-\tau A_\text{denom}-\lambda_1A_1-\lambda_2A_2 \preccurlyeq 0,\\<br /> &amp;\tau,\lambda_1,\lambda_2 \geqslant  0.<br /> \end{array}$$ Hence, by weak duality, any feasible point to this last SDP corresponds to an upper bound on the rate: \(\tau \geqslant \rho^2\). A mere rephrasing of weak duality can be obtained through the following reasoning: assume we received some feasible \(\tau,\lambda_1,\lambda_2\) (and hence \(\lambda_1=\lambda_2\) and a corresponding \(S\preccurlyeq 0\)), we then get, for any primal feasible \(G\succcurlyeq0\):<br />$$\begin{array}{rl}\mathrm{Tr}(SG)&amp;=\mathrm{Tr}(A_{\text{num}}G)-\tau\mathrm{Tr}(A_{\text{denom}}G)-\lambda_1\mathrm{Tr}(A_1G)-\lambda_2\mathrm{Tr}(A_2G)\\&amp;=\lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\\ \,&amp;\,\,\,-\lambda_1[     f_k-f_\star+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\,\,\,-\lambda_2 [f_\star-f_k+\frac{1}{2L}\lVert{g_k}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}g_k}\rVert^2]\\ &amp;\geqslant \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2, \end{array}$$ where the first equality follows from the definition of \(S\), the second equality corresponds to the definitions of \(A_{\text{num}}\), \(A_{\text{denom}}\), \(A_1\) and \(A_2\), and the last inequality follows from the sign of the interpolation inequalities (constraints in the primal) for any primal feasible point. Hence, we indeed have that any feasible \(\tau\) corresponds to a valid upper bound on the convergence rate, as $$S\preccurlyeq 0 \,\,\Rightarrow \,\, \mathrm{Tr}(SG)\leqslant 0\,\,\Rightarrow  \lVert x_{k+1}-x_\star\rVert^2-\tau\lVert x_{k}-x_\star\rVert^2\leqslant 0.$$ In order to obtain analytical proofs, we therefore need to find analytical dual feasible points, and numerics can of course help in this process! Let’s look at what the optimal dual solutions look like for our two running examples.</p>



<ul class="justify-text"><li> in Figure 6, we provide the numerical values for \(\lambda_1\) and \(\lambda_2\) for the distance problem.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_distance.png" alt="" width="467" height="316" />Figure 6: numerical values of optimal dual variables: \(\lambda_1\) (red) and \(\lambda_2\) (dashed blue) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. The results match \(\lambda_1=\lambda_2=2\gamma \rho(\gamma)\) with \(\rho(\gamma)=\max\{|1-\gamma L|,|1-\gamma\mu|\}\). Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<ul class="justify-text"><li>For function values, the SDP is slightly more complicated, as more inequalities are involved (6 interpolation inequalities). We provide raw numerical values for the six multipliers in Figure 7.</li></ul>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://www.di.ens.fr/~ataylor/BlogPost/Multipliers_function.png" alt="" width="463" height="348" />Figure 7: numerical values of optimal dual variables (for the rate in function values): \(\lambda_1,\lambda_2, …,\lambda_6\) as functions of the step size \(\gamma\), for the case where \(f\) is \(1\)-smooth and \(0.1\)-strongly convex. Numerical values obtained with YALMIP [<a href="https://yalmip.github.io/">9</a>] and Mosek [<a href="https://www.mosek.com/">10</a>].</figure></div>



<p>For those who want a bit more details, here are a few additional pointers:</p>



<ul class="justify-text"><li>Strong duality holds—a way to prove it is to show that there exists a Slater point in the primal, see e.g., [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, Theorem 6]—, and hence primal and dual optimal values match.</li><li>There might be different ways to optimaly combine the interpolation inequalities for proving the desired results. In other words: dual optimal solutions are often not unique—which is, in fact, quite a good news: I am sure nobody want to find the analytical version of the multipliers provided in Figure 7.</li><li>It is often possible to simplify the proofs by using fewer, or weaker, inequalities. This might lead to ”cleaner” results, typically (but not always) at the cost of ”weaker” rates. This was done for designing the proof for function values, later in this text.</li></ul>



<h2>Combinations of inequalities: same proofs without SDPs</h2>



<p class="justify-text">So far, we showed that computing convergence rates can be done in a very principled way. To this end, one can solve semidefinite programs—which may have arbitrarily complicated analytical solutions. Here, I want to emphasize that the process of <em>verifying</em> a solution can be quite different to that of<em> finding</em> a solution. Put in other words, although the dual certificates (a.k.a., the proofs) might have been found by solving SDPs, they can be formulated in ways that do not require the reader to know anything about the PEP methodology, nor on any SDP material, for verifying them. This fact might actually not be very surprising to the reader, as many proofs arising in the first-order optimization literature actually “only consists” in linear combinations of (quadratic) inequalities. On the one hand, those proofs can be seen as feasible points to “dual SDPs”, although generally not explicitely proved as such. On the other hand, proofs arising from the SDPs might therefore be expected to be writable without any explicit reference to semidefinite programing and performance estimation problems.<br /></p>



<p class="justify-text">In what follows, we provide the proofs for gradient descent, using the previous numerical inspiration, but without explicitly relying on any semidefinite program. The reader is not expected to verify any of those computations, as our goal is rather to emphasize that the principles underlying both proofs are exactly the same: reformulating linear combinations of inequalities.</p>



<p class="justify-text">For both proofs below, we limit ourselves to the step size regime \(0\leq   \gamma \leq \tfrac{2}{L+\mu}\), and we prove  that, in  this regime, \(\rho(\gamma)=(1-\gamma\mu)\)—actually we only proof the upper bounds, but one can easily verify that they are <em>tight</em> on simple quadratic functions.  The complete proofs (for the proximal gradient method),  can be found in [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>]. </p>



<h3>Example 1: distance to optimality</h3>



<p class="justify-text">Recall the notations: \(g_k:=\nabla f(x_k)\), \(f_k:= f(x_k)\), \(g_\star:=\nabla f(x_\star)\), and \(f_\star:= f(x_\star)\).</p>



<p class="justify-text">For distance to optimality, sum the following inequalities with their corresponding weights: $$\begin{array}{r}     f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2  :\lambda_1,  \\     f_k \geqslant      f_\star+\langle{g_\star};{x_k-x_\star}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{{1}}{L}(g_k-g_\star)}\rVert^2:\lambda_2.     \end{array}$$ We use the following values for the multipliers: \(\lambda_1=\lambda_2=2\gamma\rho(\gamma) \geqslant      0\) (see Figure 6). </p>



<p class="justify-text">After appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), and with little effort, one can check that the previous weighted sum of inequalities can be written in the form: $$ \begin{array}{rl}    \lVert{x_{k+1}-x_\star}\rVert^2  \leqslant      &amp; \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2 -\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2. \end{array}$$ This statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation) and verifying that all terms indeed match.</p>



<p class="justify-text">Finally, using $$\gamma(2-\gamma (L+\mu)) \geqslant      0,  \text{ and } L-\mu \geqslant      0,$$ which are nonnegative by assumptions on the values of \(L\in(0,\infty)\), \(\mu\in (0,L)\) and \(\gamma\in(0,2/(L+\mu))\), we arrive to the desired $$ \lVert{x_{k+1}-x_\star}\rVert^2 \leqslant      \left(1-\gamma \mu \right)^2\lVert{x_{k}-x_\star}\rVert^2.$$</p>



<p class="justify-text">Note that, by using \(\lambda_1=\lambda_2\), the weighted sum exactly corresponds to the (scaled by a positive constant) inequality introduced in the early stage of this note for studying distance to optimality. However, the resulting expression is tight for all values of the step size here, whereas it was only tight for \(\gamma=2/(L+\mu)\) earlier, due to a different choice of weights! </p>



<p class="justify-text">The curious reader might wonder how to find such a reformulation. Actually, back in terms of SDPs, and using the expressions for the multipliers, it simply corresponds to $$\mathrm{Tr}(SG)=-\frac{\gamma(2-\gamma (L+\mu))}{L-\mu} \lVert{\mu {(x_k  -x_\star)} – g_k}\rVert^2.$$ In the example below, the reformulation is a bit more tricky—as \(\mathrm{Tr}(SG)\)  has two nonnegative terms, which were simply obtained by doing an analytical Cholesky factorization of the term \(\mathrm{Tr}(SG)\)—, but the idea is exactly the same.</p>



<h3>Example 2: function values</h3>



<p class="justify-text">For function values, we combine the following inequalities after multiplication with their respective coefficients:    </p>



<p class="justify-text">$$\scriptsize \begin{array}{lr}     f_k \geqslant      f_{k+1}+\langle{g_{k+1}};{x_k-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_k-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_{k+1}-\frac{1}{L}(g_k-g_{k+1})}\rVert^2    &amp;:\lambda_1,\\<br />f_\star \geqslant      f_k+\langle{g_k};{x_\star-x_k}\rangle+\frac{1}{2L}\lVert{g_k-g_\star}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_k-x_\star-\frac{1}{L}(g_k-g_\star)}\rVert^2  &amp;:\lambda_2, \\<br />f_\star \geqslant      f_{k+1}+\langle{g_{k+1}};{x_\star-x_{k+1}}\rangle+\frac{1}{2L}\lVert{g_\star-g_{k+1}}\rVert^2+\frac{\mu}{2(1-\mu/L)}\lVert{x_\star-x_{k+1}-\frac{1}{L}(g_\star-g_{k+1})}\rVert^2  &amp;:\lambda_3.     \end{array}$$ We use the following multipliers \(\lambda_1=\rho(\gamma)\), \(\lambda_2=(1-\rho(\gamma))\rho(\gamma)\), and  \(\lambda_3=1-\rho(\gamma)\) (obtained by greedily trying to set different combinations of multipliers to \(0\) in the SDP—see Figure 7 for the values without such simplifications).</p>



<p class="justify-text">Again, after appropriate substitutions of \(g_\star\), \(x_{k+1}\), and \(\rho(\gamma)\), using respectively \(g_\star=0\), \(x_{k+1}=x_k-\gamma g_k\) and \(\rho(\gamma)=(1-\gamma\mu)\), we obtain that the weighted sum of inequalities can be reformulated exactly as $$  \begin{array}{rl}          f(x_{k+1})-f_\star \leqslant      &amp;\left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right)\\&amp;-\frac{1}{2 (L-\mu)}\lVert \nabla f(x_{k+1})-(1-\gamma  (L+\mu))\nabla f(x_k) +\gamma  \mu  L (x_\star-x_k)\rVert^2\\<br />&amp;-\frac{\gamma  L(2- \gamma  (L+\mu))}{2 (L-\mu )}\lVert \nabla f(x_k)+\mu  (x_\star-x_k)\rVert^2.\end{array}$$ Again, this statement can be checked simply by expanding both expressions (i.e., the weighted sum and its reformulation), and verifying that all terms match. The desired conclusion $$ f(x_{k+1})-f_\star \leqslant \left(1-\gamma \mu\right)^2 \left(f(x_k)-f_\star\right), $$ follows from the signs of the leading coefficients: \(\gamma(2-\gamma (L+\mu)) \geqslant      0\), and \(L-\mu \geqslant      0\).</p>



<h3>To go further</h3>



<p class="justify-text">Before finishing, let us mention that we only dealt with linear convergence through a single iteration of gradient descent.</p>



<p class="justify-text">There are quite a few ways to handle both more iterations and sublinear convergence rates. Using SDPs, probably the most natural approach is to directly incorporate several iterations in the problem by  studying, for example, ratios of the form  $$\sup_{f\in\mathcal{F}_{\mu,L},\, x_0}  \frac{f(x_{N})-f_\star}{\lVert x_0-x_\star\rVert^2}. $$ This type of approach was used in the work of Drori and Teboulle [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>] and in most consecutive PEP-related works: it has the advantage of providing  comfortable “non-improvable results” [<a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">4</a>, <a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>]   (by providing matching lower bounds) for any given \(N\), but requires solving larger and larger SDPs. Alternatively, simpler proofs can often be obtained through the use of  Lyapunov (or potential) functions—i.e., study a single iteration to produce recursable inequalities; a nice introduction is provided in [<a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">13</a>]. This idea can be exploited in PEPs [<a href="https://arxiv.org/pdf/1902.00947.pdf">14</a>] by enforcing the proofs to have a certain structure. Those principles are also at the heart of the related approach using integral quadratic constraints [<a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">3</a>, <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">15</a>]. </p>



<h2>Take-home message and conclusions</h2>



<p class="justify-text">The overall message of this note is that first-order methods can often be studied directly using the definition of their “worst-cases” (i.e., by trying to find worst-case scenarios), along with their dual counterparts (linear combinations of inequalities), by translating them into semidefinite programs.</p>



<p class="justify-text">What we saw might look like an overkill for studying gradient descent. However, as long as we deal with Euclidean spaces, the same approach actually works beyond this simple case. In particular, the same technique applies to first-order methods performing explicit, projected, proximal, conditional, and inexact (sub)gradient steps [<a href="https://arxiv.org/pdf/1512.07516.pdf">12</a>].</p>



<p class="justify-text">Finally, let us mention a few previous works illustrating that the use of such computer-assisted proofs allowed obtaining results that are apparently too complicated for us to find bare-handed—even in apparently simple contexts.  Reasonable examples include the direct proof for convergence rates in  function values [<a href="https://arxiv.org/pdf/1705.04398.pdf">11</a>] presented above, but also proofs arising in the context of optimized numerical schemes [<a href="https://arxiv.org/pdf/1206.3209.pdf">2</a>, <a href="https://arxiv.org/abs/1409.2636">16</a>, <a href="https://arxiv.org/pdf/1406.5468.pdf">17</a>, <a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>]—in particular [<a href="https://arxiv.org/pdf/1803.06600.pdf">18</a>] presents a method for minimizing the gradient norm at the last iterate, in smooth convex minimization—,  in the context of monotone inclusions,  and even for more general fixed-point problems (e.g., for Halpern iterations [<a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">19</a>]).</p>



<h3>Toolbox</h3>



<p class="justify-text">The PErformance EStimation TOolbox (PESTO) [<a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">20</a>, see <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/graphs/traffic">Github</a>] allows a quick access to the methodology without worrying about details of semidefinite reformulations. The toolbox contains many  examples (about 50) in different settings, and include progresses on the approach, and results, by other groups (which are much more thoroughly referenced in the <a href="https://github.com/AdrienTaylor/Performance-Estimation-Toolbox/blob/master/UserGuide.pdf">user guide</a>). In particular, we included standard classes of functions and operators, along with examples for analyzing recent optimized methods.</p>



<h2>References</h2>



<p class="justify-text">[1] Mark Schmidt, Nicolas Le Roux, Francis Bach. <a href="https://arxiv.org/pdf/1309.2388.pdf">Minimizing finite sums with the stochastic average gradient</a>. <em>Mathematical Programming</em>, <em>162</em>(1-2), 83-112, 2017.<br />[2] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/pdf/1206.3209.pdf">Performance of first-order methods for smooth convex minimization: a novel approach</a>. <em>Mathematical Programming</em>, 145(1-2), 451-482, 2014.<br />[3] Laurent Lessard, Benjamin Recht, Andrew Packard. <a href="https://epubs.siam.org/doi/abs/10.1137/15M1009597">Analysis and design of  optimization algorithms via integral quadratic constraints</a>. <em>SIAM Journal on Optimization</em>, 26(1), 57-95, 2016.<br />[4] Adrien Taylor,  Julien Hendrickx, François Glineur. <a href="https://link.springer.com/article/10.1007/s10107-016-1009-3">Smooth strongly convex interpolation and exact worst-case performance of first-order methods</a>. <em>Mathematical Programming</em>, 161(1-2), 307-345, 2017.<br />[5] Yurii Nesterov. <a href="https://link.springer.com/book/10.1007/978-1-4419-8853-9">Introductory Lectures on Convex Optimization : a Basic Course</a>. <em>Applied optimization</em>. Kluwer Academic Publishing, 2004.<br />[6]  Boris Polyak. Introduction to Optimization. Optimization Software New York, 1987.<br />[7] Daniel Azagra, Carlos Mudarra. <a href="https://arxiv.org/pdf/1603.00241.pdf">An extension theorem for convex functions of class \(C^{1,1}\) on Hilbert spaces</a>. <em>Journal of Mathematical Analysis and Applications</em>, 446(2):1167–1182, 2017.<br />[8] Aris Daniilidis, Mounir Haddou, Erwan Le Gruyer, Olivier Ley. <a href="https://hal.archives-ouvertes.fr/hal-01530908/file/DHLL_appendix.pdf">Explicit formulas for \(C^{1,1}\) Glaeser-Whitney extensions of 1-Taylor fields in Hilbert spaces</a>. <em>Proceedings of the American Mathematical Society</em>, 146(10):4487–4495, 2018.<br />[9] Johan Löfberg. <a href="https://yalmip.github.io/">YALMIP : A toolbox for modeling and optimization in MATLAB</a>. <em>Proceedings of the CACSD Conference</em>, 2004.<br />[10] APS Mosek. <a href="https://www.mosek.com/">The MOSEK optimization software</a>. Online at http://www.mosek.com, 54, 2010.<br />[11] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1705.04398.pdf">Exact worst-case convergence rates of the proximal gradient method for  composite convex minimization</a>. <em>Journal of Optimization Theory and Applications</em>, vol. 178, no 2, p. 455-476, 2018.<br />[12] Adrien Taylor, Julien Hendrickx, François Glineur. <a href="https://arxiv.org/pdf/1512.07516.pdf">Exact worst-case performance of first-order methods for composite convex optimization</a>. <em>SIAM Journal on Optimization</em>, vol. 27, no 3, p. 1283-1313, 2017.<br />[13] Nikhil Bansal, Anupam Gupta. <a href="http://www.theoryofcomputing.org/articles/v015a004/v015a004.pdf">Potential-Function Proofs for Gradient Methods. <em>Theory of Computing</em></a>, <em>15</em>(1), 1-32, 2019.<br />[14] Adrien Taylor, Francis Bach. <a href="https://arxiv.org/pdf/1902.00947.pdf">Stochastic first-order methods: non-asymptotic and computer-aided analyses via potential functions</a>, <em>Proceedings of the 32nd Conference on Learning Theory (COLT)</em>, 99:2934-2992, 2019.  <br />[15] Bin Hu, Laurent Lessard. <a href="http://proceedings.mlr.press/v70/hu17a/hu17a.pdf">Dissipativity theory for Nesterov’s accelerated method</a>, <em>Proceedings of the 34th International Conference on Machine Learning</em>, 70:1549-1557, 2017. <br />[16] Yoel Drori, Marc Teboulle. <a href="https://arxiv.org/abs/1409.2636">An optimal variant of Kelley’s cutting-plane method</a>. <em>Mathematical Programming</em> 160.1-2: 321-351, 2016.<br />[17] Donghwan<strong> </strong>Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1406.5468.pdf">Optimized first-order methods for smooth convex minimization</a>, <em>Mathematical programming</em>, <em>159</em>(1-2), 81-107, 2016.<br />[18] Donghwan Kim, Jeffrey Fessler. <a href="https://arxiv.org/pdf/1803.06600.pdf">Optimizing the efficiency of first-order methods for decreasing the gradient of smooth convex functions</a>, <em>preprint arXiv:1803.06600</em>, 2018.   <br />[19] Felix Lieder. <a href="http://www.optimization-online.org/DB_FILE/2017/11/6336.pdf">On the convergence rate of the Halpern-iteration</a>. Technical Report, 2019.<br />[20] Adrien Taylor, Julien Hendrickx, François Glineur.  <a href="https://perso.uclouvain.be/julien.hendrickx/availablepublications/PESTO_CDC_2017.pdf">Performance estimation toolbox (PESTO): automated worst-case analysis of  first-order optimization methods</a>,<em> Proceedings of the 56th Annual Conference on Decision and Control (CDC)</em>, pp. 1278-1283, 2017.</p></div>







<p class="date">
by Adrien Taylor <a href="https://francisbach.com/computer-aided-analyses/"><span class="datestr">at April 03, 2020 11:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19411">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/04/03/trees-not-cubes-memories-of-boris-tsirelson/">Trees not Cubes! Memories of Boris Tsirelson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>This post is devoted to a few memories of Boris Tsirelson who passed away at the end of January. I would like to mention that a few days ago graph theorist Robin Thomas passed away after long battle with ALS. I hope  to tell about Robin’s stunning mathematics in a future post.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/tsirelson_boris.jpg"><img src="https://gilkalai.files.wordpress.com/2020/03/tsirelson_boris.jpg?w=640&amp;h=480" alt="" width="640" class="alignnone size-full wp-image-19552" height="480" /></a></p>
<p>Boris Tsirelson (1950 – 2020); <a href="http://www.math.tau.ac.il/~tsirel/">Boris’ home-page</a>, and <a href="https://en.wikipedia.org/wiki/Boris_Tsirelson">Wikipedia</a>. (More links, below.)</p>
<p>The title of the post is taken from the title of a very interesting 1999 paper by Boris Tsirelson and Oded Schramm: <a href="https://arxiv.org/abs/math/9902116">Trees, not cubes: hypercontractivity, cosiness, and noise stability</a></p>
<p>I was very sad and shocked to hear that Boris Tsirelson had passed away. Boris was one of the greatest Israeli mathematicians, and since 1997 or so we established mathematical connections surrounding several matters of common interest.  Here are a few memories.</p>
<h3>Love for coding</h3>
<p>1) One thing that Boris told me was that he loves to code. Being a “refusnik”, he could not get into Academia and (luckily) he could work as a programmer. And he told me that afterwards deciding what he liked more – programming or doing mathematical research – was no longer a trivial question for him.  Boris chose to go back to mathematical research, but he continued to enjoy programming, and when he needed it in his mathematical research, he could easily program.</p>
<h3>Love for quantum</h3>
<p>2) Another thing that Boris loved is “quantum”, the mathematics and physics of quantum mechanics and various connections to mathematics. Early on he proved his famous Tsirelson’s bound related to Bell’s inequalities, and later he was enthusiastic about the area of quantum computing. (And he learned it quickly, taught a course about it in 1997, and his 1997 lecture notes are still considered very useful.)</p>
<h3>Black Noise and noise sensitivity</h3>
<p>3) Perhaps the most significant mathematical connection between us was in the late 90s, and was centered around the theory of noise stability and noise sensitivity by Benjamini, Schramm and myself, which was closely related to a theory initiated by Boris Tsirelson and Anatoly Vershik. The translation between the different languages that we used and that Boris used was awkward, since the analog of Boolean functions that we studied was the “noise” that Boris studied, and the analog of noise sensitive Boolean functions in our language was “black noise” in Boris’s language. In any case, we had email discussions and we also met a few times with Itai and Oded regarding this connection.</p>
<h3>Black Noise and noise sensitivity II</h3>
<p>4)  Boris developed a very rich theory of black noise with relations to various areas of probability theory and operator algebras. He also found hypercontractivity that we used in our work quite useful to his applications, and also in this theory, he considered both classical and quantum aspects. I know only a little about Boris Tsirelson’s theory and its applications, but as far as tangent points with our Boolean interests are concerned, I can mention that Boris was enthusiastic by the <a href="https://arxiv.org/abs/1101.5820">result</a> of Schramm and Stas Smirnov that percolation is a “black noise” and also that, in 1999, Boris and Oded Schramm wrote a paper whose title started with “Trees not cubes!”, presenting a different angle on this theory.</p>
<p>Tsirelson saw white noise (what we call noise stability) as manifesting “linearity” while “black noise” (what we call noise sensitivity) as manifesting “non-linearity”. Over the years, I often asked him to explain this to me.</p>
<h3>Tsireslon’s Banach spaces</h3>
<p>5) Geometry of Banach spaces is a very strong area in Israel so naturally I heard as a graduate student about “Tsirelson’s space” from 1974 and some subsequent developments in the 80s. Boris Tsirelson constructed a  Banach space that does not contain an imbedding of <img src="https://s0.wp.com/latex.php?latex=%5Cell_p&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\ell_p" class="latex" title="\ell_p" /> or <img src="https://s0.wp.com/latex.php?latex=c_0&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="c_0" class="latex" title="c_0" />.</p>
<h3>Bible codes</h3>
<p>6) My first personal connection with Boris was related to claims regarding a hidden Bible Code, and a 1994 paper claiming a statistical proof of the existence of these Bible codes. For many years my attitude was that these claims should be ignored, but around 1997, I changed my mind and did some work to see what was going on. Now, Boris kept a site linked in his homepage devoted to developments regarding the Bible Code claims. In this site Boris kindly reported about my first 1997 paper on the topic, my observation that the proximity of two reported p-values for the two Bible code experiments was “too good to be true”, and my interpretation that this suggests that the claimed results manifest naïve statistical expectations rather than scientific reality.  A few weeks later, Boris reported about a much stronger evidence (by McKay and Bar Nathan) against the Bible Code claims (they demonstrated codes of similar quality in Tolstoy’s “War and Peace”) and subsequently after some time he lost interest in this topic.</p>
<h3>Quantum computing skepticism</h3>
<p>6) In 2005 we had some correspondence and meetings regarding my quantum computing skepticism. In his first email he told me that my reference to “decoherence” seemed strange and I realized that I consistently referred to “entanglement” as “decoherence” and to “decoherence” as “entanglement”.</p>
<p>7) In his 1997 lecture notes on quantum computing (that I cannot find on the web, so I count on my memory), Boris addressed the concerns of early quantum computers skeptics like Rolf Landauer. He did not accept the analogy between quantum computing and analog computation, but he also regarded the analogy with digital computation as problematic. Rather, he regarded quantum information based on qubits as something (at least a priori) different from both these examples. (Update: I found one non-broken link to the lecture notes; indeed the subtitle of Chapter 9 is “neither analog nor digital”.)</p>
<p>A joke that I heard from Boris at that time</p>
<p>8) I remember that once when I asked him about some aspects of quantum fault tolerance he told me the following joke: A student is entitled to a special exam, he arrives at the professor’s office, is given three questions to answer and he fails to do so. He request and is granted a make-up exam two weeks later. When the student shows up at the office two weeks later the professor, who forgot all about it, gave him the same three questions. “This is extremely unfair”, said the student “you ask me questions that you already know that I cannot answer.”</p>
<h3>Noise sensitivity and high energy physics</h3>
<p>9) In 2006 I came up with the idea that noise sensitivity might be a great idea for physics. Knowing very little physics, I wrote a little manifesto with this idea and tried it, among other people, on Boris. As it turned out, Boris had the idea that noise sensitivity could add a useful modeling power to physics (especially high energy physics) well before that time. (And by 2006 he was already a bit skeptical regarding his own idea.) He also told me that one of the motivations of his 1998 paper with Tolya Vershik came from some mathematical ideas related to physics of the big bang. When I asked him if this was written somewhere in the paper itself, he answered: “Of course, not!”</p>
<h3>Boris Tsirelson’s lecture at Oded’s memorial school</h3>
<p>10) in 2009 we organized a meeting in memory of Oded Schramm and Boris gave a lecture related to the Schramm-Smirnov “percolation is black noise” result with a single theorem. And what was remarkable about it that it was that he presented a classical theorem with a quantum proof. You can find the videotaped lecture here  (And here are the slides. Boris never wrote up this result.) Following this lecture we had a short correspondence with Scott A. and Greg K. about quantum proofs to classical theorems. (Namely theorems that do not mention quantum in the statement).</p>
<h3>Tsirelson’s problem</h3>
<p>11) Our last correspondence in 2019 was about Thomas Vidick’s  Notices AMS article about Tsirelson’s problem. (This was a couple of months before the announcement of the solution.) Boris was pleased to hear about these developments, as he was regarding earlier developments in this area. He humorously refers to the history of his problem on his homepage and this interview.</p>
<p>12) People who knew Boris regarded him as a genius from a very early age, and former students have fond memories of his classes.</p>
<p> </p>
<h3>More resources:</h3>
<p>Boris’s <a href="http://www.math.tau.ac.il/~tsirel/">home page</a> contains  “Museum to my courses” with many useful lecture notes; link to a small <a href="http://www.math.tau.ac.il/~tsirel/Research/qcomp/main.html">page on quantum computation</a> with a link to Boris’ <a href="http://www.math.tau.ac.il/~tsirel/Courses/QuantInf/syllabus.html">1997 lecture notes on quantum computing</a>.  Links to comments on some of Tsirelson’s famous papers. <a href="http://www.math.tau.ac.il/~tsirel/Research/mybound/main.html">Tsirelson’s 1980 bound</a>. Boris <a href="http://www.math.tau.ac.il/~tsirel/Research/refereed.html">published papers</a>, and his “<a href="http://www.math.tau.ac.il/~tsirel/Research/self-publ.html">self-published</a>” papers.</p>
<p>Boris was a devoted Wikipedian and his Wikipidea <a href="https://en.wikipedia.org/wiki/User:Tsirel">user page</a> is now devoted to his memory; Here is <a href="https://www.iqoqi-vienna.at/en/blog/article/boris-tsirelson/?fbclid=IwAR1PrVvK0u5XmnFLLoPMzMN3x9rY1WIdp1wrYZ_yYPlqSGRpXDkollYTCR0">a great interview</a> with Boris; A very nice <a href="https://www.scottaaronson.com/blog/?p=4626">memorial post</a> on Freeman Dyson and Boris Tsirelson on the Shtetl Optimized; Tim Gowers explains some ideas behind Tsirelson’s space <a href="https://twitter.com/wtgowers/status/1231704267641249794">over Twitter;</a> and here in <a href="https://gowers.wordpress.com/2009/02/17/must-an-explicitly-defined-banach-space-contain-c_0-or-ell_p/">Polymath2</a>.</p>
<p>Below the fold some emails of interest from Boris, mainly where he explained to me various mathematics. (More can be found in this page.)</p>
<p><span id="more-19411"></span></p>
<h2>Some email correspondence</h2>
<h3>Oct. 2019 Vidick’s paper</h3>
<p>Dear Boris<br />
<a href="https://www.ams.org/journals/notices/201910/rnoti-p1618.pdf">This paper</a> by Thomas Vidick may interest you,<br />
best regards and shana tova Gil</p>
<p>Oh yes, sure!<br />
Thank you.<br />
Shana metuka, Boris</p>
<p>(Remark: “metuka” means “sweet” in Hebrew.)</p>
<h3>Dec 2006 (about noise sensitivity and physics)</h3>
<p>(Dec 2006) My very first idea in this field (inspired by conversations with Vershik) was<br />
rather physical (that Big Bang could be a natural occurrence of black noise),<br />
and in fact the main example of “Tsirelson and Vershik 1998” follows this line<br />
(not explicitly, of course).</p>
<p>In local (not Big Bang related) physics, I think, nonlinearity could produce<br />
such effect. And then the very idea of `the field operator at a point’ (on<br />
the level of operator-valued Schwartz distributions or something like that)<br />
will fail. However, physicists do not want to consider this possibility<br />
without very serious indications that it really is used by the nature. And<br />
they are right…</p>
<h3>2005 quantum computer skepticism</h3>
<p>Subject: Re: Noise and more</p>
<p>Dear Gil:<br />
Yes, of course, we can meet and speak.</p>
<p>For now, I am not much bothered. I am not an expert in quantum error<br />
correction, but anyway, my feeling is that all physically reasonable<br />
“attacks” of Nature are repelled. Especially, your three-qubit attack<br />
looks to me not dangerous. And, “der Herr Gott is raffiniert, aber<br />
boschaft ist er nicht”; Nature never attacks like an enemy.</p>
<p>Yours, Boris.</p>
<h3>Quick 2000 comments on a (sloppy) draft of my survey paper</h3>
<p>Dear Gil:</p>
<p>Thank you for the text; I am reading it.<br />
For now, only a trivial remark: “Tsilerson” should be “Tsirelson” in<br />
[133] and [134]; and in [132] “” should be “Tsirelson”…</p>
<p>Shabat shalom,<br />
Yours, Boris.</p>
<h3>November 1998: Noise sensitivity and black noise</h3>
<p>Dear Gil,</p>
<p>I am reading your (with Itai and Oded) paper. Thanks.</p>
<p>Moreover, I am thinking about changing the title of my future talk in<br />
Vien accordingly: from “The five noises” to “The six noises” (or even<br />
more).<br />
To this end, however, I need to answer the following question.</p>
<p>Is there a mesh refinement limit for the percolation?</p>
<p>That is, take the lattice with a small pitch \eps. Choose two<br />
“electrodes”, say, two vertical intervals on two parallel vertical<br />
lines, and ask about the probability that they are connected (via the<br />
bond percolation on the whole band between the two vertical lines).<br />
Let the electrodes be macroscopic; that is, they do not depend on<br />
\eps. Does the probability of the event have a limit for \eps \to 0 ?<br />
If it does, then one more question: what about the joint distribution<br />
for a finite collection of such events? That is, I want to see a weak<br />
limit of these “discrete” random processes. It seems to me, the<br />
question is well-known and was discussed. However, do you know the<br />
answer?</p>
<p>Yours, Boris.</p>
<p>Dear Itai, Oded, and Gil,</p>
<p>Thank you for the information. I see that for now we have a<br />
conditional result: if there exists “the noise of percolation”, then<br />
it is not a white noise.<br />
Yours, Boris.</p>
<p>Dear Gil:<br />
&gt; I dont understand yet the concept of “noise” precisely</p>
<p>One of ways is this. A noise is a scaling limit for coin tossing.<br />
You choose a class of “macroscopic observables” and look, whether<br />
their joint distribution converges, when n\to\infty. If it does, you<br />
get a noise. (For percolation we do not know, does it or not.)<br />
Now, if all “macroscopic observables” are noise insensitive, it means<br />
that the noise is white. For a white noise, there is only one<br />
invariant, its dimension (or multiplicity).<br />
If all “macroscopic observables” are noise sensitive, the noise is<br />
black. Probably, there are a lot of black noises, but for now we have<br />
only two examples, without knowing, whether they are isomorphic, or<br />
not. Spectra may be used for classifying black noises. Say, it may<br />
happen that for each “macroscopic observable”, its spectrum is<br />
concentrated on sets having Hausdorf dimension less than something.<br />
If some “macroscopic observables” are noise sensitive but some others<br />
are not (except for constants, of course), then the noise is neither<br />
white nor black. It may happen that it is a direct sum of a white<br />
noise and a black noise. However, it may happen that it is not. We<br />
have for now two such examples: “noise if splitting” and “noise of<br />
stickiness” (they are probably non-isomorphic); both are found by Jonathan<br />
Warren. I am trying to understand, whether your matter can give more<br />
examples.</p>
<p> </p>
<h3>August 1998: Bible code story</h3>
<p>Dear Gil,</p>
<p>Thanks for the text.<br />
As for me, it is already an `overkill’, since for me the WRR94<br />
is basically dead. But maybe for others…</p>
<p>Yours, Boris.</p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/04/03/trees-not-cubes-memories-of-boris-tsirelson/"><span class="datestr">at April 03, 2020 08:03 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1644">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/04/01/approx-random-2020-is-virtual-from-the-get-go/">APPROX/RANDOM 2020 is Virtual From the Get Go</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>While <a href="https://randomconference.com/random-2020-home/">APPROX/RANDOM 2020</a> was scheduled for September, we decided to reduce uncertainty in these stormy days and declare it to be virtual already in the <a href="https://randomconference.files.wordpress.com/2020/04/randomapprox2020cfp-3.pdf">CFP</a>. We hope to have APPROX/RANDOM 2021 hosted in Seattle by UW, instead of this year,  So if you never sent papers to APPROX/RANDOM because you hate travel, this is your year to start!</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/04/01/approx-random-2020-is-virtual-from-the-get-go/"><span class="datestr">at April 01, 2020 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19719">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/04/01/an-update-from-israel-and-memories-from-singapore-partha-dasgupta-robin-mason-frank-ramsey-and-007/">A small update from Israel and memories from Singapore: Partha Dasgupta, Robin Mason, Frank Ramsey, and 007</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h3>A small update about the situation here in Israel</h3>
<p>Eight weeks ago <a href="https://gilkalai.wordpress.com/2020/02/03/thinking-about-the-people-of-wuhan-and-china/">I wrote</a> that my heart goes out to the people of Wuhan and China, and these days my heart goes out to people in Italy, Spain, the US, Iran, France, the United Kingdom, Germany, Netherland and many other countries all over the world. Of course, I am especially worried about the situation here in my beloved country Israel, and let me tell you a little about it.</p>
<p>The pandemic started here late but it hit us pretty hard with 5,358 identified cases yesterday. Severe measures of social distancing were gradually introduced, and right now it is too early to tell if the pandemic is under control.</p>
<p>My part in this struggle is to stay at home. (Many Israeli scientists are making various endeavors and proposing ideas of various kind for fighting the disease and I salute them all for their efforts.) Like all of us I am very thankful to medical and other essential workers who are in the front-lines. As a scientist, I am especially impressed by the people from the Ministry of Health who manage the crisis and communicate with the public. They represent the very best we can offer in terms of science and medicine, decision making, gathering information, communicating with the public, and managing the crisis. In the picture below you can see three of the leaders – Moshe Bar Siman Tov (middle) Prof. Itamar Grotto (right) and Professor Sigal Sadetzki (left).</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/listen.png"><img src="https://gilkalai.files.wordpress.com/2020/03/listen.png?w=640&amp;h=371" alt="" width="640" class="alignnone size-full wp-image-19695" height="371" /></a></p>
<h2>And now for today’s post</h2>
<p>We had a tradition of sharing entertaining taxi-and-more stories and this post belongs to this category. We note that our highest quality story teller Michal Linial, a prominent Israeli biologist, is now involved in various aspects of the struggle against the disease. Our post today is part of<a href="https://gilkalai.files.wordpress.com/2020/03/gil-michal.docx"> a report by Michal Feldman and me on our experience from the ICA3 conferences in Singapore and Birmingham</a>.</p>
<h2>Partha Dasgupta, Robin Mason, Frank Ramsey, and James Bond</h2>
<p>After hearing about him for many years, it was a great pleasure for both Michal Feldman and myself to finally meet Partha Dasgupta in person and to listen to his lecture. Partha who is the Frank Ramsey Professor of Economics at Cambridge was introduced by a person, who entered the room directly from an intercontinental flight, whom we did not know but who made a strong impression on us. He devoted part of his introduction to Frank Ramsey who was a mathematician, philosopher and economist, and who had made fundamental contributions to algebra and had developed the canonical model of saving in economic growth, before he died at the young age of 26. (And yes! also Ramsey’s theorem!)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/james-bond.png"><img src="https://gilkalai.files.wordpress.com/2020/03/james-bond.png?w=640&amp;h=423" alt="" width="640" class="alignnone size-full wp-image-19699" height="423" /></a></p>
<p>Seeing the introducer, Robin Mason, three words came into our minds (more precisely two words, one repeated twice): “Bond, James Bond.”</p>
<p>Indeed, this has led to the following sequence of profound ideas:</p>
<p>1) Robin Mason is a perfect choice for a new generation James Bond.</p>
<p>2) The name “James Bond” is overused. “Robin Mason” is a perfect name to replace the name “James Bond”.</p>
<p>3) Espionage is a little obsolete and it lost much of its prestige and charm. Science and academia is the new thing! An international interdisciplinary academics is the perfect profession which, at present, deserves the prestige formely associated with espionage.</p>
<p>In summary, we came a full circle. Robin Mason is the perfect new choice for James Bond, “Robin Mason” is the perfect new name to replace the name “James Bond,” and Mason’s academic activities and title of Pro-Vice-Chancellor (International) are the perfect replacement for Bond’s activities and the title ‘007’.</p>
<p>(The option of Mason playing his role on the movies rather than in real life should be considered. ‘Q’ could be handy for science as well. )</p>
<p><a href="https://youtu.be/dMSHmHc0z-E">Clique here</a> for Robin’s introduction and Partha’s lectur</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/04/01/an-update-from-israel-and-memories-from-singapore-partha-dasgupta-robin-mason-frank-ramsey-and-007/"><span class="datestr">at April 01, 2020 07:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16904">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/04/01/research-at-home/">Research at Home</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>An idea for human-interest interviews</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/04/01/research-at-home/femalefool/" rel="attachment wp-att-16906"><img src="https://rjlipton.files.wordpress.com/2020/03/femalefool.png?w=137&amp;h=213" alt="" width="137" class="alignright wp-image-16906" height="213" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Pixabay free <a href="https://pixabay.com/illustrations/toon-figure-female-fool-funny-4292442/">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Dr. Lofa Polir is, like many of us, working from home. When we last <a href="https://rjlipton.wordpress.com/2018/04/01/the-entropy-of-baseball/">wrote</a> about her two years ago, she had started work for the Livingston, Louisiana branch of <a href="https://www.ligo.caltech.edu/page/about">LIGO</a>. They sent her and the rest of the staff home on March 19 and <a href="https://www.ligo.caltech.edu/news/ligo20200326">suspended</a> observations on the 26th. Since Polir’s duties already included public outreach, she is looking to continue that online.</p>
<p>
Today we helped Dr. Polir interview another pandemic-affected researcher.</p>
<p>
We liked her idea of interviewing young people just starting their careers, who are facing unexpected uncertainties. Her first choice was a new graduate of Cambridge University doing fundamental work related to LIGO. Unfortunately, he had been unable to install a current version of Zoom on his handheld device, or maybe afraid owing to security <a href="https://twitter.com/random_walker/status/1244987617676050434?s=11">issues</a>. So she requested the special equipment we have used to <a href="https://rjlipton.wordpress.com/2011/10/31/an-interview-with-kurt-gdel/">interview</a> people <a href="https://rjlipton.wordpress.com/2012/11/03/more-interview-with-kurt-godel/">in</a> the <a href="https://rjlipton.wordpress.com/2013/11/15/the-graph-of-math/">past</a>. </p>
<p>
He replied at the speed of light that he was willing to do the interview so long as we respected some privacy measures. As for what name to use, he said we could just call him Izzy—Izzy Jr., in fact. So Dick, I, and Dr. Polir all used our own Zoom to port into our machine’s console room. The connection worked right away as Izzy’s head glimmered into view.</p>
<p>
</p><p></p><h2> Starting The Interview </h2><p></p>
<p></p><p>
At first glimpse, all we could see was his long, light-brown hippie hair. This really surprised us—not the image we had of Cambridge—and we gasped about it before even saying hello. He replied that it was fashion from the Sixties. We asked how his family was doing and he said his fathers had passed on but mother and young siblings were at home and fine. We think he said “fathers” plural—the machine rendered him in a drawl like Mick Jagger and he was hard to follow.</p>
<p>
Izzy picked up on our discomfort and immediately assured us he hadn’t been doing any drugs: “You can’t get them anyway because they’re all being diverted to treat the sick.” But he did open up to us that he was in some kind of withdrawal. He confessed that he had resorted to looking at the sun with one eye. “It was ecstasy but bad—I still can see only reds and blues with that eye, and I need to use an extra-large rectangular cursor to read text.” We were curious what brand of handheld device he was using because of his problems with Zoom, and he told us it was a Napier 1660 by <a href="http://www.oughtred.org/history.shtml">Oughtred, Ltd.</a> We hadn’t heard of that model but he said he’d connected three of them into a good home lab setup.</p>
<p>
We asked how he was coping with distance teaching, but he said he hadn’t yet started his faculty position at Trinity College. We were surprised to learn that lecture attendance at Cambridge University is optional. “I shall be required to give the lectures but nobody will come to them so that’s all the same now—at least here I’ll have a cat for audience. No dogs and not my mother or siblings—I’d sooner burn the house down.” He quickly added, “Oh, my mother and I get along fine now and I love playing teatime with my little sisters.”</p>
<p>
We really didn’t want to go into Izzy’s personal life, and I tried to shift the small-talk by noting a little chess set on a shelf behind him. He snapped that he shouldn’t have spent money on it and he was a poor player anyway. We thought, wow, either this guy’s really down on himself or the cabin fever of the pandemic is getting to him. So Dick, always quick to pick up on things and find ways of encouragement, said:</p>
<p>
“Dr. Polir here works on gravity and we’re told you have some great new ideas about it. We’d love to hear them.”</p>
<p>
“Yes, I do—or did. But something happened yesterday that is making me realize that it’s all wrong, rubbish really…”</p>
<p>
</p><p></p><h2> In the Garden </h2><p></p>
<p></p><p>
Izzy started by explaining that it’s a basic principle of alchemy that all objects have humors that can manifest as kinds of magnetism. (“Alchemy”? did we hear him right?) If you realize that the Earth and Sun are objects just like any other then you can model gravity that way. You just need to assign each object a number called its “mass” and then you get the equation </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++F+%3D+G+%5Cfrac%7Bm_1+m_2%7D%7Br%5E2%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  F = G \frac{m_1 m_2}{r^2} " class="latex" title="\displaystyle  F = G \frac{m_1 m_2}{r^2} " /></p>
<p>for the force of attraction, where <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> is the distance between the objects with masses <img src="https://s0.wp.com/latex.php?latex=%7Bm_1%2Cm_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m_1,m_2}" class="latex" title="{m_1,m_2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> is a constant that depends on your units.</p>
<p>
“We understand all that,” said Dr. Polir.</p>
<p>
Izzy said the point is that <img src="https://s0.wp.com/latex.php?latex=%7BG%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{G}" class="latex" title="{G}" /> depends <b>only</b> on your units and is the same regardless of where you are on Earth or on the Moon or wherever. It is very small, though. Then he went into his story of yesterday.</p>
<blockquote><p><b> </b> <em> “I was in our garden by the path to the neighbor’s farm. I was supposed to be watching my little brother Benjamin who wanted to help harvest squash but I hate farming so I let him go without me. I was lying under an apple tree for shade when an apple fell and I realized all my mistakes.” </em>
</p></blockquote>
<p></p><p>
“What?,” we thought silently. We didn’t need to speak up—Izzy launched right into his litany of error:</p>
<blockquote><p><b> </b> <em> “First, I’d thought the force was in what made the apple fall, but that’s nonsense. The apple would fall naturally because down is the shortest path it would be on if the tree branch were not holding it back. The only force is the tensile strength of the branch which was restraining it. I think that the tensile force really is magnetism, by the way.”</em></p><em>
<p>
“Second, it’s ridiculous to think the force is coming <b>from</b> the Earth. On first principles, it could come from the ground, but that’s not what the equations say. They could have it all coming from one point in the <b>center</b> of the Earth. Just one point—four thousand miles deep!”</p>
</em><p><em>
“Third and worst, though, is when you apply it to the Sun and the Earth. My equation means they are exerting force on each other instantaneously. But they are millions of miles apart. Whereas, the tree was <b>touching</b> the apple. Force can work only by touch, not by some kind of spooky action at a distance.” </em>
</p></blockquote>
<p></p><p>
We realized what he was driving at. Dick again always likes to encourage, so he said:</p>
<p>
“But the math you developed for this force theory—surely it is good for calculations…?”</p>
<blockquote><p><b> </b> <em> “No it’s not—it’s the Devil’s own box. I can calculate two bodies—the Earth and the Sun, or the Moon and the Earth if you suppose there is no Sun, but as soon as you have all three bodies it’s a bog. Worst of all, I can arrange five bodies so that one of them gets accelerated to infinite velocity—<a href="https://rjlipton.wordpress.com/2019/10/31/hobgoblins-in-our-equations/">in finite time</a>. This is a clear impossibility, a contradiction, so by <em>modus tollens</em>… it can all go in the bin.” </em>
</p></blockquote>
<p></p><p>
We didn’t think it would help to tell him that his math was good enough to <a href="https://ntrs.nasa.gov/archive/nasa/casi.ntrs.nasa.gov/19720022040.pdf">calculate</a> a Moon landing but not to locate a friend’s house while driving. He supplied his own <em>coup-de-grâce</em> anyway:</p>
<blockquote><p><b> </b> <em> “And even the two-body calculations are tainted. I can calculate the orbits of the planets but the equations I get aren’t stable. I would wind up having to postulate something like God keeps the planets on their tracks. Yes, you need an intelligent Agent to start the planets going—all in one plane, basically—but to need such intervention all the time defeats the point of having equations.” </em>
</p></blockquote>
<p>
</p><p></p><h2> Inklings </h2><p></p>
<p></p><p>
We asked Izzy what he was going to do. He said that the one blessing of enforced solitude is that one gets time to reflect on things and deepen the foundations. And he said he’d had an idea later that afternoon.</p>
<blockquote><p><b> </b> <em> “Toward supper I realized I needed to get Benjamin home. The path to the farm is straight except it goes over a mound. I was sauntering along and when I got to the hill I realized that if I didn’t watch it I’d have fallen right into it. So that got me thinking. First, what I thought was straight on the path was really a curve—the Earth is after all a ball. We think space is straight, but maybe it too is curved. So when I’m standing here, perhaps I would really be moving in a diagonally down direction, but the Earth is stopping me. The Irish blessing says, ‘may the road rise up to meet you.’ Perhaps it does.” </em>
</p></blockquote>
<p></p><p>
“So are you doing math to work that out?,” I ventured.</p>
<blockquote><p><b> </b> <em> “I started after supper. One good thing is that it allows light to be affected by gravity—which I was already convinced of—even if light has no mass. But a problem is that it appears Time would have to be included as curved. That does not make sense either.” </em>
</p></blockquote>
<p></p><p>
We asked when he might write up all this. He said he didn’t want to be quick to publish something so flawed on the one hand, or incomplete on the other, “unless someone else be about to publish the same.” We noted that there weren’t going to be any in-person conferences to present papers at for awhile anyway.</p>
<blockquote><p><b> </b> <em> “Besides, that’s not what I’m most eager to do. What the respite is really giving me time for is to start writing up my work on Theology. That’s most important—it could have stopped thirty years of war. For one thing, <a href="https://en.wikipedia.org/wiki/Homoiousios">homoiousios</a>, not <a href="https://en.wikipedia.org/wiki/Homoousios">homoousios</a>, is the right rendering. There will be a time and times and the dividing of times in under 400 years <a href="https://www.questia.com/library/journal/1G1-116141910/a-time-and-times-and-the-dividing-of-time-isaac">anyway</a>.” </em>
</p></blockquote>
<p></p><p>
That last statement somehow did not reassure us. We thanked Izzy Jr. for the interview and he gave consent to publish it posthumously.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
We hope that your April Fool’s Day is such as to allow a time to laugh. But also seriously, would you be interested in the idea of our interviewing people during these times? Is there anyone you would like to suggest?</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/04/01/research-at-home/"><span class="datestr">at April 01, 2020 05:10 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/042">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/042">TR20-042 |  Poly-time blackbox identity testing for sum of log-variate constant-width ROABPs | 

	Pranav Bisht, 

	Nitin Saxena</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Blackbox polynomial identity testing (PIT) affords 'extreme variable-bootstrapping' (Agrawal et al, STOC'18; PNAS'19; Guo et al, FOCS'19). This motivates us to study log-variate read-once oblivious algebraic branching programs (ROABP). We restrict width of ROABP to a constant and study the more general sum-of-ROABPs model. We give the first poly($s$)-time blackbox PIT for sum of constant-many, size-$s$, $O(\log s)$-variate constant-width ROABPs. The previous best for this model was quasi-polynomial time (Gurjar et al, CCC'15; CC'16) which is comparable to brute-force in the log-variate setting. Also, we handle unbounded-many such ROABPs if each ROABP computes a homogeneous polynomial. 

Our new techniques comprise-- (1) an ROABP computing a homogeneous polynomial can be made syntactically homogeneous in the same width; and (2) overcome the hurdle of unknown variable order in sum-of-ROABPs in the log-variate setting (over any field).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/042"><span class="datestr">at March 31, 2020 01:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1640">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/03/30/forc-2020-going-strong-going-virtual/">FORC 2020: Going Strong, Going Virtual</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>FORC 2020 <a href="https://responsiblecomputing.org/accepted-papers/?fbclid=IwAR0NTKaoKheiOmzYYyBqbDVtnkrPL8ooELD2RvfRFe7BHMF5tbgFg_bV840">accepted papers are out</a>. Despite the <a href="https://theorydish.blog/2019/10/30/toc-for-society/">last minute announcement</a> and minimal advertising of this new conference, we have an exciting and strong program. This confirms our conviction that the new conference fills an important need for a home to the TOC sub-community that works on the societal aspects of computation.</p>
<p>Unfortunately, but non-surprisingly, the conference will be virtual this year. But I’m sure that, thanks to <a href="https://www.cis.upenn.edu/~aaroth/">Aaron Roth</a> and to the inaugural PC, we will make the best what’s possible and have a great event.</p></div>







<p class="date">
by Omer Reingold <a href="https://theorydish.blog/2020/03/30/forc-2020-going-strong-going-virtual/"><span class="datestr">at March 30, 2020 08:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16861">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/">Logic and Star-Free, Part Deux</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>A visual proof with no abstract-algebra overhead</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/perrinpin/" rel="attachment wp-att-16863"><img src="https://rjlipton.files.wordpress.com/2020/03/perrinpin.png?w=200&amp;h=154" alt="" width="200" class="alignright wp-image-16863" height="154" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="http://www-igm.univ-mlv.fr/~perrin/">src1</a>, <a href="https://www.ae-info.org/ae/Member/Pin_Jean-Eric">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Dominique Perrin and Jean-Éric Pin are French mathematicians who have done significant work in automata theory. Their 1986 <a href="https://core.ac.uk/download/pdf/82354218.pdf">paper</a> “First-Order Logic and Star-Free Sets” gave a new proof that first-order logic plus the <img src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{&lt;}" class="latex" title="{&lt;}" /> relation characterizes star-free regular sets.</p>
<p>
Today we present their proof in a new visual way, using “stacked words” rather than their “marked words.” We also sidestep algebra by appealing to the familiar theorem that every regular language has a unique minimal deterministic finite automaton (DFA).<br />
<span id="more-16861"></span></p>
<p>
The first <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a> in this series defined the classes <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> for star-free regular and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> for first-order logic where variables <img src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%2Cw%2C%5Cdots%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u,v,w,\dots}" class="latex" title="{u,v,w,\dots}" /> range over the indices <img src="https://s0.wp.com/latex.php?latex=%7B0%2C%5Cdots%2Cn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0,\dots,n-1}" class="latex" title="{0,\dots,n-1}" /> of a string <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. For any character <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> in the alphabet <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> there is the predicate <img src="https://s0.wp.com/latex.php?latex=%7BX_c%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c(u)}" class="latex" title="{X_c(u)}" /> saying that the character in position <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> equals <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" />. The first part proved that for any language <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Cin+%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \in \mathsf{SF}}" class="latex" title="{A \in \mathsf{SF}}" /> there is a sentence <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_A}" class="latex" title="{\psi_A}" /> using only predicates <img src="https://s0.wp.com/latex.php?latex=%7BX_c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c}" class="latex" title="{X_c}" /> and the relation <img src="https://s0.wp.com/latex.php?latex=%7Bu+%3C+v%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u &lt; v}" class="latex" title="{u &lt; v}" /> besides the usual quantifiers and Boolean operations of first-order logic. such that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_A}" class="latex" title="{\psi_A}" /> defined <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />. That is, it proved <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%5Csubseteq%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}\subseteq\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{SF}\subseteq\mathsf{FO}[&lt;]}" />.</p>
<p>
A key trick was to focus not on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_A}" class="latex" title="{\psi_A}" /> but on a formula <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_A%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_A(i,j)}" class="latex" title="{\phi_A(i,j)}" /> expressing that the part of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> from position <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> (inclusive) to <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> (exclusive) belongs to <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />. To prove the converse direction, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%5Csubseteq%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]\subseteq\mathsf{SF}}" class="latex" title="{\mathsf{FO}[&lt;]\subseteq\mathsf{SF}}" />, we focus not on middles of strings but on prefixes and suffixes. The previous <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a> proved two lemmas showing that if <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> is star-free then for any string <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, so are its prefix and suffix languages: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++L%5Cbackslash+y+%26%3D%26+%5C%7Bz%3A+yz+%5Cin+L%5C%7D%5C%5C+L%2Fy+%26%3D%26+%5C%7Bx%3A+xy+%5Cin+L%5C%7D.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  L\backslash y &amp;=&amp; \{z: yz \in L\}\\ L/y &amp;=&amp; \{x: xy \in L\}. \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  L\backslash y &amp;=&amp; \{z: yz \in L\}\\ L/y &amp;=&amp; \{x: xy \in L\}. \end{array} " /></p>
<p>We will piece together star-free expressions for a multitude of <img src="https://s0.wp.com/latex.php?latex=%7BL%2Fy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L/y}" class="latex" title="{L/y}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BL+%5Cbackslash+y%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L \backslash y}" class="latex" title="{L \backslash y}" /> sets that come from analyzing minimum DFAs <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> at each induction step, until we have built a big star-free expression <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />. This sounds complex—and is complex—but all the steps are elementary. At the end we’ll try to see how big <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> gets. <b>Again the rest of this post up to end notes is written by Daniel Winton</b>.</p>
<p>
</p><p>
</p><p></p><h2> Stacked Words and FO Formulas </h2><p></p>
<p></p><p>
We implement the “marked words” idea of Perrin and Pin by using extra dimensions rather than marks. Consider any formula <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28u_1%2C+%5Cdots%2C+u_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi(u_1, \dots, u_j)}" class="latex" title="{\phi(u_1, \dots, u_j)}" /> in FO[<img src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{&lt;}" class="latex" title="{&lt;}" />] where <img src="https://s0.wp.com/latex.php?latex=%7Bu_1%2C%5Cdots%2Cu_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_1,\dots,u_j}" class="latex" title="{u_1,\dots,u_j}" /> are the free variables. Our "stacked words" have <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> extra rows underneath the top level holding the string <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />. Each row <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> has the same length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> as <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and contains a single <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%28n-1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(n-1)}" class="latex" title="{(n-1)}" /> <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />s. The column <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> in which the <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> lies gives the value of the variable <img src="https://s0.wp.com/latex.php?latex=%7Bu_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_i}" class="latex" title="{u_i}" />. Thus the alphabet of our stacked words is <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%5E%7B%28j%29%7D+%3D+%5CSigma%5Ctimes%5C%7B0%2C1%5C%7D%5Ej%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma^{(j)} = \Sigma\times\{0,1\}^j}" class="latex" title="{\Sigma^{(j)} = \Sigma\times\{0,1\}^j}" />. Here is an example:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/stackedword/" rel="attachment wp-att-16865"><img src="https://rjlipton.files.wordpress.com/2020/03/stackedword.jpg?w=242&amp;h=248" alt="" width="242" class="aligncenter wp-image-16865" height="248" /></a></p>
<p></p><p><br />
Each column is really a single character <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Cin+%5CSigma%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C \in \Sigma^{(j)}}" class="latex" title="{C \in \Sigma^{(j)}}" />, but we picture its entries as characters in <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{0,1\}}" class="latex" title="{\{0,1\}}" />. For any row <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, define <img src="https://s0.wp.com/latex.php?latex=%7BY_%7Bi%2C0%7D%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y_{i,0}(\cdot)}" class="latex" title="{Y_{i,0}(\cdot)}" /> to be the disjunction of <img src="https://s0.wp.com/latex.php?latex=%7BX_C%28%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_C(\cdot)}" class="latex" title="{X_C(\cdot)}" /> over all <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" /> that have a <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> in entry <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, and define <img src="https://s0.wp.com/latex.php?latex=%7BY_%7Bi%2C1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y_{i,1}}" class="latex" title="{Y_{i,1}}" /> similarly. Then the following sentence expresses the “format condition” that row <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> has exactly one <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28%5Cexists+k%29%5BY_%7Bi%2C1%7D%28k%29+%5Cland+%28%5Cforall+%5Cell%29+%5B%5Cell+%5Cneq+k+%5Crightarrow+Y_%7Bi%2C0%7D%28k%29%5D%5D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (\exists k)[Y_{i,1}(k) \land (\forall \ell) [\ell \neq k \rightarrow Y_{i,0}(k)]]. " class="latex" title="\displaystyle  (\exists k)[Y_{i,1}(k) \land (\forall \ell) [\ell \neq k \rightarrow Y_{i,0}(k)]]. " /></p>
<p>This readily transforms into a star-free expression for the language of stacked words with exactly one <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in row <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_i+%3D+C_%7Bi%2C0%7D%5E%2A+C_%7Bi%2C1%7D+C_%7Bi%2C0%7D%5E%2A%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \alpha_i = C_{i,0}^* C_{i,1} C_{i,0}^*, " class="latex" title="\displaystyle  \alpha_i = C_{i,0}^* C_{i,1} C_{i,0}^*, " /></p>
<p>Here <img src="https://s0.wp.com/latex.php?latex=%7BC_%7Bi%2C0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_{i,0}}" class="latex" title="{C_{i,0}}" /> is the union of all stacked characters that have a <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> in entry <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, and <img src="https://s0.wp.com/latex.php?latex=%7BC_%7Bi%2C1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_{i,1}}" class="latex" title="{C_{i,1}}" /> is similarly defined. This is where the examples in the previous <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a> about finite unions inside stars come in handy. The upshot is that </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Calpha_0+%3D+%5Cbigcap_%7Bi%3D1%7D%5Ej+%5Calpha_i+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \alpha_0 = \bigcap_{i=1}^j \alpha_i " class="latex" title="\displaystyle  \alpha_0 = \bigcap_{i=1}^j \alpha_i " /></p>
<p>is a <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> expression that enforces the “format condition” over all rows. We will use this at the crux of the proof; whether <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_0}" class="latex" title="{\alpha_0}" /> is really needed is a question at the end. If we take the format for granted, then the main advantage of our stacked words will be visualizing how to decompose automata according to when the <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in a critical row is read.</p>
<p>
</p><p></p><h2> From FO To SF </h2><p></p>
<p></p><p>
The proof manipulates formulas <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28u_1%2C%5Cdots%2Cu_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi(u_1,\dots,u_j)}" class="latex" title="{\phi(u_1,\dots,u_j)}" /> having the <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> free variables shown. The corresponding language <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" /> is the set of stacked words that make <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%28k_1%2C%5Cdots%2Ck_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi(k_1,\dots,k_j)}" class="latex" title="{\phi(k_1,\dots,k_j)}" /> true, where for each <img src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cleq+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i \leq j}" class="latex" title="{i \leq j}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bk_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k_i}" class="latex" title="{k_i}" /> is the position of the lone <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in row <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, which gives the value of <img src="https://s0.wp.com/latex.php?latex=%7Bu_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_i}" class="latex" title="{u_i}" />. </p>
<blockquote><p><b>Theorem 1</b> <em> For all formulas <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" />, <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%5Cin%5Cmathsf%7BSF%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L_\phi\in\mathsf{SF}}" class="latex" title="{L_\phi\in\mathsf{SF}}" />. </em>
</p></blockquote>
<p></p><p>
Without loss of generality we may suppose <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> is in <em>prenex form</em>, meaning that it has all quantifiers out front. If there are <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> variables of which <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> are free, this means </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi+%3D+%28Q_%7Bj%2B1%7D+u_%7Bj%2B1%7D%29%5Ccdots+%28Q_r+u_r%29%5Cmu%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \phi = (Q_{j+1} u_{j+1})\cdots (Q_r u_r)\mu, " class="latex" title="\displaystyle  \phi = (Q_{j+1} u_{j+1})\cdots (Q_r u_r)\mu, " /></p>
<p>where each <img src="https://s0.wp.com/latex.php?latex=%7BQ_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_i}" class="latex" title="{Q_i}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cforall%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\forall}" class="latex" title="{\forall}" /> or <img src="https://s0.wp.com/latex.php?latex=%7B%5Cexists%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\exists}" class="latex" title="{\exists}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" /> has no quantifiers. If we picture the variables <img src="https://s0.wp.com/latex.php?latex=%7Bu_1%2C%5Cdots%2Cu_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_1,\dots,u_j}" class="latex" title="{u_1,\dots,u_j}" /> as once having had quantifiers <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%2C%5Cdots%2CQ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1,\dots,Q_j}" class="latex" title="{Q_1,\dots,Q_j}" />, then the proof—after dealing with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" />—restores them one at a time, beginning with <img src="https://s0.wp.com/latex.php?latex=%7BQ_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_j}" class="latex" title="{Q_j}" />. That is the induction. We prove the base case <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" /> here and the induction case in the coming sections.</p>
<p>
<em>Proof:</em>  Quantifier free formulas in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> are Boolean combinations of the <em>atomic predicates</em> <img src="https://s0.wp.com/latex.php?latex=%7BX_c%28u_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c(u_i)}" class="latex" title="{X_c(u_i)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bu_h+%3C+u_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_h &lt; u_i}" class="latex" title="{u_h &lt; u_i}" />. Here <img src="https://s0.wp.com/latex.php?latex=%7BX_c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c}" class="latex" title="{X_c}" /> is only for the characters <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c \in \Sigma}" class="latex" title="{c \in \Sigma}" />, not the stacked characters <img src="https://s0.wp.com/latex.php?latex=%7BC+%5Cin+%5CSigma%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C \in \Sigma^{(j)}}" class="latex" title="{C \in \Sigma^{(j)}}" />. But inside <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mu}" class="latex" title="{\mu}" /> (when we have <img src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j = r}" class="latex" title="{j = r}" />) we have to deal with the whole stack to represent <img src="https://s0.wp.com/latex.php?latex=%7BX_c%28u_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c(u_i)}" class="latex" title="{X_c(u_i)}" />. Putting <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma+%3D+%5C%7Bc_1%2C%5Cdots%2Cc_%7B%5Cell%7D%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma = \{c_1,\dots,c_{\ell}\}}" class="latex" title="{\Sigma = \{c_1,\dots,c_{\ell}\}}" />, the expression can be viewed schematically as:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/xcstackedexp/" rel="attachment wp-att-16867"><img src="https://rjlipton.files.wordpress.com/2020/03/xcstackedexp.jpg?w=600&amp;h=126" alt="" width="600" class="aligncenter size-large wp-image-16867" height="126" /></a></p>
<p></p><p><br />
As illustrated above, using the initial lemma in the part-1 <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">post</a>, this is equivalent to a star-free regular expression. The other atomic predicate, <img src="https://s0.wp.com/latex.php?latex=%7Bu_h+%3C+u_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_h &lt; u_i}" class="latex" title="{u_h &lt; u_i}" />, is true when we have a stacked word <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> of the form: </p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/ltstackedword2/" rel="attachment wp-att-16891"><img src="https://rjlipton.files.wordpress.com/2020/03/ltstackedword2.jpg?w=300&amp;h=250" alt="" width="300" class="aligncenter wp-image-16891" height="250" /></a></p>
<p></p><p><br />
It is not important to have <img src="https://s0.wp.com/latex.php?latex=%7Bh+%3C+i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h &lt; i}" class="latex" title="{h &lt; i}" />; these are just the labels of the variables. Their values <img src="https://s0.wp.com/latex.php?latex=%7Bk_1%2Ck_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k_1,k_2}" class="latex" title="{k_1,k_2}" /> must obey <img src="https://s0.wp.com/latex.php?latex=%7Bk_1+%3C+k_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k_1 &lt; k_2}" class="latex" title="{k_1 &lt; k_2}" />, meaning that the <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in row <img src="https://s0.wp.com/latex.php?latex=%7Bh%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{h}" class="latex" title="{h}" /> comes in an earlier column than the <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in row <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />. The characters of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> in the top row are immaterial. We can capture this condition over all strings <img src="https://s0.wp.com/latex.php?latex=%7BY%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Y}" class="latex" title="{Y}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%5E%7B%28j%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma^{(j)}}" class="latex" title="{\Sigma^{(j)}}" /> by the expression:</p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/ltstackedexp/" rel="attachment wp-att-16872"><img src="https://rjlipton.files.wordpress.com/2020/03/ltstackedexp.jpg?w=600&amp;h=212" alt="" width="600" class="aligncenter size-large wp-image-16872" height="212" /></a></p>
<p></p><p><br />
Again by the lemma in Part 1, this yields a star-free expression. To complete the basis, we note that if <img src="https://s0.wp.com/latex.php?latex=%7BL_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_1}" class="latex" title="{L_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BL_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_2}" class="latex" title="{L_2}" /> have star-free expressions <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_1}" class="latex" title="{\alpha_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_2}" class="latex" title="{\alpha_2}" /> corresponding to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_1%2C+%5Cphi_2%5Cin+%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_1, \phi_2\in \mathsf{FO}[&lt;]}" class="latex" title="{\phi_1, \phi_2\in \mathsf{FO}[&lt;]}" />, then <img src="https://s0.wp.com/latex.php?latex=%7B%5Clnot%5Cphi_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lnot\phi_1}" class="latex" title="{\lnot\phi_1}" /> is represented by <img src="https://s0.wp.com/latex.php?latex=%7B%5Csim%7B%5Calpha_1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sim{\alpha_1}}" class="latex" title="{\sim{\alpha_1}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_1%5Clor%5Cphi_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_1\lor\phi_2}" class="latex" title="{\phi_1\lor\phi_2}" /> by <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_1%5Ccup%5Calpha_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_1\cup\alpha_2}" class="latex" title="{\alpha_1\cup\alpha_2}" />, both of which are clearly star-free. </p>
<p>
</p><p></p><h2> Strategy For the Induction Case </h2><p></p>
<p></p><p>
Assume that all formulas in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell+%3D+r+-+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell = r - j}" class="latex" title="{\ell = r - j}" /> quantifiers have star-free translations. We will show that any formula in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> with <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell+1}" class="latex" title="{\ell+1}" /> quantifiers also has a star-free translation. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%28u_1%2C...+%2Cu_%7Bj-1%7D%29%3D%5Cexists+u_j+%5Cphi%28u_1%2C...%2C+u_j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi(u_1,... ,u_{j-1})=\exists u_j \phi(u_1,..., u_j)}" class="latex" title="{\psi(u_1,... ,u_{j-1})=\exists u_j \phi(u_1,..., u_j)}" /> where <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> is a formula in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> that has <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> total variables, <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> free variables and <img src="https://s0.wp.com/latex.php?latex=%7Bm-j%3D%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m-j=\ell}" class="latex" title="{m-j=\ell}" /> quantifiers. We are allowed to assume the first quantifier in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> is existential as <img src="https://s0.wp.com/latex.php?latex=%7B%5Cexists+%5Cequiv+%5Clnot+%28%5Cforall+%5Clnot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\exists \equiv \lnot (\forall \lnot)}" class="latex" title="{\exists \equiv \lnot (\forall \lnot)}" /> and we observed above that the star-free expressible formulas in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> are closed under negation. </p>
<p>
The language of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" /> is given by: </p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%3D%5C%7Bz%5Cin%28%5CSigma%5Ctimes+%5C%7B0%2C1%5C%7D%5E%7Bj-1%7D%29%5E%2A%3A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\psi=\{z\in(\Sigma\times \{0,1\}^{j-1})^*:}" class="latex" title="{L_\psi=\{z\in(\Sigma\times \{0,1\}^{j-1})^*:}" /> we can add a <img src="https://s0.wp.com/latex.php?latex=%7B%7B%28j%2B1%29%7D%5E%7Bth%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{(j+1)}^{th}}" class="latex" title="{{(j+1)}^{th}}" /> row to each of the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> characters of <img src="https://s0.wp.com/latex.php?latex=%7Bz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z}" class="latex" title="{z}" /> using <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> minus one <img src="https://s0.wp.com/latex.php?latex=%7B0%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0'}" class="latex" title="{0'}" />s and one <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> such that the resulting string <img src="https://s0.wp.com/latex.php?latex=%7Bz%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z'}" class="latex" title="{z'}" /> belongs to <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%5C%7D.%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi\}.}" class="latex" title="{L_\phi\}.}" /> </p>
<p>We must show that <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\psi}" class="latex" title="{L_\psi}" /> is star-free. As <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> has <img src="https://s0.wp.com/latex.php?latex=%7B%5Cell%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\ell}" class="latex" title="{\ell}" /> quantifiers, then by assumption <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" /> is star-free regular. </p>
<p>
Note that <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" /> has one more row than <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\psi}" class="latex" title="{L_\psi}" /> because it has one more free variable. Without loss of generality we may suppose it is the bottom row. </p>
<p>
</p><p></p><h3> The Tricky Point </h3><p></p>
<p></p><p>
Since we have an existential quantifier we might think we can simply delete the last row of <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" />. But here is a counterexample to show why we must be careful not to “lose information”:</p>
<p>
Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha=}" class="latex" title="{\alpha=}" /> </p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/alphastackedexp/" rel="attachment wp-att-16875"><img src="https://rjlipton.files.wordpress.com/2020/03/alphastackedexp.jpg?w=600&amp;h=56" alt="" width="600" class="aligncenter size-large wp-image-16875" height="56" /></a></p>
<p>
and <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%27%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha'=}" class="latex" title="{\alpha'=}" /> </p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/alphaprime/" rel="attachment wp-att-16876"><img src="https://rjlipton.files.wordpress.com/2020/03/alphaprime.jpg?w=600&amp;h=43" alt="" width="600" class="aligncenter size-large wp-image-16876" height="43" /></a></p>
<p>
Notice that <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha'}" class="latex" title="{\alpha'}" /> equals <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> with its final row removed. We have <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\alpha=}" class="latex" title="{L_\alpha=}" /></p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/lalpha/" rel="attachment wp-att-16878"><img src="https://rjlipton.files.wordpress.com/2020/03/lalpha.jpg?w=357&amp;h=44" alt="" width="357" class="aligncenter wp-image-16878" height="44" /></a></p>
<p>
and <img src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Calpha%27%7D%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{\alpha'}=}" class="latex" title="{L_{\alpha'}=}" /></p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/lalphaprime/" rel="attachment wp-att-16880"><img src="https://rjlipton.files.wordpress.com/2020/03/lalphaprime.jpg?w=300&amp;h=44" alt="" width="300" class="aligncenter wp-image-16880" height="44" /></a></p>
<p></p><p><br />
Then <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\alpha}" class="latex" title="{L_\alpha}" /> is the language of strings with at least three zeroes in a row and <img src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Calpha%27%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{\alpha'}}" class="latex" title="{L_{\alpha'}}" /> is the language of strings with at least two zeroes in a row.</p>
<p>
We cannot add a second row consisting of zeroes and one 1 to each word <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\alpha'}" class="latex" title="{L_\alpha'}" /> to force <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> to be in <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\alpha}" class="latex" title="{L_\alpha}" />. For a trivial example, consider the word <img src="https://s0.wp.com/latex.php?latex=%7Bw%3D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w=}" class="latex" title="{w=}" /></p>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/w00/" rel="attachment wp-att-16881"><img src="https://rjlipton.files.wordpress.com/2020/03/w00.jpg?w=75&amp;h=36" alt="" width="75" class="aligncenter wp-image-16881" height="36" /></a></p>
<p></p><p></p>
<p>
The fault can be interpreted as <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> not being recoverable uniquely from <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha'}" class="latex" title="{\alpha'}" /> owing to a loss of information. We could also pin the fault in this case on the central <img src="https://s0.wp.com/latex.php?latex=%7B%5Ccap%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\cap}" class="latex" title="{\cap}" />, noting that <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cexists+u%29%28f%28u%29+%5Cwedge+g%28u%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\exists u)(f(u) \wedge g(u))}" class="latex" title="{(\exists u)(f(u) \wedge g(u))}" /> is generally not equivalent to <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cexists+u%29f%28u%29+%5Cwedge+%28%5Cexists+u%29g%28u%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\exists u)f(u) \wedge (\exists u)g(u)}" class="latex" title="{(\exists u)f(u) \wedge (\exists u)g(u)}" />. </p>
<p>
Either way, this means we must be careful with how we express (the final row of) <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" />. The idea is to give <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" /> in segments such that the final row of each segment is all-zero or a single <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, so that the act of removing the final row could be inverted. This is the crux of the proof. To handle it we employ the unique DFA for the regular expression already obtained by induction for <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" />. </p>
<p>
</p><p></p><h2> Main Part of the Proof </h2><p></p>
<p></p><p>
By the Myhill-Nerode Theorem, there must exist a unique minimal automaton <img src="https://s0.wp.com/latex.php?latex=%7BM_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_\phi}" class="latex" title="{M_\phi}" /> over the alphabet of our stacked words defining the language <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" /> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" />. </p>
<p>
The state set <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BM_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_\phi}" class="latex" title="{M_\phi}" /> can be partitioned into the set <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1}" class="latex" title="{Q_1}" /> of states before any <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> is read in the final row, the set <img src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_2}" class="latex" title="{Q_2}" /> of states reached after reading a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in the final row, plus a dead state <img src="https://s0.wp.com/latex.php?latex=%7Bq_D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_D}" class="latex" title="{q_D}" /> belonging to neither <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1}" class="latex" title="{Q_1}" /> nor <img src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_2}" class="latex" title="{Q_2}" />. The start state belongs to <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1}" class="latex" title="{Q_1}" /> and all accepting states belong to <img src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_2}" class="latex" title="{Q_2}" />. Since any stacked word and therefore accepting computation has exactly one <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in any row, all arcs within <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1}" class="latex" title="{Q_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_2}" class="latex" title="{Q_2}" /> must have a only <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />s in their final row, while the letters connecting states in <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1}" class="latex" title="{Q_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_2}" class="latex" title="{Q_2}" /> must have a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in their final row. The minimality of <img src="https://s0.wp.com/latex.php?latex=%7BM_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M_\phi}" class="latex" title="{M_\phi}" /> enforces these properties. Here is a sketch, omitting <img src="https://s0.wp.com/latex.php?latex=%7Bq_D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_D}" class="latex" title="{q_D}" />: </p>
<p></p><p><br />
<a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/lphidfa/" rel="attachment wp-att-16883"><img src="https://rjlipton.files.wordpress.com/2020/03/lphidfa.jpg?w=600&amp;h=324" alt="" width="600" class="aligncenter size-large wp-image-16883" height="324" /></a></p>
<p></p><p><br />
Let <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> be the set of edges that cross from <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1}" class="latex" title="{Q_1}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_2}" class="latex" title="{Q_2}" />. With <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+%7CE%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m = |E|}" class="latex" title="{m = |E|}" /> we can label their origins by states <img src="https://s0.wp.com/latex.php?latex=%7Bp_1%2C%5Cdots%2Cp_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_1,\dots,p_m}" class="latex" title="{p_1,\dots,p_m}" /> (not necessarily all distinct), and similarly label their characters by <img src="https://s0.wp.com/latex.php?latex=%7Bc_1%2C%5Cdots%2Cc_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_1,\dots,c_m}" class="latex" title="{c_1,\dots,c_m}" /> and the destination states by <img src="https://s0.wp.com/latex.php?latex=%7Br_1%2C%5Cdots%2Cr_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_1,\dots,r_m}" class="latex" title="{r_1,\dots,r_m}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7BC+%3D+%5C%7Bc_1%2C%5Cdots%2Cc_m%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C = \{c_1,\dots,c_m\}}" class="latex" title="{C = \{c_1,\dots,c_m\}}" /> collects all the characters used by <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> that have a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in row <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> (except those into or at the dead state <img src="https://s0.wp.com/latex.php?latex=%7Bq_D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q_D}" class="latex" title="{q_D}" />). We can identify <img src="https://s0.wp.com/latex.php?latex=%7BE%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{E}" class="latex" title="{E}" /> with the set of instructions <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B%28p_e%2C+c_e%2C+r_e%29%3A+1+%5Cleq+e+%5Cleq+m%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{(p_e, c_e, r_e): 1 \leq e \leq m\}}" class="latex" title="{\{(p_e, c_e, r_e): 1 \leq e \leq m\}}" />. </p>
<p>
Finally let <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bp%2Cq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{p,q}}" class="latex" title="{L_{p,q}}" /> denote the set of strings that take <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" /> from state <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> to state <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" />, and let <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Br%2CF%7D+%3D+%5Ccup_%7Bf+%5Cin+F%7D+L_%7Br%2Cf%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{r,F} = \cup_{f \in F} L_{r,f}}" class="latex" title="{L_{r,F} = \cup_{f \in F} L_{r,f}}" />. Then we can define <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" /> by the expression <a name="expansion"></a></p><a name="expansion">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%5Cphi+%3D%5Cbigcup_%7B%28p_e%2C+c_e%2C+r_e%29%5Cin+E%7D+L_%7Bs%2Cp_e%7D%5Ccdot+c_e+%5Ccdot+L_%7Br_e%2CF%7D.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_\phi =\bigcup_{(p_e, c_e, r_e)\in E} L_{s,p_e}\cdot c_e \cdot L_{r_e,F}. \ \ \ \ \ (1)" class="latex" title="\displaystyle  L_\phi =\bigcup_{(p_e, c_e, r_e)\in E} L_{s,p_e}\cdot c_e \cdot L_{r_e,F}. \ \ \ \ \ (1)" /></p>
</a><p><a name="expansion"></a> What remains is to find <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> expressions for <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e}}" class="latex" title="{L_{s,p_e}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Br_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{r_e,F}}" class="latex" title="{L_{r_e,F}}" /> for each <img src="https://s0.wp.com/latex.php?latex=%7Be%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{e}" class="latex" title="{e}" />. The latter is easy: Pick any string <img src="https://s0.wp.com/latex.php?latex=%7By_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_e}" class="latex" title="{y_e}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e}}" class="latex" title="{L_{s,p_e}}" />. Then </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%7Br_e%2CF%7D+%3D+%5C%7Bz%3A+y_e%5Ccdot+c_e+%5Ccdot+z+%5Cin+L%28M%29%5C%7D+%3D+L_%7B%5Cphi%7D+%5Cbackslash+y_e+c_e.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_{r_e,F} = \{z: y_e\cdot c_e \cdot z \in L(M)\} = L_{\phi} \backslash y_e c_e. " class="latex" title="\displaystyle  L_{r_e,F} = \{z: y_e\cdot c_e \cdot z \in L(M)\} = L_{\phi} \backslash y_e c_e. " /></p>
<p>The closure of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> under left quotients supplies expressions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta_e}" class="latex" title="{\beta_e}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Br_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{r_e,F}}" class="latex" title="{L_{r_e,F}}" />. </p>
<p>
The case of <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e}}" class="latex" title="{L_{s,p_e}}" />, however, is harder. What we would like to do is choose some (any) string <img src="https://s0.wp.com/latex.php?latex=%7Bw_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_e}" class="latex" title="{w_e}" /> that goes from <img src="https://s0.wp.com/latex.php?latex=%7Br_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_e}" class="latex" title="{r_e}" /> to an accepting state and claim that <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D+%3D+L%28M%29%2Fc_e+w_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e} = L(M)/c_e w_e}" class="latex" title="{L_{s,p_e} = L(M)/c_e w_e}" />. The problem is that <img src="https://s0.wp.com/latex.php?latex=%7Bw_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_e}" class="latex" title="{w_e}" /> might be accepted from some state <img src="https://s0.wp.com/latex.php?latex=%7Br_d+%5Cneq+r_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_d \neq r_e}" class="latex" title="{r_d \neq r_e}" /> that has an incoming arc on the same character <img src="https://s0.wp.com/latex.php?latex=%7Bc_d+%3D+c_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_d = c_e}" class="latex" title="{c_d = c_e}" /> from some other state <img src="https://s0.wp.com/latex.php?latex=%7Bp_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_d}" class="latex" title="{p_d}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_d}}" class="latex" title="{L_{s,p_d}}" />, which is disjoint from <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e}}" class="latex" title="{L_{s,p_e}}" />, is included also in <img src="https://s0.wp.com/latex.php?latex=%7BL%28M%29%2Fc_e+w_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L(M)/c_e w_e}" class="latex" title="{L(M)/c_e w_e}" />. There may, however, be strings <img src="https://s0.wp.com/latex.php?latex=%7By_d+%5Cin+L_%7Bs%2Cp_d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_d \in L_{s,p_d}}" class="latex" title="{y_d \in L_{s,p_d}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bw%27_e+%5Cin+L_%7Br_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'_e \in L_{r_e,F}}" class="latex" title="{w'_e \in L_{r_e,F}}" /> such that <img src="https://s0.wp.com/latex.php?latex=%7By+%3D+y_d+c_e+w%27_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y = y_d c_e w'_e}" class="latex" title="{y = y_d c_e w'_e}" /> is <b>not</b> accepted by <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />. Then the string <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> would be wrongly included if we substituted <img src="https://s0.wp.com/latex.php?latex=%7BL%28M%29%2Fc_e+z_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L(M)/c_e z_e}" class="latex" title="{L(M)/c_e z_e}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e}}" class="latex" title="{L_{s,p_e}}" /> (or for <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D+%5Ccup+L_%7Bs%2Cp_d%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e} \cup L_{s,p_d}}" class="latex" title="{L_{s,p_e} \cup L_{s,p_d}}" />) in (1). </p>
<p>
There is also a second issue when crossing edges on the same character <img src="https://s0.wp.com/latex.php?latex=%7Bc_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_e}" class="latex" title="{c_e}" /> come in from distinct states <img src="https://s0.wp.com/latex.php?latex=%7Bp_d%2Cp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_d,p_e}" class="latex" title="{p_d,p_e}" /> to the same state <img src="https://s0.wp.com/latex.php?latex=%7Br_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_e}" class="latex" title="{r_e}" />. To fix all this, we need to use sets of strings that distinguish <img src="https://s0.wp.com/latex.php?latex=%7Bp_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_e}" class="latex" title="{p_e}" /> from all the other states <img src="https://s0.wp.com/latex.php?latex=%7Bp_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_d}" class="latex" title="{p_d}" />. This requires the most particular use of the minimality of <img src="https://s0.wp.com/latex.php?latex=%7BM%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{M}" class="latex" title="{M}" />: If <img src="https://s0.wp.com/latex.php?latex=%7Bp_d+%5Cneq+p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_d \neq p_e}" class="latex" title="{p_d \neq p_e}" />, then there is either (or both):</p>
<ul>
<li>
a string <img src="https://s0.wp.com/latex.php?latex=%7Bz_%7Be%2Cd%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z_{e,d}}" class="latex" title="{z_{e,d}}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bp_e%2CF%7D+-+L_%7Bp_d%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{p_e,F} - L_{p_d,F}}" class="latex" title="{L_{p_e,F} - L_{p_d,F}}" />, or <p></p>
</li><li>
a string <img src="https://s0.wp.com/latex.php?latex=%7Bz_%7Bd%2Ce%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{z_{d,e}}" class="latex" title="{z_{d,e}}" /> in <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bp_d%2CF%7D+-+L_%7Bp_e%2CF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{p_d,F} - L_{p_e,F}}" class="latex" title="{L_{p_d,F} - L_{p_e,F}}" />.
</li></ul>
<p>
The strings in question need not begin with a character in <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C}" class="latex" title="{C}" />—they need not cross right away. Let <img src="https://s0.wp.com/latex.php?latex=%7BZ_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_e}" class="latex" title="{Z_e}" /> stand for a choice of strings of the former kind, <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_e}" class="latex" title="{Z'_e}" /> the latter kind, covering all states <img src="https://s0.wp.com/latex.php?latex=%7Bp_d+%5Cneq+p_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_d \neq p_e}" class="latex" title="{p_d \neq p_e}" />. Then <a name="distinct"></a></p><a name="distinct">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++L_%7Bs%2Cp_e%7D+%3D+%5Cleft%28%5Cbigcap_%7Bz+%5Cin+Z_e%7D+L_%7B%5Cphi%7D%2Fz%5Cright%29+%5Ccap+%5Cleft%28%5Cbigcap_%7Bz%27+%5Cin+Z%27_e%7D+%28%5Calpha_0+%5Ccap+%5Ctilde%7BL%7D_%7B%5Cphi%7D%29%2Fz%27%5Cright%29.+%5C+%5C+%5C+%5C+%5C+%282%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  L_{s,p_e} = \left(\bigcap_{z \in Z_e} L_{\phi}/z\right) \cap \left(\bigcap_{z' \in Z'_e} (\alpha_0 \cap \tilde{L}_{\phi})/z'\right). \ \ \ \ \ (2)" class="latex" title="\displaystyle  L_{s,p_e} = \left(\bigcap_{z \in Z_e} L_{\phi}/z\right) \cap \left(\bigcap_{z' \in Z'_e} (\alpha_0 \cap \tilde{L}_{\phi})/z'\right). \ \ \ \ \ (2)" /></p>
</a><p><a name="distinct"></a> We could not use just the complement <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctilde%7BL%7D_%7B%5Cphi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\tilde{L}_{\phi}}" class="latex" title="{\tilde{L}_{\phi}}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Cphi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{\phi}}" class="latex" title="{L_{\phi}}" /> because that would allow strings that violate the “one <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />” condition in the rows. Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0+%5Ccap+%5Ctilde%7BL%7D_%7B%5Cphi%7D+%3D+L_%7B%5Cneg%5Cphi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_0 \cap \tilde{L}_{\phi} = L_{\neg\phi}}" class="latex" title="{\alpha_0 \cap \tilde{L}_{\phi} = L_{\neg\phi}}" />. Whether one can do the induction for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cneg%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\neg\phi}" class="latex" title="{\neg\phi}" /> in tandem without invoking <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_0}" class="latex" title="{\alpha_0}" /> is a riddle we pose at the end. </p>
<p>
Either way, the closure of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> under right quotients yields a star-free expression <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_e}" class="latex" title="{\alpha_e}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BL_%7Bs%2Cp_e%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_{s,p_e}}" class="latex" title="{L_{s,p_e}}" />. Then we just have to plug our expressions <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_e}" class="latex" title="{\alpha_e}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta_e}" class="latex" title="{\beta_e}" /> into (1) to get a star-free expression <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta_\phi}" class="latex" title="{\beta_\phi}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" />. Now we are ready for the crude final step:</p>
<blockquote><p><b> </b> <em> Form <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\beta'}" class="latex" title="{\beta'}" /> by knocking out the last entry in every character occurring in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_%5Cphi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\beta_\phi}" class="latex" title="{\beta_\phi}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\beta'}" class="latex" title="{\beta'}" /> represents <img src="https://s0.wp.com/latex.php?latex=%7BL_%7B%5Cpsi%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L_{\psi}}" class="latex" title="{L_{\psi}}" />. </em>
</p></blockquote>
<p></p><p>
To prove this final statement, first suppose <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> is a stacked word in <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\psi}" class="latex" title="{L_\psi}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cexists+u%29%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\exists u)\phi}" class="latex" title="{(\exists u)\phi}" />, so there is a value <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> so that <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> set equal to the value <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />. This means that the stacked word <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> formed from <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> and a last row with <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in position <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> belongs to <img src="https://s0.wp.com/latex.php?latex=%7BL_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_\phi}" class="latex" title="{L_\phi}" /> and hence matches <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta_%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta_\phi}" class="latex" title="{\beta_\phi}" />. Since <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> is obtained by knocking out the last row of <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" />, <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> matches <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta'}" class="latex" title="{\beta'}" />. </p>
<p>
The converse is the part where the tricky point we noted at the outset could trip us up. Suppose <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> matches <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta'}" class="latex" title="{\beta'}" />. From the form of (1) as a union of terms <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_e+c_e+%5Cbeta_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_e c_e \beta_e}" class="latex" title="{\alpha_e c_e \beta_e}" />, we can trace how <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> is matched to identify a place in <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> that matches a “middle character” <img src="https://s0.wp.com/latex.php?latex=%7Bc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c'}" class="latex" title="{c'}" /> obtained from a <img src="https://s0.wp.com/latex.php?latex=%7Bc_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c_e}" class="latex" title="{c_e}" /> in a crossing edge. Putting a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> in a new row underneath this place and <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" />s elsewhere hence makes a word <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> that matches the unique regular expression <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta''}" class="latex" title="{\beta''}" /> obtained by appending a <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> component to every “middle character” <img src="https://s0.wp.com/latex.php?latex=%7Bc%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c'}" class="latex" title="{c'}" /> and a <img src="https://s0.wp.com/latex.php?latex=%7B0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0}" class="latex" title="{0}" /> to all other characters in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta'}" class="latex" title="{\beta'}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%27%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta''}" class="latex" title="{\beta''}" /> is equivalent to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbeta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\beta}" class="latex" title="{\beta}" />, so <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" />. Since the last row that was added to <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> amounts to supplying a value <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" /> for the variable <img src="https://s0.wp.com/latex.php?latex=%7Bu_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_j}" class="latex" title="{u_j}" />, it follows that <img src="https://s0.wp.com/latex.php?latex=%7Bw%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w'}" class="latex" title="{w'}" /> satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bu_j+%3D+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u_j = k}" class="latex" title="{u_j = k}" />, hence satisfies <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi}" class="latex" title="{\psi}" />. This yields <img src="https://s0.wp.com/latex.php?latex=%7BL%28%5Cbeta%27%29+%3D+L_%7B%5Cpsi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L(\beta') = L_{\psi}}" class="latex" title="{L(\beta') = L_{\psi}}" /> and so the entire induction goes through. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
First, as an end note, the end of the proof wound up different from what we envisioned until polishing this post. It originally applied the distinct-states argument to states <img src="https://s0.wp.com/latex.php?latex=%7Br_d%2Cr_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r_d,r_e}" class="latex" title="{r_d,r_e}" /> on the far side of the crossing, but we had to backtrack on having previously thought that the “second issue” did not matter. Two other questions we pose for our readers:</p>
<ul>
<li>
Do the definitions of <img src="https://s0.wp.com/latex.php?latex=%7BZ_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z_e}" class="latex" title="{Z_e}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BZ%27_e%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Z'_e}" class="latex" title="{Z'_e}" /> need to extend over all states <img src="https://s0.wp.com/latex.php?latex=%7Bp+%5Cin+Q_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p \in Q_1}" class="latex" title="{p \in Q_1}" />, not just the other states <img src="https://s0.wp.com/latex.php?latex=%7Bp_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p_d}" class="latex" title="{p_d}" /> on the border? <p></p>
</li><li>
Is <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_0}" class="latex" title="{\alpha_0}" /> needed in (2), or in the proof overall?
</li></ul>
<p>
A larger question concerns how the size of the translated expressions increases as we add more quantifiers. We discuss the blowup in terms of quantifier depth <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> and length <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D%7Cx%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n=|x|}" class="latex" title="{n=|x|}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_0}" class="latex" title="{\psi_0}" /> be a first-order formula with no quantifiers and let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_m}" class="latex" title="{\psi_m}" /> denote <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_0}" class="latex" title="{\psi_0}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m}" class="latex" title="{m}" /> quantifiers applied to it. Also let <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_m}" class="latex" title="{\alpha_m}" /> be a star-free translation of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_m}" class="latex" title="{\psi_m}" /> and the length of <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_0}" class="latex" title="{\alpha_0}" />, denoted by len<img src="https://s0.wp.com/latex.php?latex=%7B%28%5Calpha_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\alpha_0)}" class="latex" title="{(\alpha_0)}" />, equal <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />. </p>
<p>
To obtain <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_%7B1%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_{1}}" class="latex" title="{\alpha_{1}}" /> from <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_0}" class="latex" title="{\alpha_0}" /> we represent <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha_0}" class="latex" title="{\alpha_0}" /> by a union over crossing edges between <img src="https://s0.wp.com/latex.php?latex=%7BQ_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_1}" class="latex" title="{Q_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BQ_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q_2}" class="latex" title="{Q_2}" /> and the final states of <img src="https://s0.wp.com/latex.php?latex=%7BQ%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{Q}" class="latex" title="{Q}" /> of the concatenation of prefix and suffix languages and a crossing character between them. We have that <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> gives a decent approximation for—worst-case—length of the prefix languages, suffix languages and the product of crossing edges and final states. Using these approximations we have <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_1%29%5Capprox%282n%2B1%29%28n%29%5Capprox+n%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathit{len}(\alpha_1)\approx(2n+1)(n)\approx n^2}" class="latex" title="{\mathit{len}(\alpha_1)\approx(2n+1)(n)\approx n^2}" />. Iterating gives <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_2%29%5Capprox%282%5Cmathit%7Blen%7D%28%5Calpha_1%29%2B1%29%5Cmathit%7Blen%7D%28%5Calpha_1%29%5Capprox+n%5E4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathit{len}(\alpha_2)\approx(2\mathit{len}(\alpha_1)+1)\mathit{len}(\alpha_1)\approx n^4}" class="latex" title="{\mathit{len}(\alpha_2)\approx(2\mathit{len}(\alpha_1)+1)\mathit{len}(\alpha_1)\approx n^4}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_3%29%5Capprox+n%5E8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathit{len}(\alpha_3)\approx n^8}" class="latex" title="{\mathit{len}(\alpha_3)\approx n^8}" />, and in general, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Blen%7D%28%5Calpha_m%29%5Capprox+%28%7Bn%5E%7B2%5Em%7D%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathit{len}(\alpha_m)\approx ({n^{2^m}})}" class="latex" title="{\mathit{len}(\alpha_m)\approx ({n^{2^m}})}" />. This says that our blowup could be doubly exponential. Is there a tighter estimate?</p>
<p>
Our final question is: how well do our “stacked words” help to visualize the proof? Are they helpful for framing proofs of equivalences between language classes and logics that are higher up?</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/03/29/logic-and-star-free-part-deux/"><span class="datestr">at March 29, 2020 07:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/03/29/postdoctoral-researchers-at-millennium-institute-for-foundational-research-on-data-imfd-chile-apply-by-january-7-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/03/29/postdoctoral-researchers-at-millennium-institute-for-foundational-research-on-data-imfd-chile-apply-by-january-7-2020/">Postdoctoral Researchers at Millennium Institute for Foundational Research on Data, IMFD Chile (apply by January 7, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Millennium Institute for Foundational Research on Data (IMFD Chile, <a href="http://www.imfd.cl" rel="nofollow">http://www.imfd.cl</a>) offers a postdoc position to advance the understanding of theoretical aspects of neural network architectures, in particular, its expressive and computational power. The coordinators of this project are Professors Pablo Barceló (<a href="http://pbarcelo.ing.uc.cl/">http://pbarcelo.ing.uc.cl/</a>) and Jorge Pérez (<a href="https://users.dcc.uchile.cl/~jperez/">https://users.dcc.uchile.cl/~jperez/</a>).</p>
<p>Website: <a href="https://docs.google.com/document/d/1PyHp-MRAPWg_0aeinpDGmzJGZbwMtsqC6BqE_4T3KFc/edit">https://docs.google.com/document/d/1PyHp-MRAPWg_0aeinpDGmzJGZbwMtsqC6BqE_4T3KFc/edit</a><br />
Email: pbarcelo@ing.puc.cl</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/03/29/postdoctoral-researchers-at-millennium-institute-for-foundational-research-on-data-imfd-chile-apply-by-january-7-2020/"><span class="datestr">at March 29, 2020 04:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/041">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/041">TR20-041 |  A Polynomial Degree Bound on Defining Equations of Non-rigid Matrices and  Small Linear Circuits | 

	Mrinal Kumar, 

	Ben Lee Volk</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that there is a defining equation of degree at most poly(n) for the (Zariski closure of the) set of the non-rigid matrices: that is, we show that for every large enough field $\mathbb{F}$, there is a non-zero $n^2$-variate polynomial $P \in \mathbb{F}(x_{1, 1}, \ldots, x_{n, n})$ of degree at most poly(n) such that  every matrix $M$ which can be written as a sum of a matrix of rank at most $n/100$ and sparsity at most $n^2/100$ satisfies $P(M) = 0$. This  confirms a conjecture of Gesmundo, Hauenstein, Ikenmeyer and Landsberg [GHIL16] and improves the best upper bound known for this problem down from $\exp(n^2)$ [KLPS14, GHIL16] to $poly(n)$. 

We also show a similar polynomial degree bound for the (Zariski closure of the) set of all matrices $M$ such that the linear transformation represented by $M$ can be computed by an algebraic circuit with at most  $n^2/200$ edges (without any restriction on the depth). As far as we are aware, no such bound was known prior to this work when the depth of the circuits is unbounded. 

Our methods are elementary and short and rely on a polynomial map of Shpilka and Volkovich [SV15] to construct low degree ``universal'' maps for non-rigid matrices and small linear circuits. Combining this construction with a simple dimension counting argument to show that any such polynomial map has a low degree annihilating polynomial completes the proof.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/041"><span class="datestr">at March 29, 2020 06:14 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19560">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/03/29/game-theory-on-line-course-at-idc-herzliya/">Game Theory – on-line Course at IDC, Herzliya</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h3>Game theory, a graduate course at IDC, Herzliya; Lecturer: Gil Kalai; TA: Einat Wigderson,  ZOOM mentor: Ethan.</h3>
<p>Starting Tuesday March 31, I am giving an on-line course (in Hebrew) on Game theory at <a href="https://www.idc.ac.il/he/pages/home.aspx">IDC, Herzliya</a> (<a href="https://www.idc.ac.il/en/pages/home.aspx">IDC English site</a>; <a href="https://www.idc.ac.il/chinese/pages/home.aspx">IDC Chinese site</a>).</p>
<p>In addition to the IDC moodle (course site) that allows IDC students to listen to recorded lectures, submit solutions to problem sets , etc., there will be a page here on the blog devoted to the course. Zoom link for the first meeting. <a href="https://idc-il.zoom.us/j/726950787" rel="nofollow">https://idc-il.zoom.us/j/726950787</a></p>
<p>A small memory: In 1970 there was a strike in Israelis’ high schools and I took a few classes at the university. One of these classes was Game theory and it was taught by <a href="https://gilkalai.wordpress.com/?s=Michael+Maschler">Michael Maschler</a>. (I also took that trimester a course on art taught by Ziva <span class="st"><span dir="ltr">Meisels</span></span>.) Our department at HUJI is very strong in game theory, but once all the “professional” game theorists retired, I gave twice a game theory course which I enjoyed a lot and it was well accepted by students. In term of the number of registered students, it seems that this year’s course at IDC is quite popular and I hope it will be successful.</p>
<h2>The first six slides of the first presentation</h2>
<p>(Click to enlarge)</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt1.png"><img src="https://gilkalai.files.wordpress.com/2020/03/gt1.png?w=300&amp;h=225" alt="" width="300" class="alignnone size-medium wp-image-19661" height="225" /></a></p>
<p>Game Theory 2020, games, decisions, competition, strategies, mechanisms, cooperation</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt2.png"><img src="https://gilkalai.files.wordpress.com/2020/03/gt2.png?w=300&amp;h=131" alt="" width="300" class="alignnone size-medium wp-image-19662" height="131" /></a></p>
<p>The course deals with basic notions, central mathematical results, and important examples in non-cooperative game theory and in cooperative game theory, and with connections of game theory with computer science, economics and other areas.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt3.png"><img src="https://gilkalai.files.wordpress.com/2020/03/gt3.png?w=300&amp;h=226" alt="" width="300" class="alignnone size-medium wp-image-19663" height="226" /></a></p>
<p>What we will learn</p>
<p>1. Full information zero-sum games. The value of a game. Combinatorial games.</p>
<p>2. Zero-sum games with incomplete information. Mixed strategies, the Minmax Theorem and the value of the game.</p>
<p>3. Non cooperative games, the prisoner dilemma, Nash equilibrium, Nash’s theorem on the existence of equilibrium.</p>
<p>4. Cooperative games, the core and the Shapley value. Nash bargaining problem, voting rules and social choice.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt4.png"><img src="https://gilkalai.files.wordpress.com/2020/03/gt4.png?w=300&amp;h=225" alt="" width="300" class="alignnone size-medium wp-image-19664" height="225" /></a></p>
<p>Background material:</p>
<p><a href="https://homes.cs.washington.edu/~karlin/GameTheoryBook.pdf">Game theory alive</a> by Anna Karlin and Yuval Peres (available on-line).</p>
<p>In addition I may use material from several books in Hebrew by Maschler, Solan, Zamir, by Hefetz, and by Megiddo (based on lectures by Peleg). (If only I will manage to unite with my books that are not here.) We will also use a site by Ariel Rubinstein for playing games and some material from the book by Osborne and Rubinstein.</p>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt5.png"><img src="https://gilkalai.files.wordpress.com/2020/03/gt5.png?w=300&amp;h=226" alt="" width="300" class="alignnone size-medium wp-image-19665" height="226" /></a></p>
<p>Requirement and challenges:</p>
<ul>
<li><strong>Play, play, play games</strong>, in Ariel Rubinshtein site and various other games.</li>
<li>Solve 10 short theoretical problem set.</li>
<li>Final assignment, including some programming project that can be carried out during the semester.</li>
<li>Of course, we will experience on-line study which is a huge challenge for us all.</li>
</ul>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/gt6.png"><img src="https://gilkalai.files.wordpress.com/2020/03/gt6.png?w=300&amp;h=226" alt="" width="300" class="alignnone size-medium wp-image-19667" height="226" /></a></p>
<p>Games and computers</p>
<ul>
<li>Computer games</li>
<li>Algorithms for playing games</li>
<li>algorithmic game theory:
<ul>
<li>Mechanism design</li>
<li>Analyzing games in tools of computer science</li>
<li>Electronic commerce</li>
</ul>
</li>
<li>Games, logic and automata: there will be a parallel course by <a href="http://www.faculty.idc.ac.il/udiboker/">Prof. Udi Boker</a></li>
</ul>
<p><a href="https://gilkalai.files.wordpress.com/2020/03/z9.png"><img src="https://gilkalai.files.wordpress.com/2020/03/z9.png?w=640&amp;h=192" alt="" width="640" class="alignnone size-large wp-image-19668" height="192" /></a></p>
<p><span style="color: #ff0000;">I still have some difficulty with the virtual background in ZOOM.</span></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/03/29/game-theory-on-line-course-at-idc-herzliya/"><span class="datestr">at March 28, 2020 09:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=410">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/03/28/tcs-talk-wednesday-april-1-venkat-guruswami-cmu/">TCS+ talk: Wednesday, April 1 — Venkat Guruswami, CMU</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, April 1th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 17:00 UTC). <strong>Venkat Guruswami</strong> from CMU will speak about “<em>Arıkan meets Shannon: Polar codes with near-optimal convergence to channel capacity</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. (The link will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to join, until the maximum capacity of 300 seats is reached.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We establish a constructive version of Shannon’s noisy coding theorem for binary codes, with information rate converging near-optimally fast to channel capacity as a function of code length. Specifically, let <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=fff&amp;fg=444444&amp;s=0" alt="W" class="latex" title="W" /> be an arbitrary binary-input memoryless symmetric channel with Shannon capacity <img src="https://s0.wp.com/latex.php?latex=I%28W%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="I(W)" class="latex" title="I(W)" />, and fix any <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3E0&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\delta &gt;0" class="latex" title="\delta &gt;0" />. We construct, for any sufficiently small <img src="https://s0.wp.com/latex.php?latex=%5Cvarepsilon+%3E0&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\varepsilon &gt;0" class="latex" title="\varepsilon &gt;0" />, binary linear codes of block length <img src="https://s0.wp.com/latex.php?latex=O%281%2F%5Cvarepsilon%5E%7B2%2B%5Cdelta%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(1/\varepsilon^{2+\delta})" class="latex" title="O(1/\varepsilon^{2+\delta})" /> and rate <img src="https://s0.wp.com/latex.php?latex=I%28W%29-%5Cvarepsilon&amp;bg=fff&amp;fg=444444&amp;s=0" alt="I(W)-\varepsilon" class="latex" title="I(W)-\varepsilon" /> that enable reliable communication on <img src="https://s0.wp.com/latex.php?latex=W&amp;bg=fff&amp;fg=444444&amp;s=0" alt="W" class="latex" title="W" /> with quasi-linear time encoding and decoding. Shannon’s theorem implies the existence of such codes (without efficient constructions or decoding) with block length <img src="https://s0.wp.com/latex.php?latex=O%281%2F%5Cvarepsilon%5E2%29&amp;bg=fff&amp;fg=444444&amp;s=0" alt="O(1/\varepsilon^2)" class="latex" title="O(1/\varepsilon^2)" />. This quadratic dependence on the gap epsilon to capacity is known to be best possible. Previously such a construction was only known for the case of the erasure channel.</p>
<p>Our codes are a variant of Arıkan’s polar codes based on multiple carefully constructed local kernels, one for each intermediate channel that arises in the decoding. A key technical ingredient in the analysis is a strong converse to the noisy coding theorem that shows extreme unpredictability of even a single message bit when communicating via random linear codes at rates slightly above capacity.</p>
<p>Joint work with Andrii Riazanov and Min Ye.</p></blockquote>
<p> </p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/03/28/tcs-talk-wednesday-april-1-venkat-guruswami-cmu/"><span class="datestr">at March 28, 2020 04:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://agtb.wordpress.com/?p=3461">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/agtb.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://agtb.wordpress.com/2020/03/27/calendar-of-virtual-csecon-seminars/">Calendar of Virtual CS+Econ Seminars</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Our community has some outstanding long-running virtual seminars, and there are many traditional seminars now moving to a virtual format.  Northwestern Ph.D. students <a href="https://mkcamara.github.io/">Modibo Camara</a> and <a href="https://sites.northwestern.edu/yiding/">Yiding Feng</a> have a collection of them in a Google Calendar at <a href="https://sites.google.com/view/virtualcseconseminars/">Virtual CS+Econ Seminars</a>.  Don’t miss any of the action!</p>
<p>The topics include but not limited to theoretical computer science, economic theory, theoretical machine learning, and econometrics.  The calendar currently tracks talks in <a href="https://mobile.twitter.com/CaltechEconThry">Caltech Econ Theory</a>, <a href="https://www.chamberlainseminar.org">Chamberlain Seminar in Econometrics</a>, <a href="https://www.ideal.northwestern.edu/">IDEAL</a>, <a href="http://md4sg.com">MD4SG</a>, and <a href="https://sites.google.com/site/plustcs">TCS+</a>. Send other relevant talk series or one-off events to Modibo and Yiding at <a href="mailto:VirtualCSEconSeminar@gmail.com" class="c-link" rel="noopener noreferrer" target="_blank">VirtualCSEconSeminar@gmail.com</a>.</p></div>







<p class="date">
by Jason Hartline <a href="https://agtb.wordpress.com/2020/03/27/calendar-of-virtual-csecon-seminars/"><span class="datestr">at March 26, 2020 10:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/040">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/040">TR20-040 |  Topology and adjunction in promise constraint satisfaction | 

	Andrei Krokhin, 

	Jakub Opršal, 

	Marcin Wrochna, 

	Stanislav Zivny</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The approximate graph colouring problem concerns colouring a $k$-colourable
  graph with $c$ colours, where $c\geq k$. This problem naturally generalises
  to promise graph homomorphism and further to promise constraint satisfaction
  problems. Complexity analysis of all these problems is notoriously difficult.
  In this paper, we introduce two new techniques to analyse the complexity of
  promise CSPs: one is based on topology and the other on adjunction. We apply
  these techniques, together with the previously introduced algebraic approach,
  to obtain new NP-hardness results for a significant class of approximate
  graph colouring and promise graph homomorphism problems.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/040"><span class="datestr">at March 26, 2020 02:25 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7660">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/03/26/technology-for-theory-covid-19-edition/">Technology for theory: COVID-19 edition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The new coronavirus upended much of society, including our little corner of it. I believe at this point almost all theorists are teaching and doing research at home, and I thought it would be good to share some of the tools we use for doing so. Below I will describe my setup, but I hope other people share theirs too.</p>



<h2>Teaching and virtual whiteboards</h2>



<p>I am teaching using Zoom and using an iPad pro with a pencil to simulate a whiteboard. I use a laptop to connect to Zoom and for the camera, laptop, and chat window, and then join the iPad.There are several ways to connect an iPad to a Zoom session:</p>



<ol><li>Join the session from the iPad separately using the iPad Zoom app. (To do so you <em>might</em> need to logout of your other account.)</li><li>Within the Zoom program on your computer you can choose “share screen” and then one of the option is to join an iPad connected to the same wireless network as the laptop/desktop and use “screen mirroring” on the iPad. (You can find the screen mirroring option on the iPad by swiping from the top right corner in a diagonal motion.)</li><li>Another variant of this is to use a third party app such as <a href="https://www.airsquirrels.com/reflector">Reflector 3</a>. Reflector 3 sets up an airplay server on your PC so you can mirror the iPad screen to it. You can then share the Reflector 3 window from Zoom (see screen shorts below). If you do use Reflector 3, you can remove its annoying iPad like frame.</li><li>You can use a wired connection, which is either by just connecting through USB (in a Mac) or a complex combination of combining an adapter to take an HDMI signal out of an iPad with an HDMI capture card to stream this signal to the computer.</li></ol>



<p>I use either option 2 or 3. (Might have used 4 if I had a Mac.) The main reason I prefer these to option 1 is because the application I use for a whiteboard –  <a href="https://www.goodnotes.com/">GoodNotes</a> – has a <a href="https://support.goodnotes.com/hc/en-us/articles/360001100576-How-to-use-Presentation-Mode">presentation mode</a> that behaves differently when you are connected to an external display or use AirPlay (which is what options 2 and 3 do). In this presentation mode the students don’t see your interface, and so you can Zoom, go to the page selector and more without it disturbing what they see. GoodNotes also has a great “laser pointer”. I set the pages at a landscape orientation,  and pre-write a good chunk of what I plan to present before the lecture. I also use the ability to “duplicate pages” to achieve the PowerPoint like effect of gradual reveal.</p>



<p>It is not perfect – I’ve discovered that the screen share sometimes stops refreshing and I need to leave GoodNotes and return to it for it to go back (this seems to works better in Reflector 3 so far for me).</p>



<p>Monitoring the chat window and raised hands in Zoom is non-trivial. It helps a lot that I have a teaching assistant that participates in lecture and notices if I missed something. </p>



<p>Some people say that a “matte screen protector” such as <a href="https://paperlike.com/">PaperLike</a> makes the iPad more comfortable to write on – haven’t yet tried it. (Update 4/1/2020: I now tried PaperLike and can vouch for it – it greatly improves my handwriting! shipping from the UK did take some time though.)</p>



<p>I have a good Webcam (<a href="https://www.amazon.com/Logitech-BRIO-Conferencing-Recording-Streaming/dp/B01N5UOYC4">Logitech Brio</a>) but at the moment I’m not using it since it seems too taxing on my laptop and so I went back to the native webcam. I have a very nice wireless headset/mic combo (<a href="https://www.amazon.com/Jabra-Bluetooth-Headphones-Including-Packaging/dp/B072JWYJMC">Jabra Evolve 75</a>) that I am constantly using and have been very happy with. I particularly like the feature of being able to unmute and mute yourself by raising and lowering the mike. </p>



<figure class="wp-block-image size-large"><img src="https://windowsontheory.files.wordpress.com/2020/04/screenshot-2020-04-01-10.27.41.png?w=1024" alt="" class="wp-image-7668" />Using Screen share from Zoom to either share an iPad or the Reflector 3 window</figure>



<figure class="wp-block-image size-large"><img src="https://windowsontheory.files.wordpress.com/2020/04/21360-1.jpg?w=1024" alt="" class="wp-image-7667" />Choose which source to mirror the screen to on your iPad screen</figure>



<figure class="wp-block-image size-large"><img src="https://windowsontheory.files.wordpress.com/2020/04/85387-1.jpg?w=726" alt="" class="wp-image-7669" />You can reach the screen mirroring options by swiping from the top right corner of the iPad.</figure>



<h2>Research</h2>



<p>For research Slack continues to extremely useful. For working jointly on a paper <a href="https://www.overleaf.com/">Overleaf </a> is of course great, but for maintaining a shared document it sometimes useful to use simpler platform that are not full fledged LaTeX. Some options include:</p>



<ul><li><a href="https://hackmd.io/">Hackmd.io</a> for markdown (supports LaTeX math)</li><li>Google docs of course. I heard about the <a href="https://gsuite.google.com/marketplace/app/autolatex_equations/850293439076">Auto-LaTeX plugin</a> but haven’t used it yet.</li><li><a href="https://www.dropbox.com/paper">Dropbox Paper</a> supports LaTeX natively.</li></ul>



<p><a href="https://jamboard.google.com/">Google JamBoard</a> is an interactive whiteboard, also with an <a href="https://apps.apple.com/us/app/jamboard/id1143591418">iPad app</a>. I haven’t tried it yet but it seems promising.</p>



<p></p>



<h2>Keeping children busy</h2>



<p>For many people I imagine childcare is one of the most challenging aspects. At the moment at least the Cambridge Public Schools are not keeping my kids too busy. While probably most of their time is spent in non educational pursuits, we try to also encourage (i.e., bribe/extort/threaten/beg) them to do some learning. If your kids are interested in math, I highly recommend the courses offered by the <a href="https://artofproblemsolving.com/">Art of Problem Solving</a> (they also have a theory connection: one of their books was co-authored by theorist Ravi Boppana). For younger kids you can also try their <a href="https://beastacademy.com/">Beast Academy</a>.</p>



<p>The AOPS program is not free but over the years my kids (especially my 13 year old daughter Alma) have also spent a lot of time on the free and amazing <a href="https://www.khanacademy.org/">Khan Academy</a>. In fact, last year she was inspired enough by Khan’s JavaScript course to write the following poem which (for obvious reasons)  moved me very much:</p>



<p>Tending / Alma Barak</p>



<p>My mind is a desert<br />of boredom<br />of blankness<br />of leaning-back-in-your-chairness<br />and of simply-staring-at-the-ceilingness<br />I kick at a crumpled<br />deserted baby-blonde post-it<br />with my spotted socked feet<br />waiting for Aba to come.</p>



<p>We dive when he comes<br />into the seas of Khan<br />free-styling our way<br />into the lakes of Java<br />we pass codes we already<br />knew<br />while loops<br />for loops<br />arrays<br />reminding me of what I’d learned</p>



<p>We frog-kick to an<br />uncharted<br />unfamiliar<br />lagoon of code I don’t know<br />sometimes I get swept away by currents<br />of confusion<br />but my aba, my dad<br />grabs my hand<br />and shows me the way through<br />teaching me<br />tending to me<br />washing away the sands of boredom with the sea of Khan.</p>



<p></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/03/26/technology-for-theory-covid-19-edition/"><span class="datestr">at March 26, 2020 12:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/039">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/039">TR20-039 |  Lower bounds on the sum of 25th-powers of univariates lead to complete derandomization of PIT | 

	Pranjal Dutta, 

	Nitin Saxena, 

	Thomas Thierauf</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We consider the univariate polynomial $f_d:=(x+1)^d$ when represented as a sum of constant-powers of univariate polynomials. We define a natural measure for the model, the support-union, and conjecture that it is $\Omega(d)$ for $f_d$. 

We show a stunning connection of the conjecture to the two main problems in algebraic complexity: Polynomial Identity Testing (PIT) and VP vs VNP. Our conjecture on $f_d$ implies blackbox-PIT in P. Assuming the  Generalized Riemann Hypothesis (GRH), it also implies VP $\neq$ VNP. No such connection to PIT, from lower bounds on constant-powers representation of polynomials was known before. We establish that studying the expression of $(x+1)^d$, as the sum of $25^{th}$-powers of univariates, suffices to solve the two major open questions.   

In support, we show that our conjecture holds over the integer ring of any number field. We also establish a connection with the well-studied notion of matrix rigidity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/039"><span class="datestr">at March 25, 2020 09:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7657">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/03/25/new-cs-theory-talk-aggragator/">New CS theory talk aggragator</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Shcachar Lovett has put together a new website aggregating information about virtual talks in CS theory: <a href="https://cstheorytalks.wordpress.com/">https://cstheorytalks.wordpress.com/</a></p>



<p> It has a Google calendar that people can add to their own, and a form to submit a new talk that automatically gets added to the Google calendar. </p>



<p>This can be a fantastic resource these days that almost no one can travel – please publicize this and also submit to it talks that you are organizing.</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/03/25/new-cs-theory-talk-aggragator/"><span class="datestr">at March 25, 2020 05:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/03/24/full-professor-w3-at-tu-dortmund-university-apply-by-april-15-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/03/24/full-professor-w3-at-tu-dortmund-university-apply-by-april-15-2020/">Full Professor (W3)  at TU Dortmund University (apply by April 15, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at TU Dortmund University (<a href="https://tu-dortmund.de/en">https://tu-dortmund.de/en</a>) is seeking to fill the position of a Full Professor Position (W3) in “Efficient Algorithms and Complexity Theory” commencing as soon as possible.</p>
<p>Website: <a href="https://service.tu-dortmund.de/documents/18/2120803/Professor+W3+in+Efficient+Algorithms+and+Complexity+Theory.pdf/64785b24-b188-fbaa-e337-a2405661868f">https://service.tu-dortmund.de/documents/18/2120803/Professor+W3+in+Efficient+Algorithms+and+Complexity+Theory.pdf/64785b24-b188-fbaa-e337-a2405661868f</a><br />
Email: thomas.schwentick@tu-dortmund.de</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/03/24/full-professor-w3-at-tu-dortmund-university-apply-by-april-15-2020/"><span class="datestr">at March 24, 2020 10:41 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19400">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/03/22/kelman-kindler-lifshitz-minzer-and-safra-towards-the-entropy-influence-conjecture/">Kelman, Kindler, Lifshitz, Minzer, and Safra: Towards the Entropy-Influence Conjecture</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Let me briefly report on a remarkable new paper by Esty Kelman, Guy Kindler, Noam Lifshitz, Dor Minzer, and Muli Safra, <a href="https://arxiv.org/abs/1911.10579">Revisiting Bourgain-Kalai and Fourier Entropies</a>. The paper describes substantial progress towards the Entropy-Influence conjecture, posed by <a href="https://www.ams.org/journals/proc/1996-124-10/S0002-9939-96-03732-X/S0002-9939-96-03732-X.pdf">Ehud Friedgut and me in 1996</a>. (See this <a href="https://terrytao.wordpress.com/2007/08/16/gil-kalai-the-entropyinfluence-conjecture/">blog post from 2007</a>.)</p>
<p><strong>Abstract:</strong> The total inﬂuence of a function is a central notion in analysis of Boolean functions, and characterizing functions that have small total inﬂuence is one of the most fundamental questions associated with it. The KKL theorem and the Friedgut junta theorem give a strong characterization of such functions whenever the bound on the total inﬂuence is <em>o(logn)</em>, however, both results become useless when the total inﬂuence of the function is <em>ω(logn)</em>. The only case in which this logarithmic barrier has been broken for an interesting class of function was proved by Bourgain and Kalai, who focused on functions that are symmetric under large enough subgroups of <img src="https://s0.wp.com/latex.php?latex=S_n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="S_n" class="latex" title="S_n" />.</p>
<p>In this paper, we revisit the key ideas of the Bourgain-Kalai paper. We prove a new general inequality that upper bounds the correlation between a Boolean function <em>f</em> and a real-valued, low degree function<em> g</em> in terms of their norms, Fourier coefﬁcients and total inﬂuences.</p>
<p>Some corollaries of this inequality are:</p>
<ol>
<li>The Bourgain-Kalai result.</li>
<li>A slightly weaker version of the Fourier-Entropy Conjecture. More precisely, we prove that the Fourier entropy of the low-degree part of<em> f</em> is at most <img src="https://s0.wp.com/latex.php?latex=O%28I%5Bf%5Dlog%5E2+I%5Bf%5D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(I[f]log^2 I[f])" class="latex" title="O(I[f]log^2 I[f])" />, where<em> I[f]</em> is the total inﬂuence of <em>f</em>. In particular, we conclude that the Fourier spectrum of a Boolean function is concentrated on at most <img src="https://s0.wp.com/latex.php?latex=2O%28I%5Bf%5Dlog%5E2+I%5Bf%5D%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="2O(I[f]log^2 I[f])" class="latex" title="2O(I[f]log^2 I[f])" /> Fourier coefﬁcients.</li>
<li>Using well-known learning algorithms of sparse functions, the previous point implies that the class of functions with sub-logarithmic total inﬂuence (i.e. at most <img src="https://s0.wp.com/latex.php?latex=O%28%5Clog+n%2F%28%5Clog+%5Clog+n%292%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="O(\log n/(\log \log n)2))" class="latex" title="O(\log n/(\log \log n)2))" /> is learnable in polynomial time, using membership queries.</li>
</ol>
<h2><a href="https://gilkalai.files.wordpress.com/2020/03/bour-kal.png"><img src="https://gilkalai.files.wordpress.com/2020/03/bour-kal.png?w=640&amp;h=435" alt="" width="640" class="alignnone size-large wp-image-19597" height="435" /></a></h2>
<p>Our theorem on influence under symmetry. From my <a href="https://youtu.be/35saSZ93PlI">videotaped lecture</a> on Jean Bourgain. See <a href="https://gilkalai.wordpress.com/2019/01/02/jean/">this post</a> about Jean Bourgain.</p>
<h2>A few remarks:</h2>
<p>A) Given a Boolean function <img src="https://s0.wp.com/latex.php?latex=f%3A%5C%7B-1%2C1%5C%7D%5En%5Cto+%5C%7B-1%2C1%5C%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f:\{-1,1\}^n\to \{-1,1\}" class="latex" title="f:\{-1,1\}^n\to \{-1,1\}" /> let <img src="https://s0.wp.com/latex.php?latex=f%3D%5Csum_%7BS+%5Csubset+%5C%7B1%2C2%2C%5Cdots+%2Cn%5C%7D%7D%5Chat+f%28S%29W_S&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f=\sum_{S \subset \{1,2,\dots ,n\}}\hat f(S)W_S" class="latex" title="f=\sum_{S \subset \{1,2,\dots ,n\}}\hat f(S)W_S" /> be its Fourier-Walsh expansion. (Here <img src="https://s0.wp.com/latex.php?latex=W_S%28x_1%2Cx_2%2C%5Cdots+%2Cx_n%29%3D%5Cprod_%7Bi%5Cin+S%7Dx_i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="W_S(x_1,x_2,\dots ,x_n)=\prod_{i\in S}x_i" class="latex" title="W_S(x_1,x_2,\dots ,x_n)=\prod_{i\in S}x_i" />.) The total influence <img src="https://s0.wp.com/latex.php?latex=I%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(f)" class="latex" title="I(f)" /> of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> is described by</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=I%28f%29%3D%5Csum+%7BS+%5Csubset+%5C%7B1%2C2%2C%5Cdots+%2Cn%5C%7D%7D%5Chat+f%5E2%28S%29%7CS%7C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(f)=\sum {S \subset \{1,2,\dots ,n\}}\hat f^2(S)|S|" class="latex" title="I(f)=\sum {S \subset \{1,2,\dots ,n\}}\hat f^2(S)|S|" />.</p>
<p>The spectral entropy <img src="https://s0.wp.com/latex.php?latex=E%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(f)" class="latex" title="E(f)" /> of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> is defined by</p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=E%28f%29%3D%5Csum_%7BS+%5Csubset+%5C%7B1%2C2%2C%5Cdots+%2Cn%5C%7D%7D%5Chat+f%5E2%28S%29+%5Clog+%28%5Chat+f%5E2%28S%29%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="E(f)=\sum_{S \subset \{1,2,\dots ,n\}}\hat f^2(S) \log (\hat f^2(S))" class="latex" title="E(f)=\sum_{S \subset \{1,2,\dots ,n\}}\hat f^2(S) \log (\hat f^2(S))" />.</p>
<p>The entropy-influence conjecture (here called the Fourier-entropy conjecture) asserts that for some universal constant <em>C</em></p>
<p style="text-align: center;"><img src="https://s0.wp.com/latex.php?latex=I%28f%29+%5Cge+C+E%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="I(f) \ge C E(f)" class="latex" title="I(f) \ge C E(f)" />.</p>
<p>B) One interesting feature of the conjecture is that the RHS is invariant under arbitrary linear transformations of <img src="https://s0.wp.com/latex.php?latex=%5C%7B-1%2C1%5C%7D%5En&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\{-1,1\}^n" class="latex" title="\{-1,1\}^n" /> (regarded as an <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="n" class="latex" title="n" />-dimensional vector space) while the LHS is invariant only to permutations of the variables.</p>
<p>C) My paper with Jean Bourgain, <a href="http://www.ma.huji.ac.il/~kalai/bki.pdf">Influences of variables and threshold intervals under group symmetries</a>, describes lower bounds on total influences for Boolean function invariant under certain groups of permutations (of the variables). Those results are stronger (but more restrictive) than what the Entropy/influence conjecture directly implies. (This was overlooked for a while.) The new paper gives (much hoped for, see below) simpler proofs and stronger results compared to those in my paper with Jean Bourgain.</p>
<p>D) <a href="https://terrytao.wordpress.com/2018/12/29/jean-bourgain/#comment-509792">Ryan O’Donnel wrote</a> about Bourgain and some of his contributions to the analysis of Boolean functions:</p>
<p><em>“I spent close to 5 years understanding one 6-page paper of his (“On the distribution of the Fourier spectrum of Boolean functions”), and also close to 10 years understanding a 10-page paper of his (the k-SAT sharp threshold ‘appendix’). If anyone’s up for a challenge, I’m pretty sure no one on earth fully understands the second half of his paper “Influences of variables and threshold intervals under group symmetries” with Kalai (including Gil <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f642.png" alt="🙂" style="height: 1em;" class="wp-smiley" /> )”</em></p>
<p>It looks that by now we have pretty good understanding and even some far-reaching progress regarding all three papers that Ryan mentioned. (It is unclear if we can hope now for an exponential spread of understanding for Bourgain’s proofs.)</p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/03/22/kelman-kindler-lifshitz-minzer-and-safra-towards-the-entropy-influence-conjecture/"><span class="datestr">at March 22, 2020 10:43 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/038">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/038">TR20-038 |  Error Correcting Codes for Uncompressed Messages | 

	Ofer Grossman, 

	Justin Holmgren</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Most types of messages we transmit (e.g., video, audio, images, text) are not fully compressed, since they do not have known efficient and information theoretically optimal compression algorithms.  When transmitting such messages, standard error correcting codes fail to take advantage of the fact that messages are not fully compressed.

We show that in this setting, it is sub-optimal to use standard error correction. We consider a model where there is a set of “valid messages” which the sender may send that may not be efficiently compressible, but where it is possible for the receiver to recognize valid messages. In this model, we construct a (probabilistic) encoding procedure that achieves better tradeoffs between data rates and error-resilience (compared to just applying a standard error correcting code).

Additionally, our techniques yield improved efficiently decodable (probabilistic) codes for fully compressed messages (the standard setting where the set of valid messages is all binary strings) in the high-rate regime.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/038"><span class="datestr">at March 22, 2020 08:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16828">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/">Star-Free Regular Languages and Logic</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Part 1 of a two-part series</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/wintonprofile/" rel="attachment wp-att-16830"><img src="https://rjlipton.files.wordpress.com/2020/03/wintonprofile.png?w=150&amp;h=165" alt="" width="150" class="alignright wp-image-16830" height="165" /></a></p>
<p>
Daniel Winton is a graduate student in mathematics at Buffalo. He did an independent study with me last semester on descriptive complexity.</p>
<p>
Today we begin a two-part series written by Daniel on a foundational result in this area involving first-order logic and <em>star-free</em> languages.</p>
<p><span id="more-16828"></span></p>
<p>
Dick and I have discussed how GLL might act during the terrible coronavirus developments. We could collect quantitative and theoretical insights to help understand what is happening and possibly contribute to background for attempts to deal with it. Our March 12 <a href="https://rjlipton.wordpress.com/2020/03/12/group-testing-for-the-coronavirus/">post</a> was this kind, and was on the wavelength of an actual advance in group testing announced in Israel two days ago, as noted in a <a href="https://rjlipton.wordpress.com/2020/03/12/group-testing-for-the-coronavirus/#comment-109506">comment</a>. We could try to be even more active than that. We could focus on entertainment and diversion. Our annual St. Patrick’s Day <a href="https://rjlipton.wordpress.com/2020/03/17/leprechauns-stay-home/">post</a> mentioned the ongoing <a href="https://en.candidates-2020.com/main">Candidates</a> <a href="https://new.uschess.org/news/2020-candidates-couch-potatoes/">Tournament</a> in chess, with links to follow it live 7am–noon EDT. Game analysis may be found <a href="http://www.thechessmind.net/">here</a> and elsewhere.</p>
<p>
Here we’re doing what we most often do: present a hopefully sprightly angle on a technical subject. We offer this in solidarity with the many professors and teachers who are beginning to teach online to many students. The subject of regular languages is the start of many theory courses and sometimes taught in high schools. Accordingly, Dick and I decided to prefix a section introducing regular languages as a teaching topic and motivating the use of logic, before entering the main body written by Daniel.</p>
<p>
</p><p></p><h2> Regular Languages and Logic </h2><p></p>
<p></p><p>
<a href="https://en.wikipedia.org/wiki/Regular_language">Regular</a> languages are building blocks used throughout computer science. They can be defined in many ways. Two major types of descriptions are:</p>
<ol>
<li>
Regular expressions. For example, the regular expression <p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++b%5E%7B%2A%7D%28a+b%5E%7B%2A%7D+a+b%5E%7B%2A%7D%29%5E%7B%2A%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  b^{*}(a b^{*} a b^{*})^{*} " class="latex" title="\displaystyle  b^{*}(a b^{*} a b^{*})^{*} " /></p>
<p>describes the set of strings over the alphabet <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Ba%2Cb%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{a,b\}}" class="latex" title="{\{a,b\}}" /> that have an even number of <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" />‘s. </p>
</li><li>
Finite automata, for example:
</li></ol>
<p>
<a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/evendfa/" rel="attachment wp-att-16832"><img src="https://rjlipton.files.wordpress.com/2020/03/evendfa.jpg?w=300&amp;h=140" alt="" width="300" class="aligncenter wp-image-16832" height="140" /></a></p>
<p>
The regular languages defined by (1) and (2) are the same. All regular expressions have corresponding finite automata. This equivalence makes a powerful statement about the concept of regular languages. The more and more diverse definitions we have, the better we understand a concept. This leads us to consider other possible definitions.</p>
<p>
A natural kind of definition involves <em>logic</em>. Studying complexity classes through logic and <a href="https://en.wikipedia.org/wiki/Model_theory">model theory</a> has proven fruitful, creating <a href="https://en.wikipedia.org/wiki/Descriptive_complexity_theory">descriptive complexity</a> as an area. <em>Good news:</em> there are logic definitions equivalent to the regular languages. <em>Bad news:</em> they require going up to second-order logic. We would like to stay with first-order logic. So we ask:</p>
<blockquote><p><b> </b> <em> What kind of languages can we define using only first-order logic (FOL) and simple predicates like “the <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />th bit of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" />” and “place <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> comes before place <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" />“? </em>
</p></blockquote>
<p></p><p>
The answer is the <em>star-free</em> languages, which form a subclass <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> of the regular languages. They were made famous in the book <em>Counter-Free Automata</em> by Robert McNaughton and Seymour Papert, where the equivalence to FOL was proved. A portentous fact is that these automata cannot solve simple tasks involving modular counting. Nor can <em>perceptrons</em>—the title subject of a book at the same time by Papert with Marvin Minsky, which we <a href="https://rjlipton.wordpress.com/2016/01/27/minsky-the-theorist/">discussed</a> in relation to both AI and circuit complexity. This post will introduce <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> and FOL, prove the easier direction of the characterization, and give two lemmas for next time. The second post will present a new way to visualize the other direction. <b>The rest of this post is by Daniel Winton.</b></p>
<p>
</p><p></p><h2> No Stars Upon Thars </h2><p></p>
<p></p><p>
A regular language over an alphabet <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> is one with an expression that can be obtained by applying the union, concatenation, and Kleene star operations a finite number of times on the empty set and singleton subsets of <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" />. Star-free languages are defined similarly but give up the use of the Kleene star <img src="https://s0.wp.com/latex.php?latex=%7B%7B%7D%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{}^*}" class="latex" title="{{}^*}" /> operation, while adding complementation (<img src="https://s0.wp.com/latex.php?latex=%7B%5Csim%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sim}" class="latex" title="{\sim}" />) as a basic operation. The star-free languages are a subset of the regular languages, because regular languages are closed under complementation. </p>
<p>
Complementation often helps find star-free expressions that we ordinarily write using stars. For instance, if the alphabet <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7Ba%2Cb%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\{a,b\}}" class="latex" title="{\{a,b\}}" />, then <img src="https://s0.wp.com/latex.php?latex=%7B%28%5Csim+%5Cemptyset%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\sim \emptyset)}" class="latex" title="{(\sim \emptyset)}" /> gives <img src="https://s0.wp.com/latex.php?latex=%7B%28a+%2B+b%29%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(a + b)^*}" class="latex" title="{(a + b)^*}" />. The following lemma gives a family of regular expressions that use Kleene star but are really star-free.</p>
<blockquote><p><b>Lemma 1</b> <em> The language given by taking the Kleene star operation on a union of singleton elements in an alphabet <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> is star-free. </em>
</p></blockquote>
<p></p><p>
<em>Proof.</em> For <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%3D%5C%7Ba_1%2C+...%2C+a_n%2C+b_1%2C+...%2C+b_m%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma=\{a_1, ..., a_n, b_1, ..., b_m\}}" class="latex" title="{\Sigma=\{a_1, ..., a_n, b_1, ..., b_m\}}" /> we have that <img src="https://s0.wp.com/latex.php?latex=%7B%28b_1%2B+...+%2B+b_m%29%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(b_1+ ... + b_m)^*}" class="latex" title="{(b_1+ ... + b_m)^*}" /> can be given by </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csim%28%28%5Csim%5Cemptyset%29+%28a_1%2B+...+%2B+a_n%29+%28%5Csim%5Cemptyset%29%29.+%5Cquad++&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sim((\sim\emptyset) (a_1+ ... + a_n) (\sim\emptyset)). \quad  " class="latex" title="\displaystyle  \sim((\sim\emptyset) (a_1+ ... + a_n) (\sim\emptyset)). \quad  " /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>For example, the language <img src="https://s0.wp.com/latex.php?latex=%7Bb%5E%2Aab%5E%2Aab%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b^*ab^*ab^*}" class="latex" title="{b^*ab^*ab^*}" /> is star-free because <img src="https://s0.wp.com/latex.php?latex=%7Bb%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b^*}" class="latex" title="{b^*}" /> is by this lemma. This idea extends also to forbidden substrings—e.g., the set of strings with no <img src="https://s0.wp.com/latex.php?latex=%7Baa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{aa}" class="latex" title="{aa}" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%5C%3B%5Csim%28%28%5Csim%5Cemptyset%29aa%28%5Csim%5Cemptyset%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\;\sim((\sim\emptyset)aa(\sim\emptyset))}" class="latex" title="{\;\sim((\sim\emptyset)aa(\sim\emptyset))}" />. </p>
<p>
The language <img src="https://s0.wp.com/latex.php?latex=%7B%28ab+%2B+ba+%2B+bb%29%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(ab + ba + bb)^*}" class="latex" title="{(ab + ba + bb)^*}" /> is not the same, however, and it is not star-free. Intuitively this is because it involves modular counting: an <img src="https://s0.wp.com/latex.php?latex=%7Baa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{aa}" class="latex" title="{aa}" /> in an odd position is OK but not even. The parity language <img src="https://s0.wp.com/latex.php?latex=%7Bb%5E%2A%28ab%5E%2Aab%5E%2A%29%5E%2A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b^*(ab^*ab^*)^*}" class="latex" title="{b^*(ab^*ab^*)^*}" /> from the introduction is another example. So <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> is a proper subset of the regular languages. What kind of subset? This is where having a third description via logic is really useful.</p>
<p>
</p><p></p><h2> The First Order of Business </h2><p></p>
<p></p><p>
In addition to the familiar Boolean operations <img src="https://s0.wp.com/latex.php?latex=%7B%5Cwedge%2C%5Cvee%2C%5Cneg%2C%5Crightarrow%2C%5Cleftrightarrow%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\wedge,\vee,\neg,\rightarrow,\leftrightarrow}" class="latex" title="{\wedge,\vee,\neg,\rightarrow,\leftrightarrow}" /> and truth values, <em>first-order logic</em> provides variables that range over elements of a structure and quantifiers on those variables. Since we will be concerned with Boolean strings <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, the variables will range over places in the string <img src="https://s0.wp.com/latex.php?latex=%7B0%2C%5Cdots%2Cn-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0,\dots,n-1}" class="latex" title="{0,\dots,n-1}" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+%7Cx%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = |x|}" class="latex" title="{n = |x|}" />. A logic also specifies a set of predicates that relate variables and interact with the structure. For strings we have:</p>
<ul>
<li>
<img src="https://s0.wp.com/latex.php?latex=%7BX_c%28i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c(i)}" class="latex" title="{X_c(i)}" />, meaning that the symbol indexed <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> in <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> is the character <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" />. The logic gives one such predicate for each <img src="https://s0.wp.com/latex.php?latex=%7Bc+%5Cin+%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c \in \Sigma}" class="latex" title="{c \in \Sigma}" />. <p></p>
</li><li>
<img src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i &lt; j}" class="latex" title="{i &lt; j}" />, with the obvious meaning for natural numbers <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" />.
</li></ul>
<p>
We can take the <img src="https://s0.wp.com/latex.php?latex=%7BX_c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c}" class="latex" title="{X_c}" /> for granted since we are talking about strings, but we need to say that predicates like <img src="https://s0.wp.com/latex.php?latex=%7Bi+%2B+j+%3D+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i + j = k}" class="latex" title="{i + j = k}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bi%5Ccdot+j+%3D+k%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i\cdot j = k}" class="latex" title="{i\cdot j = k}" /> are excluded, so we call this <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" />. We could define equality by <img src="https://s0.wp.com/latex.php?latex=%7Bi+%3D+j+%5Cequiv+%5Clnot%28i+%3C+j+%5Clor+j+%3C+i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i = j \equiv \lnot(i &lt; j \lor j &lt; i)}" class="latex" title="{i = j \equiv \lnot(i &lt; j \lor j &lt; i)}" /> but we regard equality as inherent.</p>
<p>
We can use <img src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{&lt;}" class="latex" title="{&lt;}" /> to define the successor relation <img src="https://s0.wp.com/latex.php?latex=%7BS%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S(i,j)}" class="latex" title="{S(i,j)}" />, which denotes that position <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> comes immediately after position <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S%28i%2Cj%29+%5Cequiv+i%3Cj+%5Cland+%5Cforall+k+%28i%3Ck+%5Crightarrow+j%5Cleq+k%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  S(i,j) \equiv i&lt;j \land \forall k (i&lt;k \rightarrow j\leq k). " class="latex" title="\displaystyle  S(i,j) \equiv i&lt;j \land \forall k (i&lt;k \rightarrow j\leq k). " /></p>
<p>
Note the use of quantifiers. We can use quantifiers to say things about the string <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> too. For instance, the language <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> of strings having no <img src="https://s0.wp.com/latex.php?latex=%7Baa%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{aa}" class="latex" title="{aa}" /> substrings is defined by the logical sentence</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csigma_L+%3D+%28%5Cforall+i%2Cj%29%3AS%28i%2Cj%29+%5Crightarrow+%5Cneg+%28X_a%28i%29+%5Cland+X_a%28j%29%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sigma_L = (\forall i,j):S(i,j) \rightarrow \neg (X_a(i) \land X_a(j)). " class="latex" title="\displaystyle  \sigma_L = (\forall i,j):S(i,j) \rightarrow \neg (X_a(i) \land X_a(j)). " /></p>
<p>
It is implicit here that <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> are always in-bounds. If <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> were a legal constant with <img src="https://s0.wp.com/latex.php?latex=%7BX_c%28n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{X_c(n)}" class="latex" title="{X_c(n)}" /> always false then a string like <img src="https://s0.wp.com/latex.php?latex=%7Bbbba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{bbba}" class="latex" title="{bbba}" /> (which belongs to <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" />) would falsify <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_L}" class="latex" title="{\sigma_L}" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bi+%3D+n-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i = n-1}" class="latex" title="{i = n-1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj+%3D+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j = n}" class="latex" title="{j = n}" />. </p>
<p>
How big is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" />? We'll see it is no more and no less than <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" />.</p>
<p>
</p><p></p><h2> From SF to FO </h2><p></p>
<p></p><p>
To prove that any language <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> has a definition in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}}" class="latex" title="{\mathsf{FO}}" />, we will not only give a sentence <img src="https://s0.wp.com/latex.php?latex=%7B%5Csigma_L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sigma_L}" class="latex" title="{\sigma_L}" /> but also a <em>formula</em> <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_L%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_L(i,j)}" class="latex" title="{\phi_L(i,j)}" />. We will define this formula to indicate that for a given string <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, the portion of the string between indices <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j-1}" class="latex" title="{j-1}" /> is in <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" />. Then for the correct choices of <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_L%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_L(i,j)}" class="latex" title="{\phi_L(i,j)}" /> gives <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" />. We define <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi}" class="latex" title="{\phi}" /> to test middle portions of strings, because it handles lengths better for the induction in the concatenation case. </p>
<blockquote><p><b>Theorem 2</b> <em></em></p><em>
<p>
Every language in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" /> is definable in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" />.</p>
</em><p><em>
</em>
</p></blockquote>
<p>
The proof is a nice example where “building up” to prove something more general—involving two extra variables—makes induction go smoothly.</p>
<p>
<em>Proof:</em>  Let <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> be a star-free regular language and <img src="https://s0.wp.com/latex.php?latex=%7BL%27%3D%5C%7B%5Clangle+x%2C+i+%2Cj+%5Crangle%3A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L'=\{\langle x, i ,j \rangle:}" class="latex" title="{L'=\{\langle x, i ,j \rangle:}" /> the portion of the string <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> between indices <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> (inclusive) and <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> (exclusive) is contained in <img src="https://s0.wp.com/latex.php?latex=%7BL%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L\}}" class="latex" title="{L\}}" />. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_L%28i%2Cj%29%5Cin+%5Csf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_L(i,j)\in \sf{FO}[&lt;]}" class="latex" title="{\phi_L(i,j)\in \sf{FO}[&lt;]}" /> be the formula denoting that for a given string <img src="https://s0.wp.com/latex.php?latex=%7Bx%2C+x%5Bi%2Cj%29%5Cin+L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x, x[i,j)\in L}" class="latex" title="{x, x[i,j)\in L}" />, that is, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_L%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_L(i,j)}" class="latex" title="{\phi_L(i,j)}" /> is the representation of <img src="https://s0.wp.com/latex.php?latex=%7BL%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L'}" class="latex" title="{L'}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" />. We will show that such a <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_L%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_L(i,j)}" class="latex" title="{\phi_L(i,j)}" /> exists via induction on <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" />. This is sufficient, as for a given symbol <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> that always represents the length of a string <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_L%280%2Cn%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_L(0,n)}" class="latex" title="{\phi_L(0,n)}" /> is the formula in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> representing the language <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" />. </p>
<p>
First, we must show that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_L%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_L}" class="latex" title="{\phi_L}" /> is in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> one of the basis languages, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%2C+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset, \epsilon}" class="latex" title="{\emptyset, \epsilon}" />, and <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" />, for some <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" />. We have that:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Cphi_%5Cemptyset%28i%2Cj%29+%26%3D%26+%5Ctexttt%7Bfalse%7D%3B%5C%5C+%5Cphi_%5Cepsilon%28i%2Cj%29+%26%3D%26+i%3Dj%3B%5C%5C+%5Cphi_c%28i%2Cj%29+%26%3D%26+%28X_c%28i%29%5Cland+S%28i%2Cj%29%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  \phi_\emptyset(i,j) &amp;=&amp; \texttt{false};\\ \phi_\epsilon(i,j) &amp;=&amp; i=j;\\ \phi_c(i,j) &amp;=&amp; (X_c(i)\land S(i,j)). \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  \phi_\emptyset(i,j) &amp;=&amp; \texttt{false};\\ \phi_\epsilon(i,j) &amp;=&amp; i=j;\\ \phi_c(i,j) &amp;=&amp; (X_c(i)\land S(i,j)). \end{array} " /></p>
<p>
Now, we must show that given star-free languages <img src="https://s0.wp.com/latex.php?latex=%7BL_1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_1}" class="latex" title="{L_1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BL_2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L_2}" class="latex" title="{L_2}" /> with FO<img src="https://s0.wp.com/latex.php?latex=%7B%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[&lt;]}" class="latex" title="{[&lt;]}" /> translations <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_1%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_1(i,j)}" class="latex" title="{\psi_1(i,j)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpsi_2%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\psi_2(i,j)}" class="latex" title="{\psi_2(i,j)}" /> respectively, we have <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_%7BL_1%5Ccup+L_2%7D%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_{L_1\cup L_2}(i,j)}" class="latex" title="{\phi_{L_1\cup L_2}(i,j)}" />, <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_%7BL_1%5Ccdot+L_2%7D%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_{L_1\cdot L_2}(i,j)}" class="latex" title="{\phi_{L_1\cdot L_2}(i,j)}" />, and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_%7B%5Csim+L_1%7D%28i%2Cj%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_{\sim L_1}(i,j)}" class="latex" title="{\phi_{\sim L_1}(i,j)}" /> are in <img src="https://s0.wp.com/latex.php?latex=%7B%5Csf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sf{FO}[&lt;]}" class="latex" title="{\sf{FO}[&lt;]}" />. Then: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Cphi_%7BL_1%5Ccup+L_2%7D%28i%2Cj%29%26%3D%26%5Cpsi_1%28i%2Cj%29+%5Clor+%5Cpsi_2%28i%2Cj%29%3B%5C%5C+%5C%5C+%5Cphi_%7BL_1%5Ccdot+L_2%7D%28i%2Cj%29%26%3D%26%5Cexists+k%28i%5Cleq+k+%5Cland+k+%5Cleq+j%29+%28%5Cpsi_1%28i%2Ck%29+%5Cland+%5Cpsi_2%28k%2Cj%29%29%3B%5C%5C+%5C%5C+%5Cphi_%7B%5Csim+L_1%7D%28i%2Cj%29%26%3D%26%5Clnot+%5Cpsi_%7B1%7D%28i%2Cj%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  \phi_{L_1\cup L_2}(i,j)&amp;=&amp;\psi_1(i,j) \lor \psi_2(i,j);\\ \\ \phi_{L_1\cdot L_2}(i,j)&amp;=&amp;\exists k(i\leq k \land k \leq j) (\psi_1(i,k) \land \psi_2(k,j));\\ \\ \phi_{\sim L_1}(i,j)&amp;=&amp;\lnot \psi_{1}(i,j). \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  \phi_{L_1\cup L_2}(i,j)&amp;=&amp;\psi_1(i,j) \lor \psi_2(i,j);\\ \\ \phi_{L_1\cdot L_2}(i,j)&amp;=&amp;\exists k(i\leq k \land k \leq j) (\psi_1(i,k) \land \psi_2(k,j));\\ \\ \phi_{\sim L_1}(i,j)&amp;=&amp;\lnot \psi_{1}(i,j). \end{array} " /></p>
<p>
Since star-free languages can be obtained by applying the union, concatenation, and complementation operations a finite number of times on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cemptyset%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\emptyset}" class="latex" title="{\emptyset}" /> and singleton subsets of <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" />, this completes the proof of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D+%5Csubseteq+%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF} \subseteq \mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{SF} \subseteq \mathsf{FO}[&lt;]}" />. <img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
</p><p></p><h2> Two Lemmas For Next Time </h2><p></p>
<p></p><p>
Prefatory to showing (in the next post) that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;]}" class="latex" title="{\mathsf{FO}[&lt;]}" /> is contained in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{SF}}" class="latex" title="{\mathsf{SF}}" />, we prove properties about substrings on the ends of star-free languages, rather than in the middle as with the trick in the proof of Theorem 2.</p>
<p>
Let <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> be a language over an alphabet <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> be a word in <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma^n}" class="latex" title="{\Sigma^n}" /> for some <img src="https://s0.wp.com/latex.php?latex=%7Bn%5Cin+%5Cmathbb%7BN%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n\in \mathbb{N}}" class="latex" title="{n\in \mathbb{N}}" />. Define <img src="https://s0.wp.com/latex.php?latex=%7BL%2Fw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L/w}" class="latex" title="{L/w}" />, the <em>right quotient</em> of <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> by <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" />, by <img src="https://s0.wp.com/latex.php?latex=%7BL%2Fw+%3D%5C%7Bv%3A+vw+%5Cin+L%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L/w =\{v: vw \in L\}}" class="latex" title="{L/w =\{v: vw \in L\}}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BL%5Cbackslash+w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L\backslash w}" class="latex" title="{L\backslash w}" />, the <em>left quotient</em> of <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> by <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" />, by <img src="https://s0.wp.com/latex.php?latex=%7BL%5Cbackslash+w%3D%5C%7Bv%3Awv+%5Cin+L%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L\backslash w=\{v:wv \in L\}}" class="latex" title="{L\backslash w=\{v:wv \in L\}}" />.  First we handle right quotients:</p>
<blockquote><p><b>Lemma 3</b> <em> If <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> is star-free, then <img src="https://s0.wp.com/latex.php?latex=%7BL%2Fw%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L/w}" class="latex" title="{L/w}" /> is star-free. </em>
</p></blockquote>
<p></p><p>
<em>Proof:</em>  For any word <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> we define a function <img src="https://s0.wp.com/latex.php?latex=%7Bf_w%28%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_w(\alpha)}" class="latex" title="{f_w(\alpha)}" /> by <img src="https://s0.wp.com/latex.php?latex=%7Bf_w%28%5Calpha%29%3D%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_w(\alpha)=\alpha'}" class="latex" title="{f_w(\alpha)=\alpha'}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BL%28%5Calpha%27%29%3DL%28%5Calpha%29%2Fw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L(\alpha')=L(\alpha)/w}" class="latex" title="{L(\alpha')=L(\alpha)/w}" />. If <img src="https://s0.wp.com/latex.php?latex=%7Bw+%3D+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w = \epsilon}" class="latex" title="{w = \epsilon}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bf_w%28%5Calpha%29%3D%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_w(\alpha)=\alpha}" class="latex" title="{f_w(\alpha)=\alpha}" />, and so the statement of the lemma trivially holds. So let <img src="https://s0.wp.com/latex.php?latex=%7Bw+%3D+vc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w = vc}" class="latex" title="{w = vc}" /> for some string <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> and character <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" />. Note that <img src="https://s0.wp.com/latex.php?latex=%7BL%2F%28vc%29+%3D+%28L%2Fc%29%2Fv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L/(vc) = (L/c)/v}" class="latex" title="{L/(vc) = (L/c)/v}" />. Thus <img src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bvc%7D%28%5Calpha%29+%3D+f_v%28f_c%28%5Calpha%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_{vc}(\alpha) = f_v(f_c(\alpha))}" class="latex" title="{f_{vc}(\alpha) = f_v(f_c(\alpha))}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />. Hence it suffices to define <img src="https://s0.wp.com/latex.php?latex=%7Bf_c%28%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_c(\alpha)}" class="latex" title="{f_c(\alpha)}" /> for any single character <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> by recursion on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />. We have:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++f_c%28%5Cemptyset%29%26%3D%26%5Cemptyset%3B%5C%5C+f_c%28%5Cepsilon%29%26%3D%26%5Cemptyset%3B%5C%5C+f_c%28c%29%26%3D%26%5Cepsilon%3B%5C%5C+f_c%28a%29%26%3D%26%5Cemptyset%2C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  f_c(\emptyset)&amp;=&amp;\emptyset;\\ f_c(\epsilon)&amp;=&amp;\emptyset;\\ f_c(c)&amp;=&amp;\epsilon;\\ f_c(a)&amp;=&amp;\emptyset, \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  f_c(\emptyset)&amp;=&amp;\emptyset;\\ f_c(\epsilon)&amp;=&amp;\emptyset;\\ f_c(c)&amp;=&amp;\epsilon;\\ f_c(a)&amp;=&amp;\emptyset, \end{array} " /></p>
<p>
and recursively:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++f_c%28%5Calpha+%5Ccup%5Cbeta%29%26%3D%26f_c%28%5Calpha%29+%5Ccup+f_c%28%5Cbeta%29%3B%5C%5C%5C%5C+f_c%28%5Calpha%5Ccdot%5Cbeta%29%26%3D%26%5Cbegin%7Bcases%7D+%5Calpha%5Ccdot+f_c%28%5Cbeta%29+%26+%5Cepsilon%5Cnot%5Cin+L%28%5Cbeta%29%2C+%5C%5C+%5Calpha%5Ccdot+f_c%28%5Cbeta%29+%5Ccup+f_c%28%5Calpha%29+%26+otherwise%5Ctext%7B%3B%7D+%5Cend%7Bcases%7D%5C%5C%5C%5C+f_c%28%5Csim%5Calpha%29%26%3D%26%5Csim+f_c%28%5Calpha%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  f_c(\alpha \cup\beta)&amp;=&amp;f_c(\alpha) \cup f_c(\beta);\\\\ f_c(\alpha\cdot\beta)&amp;=&amp;\begin{cases} \alpha\cdot f_c(\beta) &amp; \epsilon\not\in L(\beta), \\ \alpha\cdot f_c(\beta) \cup f_c(\alpha) &amp; otherwise\text{;} \end{cases}\\\\ f_c(\sim\alpha)&amp;=&amp;\sim f_c(\alpha). \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  f_c(\alpha \cup\beta)&amp;=&amp;f_c(\alpha) \cup f_c(\beta);\\\\ f_c(\alpha\cdot\beta)&amp;=&amp;\begin{cases} \alpha\cdot f_c(\beta) &amp; \epsilon\not\in L(\beta), \\ \alpha\cdot f_c(\beta) \cup f_c(\alpha) &amp; otherwise\text{;} \end{cases}\\\\ f_c(\sim\alpha)&amp;=&amp;\sim f_c(\alpha). \end{array} " /></p>
<p>
In general, if <img src="https://s0.wp.com/latex.php?latex=%7Bw+%3D+c_1+c_2+%5Ccdots+c_%7Bn-1%7D+c_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w = c_1 c_2 \cdots c_{n-1} c_n}" class="latex" title="{w = c_1 c_2 \cdots c_{n-1} c_n}" />, then</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L%2Fw+%3D+f_%7Bc_1%7D%28f_%7Bc_2%7D%28%5Cdots+f_%7Bc_%7Bn-1%7D%7D%28f_%7Bc_n%7D%28%5Calpha%29%29%5Cdots%29%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle L/w = f_{c_1}(f_{c_2}(\dots f_{c_{n-1}}(f_{c_n}(\alpha))\dots))." class="latex" title="\displaystyle L/w = f_{c_1}(f_{c_2}(\dots f_{c_{n-1}}(f_{c_n}(\alpha))\dots))." /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<blockquote><p><b>Lemma 4</b> <em> If <img src="https://s0.wp.com/latex.php?latex=%7BL%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L}" class="latex" title="{L}" /> is star-free, then <img src="https://s0.wp.com/latex.php?latex=%7BL%5Cbackslash+w%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{L\backslash w}" class="latex" title="{L\backslash w}" /> is star-free. </em>
</p></blockquote>
<p></p><p>
The proof of Lemma 4 is similar to the proof of Lemma 3. The main differences lie in the concatenation subcase for the <img src="https://s0.wp.com/latex.php?latex=%7Bw%3Dc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w=c}" class="latex" title="{w=c}" /> case and the order of quotienting when using this operation repeatedly.</p>
<p>
<em>Proof:</em>  For any word <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B%5CSigma%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\Sigma}" class="latex" title="{\Sigma}" /> we define a function <img src="https://s0.wp.com/latex.php?latex=%7Bf_w%28%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_w(\alpha)}" class="latex" title="{f_w(\alpha)}" /> by <img src="https://s0.wp.com/latex.php?latex=%7Bf_w%28%5Calpha%29%3D%5Calpha%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_w(\alpha)=\alpha'}" class="latex" title="{f_w(\alpha)=\alpha'}" /> where <img src="https://s0.wp.com/latex.php?latex=%7BL%28%5Calpha%27%29%3DL%28%5Calpha%29%5Cbackslash+w%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L(\alpha')=L(\alpha)\backslash w}" class="latex" title="{L(\alpha')=L(\alpha)\backslash w}" />. If <img src="https://s0.wp.com/latex.php?latex=%7Bw+%3D+%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w = \epsilon}" class="latex" title="{w = \epsilon}" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bf_w%28%5Calpha%29%3D%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_w(\alpha)=\alpha}" class="latex" title="{f_w(\alpha)=\alpha}" />, and so the statement of the lemma trivially holds. So let <img src="https://s0.wp.com/latex.php?latex=%7Bw+%3D+vc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w = vc}" class="latex" title="{w = vc}" /> for some string <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> and character <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" />. Note that <img src="https://s0.wp.com/latex.php?latex=%7BL%5Cbackslash%28vc%29+%3D+%28L%5Cbackslash+v%29%5Cbackslash+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{L\backslash(vc) = (L\backslash v)\backslash c}" class="latex" title="{L\backslash(vc) = (L\backslash v)\backslash c}" />. Thus <img src="https://s0.wp.com/latex.php?latex=%7Bf_%7Bvc%7D%28%5Calpha%29+%3D+f_c%28f_v%28%5Calpha%29%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_{vc}(\alpha) = f_c(f_v(\alpha))}" class="latex" title="{f_{vc}(\alpha) = f_c(f_v(\alpha))}" /> for all <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />. Hence it suffices to define <img src="https://s0.wp.com/latex.php?latex=%7Bf_c%28%5Calpha%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f_c(\alpha)}" class="latex" title="{f_c(\alpha)}" /> for any single character <img src="https://s0.wp.com/latex.php?latex=%7Bc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c}" class="latex" title="{c}" /> by recursion on <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />. We have:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++f_c%28%5Cemptyset%29%26%3D%26%5Cemptyset%3B%5C%5C+f_c%28%5Cepsilon%29%26%3D%26%5Cemptyset%3B%5C%5C+f_c%28c%29%26%3D%26%5Cepsilon%3B%5C%5C+f_c%28a%29%26%3D%26%5Cemptyset.%5C%5C+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  f_c(\emptyset)&amp;=&amp;\emptyset;\\ f_c(\epsilon)&amp;=&amp;\emptyset;\\ f_c(c)&amp;=&amp;\epsilon;\\ f_c(a)&amp;=&amp;\emptyset.\\ \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  f_c(\emptyset)&amp;=&amp;\emptyset;\\ f_c(\epsilon)&amp;=&amp;\emptyset;\\ f_c(c)&amp;=&amp;\epsilon;\\ f_c(a)&amp;=&amp;\emptyset.\\ \end{array} " /></p>
<p>
and recursively:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++f_c%28%5Calpha%5Ccup%5Cbeta%29%26%3D%26f_c%28%5Calpha%29%5Ccup+f_c%28%5Cbeta%29%3B%5C%5C%5C%5C+f_c%28%5Calpha%5Ccdot%5Cbeta%29%26%3D%26%5Cbegin%7Bcases%7D+f_c%28%5Calpha%29%5Ccdot%5Cbeta+%26+%5Cepsilon%5Cnot%5Cin+L%28%5Calpha%29%2C+%5C%5C+f_c%28%5Calpha%29%5Ccdot%5Cbeta+%5Ccup+f_c%5Cbeta%29+%26+otherwise%5Ctext%7B%3B%7D+%5Cend%7Bcases%7D%5C%5C%5C%5C+f_c%28%5Csim+%5Calpha%29%26%3D%26%5Csim+f_c%28%5Calpha%29.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  f_c(\alpha\cup\beta)&amp;=&amp;f_c(\alpha)\cup f_c(\beta);\\\\ f_c(\alpha\cdot\beta)&amp;=&amp;\begin{cases} f_c(\alpha)\cdot\beta &amp; \epsilon\not\in L(\alpha), \\ f_c(\alpha)\cdot\beta \cup f_c\beta) &amp; otherwise\text{;} \end{cases}\\\\ f_c(\sim \alpha)&amp;=&amp;\sim f_c(\alpha). \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  f_c(\alpha\cup\beta)&amp;=&amp;f_c(\alpha)\cup f_c(\beta);\\\\ f_c(\alpha\cdot\beta)&amp;=&amp;\begin{cases} f_c(\alpha)\cdot\beta &amp; \epsilon\not\in L(\alpha), \\ f_c(\alpha)\cdot\beta \cup f_c\beta) &amp; otherwise\text{;} \end{cases}\\\\ f_c(\sim \alpha)&amp;=&amp;\sim f_c(\alpha). \end{array} " /></p>
<p>
In general, if <img src="https://s0.wp.com/latex.php?latex=%7Bw+%3D+c_1+c_2+%5Ccdots+c_%7Bn-1%7D+c_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w = c_1 c_2 \cdots c_{n-1} c_n}" class="latex" title="{w = c_1 c_2 \cdots c_{n-1} c_n}" />, then</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+L%5Cbackslash+w+%3D+f_%7Bc_n%7D%28f_%7Bc_%7Bn-1%7D%7D%28%5Cdots+f_%7Bc_%7B2%7D%7D%28f_%7Bc_1%7D%28%5Calpha%29%29%5Cdots%29%29.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle L\backslash w = f_{c_n}(f_{c_{n-1}}(\dots f_{c_{2}}(f_{c_1}(\alpha))\dots))." class="latex" title="\displaystyle L\backslash w = f_{c_n}(f_{c_{n-1}}(\dots f_{c_{2}}(f_{c_1}(\alpha))\dots))." /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5CBox&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\Box" class="latex" title="\Box" /></p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
There are richer systems such as <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%28%2B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}(+)}" class="latex" title="{\mathsf{FO}(+)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%28%2B%2C%5Ccdot%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}(+,\cdot)}" class="latex" title="{\mathsf{FO}(+,\cdot)}" />. Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%28%2B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}(+)}" class="latex" title="{\mathsf{FO}(+)}" /> allows defining the <img src="https://s0.wp.com/latex.php?latex=%7B%3C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{&lt;}" class="latex" title="{&lt;}" /> relation via <img src="https://s0.wp.com/latex.php?latex=%7Bi+%3C+j+%5Cequiv+%28%5Cexists+k%29+%5Clnot%28k%3D+0%29+%5Cland+i+%2B+k+%3D+j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{i &lt; j \equiv (\exists k) \lnot(k= 0) \land i + k = j}" class="latex" title="{i &lt; j \equiv (\exists k) \lnot(k= 0) \land i + k = j}" />. We can define non-regular languages such as <img src="https://s0.wp.com/latex.php?latex=%7B%7Ba%5En+b%5En%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{{a^n b^n}}" class="latex" title="{{a^n b^n}}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%28%2B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}(+)}" class="latex" title="{\mathsf{FO}(+)}" />. The class <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%28%2B%2C%5Ctimes%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}(+,\times)}" class="latex" title="{\mathsf{FO}(+,\times)}" /> famously equals uniform <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BAC%5E0%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{AC^0}}" class="latex" title="{\mathsf{AC^0}}" />, see chapter 5 of Neil Immerman's <a href="https://link.springer.com/book/10.1007/978-1-4612-0539-5">book</a> <em>Descriptive Complexity</em>. Thus we hope our new style for proving <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BFO%7D%5B%3C%5D+%5Csubseteq+%5Cmathsf%7BSF%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{FO}[&lt;] \subseteq \mathsf{SF}}" class="latex" title="{\mathsf{FO}[&lt;] \subseteq \mathsf{SF}}" /> (to come in the next part) will build a nice foundation for visualizing these higher results.</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/03/21/star-free-regular-languages-and-logic/"><span class="datestr">at March 21, 2020 08:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/037">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/037">TR20-037 |  Failure of Feasible Disjunction Property for $k$-DNF Resolution and NP-hardness of Automating It | 

	Michal Garlik</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that for every integer $k \geq 2$, the Res($k$) propositional proof system does not have the weak feasible disjunction property. Next, we generalize a recent result of Atserias and Müller [FOCS, 2019] to Res($k$). We show that if NP is not included in P (resp. QP, SUBEXP) then for every integer $k \geq 1$, Res($k$) is not automatable in polynomial (resp. quasi-polynomial, subexponential) time.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/037"><span class="datestr">at March 21, 2020 11:53 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7654">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/03/19/focs-deadline-pushed-back-6-days/">FOCS deadline pushed back 6 days</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>From Sandy Irani, FOCS 2020 PC chair:</p>



<p>In light of the very unusual developments in the world due to the spread of Covid-19 and the disruption it is causing to many people in our field, especially those with young children at home, the FOCS PC has decided to push back the final deadline for papers by six days. We would have liked to do more, but we still are trying to stick to our timeline for notification since that date is coordinated with other deadlines in the theory community. In addition, some members of the committee are also affected by this crisis and there is concern that we may not be able to do our job as a committee in a shorter time frame. Pre-registration (including titles and abstracts) is still required by the original deadline. Here are the new dates:</p>



<p><strong>Pre-registration (including titles and abstracts):</strong> Thursday <strong>April 9</strong>, 11:59 PM (EDT)</p>



<p><strong>Final Paper Submission:</strong> Wednesday <strong>April 15</strong>, 11:59 PM (EDT)</p>



<p>Conference url: <a href="https://focs2020.cs.duke.edu/" target="_blank" rel="noreferrer noopener">https://focs2020.cs.duke.edu/</a></p>



<p>We hope you all stay healthy!</p>



<p>–Sandy Irani, for the FOCS 2020 Committee</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/03/19/focs-deadline-pushed-back-6-days/"><span class="datestr">at March 19, 2020 04:27 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=39">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/03/19/friday-march-27-sujay-sanghavi-from-ut-austin/">Friday, March 27 — Sujay Sanghavi from UT Austin</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The second Foundations of Data Science virtual talk will take place next Friday, March 27th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Sujay Sanghavi</strong> from University of Texas at Austin will speak about “<em>Towards Model Agnostic Robustness</em>”.</p>



<p><strong>Abstract</strong>: It is now common practice to try and solve machine learning problems by starting with a complex existing model or architecture, and fine-tuning/adapting it to the task at hand. However, outliers, errors or even just sloppiness in training data often lead to drastic drops in performance. </p>



<p>We investigate a simple generic approach to correct for this, motivated by a classic statistical idea: trimmed loss. This advocates jointly (a) selecting which training samples to ignore, and (b) fitting a model on the remaining samples. As such this is computationally infeasible even for linear regression. We propose and study the natural iterative variant that alternates between these two steps (a) and (b) – each of which individually can be easily accomplished in pretty much any statistical setting. We also study the batch-SGD variant of this idea. We demonstrate both theoretically (for generalized linear models) and empirically (for vision and NLP neural network models) that this effectively recovers accuracy in the presence of bad training data.</p>



<p>This work is joint with Yanyao Shen and Vatsal Shah and appears in NeurIPS 2019, ICML 2019 and AISTATS 2020.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/03/19/friday-march-27-sujay-sanghavi-from-ut-austin/"><span class="datestr">at March 19, 2020 02:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1570">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2020/03/18/private-and-secure-distributed-matrix-multiplication/">Private and Secure Distributed Matrix Multiplication</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Machine learning on big data sets takes a significant amount of computational power, so it  is often necessary to offload some of the work to external distributed systems, such as an Amazon EC2 cluster. It is useful to be able to utilize external resources for computation tasks while keeping the actual data <em>private</em> and<em> secure</em>. In particular, matrix multiplication is an essential step in many machine learning processes, but the owner of the matrices may have reasons to keep the actual values protected.</p>



<p>In this post, we’ll discuss four works about secure distributed computation. First, we’ll talk about a method of using MDS (maximum distance separable) error correcting codes to add security and privacy to general data storage (“<a href="https://arxiv.org/pdf/1808.07457.pdf">Cross Subspace Alignment and the Asymptotic Capacity of X-Secure T-Private Information Retrieval”</a> by Jia, Sun, Jafar). </p>



<p>Then we’ll discuss method of adapting a coding strategy for straggler mitigation (<a href="http://papers.nips.cc/paper/7027-polynomial-codes-an-optimal-design-for-high-dimensional-coded-matrix-multiplication.pdf">“Polynomial codes: an optimal design for high-dimensional coded matrix multiplication”</a> by Yu, Qian, Maddah-Ali, Avestimehr) in matrix multiplication to instead add security or privacy (<a href="https://uweb.engr.arizona.edu/~wchang/Globecom-SecureMM-2018.pdf">“On the capacity of secure distributed matrix multiplication”</a> by Chang, Tandon and <a href="https://ieeexplore-ieee-org.stanford.idm.oclc.org/abstract/document/8832193">“Private Coded Matrix Multiplication”</a> by Kim, Yang, Lee)</p>



<p>Throughout this post we will use variations on the following communication model:</p>



<figure class="wp-block-image size-large is-resized"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig1.png?w=1024" alt="" width="404" class="wp-image-1572" height="192" /></figure>



<p>The data in the grey box is only given to the master, so workers only have access to what they receive (via green arrows). Later on we will also suppose the workers have a shared library not available to the master. The workers do not communicate with each other as part of the computation, but we want to prevent them from figuring out anything about the data if they do talk to each other.</p>



<p> This model is related to <em>private computation</em> but not exactly the same. We assume the servers are “honest but curious”, meaning they won’t introduce malicious computations. We also only require the master to receive the final result, and don’t need to protect any data from the master. This is close to the BGW scheme ([Ben-Or, Goldwasser, Wigderson ’88]), but we do not allow workers to communicate with each other as part of the computation of the result.</p>



<p> We consider <em>unconditional</em> or <em>information-theoretic</em> security, meaning the data is protected even if the workers have unbounded computational power. Furthermore, we will consider having <em>perfect  secrecy</em>, in which the mutual information between the information revealed to the workers and the actual messages is zero.</p>



<h2>X-Secure T-Private Information Retrieval</h2>



<p> Before we get into matrix-matrix multiplication, consider the problem of storing information on the workers to be retrieved by the master, such that it is “protected.” What do we mean by that? [Jia, Sun, and Jafar ’19] define X-secure T-private information retrieval as follows: </p>



<blockquote class="wp-block-quote"><p>Let <img src="https://s0.wp.com/latex.php?latex=W_1%2C...%2CW_%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="W_1,...,W_{K}" class="latex" title="W_1,...,W_{K}" /> be a data set of messages, such that each <img src="https://s0.wp.com/latex.php?latex=W_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="W_i" class="latex" title="W_i" /> consists of <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L" class="latex" title="L" /> random bits. A storage scheme of <img src="https://s0.wp.com/latex.php?latex=W_%7B1%7D%2C...%2CW_%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="W_{1},...,W_{K}" class="latex" title="W_{1},...,W_{K}" /> on <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> nodes is </p><p>1. <em>X-secure</em> if any set of up to <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="X" class="latex" title="X" /> servers cannot determine anything about any <img src="https://s0.wp.com/latex.php?latex=W_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="W_i" class="latex" title="W_i" /> and</p><p>2. <em>T-private </em> if given a query from the user to retrieve some data element <img src="https://s0.wp.com/latex.php?latex=W_%7B%5Ctheta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="W_{\theta}" class="latex" title="W_{\theta}" />, any set of up to <img src="https://s0.wp.com/latex.php?latex=T&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="T" class="latex" title="T" /> users cannot determine the value of <img src="https://s0.wp.com/latex.php?latex=%5Ctheta&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\theta" class="latex" title="\theta" />.</p><cite>[Jia, Sun, and Jafar ’19]</cite></blockquote>



<p>Letting <img src="https://s0.wp.com/latex.php?latex=Q_%7B1%7D%5E%7B%5B%5Ctheta%5D%7D%2C...%2CQ_%7BN%7D%5E%7B%5B%5Ctheta%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="Q_{1}^{[\theta]},...,Q_{N}^{[\theta]}" class="latex" title="Q_{1}^{[\theta]},...,Q_{N}^{[\theta]}" /> be the set of queries sent to each node and <img src="https://s0.wp.com/latex.php?latex=S_1%2C...%2CS_N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_1,...,S_N" class="latex" title="S_1,...,S_N" /> be the information stored on each node  (all vectors of length L), we depict this as:</p>



<figure class="wp-block-image size-large is-resized"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig2.png?w=1024" alt="" width="452" class="wp-image-1581" height="223" /></figure>



<p>The information theoretic requirements of this system to be correct can be summarized as follows (using notation <img src="https://s0.wp.com/latex.php?latex=S_%7B%5B1%3AN%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_{[1:N]}" class="latex" title="S_{[1:N]}" /> for set <img src="https://s0.wp.com/latex.php?latex=S_1%2C...%2CS_N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="S_1,...,S_N" class="latex" title="S_1,...,S_N" />):</p>



<figure class="wp-block-table"><table><tbody><tr><td><strong>Property</strong></td><td><strong>Information Theoretic Requirement</strong></td></tr><tr><td>Data messages are size <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L" class="latex" title="L" /> bits</td><td><img src="https://s0.wp.com/latex.php?latex=H%28W_1%29%3DH%28W_2%29%3D....%3DH%28W_K%29+%3D+L&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="H(W_1)=H(W_2)=....=H(W_K) = L" class="latex" title="H(W_1)=H(W_2)=....=H(W_K) = L" /></td></tr><tr><td>Data messages are independent</td><td><img src="https://s0.wp.com/latex.php?latex=H%28W_1%2C...%2CW_K%29+%3D+KL&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="H(W_1,...,W_K) = KL" class="latex" title="H(W_1,...,W_K) = KL" /></td></tr><tr><td>Data can be determined from the stored information</td><td><img src="https://s0.wp.com/latex.php?latex=H%28W_1%2C....%2CW_K%29%7CS_%7B%5B1%3AN%5D%7D%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="H(W_1,....,W_K)|S_{[1:N]}) = 0" class="latex" title="H(W_1,....,W_K)|S_{[1:N]}) = 0" /></td></tr><tr><td>User has no prior knowledge of server data</td><td><img src="https://s0.wp.com/latex.php?latex=I%28S_%7B%5B1%3AN%5D%7D%3BQ%5E%7B%5B%5Ctheta%5D%7D_%7B%5B1%3AN%5D%7D%2C%5Ctheta%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="I(S_{[1:N]};Q^{[\theta]}_{[1:N]},\theta) = 0" class="latex" title="I(S_{[1:N]};Q^{[\theta]}_{[1:N]},\theta) = 0" /></td></tr><tr><td>X-Security</td><td><img src="https://s0.wp.com/latex.php?latex=I%28S_%7B%5Cmathcal%7BX%7D%7D%3BW_1%2C...%2CW_K%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="I(S_{\mathcal{X}};W_1,...,W_K) = 0" class="latex" title="I(S_{\mathcal{X}};W_1,...,W_K) = 0" />, <img src="https://s0.wp.com/latex.php?latex=%5Cforall+%5Cmathcal%7BX%7D%5Csubset+%5B1%3AN%5D%2C%7C%5Cmathcal%7BX%7D%7C%3DX&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\forall \mathcal{X}\subset [1:N],|\mathcal{X}|=X" class="latex" title="\forall \mathcal{X}\subset [1:N],|\mathcal{X}|=X" /></td></tr><tr><td> T-Privacy</td><td><img src="https://s0.wp.com/latex.php?latex=I%28Q_%7B%5Cmathcal%7BT%7D%7D%5E%7B%5B%5Ctheta%5D%7D%2CS_%7B%5Cmathcal%7BT%7D%7D%3B+%5Ctheta%29+%3D+0%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="I(Q_{\mathcal{T}}^{[\theta]},S_{\mathcal{T}}; \theta) = 0," class="latex" title="I(Q_{\mathcal{T}}^{[\theta]},S_{\mathcal{T}}; \theta) = 0," />  <img src="https://s0.wp.com/latex.php?latex=%5Cforall+%5Cmathcal%7BT%7D+%5Csubset+%5B1%3AN%5D%2C+%7C%5Cmathcal%7BT%7D%7C%3DT&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\forall \mathcal{T} \subset [1:N], |\mathcal{T}|=T" class="latex" title="\forall \mathcal{T} \subset [1:N], |\mathcal{T}|=T" /></td></tr><tr><td>Nodes answer only based on their data and received query </td><td><img src="https://s0.wp.com/latex.php?latex=H%28A_n%5E%7B%5B%5Ctheta%5D%7D%7C+Q_n%5E%7B%5B%5Ctheta%5D%7D%2CS_n%29+%3D0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="H(A_n^{[\theta]}| Q_n^{[\theta]},S_n) =0" class="latex" title="H(A_n^{[\theta]}| Q_n^{[\theta]},S_n) =0" /></td></tr><tr><td>User can decode desired message from answers</td><td><img src="https://s0.wp.com/latex.php?latex=H%28W_%7B%5Ctheta%7D+%7C+A_%7B%5B1%3AN%5D%7D%5E%7B%5B%5Ctheta%5D%7D%2CQ_%7B%5B1%3AN%5D%7D%5E%7B%5B%5Ctheta%5D%7D+%2C%5Ctheta%29+%3D+0&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="H(W_{\theta} | A_{[1:N]}^{[\theta]},Q_{[1:N]}^{[\theta]} ,\theta) = 0" class="latex" title="H(W_{\theta} | A_{[1:N]}^{[\theta]},Q_{[1:N]}^{[\theta]} ,\theta) = 0" /></td></tr></tbody></table></figure>



<p>Given these constraints, Jia et al. give bounds on the capacity of the system. Capacity is the maximum rate achievable, where rate is defined as bits requested by the worker (<img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L" class="latex" title="L" />, the length of a single message) divided by the number of bits downloaded by the worker. The bounds are in terms of the capacity of T-Private Information Retrieval, (which is the same as the above definition, with only requirement 2).</p>



<blockquote class="wp-block-quote"><p>If <img src="https://s0.wp.com/latex.php?latex=N+%5Cleq+X%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N \leq X+T" class="latex" title="N \leq X+T" /> then for arbitrary <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="K" class="latex" title="K" />, <img src="https://s0.wp.com/latex.php?latex=C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%3D+%5Cfrac%7BN-X%7D%7BN%7DC_%7BTPIR%7D%28N-X%2CK%2CT%29+%3D+%5Cfrac%7BN-X%7D%7BNK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="C_{XSTPIR}(N,K,X,T) = \frac{N-X}{N}C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}" class="latex" title="C_{XSTPIR}(N,K,X,T) = \frac{N-X}{N}C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}" />.</p><p><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%5Cleq+%5Cleft%28%5Cfrac%7BN-X%7D%7BN%7D%5Cright%29+C_%7BTPIR%7D%28N-X%2CK%2CT%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle C_{XSTPIR}(N,K,X,T) \leq \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T)" class="latex" title="\displaystyle C_{XSTPIR}(N,K,X,T) \leq \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T)" /></p><p> When <img src="https://s0.wp.com/latex.php?latex=N%5Cleq+X%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N\leq X+T" class="latex" title="N\leq X+T" />: <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle+C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%3D+%5Cleft%28%5Cfrac%7BN-X%7D%7BN%7D%5Cright%29+C_%7BTPIR%7D%28N-X%2CK%2CT%29+%3D+%5Cfrac%7BN-X%7D%7BNK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle C_{XSTPIR}(N,K,X,T) = \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}" class="latex" title="\displaystyle C_{XSTPIR}(N,K,X,T) = \left(\frac{N-X}{N}\right) C_{TPIR}(N-X,K,T) = \frac{N-X}{NK}" /> </p><p> <img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle%5Clim_%7BK%5Cto+%5Cinfty%7D+C_%7BXSTPIR%7D%28N%2CK%2CX%2CT%29+%3D+%5Clim_%7BK%5Cto+%5Cinfty%7D+%5Cleft%28%5Cfrac%7BN-K%7D%7BN%7D%5Cright%29+C_%7BTPIR%7D%28N-X%2CK%2CT%29+%3D%5Cbegin%7Bcases%7D%C2%A0+%C2%A01-%28%5Cfrac%7BX%2BT%7D%7BN%7D%29+%26+N%3EX%2BT++%5C%5C%C2%A0++0+%26+N%5Cleq+X%2BT+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle\lim_{K\to \infty} C_{XSTPIR}(N,K,X,T) = \lim_{K\to \infty} \left(\frac{N-K}{N}\right) C_{TPIR}(N-X,K,T) =\begin{cases}   1-(\frac{X+T}{N}) &amp; N&gt;X+T  \\   0 &amp; N\leq X+T \end{cases}" class="latex" title="\displaystyle\lim_{K\to \infty} C_{XSTPIR}(N,K,X,T) = \lim_{K\to \infty} \left(\frac{N-K}{N}\right) C_{TPIR}(N-X,K,T) =\begin{cases}   1-(\frac{X+T}{N}) &amp; N&gt;X+T  \\   0 &amp; N\leq X+T \end{cases}" /></p><cite>[Jia, Sun, and Jafar ’19]</cite></blockquote>



<p>Jia et al. give schemes that achieve these bounds while preserving the privacy and security constraints by introducing random noise vectors into how data is stored and queries are constructed. The general scheme for <img src="https://s0.wp.com/latex.php?latex=N%3EX%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N&gt;X+T" class="latex" title="N&gt;X+T" /> uses <em>cross subspace alignment</em>, which essentially chooses how to construct the stored information and the queries such that the added noise mostly “cancels out” when the master combines all the response from the servers. The scheme for <img src="https://s0.wp.com/latex.php?latex=N%5Cleq+X%2BT&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N\leq X+T" class="latex" title="N\leq X+T" /> is straightforward to explain, and demonstrates the idea of using error correcting codes that treat the random values as the message and the actual data as the “noise.”</p>



<p>For this scheme, the message length <img src="https://s0.wp.com/latex.php?latex=L&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L" class="latex" title="L" /> is set to <img src="https://s0.wp.com/latex.php?latex=N-X&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N-X" class="latex" title="N-X" /> (the number of nodes <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" />, minus the maximum number of colluding servers <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="X" class="latex" title="X" />). First, we generate <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="K" class="latex" title="K" /> random bit vectors of length <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="X" class="latex" title="X" />:</p>



<figure class="wp-block-image size-large is-resized"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig3.png?w=856" alt="" width="370" class="wp-image-1590" height="157" /></figure>



<p>Next, apply an <img src="https://s0.wp.com/latex.php?latex=%28N%2CX%29&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="(N,X)" class="latex" title="(N,X)" /> MDS code to <img src="https://s0.wp.com/latex.php?latex=Z_1%2C...%2CZ_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="Z_1,...,Z_K" class="latex" title="Z_1,...,Z_K" /> to get <img src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_1%2C..%2C%5Cbar%7BZ%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bar{Z}_1,..,\bar{Z}_K" class="latex" title="\bar{Z}_1,..,\bar{Z}_K" />, which are <img src="https://s0.wp.com/latex.php?latex=K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="K" class="latex" title="K" /> encoded vectors of length <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" />:</p>



<figure class="wp-block-image size-large"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig4.png?w=1024" alt="" class="wp-image-1591" /></figure>



<p>For our data <img src="https://s0.wp.com/latex.php?latex=W_1%2C...%2CW_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="W_1,...,W_K" class="latex" title="W_1,...,W_K" />, we pad each vector with zeros to get <img src="https://s0.wp.com/latex.php?latex=%5Cbar%7BW%7D_1%2C..%2C%5Cbar%7BW%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bar{W}_1,..,\bar{W}_K" class="latex" title="\bar{W}_1,..,\bar{W}_K" /> of length <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" />:</p>



<figure class="wp-block-image size-large"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig5.png?w=1024" alt="" class="wp-image-1592" /></figure>



<p>Now that the dimensions line up, we can add the two together and store each column <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n" class="latex" title="n" /> at the <img src="https://s0.wp.com/latex.php?latex=n%5E%7Bth%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="n^{th}" class="latex" title="n^{th}" /> node:</p>



<figure class="wp-block-image size-large"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig6.png?w=1024" alt="" class="wp-image-1593" /></figure>



<p>To access the data, the user downloads all <img src="https://s0.wp.com/latex.php?latex=NK&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="NK" class="latex" title="NK" /> bits. The length <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> string downloaded from  row <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i" class="latex" title="i" /> can be used to decode <img src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bar{Z}_i" class="latex" title="\bar{Z}_i" />: <img src="https://s0.wp.com/latex.php?latex=%5Cbar%7BW%7D_%7BL%2B1%7D%2C%5Cbar%7BW%7D_%7BL%2B2%7D%2C...%2C%5Cbar%7BW%7D_%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bar{W}_{L+1},\bar{W}_{L+2},...,\bar{W}_{N}" class="latex" title="\bar{W}_{L+1},\bar{W}_{L+2},...,\bar{W}_{N}" /> are all zero, so columns <img src="https://s0.wp.com/latex.php?latex=L%2B1+%3D+N-X%2B1&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="L+1 = N-X+1" class="latex" title="L+1 = N-X+1" /> through <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> have the values of <img src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_%7Bi%2CN-X%2B1%7D%2C...%2C%5Cbar%7BZ%7D_%7Bi%2CN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bar{Z}_{i,N-X+1},...,\bar{Z}_{i,N}" class="latex" title="\bar{Z}_{i,N-X+1},...,\bar{Z}_{i,N}" />. This gives the user <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="X" class="latex" title="X" /> values from the MDS code used on each row, so they can decode and get <img src="https://s0.wp.com/latex.php?latex=Z_1%2C...%2CZ_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="Z_1,...,Z_K" class="latex" title="Z_1,...,Z_K" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_%7B1%7D%2C...%2C%5Cbar%7BZ%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bar{Z}_{1},...,\bar{Z}_K" class="latex" title="\bar{Z}_{1},...,\bar{Z}_K" />. Then a subtraction from the downloaded data gives <img src="https://s0.wp.com/latex.php?latex=W_1%2C...%2CW_%7BK%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="W_1,...,W_{K}" class="latex" title="W_1,...,W_{K}" />. Because of the MDS property of the code used to get <img src="https://s0.wp.com/latex.php?latex=%5Cbar%7BZ%7D_1%2C...%2C%5Cbar%7BZ%7D_K&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bar{Z}_1,...,\bar{Z}_K" class="latex" title="\bar{Z}_1,...,\bar{Z}_K" />, this scheme is X-secure and because the user downloads all bits, it is T-private.</p>



<h2>Matrix Multiplication with Polynomial Codes</h2>



<p>We now move on to the task of matrix-matrix multiplication. The methods for secure and private distributed matrix multiplication we will discuss shortly are based on <em>polynomial codes</em>, used by [Yu, Maddah-Ali, Avestimehr ’17] for doing distributed matrix multiplications robust to stragglers. Suppose the master has matrices <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BA%7D%7D+%5Cin+%5Cmathbb%7BF%7D_q%5E%7Bm%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bf{A}} \in \mathbb{F}_q^{m\times n}" class="latex" title="{\bf{A}} \in \mathbb{F}_q^{m\times n}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BB%7D%7D+%5Cin+%5Cmathbb%7BF%7D_q%5E%7Bn+%5Ctimes+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bf{B}} \in \mathbb{F}_q^{n \times p}" class="latex" title="{\bf{B}} \in \mathbb{F}_q^{n \times p}" /> for some finite field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb%7BF%7D_q&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\mathbb{F}_q" class="latex" title="\mathbb{F}_q" />, and <img src="https://s0.wp.com/latex.php?latex=m%2Cn%2Cp+%5Cin+%5Cmathbb%7BZ%7D%5E%2B&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="m,n,p \in \mathbb{Z}^+" class="latex" title="m,n,p \in \mathbb{Z}^+" />. Assume <img src="https://s0.wp.com/latex.php?latex=m&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="m" class="latex" title="m" /> and <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="p" class="latex" title="p" /> are divisible by <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" />, so we can represent the matrices divided into <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> submatrices: </p>



<p class="has-text-align-center"><img src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BA%7D%7D%3D+%5Cbegin%7Bbmatrix%7DA_1%5C%5C+A_2+%5C%5C+%5Cvdots+%5C%5C+A_m%5Cend%7Bbmatrix%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bf{A}}= \begin{bmatrix}A_1\\ A_2 \\ \vdots \\ A_m\end{bmatrix}" class="latex" title="{\bf{A}}= \begin{bmatrix}A_1\\ A_2 \\ \vdots \\ A_m\end{bmatrix}" />               and        <img src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BB%7D%7D%3D+%5Cbegin%7Bbmatrix%7DB_1%26+B_2+%26+%5Cdots+%26B_n%5Cend%7Bbmatrix%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bf{B}}= \begin{bmatrix}B_1&amp; B_2 &amp; \dots &amp;B_n\end{bmatrix}" class="latex" title="{\bf{B}}= \begin{bmatrix}B_1&amp; B_2 &amp; \dots &amp;B_n\end{bmatrix}" /> </p>



<p>So to recover <img src="https://s0.wp.com/latex.php?latex=%5Cbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bf{AB}" class="latex" title="\bf{AB}" />, the master needs each entry of: </p>



<p><img src="https://s0.wp.com/latex.php?latex=%7B%5Cbf%7BAB%7D%7D+%3D+%5Cbegin%7Bbmatrix%7DA_1B_1+%26+A_1B_2+%26+%5Cdots+%26+A_1B_n%5C%5CA_2B_1+%26+A_2B_2+%26+%5Cdots+%26+A_2+B_n%5C%5C%5Cvdots+%26+%5Cvdots+%26%5Cvdots+%26%5Cvdots%5C%5CA_mB_1+%26A_mB_2+%26+%5Cdots%C2%A0+%26+A_mB_n+%5Cend%7Bbmatrix%7D.&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bf{AB}} = \begin{bmatrix}A_1B_1 &amp; A_1B_2 &amp; \dots &amp; A_1B_n\\A_2B_1 &amp; A_2B_2 &amp; \dots &amp; A_2 B_n\\\vdots &amp; \vdots &amp;\vdots &amp;\vdots\\A_mB_1 &amp;A_mB_2 &amp; \dots  &amp; A_mB_n \end{bmatrix}." class="latex" title="{\bf{AB}} = \begin{bmatrix}A_1B_1 &amp; A_1B_2 &amp; \dots &amp; A_1B_n\\A_2B_1 &amp; A_2B_2 &amp; \dots &amp; A_2 B_n\\\vdots &amp; \vdots &amp;\vdots &amp;\vdots\\A_mB_1 &amp;A_mB_2 &amp; \dots  &amp; A_mB_n \end{bmatrix}." /></p>



<p>The key idea of polynomial codes is to encode <img src="https://s0.wp.com/latex.php?latex=A_1%2C...%2CA_m&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A_1,...,A_m" class="latex" title="A_1,...,A_m" /> and <img src="https://s0.wp.com/latex.php?latex=B_1%2C...%2CB_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="B_1,...,B_n" class="latex" title="B_1,...,B_n" /> in polynomials <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{A}_i" class="latex" title="\tilde{A}_i" /> and <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BB%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{B}_i" class="latex" title="\tilde{B}_i" /> to be sent to the <img src="https://s0.wp.com/latex.php?latex=i%5E%7Bth%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i^{th}" class="latex" title="i^{th}" /> worker,  where they are multiplied and the result is returned. The goal of Yu et al. was to create robustness to stragglers, and so they add redundancy in this process so that not all workers need to return a result for the master to be able to determine <img src="https://s0.wp.com/latex.php?latex=%5Cbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bf{AB}" class="latex" title="\bf{AB}" />. In particular, only <img src="https://s0.wp.com/latex.php?latex=mn&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="mn" class="latex" title="mn" /> returned values are needed, so <img src="https://s0.wp.com/latex.php?latex=N-mn&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N-mn" class="latex" title="N-mn" /> servers can be slow or fail completely without hurting the computation. This method can be thought of as setting up the encodings of <img src="https://s0.wp.com/latex.php?latex=%5Cbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bf{A}" class="latex" title="\bf{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\bf{B}" class="latex" title="\bf{B}" /> so that the resulting multiplications <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BC%7D_1%3D%5Ctilde%7BA%7D_1%5Ctilde%7BB%7D_1%2C...%2C%5Ctilde%7BC%7D_N%3D%5Ctilde%7BA%7D_N%5Ctilde%7BB%7D_N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{C}_1=\tilde{A}_1\tilde{B}_1,...,\tilde{C}_N=\tilde{A}_N\tilde{B}_N" class="latex" title="\tilde{C}_1=\tilde{A}_1\tilde{B}_1,...,\tilde{C}_N=\tilde{A}_N\tilde{B}_N" /> are evaluations of a polynomial with coefficients  <img src="https://s0.wp.com/latex.php?latex=A_1B_1%2CA_1B_2%2C...%2CA_2B_1....%2CA_mB_n&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="A_1B_1,A_1B_2,...,A_2B_1....,A_mB_n" class="latex" title="A_1B_1,A_1B_2,...,A_2B_1....,A_mB_n" /> at <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> different points — equivalent to a Reed-Solomon code. </p>



<figure class="wp-block-image size-large"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig7.png?w=1024" alt="" class="wp-image-1603" /></figure>



<p>This idea is adapted by [Chang, Tandon ’18] to protect the data from colluding servers: noise is incorporated into the encodings such that the number of encoded matrices required to determine anything about the data is greater than the security threshold <img src="https://s0.wp.com/latex.php?latex=X+%3C+N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="X &lt; N" class="latex" title="X &lt; N" />. Since the master receives all <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> responses it is able to decode the result of <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{AB}" class="latex" title="\textbf{AB}" />, but no set of <img src="https://s0.wp.com/latex.php?latex=X&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="X" class="latex" title="X" /> nodes can decode <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{A}" class="latex" title="\textbf{A}" />, <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{B}" class="latex" title="\textbf{B}" />, or <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BAB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{AB}" class="latex" title="\textbf{AB}" />. Similarly, [Kim, Yang, Li ’19] adapts this idea to impose privacy on a matrix-matrix multiplication: workers are assumed to have a shared library <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D_i%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{{\textbf{B}}_i\}_{i=1}^M" class="latex" title="\{{\textbf{B}}_i\}_{i=1}^M" />, and the user would like to multiply <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctextbf%7BA%7D%7D%7B%5Ctextbf%7BB%7D%7D_%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\textbf{A}}{\textbf{B}}_{D}" class="latex" title="{\textbf{A}}{\textbf{B}}_{D}" /> for some <img src="https://s0.wp.com/latex.php?latex=D+%5Cin%5B1%3AM%5D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="D \in[1:M]" class="latex" title="D \in[1:M]" /> without revealing the value of <img src="https://s0.wp.com/latex.php?latex=D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="D" class="latex" title="D" /> to the workers. The workers encode the entire library such that when the  encoding is multiplied by an encoded input <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{A}" class="latex" title="\tilde{A}" /> from the master, the result is useful to the master in decoding <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctextbf%7BA%7D%7D%7B%5Ctextbf%7BB%7D%7D_D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\textbf{A}}{\textbf{B}}_D" class="latex" title="{\textbf{A}}{\textbf{B}}_D" />.</p>



<p>Chang and Tandon consider the following two privacy models, where up to <img src="https://s0.wp.com/latex.php?latex=%5Cell&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\ell" class="latex" title="\ell" /> servers may collude. The master also has <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="K^{(A)}" class="latex" title="K^{(A)}" /> (and in the second model, <img src="https://s0.wp.com/latex.php?latex=K%5E%7B%28B%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="K^{(B)}" class="latex" title="K^{(B)}" />), which are matrices of random values with the same dimensions as <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{A}" class="latex" title="\textbf{A}" /> (and <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{B}" class="latex" title="\textbf{B}" />). These are used in creating the encodings <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{A}_i" class="latex" title="\tilde{A}_i" /> (and <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BB%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{B}_i" class="latex" title="\tilde{B}_i" />).</p>



<p> <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{B}" class="latex" title="\textbf{B}" /> is public, <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{A}" class="latex" title="\textbf{A}" /> is private:</p>



<figure class="wp-block-image size-large"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig8.png?w=1024" alt="" class="wp-image-1604" /></figure>



<p>Both private:</p>



<figure class="wp-block-image size-large"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig9.png?w=1024" alt="" class="wp-image-1605" /></figure>



<p>Kim, Yang, and Lee take a similar approach of applying the method of polynomial code to <em>private</em> matrix multiplication. As before, there are <img src="https://s0.wp.com/latex.php?latex=N&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="N" class="latex" title="N" /> workers, but now the master wants to multiply <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{A}" class="latex" title="\textbf{A}" /> with some <img src="https://s0.wp.com/latex.php?latex=%7B%5Ctextbf%7BB%7D%7D_D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\textbf{B}}_D" class="latex" title="{\textbf{B}}_D" /> in shared library <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D_i%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{{\textbf{B}}_i\}_{i=1}^M" class="latex" title="\{{\textbf{B}}_i\}_{i=1}^M" /> (all the workers have the shared library). </p>



<p>Since the master isn’t itself encoding <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{{\textbf{B}}\}_{i=1}^M" class="latex" title="\{{\textbf{B}}\}_{i=1}^M" /> it has to tell the workers how to encode the library so that it can reconstruct the desired product. This is done by having the master tell the workers what values of <img src="https://s0.wp.com/latex.php?latex=%5Cvec%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\vec{y}" class="latex" title="\vec{y}" /> they should use to evaluate the polynomial that corresponds to encoding each library matrix. We denote the encoding of the library done by each worker <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="i" class="latex" title="i" /> as the multivariate polynomial <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="h" class="latex" title="h" /> which is evaluated at <img src="https://s0.wp.com/latex.php?latex=%5C%7B%7B%5Ctextbf%7BB%7D%7D%5C%7D_%7Bi%3D1%7D%5EM&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\{{\textbf{B}}\}_{i=1}^M" class="latex" title="\{{\textbf{B}}\}_{i=1}^M" /> and the node-specific vector <img src="https://s0.wp.com/latex.php?latex=y%5E%7B%28i%29%7D_%7B%5B1%3AM%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="y^{(i)}_{[1:M]}" class="latex" title="y^{(i)}_{[1:M]}" /> to get the node’s encoding, <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BB%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{B}_i" class="latex" title="\tilde{B}_i" />. The worker multiplies this with the encoding of <img src="https://s0.wp.com/latex.php?latex=%5Ctextbf%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\textbf{A}" class="latex" title="\textbf{A}" /> it receives, <img src="https://s0.wp.com/latex.php?latex=%5Ctilde%7BA%7D_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\tilde{A}_i" class="latex" title="\tilde{A}_i" /> and returns the resulting value <img src="https://s0.wp.com/latex.php?latex=Z_i&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="Z_i" class="latex" title="Z_i" />. All together, we get the following communication model: </p>



<figure class="wp-block-image size-large"><img src="https://theorydish.files.wordpress.com/2020/03/blog_fig10.png?w=1024" alt="" class="wp-image-1611" /></figure>



<h2>Conclusion</h2>



<p>As we’ve seen, coding techniques originally designed to add redundancy and protect against data loss can also be used to intentionally incorporate noise for data protection. In particular, this can be done when out-sourcing matrix multiplications, making it a useful technique in many data processing and machine learning applications.</p>



<p>References:</p>



<ul><li><a href="https://arxiv.org/pdf/1808.07457.pdf">Jia, Zhuqing, Hua Sun, and Syed Ali Jafar. “Cross Subspace Alignment and the Asymptotic Capacity of  X-Secure T-Private Information Retrieval.” <em>IEEE Transactions on Information Theory</em> 65.9 (2019): 5783-5798.</a></li><li><a href="http://papers.nips.cc/paper/7027-polynomial-codes-an-optimal-design-for-high-dimensional-coded-matrix-multiplication.pdf">Yu, Qian, Mohammad Maddah-Ali, and Salman Avestimehr. “Polynomial codes: an optimal design for high-dimensional coded matrix multiplication.” <em>Advances in Neural Information Processing Systems</em>. 2017.</a></li><li><a href="https://uweb.engr.arizona.edu/~wchang/Globecom-SecureMM-2018.pdf">Chang, Wei-Ting, and Ravi Tandon. “On the capacity of secure distributed matrix multiplication.” <em>2018 IEEE Global Communications Conference (GLOBECOM)</em>. IEEE, 2018.</a></li><li><a href="https://ieeexplore-ieee-org.stanford.idm.oclc.org/abstract/document/8832193">Kim, Minchul, Heecheol Yang, and Jungwoo Lee. “Private Coded Matrix Multiplication.” <em>IEEE Transactions on Information Forensics and Security</em> (2019).</a></li></ul>



<p></p></div>







<p class="date">
by Alex Porter <a href="https://theorydish.blog/2020/03/18/private-and-secure-distributed-matrix-multiplication/"><span class="datestr">at March 18, 2020 11:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=405">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/03/18/tcs-talk-wednesday-march-25-dana-moshkovitz-ut-austin/">TCS+ talk: Wednesday, March 25 — Dana Moshkovitz, UT Austin</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, March 25th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). <strong>Dana Moshkovitz</strong> from UT Austin will speak about “<em>Nearly Optimal Pseudorandomness From Hardness</em>” (abstract below).</p>
<p>You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. (The link will also be posted <a href="https://sites.google.com/site/plustcs/livetalk">on our website</a> on the day of the talk, so people who did not sign up will still be able to join, until the maximum capacity of 300 seats is reached.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: Existing proofs that deduce BPP=P from circuit lower bounds convert randomized algorithms into deterministic algorithms with a large polynomial slowdown. We convert randomized algorithms into deterministic ones with little slowdown. Specifically, assuming exponential lower bounds against randomized single-valued nondeterministic (SVN) circuits, we convert any randomized algorithm over inputs of length n running in time <img src="https://s0.wp.com/latex.php?latex=t%5Cgeq+n&amp;bg=fff&amp;fg=444444&amp;s=0" alt="t\geq n" class="latex" title="t\geq n" /> to a deterministic one running in time <img src="https://s0.wp.com/latex.php?latex=t%5E%7B2%2B%5Calpha%7D&amp;bg=fff&amp;fg=444444&amp;s=0" alt="t^{2+\alpha}" class="latex" title="t^{2+\alpha}" /> for an arbitrarily small constant <img src="https://s0.wp.com/latex.php?latex=%5Calpha+%3E+0&amp;bg=fff&amp;fg=444444&amp;s=0" alt="\alpha &gt; 0" class="latex" title="\alpha &gt; 0" />. Such a slowdown is nearly optimal, as, under complexity-theoretic assumptions, there are problems with an inherent quadratic derandomization slowdown. We also convert any randomized algorithm that errs rarely into a deterministic algorithm having a similar running time (with pre-processing). The latter derandomization result holds under weaker assumptions, of exponential lower bounds against deterministic SVN circuits. Our results follow from a new, nearly optimal, explicit pseudorandom generator. The construction uses, among other ideas, a new connection between pseudoentropy generators and locally list recoverable codes.</p></blockquote>
<p> </p></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/03/18/tcs-talk-wednesday-march-25-dana-moshkovitz-ut-austin/"><span class="datestr">at March 18, 2020 11:13 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
