<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wpcomstaging.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wpcomstaging.com" title="Gödel's Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://www.let-all.com/blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.let-all.com/blog" title="The Learning Theory Alliance Blog">The Learning Theory Alliance Blog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at June 10, 2021 04:39 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.05245">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.05245">Local Algorithms for Finding Densely Connected Clusters</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Peter Macgregor, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:He.html">He Sun</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05245">PDF</a><br /><b>Abstract: </b>Local graph clustering is an important algorithmic technique for analysing
massive graphs, and has been widely applied in many research fields of data
science. While the objective of most (local) graph clustering algorithms is to
find a vertex set of low conductance, there has been a sequence of recent
studies that highlight the importance of the inter-connection between clusters
when analysing real-world datasets. Following this line of research, in this
work we study local algorithms for finding a pair of vertex sets defined with
respect to their inter-connection and their relationship with the rest of the
graph. The key to our analysis is a new reduction technique that relates the
structure of multiple sets to a single vertex set in the reduced graph. Among
many potential applications, we show that our algorithms successfully recover
densely connected clusters in the Interstate Disputes Dataset and the US
Migration Dataset.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.05245"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.05161">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.05161">Interactive Modelling of Volumetric Musculoskeletal Anatomy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Abdrashitov:Rinat.html">Rinat Abdrashitov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bang:Seungbae.html">Seungbae Bang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Levin:David_I=_W=.html">David I. W. Levin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singh:Karan.html">Karan Singh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jacobson:Alec.html">Alec Jacobson</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05161">PDF</a><br /><b>Abstract: </b>We present a new approach for modelling musculoskeletal anatomy. Unlike
previous methods, we do not model individual muscle shapes as geometric
primitives (polygonal meshes, NURBS etc.). Instead, we adopt a volumetric
segmentation approach where every point in our volume is assigned to a muscle,
fat, or bone tissue. We provide an interactive modelling tool where the user
controls the segmentation via muscle curves and we visualize the muscle shapes
using volumetric rendering. Muscle curves enable intuitive yet powerful control
over the muscle shapes. This representation allows us to automatically handle
intersections between different tissues (musclemuscle, muscle-bone, and
muscle-skin) during the modelling and automates computation of muscle fiber
fields. We further introduce a novel algorithm for converting the volumetric
muscle representation into tetrahedral or surface geometry for use in
downstream tasks. Additionally, we introduce an interactive skeleton authoring
tool that allows the users to create skeletal anatomy starting from only a skin
mesh using a library of bone parts.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.05161"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.05145">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.05145">Relative Clustering Coefficient</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Touli:Elena_Farahbakhsh.html">Elena Farahbakhsh Touli</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lindberg:Oscar.html">Oscar Lindberg</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05145">PDF</a><br /><b>Abstract: </b>In this paper, we relatively extend the definition of global clustering
coefficient to another clustering, which we call it relative clustering
coefficient. The idea of this definition is to ignore the edges in the network
that the probability of having an edge is 0. Here, we also consider a model as
an example that using relative clustering coefficient is better than global
clustering coefficient for comparing networks and also checking the properties
of the networks.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.05145"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.05131">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.05131">Prior-Aware Distribution Estimation for Differential Privacy</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tao:Yuchao.html">Yuchao Tao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bater:Johes.html">Johes Bater</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Machanavajjhala:Ashwin.html">Ashwin Machanavajjhala</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05131">PDF</a><br /><b>Abstract: </b>Joint distribution estimation of a dataset under differential privacy is a
fundamental problem for many privacy-focused applications, such as query
answering, machine learning tasks and synthetic data generation. In this work,
we examine the joint distribution estimation problem given two data points: 1)
differentially private answers of a workload computed over private data and 2)
a prior empirical distribution from a public dataset. Our goal is to find a new
distribution such that estimating the workload using this distribution is as
accurate as the differentially private answer, and the relative entropy, or KL
divergence, of this distribution is minimized with respect to the prior
distribution. We propose an approach based on iterative optimization for
solving this problem. An application of our solution won second place in the
NIST 2020 Differential Privacy Temporal Map Challenge, Sprint 2.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.05131"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.05123">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.05123">Pattern-defeating Quicksort</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Orson R. L. Peters <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.05123">PDF</a><br /><b>Abstract: </b>A new solution for the Dutch national flag problem is proposed, requiring no
three-way comparisons, which gives quicksort a proper worst-case runtime of
$O(nk)$ for inputs with $k$ distinct elements. This is used together with other
known and novel techniques to construct a hybrid sort that is never
significantly slower than regular quicksort while speeding up drastically for
many input distributions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.05123"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04973">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04973">Reachability Problems for Transmission Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Shinwoo An, Eunjin Oh <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04973">PDF</a><br /><b>Abstract: </b>Let $P$ be a set of $n$ points in the plane where each point $p$ of $P$ is
associated with a radius $r_p&gt;0$.The transmission graph $G=(P,E)$ of $P$ is
defined as the directed graph such that $E$ contains an edge from $p$ to $q$ if
and only if $|pq|\leq r_p$ for any two points $p$ and $q$ in $P$, where $|pq|$
denotes the Euclidean distance between $p$ and $q$. In this paper, we present a
data structure of size $O(n^{5/3})$ such that for any two points in $P$, we can
check in $O(n^{2/3})$ time if there is a path in $G$ between the two points.
This is the first data structure for answering reachability queries whose
performance depends only on $n$ but not on the number of edges.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04973"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04941">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04941">Symmetric Spaces for Graph Embeddings: A Finsler-Riemannian Approach</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/L=oacute=pez:Federico.html">Federico López</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pozzetti:Beatrice.html">Beatrice Pozzetti</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Trettel:Steve.html">Steve Trettel</a>, Michael Strube, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wienhard:Anna.html">Anna Wienhard</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04941">PDF</a><br /><b>Abstract: </b>Learning faithful graph representations as sets of vertex embeddings has
become a fundamental intermediary step in a wide range of machine learning
applications. We propose the systematic use of symmetric spaces in
representation learning, a class encompassing many of the previously used
embedding targets. This enables us to introduce a new method, the use of
Finsler metrics integrated in a Riemannian optimization scheme, that better
adapts to dissimilar structures in the graph. We develop a tool to analyze the
embeddings and infer structural properties of the data sets. For
implementation, we choose Siegel spaces, a versatile family of symmetric
spaces. Our approach outperforms competitive baselines for graph reconstruction
tasks on various synthetic and real-world datasets. We further demonstrate its
applicability on two downstream tasks, recommender systems and node
classification.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04941"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04863">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04863">A Randomness Threshold for Online Bipartite Matching, via Lossless Online Rounding</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Buchbinder:Niv.html">Niv Buchbinder</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Naor:Joseph.html">Joseph Naor</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wajc:David.html">David Wajc</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04863">PDF</a><br /><b>Abstract: </b>Over three decades ago, Karp, Vazirani and Vazirani (STOC'90) introduced the
online bipartite matching problem. They observed that deterministic algorithms'
competitive ratio for this problem is no greater than $1/2$, and proved that
randomized algorithms can do better. A natural question thus arises: \emph{how
random is random}? i.e., how much randomness is needed to outperform
deterministic algorithms? The \textsc{ranking} algorithm of Karp et
al.~requires $\tilde{O}(n)$ random bits, which, ignoring polylog terms,
remained unimproved. On the other hand, Pena and Borodin (TCS'19) established a
lower bound of $(1-o(1))\log\log n$ random bits for any $1/2+\Omega(1)$
competitive ratio.
</p>
<p>We close this doubly-exponential gap, proving that, surprisingly, the lower
bound is tight. In fact, we prove a \emph{sharp threshold} of $(1\pm
o(1))\log\log n$ random bits for the randomness necessary and sufficient to
outperform deterministic algorithms for this problem, as well as its
vertex-weighted generalization. This implies the same threshold for the advice
complexity (nondeterminism) of these problems.
</p>
<p>Similar to recent breakthroughs in the online matching literature, for
edge-weighted matching (Fahrbach et al.~FOCS'20) and adwords (Huang et
al.~FOCS'20), our algorithms break the barrier of $1/2$ by randomizing matching
choices over two neighbors. Unlike these works, our approach does not rely on
the recently-introduced OCS machinery, nor the more established randomized
primal-dual method. Instead, our work revisits a highly-successful online
design technique, which was nonetheless under-utilized in the area of online
matching, namely (lossless) online rounding of fractional algorithms. While
this technique is known to be hopeless for online matching in general, we show
that it is nonetheless applicable to carefully designed fractional algorithms
with additional (non-convex) constraints.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04863"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04856">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04856">Strongly Sublinear Algorithms for Testing Pattern Freeness</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Newman:Ilan.html">Ilan Newman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Varma:Nithin.html">Nithin Varma</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04856">PDF</a><br /><b>Abstract: </b>Given a permutation $\pi:[k] \to [k]$, a function $f:[n] \to \mathbb{R}$
contains a $\pi$-appearance if there exists $1 \leq i_1 &lt; i_2 &lt; \dots &lt; i_k
\leq n$ such that for all $s,t \in [k]$, it holds that $f(i_s) &lt; f(i_t)$ if and
only if $\pi(s) &lt; \pi(t)$. The function is $\pi$-free if it has no
$\pi$-appearances. In this paper, we investigate the problem of testing whether
an input function $f$ is $\pi$-free or whether at least $\varepsilon n$ values
in $f$ need to be changed in order to make it $\pi$-free. This problem is a
generalization of the well-studied monotonicity testing and was first studied
by Newman, Rabinovich, Rajendraprasad and Sohler (Random Structures and
Algorithms 2019). We show that for all constants $k \in \mathbb{N}$,
$\varepsilon \in (0,1)$, and permutation $\pi:[k] \to [k]$, there is a
one-sided error $\varepsilon$-testing algorithm for $\pi$-freeness of functions
$f:[n] \to \mathbb{R}$ that makes $\tilde{O}(n^{o(1)})$ queries. We improve
significantly upon the previous best upper bound $O(n^{1 - 1/(k-1)})$ by
Ben-Eliezer and Canonne (SODA 2018). Our algorithm is adaptive, while the
earlier best upper bound is known to be tight for nonadaptive algorithms.
Hence, our results also show that adaptivity helps in testing freeness of order
patterns.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04856"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04819">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04819">Contextual Recommendations and Low-Regret Cutting-Plane Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gollapudi:Sreenivas.html">Sreenivas Gollapudi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruganesh:Guru.html">Guru Guruganesh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kollias:Kostas.html">Kostas Kollias</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leme:Renato_Paes.html">Renato Paes Leme</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schneider:Jon.html">Jon Schneider</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04819">PDF</a><br /><b>Abstract: </b>We consider the following variant of contextual linear bandits motivated by
routing applications in navigational engines and recommendation systems. We
wish to learn a hidden $d$-dimensional value $w^*$. Every round, we are
presented with a subset $\mathcal{X}_t \subseteq \mathbb{R}^d$ of possible
actions. If we choose (i.e. recommend to the user) action $x_t$, we obtain
utility $\langle x_t, w^* \rangle$ but only learn the identity of the best
action $\arg\max_{x \in \mathcal{X}_t} \langle x, w^* \rangle$. We design
algorithms for this problem which achieve regret $O(d\log T)$ and $\exp(O(d
\log d))$. To accomplish this, we design novel cutting-plane algorithms with
low "regret" -- the total distance between the true point $w^*$ and the
hyperplanes the separation oracle returns. We also consider the variant where
we are allowed to provide a list of several recommendations. In this variant,
we give an algorithm with $O(d^2 \log d)$ regret and list size
$\mathrm{poly}(d)$. Finally, we construct nearly tight algorithms for a weaker
variant of this problem where the learner only learns the identity of an action
that is better than the recommendation. Our results rely on new algorithmic
techniques in convex geometry (including a variant of Steiner's formula for the
centroid of a convex set) which may be of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04819"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04769">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04769">Submodular + Concave</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitra:Siddharth.html">Siddharth Mitra</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feldman:Moran.html">Moran Feldman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karbasi:Amin.html">Amin Karbasi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04769">PDF</a><br /><b>Abstract: </b>It has been well established that first order optimization methods can
converge to the maximal objective value of concave functions and provide
constant factor approximation guarantees for (non-convex/non-concave)
continuous submodular functions. In this work, we initiate the study of the
maximization of functions of the form $F(x) = G(x) +C(x)$ over a solvable
convex body $P$, where $G$ is a smooth DR-submodular function and $C$ is a
smooth concave function. This class of functions is a strict extension of both
concave and continuous DR-submodular functions for which no theoretical
guarantee is known. We provide a suite of Frank-Wolfe style algorithms, which,
depending on the nature of the objective function (i.e., if $G$ and $C$ are
monotone or not, and non-negative or not) and on the nature of the set $P$
(i.e., whether it is downward closed or not), provide $1-1/e$, $1/e$, or $1/2$
approximation guarantees. We then use our algorithms to get a framework to
smoothly interpolate between choosing a diverse set of elements from a given
ground set (corresponding to the mode of a determinantal point process) and
choosing a clustered set of elements (corresponding to the maxima of a suitable
concave function). Additionally, we apply our algorithms to various functions
in the above class (DR-submodular + concave) in both constrained and
unconstrained settings, and show that our algorithms consistently outperform
natural baselines.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04769"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04727">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04727">ParChain: A Framework for Parallel Hierarchical Agglomerative Clustering using Nearest-Neighbor Chain</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Shangdi.html">Shangdi Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Yiqiu.html">Yiqiu Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gu:Yan.html">Yan Gu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dhulipala:Laxman.html">Laxman Dhulipala</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shun:Julian.html">Julian Shun</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04727">PDF</a><br /><b>Abstract: </b>This paper studies the hierarchical clustering problem, where the goal is to
produce a dendrogram that represents clusters at varying scales of a data set.
We propose the ParChain framework for designing parallel hierarchical
agglomerative clustering (HAC) algorithms, and using the framework we obtain
novel parallel algorithms for the complete linkage, average linkage, and Ward's
linkage criteria. Compared to most previous parallel HAC algorithms, which
require quadratic memory, our new algorithms require only linear memory, and
are scalable to large data sets. ParChain is based on our parallelization of
the nearest-neighbor chain algorithm, and enables multiple clusters to be
merged on every round. We introduce two key optimizations that are critical for
efficiency: a range query optimization that reduces the number of distance
computations required when finding nearest neighbors of clusters, and a caching
optimization that stores a subset of previously computed distances, which are
likely to be reused.
</p>
<p>Experimentally, we show that our highly-optimized implementations using 48
cores with two-way hyper-threading achieve 5.8--110.1x speedup over
state-of-the-art parallel HAC algorithms and achieve 13.75--54.23x
self-relative speedup. Compared to state-of-the-art algorithms, our algorithms
require up to 237.3x less space. Our algorithms are able to scale to data set
sizes with tens of millions of points, which existing algorithms are not able
to handle.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04727"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04708">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04708">Boolean Matrix Factorization via Nonnegative Auxiliary Optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Truong:Duc_P=.html">Duc P. Truong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Skau:Erik.html">Erik Skau</a>, Derek Desantis, Boian Alexandrov <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04708">PDF</a><br /><b>Abstract: </b>A novel approach to Boolean matrix factorization (BMF) is presented. Instead
of solving the BMF problem directly, this approach solves a nonnegative
optimization problem with the constraint over an auxiliary matrix whose Boolean
structure is identical to the initial Boolean data. Then the solution of the
nonnegative auxiliary optimization problem is thresholded to provide a solution
for the BMF problem. We provide the proofs for the equivalencies of the two
solution spaces under the existence of an exact solution. Moreover, the
nonincreasing property of the algorithm is also proven. Experiments on
synthetic and real datasets are conducted to show the effectiveness and
complexity of the algorithm compared to other current methods.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04708"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04704">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04704">Pricing Ordered Items</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Shuchi Chawla, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rezvan:Rojin.html">Rojin Rezvan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Teng:Yifeng.html">Yifeng Teng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tzamos:Christos.html">Christos Tzamos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04704">PDF</a><br /><b>Abstract: </b>We study the revenue guarantees and approximability of item pricing. Recent
work shows that with $n$ heterogeneous items, item-pricing guarantees an
$O(\log n)$ approximation to the optimal revenue achievable by any (buy-many)
mechanism, even when buyers have arbitrarily combinatorial valuations. However,
finding good item prices is challenging -- it is known that even under
unit-demand valuations, it is NP-hard to find item prices that approximate the
revenue of the optimal item pricing better than $O(\sqrt{n})$.
</p>
<p>Our work provides a more fine-grained analysis of the revenue guarantees and
computational complexity in terms of the number of item ``categories'' which
may be significantly fewer than $n$. We assume the items are partitioned in $k$
categories so that items within a category are totally-ordered and a buyer's
value for a bundle depends only on the best item contained from every category.
</p>
<p>We show that item-pricing guarantees an $O(\log k)$ approximation to the
optimal (buy-many) revenue and provide a PTAS for computing the optimal
item-pricing when $k$ is constant. We also provide a matching lower bound
showing that the problem is (strongly) NP-hard even when $k=1$. Our results
naturally extend to the case where items are only partially ordered, in which
case the revenue guarantees and computational complexity depend on the width of
the partial ordering, i.e. the largest set for which no two items are
comparable.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04704"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04633">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04633">A Quantum Advantage for a Natural Streaming Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kallaugher:John.html">John Kallaugher</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04633">PDF</a><br /><b>Abstract: </b>Data streaming, in which a large dataset is received as a "stream" of
updates, is an important model in the study of space-bounded computation.
Starting with the work of Le Gall [SPAA `06], it has been known that quantum
streaming algorithms can use asymptotically less space than their classical
counterparts for certain problems. However, so far, all known examples of
quantum advantages in streaming are for problems that are either specially
constructed for that purpose, or require many streaming passes over the input.
</p>
<p>We give a one-pass quantum streaming algorithm for one of the best studied
problems in classical graph streaming - the triangle counting problem.
Almost-tight parametrized upper and lower bounds are known for this problem in
the classical setting; our algorithm uses polynomially less space in certain
regions of the parameter space, resolving a question posed by Jain and Nayak in
2014 on achieving quantum advantages for natural streaming problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04633"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04629">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04629">New Competitive Semi-online Scheduling Algorithms for Small Number of Identical Machines</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dwibedy:Debasis.html">Debasis Dwibedy</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mohanty:Rakesh.html">Rakesh Mohanty</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04629">PDF</a><br /><b>Abstract: </b>Design and analysis of constant competitive deterministic semi-online
algorithms for the multi-processor scheduling problem with small number of
identical machines have gained significant research interest in the last two
decades. In the semi-online scheduling problem for makespan minimization, we
are given a sequence of independent jobs one by one in order and upon arrival,
each job must be allocated to a machine with prior knowledge of some Extra
Piece of Information (EPI) about the future jobs. Researchers have designed
multiple variants of semi-online scheduling algorithms with constant
competitive ratios by considering one or more EPI. In this paper, we propose
four new variants of competitive deterministic semi-online algorithms for
smaller number of identical machines by considering two EPI such as Decr and
Sum. We obtain improved upper bound and lower bound results on the competitive
ratio for our proposed algorithms, which are comparable to the best known
results in the literature. In two identical machines setting with known Sum, we
show a tight bound of 1.33 on the competitive ratio by considering a sequence
of equal size jobs. In the same setting we achieve a lower bound of 1.04 and an
upper bound of 1.16 by considering Sum and a sequence of jobs arriving in order
of decreasing sizes. For three identical machines setting with known Decr and
Sum, we show a lower bound of 1.11 on the competitive ratio. In this setting,
we obtain an upper bound of 1.5 for scheduling a sequence of equal size jobs
and achieves an upper bound of 1.2 by considering a sequence of decreasing size
jobs. Further we develop an improved competitive algorithm with an upper bound
of 1.11 on the competitive ratio.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04629"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04486">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04486">Sketch-Based Streaming Anomaly Detection in Dynamic Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Siddharth Bhatia, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wadhwa:Mohit.html">Mohit Wadhwa</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yu:Philip_S=.html">Philip S. Yu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hooi:Bryan.html">Bryan Hooi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04486">PDF</a><br /><b>Abstract: </b>Given a stream of graph edges from a dynamic graph, how can we assign anomaly
scores to edges and subgraphs in an online manner, for the purpose of detecting
unusual behavior, using constant time and memory? For example, in intrusion
detection, existing work seeks to detect either anomalous edges or anomalous
subgraphs, but not both. In this paper, we first extend the count-min sketch
data structure to a higher-order sketch. This higher-order sketch has the
useful property of preserving the dense subgraph structure (dense subgraphs in
the input turn into dense submatrices in the data structure). We then propose
four online algorithms that utilize this enhanced data structure, which (a)
detect both edge and graph anomalies; (b) process each edge and graph in
constant memory and constant update time per newly arriving edge, and; (c)
outperform state-of-the-art baselines on four real-world datasets. Our method
is the first streaming approach that incorporates dense subgraph search to
detect graph anomalies in constant memory and time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04486"><span class="datestr">at June 10, 2021 12:22 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04365">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04365">robustBF: A High Accuracy and Memory Efficient 2D Bloom Filter</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patgiri:Ripon.html">Ripon Patgiri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04365">PDF</a><br /><b>Abstract: </b>Bloom Filter is an important probabilistic data structure to reduce memory
consumption for membership filters. It is applied in diverse domains such as
Computer Networking, Network Security and Privacy, IoT, Edge Computing, Cloud
Computing, Big Data, and Biometrics. But Bloom Filter has an issue of the false
positive probability. To address this issue, we propose a novel robust Bloom
Filter, robustBF for short. robustBF is a 2D Bloom Filter, capable of filtering
millions of data with high accuracy without compromising the performance. Our
proposed system is presented in two-fold. Firstly, we modify the murmur hash
function, and test all modified hash functions for improvements and select the
best-modified hash function experimentally. Secondly, we embed the modified
hash functions in 2D Bloom Filter. Our experimental results show that robustBF
is better than standard Bloom Filter and counting Bloom Filter in every aspect.
robustBF exhibits nearly zero false positive probability with more than
$10\times$ and $44\times$ lower memory consumption than standard Bloom filter
and counting Bloom Filter, respectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04365"><span class="datestr">at June 09, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04364">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04364">countBF: A General-purpose High Accuracy and Space Efficient Counting Bloom Filter</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nayak:Sabuzima.html">Sabuzima Nayak</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patgiri:Ripon.html">Ripon Patgiri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04364">PDF</a><br /><b>Abstract: </b>Bloom Filter is a probabilistic data structure for the membership query, and
it has been intensely experimented in various fields to reduce memory
consumption and enhance a system's performance. Bloom Filter is classified into
two key categories: counting Bloom Filter (CBF), and non-counting Bloom Filter.
CBF has a higher false positive probability than standard Bloom Filter (SBF),
i.e., CBF uses a higher memory footprint than SBF. But CBF can address the
issue of the false negative probability. Notably, SBF is also false negative
free, but it cannot support delete operations like CBF. To address these
issues, we present a novel counting Bloom Filter based on SBF and 2D Bloom
Filter, called countBF. countBF uses a modified murmur hash function to enhance
its various requirements, which is experimentally evaluated. Our experimental
results show that countBF uses $1.96\times$ and $7.85\times$ less memory than
SBF and CBF respectively, while preserving lower false positive probability and
execution time than both SBF and CBF. The overall accuracy of countBF is
$99.999921$, and it proves the superiority of countBF over SBF and CBF. Also,
we compare with other state-of-the-art counting Bloom Filters.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04364"><span class="datestr">at June 09, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04254">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04254">Coresets for Classification -- Simplified and Strengthened</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mai:Tung.html">Tung Mai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rao:Anup_B=.html">Anup B. Rao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Musco:Cameron.html">Cameron Musco</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04254">PDF</a><br /><b>Abstract: </b>We give relative error coresets for training linear classifiers with a broad
class of loss functions, including the logistic loss and hinge loss. Our
construction achieves $(1\pm \epsilon)$ relative error with $\tilde O(d \cdot
\mu_y(X)^2/\epsilon^2)$ points, where $\mu_y(X)$ is a natural complexity
measure of the data matrix $X \in \mathbb{R}^{n \times d}$ and label vector $y
\in \{-1,1\}^n$, introduced in by Munteanu et al. 2018. Our result is based on
subsampling data points with probabilities proportional to their $\ell_1$
$Lewis$ $weights$. It significantly improves on existing theoretical bounds and
performs well in practice, outperforming uniform subsampling along with other
importance sampling methods. Our sampling distribution does not depend on the
labels, so can be used for active learning. It also does not depend on the
specific loss function, so a single coreset can be used in multiple training
scenarios.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04254"><span class="datestr">at June 09, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04247">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04247">Private Counting from Anonymous Messages: Near-Optimal Accuracy with Vanishing Communication Overhead</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghazi:Badih.html">Badih Ghazi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Ravi.html">Ravi Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pagh:Rasmus.html">Rasmus Pagh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04247">PDF</a><br /><b>Abstract: </b>Differential privacy (DP) is a formal notion for quantifying the privacy loss
of algorithms. Algorithms in the central model of DP achieve high accuracy but
make the strongest trust assumptions whereas those in the local DP model make
the weakest trust assumptions but incur substantial accuracy loss. The shuffled
DP model (Bittau et al., 2017; Erlingsson et al., 2019; Cheu et al., 2019) has
recently emerged as a feasible middle ground between the central and local
models, providing stronger trust assumptions than the former while promising
higher accuracies than the latter. In this paper, we obtain practical
communication-efficient algorithms in the shuffled DP model for two basic
aggregation primitives used in machine learning: 1) binary summation, and 2)
histograms over a moderate number of buckets. Our algorithms achieve accuracy
that is arbitrarily close to that of central DP algorithms with an expected
communication per user essentially matching what is needed without any privacy
constraints! We demonstrate the practicality of our algorithms by
experimentally comparing their performance to several widely-used protocols
such as Randomized Response (Warner, 1965) and RAPPOR (Erlingsson et al.,
2014).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04247"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04224">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04224">Improved Online Correlated Selection</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Ruiquan Gao, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/He:Zhongtian.html">Zhongtian He</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Zhiyi.html">Zhiyi Huang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nie:Zipei.html">Zipei Nie</a>, Bijun Yuan, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhong:Yan.html">Yan Zhong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04224">PDF</a><br /><b>Abstract: </b>This paper studies the online correlated selection (OCS) problem introduced
by Fahrbach, Huang, Tao, and Zadimoghaddam (2020) to get the first
edge-weighted online bipartite matching algorithm that breaks the $0.5$
barrier. Suppose that we receive a pair of elements in each round and select
one of them. Can we select with negative correlation to be more effective than
independent random selections? Our contributions are threefold. For semi-OCS,
which considers the probability that an element remains unselected after
appearing in $k$ rounds, we give an optimal algorithm that minimizes this
probability for all $k$. It leads to $0.536$-competitive unweighted and
vertex-weighted online bipartite matching algorithms that randomize over only
two options in each round, improving the previous 0.508-competitive ratio by
Fahrbach et al. (2020). Further, we give the first multi-way semi-OCS that
allows an arbitrary number of elements with arbitrary masses in each round. As
an application, it rounds the Balance algorithm in unweighted and
vertex-weighted online bipartite matching to get a $0.593$-competitive ratio.
This is the first algorithm other than Ranking whose competitive ratio is
beyond the $0.5 + \epsilon$ regime. Finally, we study OCS, which further
considers the probability that an element is unselected in any subset of
rounds. We prove that the optimal "level of negative correlation" is between
$0.167$ and $0.25$, improving the previous bounds of $0.109$ and $1$ by
Fahrbach et al. (2020). Our OCS gives a $0.519$-competitive edge-weighted
online bipartite matching algorithm, improving the previous $0.508$-competitive
ratio by Fahrbach et al. (2020).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04224"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04191">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04191">FPT Algorithms to Compute the Elimination Distance to Bipartite Graphs and More</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jansen:Bart_M=_P=.html">Bart M. P. Jansen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kroon:Jari_J=_H=_de.html">Jari J. H. de Kroon</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04191">PDF</a><br /><b>Abstract: </b>For a hereditary graph class $\mathcal{H}$, the $\mathcal{H}$-elimination
distance of a graph $G$ is the minimum number of rounds needed to reduce $G$ to
a member of $\mathcal{H}$ by removing one vertex from each connected component
in each round. The $\mathcal{H}$-treewidth of a graph $G$ is the minimum, taken
over all vertex sets $X$ for which each connected component of $G - X$ belongs
to $\mathcal{H}$, of the treewidth of the graph obtained from $G$ by replacing
the neighborhood of each component of $G-X$ by a clique and then removing $V(G)
\setminus X$. These parameterizations recently attracted interest because they
are simultaneously smaller than the graph-complexity measures treedepth and
treewidth, respectively, and the vertex-deletion distance to $\mathcal{H}$. For
the class $\mathcal{H}$ of bipartite graphs, we present non-uniform
fixed-parameter tractable algorithms for testing whether the
$\mathcal{H}$-elimination distance or $\mathcal{H}$-treewidth of a graph is at
most $k$. Along the way, we also provide such algorithms for all graph classes
$\mathcal{H}$ defined by a finite set of forbidden induced subgraphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04191"><span class="datestr">at June 09, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04179">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04179">Deterministic $(1+\varepsilon)$-Approximate Maximum Matching with $\mathsf{poly}(1/\varepsilon)$ Passes in the Semi-Streaming Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fischer:Manuela.html">Manuela Fischer</a>, Slobodan Mitrović, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/u/Uitto:Jara.html">Jara Uitto</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04179">PDF</a><br /><b>Abstract: </b>We present a deterministic $(1+\varepsilon)$-approximate maximum matching
algorithm in $\mathsf{poly}(1/\varepsilon)$ passes in the semi-streaming model,
solving the long-standing open problem of breaking the exponential barrier in
the dependence on $1/\varepsilon$. Our algorithm exponentially improves on the
well-known randomized $(1/\varepsilon)^{O(1/\varepsilon)}$-pass algorithm from
the seminal work by McGregor [APPROX05], the recent deterministic algorithm by
Tirodkar with the same pass complexity [FSTTCS18], as well as the deterministic
$\log n \cdot \mathsf{poly}(1/\varepsilon)$-pass algorithm by Ahn and Guha
[ICALP11].
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04179"><span class="datestr">at June 09, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04105">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04105">Entropic Independence in High-Dimensional Expanders: Modified Log-Sobolev Inequalities for Fractionally Log-Concave Polynomials and the Ising Model</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Anari:Nima.html">Nima Anari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Vishesh.html">Vishesh Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koehler:Frederic.html">Frederic Koehler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pham:Huy_Tuan.html">Huy Tuan Pham</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vuong:Thuy=Duong.html">Thuy-Duong Vuong</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04105">PDF</a><br /><b>Abstract: </b>We introduce a notion called entropic independence for distributions $\mu$
defined on pure simplicial complexes, i.e., subsets of size $k$ of a ground set
of elements. Informally, we call a background measure $\mu$ entropically
independent if for any (possibly randomly chosen) set $S$, the relative entropy
of an element of $S$ drawn uniformly at random carries at most $O(1/k)$
fraction of the relative entropy of $S$, a constant multiple of its ``share of
entropy.'' Entropic independence is the natural analog of spectral
independence, another recently established notion, if one replaces variance by
entropy.
</p>
<p>In our main result, we show that $\mu$ is entropically independent exactly
when a transformed version of the generating polynomial of $\mu$ can be upper
bounded by its linear tangent, a property implied by concavity of the said
transformation. We further show that this concavity is equivalent to spectral
independence under arbitrary external fields, an assumption that also goes by
the name of fractional log-concavity. Our result can be seen as a new tool to
establish entropy contraction from the much simpler variance contraction
inequalities. A key differentiating feature of our result is that we make no
assumptions on marginals of $\mu$ or the degrees of the underlying graphical
model when $\mu$ is based on one. We leverage our results to derive tight
modified log-Sobolev inequalities for multi-step down-up walks on fractionally
log-concave distributions. As our main application, we establish the tight
mixing time of $O(n\log n)$ for Glauber dynamics on Ising models with
interaction matrix of operator norm smaller than $1$, improving upon the prior
quadratic dependence on $n$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04105"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04037">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04037">Online Algorithms for Network Robustness under Connectivity Constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Muthirayan:Deepan.html">Deepan Muthirayan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khargonekar:Pramod_P=.html">Pramod P. Khargonekar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04037">PDF</a><br /><b>Abstract: </b>In this paper, we present algorithms for designing networks that are robust
to node failures with minimal or limited number of links. We present algorithms
for both the static network setting and the dynamic network setting; setting
where new nodes can arrive in the future. For the static setting, we present
algorithms for constructing the optimal network in terms of the number of links
used for a given node size and the number of nodes that can fail. We then
consider the dynamic setting where it is disruptive to remove any of the older
links. For this setting, we present online algorithms for two cases: (i) when
the number of nodes that can fail remains constant and (ii) when only the
proportion of the nodes that can fail remains constant. We show that the
proposed algorithm for the first case saves nearly $3/4$th of the total
possible links at any point of time. We then present algorithms for various
levels of the fraction of the nodes that can fail and characterize their link
usage. We show that when $1/2$ the number of nodes can fail at any point of
time, the proposed algorithm saves nearly $1/2$ of the total possible links at
any point of time. We show that when the number of nodes that can fail is
limited to the fraction $1/(2m)$ ($m \in \mathbb{N}$), the proposed algorithm
saves nearly as much as $(1-1/2m)$ of the total possible links at any point of
time. We also show that when the number of nodes that can fail at any point of
time is $1/2$ of the number of nodes plus $n$, $n \in \mathbb{N}$, the number
of links saved by the proposed algorithm reduces only linearly in $n$. We
conjecture that the saving ratio achieved by the algorithms we present is
optimal for the dynamic setting.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04037"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.03969">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.03969">Chow-Liu++: Optimal Prediction-Centric Learning of Tree Ising Models</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Enric Boix-Adsera, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bresler:Guy.html">Guy Bresler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Koehler:Frederic.html">Frederic Koehler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.03969">PDF</a><br /><b>Abstract: </b>We consider the problem of learning a tree-structured Ising model from data,
such that subsequent predictions computed using the model are accurate.
Concretely, we aim to learn a model such that posteriors $P(X_i|X_S)$ for small
sets of variables $S$ are accurate. Since its introduction more than 50 years
ago, the Chow-Liu algorithm, which efficiently computes the maximum likelihood
tree, has been the benchmark algorithm for learning tree-structured graphical
models. A bound on the sample complexity of the Chow-Liu algorithm with respect
to the prediction-centric local total variation loss was shown in [BK19]. While
those results demonstrated that it is possible to learn a useful model even
when recovering the true underlying graph is impossible, their bound depends on
the maximum strength of interactions and thus does not achieve the
information-theoretic optimum. In this paper, we introduce a new algorithm that
carefully combines elements of the Chow-Liu algorithm with tree metric
reconstruction methods to efficiently and optimally learn tree Ising models
under a prediction-centric loss. Our algorithm is robust to model
misspecification and adversarial corruptions. In contrast, we show that the
celebrated Chow-Liu algorithm can be arbitrarily suboptimal.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.03969"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.03943">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.03943">Near-Optimal Dispersion on Arbitrary Anonymous Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kshemkalyani:Ajay_D=.html">Ajay D. Kshemkalyani</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Gokarna.html">Gokarna Sharma</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.03943">PDF</a><br /><b>Abstract: </b>Given an undirected, anonymous, port-labeled graph of $n$ memory-less nodes,
$m$ edges, and degree $\Delta$, we consider the problem of dispersing $k\leq n$
robots (or tokens) positioned initially arbitrarily on one or more nodes of the
graph to exactly $k$ different nodes of the graph, one on each node. The
objective is to simultaneously minimize time to achieve dispersion and memory
requirement at each robot. If all $k$ robots are positioned initially on a
single node, depth first search (DFS) traversal solves this problem in
$O(\min\{m,k\Delta\})$ time with $\Theta(\log(k+\Delta))$ bits at each robot.
However, if robots are positioned initially on multiple nodes, the best
previously known algorithm solves this problem in $O(\min\{m,k\Delta\}\cdot
\log \ell)$ time storing $\Theta(\log(k+\Delta))$ bits at each robot, where
$\ell\leq k/2$ is the number of multiplicity nodes in the initial
configuration. In this paper, we present a novel multi-source DFS traversal
algorithm solving this problem in $O(\min\{m,k\Delta\})$ time with
$\Theta(\log(k+\Delta))$ bits at each robot, improving the time bound of the
best previously known algorithm by $O(\log \ell)$ and matching asymptotically
the single-source DFS traversal bounds. This is the first algorithm for
dispersion that is optimal in both time and memory in arbitrary anonymous
graphs of constant degree, $\Delta=O(1)$. Furthermore, the result holds in both
synchronous and asynchronous settings.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.03943"><span class="datestr">at June 10, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/079">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/079">TR21-079 |  The zero-rate threshold for adversarial bit-deletions is less than 1/2 | 

	Venkatesan Guruswami, 

	Xiaoyu He, 

	Ray Li</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove that there exists an absolute constant $\delta&gt;0$ such any binary code $C\subset\{0,1\}^N$ tolerating $(1/2-\delta)N$ adversarial deletions must satisfy $|C|\le 2^{\poly\log N}$ and thus have rate asymptotically approaching $0$. This is the first constant fraction improvement over the trivial bound that codes tolerating $N/2$ adversarial deletions must have rate going to $0$ asymptotically.  Equivalently, we show that there exists absolute constants $A$ and $\delta&gt;0$ such that any set $C\subset\{0,1\}^N$ of $2^{\log^A N}$ binary strings must contain two strings $c$ and $c'$ whose longest common subsequence has length at least $(1/2+\delta)N$. As an immediate corollary, we show that $q$-ary codes tolerating a fraction $1-(1+2\delta)/q$ of adversarial deletions must also have rate approaching $0$.
 
Our techniques include string regularity arguments and a structural lemma that classifies binary strings by their oscillation patterns.  Leveraging these tools, we find in any large code two strings with similar oscillation patterns, which is exploited to find a long common subsequence.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/079"><span class="datestr">at June 09, 2021 04:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=21799">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/">To cheer you up in difficult times 26: Two real-life lectures yesterday at the Technion</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>After 16 months without lecturing to an audience in my same location, I gave yesterday two lectures at the Technion in front of a live audience (and some additional audience in remote locations). The main lecture was in <a href="https://comsoc2021.net.technion.ac.il/">COMSOC 2021,</a> an international conference on computational social choice,  and earlier I gave a guest lecture in Roy Meshulam’s class about simple polytopes. I also met many friends. </p>
<p><a href="https://reshef.net.technion.ac.il/">Reshef Meir</a> who organized (with Bill Zwicker) COMSOC 2021 wrote:</p>
<blockquote>
<div><span style="color: #993366;"><em>Hi all, </em></span></div>
<div><span style="color: #993366;"><em>today was beyond expectations – the first feeling of a real actual conference after almost a year and a half!  We had about 40 people attending, viewing posters, and listening to talks. I truly hope this will return to be a common scene and that we can all meet face to face soon.</em></span></div>
</blockquote>
<div> </div>
<p>In my COMSOC lecture I talked about some earlier ideas and results in my work on social choice, starting with my paper with Ariel Rubinstein and Rani Spiegler on rationalizing individual choice by multiple rationals, and my subsequent attempt to use learnability as a tool for understanding choices of economic agents. This led to interesting questions on social choice <a href="https://gilkalai.wordpress.com/2009/06/02/social-choice-preview/">that are discussed in this 2009 post.</a></p>
<p>In Roy’s course I explained <img src="https://s0.wp.com/latex.php?latex=h&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="h" class="latex" />-vectors of polytopes and the Dehn-Sommerville relations based on counting outdegrees of the graph of the polytope when we direct its edges based on a generic abstract objective function. I moved on to present a proof of Blind-Mani’s theorem that the graph of the polytope determines the full combinatorics. This proof is probably the one proof I presented the most and it is given in <a href="https://gilkalai.wordpress.com/2009/01/16/telling-a-simple-polytope-from-its-graph/">this 2009 post</a>.</p>
<p><img width="420" alt="sc1" src="https://gilkalai.files.wordpress.com/2021/06/sc1.png" class="alignnone size-full wp-image-21802" height="391" /></p>
<p><span style="color: #ff0000;">In my  COMSOC lecture I described how to fill the two question marks in the table above.</span></p>
<p><img width="420" alt="sc2" src="https://gilkalai.files.wordpress.com/2021/06/sc2.png" class="alignnone size-full wp-image-21803" height="391" /></p>


<p></p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2021/06/09/to-cheer-you-up-in-difficult-times-26-two-real-life-lectures-yesterday-at-the-technion/"><span class="datestr">at June 09, 2021 06:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1526">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1526">News for May 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>We hope you are all staying safe. With massive vaccination programs across the globe we hope you and your loved ones are getting back to what used to be normal. With that out of the way, let us circle back to Property Testing. This month was less sleepy as compared to the two preceding months and we saw six papers in total (two of them explore problems in quantum property testing). Without further ado, let us take a deeper dive.</p>



<p></p>



<p><strong>GSF-locality is not sufficient for proximity-oblivious testing</strong>, by Isolde Adler, Noleen Kohler, Pan Peng (<a href="https://arxiv.org/abs/2105.08490">arXiv</a>) The notion of proximity oblivious testers was made explicit in the seminal work of Goldreich and Ron in 2009 [GR09]. A proximity oblivious tester for a graph property is a constant query tester that rejects a graph with probability that monotonically increases with distance to the property. (<strong>Edit</strong>: <em>Correction</em>) A property is called proximity oblivious testable (or PO testable) if it has a one sided proximity oblivious tester. [GR09] gave a characterization of which properties \(\Pi\) are PO testable in the bounded degree model <em>if and only if</em> it is a “local” property of some kind which satisfies a certain non propagation condition. [GR09] conjectured that all such “local” properties satisfy this non propagation condition. This paper refutes the above conjecture from [GR09].</p>



<p></p>



<p>Coming up next. More action on triangle freeness.</p>



<p><strong>Testing Triangle Freeness in the General Model in Graphs with Arboricity \(O(\sqrt n)\)</strong>, by Reut Levi (<a href="https://arxiv.org/abs/2105.04809">arXiv</a>) PTReview readers are likely to be aware that triangle freeness has been a rich source of problems for developing new sublinear time algorithms. This paper considers the classic problem of testing triangle freeness in general graphs. In the dense case, algorithms with running time depending only on \(\varepsilon\) are known thanks to the work of Alon, Fischer, Krivelevich and Szegedy. In the bounded degree case, Goldreich and Ron gave testers with query complexity \(O(1/\varepsilon)\). This paper explores the problem in general graph case and proves an upper bound of \(O(\Gamma/d_{avg} + \Gamma)\) where \(\Gamma\) is the arboricity of the graph. The author also shows that this upperbound is tight for graphs with arboricity at most \(O(\sqrt n)\). Curiously enough, the algorithm does not take arboricity of the graph as an input and yet \(\Gamma\) (the arboricity) shows up in the upper and lower bounds.</p>



<p></p>



<p><strong>Testing Dynamic Environments: Back to Basics</strong>, by Yonatan Nakar and Dana Ron (<a href="https://arxiv.org/abs/2105.00759">arXiv</a>) Goldreich and Ron introduced the problem of testing “dynamic environments” in 2014. Here is the setup for this problem. You are given an environment that evolves according to a local rule.  Your goal is to query some of the states in the system at some point of time and determine if the system is evolving according to some fixed rule or is far from it. In this paper, the authors consider environments defined by elementary cellular automata which evolve according to threshold rules as one of the first steps towards understanding what makes a dynamic environment tested efficiently.  The main result proves the following: if your local rules satisfy some <em>conditions</em>, you can use a meta algorithm with query complexity \(poly(1/\varepsilon)\) which is non adaptive and has one sided error. And all the threshold rules indeed satisfy these <em>conditions</em> which means they can be tested efficiently. </p>



<p></p>



<p><strong>Identity testing under label mismatch</strong>, by Clement Canonne and Karl Wimmer (<a href="https://arxiv.org/abs/2105.01856">arXiv</a>) This paper considers a classic problem distribution testing with the following twist. Let \(q\) denote a distribution supported on \([n]\). You are given access to samples from another distribution \(p\) where \(p  = q \circ \pi\) where \(\pi\) is some unknown permutation. Thus, I relabel the data and I give you access to samples from the relabeled dataset. Under this promise, note that identity testing becomes a trivial problem if \(q\) is known to be uniform over \([n]\). The authors develop algorithms for testing and tolerant testing of distributions under this additional promise of \(p\) being a permutation of some known distribution \(q\). The main result shows as exponential gap between the sample complexity of testing and tolerant testing under this promise. In particular, identity testing under the promise of permutation has sample complexity \(\Theta(\log^2 n)\) whereas tolerant identity testing under this promise has sample complexity \(\Theta(n^{1-o(1)})\).</p>



<p></p>



<p><strong>Testing symmetry on quantum computers</strong>, by Margarite L. LaBorde and Mark M. Wilde (<a href="https://arxiv.org/abs/2105.12758">arXiv</a>) This paper develops algorithms which test symmetries of a quantum states and changes generated by quantum circuits. These tests additionally also quantify how symmetric these states (or channels) are. For testing what are called “Bose states” the paper presents efficient algorithms. The tests for other kinds of symmetry presented in the paper rely on some aid from a quantum prover.</p>



<p></p>



<p><strong>Quantum proofs of proximity</strong>, by Marcel Dall’Agnol, Tom Gur, Subhayan Roy Moulik, Justin Thaler (<a href="https://eccc.weizmann.ac.il/report/2021/068/">ECCC</a>) The sublinear time (quantum) computation model has been gathering momentum steadily over the past several years. This paper seeks to understand the power of \({\sf QMA}\) proofs of proximity for property testing (recall \({\sf QMA}\) is the quantum analogue of \({\sf NP}\)). On the algorithmic front, the paper develops sufficient conditions for properties to admit efficient \({\sf QMA}\) proofs of proximity. On the complexity front, the paper demonstrates a property which admits  an efficient \({\sf QMA}\) proof but does not admit a \({\sf MA}\) or an interactive proof of proximity.</p></div>







<p class="date">
by Akash <a href="https://ptreview.sublinear.info/?p=1526"><span class="datestr">at June 09, 2021 05:31 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04332">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04332">Progressive Spatio-Temporal Bilinear Network with Monte Carlo Dropout for Landmark-based Facial Expression Recognition with Uncertainty Estimation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heidari:Negar.html">Negar Heidari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Iosifidis:Alexandros.html">Alexandros Iosifidis</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04332">PDF</a><br /><b>Abstract: </b>Deep neural networks have been widely used for feature learning in facial
expression recognition systems. However, small datasets and large intra-class
variability can lead to overfitting. In this paper, we propose a method which
learns an optimized compact network topology for real-time facial expression
recognition utilizing localized facial landmark features. Our method employs a
spatio-temporal bilinear layer as backbone to capture the motion of facial
landmarks during the execution of a facial expression effectively. Besides, it
takes advantage of Monte Carlo Dropout to capture the model's uncertainty which
is of great importance to analyze and treat uncertain cases. The performance of
our method is evaluated on three widely used datasets and it is comparable to
that of video-based state-of-the-art methods while it has much less complexity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04332"><span class="datestr">at June 09, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04299">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04299">A direct product theorem for quantum communication complexity with applications to device-independent QKD</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Jain:Rahul.html">Rahul Jain</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kundu:Srijita.html">Srijita Kundu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04299">PDF</a><br /><b>Abstract: </b>We give a direct product theorem for the entanglement-assisted interactive
quantum communication complexity of an $l$-player predicate $\mathsf{V}$. In
particular we show that for a distribution $p$ that is product across the input
sets of the $l$ players, the success probability of any entanglement-assisted
quantum communication protocol for computing $n$ copies of $\mathsf{V}$, whose
communication is $o(\log(\mathrm{eff}^*(\mathsf{V},p))\cdot n)$, goes down
exponentially in $n$. Here $\mathrm{eff}^*(\mathsf{V}, p)$ is a distributional
version of the quantum efficiency or partition bound introduced by Laplante,
Lerays and Roland (2014), which is a lower bound on the distributional quantum
communication complexity of computing a single copy of $\mathsf{V}$ with
respect to $p$.
</p>
<p>As an application of our result, we show that it is possible to do
device-independent quantum key distribution (DIQKD) without the assumption that
devices do not leak any information after inputs are provided to them. We
analyze the DIQKD protocol given by Jain, Miller and Shi (2017), and show that
when the protocol is carried out with devices that are compatible with $n$
copies of the Magic Square game, it is possible to extract $\Omega(n)$ bits of
key from it, even in the presence of $O(n)$ bits of leakage. Our security proof
is parallel, i.e., the honest parties can enter all their inputs into their
devices at once, and works for a leakage model that is arbitrarily interactive,
i.e., the devices of the honest parties Alice and Bob can exchange information
with each other and with the eavesdropper Eve in any number of rounds, as long
as the total number of bits or qubits communicated is bounded.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04299"><span class="datestr">at June 09, 2021 10:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2106.04086">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2106.04086">Complexity classification of counting graph homomorphisms modulo a prime number</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bulatov:Andrei_A=.html">Andrei A. Bulatov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kazeminia:Amirhossein.html">Amirhossein Kazeminia</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2106.04086">PDF</a><br /><b>Abstract: </b>Counting graph homomorphisms and its generalizations such as the Counting
Constraint Satisfaction Problem (CSP), its variations, and counting problems in
general have been intensively studied since the pioneering work of Valiant.
While the complexity of exact counting of graph homomorphisms (Dyer and
Greenhill, 2000) and the counting CSP (Bulatov, 2013, and Dyer and Richerby,
2013) is well understood, counting modulo some natural number has attracted
considerable interest as well. In their 2015 paper Faben and Jerrum suggested a
conjecture stating that counting homomorphisms to a fixed graph H modulo a
prime number is hard whenever it is hard to count exactly, unless H has
automorphisms of certain kind. In this paper we confirm this conjecture. As a
part of this investigation we develop techniques that widen the spectrum of
reductions available for modular counting and apply to the general CSP rather
than being limited to graph homomorphisms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2106.04086"><span class="datestr">at June 09, 2021 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5539">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5539">More quantum computing popularization!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>I now have a feature article up at <em>Quanta</em> magazine, entitled <a href="https://www.quantamagazine.org/why-is-quantum-computing-so-hard-to-explain-20210608/">“What Makes Quantum Computing So Hard To Explain?”</a>  I.e., why do journalists, investors, etc. so consistently get central points wrong, even after the subject has been in public consciousness for more than 25 years?  Perhaps unsurprisingly, I found it hard to discuss that meta-level question, as <em>Quanta</em>‘s editors asked me to do, without also engaging in the object-level task of actually explaining QC.  For regular <em>Shtetl-Optimized</em> readers, there will be nothing new here, but I’m happy with how the piece turned out.</p>



<p>Accompanying the <em>Quanta</em> piece is a <a href="https://www.youtube.com/watch?v=jHoEjvuPoB8&amp;t=6s">10-minute YouTube explainer on quantum computing</a>, which (besides snazzy graphics) features interviews with me, John Preskill, and Dorit Aharonov.</p>



<p>On a different note, my colleague <a href="https://www.markwilde.com/">Mark Wilde</a> has recorded a <a href="https://soundcloud.com/mark-m-wilde/quantum-computer">punk-rock song about BosonSampling</a>.  I can honestly report that it’s some of the finest boson-themed music I’ve heard in years.  It includes the following lyrics:</p>



<blockquote class="wp-block-quote"><p>Quantum computer, Ain’t no loser<br />Quantum computer, Quantum computer</p><p>People out on the streets<br />They don’t know what it is<br />They think it finds the cliques<br />Or finds graph colorings<br />But it don’t solve anything<br />Said it don’t solve anything<br />Bosonic slot machine<br />My lil’ photonic dream</p></blockquote>



<p>Speaking of BosonSampling, A. S. Popova and A. N. Rubtsov, of the Skolkovo Institute in Moscow, have a new preprint entitled <a href="https://arxiv.org/abs/2106.01445">Cracking the Quantum Advantage threshold for Gaussian Boson Sampling</a>.  In it, they claim to give an efficient classical algorithm to simulate noisy GBS experiments, like the <a href="https://www.scottaaronson.com/blog/?p=5159">one six months ago</a> from USTC in China.  I’m still unsure how well this scales from 30-40 photons up to 50-70 photons; which imperfections of the USTC experiment are primarily being taken advantage of (photon losses?); and how this relates to the earlier proposed classical algorithms for simulating noisy BosonSampling, like the one by <a href="https://arxiv.org/abs/1409.3093">Kalai and Kindler</a>.  Anyone with any insight is welcome to share!</p>



<p>OK, one last announcement: the Simons Institute for the Theory of Computing, in Berkeley, has a new online lecture series called <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">“Breakthroughs,”</a> which many readers of this blog might want to check out.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5539"><span class="datestr">at June 08, 2021 08:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-7554871212591440842">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2021/06/machlne-learning-for-algorithms.html">Machine Learning for Algorithms Workshop (July 13-14)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>We're having an online workshop on "Machine Learning for Algorithms" on July 13-14, with a great group of speakers.  Announcement below, link at <a href="https://fodsi.us/ml4a.html">https://fodsi.us/ml4a.html</a>, free registration (but please register in advance)!</p><div style="font-size: small;" class="gmail_default">In recent years there has been increasing interest in using machine learning to improve the performance of classical algorithms in computer science, by fine-tuning their behavior to adapt to the properties of the input distribution. This "data-driven" or "learning-based" approach to algorithm design has the potential to significantly improve the efficiency of some of the most widely used algorithms. For example, they have been used to design better data structures, online algorithms, streaming and sketching algorithms, market mechanisms and algorithms for combinatorial optimization, similarity search and inverse problems.  This virtual workshop will feature talks from experts at the forefront of this exciting area.<br /><br />The workshop is organized by Foundations of Data Science Institute (FODSI), a project supported by the NSF TRIPODS program (see fodsi.us). To attend, please register at    <br /> <br /><a href="https://fodsi.us/ml4a.html">https://fodsi.us/ml4a.html</a>  </div></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2021/06/machlne-learning-for-algorithms.html"><span class="datestr">at June 08, 2021 07:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/078">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/078">TR21-078 |  A direct product theorem for quantum communication complexity with applications to device-independent QKD | 

	Rahul  Jain, 

	Srijita Kundu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give a direct product theorem for the entanglement-assisted interactive quantum communication complexity of an $l$-player predicate $V$. In particular we show that for a distribution $p$ that is product across the input sets of the $l$ players, the success probability of any entanglement-assisted quantum communication protocol for computing $n$ copies of $V$, whose communication is $o(\log(\mathrm{eff}^*(V,p))\cdot n)$, goes down exponentially in $n$. Here $\mathrm{eff}^*(V, p)$ is a distributional version of the quantum efficiency or partition bound introduced by Laplante, Lerays and Roland (2014), which is a lower bound on the distributional quantum communication complexity of computing a single copy of $V$ with respect to $p$.
  As an application of our result, we show that it is possible to do device-independent quantum key distribution (DIQKD) without the assumption that devices do not leak any information after inputs are provided to them. We analyze the DIQKD protocol given by Jain, Miller and Shi (2017), and show that when the protocol is carried out with devices that are compatible with $n$ copies of the Magic Square game, it is possible to extract $\Omega(n)$ bits of key from it, even in the presence of $O(n)$ bits of leakage. Our security proof is parallel, i.e., the honest parties can enter all their inputs into their devices at once, and works for a leakage model that is arbitrarily interactive, i.e., the devices of the honest parties Alice and Bob can exchange information with each other and with the eavesdropper Eve in any number of rounds, as long as the total number of bits or qubits communicated is bounded.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/078"><span class="datestr">at June 08, 2021 12:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://gradientscience.org/3db-light/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/madry.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://gradientscience.org/3db-light/">3DB: A Framework for Debugging Vision Models</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a style="float: left; width: 45%; margin-bottom: 0;" href="https://arxiv.org/abs/2106.03805" class="bbutton">
<i class="fas fa-file-pdf"></i>
    Paper
</a>
<a style="float: left; width: 45%; margin-bottom: 0;" href="https://github.com/3db/3db/" class="bbutton">
<i class="fab fa-github"></i>
   Project Repo
</a>
<a style="float: left; width: 45%;" href="https://3db.github.io/3db/usage/quickstart.html" class="bbutton">
<i class="fas fa-file-alt"></i>
   Documentation and Guides
</a> 
<a style="float: left; width: 45%;" href="https://github.com/3db/blog_demo/" class="bbutton">
<i class="fab fa-github"></i>
   Blog Demo
</a> 
<br /></p>

<p><i>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, in collaboration with Microsoft Research, we introduce
3DB: an extendable, unified framework for debugging and analyzing vision models
using photorealistic simulation. We’re releasing 3DB as a package, accompanied
by extensive API documentation, guides, and demos.</i></p>

<p><em>Note: You are now viewing the Javascript-free/lightweight version of this
post—to see the full version (with interactive plots, diagrams, and models!),
click <a href="https://gradientscience.org/3db/">here</a></em></p>

<p>Identifying failure modes and biases in vision models is a rapidly
emerging challenge in machine learning. In high-stakes
applications, simply deploying models and collecting failures that arise in
the wild is often difficult, expensive, and irresponsible. To this end, a
recent line of work in vision focuses on identifying model failure
modes via in-depth analyses of <a href="https://arxiv.org/abs/1712.02779">image transformations</a> and 
<a href="https://arxiv.org/abs/1903.12261">corruptions</a>, <a href="https://objectnet.dev">object orientations</a>,
<a href="https://gradientscience.org/background/">backgrounds</a>, or <a href="https://arxiv.org/abs/1811.12231v2">shape-texture conflicts</a>. These studies 
(and other similarly important ones) reveal a variety of patterns of
performance degradation in vision models. Still, performing each such study
requires time, developing (often complex)
toolingFor <a href="https://gradientscience.org/background/">our study of image backgrounds</a>, for example, we used a
combination of bounding boxes and classical computer vision tools to crop out
image backgrounds. We then had to manually filter out the images for which
the tools failed. Even for the images where the toolkit succeeded, there
remained inevitable cropping artifacts., and a willingness to settle for less than perfect simulations of each
potential failure mode. Our question is: can we support reliable discovery of model failures in a systematic,
automated, and unified way?</p>

<h2 id="3db-a-rendering-based-debugging-platform">3DB: A Rendering-based Debugging Platform</h2>

<p><img src="https://gradientscience.org/assets/3db/3db_headline.png" alt="A sampling of the analyses enabled by 3DB." class="bigimg" /></p>
<div style="margin-top: 0;" class="caption">
A sampling of the analyses enabled by 3DB.
</div>

<p>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, we try to make progress on this question and propose
3DB, a platform for automatically identifying and analyzing the failure modes
of computer vision models using 3D rendering. 3DB aims to allow users to go
from a testable, robustness-based hypothesis to concrete, photorealistic
experimental evidence with minimal time and effort.</p>

<p>The platform revolves around the modular workflow pictured below. First,
users specify a set of 3D objects and environments, as well as a set of 3D
(or 2D) transformations called controls that determine the space of
admissible object-environment configurations. 3DB then renders a myriad of
admissible scenes and feeds them through the user’s computer vision model of
choice. The user can finally stratify, aggregate, or otherwise analyze the
results either by reading the outputted JSON, or through the pre-packaged
dashboard.</p>

<p><img src="https://gradientscience.org/assets/3db/workflow.png" alt="An illustration of the 3DB workflow." class="bigimg" /></p>

<p>3DB easily adapts to a variety of use cases: in particular, users can
modify and swap out any part of this pipeline (e.g., the renderer, the
logger, the model type, or the controls) for their own custom-written
components, without needing to modify any of the 3DB codebase. We’ve compiled <a href="https://3db.github.io/3db/">guides</a>,
extensive <a href="https://3db.github.io/3db/api_doc.html">API documentation</a>, and a
<a href="https://github.com/3db/demo">full demo</a> showing how 3DB streamlines model debugging.</p>

<p><strong>In fact, this blog post will double as another demo! We’ll present the (short) code
necessary to reproduce every plot in the post below using 3DB. You can download 
the aggregated code for this blog post <a href="https://github.com/3db/blog_demo">here</a>.</strong></p>

<p><em>To set up, follow the steps below—then, in the remainder of this post, press
“Show/hide code and instructions” to see the steps necessary to reproduce each
experiment below.</em></p>
<div class="code-container">
  <input id="general-tab1" type="radio" checked="" name="general-tab" class="tab1" />
  <label for="general-tab1"><i class="fa fa-gear"></i>  Setup</label>
  <input id="general-tab2" type="radio" name="general-tab" class="tab2" />
  <label for="general-tab2"><i class="fa fa-code"></i>  Config (base.yaml)</label>
  <div class="line"></div>
  <div class="content-container">
<div class="content c1">

<ol class="instructions">
<li>Clone the  <a href="https://github.com/3db/blog_demo">blog demo <i class="fab fa-github"></i></a> repo</li>
<li>Run <pre>cd blog_demo</pre>, then <pre>bash setup.sh</pre> (assumes
<pre>unzip</pre> is installed) to download a large Blender environment, then
<pre>cd ../</pre></li>
<li>Install 3DB: <pre>curl -L https://git.io/Js8eT | bash /dev/stdin threedb</pre></li>
<li>Run <pre>conda activate threedb</pre></li>
<li>Our experiments below will need a <pre>BLENDER_DATA</pre> folder that contains two
subfolders: <pre>blender_models/</pre> containing 3D models (<pre>.blend</pre> files with a single
object whose name matches the filename), and <pre>blender_environments/</pre>
containing environments. We will provide you with these later</li> 
<li>Separately, make a file called <pre>base.yaml</pre> and paste in the configuration from the next pane.</li>
</ol>

</div>
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models'
  label_map: 'blog_demo/resources/imagenet_mapping.json'
  class: 'resnet18'
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.classification'
  args:
    classmap_path: 'blog_demo/resources/ycb_to_IN.json'
    topk: 1
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
policy:
  module: "threedb.policies.random_search"
  samples: 5
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"

</code></pre></div>
 </div>
</div>

<h2 id="using-3db">Using 3DB</h2>

<p>Prior works have already used 3D rendering (to great effect) to study biases
of machine learning models, including pose and context-based biases. Our goal
is not to propose a specific 3D-rendering based analysis, but
rather to provide an easy-to-use, highly extendable framework that unifies
prior analyses (both 3D and 2D) while enabling users to (a) conduct a host of
new analyses with the same ease and with realistic results; and (b)
effortlessly <em>compose</em> different factors of variation to understand their
interplay.</p>

<p>We’ll dedicate the rest of this post to illustrating how one
might actually use 3DB in practice, focusing on a single example 3D
model3DB works with any 3D model, and we refer the reader to 
<a href="https://arxiv.org/abs/2106.03805">our paper</a> for more examples and details.:</p>

<p style="text-align: center;">
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_1.png" style="display: inline; width: 18%;" />
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_2.png" style="display: inline; width: 18%;" />
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_3.png" style="display: inline; width: 18%;" />
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_4.png" style="display: inline; width: 18%;" />
<img src="https://gradientscience.org/assets/3db/plain_mug/plain_mug_5.png" style="display: inline; width: 18%;" />
</p>
<div style="margin-top: 0px; margin-bottom: 15px;" class="caption">
    The 3D mug model that we'll be using throughout this post.
</div>

<p>In what follows, we will walk through example applications of 3DB to discover biases of
ML models (some previously documented, others not). For the sake of brevity,
we’ll highlight just a few of these (re-)discoveries—to see more, check out
the <a href="https://arxiv.org/abs/2106.03805">paper</a>. We’ll then demonstrate that the discoveries of 3DB
transfer pretty reliably to the real world!</p>

<p>Our experiments will all operate on an ImageNet-pretrained
ResNet-18The classifier has a ~70% validation-set
accuracy. that has 42% accuracy on images from the
“coffee mug” ImageNet subclass. While we only study classification in this blog post,
3DB also supports object detection and can be easily extended to support other
image-based tasks, such as semantic segmentation, too.</p>

<h2 id="image-background-sensitivity">Image Background Sensitivity</h2>

<p>In one of our <a href="https://gradientscience.org/background/">previous posts</a>,
we continued a long line of prior work (see, e.g.,
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">here</a>, <a href="https://arxiv.org/abs/1611.06596">here</a>, <a href="https://arxiv.org/abs/1911.08731">here</a>, etc.) showing that models can be
over-reliant on image backgrounds, and demonstrated that they are easily
broken by adversarially chosen backgrounds. To accomplish this, our prior
analysis used classical computer vision tools to separate foregrounds from
backgrounds, then pasted foregrounds from one image onto backgrounds from
another. This process was slow and required extensive quality control to
ensure that backgrounds and foregrounds were being extracted properly—and
even when they were, a few artifacts remained:</p>

<div style="margin-bottom: 15px; overflow: hidden; text-align: center;">
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/1.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/2.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/3.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/4.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/5.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/6.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
</div>

<p>3DB lets us reproduce these findings effortlessly and without introducing
such artifacts. To demonstrate this, we use 3DB to render our mug 3D model on
hundreds of HDRI backgrounds, resulting in images such as:</p>

<div style="margin-bottom: 15px; overflow: hidden;">
    
        <img src="https://gradientscience.org/assets/3db/background-renders/1.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/2.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/3.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/4.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/5.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/6.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/7.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/8.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/9.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/10.png" style="float: right; width: 20%;" />
    
</div>

<p>We then analyze the performance of a pretrained ResNet-18Recall that this model
obtains 42% accuracy on the corresponding "coffee mug" ImageNet class subset.on these images. We
find that the performance of the classifier varies significantly across
backgrounds, and that accuracy correlates with a crude measure of
“background simplicity” (the JPEG compressed size of the image—with smaller size corresponding to being more simple).</p>

<p><img src="https://gradientscience.org/assets/3db/mug_background_complexity.png" alt="Simplicity versus model accuracy for HDRI backgrounds" /></p>

<div class="caption">
A graph plotting average accuracy of our pre-trained ImageNet model (y-axis) on
images rendered by 3DB while varying the complexity of the rendering backgrounds
(x-axis). 
</div>

<p><strong>A note on compositionality</strong>: An important part of 3DB that we don’t discuss here is compositionality, i.e., the ability to put together multiple controls and study their joint effect. For example, in our paper we studied how a model’s prediction vary with various zoom levels and backgrounds of an object. We found that the optimal zoom level varies a lot by background.</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="bg-tab1" type="radio" checked="" name="bg-tab" class="tab1" />
    <label for="bg-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="bg-tab2" type="radio" name="bg-tab" class="tab2" />
    <label for="bg-tab2"><i class="fa fa-code"></i>  Config (backgrounds.yaml)</label>
    <input id="bg-tab3" type="radio" name="bg-tab" class="tab3" />
    <label for="bg-tab3"><i class="fa fa-search"></i>  Analysis (analyze_bgs.py)</label>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="bash">
# $BLENDER_DATA/blender_environments` contains several backgrounds and
# $BLENDER_DATA/blender_models contains the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/backgrounds
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# (Optional) Download additional backgrounds you want---e.g., from
# https://hdrihaven.com/hdris/ (both `.hdr` and `.blend` files work) and put
# them in BLENDER_DATA/blender_environments. 
wget https://hdrihaven.com/hdris/PATH/TO/HDRI \
    -O $BLENDER_DATA/blender_environments

# Direct results
export RESULTS_FOLDER='results_backgrounds'

# Run 3DB (with the YAML file from the next pane saved as `backgrounds.yaml`):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA backgrounds.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (third pane)
python analyze_bgs.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_backgrounds/details.log').readlines()
class_map = json.load(open('results_backgrounds/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('environment').agg(accuracy=('is_correct', 'mean'),
        most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
</div>
</div>
</details>

<h2 id="texture-bias">Texture Bias</h2>
<p>Another <a href="https://arxiv.org/abs/1811.12231v2">recent study</a> of neural network biases showed that in
contrast to humans, convolutional neural networks (CNNs) rely more on texture
to recognize objects than on shape. The example below typifies this
phenomenon—a cat with an elephant texture is recognized as a cat by humans,
but as an elephant by CNNs:</p>

<p><img src="https://gradientscience.org/assets/3db/cue_conflict.png" alt="Cue-conflict images introduced by Geirhos et al." /></p>
<div class="caption">
An example of the cue-conflict images introduced by Geirhos et al. Combining the
elephant texture with the cat shape results in a mixed image on which CNNs
consistently predict with the texture signal.
</div>

<p>This example and others like it (dubbed ‘cue-conflict’ images) provide a
striking illustration of the contrast between human and CNN-based
classification mechanisms. Still, just as in the case of image backgrounds,
creating such images typically necessitates time, technical skill,
quality control, and/or introduction of unwanted artifacts (for example, in the above figure,
ideally we would modify only the texture of the cat without altering the background).</p>

<p>However, using 3DB we can easily collect photorealistic empirical evidence of
texture bias. Without modifying the internal 3DB codebase at all,
one can write a <a href="https://github.com/3db/3db/blob/main/threedb/controls/blender/material.py">custom control</a> that modifies the texture of
objects in the scene while keeping the rest intact. With this custom control
in placeIn fact, the texture-swapping control for this experiment is now 
pre-packaged with 3DB, since we already wrote it ourselves!, one can simply 
randomize the texture of the mug across various
backgrounds, poses and camera parameters before stratifying results:</p>

<p><img src="https://gradientscience.org/assets/3db/texture_swap_histograms.png" alt="Chungus" /></p>

<p>The performance of the pretrained model on mugs (and other objects)
deteriorates severely upon replacing the mug’s texture with a “wrong” one,
providing clear corroborating evidence of the texture bias! We noticed in our
experiments that for some textures (e.g., zebra), the coffee mug was
consistently misclassified as the corresponding animal, whereas for others
(e.g., crocodile), the mug is misclassified as either a related class (e.g.,
turtle or other reptile), or as an unrelated object (e.g., a trash can).</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="texture-tab1" type="radio" checked="" name="texture-tab" class="tab1" />
    <label for="texture-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="texture-tab2" type="radio" name="texture-tab" class="tab2" />
    <label for="texture-tab2"><i class="fa fa-code"></i>  Config (texture_swaps.yaml)</label>
    <input id="texture-tab3" type="radio" name="texture-tab" class="tab3" />
    <label for="texture-tab3"><i class="fa fa-search"></i>  Analysis (analyze_ts.py)</label>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1">
<pre class="wrapped"><code class="bash">
# ${BLENDER_DATA}/blender_environments contains several backgrounds,
# ${BLENDER_DATA}/blender_models contain the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/texture_swaps

# List the materials that we will use for this post:
ls blog_demo/data/texture_swaps/blender_control_material
# You can also make or download blender materials corresponding 
# to other textures you want to test, and add them to that folder 

# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

export RESULTS_FOLDER=results_texture

# Run 3DB (with the YAML file from the next pane saved as texture_swaps.yaml):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA texture_swaps.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (copy from third pane)
python analyze_ts.py

</code></pre>
</div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.position"
    offset_x: 0.
    offset_y: 0.5
    offset_z: 0.
  - module: "threedb.controls.blender.pin_to_ground"
    z_ground: 0.25
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: [0., 1.]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.material"
    replacement_material: ["cow.blend", "elephant.blend", "zebra.blend", "crocodile.blend", "keep_original"]
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_texture/details.log').readlines()
class_map = json.load(open('results_texture/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df = df.drop('render_args', axis=1).join(pd.DataFrame(df.render_args.values.tolist()))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('MaterialControl.replacement_material').agg(acc=('is_correct', 'mean'),
      most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
    </div>
</div>
</details>

<h2 id="part-of-object-attribution">Part-of-Object Attribution</h2>

<p>Beyond general hypotheses about model biases, 3DB allows us to test vision
systems on a more fine-grained level. In the case of our running mug example,
for instance, we can use the platform to understand which specific parts of
its 3D mesh correlate with classifier accuracy. Specifically, below we
generate (and classify) scenes with random mug positions, rotations, and
backgrounds. Since 3DB stores texture-coordinate information for each
rendering, we can reconstruct a three-dimensional heatmap that encodes, for
each point on the surface of the mug, the classifier’s accuracy conditioned
on that point being visible:</p>

<p style="text-align: center;">
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_1.png" style="width: 18%; display: inline;" />
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_2.png" style="width: 18%; display: inline;" />
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_3.png" style="width: 18%; display: inline;" />
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_4.png" style="width: 18%; display: inline;" />
    <img src="https://gradientscience.org/assets/3db/heatmap_mug/heatmap_mug_5.png" style="width: 18%; display: inline;" />
</p>
<div style="margin-top: 0px; margin-bottom: 15px;" class="caption">
    A part-of-object attribution heatmap for our mug 3D model. <span style="color: red;">Red</span> pixels indicate areas whose visibility most
    improves accuracy, whereas <span style="color: blue;">blue</span> areas'
    visibility correlates with incorrect classifications.
</div>

<p>A number of phenomena stand out from this heatmap, including:</p>

<ol>
  <li>The classifier is worse when the side of the mug opposite the handle is seen.</li>
  <li>The classifier is more accurate when the bottom rim is visible.</li>
  <li>The classifier performs worst when the inside of the mug is visible.</li>
</ol>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="pobj-tab1" type="radio" checked="" name="pobj-tab" class="tab1" />
    <label for="pobj-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="pobj-tab2" type="radio" name="pobj-tab" class="tab2" />
    <label for="pobj-tab2"><i class="fa fa-code"></i>  Config (part_of_object.yaml)</label>
    <input id="pobj-tab3" type="radio" name="pobj-tab" class="tab3" />
    <label for="pobj-tab3"><i class="fa fa-search"></i>  Analysis (analyze_po.py)</label>
    <div class="line"></div>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# point BLENDER_DATA to the environments and models for this experiment
export BLENDER_DATA=$(realpath blog_demo)/data/part_of_object
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# Optionally: download additional backgrounds (`.hdr` or `.blend`) e.g.,
wget URL -O $BLENDER_DATA/blender_environments/new_env.hdr

# Point results folder to where you want output written
export RESULTS_FOLDER='results_part_of_object'

# Run 3DB (with the YAML file from the next pane):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA part_of_object.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Run `part_of_object.py` (third pane) to generate the heat map of the mug.
python po_analysis.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_uv: True
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: 1.
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"
  - module: "threedb.controls.blender.background"
    H: 1.
    S: 0.
    V: 1.
</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json
from PIL import Image

DIR = 'results_part_of_object'
log_lines = open(f'{DIR}/details.log').readlines()
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))

# From class index to class name (for readability)
class_map = json.load(open(f'{DIR}/class_maps.json'))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])

# We'll be a little lenient here to get a more interesting heatmap
df['is_correct'] = df['prediction'].isin(['cup', 'coffee mug'])

uv_num_correct = np.zeros((256, 256))
uv_num_visible = np.zeros((256, 256))
for imid in df["id"].unique().tolist():
    is_correct = float(df.set_index('id').loc[imid]['is_correct'])
    vis_coords_im = Image.open(f'{DIR}/images/{imid}_uv.png')
    vis_coords = np.array(vis_coords_im).reshape(-1, 3)
    # R and G channels encode texture coordinates (x, y), 
    # B channel is 255 for object and 0 for background
    # So we will filter by B then only look at R and G.
    vis_coords = vis_coords[vis_coords[:,2] &gt; 0][:,:2]

    uv_num_visible[vis_coords[:,0], vis_coords[:,1]] += 1.
    uv_num_correct[vis_coords[:,0], vis_coords[:,1]] += is_correct

# Accuracy = # correct / # visible
uv_accuracy = uv_num_correct / (uv_num_visible + 1e-4)

# Saves a black-and-white heatmap
Image.fromarray((255 * uv_accuracy).astype('uint8'))

</code></pre></div>
</div>
</div>
</details>
<p><br /></p>

<p>Now that we have hypotheses regarding model performance, we can test them! Inspecting
the ImageNet validation set, we found that our classifier indeed (a) struggles on coffee mugs when the
handle is not showing (providing a feasible explanation for (1), since the side
opposite the handle is only visible when the handle itself isn’t), and (b)
performs worse at higher camera angles (providing a plausible explanation for
(2)). We want to focus, however, on the third phenomenon,
i.e., that the classifier performs quite poorly whenever the inside of the
mug is visible. Why could this be the case? We can use 3DB to gain insight into the
phenomenon. Specifically, we want to test the following hypothesis: when
classifying mugs, does our ImageNet model rely on the exact liquid inside the
cup?</p>

<p>We investigate this hypothesis by writing a custom control that fills
our mug with various liquids (more precisely, a parameterized mixture of
water, milk, and coffee):</p>

<p><img src="https://gradientscience.org/assets/3db/mug_liquid_experiment_samples.png" alt="Examples of the mugs rendered in this experiment" /></p>
<div class="caption">
Our running example mug, filled with different parameterized liquids: 100% water
(top left), 100% coffee (top right), 100% milk (bottom right), and a coffee-milk
mixture (bottom left)
</div>

<p>In contrast to the last experiment (where we varied the orientation of the
mug), we render scenes containing the mug in a fixed set of poses that reveal
the contents—just as in the last experiment, however, we still vary
background and mug location. We visualize the results below—each cell in
the heatmap corresponds to a fixed mixture of coffee, water, and milk (i.e.,
the labeled corners are 100% coffee, 100% milk, and 100% water, and the other
cells are linear interpolations of these ratios) and the color of the cell
encodes the relative accuracy of the classifier when the mug is filled with
that liquid:</p>



<p><img src="https://gradientscience.org/assets/3db/mug_liquid_experiment_simplex.png" alt="" /></p>

<div class="caption">
Measuring the relative effect of the liquid mixture in the mug on model
predictions. Each cell represents a specific liquid mixture, and the color of
the cell represents the tendency of the model (averaged over random viewpoints
and relative to the other cells) to predict "cup"/"pill bottle," "bucket," or
"mug."
</div>

<p>It turns out that mug content indeed highly impacts classification:
our model is much less likely to correctly classify a mug that doesn’t contain coffee!
This is just one example of how 3DB can help in proving or disproving hypotheses
about model behavior.</p>

<h2 id="from-simulation-to-reality">From Simulation to Reality</h2>

<p>So far, we’ve used 3DB to discover ML models’ various failure modes and biases
via photorealistic rendering. To what extent though do the insights
gleaned from simulated 3DB experiments actually “transfer” to the physical
world?</p>

<p>To test such transferability, we began by creating a 3D model of a physical room we
had access to. We also collected eight different 3D models with closely matching
physical world counterparts—including the mug analyzed above. Next, we used 3DB to find correctly and incorrectly classified
configurations (pose, orientation, location) of these eight objects inside that
room. Finally, we replicated these poses (to
the best of our abilities) in the physical room, and took photos with a
cellphone camera:</p>

<p><img src="https://gradientscience.org/assets/3db/real_life_exp_samples.png" alt="Samples from our physical-world experiment." class="bigimg" /></p>

<div class="caption">
Examples of simulated scenes (top) and their re-created counterparts (bottom)
from our physical-world experiment.
</div>

<p>We classified these photos with the same vision model as before and measured
how often the simulated classifier correctness matched correctness on the
real photographs. We observed an ~85% match! So the failure
modes identified by 3DB are not merely simulation artifacts, and can indeed arise in
the real world.</p>

<h2 id="conclusion">Conclusion</h2>

<p>3DB is a flexible, easy-to-use, and extensible framework for
identifying model failure modes, uncovering biases, and testing fine-grained
hypotheses about model behavior. We hope it will prove to be a useful tool
for debugging vision models.</p>
<h2 id="bonus-object-detection-web-dashboard-and-more">Bonus: Object Detection, Web Dashboard, and more!</h2>

<p>We’ll wrap up by highlighting some additional capabilities of 3DB that we didn’t
get to demonstrate in this blog post:</p>

<h3 id="3dboard-a-web-interface-for-exploring-results">3DBoard: a web interface for exploring results</h3>

<p>In all of the code examples above, we showed how to analyze the results of a 3DB
experiment by loading the output into a <code class="language-plaintext highlighter-rouge">pandas</code> dataframe. For additional
convenience, however, 3DB also comes with a web-based dashboard for exploring
experimental results. The following command suffices to visualize the texture swaps experiment from earlier:</p>

<pre style="padding: 0; margin: 0;"><code class="bash">
python -m threedboard results_texture/ --port 3000

</code>
</pre>

<p>Navigating to <code class="language-plaintext highlighter-rouge">YOUR_IP:3000</code> should lead you to a page that looks like this:</p>

<p><img src="https://gradientscience.org/assets/3db/dashboard_screenshot.png" alt="Dashboard screenshot" /></p>

<h3 id="object-detection-and-other-tasks">Object detection and other tasks</h3>

<p>In this blog post, we focused on using 3DB to analyze image classification
models. However, the library also supports object detection out-of-the-box, and
can easily be extended to support a variety of image-based tasks (e.g.,
segmentation or regression-based tasks). For example, below we provide a simple
end-to-end object detection example:</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="objdet-tab1" type="radio" checked="" name="objdet-tab" class="tab1" />
    <label for="objdet-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="objdet-tab2" type="radio" name="objdet-tab" class="tab2" />
    <label for="objdet-tab2"><i class="fa fa-code"></i>  Config (part_of_object.yaml)</label>
    <div class="line"></div>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# The object detection example is separate from the rest of the blog demo, so
# run the following in a separate repo:
git clone https://github.com/3db/object_detection_demo

# The repo has a data/ folder containing the Blender model (a banana) and some
# HDRI backgrounds, a classmap.json file mapping the UID of the model to a COCO
# class, and the detection.yaml file from the next pane.
cd object_detection_demo/

export BLENDER_DATA=data/
export RESULTS_FOLDER=results/

# Run 3DB
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp; 
threedb_master $BLENDER_DATA detection.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

</code></pre></div> 
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models.detection'
  class: 'retinanet_resnet50_fpn'
  label_map: './resources/coco_mapping.json'
  normalization:
    mean: [0., 0., 0.]
    std: [1., 1., 1.]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.detection'
  args:
    iou_threshold: 0.5
    nms_threshold: 0.1
    max_num_boxes: 10
    classmap_path: 'classmap.json'
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_segmentation: true
policy:
  module: "threedb.policies.random_search"
  samples: 2
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
</div>
</div>
</details></div>







<p class="date">
<a href="https://gradientscience.org/3db-light/"><span class="datestr">at June 08, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://gradientscience.org/3db/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/madry.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://gradientscience.org/3db/">3DB: A Framework for Debugging Vision Models</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><a style="float: left; width: 45%; margin-bottom: 0;" href="https://arxiv.org/abs/2106.03805" class="bbutton">
<i class="fas fa-file-pdf"></i>
    Paper
</a>
<a style="float: left; width: 45%; margin-bottom: 0;" href="https://github.com/3db/3db/" class="bbutton">
<i class="fab fa-github"></i>
   Project Repo
</a>
<a style="float: left; width: 45%;" href="https://3db.github.io/3db/usage/quickstart.html" class="bbutton">
<i class="fas fa-file-alt"></i>
   Documentation and Guides
</a> 
<a style="float: left; width: 45%;" href="https://github.com/3db/blog_demo/" class="bbutton">
<i class="fab fa-github"></i>
   Blog Demo
</a> 
<br /></p>

<p><i>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, in collaboration with Microsoft Research, we introduce
3DB: an extendable, unified framework for debugging and analyzing vision models
using photorealistic simulation. We’re releasing 3DB as a package, accompanied
by extensive API documentation, guides, and demos.</i></p>

<p><em>Note: this post contains some interactive plots and 3D models that use
JavaScript: click <a href="https://gradientscience.org/3db-light/">here</a> for a JS-free version of this post.</em></p>

<p>Identifying failure modes and biases in vision models is a rapidly
emerging challenge in machine learning. In high-stakes
applications, simply deploying models and collecting failures that arise in
the wild is often difficult, expensive, and irresponsible. To this end, a
recent line of work in vision focuses on identifying model failure
modes via in-depth analyses of <a href="https://arxiv.org/abs/1712.02779">image transformations</a> and 
<a href="https://arxiv.org/abs/1903.12261">corruptions</a>, <a href="https://objectnet.dev">object orientations</a>,
<a href="https://gradientscience.org/background/">backgrounds</a>, or <a href="https://arxiv.org/abs/1811.12231v2">shape-texture conflicts</a>. These studies 
(and other similarly important ones) reveal a variety of patterns of
performance degradation in vision models. Still, performing each such study
requires time, developing (often complex)
toolingFor <a href="https://gradientscience.org/background/">our study of image backgrounds</a>, for example, we used a
combination of bounding boxes and classical computer vision tools to crop out
image backgrounds. We then had to manually filter out the images for which
the tools failed. Even for the images where the toolkit succeeded, there
remained inevitable cropping artifacts., and a willingness to settle for less than perfect simulations of each
potential failure mode. Our question is: can we support reliable discovery of model failures in a systematic,
automated, and unified way?</p>

<h2 id="3db-a-rendering-based-debugging-platform">3DB: A Rendering-based Debugging Platform</h2>

<p><img src="https://gradientscience.org/assets/3db/3db_headline.png" alt="A sampling of the analyses enabled by 3DB." class="bigimg" /></p>
<div style="margin-top: 0;" class="caption">
A sampling of the analyses enabled by 3DB.
</div>

<p>In our <a href="https://arxiv.org/abs/2106.03805">latest paper</a>, we try to make progress on this question and propose
3DB, a platform for automatically identifying and analyzing the failure modes
of computer vision models using 3D rendering. 3DB aims to allow users to go
from a testable, robustness-based hypothesis to concrete, photorealistic
experimental evidence with minimal time and effort.</p>

<p>The platform revolves around the modular workflow pictured below. First,
users specify a set of 3D objects and environments, as well as a set of 3D
(or 2D) transformations called controls that determine the space of
admissible object-environment configurations. 3DB then renders a myriad of
admissible scenes and feeds them through the user’s computer vision model of
choice. The user can finally stratify, aggregate, or otherwise analyze the
results either by reading the outputted JSON, or through the pre-packaged
dashboard.</p>

<p><img src="https://gradientscience.org/assets/3db/workflow.png" alt="An illustration of the 3DB workflow." class="bigimg" /></p>

<p>3DB easily adapts to a variety of use cases: in particular, users can
modify and swap out any part of this pipeline (e.g., the renderer, the
logger, the model type, or the controls) for their own custom-written
components, without needing to modify any of the 3DB codebase. We’ve compiled <a href="https://3db.github.io/3db/">guides</a>,
extensive <a href="https://3db.github.io/3db/api_doc.html">API documentation</a>, and a
<a href="https://github.com/3db/demo">full demo</a> showing how 3DB streamlines model debugging.</p>

<p><strong>In fact, this blog post will double as another demo! We’ll present the (short) code
necessary to reproduce every plot in the post below using 3DB. You can download 
the aggregated code for this blog post <a href="https://github.com/3db/blog_demo">here</a>.</strong></p>

<p><em>To set up, follow the steps below—then, in the remainder of this post, press
“Show/hide code and instructions” to see the steps necessary to reproduce each
experiment below.</em></p>
<div class="code-container">
  <input id="general-tab1" type="radio" checked="" name="general-tab" class="tab1" />
  <label for="general-tab1"><i class="fa fa-gear"></i>  Setup</label>
  <input id="general-tab2" type="radio" name="general-tab" class="tab2" />
  <label for="general-tab2"><i class="fa fa-code"></i>  Config (base.yaml)</label>
  <div class="line"></div>
  <div class="content-container">
<div class="content c1">

<ol class="instructions">
<li>Clone the  <a href="https://github.com/3db/blog_demo">blog demo <i class="fab fa-github"></i></a> repo</li>
<li>Run <pre>cd blog_demo</pre>, then <pre>bash setup.sh</pre> (assumes
<pre>unzip</pre> is installed) to download a large Blender environment, then
<pre>cd ../</pre></li>
<li>Install 3DB: <pre>curl -L https://git.io/Js8eT | bash /dev/stdin threedb</pre></li>
<li>Run <pre>conda activate threedb</pre></li>
<li>Our experiments below will need a <pre>BLENDER_DATA</pre> folder that contains two
subfolders: <pre>blender_models/</pre> containing 3D models (<pre>.blend</pre> files with a single
object whose name matches the filename), and <pre>blender_environments/</pre>
containing environments. We will provide you with these later</li> 
<li>Separately, make a file called <pre>base.yaml</pre> and paste in the configuration from the next pane.</li>
</ol>

</div>
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models'
  label_map: 'blog_demo/resources/imagenet_mapping.json'
  class: 'resnet18'
  normalization:
    mean: [0.485, 0.456, 0.406]
    std: [0.229, 0.224, 0.225]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.classification'
  args:
    classmap_path: 'blog_demo/resources/ycb_to_IN.json'
    topk: 1
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
policy:
  module: "threedb.policies.random_search"
  samples: 5
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"

</code></pre></div>
 </div>
</div>

<h2 id="using-3db">Using 3DB</h2>

<p>Prior works have already used 3D rendering (to great effect) to study biases
of machine learning models, including pose and context-based biases. Our goal
is not to propose a specific 3D-rendering based analysis, but
rather to provide an easy-to-use, highly extendable framework that unifies
prior analyses (both 3D and 2D) while enabling users to (a) conduct a host of
new analyses with the same ease and with realistic results; and (b)
effortlessly <em>compose</em> different factors of variation to understand their
interplay.</p>

<p>We’ll dedicate the rest of this post to illustrating how one
might actually use 3DB in practice, focusing on a single example 3D
model3DB works with any 3D model, and we refer the reader to 
<a href="https://arxiv.org/abs/2106.03805">our paper</a> for more examples and details.:</p>





<div style="text-align: center;" id="mug-blocker">
    
        
            
        
        
    
</div>
<div style="margin-top: 0px; margin-bottom: 15px;" class="caption">
    The 3D mug model that we'll be using throughout this post. <strong>
    Click to <a id="mug-interact">enable 
    interactivity</a>.</strong>
</div>

<p>In what follows, we will walk through example applications of 3DB to discover biases of
ML models (some previously documented, others not). For the sake of brevity,
we’ll highlight just a few of these (re-)discoveries—to see more, check out
the <a href="https://arxiv.org/abs/2106.03805">paper</a>. We’ll then demonstrate that the discoveries of 3DB
transfer pretty reliably to the real world!</p>

<p>Our experiments will all operate on an ImageNet-pretrained
ResNet-18The classifier has a ~70% validation-set
accuracy. that has 42% accuracy on images from the
“coffee mug” ImageNet subclass. While we only study classification in this blog post,
3DB also supports object detection and can be easily extended to support other
image-based tasks, such as semantic segmentation, too.</p>

<h2 id="image-background-sensitivity">Image Background Sensitivity</h2>

<p>In one of our <a href="https://gradientscience.org/background/">previous posts</a>,
we continued a long line of prior work (see, e.g.,
<a href="https://hal.archives-ouvertes.fr/hal-00171412/file/ZhangMarszalekLazebnikSchmid-IJCV07-ClassificationStudy.pdf">here</a>, <a href="https://arxiv.org/abs/1611.06596">here</a>, <a href="https://arxiv.org/abs/1911.08731">here</a>, etc.) showing that models can be
over-reliant on image backgrounds, and demonstrated that they are easily
broken by adversarially chosen backgrounds. To accomplish this, our prior
analysis used classical computer vision tools to separate foregrounds from
backgrounds, then pasted foregrounds from one image onto backgrounds from
another. This process was slow and required extensive quality control to
ensure that backgrounds and foregrounds were being extracted properly—and
even when they were, a few artifacts remained:</p>

<div style="margin-bottom: 15px; overflow: hidden; text-align: center;">
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/1.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/2.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/3.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/4.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/5.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
        <img src="https://gradientscience.org/assets/3db/backgrounds-manual/6.JPEG" style="width: 15%; margin: 2px; display: inline;" />
    
</div>

<p>3DB lets us reproduce these findings effortlessly and without introducing
such artifacts. To demonstrate this, we use 3DB to render our mug 3D model on
hundreds of HDRI backgrounds, resulting in images such as:</p>

<div style="margin-bottom: 15px; overflow: hidden;">
    
        <img src="https://gradientscience.org/assets/3db/background-renders/1.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/2.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/3.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/4.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/5.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/6.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/7.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/8.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/9.png" style="float: right; width: 20%;" />
    
        <img src="https://gradientscience.org/assets/3db/background-renders/10.png" style="float: right; width: 20%;" />
    
</div>

<p>We then analyze the performance of a pretrained ResNet-18Recall that this model
obtains 42% accuracy on the corresponding "coffee mug" ImageNet class subset.on these images. We
find that the performance of the classifier varies significantly across
backgrounds, and that accuracy correlates with a crude measure of
“background simplicity” (the JPEG compressed size of the image—with smaller size corresponding to being more simple).</p>

<div>
  <canvas id="myChart"></canvas>
</div>

<div class="caption">
A graph plotting average accuracy of our pre-trained ImageNet model (y-axis) on
images rendered by 3DB while varying the complexity of the rendering backgrounds
(x-axis). 
</div>

<p><strong>A note on compositionality</strong>: An important part of 3DB that we don’t discuss here is compositionality, i.e., the ability to put together multiple controls and study their joint effect. For example, in our paper we studied how a model’s prediction vary with various zoom levels and backgrounds of an object. We found that the optimal zoom level varies a lot by background.</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="bg-tab1" type="radio" checked="" name="bg-tab" class="tab1" />
    <label for="bg-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="bg-tab2" type="radio" name="bg-tab" class="tab2" />
    <label for="bg-tab2"><i class="fa fa-code"></i>  Config (backgrounds.yaml)</label>
    <input id="bg-tab3" type="radio" name="bg-tab" class="tab3" />
    <label for="bg-tab3"><i class="fa fa-search"></i>  Analysis (analyze_bgs.py)</label>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="bash">
# $BLENDER_DATA/blender_environments` contains several backgrounds and
# $BLENDER_DATA/blender_models contains the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/backgrounds
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# (Optional) Download additional backgrounds you want---e.g., from
# https://hdrihaven.com/hdris/ (both `.hdr` and `.blend` files work) and put
# them in BLENDER_DATA/blender_environments. 
wget https://hdrihaven.com/hdris/PATH/TO/HDRI \
    -O $BLENDER_DATA/blender_environments

# Direct results
export RESULTS_FOLDER='results_backgrounds'

# Run 3DB (with the YAML file from the next pane saved as `backgrounds.yaml`):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA backgrounds.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (third pane)
python analyze_bgs.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_backgrounds/details.log').readlines()
class_map = json.load(open('results_backgrounds/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('environment').agg(accuracy=('is_correct', 'mean'),
        most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
</div>
</div>
</details>

<h2 id="texture-bias">Texture Bias</h2>
<p>Another <a href="https://arxiv.org/abs/1811.12231v2">recent study</a> of neural network biases showed that in
contrast to humans, convolutional neural networks (CNNs) rely more on texture
to recognize objects than on shape. The example below typifies this
phenomenon—a cat with an elephant texture is recognized as a cat by humans,
but as an elephant by CNNs:</p>

<p><img src="https://gradientscience.org/assets/3db/cue_conflict.png" alt="Cue-conflict images introduced by Geirhos et al." /></p>
<div class="caption">
An example of the cue-conflict images introduced by Geirhos et al. Combining the
elephant texture with the cat shape results in a mixed image on which CNNs
consistently predict with the texture signal.
</div>

<p>This example and others like it (dubbed ‘cue-conflict’ images) provide a
striking illustration of the contrast between human and CNN-based
classification mechanisms. Still, just as in the case of image backgrounds,
creating such images typically necessitates time, technical skill,
quality control, and/or introduction of unwanted artifacts (for example, in the above figure,
ideally we would modify only the texture of the cat without altering the background).</p>

<p>However, using 3DB we can easily collect photorealistic empirical evidence of
texture bias. Without modifying the internal 3DB codebase at all,
one can write a <a href="https://github.com/3db/3db/blob/main/threedb/controls/blender/material.py">custom control</a> that modifies the texture of
objects in the scene while keeping the rest intact. With this custom control
in placeIn fact, the texture-swapping control for this experiment is now 
pre-packaged with 3DB, since we already wrote it ourselves!, one can simply 
randomize the texture of the mug across various
backgrounds, poses and camera parameters before stratifying results:</p>

<div class="widget">
    <div class="choices_one_full" id="gen">
    <span class="widgetheading" id="genclass">Choose an Image</span>
    </div>
    <div style="border-right: 3px white solid;">
        <div style="width: 32%; margin-right: 2%;" class="image-container">
            <h4 style="text-align: center;">Average accuracy (compare to 42% on ImageNet val set)</h4>
            <canvas id="gen1"></canvas>
        </div>
        <div style="width: 66%;" class="image-container" id="gen2">
            <img class="example-texture" id="gen2-0" />
            <img class="example-texture" id="gen2-1" />
            <img class="example-texture" id="gen2-2" />
            <img class="example-texture" id="gen2-3" />
            <img class="example-texture" id="gen2-4" />
            <img class="example-texture" id="gen2-5" />
            <img class="example-texture" id="gen2-6" />
            <img class="example-texture" id="gen2-7" />
        </div>
    </div>
</div>
<div style="clear: both;"></div>
<div class="caption">
<strong>Interactive demo</strong>: select any image in the top two rows to see additional
samples of that class.
</div>

<p>The performance of the pretrained model on mugs (and other objects)
deteriorates severely upon replacing the mug’s texture with a “wrong” one,
providing clear corroborating evidence of the texture bias! We noticed in our
experiments that for some textures (e.g., zebra), the coffee mug was
consistently misclassified as the corresponding animal, whereas for others
(e.g., crocodile), the mug is misclassified as either a related class (e.g.,
turtle or other reptile), or as an unrelated object (e.g., a trash can).</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="texture-tab1" type="radio" checked="" name="texture-tab" class="tab1" />
    <label for="texture-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="texture-tab2" type="radio" name="texture-tab" class="tab2" />
    <label for="texture-tab2"><i class="fa fa-code"></i>  Config (texture_swaps.yaml)</label>
    <input id="texture-tab3" type="radio" name="texture-tab" class="tab3" />
    <label for="texture-tab3"><i class="fa fa-search"></i>  Analysis (analyze_ts.py)</label>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1">
<pre class="wrapped"><code class="bash">
# ${BLENDER_DATA}/blender_environments contains several backgrounds,
# ${BLENDER_DATA}/blender_models contain the 3D model of a mug.
export BLENDER_DATA=$(realpath blog_demo)/data/texture_swaps

# List the materials that we will use for this post:
ls blog_demo/data/texture_swaps/blender_control_material
# You can also make or download blender materials corresponding 
# to other textures you want to test, and add them to that folder 

# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

export RESULTS_FOLDER=results_texture

# Run 3DB (with the YAML file from the next pane saved as texture_swaps.yaml):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA texture_swaps.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Finally, run analysis using pandas (copy from third pane)
python analyze_ts.py

</code></pre>
</div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.position"
    offset_x: 0.
    offset_y: 0.5
    offset_z: 0.
  - module: "threedb.controls.blender.pin_to_ground"
    z_ground: 0.25
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: [0., 1.]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.material"
    replacement_material: ["cow.blend", "elephant.blend", "zebra.blend", "crocodile.blend", "keep_original"]
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json

log_lines = open('results_texture/details.log').readlines()
class_map = json.load(open('results_texture/class_maps.json'))
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))
df = df.drop('render_args', axis=1).join(pd.DataFrame(df.render_args.values.tolist()))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])
df['is_correct'] = (df['is_correct'] == 'True')

res = df.groupby('MaterialControl.replacement_material').agg(acc=('is_correct', 'mean'),
      most_frequent_prediction=('prediction', lambda x: x.mode()))
print(res)

</code></pre></div>
    </div>
</div>
</details>

<h2 id="part-of-object-attribution">Part-of-Object Attribution</h2>

<p>Beyond general hypotheses about model biases, 3DB allows us to test vision
systems on a more fine-grained level. In the case of our running mug example,
for instance, we can use the platform to understand which specific parts of
its 3D mesh correlate with classifier accuracy. Specifically, below we
generate (and classify) scenes with random mug positions, rotations, and
backgrounds. Since 3DB stores texture-coordinate information for each
rendering, we can reconstruct a three-dimensional heatmap that encodes, for
each point on the surface of the mug, the classifier’s accuracy conditioned
on that point being visible:</p>

<div style="text-align: center;" id="heatmap-blocker">
    
        
            
        
        
        
    
</div>
<div style="margin-top: 0px; margin-bottom: 15px;" class="caption">
    A part-of-object attribution heatmap for our mug 3D model. <span style="color: red;">Red</span> pixels indicate areas whose visibility most
    improves accuracy, whereas <span style="color: blue;">blue</span> areas'
    visibility correlates with incorrect classifications. <strong>Click here to <a id="heatmap-interact">enable
    interactivity</a>.</strong>
</div>

<p>A number of phenomena stand out from this heatmap, including:</p>

<ol>
  <li>The classifier is worse when the side of the mug opposite the handle is seen.</li>
  <li>The classifier is more accurate when the bottom rim is visible.</li>
  <li>The classifier performs worst when the inside of the mug is visible.</li>
</ol>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="pobj-tab1" type="radio" checked="" name="pobj-tab" class="tab1" />
    <label for="pobj-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="pobj-tab2" type="radio" name="pobj-tab" class="tab2" />
    <label for="pobj-tab2"><i class="fa fa-code"></i>  Config (part_of_object.yaml)</label>
    <input id="pobj-tab3" type="radio" name="pobj-tab" class="tab3" />
    <label for="pobj-tab3"><i class="fa fa-search"></i>  Analysis (analyze_po.py)</label>
    <div class="line"></div>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# point BLENDER_DATA to the environments and models for this experiment
export BLENDER_DATA=$(realpath blog_demo)/data/part_of_object
# if you want to use the pre-written material in blog_demo, uncomment:
# cd blog_demo

# Optionally: download additional backgrounds (`.hdr` or `.blend`) e.g.,
wget URL -O $BLENDER_DATA/blender_environments/new_env.hdr

# Point results folder to where you want output written
export RESULTS_FOLDER='results_part_of_object'

# Run 3DB (with the YAML file from the next pane):
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp;
threedb_master $BLENDER_DATA part_of_object.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

# Run `part_of_object.py` (third pane) to generate the heat map of the mug.
python po_analysis.py

</code></pre></div>
<div class="content c2"><pre><code class="YAML">
base_config: "base.yaml"
policy:
  module: "threedb.policies.random_search"
  samples: 20
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_uv: True
controls:
  - module: "threedb.controls.blender.orientation"
    rotation_x: -1.57
    rotation_y: 0.
    rotation_z: [-3.14, 3.14]
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    view_point_x: 1.
    view_point_y: 1.
    view_point_z: 1.
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"
  - module: "threedb.controls.blender.background"
    H: 1.
    S: 0.
    V: 1.
</code></pre></div>
<div class="content c3"><pre><code class="python">
import pandas as pd
import numpy as np
import json
from PIL import Image

DIR = 'results_part_of_object'
log_lines = open(f'{DIR}/details.log').readlines()
df = pd.DataFrame.from_records(list(map(json.loads, log_lines)))

# From class index to class name (for readability)
class_map = json.load(open(f'{DIR}/class_maps.json'))
df['prediction'] = df['prediction'].apply(lambda x: class_map[x[0]])

# We'll be a little lenient here to get a more interesting heatmap
df['is_correct'] = df['prediction'].isin(['cup', 'coffee mug'])

uv_num_correct = np.zeros((256, 256))
uv_num_visible = np.zeros((256, 256))
for imid in df["id"].unique().tolist():
    is_correct = float(df.set_index('id').loc[imid]['is_correct'])
    vis_coords_im = Image.open(f'{DIR}/images/{imid}_uv.png')
    vis_coords = np.array(vis_coords_im).reshape(-1, 3)
    # R and G channels encode texture coordinates (x, y), 
    # B channel is 255 for object and 0 for background
    # So we will filter by B then only look at R and G.
    vis_coords = vis_coords[vis_coords[:,2] &gt; 0][:,:2]

    uv_num_visible[vis_coords[:,0], vis_coords[:,1]] += 1.
    uv_num_correct[vis_coords[:,0], vis_coords[:,1]] += is_correct

# Accuracy = # correct / # visible
uv_accuracy = uv_num_correct / (uv_num_visible + 1e-4)

# Saves a black-and-white heatmap
Image.fromarray((255 * uv_accuracy).astype('uint8'))

</code></pre></div>
</div>
</div>
</details>
<p><br /></p>

<p>Now that we have hypotheses regarding model performance, we can test them! Inspecting
the ImageNet validation set, we found that our classifier indeed (a) struggles on coffee mugs when the
handle is not showing (providing a feasible explanation for (1), since the side
opposite the handle is only visible when the handle itself isn’t), and (b)
performs worse at higher camera angles (providing a plausible explanation for
(2)). We want to focus, however, on the third phenomenon,
i.e., that the classifier performs quite poorly whenever the inside of the
mug is visible. Why could this be the case? We can use 3DB to gain insight into the
phenomenon. Specifically, we want to test the following hypothesis: when
classifying mugs, does our ImageNet model rely on the exact liquid inside the
cup?</p>

<p>We investigate this hypothesis by writing a custom control that fills
our mug with various liquids (more precisely, a parameterized mixture of
water, milk, and coffee):</p>

<p><img src="https://gradientscience.org/assets/3db/mug_liquid_experiment_samples.png" alt="Examples of the mugs rendered in this experiment" /></p>
<div class="caption">
Our running example mug, filled with different parameterized liquids: 100% water
(top left), 100% coffee (top right), 100% milk (bottom right), and a coffee-milk
mixture (bottom left)
</div>

<p>In contrast to the last experiment (where we varied the orientation of the
mug), we render scenes containing the mug in a fixed set of poses that reveal
the contents—just as in the last experiment, however, we still vary
background and mug location. We visualize the results below—each cell in
the heatmap corresponds to a fixed mixture of coffee, water, and milk (i.e.,
the labeled corners are 100% coffee, 100% milk, and 100% water, and the other
cells are linear interpolations of these ratios) and the color of the cell
encodes the relative accuracy of the classifier when the mug is filled with
that liquid:</p>



<p><img src="https://gradientscience.org/assets/3db/mug_liquid_experiment_simplex.png" alt="" /></p>

<div class="caption">
Measuring the relative effect of the liquid mixture in the mug on model
predictions. Each cell represents a specific liquid mixture, and the color of
the cell represents the tendency of the model (averaged over random viewpoints
and relative to the other cells) to predict "cup"/"pill bottle," "bucket," or
"mug."
</div>

<p>It turns out that mug content indeed highly impacts classification:
our model is much less likely to correctly classify a mug that doesn’t contain coffee!
This is just one example of how 3DB can help in proving or disproving hypotheses
about model behavior.</p>

<h2 id="from-simulation-to-reality">From Simulation to Reality</h2>

<p>So far, we’ve used 3DB to discover ML models’ various failure modes and biases
via photorealistic rendering. To what extent though do the insights
gleaned from simulated 3DB experiments actually “transfer” to the physical
world?</p>

<p>To test such transferability, we began by creating a 3D model of a physical room we
had access to. We also collected eight different 3D models with closely matching
physical world counterparts—including the mug analyzed above. Next, we used 3DB to find correctly and incorrectly classified
configurations (pose, orientation, location) of these eight objects inside that
room. Finally, we replicated these poses (to
the best of our abilities) in the physical room, and took photos with a
cellphone camera:</p>

<p><img src="https://gradientscience.org/assets/3db/real_life_exp_samples.png" alt="Samples from our physical-world experiment." class="bigimg" /></p>

<div class="caption">
Examples of simulated scenes (top) and their re-created counterparts (bottom)
from our physical-world experiment.
</div>

<p>We classified these photos with the same vision model as before and measured
how often the simulated classifier correctness matched correctness on the
real photographs. We observed an ~85% match! So the failure
modes identified by 3DB are not merely simulation artifacts, and can indeed arise in
the real world.</p>

<h2 id="conclusion">Conclusion</h2>

<p>3DB is a flexible, easy-to-use, and extensible framework for
identifying model failure modes, uncovering biases, and testing fine-grained
hypotheses about model behavior. We hope it will prove to be a useful tool
for debugging vision models.</p>
<h2 id="bonus-object-detection-web-dashboard-and-more">Bonus: Object Detection, Web Dashboard, and more!</h2>

<p>We’ll wrap up by highlighting some additional capabilities of 3DB that we didn’t
get to demonstrate in this blog post:</p>

<h3 id="3dboard-a-web-interface-for-exploring-results">3DBoard: a web interface for exploring results</h3>

<p>In all of the code examples above, we showed how to analyze the results of a 3DB
experiment by loading the output into a <code class="language-plaintext highlighter-rouge">pandas</code> dataframe. For additional
convenience, however, 3DB also comes with a web-based dashboard for exploring
experimental results. The following command suffices to visualize the texture swaps experiment from earlier:</p>

<pre style="padding: 0; margin: 0;"><code class="bash">
python -m threedboard results_texture/ --port 3000

</code>
</pre>

<p>Navigating to <code class="language-plaintext highlighter-rouge">YOUR_IP:3000</code> should lead you to a page that looks like this:</p>

<p><img src="https://gradientscience.org/assets/3db/dashboard_screenshot.png" alt="Dashboard screenshot" /></p>

<h3 id="object-detection-and-other-tasks">Object detection and other tasks</h3>

<p>In this blog post, we focused on using 3DB to analyze image classification
models. However, the library also supports object detection out-of-the-box, and
can easily be extended to support a variety of image-based tasks (e.g.,
segmentation or regression-based tasks). For example, below we provide a simple
end-to-end object detection example:</p>

<details>
<strong>Show/hide code and instructions</strong>
<div class="code-container">
    <input id="objdet-tab1" type="radio" checked="" name="objdet-tab" class="tab1" />
    <label for="objdet-tab1"><i class="fa fa-gear"></i>  Setup</label>
    <input id="objdet-tab2" type="radio" name="objdet-tab" class="tab2" />
    <label for="objdet-tab2"><i class="fa fa-code"></i>  Config (part_of_object.yaml)</label>
    <div class="line"></div>
    <div class="line"></div>
    <div class="content-container">
<div class="content c1"><pre class="wrapped"><code class="makefile">
# The object detection example is separate from the rest of the blog demo, so
# run the following in a separate repo:
git clone https://github.com/3db/object_detection_demo

# The repo has a data/ folder containing the Blender model (a banana) and some
# HDRI backgrounds, a classmap.json file mapping the UID of the model to a COCO
# class, and the detection.yaml file from the next pane.
cd object_detection_demo/

export BLENDER_DATA=data/
export RESULTS_FOLDER=results/

# Run 3DB
threedb_workers 1 $BLENDER_DATA 5555 &gt; client.log &amp; 
threedb_master $BLENDER_DATA detection.yaml $RESULTS_FOLDER 5555

# Analyze results in the dashboard
python -m threedboard $RESULTS_FOLDER --port 3000
# Navigate to localhost:3000 to view the results!

</code></pre></div> 
<div class="content c2"><pre><code class="YAML">
inference:
  module: 'torchvision.models.detection'
  class: 'retinanet_resnet50_fpn'
  label_map: './resources/coco_mapping.json'
  normalization:
    mean: [0., 0., 0.]
    std: [1., 1., 1.]
  resolution: [224, 224]
  args:
    pretrained: True
evaluation:
  module: 'threedb.evaluators.detection'
  args:
    iou_threshold: 0.5
    nms_threshold: 0.1
    max_num_boxes: 10
    classmap_path: 'classmap.json'
render_args:
  engine: 'threedb.rendering.render_blender'
  resolution: 256
  samples: 16
  with_segmentation: true
policy:
  module: "threedb.policies.random_search"
  samples: 2
logging:
  logger_modules:
    - "threedb.result_logging.image_logger"
    - "threedb.result_logging.json_logger"
controls:
  - module: "threedb.controls.blender.orientation"
  - module: "threedb.controls.blender.camera"
    zoom_factor: [0.7, 1.3]
    aperture: 8.
    focal_length: 50.
  - module: "threedb.controls.blender.denoiser"

</code></pre></div>
</div>
</div>
</details></div>







<p class="date">
<a href="https://gradientscience.org/3db/"><span class="datestr">at June 08, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=8127">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2021/06/07/new-seminar-series-in-simons-institute/">New seminar series in Simons Institute</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Simons institute started a <a href="https://simons.berkeley.edu/news/institute-launches-breakthroughs-lecture-series">new virtual seminar</a> series highlighting recent advances in theoretical computer science. The first two talks in the series will be:</p>



<ul><li>June 16th 10am-11am PDT (1pm-2pm EDT). Virginia Vassilevska Williams on a  <a href="https://simons.berkeley.edu/events/breakthroughs-refined-laser-method-and-faster-matrix-multiplication">Refined Laser Method and Faster Matrix Multiplication</a></li><li>August 5 10am-11am PDT (1pm-2pm EDT) Yuansi Chen on <a href="https://simons.berkeley.edu/events/breakthroughs-almost-constant-lower-bound-isoperimetric-coefficient-kls-conjecture-0">An Almost Constant Lower Bound of the Isoperimetric Coefficient in the KLS Conjecture</a></li></ul>



<p></p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2021/06/07/new-seminar-series-in-simons-institute/"><span class="datestr">at June 07, 2021 06:18 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
