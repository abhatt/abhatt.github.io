<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at June 29, 2020 10:21 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17244">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/">Taking a Problem Down a Peg</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>By blowing up its objects</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/greenelobb/" rel="attachment wp-att-17246"><img width="183" alt="" src="https://rjlipton.files.wordpress.com/2020/06/greenelobb.png?w=183&amp;h=120" class="alignright wp-image-17246" height="120" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://math.berkeley.edu/people/faculty/joshua-evan-greene">src1</a>, <a href="https://groups.oist.jp/mathprog/andrew-lobb">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Joshua Greene and Andrew Lobb <a href="https://arxiv.org/pdf/2005.09193.pdf">proved</a> last month that every <em>smooth</em> Jordan curve in the plane and real <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cleq+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \leq 1}" class="latex" title="{r \leq 1}" />, there are four points on the curve that form a rectangle with sides of ratio <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />.</p>
<p>
Today we explain how this result relates to Otto Toeplitz’s famous “square peg conjecture,” which is the case <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r = 1}" class="latex" title="{r = 1}" /> when the curve need not be smooth.</p>
<p>
We noticed this via an <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> last Thursday by Kevin Hartnett for <em>Quanta</em>. Hartnett describes this research advance as a product of the pandemic inducing them to take time for deeper reflection on fundamental problems. We wonder how much is bubbling on hard problems in our own field—this is one reason for our last post’s <a href="https://rjlipton.wordpress.com/2020/06/21/some-real-and-some-virtual-news">interest</a> in (good kinds of) “gossip.”  He also gives great diagrams for the geometrical intuition.</p>
<p>
We will portray this advance instead along lines of things we’ve said recently about how to attack hard problems by seeking and solving simpler ones or special cases as stepping stones. Dick wrote a <a href="https://rjlipton.wordpress.com/2018/10/21/the-inscribed-square-problem/">post</a> two years ago on the original Toeplitz problem, which this work still leaves open. That post focused on ways general Jordan curves can be nasty. This one needs an extra niceness condition but proves a stronger result for all <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" />. How much can progress on “nice” inform problems with “nasty”? That kind of question comes up in complexity theory all the time.</p>
<p>
</p><p></p><h2> Pegging Rectangles </h2><p></p>
<p></p><p>
A <em>Jordan curve</em> is the image of a continuous 1-1 map <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> from the circle to the plane. The condition of being 1-1 prevents the image from intersecting itself, so it is a single closed loop. By the Jordan curve <a href="https://en.wikipedia.org/wiki/Jordan_curve_theorem">theorem</a>, the loop always partitions the rest of the plane into two connected regions, exactly one of which is bounded. Amazingly, a Jordan curve <a href="https://en.wikipedia.org/wiki/Osgood_curve">can</a> have positive Lebesgue measure, yet cannot fill all of <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BR%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{R}^2}" class="latex" title="{\mathbb{R}^2}" />. Such curves can, however, approach the kind of space-filling curves defined by Giuseppe Peano, and thus have any Lebesgue density less than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />, as was noted also by William Osgood in his 1903 <a href="https://www.jstor.org/stable/pdf/1986455.pdf">paper</a>.</p>
<p>
The Toeplitz conjecture is that every Jordan curve has four points that form a square. As noted in Dick’s post, the positive-area case is actually an easy yes-case. Nasty cases are where the curve is nowhere-differentiable with zero area. Thus far, the problem has been answered <em>yes</em> only in the presence of some uniformity condition that limits the local nastiness of the curve. The simplest one is for the curve to be <em>smooth</em> in that <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> has a continuous first derivative. Here is a smooth curve that is not convex, so that the square need not be “inside” the curve:</p>
<p></p><p></p>
<p><a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/matschkefig2/" rel="attachment wp-att-17247"><img src="https://rjlipton.files.wordpress.com/2020/06/matschkefig2.jpg?w=600" alt="" class="aligncenter size-full wp-image-17247" /></a></p>
<p>
This diagram is from Benjamin Matchske’s wonderful recent <a href="https://www.ams.org/notices/201404/rnoti-p346.pdf">survey</a> of the peg problem in the <em>AMS Notices</em>. Four months ago we’d have said it looks like a thin heart or fat boomerang. <i>Now</i> it looks to us like a face mask.</p>
<p>
As the survey notes, it is easy to show that every Jordan curve has <em>some</em> rectangle. The rectangle problem is to show that rectangles of <i>every</i> aspect ratio <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> can be pegged to the curve. There are two main reasons the square and rectangle problems are hard and harder:</p>
<ol>
<li>
Although any Jordan curve can be written as a limit of nice ones, the squares in the nice ones can degenerate to a single point in the limit. <p></p>
</li><li>
Even for nice curves, a parity property that holds for squares can fail for rectangles.
</li></ol>
<p>
The property in the second point enables arguments of the kind: <em>for generic curves the number of squares is odd, therefore it is nonzero</em>. This then carries over to sufficiently nice curves in the generic closure. The failure of this property for rectangles is a main reason the results by Greene and Lobb are new.</p>
<p>
</p><p></p><h2> The Paper </h2><p></p>
<p></p><p>
The new paper is written tersely at a high level, and we must confess not being able to catch all details in compressed time. But we can highlight some aspects of the argument. First, as we have said, it exemplifies:</p>
<ul>
<li>
<em>Solve a Simpler Problem</em>.
</li></ul>
<p>
This is however coupled with a second aspect:</p>
<ul>
<li>
<em>Bring Up the Reserves</em>.
</li></ul>
<p>
It may be that the rectangle conjecture is not only true but “equally true” in the sense that the fundamental reason applies equally well to the case of rectangles. The parity argument that works for cases involving squares may be a crutch that misses the deepest explanations. Promoting arguments that avoid this crutch may marshal resources needed to make a breakthrough on the main problem for completely general Jordan curves.</p>
<p>
This runs somewhat counter to what we have said about <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> versus <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P}}" class="latex" title="{\mathsf{P}}" /> proof attempts recently. The reason for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P &lt; NP}}" class="latex" title="{\mathsf{P &lt; NP}}" /> believed by most is that problems like SAT require <em>exponential</em> time, not just super-polynomial time. Yet no one knows even a <em>super-linear</em> lower bound, apart from barely-superlinear bounds that exploit grainy aspects of the multitape Turing machine model and apply only to it. Nor is any super-linear lower bound known on Boolean circuit size. Maybe it is a viable strategy also to “bring up reserves” by finding restricted cases where (conditional) exponential lower bounds can be proven, as well as to explore contingencies like <a href="https://en.wikipedia.org/wiki/Exponential_time_hypothesis">SETH</a>, as we covered <a href="https://rjlipton.wordpress.com/2015/06/01/puzzling-evidence/">here</a>. But both of use have always felt that the super-linear frontier holds the buried keys to further progress.</p>
<p>
The Greene-Lobb proof has two aspects that may also resonate in complexity:</p>
<ul>
<li>
<em>Blow Up the Objects</em>.
</li></ul>
<p>
The <a href="https://www.quantamagazine.org/new-geometric-perspective-cracks-old-problem-about-rectangles-20200625/">article</a> in <em>Quanta</em> has great diagrams illustrating how the set of pairs of points on the curve corresponds to a Möbius strip in a related space. Cole Hugelmeyer, a graduate student at Princeton, <a href="https://arxiv.org/pdf/1911.07336.pdf">proved</a> last year how to get rectangles covering at least one-third of possible values <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cin+%280%2C1%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r \in (0,1]}" class="latex" title="{r \in (0,1]}" /> by embedding the Möbius strips in a four-dimensional space. Intersections between a strip and a rotated copy yield rectangles on the original Jordan curve. </p>
<p>
That led Greene and Lobb to consider larger objects with properties like pairs of Möbius strips in the larger space. The Klein bottle is the natural next thing to consider and led to a feature of their proof that made the desired conclusion pop out:</p>
<ul>
<li>
<em>Identify and Rule Out Obstructions</em>.
</li></ul>
<p>
The clever point pivots on the fact that a Klein bottle cannot be smoothly embedded into the complex plane <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BC%7D%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{C}^2}" class="latex" title="{\mathbb{C}^2}" /> as a Lagrangian submanifold. The proof shows that for any prescribed aspect ratio <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> one can construct a mapping that almost succeeds in embedding such a Klein bottle. The fact that it must fail means that the image must yield a point of intersection witnessing the failure. The presence of this point then yields the construction of four other points on the Jordan curve that form the vertices of the needed rectangle.</p>
<p>
We have briefly <a href="https://rjlipton.wordpress.com/2018/06/06/princeton-is-invariant/">mentioned</a> how the concept of <em>obstructions</em> is integral to the <a href="https://en.wikipedia.org/wiki/Geometric_complexity_theory">Geometric</a> <a href="https://dl.acm.org/doi/10.1145/1944345.1944346">Complexity</a> <a href="http://gct.cs.uchicago.edu/">Theory</a> attack on <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP+%3C+NP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P &lt; NP}}" class="latex" title="{\mathsf{P &lt; NP}}" />. Closer to home, however, is how László Babai's graph isomorphism algorithm and proof works by identifying a subclass of graphs called Johnson graphs as obstructions to a simpler algorithm, as we highlighted <a href="https://rjlipton.wordpress.com/2017/01/06/snow-and-theory/">here</a>.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Can you find more lessons from the new advance on the Toeplitz problem?  Dick and I have considered ideas of blowing up from languages to pairs of languages (and making <i>reductions</i> between problems the fundamental units of analysis) but this has not gone beyond dreamwork.</p>
<p></p></font></font></div>







<p class="date">
by KWRegan <a href="https://rjlipton.wordpress.com/2020/06/29/taking-a-problem-down-a-peg/"><span class="datestr">at June 29, 2020 09:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-7761235140481153504">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html">Can you name a famous living Chemist? Can anyone?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<br />
I was re-watching the  Greatest-of-all-time Jeopardy championship and the following happen (I paraphrase)<br />
<br />
----------------------<br />
Alex Trebek: The category is Chemistry and we have a special guest reading the clues.<br />
<br />
Darling: I wonder who that will be.<br />
<br />
Bill: Hmm. I assume some famous chemist.<br />
------------------------<br />
<br />
So who was it? Bryan Cranston, the actor who PLAYED chemist Walter White on <i>Breaking Bad.</i><br />
<br />
Why couldn't they get a famous living chemist to read the clues?<br />
<br />
My guess: there are no famous living chemists.<br />
<br />
The number of famous living scientists is fairly short and they are often known for things that are not quite their science. Some are famous because the popularize science (deGrasse Tyson, Dawkins) or because of something unusual about their life (Hawkings when he was alive) or for something else entirely that they did (Ted Kaczynski).  Are any famous for the actual work that they do in the science?<br />
<br />
Andrew Wiles was famous for a brief time, and even made People Magazine's <i>25 most intriguing people of the year</i> list in the early 1990's (after he solved Fermat's Last Theorem). So he was famous but it was short lived.<br />
<br />
Terry Tao was on the Colbert Report (see <a href="http://www.cc.com/video-clips/6wtwlg/the-colbert-report-terence-tao">here</a>) after he won the Fields Medal, the MacAuthor Genius award, and the Breakthrough prize. And even that fame was short lived.<br />
<br />
I looked at the web page of Nobel Prize winners, <a href="https://www.nobelprize.org/prizes/lists/all-nobel-prizes">here</a>.<br />
<br />
The only Chemistry Nobel's I recognized were Marie Curie,  Irene Joilet-Curie (Marie's Daughter), and Erst Rutherford.<br />
<br />
The only Physics Nobel's I recognized were<br />
<br />
Richard Feynman,<br />
<br />
 Eugene Wigner (for writing about <a href="https://www.dartmouth.edu/~matc/MathDrama/reading/Wigner.html">The unreasonable effectiveness of mathematics in the natural sciences</a>),<br />
<br />
Richard Hofstadter (since he was the father of Douglas H and an uncle of Leonard H)<br />
<br />
 Andrew Geim (since he won  both an Ig-Noble prize and a Nobel prize, see  <a href="https://blog.computationalcomplexity.org/2010/10/noble-and-ig-noble-prizes.html">here</a>)<br />
<br />
Wolfgang Pauli (I've heard the term `Pauli Principle" though I did not know what it was until I looked it up while preparing this blog. I prob still don't really know what it means.)<br />
<br />
Enrico Fermi<br />
<br />
Erwin Schrodinger<br />
<br />
Paul Dirac<br />
<br />
Robert Millikan<br />
<br />
Albert Einstein<br />
<br />
Max Karl Ernest Ludwig Planck (I thought his last name was `Institute')<br />
<br />
Johannes Diderik van der Waals<br />
<br />
Pierre Curie<br />
<br />
Marie Curie<br />
<br />
<br />
So, some questions:<br />
<br />
a) Am I wrong? Are there famous living chemists I never heard of? Are there any famous living scientists who are famous for their work in science?<br />
<br />
b) If I am right then was there ever a time when there were famous scientists?<br />
<br />
c) If there was such a time, what changed?<br />
<br />
(I ask all of this non-rhetorically and with no agenda to push.)<br />
<br />
<br />
<br />
<br />
<br /></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/06/can-you-name-famous-living-chemist-can.html"><span class="datestr">at June 29, 2020 08:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/">Postdocs &amp; PhD students in the theory of distributed &amp; parallel computing at Aalto University (apply by August 31, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The research groups of Jukka Suomela and Jara Uitto at Aalto University (Helsinki, Finland) are looking for several postdoctoral researchers and/or doctoral students to work on the foundations of distributed and parallel computing.</p>
<p>Website: <a href="https://research.cs.aalto.fi/da/jobs/">https://research.cs.aalto.fi/da/jobs/</a><br />
Email: jukka.suomela@aalto.fi and jara.uitto@aalto.fi</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/06/29/postdocs-phd-students-in-the-theory-of-distributed-parallel-computing-at-aalto-university-apply-by-august-31-2020/"><span class="datestr">at June 29, 2020 04:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://benjamin-recht.github.io/2020/06/29/tour-revisited/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/recht.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://benjamin-recht.github.io/2020/06/29/tour-revisited/">What We've Learned to Control</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>I’m giving a keynote address at the <a href="https://www.ifac2020.org/">virtual IFAC congress this July</a>, and I submitted an abstract that forces me to reflect on the current state of research at the intersection of machine learning and control. 2020 is particularly appropriate for reflection: For personal reasons, I’ve been working in this space for about half a decade now and <a href="https://www.argmin.net/2018/06/25/outsider-rl/">wrote a blog series on the topic two years ago</a> and it seemed like ideal timing. For the broader community, 2020 happens to be the year we were promised fleets of self-driving cars. Of course, for a myriad of reasons, we’re nowhere close to achieving this goal. Full self-driving has been a key motivator of work in learning-enabled autonomous systems, and it’s important to note this example as a marker of how difficult problems this space really are.</p>

<p>The research community has come to terms with this difficulty, and has committed itself to address the many pressing challenges. Over the last year I attended several great meetings on this topic, including an <a href="https://ajwagen.github.io/adsi_learning_and_control/">NSF funded workshop at UW</a>, a plenary session at <a href="https://ita.ucsd.edu/ws/">ITA</a>, a workshop on intersections of <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">learning, control, and optimization at IPAM</a>, and the <a href="https://sites.google.com/berkeley.edu/l4dc/home">second annual conference on Learning for Dynamics and Control</a>. There is clearly a ton of enthusiasm from researchers in a many different disciplines, and we’re seeing fascinating results mixing techniques from machine learning, computer science, and control. Obviously, I’m going to be leaving out many incredible papers, but, focusing on the theoretical end of the spectrum, perhaps I could highlight <a href="https://arxiv.org/abs/1912.11899">new work on policy optimization</a> that demonstrates how simple optimization techniques can efficiently solve classic, nonconvex control-design problems or <a href="https://arxiv.org/abs/1902.08721">work connecting regret minimization and adaptive control</a> that provides nonasymptotic bounds.</p>

<p>This work has been very useful for establishing language to bridge communication between the diverse research camps interested in the space of learning, dynamics and automation. But, as I’ll discuss shortly, I’d argue that it hasn’t provided many promising approaches to improving large-scale autonomy. That’s ok! These problems are incredibly difficult and aren’t going to be solved by wishing for them to be solved. But I also think it might be worth taking a moment to reflect on which problems we are working on. It’s always a bit too easy for theorists to focus  on improving technical results and lose sight of why someone proved those results in the first place.</p>

<p>As an illustrative example, my research group spent a lot of time studying the <a href="http://www.argmin.net/2018/02/08/lqr/">Linear Quadratic Regulator</a> (LQR). The point of this work was initially to establish baselines: LQR has a closed form solution when the model is known, so we wanted to understand how different algorithms might perform when the underlying model was unknown. It turns out that if you are willing to collect enough data, the best thing you can do for LQR is <a href="https://arxiv.org/abs/1902.07826">estimate the dynamical model, and then exploit this model as if it were true</a>. This so-called “certainty equivalent control” is what practitioners have been doing since the mid-60s to fly satellites and solve other optimal control problems. Proving this result required a bunch of new mathematical insights that established connections between high dimensional statistics and automatic control theory. But it did not bring us closer to solving new challenges in robotics or autonomous systems. Our work here merely showed that what the controls community had been doing for 50 years was already about as well as we could do for this important baseline problem.</p>

<p>So what are the ways forward? Are there things that theory-minded folks can work on short term that might help us understand paths towards improving learning systems in complex feedback loops? Let me suggest a few challenges that I see as both very pressing, but also ones where we might be able to make near-term progress.</p>

<h2 id="machine-learning-is-still-not-reliable-technology">Machine Learning is still not reliable technology</h2>

<p>At the aforementioned <a href="https://www.ipam.ucla.edu/programs/workshops/intersections-between-control-learning-and-optimization/?tab=overview">IPAM meeting</a>, Richard Murray gave a <a href="https://www.youtube.com/watch?v=Wi8Y---ce28">fantastic survey of the sorts of standards of reliability imposed in aerospace engineering</a>. Go watch it! I don’t want to spoil it for you, but his discussion of Ram Air Turbines is gripping. Richard covers what is needed to get to the sorts of reliability we’d like in autonomous systems. Unfortunately, having <a href="https://arxiv.org/abs/2003.08237">88.5% Top-1 accuracy on ImageNet</a>—while a stunning achievement—doesn’t tell us how to get to systems with failure rates on the order of 1 in a billion. As Boeing has tragically shown, cutting corners on autonomous system safety standards has horrible, tragic consequences.</p>

<p>How can we make machine learning more robust? How can we approach the failure rates needed for safe, reliable autonomy? And how can we establish testing protocols to assure we have such low failure rates?</p>

<h2 id="prediction-systems-in-feedback-loops">Prediction systems in feedback loops</h2>

<p>One particular aspect that I think is worth considering is how supervised learning systems can function as “sensors” in feedback loops. Even if you know everything about a dynamical system, when you observe the state via an estimator generated by a learned component, it’s not clear how to best take action on this observation. Most classic control and planning assumes that your errors in state-estimation are Gaussian or nicely uniformly bounded. Of course, the errors from machine learning systems are neither of these (I recommend checking out the <a href="https://youtu.be/A0cb7wZVFf4">crazy videos</a> of the <a href="https://twitter.com/greentheonly/status/1130956365063761920">confusion</a> that comes out of Tesla Autopilot’s vision systems). How to properly characterize the errors of machine learning systems for control applications seems like a useful, understudied problem. Using off-the-shelf machine learing analysis, it’s unavoidable to have to densely sample all of the possible scenarios in advance in order to guarantee the sort of uniform error bounds desired by control algorithms. This isn’t practical, and, indeed, it’s clear that this sort of sensor characterization is not needed to make reasonable demos work. Though it’s a bit mundane, I think a huge contribution lies in understanding how much data we need to quantify the uncertainty in learned perception components. It’s still not clear to me if this is a machine learning question or a closed-loop design question, and I suspect both views of the problem will be needed to make progress.</p>

<h2 id="why-are-we-all-sleeping-on-model-predictive-control">Why are we all sleeping on model predictive control?</h2>

<p>I still remain baffled by how <a href="http://www.argmin.net/2018/05/02/adp/">model predictive control</a> (MPC) is consistently under appreciated. We’ll commonly see the same tasks in the same meeting, one task done on a robot using some sort of deep reinforcement learning and the other done using model predictive control, and the disparity in performance is stark. It’s like the difference between watching an Olympic level sprinter and me jogging in my neighborhood with a set of orthotics.</p>

<p>Here’s an example from the IPAM workshop. Martin Riedmiller presented work at DeepMind to catch a ball in a cup:</p>



<p>This system uses two cameras, has a rather large “cup,” (it’s a wastepaper basket) and yet still takes 3 days to train on the robot. Francesco Borrelli presented a different approach. Using only a single camera and basic, simple Newtonian physics, and MPC they were able to achieve this performance on the standard-sized “ball-in-a-cup” toy:</p>



<p>If you only saw these two videos, I can’t fathom why would you invest all of your assets into deep RL. I understand there are still a lot of diehards out there, and I know this will offend them. But I want to make a constructive point: so many theorists are spending a lot of time studying RL algorithms, but few in the ML community are analyzing MPC and why it’s so successful. We should rebalance our allocation of mental resources!</p>

<p>Now, while the basic idea of MPC is very simple, the theory gets very hairy very quickly. It definitely takes some time and effort to learn about how to prove convergence of MPC protocols. I’d urge the MPC crowd to connect more with the learning theory crowd to see if a common ground can be found to better understand how MPC works and how we might push its performance even farther.</p>

<h2 id="perhaps-we-should-stop-taking-cues-from-alphago">Perhaps we should stop taking cues from AlphaGo?</h2>

<p>One of the grand goals in RL is to use function approximation algorithms to estimate value functions. The conventional wisdom asserts that the world is a giant Markov Decision Process and once you have its value function, you can just greedily maximize it and you’ll win at life. Now, this sort of approach clearly doesn’t work for robots, and I’m perplexed by why people still think it will work at all. Part of the motivation is that this approach was used to solve Go. But at some point I think we all have to come to terms with the fact that games are not the real world.</p>

<p>Now, I’d actually argue that RL <em>does</em> work in the real world, but it’s in systems that most people don’t actively think of as RL systems. Greedy value function estimation and exploitation is <em>literally</em> how all internet revenue is made. Systems simply use past data to estimate value functions and then choose the action that maximizes the value at the next step. Though seldom described as such, these are instances of the “greedy contextual bandit” algorithm, and this algorithm makes tech companies tons of money. But many researchers have also pointed out that this algorithm leads to misinformation, polarization, and radicalization.</p>

<p>Everyone tries to motivate RL by the success of AlphaGo, but they should be using the success of Facebook and Google instead. And if they did this, I think it would be a lot more clear why RL is terrifying and dangerous, and one whose limitations we desperately need to understand so that we can build safer tools.</p>

<h2 id="lessons-from-the-70s-about-optimal-control">Lessons from the 70s about optimal control</h2>

<p>I have one set of ideas along these lines that, while I think is important, I still am having a hard time articulating. Indeed, I might just take a few blog posts to work through my thoughts on this, but let me close this blog with a teaser of discussions to come. As I mentioned above, optimal control was a guiding paradigm for a variety of control applications in the 60s and 70s. During this time, it seemed like there might even be hidden benefits to a full-on optimization paradigm: though you’d optimize a single, simple objective, you would often get additional robustness guarantees for free. However, it turned out that this was very misleading and that <a href="https://ieeexplore.ieee.org/document/1101812">there were no guarantees of robustness even for simple optimal control problems</a>. This shouldn’t be too surprising, as if you devote a lot of resources towards one objective, you are likely neglecting some other objective. But showing how and why these fragilities arise is quite delicate. It’s not always obvious how you <em>should</em> be devoting your resources.</p>

<p>Trying to determine how to allocate engineering resources to balance safety and performance is the heart of “robust control.” One thing I’m fascinated by moving forward is if any of the early developments in robust control might transfer over for a new kind of “robust ML.” Unfortunately for all of us, robust control is a rather encrypted literature. There is a lot of mathematics, but often not clear statements about <em>why</em> we study particular problems or what are the fundamental limits of feedback. While diligent young learning theorists have been scouring classic control theory text books for insights, these books don’t always articulate what we can and cannot do and what are the problems that control theory might help solve. We still have a lot of work to do in communicating what we know and what problems remain challenging. I think it would be useful for control theorists to think of how to best communicate the fundamental concepts of robust control. I hope to take up this challenge in the next few months on this blog.</p>

<p><em>I’d like to thank Sarah Dean, Horia Mania, Nik Matni, and Ludwig Schmidt for their helpful feedback on this post. I’d also like to thank John Doyle for several inspiring conversations about robustness in optimal control and on the encrypted state of the control theory literature.</em></p></div>







<p class="date">
<a href="http://benjamin-recht.github.io/2020/06/29/tour-revisited/"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15089">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15089">Cutting Polygons into Small Pieces with Chords: Laser-Based Localization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Arkin:Esther_M=.html">Esther M. Arkin</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Das:Rathish.html">Rathish Das</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gao:Jie.html">Jie Gao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Goswami:Mayank.html">Mayank Goswami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mitchell:Joseph_S=_B=.html">Joseph S. B. Mitchell</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Polishchuk:Valentin.html">Valentin Polishchuk</a>, Csaba D. Toth <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15089">PDF</a><br /><b>Abstract: </b>Motivated by indoor localization by tripwire lasers, we study the problem of
cutting a polygon into small-size pieces, using the chords of the polygon.
Several versions are considered, depending on the definition of the "size" of a
piece. In particular, we consider the area, the diameter, and the radius of the
largest inscribed circle as a measure of the size of a piece. We also consider
different objectives, either minimizing the maximum size of a piece for a given
number of chords, or minimizing the number of chords that achieve a given size
threshold for the pieces. We give hardness results for polygons with holes and
approximation algorithms for multiple variants of the problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15089"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.15024">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.15024">Computing all $s$-$t$ bridges and articulation points simplified</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cairo:Massimo.html">Massimo Cairo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khan:Shahbaz.html">Shahbaz Khan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rizzi:Romeo.html">Romeo Rizzi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schmidt:Sebastian.html">Sebastian Schmidt</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomescu:Alexandru_I=.html">Alexandru I. Tomescu</a>, Elia Zirondelli <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.15024">PDF</a><br /><b>Abstract: </b>Given a directed graph $G$ and a pair of nodes $s$ and $t$, an $s$-$t$ bridge
of $G$ is an edge whose removal breaks all $s$-$t$ paths of $G$. Similarly, an
$s$-$t$ articulation point of $G$ is a node whose removal breaks all $s$-$t$
paths of $G$. Computing the sequence of all $s$-$t$ bridges of $G$ (as well as
the $s$-$t$ articulation points) is a basic graph problem, solvable in linear
time using the classical min-cut algorithm.
</p>
<p>When dealing with cuts of unit size ($s$-$t$ bridges) this algorithm can be
simplified to a single graph traversal from $s$ to $t$ avoiding an arbitrary
$s$-$t$ path, which is interrupted at the $s$-$t$ bridges. Further, the
corresponding proof is also simplified making it independent of the theory of
network flows.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.15024"><span class="datestr">at June 29, 2020 01:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14972">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14972">On 2-Clubs in Graph-Based Data Clustering: Theory and Algorithm Engineering</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Aleksander Figiel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Himmel:Anne=Sophie.html">Anne-Sophie Himmel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nichterlein:Andr=eacute=.html">André Nichterlein</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Niedermeier:Rolf.html">Rolf Niedermeier</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14972">PDF</a><br /><b>Abstract: </b>Editing a graph into a disjoint union of clusters is a standard optimization
task in graph-based data clustering. Here, complementing classic work where the
clusters shall be cliques, we focus on clusters that shall be 2-clubs, that is,
subgraphs of diameter two. This naturally leads to the two NP-hard problems
2-Club Cluster Editing (the allowed editing operations are edge insertion and
edge deletion) and 2-Club Cluster Vertex Deletion (the allowed editing
operations are vertex deletions). Answering an open question from the
literature, we show that 2-Club Cluster Editing is W[2]-hard with respect to
the number of edge modifications, thus contrasting the fixed-parameter
tractability result for the classic Cluster Editing problem (considering
cliques instead of 2-clubs). Then focusing on 2-Club Cluster Vertex Deletion,
which is easily seen to be fixed-parameter tractable, we show that under
standard complexity-theoretic assumptions it does not have a polynomial-size
problem kernel when parameterized by the number of vertex deletions.
Nevertheless, we develop several effective data reduction and pruning rules,
resulting in a competitive solver, clearly outperforming a standard CPLEX
solver in most instances of an established biological test data set.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14972"><span class="datestr">at June 29, 2020 01:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14870">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14870">Quantum Communication Complexity of Distribution Testing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Belovs:Aleksandrs.html">Aleksandrs Belovs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Castellanos:Arturo.html">Arturo Castellanos</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gall:Fran=ccedil=ois_Le.html">François Le Gall</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Malod:Guillaume.html">Guillaume Malod</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sherstov:Alexander_A=.html">Alexander A. Sherstov</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14870">PDF</a><br /><b>Abstract: </b>The classical communication complexity of testing closeness of discrete
distributions has recently been studied by Andoni, Malkin and Nosatzki
(ICALP'19). In this problem, two players each receive $t$ samples from one
distribution over $[n]$, and the goal is to decide whether their two
distributions are equal, or are $\epsilon$-far apart in the $l_1$-distance. In
the present paper we show that the quantum communication complexity of this
problem is $\tilde{O}(n/(t\epsilon^2))$ qubits when the distributions have low
$l_2$-norm, which gives a quadratic improvement over the classical
communication complexity obtained by Andoni, Malkin and Nosatzki. We also
obtain a matching lower bound by using the pattern matrix method. Let us stress
that the samples received by each of the parties are classical, and it is only
communication between them that is quantum. Our results thus give one setting
where quantum protocols overcome classical protocols for a testing problem with
purely classical samples.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14870"><span class="datestr">at June 29, 2020 01:21 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14828">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14828">Lee-Yang zeros and the complexity of the ferromagnetic Ising Model on bounded-degree graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Pjotr Buy, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Galanis:Andreas.html">Andreas Galanis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Patel:Viresh.html">Viresh Patel</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Regts:Guus.html">Guus Regts</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14828">PDF</a><br /><b>Abstract: </b>We study the computational complexity of approximating the partition function
of the ferromagnetic Ising model in the Lee-Yang circle of zeros given by
$|\lambda|=1$, where $\lambda$ is the external field of the model.
</p>
<p>Complex-valued parameters for the Ising model are relevant for quantum
circuit computations and phase transitions in statistical physics, but have
also been key in the recent deterministic approximation scheme for all
$|\lambda|\neq 1$ by Liu, Sinclair, and Srivastava. Here, we focus on the
unresolved complexity picture on the unit circle, and on the tantalising
question of what happens in the circular arc around $\lambda=1$, where on one
hand the classical algorithm of Jerrum and Sinclair gives a randomised
approximation scheme on the real axis suggesting tractability, and on the other
hand the presence of Lee-Yang zeros alludes to computational hardness.
</p>
<p>Our main result establishes a sharp computational transition at the point
$\lambda=1$; in fact, our techniques apply more generally to the whole unit
circle $|\lambda|=1$. We show #P-hardness for approximating the partition
function on graphs of maximum degree $\Delta$ when $b$, the edge-interaction
parameter, is in the interval $(0,\frac{\Delta-2}{\Delta}]$ and $\lambda$ is a
non-real on the unit circle. This result contrasts with known approximation
algorithms when $|\lambda|\neq 1$ or $b\in (\frac{\Delta-2}{\Delta},1)$, and
shows that the Lee-Yang circle of zeros is computationally intractable, even on
bounded-degree graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14828"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14798">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14798">Training Convolutional ReLU Neural Networks in Polynomial Time: Exact Convex Optimization Formulations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Ergen:Tolga.html">Tolga Ergen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pilanci:Mert.html">Mert Pilanci</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14798">PDF</a><br /><b>Abstract: </b>We study training of Convolutional Neural Networks (CNNs) with ReLU
activations and introduce exact convex optimization formulations with a
polynomial complexity with respect to the number of data samples, the number of
neurons and data dimension. Particularly, we develop a convex analytic
framework utilizing semi-infinite duality to obtain equivalent convex
optimization problems for several CNN architectures. We first prove that
two-layer CNNs can be globally optimized via an $\ell_2$ norm regularized
convex program. We then show that certain three-layer CNN training problems are
equivalent to an $\ell_1$ regularized convex program. We also extend these
results to multi-layer CNN architectures. Furthermore, we present extensions of
our approach to different pooling methods.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14798"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14733">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14733">APX-Hardness and Approximation for the k-Burning Number Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mondal:Debajyoti.html">Debajyoti Mondal</a>, N. Parthiabn, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kavitha:V=.html">V. Kavitha</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rajasingh:Indra.html">Indra Rajasingh</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14733">PDF</a><br /><b>Abstract: </b>Consider an information diffusion process on a graph $G$ that starts with
$k&gt;0$ burnt vertices, and at each subsequent step, burns the neighbors of the
currently burnt vertices, as well as $k$ other unburnt vertices. The
\emph{$k$-burning number} of $G$ is the minimum number of steps $b_k(G)$ such
that all the vertices can be burned within $b_k(G)$ steps. Note that the last
step may have smaller than $k$ unburnt vertices available, where all of them
are burned. The $1$-burning number coincides with the well-known burning number
problem, which was proposed to model the spread of social contagion. The
generalization to $k$-burning number allows us to examine different worst-case
contagion scenarios by varying the spread factor $k$.
</p>
<p>In this paper we prove that computing $k$-burning number is APX-hard, for any
fixed constant $k$. We then give an $O((n+m)\log n)$-time 3-approximation
algorithm for computing $k$-burning number, for any $k\ge 1$, where $n$ and $m$
are the number of vertices and edges, respectively. Finally, we show that even
if the burning sources are given as an input, computing a burning sequence
itself is an NP-hard problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14733"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14677">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14677">Average-case Complexity of Teaching Convex Polytopes via Halfspace Queries</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Akash.html">Akash Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Singla:Adish.html">Adish Singla</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Yue:Yisong.html">Yisong Yue</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yuxin.html">Yuxin Chen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14677">PDF</a><br /><b>Abstract: </b>We examine the task of locating a target region among those induced by
intersections of $n$ halfspaces in $\mathbb{R}^d$. This generic task connects
to fundamental machine learning problems, such as training a perceptron and
learning a $\phi$-separable dichotomy. We investigate the average teaching
complexity of the task, i.e., the minimal number of samples (halfspace queries)
required by a teacher to help a version-space learner in locating a randomly
selected target. As our main result, we show that the average-case teaching
complexity is $\Theta(d)$, which is in sharp contrast to the worst-case
teaching complexity of $\Theta(n)$. If instead, we consider the average-case
learning complexity, the bounds have a dependency on $n$ as $\Theta(n)$ for
i.i.d. queries and $\Theta(d \log(n))$ for actively chosen queries by the
learner. Our proof techniques are based on novel insights from computational
geometry, which allow us to count the number of convex polytopes and faces in a
Euclidean space depending on the arrangement of halfspaces. Our insights allow
us to establish a tight bound on the average-case complexity for
$\phi$-separable dichotomies, which generalizes the known $\mathcal{O}(d)$
bound on the average number of "extreme patterns" in the classical
computational geometry literature (Cover, 1965).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14677"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14652">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14652">Constant-Depth and Subcubic-Size Threshold Circuits for Matrix Multiplication</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parekh:Ojas.html">Ojas Parekh</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Phillips:Cynthia_A=.html">Cynthia A. Phillips</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/James:Conrad_D=.html">Conrad D. James</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Aimone:James_B=.html">James B. Aimone</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14652">PDF</a><br /><b>Abstract: </b>Boolean circuits of McCulloch-Pitts threshold gates are a classic model of
neural computation studied heavily in the late 20th century as a model of
general computation. Recent advances in large-scale neural computing hardware
has made their practical implementation a near-term possibility. We describe a
theoretical approach for multiplying two $N$ by $N$ matrices that integrates
threshold gate logic with conventional fast matrix multiplication algorithms,
that perform $O(N^\omega)$ arithmetic operations for a positive constant
$\omega &lt; 3$. Our approach converts such a fast matrix multiplication algorithm
into a constant-depth threshold circuit with approximately $O(N^\omega)$ gates.
Prior to our work, it was not known whether the $\Theta(N^3)$-gate barrier for
matrix multiplication was surmountable by constant-depth threshold circuits.
</p>
<p>Dense matrix multiplication is a core operation in convolutional neural
network training. Performing this work on a neural architecture instead of
off-loading it to a GPU may be an appealing option.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14652"><span class="datestr">at June 29, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html">Sorting with integer offsets</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>Here’s a cute exercise for the next time you’re teaching radix sorting in an algorithms class:</p>

<p>Suppose you’re given as input a set of real numbers , and an integer parameter . Describe an algorithm for sorting the  numbers  in time . You can assume that standard arithmetic operations on real numbers (including comparisons and rounding down to an integer) take constant time per operation.</p>

<p>Models of computation that mix constant-time real arithmetic and rounding operations can be problematic, as by building up and then rounding numbers with unlimited precision you can access a level of computational power beyond what actual computers can do, but I don’t think that’s a concern here. If someone wants to use bit-packing tricks to implement a crazy but fast sorting algorithm in this model, they’re beyond the level of this exercise.</p>

<p>The same method (which I’m not going to describe, to preserve its value as an exercise) more generally allows you to take as input pairs  and sort the numbers  in time  where . But it relies heavily on the fact that you’re adding integers to the ’s. For a problem that can’t be handled in this way, consider instead sorting the numbers  where we multiply instead of adding. Or, if you prefer to view this as a type of <a href="https://en.wikipedia.org/wiki/X_%2B_Y_sorting"> sorting</a> problem, take logs in your favorite base and sort the numbers . It’s not at all obvious to me whether this can be done in the same  time bound.</p>

<p>The motivation for looking at all this is <a href="https://cstheory.stackexchange.com/q/47120/95">a question about how to implement the greedy set cover quickly</a>. You can find the unweighted <a href="https://en.wikipedia.org/wiki/Set_cover_problem#Greedy_algorithm">greedy set cover</a> in linear time (linear in the sum of the sizes of the input sets; this is an exercise in CLRS), and you can approximate the weighted greedy set cover very accurately in linear time using similar ideas. If you could sort  quickly you could use the sorted order to compute the weighted greedy set cover exactly in the same time as the sorting algorithm. Which is totally useless because the greedy cover is already an approximation, so a fast and accurate approximation to the greedy cover is good enough. But I think the question of sorting  is interesting despite its uselessness in this application.</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/06/28/sorting-integer-offsets.html"><span class="datestr">at June 28, 2020 05:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14571">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14571">Sparse Convex Optimization via Adaptively Regularized Hard Thresholding</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Axiotis:Kyriakos.html">Kyriakos Axiotis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sviridenko:Maxim.html">Maxim Sviridenko</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14571">PDF</a><br /><b>Abstract: </b>The goal of Sparse Convex Optimization is to optimize a convex function $f$
under a sparsity constraint $s\leq s^*\gamma$, where $s^*$ is the target number
of non-zero entries in a feasible solution (sparsity) and $\gamma\geq 1$ is an
approximation factor. There has been a lot of work to analyze the sparsity
guarantees of various algorithms (LASSO, Orthogonal Matching Pursuit (OMP),
Iterative Hard Thresholding (IHT)) in terms of the Restricted Condition Number
$\kappa$. The best known algorithms guarantee to find an approximate solution
of value $f(x^*)+\epsilon$ with the sparsity bound of $\gamma =
O\left(\kappa\min\left\{\log \frac{f(x^0)-f(x^*)}{\epsilon},
\kappa\right\}\right)$, where $x^*$ is the target solution. We present a new
Adaptively Regularized Hard Thresholding (ARHT) algorithm that makes
significant progress on this problem by bringing the bound down to
$\gamma=O(\kappa)$, which has been shown to be tight for a general class of
algorithms including LASSO, OMP, and IHT. This is achieved without significant
sacrifice in the runtime efficiency compared to the fastest known algorithms.
We also provide a new analysis of OMP with Replacement (OMPR) for general $f$,
under the condition $s &gt; s^* \frac{\kappa^2}{4}$, which yields Compressed
Sensing bounds under the Restricted Isometry Property (RIP). When compared to
other Compressed Sensing approaches, it has the advantage of providing a strong
tradeoff between the RIP condition and the solution sparsity, while working for
any general function $f$ that meets the RIP condition.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14571"><span class="datestr">at June 28, 2020 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14552">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14552">Practical Trade-Offs for the Prefix-Sum Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pibiri:Giulio_Ermanno.html">Giulio Ermanno Pibiri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Venturini:Rossano.html">Rossano Venturini</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14552">PDF</a><br /><b>Abstract: </b>Given an integer array A, the prefix-sum problem is to answer sum(i) queries
that return the sum of the elements in A[0..i], knowing that the integers in A
can be changed. It is a classic problem in data structure design with a wide
range of applications in computing from coding to databases. In this work, we
propose and compare several and practical solutions to this problem, showing
that new trade-offs between the performance of queries and updates can be
achieved on modern hardware.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14552"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14449">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14449">Augmenting the Algebraic Connectivity of Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Bogdan-Adrian Manghiuc, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Peng:Pan.html">Pan Peng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:He.html">He Sun</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14449">PDF</a><br /><b>Abstract: </b>For any undirected graph $G=(V,E)$ and a set $E_W$ of candidate edges with
$E\cap E_W=\emptyset$, the $(k,\gamma)$-spectral augmentability problem is to
find a set $F$ of $k$ edges from $E_W$ with appropriate weighting, such that
the algebraic connectivity of the resulting graph $H=(V,E\cup F)$ is least
$\gamma$. Because of a tight connection between the algebraic connectivity and
many other graph parameters, including the graph's conductance and the mixing
time of random walks in a graph, maximising the resulting graph's algebraic
connectivity by adding a small number of edges has been studied over the past
15 years.
</p>
<p>In this work we present an approximate and efficient algorithm for the
$(k,\gamma)$-spectral augmentability problem, and our algorithm runs in
almost-linear time under a wide regime of parameters. Our main algorithm is
based on the following two novel techniques developed in the paper, which might
have applications beyond the $(k,\gamma)$-spectral augmentability problem.
</p>
<p>(1) We present a fast algorithm for solving a feasibility version of an SDP
for the algebraic connectivity maximisation problem from [GB06]. Our algorithm
is based on the classic primal-dual framework for solving SDP, which in turn
uses the multiplicative weight update algorithm. We present a novel approach of
unifying SDP constraints of different matrix and vector variables and give a
good separation oracle accordingly.
</p>
<p>(2) We present an efficient algorithm for the subgraph sparsification
problem, and for a wide range of parameters our algorithm runs in almost-linear
time, in contrast to the previously best known algorithm running in at least
$\Omega(n^2mk)$ time [KMST10]. Our analysis shows how the randomised BSS
framework can be generalised in the setting of subgraph sparsification, and how
the potential functions can be applied to approximately keep track of different
subspaces.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14449"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14403">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14403">Approximation Algorithms for Clustering with Dynamic Points</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Deng:Shichuan.html">Shichuan Deng</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Jian.html">Jian Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rabani:Yuval.html">Yuval Rabani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14403">PDF</a><br /><b>Abstract: </b>In many classic clustering problems, we seek to sketch a massive data set of
$n$ points in a metric space, by segmenting them into $k$ categories or
clusters, each cluster represented concisely by a single point in the metric
space. Two notable examples are the $k$-center/$k$-supplier problem and the
$k$-median problem. In practical applications of clustering, the data set may
evolve over time, reflecting an evolution of the underlying clustering model.
In this paper, we initiate the study of a dynamic version of clustering
problems that aims to capture these considerations. In this version there are
$T$ time steps, and in each time step $t\in\{1,2,\dots,T\}$, the set of clients
needed to be clustered may change, and we can move the $k$ facilities between
time steps. More specifically, we study two concrete problems in this
framework: the Dynamic Ordered $k$-Median and the Dynamic $k$-Supplier problem.
We first consider the Dynamic Ordered $k$-Median problem, where the objective
is to minimize the weighted sum of ordered distances over all time steps, plus
the total cost of moving the facilities between time steps. We present one
constant-factor approximation algorithm for $T=2$ and another approximation
algorithm for fixed $T \geq 3$. Then we consider the Dynamic $k$-Supplier
problem, where the objective is to minimize the maximum distance from any
client to its facility, subject to the constraint that between time steps the
maximum distance moved by any facility is no more than a given threshold. When
the number of time steps $T$ is 2, we present a simple constant factor
approximation algorithm and a bi-criteria constant factor approximation
algorithm for the outlier version, where some of the clients can be discarded.
We also show that it is NP-hard to approximate the problem with any factor for
$T \geq 3$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14403"><span class="datestr">at June 28, 2020 11:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14312">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14312">New Approximations and Hardness Results for Submodular Partitioning Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Santiago:Richard.html">Richard Santiago</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14312">PDF</a><br /><b>Abstract: </b>We consider the following class of submodular k-multiway partitioning
problems: (Sub-$k$-MP) $\min \sum_{i=1}^k f(S_i): S_1 \uplus S_2 \uplus \cdots
\uplus S_k = V \mbox{ and } S_i \neq \emptyset \mbox{ for all }i\in [k]$. Here
$f$ is a non-negative submodular function, and $\uplus$ denotes the union of
disjoint sets. Hence the goal is to partition $V$ into $k$ non-empty sets
$S_1,S_2,\ldots,S_k$ such that $\sum_{i=1}^k f(S_i)$ is minimized. These
problems were introduced by Zhao et al. partly motivated by applications to
network reliability analysis, VLSI design, hypergraph cut, and other
partitioning problems.
</p>
<p>In this work we revisit this class of problems and shed some light onto their
hardness of approximation in the value oracle model. We provide new
unconditional hardness results for Sub-$k$-MP in the special settings where the
function $f$ is either monotone or symmetric. For symmetric functions we show
that given any $\epsilon &gt; 0$, any algorithm achieving a $(2 -
\epsilon)$-approximation requires exponentially many queries in the value
oracle model. For monotone objectives we show that given any $\epsilon &gt; 0$,
any algorithm achieving a $(4/3 - \epsilon)$-approximation requires
exponentially many queries in the value oracle model.
</p>
<p>We then extend Sub-$k$-MP to a larger class of partitioning problems, where
the functions $f_i(S_i)$ can now be all different, and there is a more general
partitioning constraint $ S_1 \uplus S_2 \uplus \cdots \uplus S_k \in
\mathcal{F}$ for some family $\mathcal{F} \subseteq 2^V$ of feasible sets. We
provide a black box reduction that allows us to leverage several existing
results from the literature; leading to new approximations for this class of
problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14312"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14309">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14309">Reconfiguration of Spanning Trees with Many or Few Leaves</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bousquet:Nicolas.html">Nicolas Bousquet</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ito:Takehiro.html">Takehiro Ito</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kobayashi:Yusuke.html">Yusuke Kobayashi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mizuta:Haruka.html">Haruka Mizuta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ouvrard:Paul.html">Paul Ouvrard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suzuki:Akira.html">Akira Suzuki</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wasa:Kunihiro.html">Kunihiro Wasa</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14309">PDF</a><br /><b>Abstract: </b>Let $G$ be a graph and $T_1,T_2$ be two spanning trees of $G$. We say that
$T_1$ can be transformed into $T_2$ via an edge flip if there exist two edges
$e \in T_1$ and $f$ in $T_2$ such that $T_2= (T_1 \setminus e) \cup f$. Since
spanning trees form a matroid, one can indeed transform a spanning tree into
any other via a sequence of edge flips, as observed by Ito et al.
</p>
<p>We investigate the problem of determining, given two spanning trees $T_1,T_2$
with an additional property $\Pi$, if there exists an edge flip transformation
from $T_1$ to $T_2$ keeping property $\Pi$ all along.
</p>
<p>First we show that determining if there exists a transformation from $T_1$ to
$T_2$ such that all the trees of the sequence have at most $k$ (for any fixed
$k \ge 3$) leaves is PSPACE-complete.
</p>
<p>We then prove that determining if there exists a transformation from $T_1$ to
$T_2$ such that all the trees of the sequence have at least $k$ leaves (where
$k$ is part of the input) is PSPACE-complete even restricted to split,
bipartite or planar graphs. We complete this result by showing that the problem
becomes polynomial for cographs, interval graphs and when $k=n-2$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14309"><span class="datestr">at June 28, 2020 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14298">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14298">An Efficient, Practical Algorithm and Implementation for Computing Multiplicatively Weighted Voronoi Diagrams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Held:Martin.html">Martin Held</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lorenzo:Stefan_de.html">Stefan de Lorenzo</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14298">PDF</a><br /><b>Abstract: </b>We present a simple wavefront-like approach for computing multiplicatively
weighted Voronoi diagrams of points and straight-line segments in the Euclidean
plane. If the input sites may be assumed to be randomly weighted points then
the use of a so-called overlay arrangement [Har-Peled&amp;Raichel, Discrete Comput.
Geom. 53:547-568, 2015] allows to achieve an expected runtime complexity of
$O(n\log^4 n)$, while still maintaining the simplicity of our approach. We
implemented the full algorithm for weighted points as input sites, based on
CGAL. The results of an experimental evaluation of our implementation suggest
$O(n\log^2 n)$ as a practical bound on the runtime. Our algorithm can be
extended to handle also additive weights in addition to multiplicative weights,
and it yields a truly simple $O(n\log n)$ solution for solving the
one-dimensional version of this problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14298"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14182">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14182">A linear time algorithm for constructing orthogonal floor plans with minimum number of bends</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Pinki, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shekhawat:Krishnendra.html">Krishnendra Shekhawat</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14182">PDF</a><br /><b>Abstract: </b>Let G = (V, E) be a planar triangulated graph (PTG) having every face
triangular. A rectilinear dual or an orthogonal floor plan (OFP) of G is
obtained by partitioning a rectangle into \mid V \mid rectilinear regions
(modules) where two modules are adjacent if and only if there is an edge
between the corresponding vertices in G. In this paper, a linear-time algorithm
is presented for constructing an OFP for a given G such that the obtained OFP
has B_{min} bends, where a bend in a concave corner in an OFP. Further, it has
been proved that at least B_{min} bends are required to construct an OFP for G,
where \rho - 2 \leq B_{min} \leq \rho + 1 and \rho is the sum of the number of
leaves of the containment tree of G and the number of K_4 (4-vertex complete
graph) in G.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14182"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14093">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14093">A Linear-Time Algorithm for Discrete Radius Optimally Augmenting Paths in a Metric Space</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Haitao.html">Haitao Wang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Yiming.html">Yiming Zhao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14093">PDF</a><br /><b>Abstract: </b>Let $P$ be a path graph of $n$ vertices embedded in a metric space. We
consider the problem of adding a new edge to $P$ so that the radius of the
resulting graph is minimized, where any center is constrained to be one of the
vertices of $P$. Previously, the "continuous" version of the problem where a
center may be a point in the interior of an edge of the graph was studied and a
linear-time algorithm was known. Our "discrete" version of the problem has not
been studied before. We present a linear-time algorithm for the problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14093"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14059">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14059">Distance bounds for high dimensional consistent digital rays and 2-D partially-consistent digital rays</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chiu:Man=Kwun.html">Man-Kwun Chiu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Korman:Matias.html">Matias Korman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Suderland:Martin.html">Martin Suderland</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tokuyama:Takeshi.html">Takeshi Tokuyama</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14059">PDF</a><br /><b>Abstract: </b>We consider the problem of digitalizing Euclidean segments. Specifically, we
look for a constructive method to connect any two points in $\mathbb{Z}^d$. The
construction must be {\em consistent} (that is, satisfy the natural extension
of the Euclidean axioms) while resembling them as much as possible. Previous
work has shown asymptotically tight results in two dimensions with $\Theta(\log
N)$ error, where resemblance between segments is measured with the Hausdorff
distance, and $N$ is the $L_1$ distance between the two points. This
construction was considered tight because of a $\Omega(\log N)$ lower bound
that applies to any consistent construction in $\mathbb{Z}^2$.
</p>
<p>In this paper we observe that the lower bound does not directly extend to
higher dimensions. We give an alternative argument showing that any consistent
construction in $d$ dimensions must have $\Omega(\log^{1/(d-1)} N)$ error. We
tie the error of a consistent construction in high dimensions to the error of
similar {\em weak} constructions in two dimensions (constructions for which
some points need not satisfy all the axioms). This not only opens the
possibility for having constructions with $o(\log N)$ error in high dimensions,
but also opens up an interesting line of research in the tradeoff between the
number of axiom violations and the error of the construction. In order to show
our lower bound, we also consider a colored variation of the concept of
discrepancy of a set of points that we find of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14059"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14029">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14029">Small Longest Tandem Scattered Subsequences</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Russo:Lu=iacute=s_M=_S=.html">Luís M. S. Russo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Francisco:Alexandre_P=.html">Alexandre P. Francisco</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14029">PDF</a><br /><b>Abstract: </b>We consider the problem of identifying tandem scattered subsequences within a
string. Our algorithm identifies a longest subsequence which occurs twice
without overlap in a string. This algorithm is based on the Hunt-Szymanski
algorithm, therefore its performance improves if the string is not self
similar. This occurs naturally on strings over large alphabets. Our algorithm
relies on new results for data structures that support dynamic longest
increasing sub-sequences. In the process we also obtain improved algorithms for
the decremental string comparison problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14029"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14015">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14015">Vector-Matrix-Vector Queries for Solving Linear Algebra, Statistics, and Graph Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rashtchian:Cyrus.html">Cyrus Rashtchian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Hanlin.html">Hanlin Zhu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14015">PDF</a><br /><b>Abstract: </b>We consider the general problem of learning about a matrix through
vector-matrix-vector queries. These queries provide the value of
$\boldsymbol{u}^{\mathrm{T}}\boldsymbol{M}\boldsymbol{v}$ over a fixed field
$\mathbb{F}$ for a specified pair of vectors $\boldsymbol{u},\boldsymbol{v} \in
\mathbb{F}^n$. To motivate these queries, we observe that they generalize many
previously studied models, such as independent set queries, cut queries, and
standard graph queries. They also specialize the recently studied matrix-vector
query model. Our work is exploratory and broad, and we provide new upper and
lower bounds for a wide variety of problems, spanning linear algebra,
statistics, and graphs. Many of our results are nearly tight, and we use
diverse techniques from linear algebra, randomized algorithms, and
communication complexity.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14015"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2006.14009">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2006.14009">Discrepancy Minimization via a Self-Balancing Walk</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alweiss:Ryan.html">Ryan Alweiss</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Yang_P=.html">Yang P. Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sawhney:Mehtaab.html">Mehtaab Sawhney</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2006.14009">PDF</a><br /><b>Abstract: </b>We study discrepancy minimization for vectors in $\mathbb{R}^n$ under various
settings. The main result is the analysis of a new simple random process in
multiple dimensions through a comparison argument. As corollaries, we obtain
bounds which are tight up to logarithmic factors for several problems in online
vector balancing posed by Bansal, Jiang, Singla, and Sinha (STOC 2020), as well
as linear time algorithms for logarithmic bounds for the Koml\'{o}s conjecture.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2006.14009"><span class="datestr">at June 28, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-2151790274753933095">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2020/06/stoc-workshop-on-algorithms-with.html">STOC Workshop on "Algorithms with Predictions"</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The STOC workshop on Algorithms with Predictions was on Friday, and I thought it went really well!  I can't speak for my talk, but the other 3 talks (Tim Roughgarden, Edith Cohen, Ravi Kumar) were fantastic and inspiring, and I really recommend them for anyone with an interest in "Beyond Worst-Case Analysis".   <br /><br />The talks are <a href="https://www.youtube.com/watch?v=byKYJwN6XKw&amp;feature=youtu.be">all on Youtube</a>.  And the <a href="https://www.mit.edu/~vakilian/stoc-workshop.html">workshop page</a> is full of useful links and information.</div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2020/06/stoc-workshop-on-algorithms-with.html"><span class="datestr">at June 27, 2020 06:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://windowsontheory.org/?p=7756">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/wot.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://windowsontheory.org/2020/06/26/stoc-2020-slack-channel-open-from-madhur-tulsiani/">STOC 2020 slack channel open (from Madhur Tulsiani)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Madhur writes:</p>



<p>Thanks to all who participated in STOC 2020! Since the discussions on some of the topics from the business meeting, on SafeToC, and  on the papers/workshops are still ongoing, we will keep the Slack workspace open till <strong>July 31st</strong> (instead of just one week after the conference, as announced earlier). Also, if any members of the community are interested in joining the discussions, they are welcome to email us (<a>stoc2020@ttic.edu</a>) and we can send them an invitation to join the workspace.</p>



<p>Of course the organizers may not always be able to quickly respond to help messages during the next month. However, all members are welcome to participate in discussions, create new topics or channels as needed, and use the workspace as they prefer.</p>



<p>TheoryFest organization team (<a href="mailto:stoc2020@ttic.edu" target="_blank" rel="noreferrer noopener">stoc2020@ttic.edu</a>)</p></div>







<p class="date">
by Boaz Barak <a href="https://windowsontheory.org/2020/06/26/stoc-2020-slack-channel-open-from-madhur-tulsiani/"><span class="datestr">at June 27, 2020 01:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19925">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/">To cheer you up in difficult times 6:  Play Rani Sharim’s two-player games of life,  read Maya Bar-Hillel presentation on catching lies with statistics, and more.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Sorry for the long blog silence. In this post I wish to give a few links each of which probably deserves a full post. I will start with</p>
<h2>Rani Sharim’s two-player variants of John Conway’s game-of-life</h2>
<p><a href="https://ranisharim.github.io/game_of_life_2_players/">Here is a web-page</a> by a student in my “Game Theory” course where you can play several two-players variants of John Conway’s game-of-life.  (A couple of variants were considered before. See, e.g. <a href="https://arxiv.org/abs/cond-mat/0207679">this  paper</a>.)</p>
<p>I really enjoyed playing Rani’s games and it can certainly cheer you up in difficult times. Questions about the game, remarks, and suggestions for improvements and for new features, are most welcome.</p>
<h2>How to catch lies with statistics, a 2006  presentation by Maya Bar-Hillel</h2>
<p><a href="https://gilkalai.files.wordpress.com/2020/06/mayesther.png"><img src="https://gilkalai.files.wordpress.com/2020/06/mayesther.png?w=640" alt="" class="alignnone size-full wp-image-19929" /></a></p>
<p>Maya Bar-Hillel (left) and Ester Samuel-Cahn</p>
<p>Here is an interesting 2006 <a href="https://gilkalai.files.wordpress.com/2020/06/ester.ppt">power point presentation entitled <strong><em>How to detect lies with statistics</em></strong> by Maya Bar-Hillel.</a>  This was a talk given by Maya at the <a href="http://www.esterconference.huji.ac.il/">conference</a> honoring Prof. Ester Samuel- Cahn , Jerusalem, December 18-20, 2006, and it described a planned research project of Maya Bar-Hillel with Yossi Rinott, David Budescu and myself. At the end we did not pursue it, mainly because each of us was involved in various other projects (but also because we were skeptical about some aspects of it.)  Ester Samuel-Cahn (1933-2015) was a famous Israeli statistician. (Here is a <a href="http://www.sci-princess.info/archives/291">post by Yosi Levy in Hebrew</a> about the conference and about Ester.)</p>
<p>The lecture starts with “Last year, <em>Statistical Science</em> celebrated 50 years for `How to Lie with Statistics’ the book [by Durell Huff] whose title inspired this talk.”</p>
<p>And here are a few other quotes from Maya’s presentation</p>
<p>“We are not sure a general toolkit for detecting lies with statistics can be developed. Perhaps that explains why none yet exists.  We have shown just a collection of anecdotes. But they can be classified and categorized. Some do seem generalizeable, at least to some extent.”</p>
<p>and the conclusion</p>
<blockquote><p>A famous quip by Fred Mosteller: “It is easy to lie with statistics, but easier to lie without them.”</p>
<p>Likewise, we should say:  “It is possible to detect (some) lies with statistics, but easier to detect them with other means”.</p></blockquote>
<h2>New bounds for Ryser’s conjecture and related problems</h2>
<p>Peter Keevash, Alexey Pokrovskiy, Benny Sudakov, and Liana Yepremyan’s paper  <a href="https://arxiv.org/abs/2005.00526">New bounds for Ryser’s conjecture and related problems,</a> describes remarkable progress very old questions regarding transversals in Latin square.</p>
<h2>Topological Tverberg news</h2>
<p>I came across a very interesting paper <a href="https://arxiv.org/abs/2005.05251">The topological Tverberg problem beyond <span class="search-hit mathjax">prime</span> powers</a> by Florian Frick and Pablo Soberón with new bounds and a new method for topological Tverberg theorem in the non prime-power case.</p>
<h2>Jeager’s conjecture refuted</h2>
<p>A year ago I came across <a href="https://www.facebook.com/photo.php?fbid=2114324995342352&amp;set=a.507523926022475&amp;type=3&amp;theater">this cool facebook post</a> by Rupei Xu</p>
<blockquote><p>OMG! Just learned that Jaeger’s conjecture is false for every t&gt;=3. An interesting consequence of it is that a specific version of Goddyn’s conjecture on thin spanning trees is false, which shows some negative evidence that the thin spanning tree approaches may fail to lead to a constant factor approximation algorithm for ATSP!</p></blockquote>
<h2>A cool rainbow post <a href="http://matroidunion.org/?p=2541">Short rainbow cycles in graphs and matroids</a> by Tony Huynh</h2>
<h2>More on the game of life</h2>
<p>Let me mention two problems I posted 6-7 years ago about Conway’s game of life. <a href="https://mathoverflow.net/questions/132402/conways-game-of-life-for-random-initial-position" class="question-hyperlink">Conway’s game of life for random initial position</a> and <a href="https://cstheory.stackexchange.com/questions/17914/does-a-noisy-version-of-conways-game-of-life-support-universal-computation" class="question-hyperlink">Does a noisy version of Conway’s game of life support universal computation?</a></p>
<div class="left-sidebar js-pinned-left-sidebar ps-relative" id="left-sidebar">
<div class="left-sidebar--sticky-container js-sticky-leftnav"></div>
</div>
<p> </p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/06/26/to-cheer-you-up-in-difficult-times-6-play-rani-sharims-two-player-games-of-life-read-maya-bar-hillel-presentation-on-catching-lies-with-statistics-and-more/"><span class="datestr">at June 25, 2020 09:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-8890204.post-5732832478359389342">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/mitzenmacher.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://mybiasedcoin.blogspot.com/2020/06/writing-code-for-paper-note-to-students.html">Writing Code for a Paper :  A Note to Students</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
This post both relates to some of the stuff I'll be presenting at Friday's STOC workshop on Algorithms with Predictions, but is also for future students in my classes, who sometimes wonder why I have them write code on theory material.  (Somehow this might be a theme for a lecture in my grad class next semester, so maybe these are a first attempt at notes for the lecture.  Comments  and  suggestions welcome.)<br /><br />Some of the work I'm doing is looking at how queueing systems perform with various sorts of predictions on the times the jobs take.  This particular work I'm doing on my own.  (While most of my research has been and is with collaborators, and it's one of the things I enjoy about computer science -- we're a very collaborative field!, which seems to surprise many people -- I still sometimes like to do research projects on my own.  I've looked at queueing systems since my PhD thesis, and it's a bit outside the research interest of most of my collaborator pool, and it's "fun" sometimes to do my own thing.  The reason why "fun" is in quotes is described below.)  <br /><br />Often in my work in queueing I'm looking at mean-field limits (meant to model infinite systems of queues, which provides a good approximation for large finite systems under reasonable assumptions), where I can derive families of differential equations describing the system behavior.  I can also simulate the large finite system directly, and make sure the results match.  I generally do this for all of these types of papers.<br /><br />Now the numbers I get from simulating the system directly and from simulating the differential equations should match (say within 1% or so).  If they don't, something is wrong.  In an effort to avoid wrongness, I won't consider the paper ready for outside consumption until I get a match.  Unfortunately, there are three ways things can go wrong.<br /><br />1.  My simulation code for the queueing system might have bugs.<br />2.  My code to evaluate the differential equations might have bugs.<br />3.  My equations themselves might have bugs.<br /><br />And I find there are two main categories of bugs.  Sometimes the bugs are simple/standard coding mistakes -- I'm off by 1 on an index, or I cut and paste and forget to change an i++ to a j++ in one my double loops, or I type x instead of a y.  Usually it's pretty easy to find these things, although I've had times where a hidden typo took hours to find.  But sometimes the bug is a thinking mistake -- I've forgotten a subcase and so my equations aren't complete (and so my code evaluating the equations won't give the right answer), or I've not handled a subcase correctly in my simulation.  That type usually takes longer. <br /><br />Usually, the first time through, most all of these types of bugs happen -- my math is off, I've typed some stuff wrong, it can all happen.  And then, like coders everywhere, I go through and fix it.  And it's painful.  Sometimes everything goes right, a quick check or two and everything works.  For more complicated stuff, it's more time figuring out what went wrong than setting up the code to begin with.  And being the personality type to not let things sit, that can mean late nights figuring out what went wrong.<br /><br />For my talk this week, there was one last problem I wanted to include, which meant finally taking the model and writing the equations and code.  I didn't even need it for the talk, but it's also the last bit before I put a paper draft on arxiv, so taking advantage of a deadline, I figured now was the time.  Which means the last 2 days, I've spent many hours (and a late night) trying to remove the disagreements.<br /><br />On the plus side, when everything finally works, it's a wonderful feeling.  And it always makes me feel better when I have worked to verify my math this way;  this time, what kept me up well past midnight and took several hours to track down was actually a boundary case I had left out of the equations.  (I had looked at the equations over and over again without noticing I had left out the subcase;  I had to step through numbers from the differential equations one time step at a time to track down what was missing, and then the numbers told me what I had done wrong.)<br /><br />On the down side, it's work, and debugging is never particularly fun.<br /><br />For students out there, maybe I'm just explaining that I understand the pain that I am putting you through.  You may wonder why I have you do simulations that take a few hours if you do them well, but days if you don't think through the best approach.  But using programming and theory together can be powerful;  it's helped me countless times in my research.<br /><br />(Related: on theory and experiments that <a href="https://cacm.acm.org/magazines/2015/9/191184-theory-without-experiments/fulltext">I've written on before</a>, along with <a href="https://cacm.acm.org/magazines/2015/9/191183-experiments-as-research-validation/fulltext">a viewpoint by Jeffrey Ullman</a>.)<br /><br /><br /></div>







<p class="date">
by Michael Mitzenmacher (noreply@blogger.com) <a href="http://mybiasedcoin.blogspot.com/2020/06/writing-code-for-paper-note-to-students.html"><span class="datestr">at June 25, 2020 05:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=775">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2020/06/25/we-dont-need-no-education/">We don’t need no education</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Around us, educational systems whose primary emphasis is on social rather than intellectual skills are simply disintegrating.  Unequipped for content delivery, teachers spray parents with a mixture of links and credentials whose collection is a complete waste of everybody’s time.  Suggestion: What about assigning <em>homework </em>and let teachers provide <em>feedback</em>?</p>



<p>To all the school-age kids stuck at home doing some fun coding, <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwio8MDa4JvqAhWfVhUIHSAIABgQyCkwAHoECBUQBw&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DYR5ApYxkU-U&amp;usg=AOvVaw0s6Ai-o5-CNtyqFC7uHT_4">this immortal song is for you</a>.</p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2020/06/25/we-dont-need-no-education/"><span class="datestr">at June 25, 2020 10:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/">Postdoc in Experimental Algorithms at National University of Singapore (apply by August 15, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A one-year postdoc position (with a possibility of extension for another year) in experimental (/practical) algorithms is available at NUS. The position will be jointly hosted by Diptarka Chakraborty and Kuldeep S. Meel. Applications are invited from candidates who have solid background in algorithm design/formal methods, mathematics. A prior experience in programming would be a plus.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br />
Email: diptarka@comp.nus.edu.sg</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/06/25/postdoc-in-experimental-algorithms-at-national-university-of-singapore-apply-by-august-15-2020/"><span class="datestr">at June 25, 2020 06:10 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/">Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br />
Email: diptarka@comp.nus.edu.sg</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020-2/"><span class="datestr">at June 25, 2020 06:05 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/">Postdoc in TCS at National University of Singapore (apply by August 15, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A one-year postdoc position (with a possibility of extension for another year, subject to availability of fund) in theoretical computer science is available in the research group of Diptarka Chakraborty at NUS. Applications are invited from candidates who have solid background in algorithm design, computational complexity and mathematics.</p>
<p>Website: <a href="https://sites.google.com/view/diptarka/postdoc-advertisement">https://sites.google.com/view/diptarka/postdoc-advertisement</a><br />
Email: diptarka@comp.nus.edu.sg</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/06/25/postdoc-in-tcs-at-national-university-of-singapore-apply-by-august-15-2020/"><span class="datestr">at June 25, 2020 06:05 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
June 29, 2020 Virtual https://www.ideal.northwestern.edu/events/workshop-computational-vs-statistical-tradeoffs-in-network-inference/ Network models have been used as a tool to understand the role of interconnections between entities in multiple research areas like sociology, biology, meteorology, economics, and computer science. Moreover emerging technological developments allow collecting data on increasingly larger networks. This leads to both computational and statistical challenges when inferring or … <a href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/" class="more-link">Continue reading <span class="screen-reader-text">IDEAL Workshop on Computational vs Statistical Tradeoffs in Network Inference</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2020/06/24/ideal-workshop-on-computational-vs-statistical-tradeoffs-in-network-inference/"><span class="datestr">at June 24, 2020 11:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/096">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/096">TR20-096 |  On the asymptotic complexity of sorting | 

	Igor Sergeev</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We investigate the number of pairwise comparisons sufficient to sort $n$ elements chosen from a linearly ordered set. This number is shown to be $\log_2(n!) + o(n)$ thus improving over the previously known upper bounds of the form $\log_2(n!) + \Theta(n)$. The new bound is achieved by the proposed group insertion sorting algorithm.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/096"><span class="datestr">at June 24, 2020 05:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/095">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/095">TR20-095 |  On Basing Auxiliary-Input Cryptography on NP-hardness via Nonadaptive Black-Box Reductions | 

	Mikito Nanashima</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A black-box (BB) reduction is a central proof technique in theoretical computer science. However, the limitations on BB reductions have been revealed for several decades, and the series of previous work gives strong evidence that we should avoid a nonadaptive BB reduction to base cryptography on NP-hardness (e.g., Akavia et al., 2006). Then should we also give up such a familiar proof technique even for an intermediate step towards cryptography?

In this paper, we continue to explore the capability of nonadaptive BB reductions and extend our knowledge on such a central technique out of the current (worst-to-average) framework. In particular, we investigate the attempt to base weaker cryptographic notions allowed to take auxiliary-input via nonadaptive BB reductions. As a result, we prove the following theorems: (1) if we base an auxiliary-input pseudorandom generator (AIPRG) on NP-hardness via a nonadaptive BB reduction, then the polynomial hierarchy collapses; (2) if we base an auxiliary-input one-way function (AIOWF) or auxiliary-input hitting set generator (AIHSG) on NP-hardness via a nonadaptive BB reduction, then an (i.o.-)one-way function also exists based on NP-hardness (via an adaptive BB reduction).

The first result gives new evidence that nonadaptive BB reductions are insufficient to base AIPRG. The second result also yields a weaker but still surprising consequence of nonadaptive BB reductions, that is, a one-way function based on NP-hardness. In fact, the second result is interpreted as the following two opposite ways. Pessimistically, it shows that basing AIOWF or AIHSG via nonadaptive BB reductions is harder than constructing a one-way function based on NP-hardness, which can be regarded as a negative result. Note that AIHSG is a weak primitive implied even by the hardness of learning; thus, this pessimistic view gives conceptually stronger limitations than the currently known limitations on nonadaptive BB reductions. Optimistically, our result gives a new hope: a breakthrough construction of auxiliary-input primitives might also be useful to construct standard cryptographic primitives. This optimistic view enhances the significance of further investigation on constructing auxiliary-input or other intermediate cryptographic primitives instead of standard cryptographic primitives.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/095"><span class="datestr">at June 24, 2020 04:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2020/06/24/equilibrium-min-max/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2020/06/24/equilibrium-min-max/">An equilibrium in nonconvex-nonconcave min-max optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>While there has been incredible progress in convex and nonconvex minimization, a multitude of problems in ML today are in need of efficient algorithms to solve min-max optimization problems. 
 Unlike minimization, where algorithms can always be shown to converge to some local minimum, there is no notion of a local equilibrium in min-max optimization that exists for general nonconvex-nonconcave functions.
    In two recent papers, we give  two notions of local equilibria that are guaranteed to exist and efficient algorithms to compute them.
In this post we present the key ideas behind a second-order notion of local min-max equilibrium from <a href="https://arxiv.org/abs/2006.12363">this paper</a> and in the next we will talk about a different notion along with the algorithm and show its implications to GANs from <a href="https://arxiv.org/abs/2006.12376">this paper</a>.</p>

<h2 id="min-max-optimization">Min-max optimization</h2>

<p>Min-max optimization of an objective function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$</p>



<p>is a powerful framework in optimization, economics, and ML as it allows one to model learning in the presence of multiple agents with competing objectives.
In ML applications, such as <a href="https://arxiv.org/abs/1406.2661">GANs</a> and <a href="https://adversarial-ml-tutorial.org">adversarial robustness</a>, the min-max objective function may be nonconvex-nonconcave.
We know that min-max optimization is at least as hard as minimization, hence, we cannot hope to find a globally optimal solution to min-max problems for general functions.</p>

<h2 id="approximate-local-minima-for-minimization">Approximate local minima for minimization</h2>

<p>Let us first revisit the special case of minimization, where there is a natural notion of an approximate second-order local minimum.</p>

<blockquote>
  <p>$x$ is a second-order $\varepsilon$-local minimum of $\mathcal{L}:\mathbb{R}^d\rightarrow \mathbb{R}$ if
</p>
</blockquote>

<p>Now suppose we just wanted to minimize a function $\mathcal{L}$, and we start from any point which is <em>not</em> at an $\varepsilon$-local minimum of $\mathcal{L}$.
Then we can always find a direction to travel in along which either $\mathcal{L}$ decreases rapidly, or the second derivative of $\mathcal{L}$ is large.
 By searching in such a direction we can easily find a new point which has a smaller value of $\mathcal{L}$ using only local information about the gradient and Hessian of $\mathcal{L}$.
 This means that we can keep decreasing $\mathcal{L}$ until we reach an $\varepsilon$-local minimum (see <a href="https://www.researchgate.net/profile/Boris_Polyak2/publication/220589612_Cubic_regularization_of_Newton_method_and_its_global_performance/links/09e4150dd2f0320879000000/Cubic-regularization-of-Newton-method-and-its-global-performance.pdf">Nesterov and Polyak</a>,  <a href="https://dl.acm.org/doi/10.1145/3055399.3055464">here</a>,  <a href="http://proceedings.mlr.press/v40/Ge15.pdf">here</a>,  and also an earlier <a href="https://www.offconvex.org/2016/03/22/saddlepoints">blog post</a> for how to do this with only access to gradients of $\mathcal{L}$).
 If $\mathcal{L}$ is Lipschitz smooth and bounded, we will reach an $\varepsilon$-local minimum in polynomial time from any starting point.</p>

<blockquote>
  <p>Is there an analogous definition with similar properties for min-max optimization?</p>
</blockquote>

<h2 id="problems-with-current-local-optimality-notions">Problems with current local optimality notions</h2>
<p>There has been much recent work on extending theoretical results in nonconvex minimization to min-max optimization (see <a href="https://arxiv.org/abs/1906.00331">here</a>, <a href="https://papers.nips.cc/paper/9430-efficient-algorithms-for-smooth-minimax-optimization">here</a>, <a href="https://arxiv.org/pdf/1807.02629.pdf">here</a>,  <a href="https://papers.nips.cc/paper/9631-solving-a-class-of-non-convex-min-max-games-using-iterative-first-order-methods.pdf">here</a>, <a href="https://arxiv.org/abs/1910.07512">here</a>.
One way to extend the notion of local minimum to the min-max setting is to seek a solution point called a “local saddle”–a point $(x,y)$ where 1) $y$ is a local maximum for $f(x, \cdot)$ and 2) $x$ is a local minimum for $f(\cdot, y).$</p>

<p>For instance,
 this is used  <a href="https://arxiv.org/abs/1706.08500">here</a>, <a href="https://arxiv.org/pdf/1901.00838.pdf">here</a>, <a href="https://arxiv.org/pdf/1705.10461.pdf">here</a>, and <a href="http://proceedings.mlr.press/v89/adolphs19a.html">here</a>.
But, there are very simple examples of two-dimensional bounded functions where a local saddle does not exist.</p>

<blockquote>
  <p>For instance, consider $f(x,y) = sin(x+y)$ from <a href="https://arxiv.org/abs/1902.00618">here</a>. Check that none of the points on this function are simultaneously a local minimum for $x$ and local maximum for $y$.</p>
</blockquote>

<p>The fact that no local saddle exists may be surprising, since an $\varepsilon$-global solution to a min-max optimization problem <em>is</em> guaranteed to exist as long as the objective function is uniformly bounded.
Roughly, this is because, in a global min-max setting, the max-player is empowered to globally maximize the function $f(x,\cdot)$, and the min-player is empowered to minimize the “global max” function $\max_y(f(x, \cdot))$.</p>

<p>The ability to compute the global max  allows the min-player to  predict the max-player’s response.
If $x$ is a global minimum of $\max_y(f(x, \cdot))$, the min-player is aware of this fact and will have no incentive to update $x$.
On the other hand, if the min-player can only simulate the max-player’s updates locally (as in local saddle),
then the min-player may try to update her strategy even when it leads to a net increase in $f$.
This can happen because the min-player is not powerful enough to accurately simulate the max-player’s response. (See  a  <a href="https://arxiv.org/abs/1902.00618">related notion</a> of local optimality with similar issues due to vanishingly small updates.)</p>

<p>The fact that players who can only make local predictions are
unable to predict their opponents’ responses can lead to convergence problems in many popular algorithms such as<br />
gradient descent ascent (GDA). This non-convergence behavior can occur if the function has no local saddle point (e.g. the function $sin(x+y)$  mentioned above), and can even happen on some functions, like $f(x,y) = xy$ which do have a local saddle point.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/GDA_spiral_fast.gif" alt="" />
<br />
<b>Figure 1.</b> GDA spirals off to infinity from almost every starting point on the objective function $f(x,y) = xy$. 
</div>
<p><br /></p>

<h2 id="greedy-max-a-computationally-tractable-alternative-to-global-max">Greedy max: a computationally tractable alternative to global max</h2>

<p>To allow for a more stable min-player, and a more stable notion of local optimality, we would like to empower the min-player to more effectively simulate the max-player’s response. 
While the notion of global min-max does exactly this by having the min-player compute the global max function $\max_y(f(\cdot,y))$, computing the global maximum may be intractable.</p>

<p>Instead, we replace the global max function $\max_y (f(\cdot ,y))$ with a computationally tractable alternative. 
Towards this end, we restrict the max-player’s response, and the min-player’s simulation of this response, to updates which can be computed using any algorithm from a class of second-order optimization algorithms.
More specifically, we restrict the max-player to updating $y$ by traveling along continuous paths which start at the current value of $y$ and along which either $f$ is increasing or the second derivative of $f$ is positive.  We refer to such paths as greedy paths since they model a class of second-order “greedy” optimization algorithms.</p>

<blockquote>
  <p><strong>Greedy path:</strong> A unit-speed path $\varphi:[0,\tau] \rightarrow \mathbb{R}^d$ is greedy if $f$ is non-decreasing over this path, and for every $t\in[0,\tau]$
</p>
</blockquote>

<p>Roughly speaking, when restricted to updates obtained from greedy paths, the max-player will always be able to reach a point which is an approximate local maximum for $f(x,\cdot)$, although there may not be a greedy path which leads the max-player to a global maximum.</p>

<div style="text-align: center;">
<img src="http://www.offconvex.org/assets/greedy_region_omega_t.png" style="width: 400px;" alt="" /> <img src="http://www.offconvex.org/assets/global_max_path_no_axes_t.png" style="width: 400px;" alt="" /> 
<br />
 <b>Figure 2.</b> <i>Left:</i> The light-colored region $\Omega$ is reachable from the initial point $A$ by a greedy path; the dark region is not reachable. <i>Right:</i> There is always a greedy path from any point $A$ to a local maximum ($B$), but a global maximum ($C$) may not be reachable by any greedy path.
</div>
<p><br /></p>

<p>To define an alternative to $\max_y(f(\cdot,y))$, we consider the local maximum point with the largest value of $f(x,\cdot)$ attainable from a given starting point $y$ by any greedy path.
We refer to the value of $f$ at this point as the <em>greedy max function</em>, and denote this value by $g(x,y)$.</p>

<blockquote>
  <p><strong>Greedy max function:</strong> 
    $g(x,y) = \max_{z \in \Omega} f(x,z),$
where $\Omega$ is points reachable from $y$ by greedy path.</p>
</blockquote>

<h2 id="our-greedy-min-max-equilibrium">Our greedy min-max equilibrium</h2>
<p>We use the greedy max function to define a new second-order notion of local optimality for min-max optimization, which we refer to as a greedy min-max equilibrium.
Roughly speaking, we say that $(x,y)$ is a greedy min-max equilibrium if 
1) $y$ is a local maximum for $f(x,\cdot)$ (and hence the endpoint of a greedy path), and 
2) if $x$ is a local minimum of the greedy max function $g(\cdot,y)$.</p>

<p>In other words, $x$ is a local minimum of $\max_y f(\cdot, y)$ under the constraint that the maximum is computed only over the set of greedy paths starting at $y$.
Unfortunately, even if $f$ is smooth, the greedy max function may not be differentiable with respect to $x$ and may even be discontinuous.</p>

<div style="text-align: center;">
<img width="400" alt="" src="http://www.offconvex.org/assets/discontinuity2_grid_t.png" /> <img width="400" alt="" src="http://www.offconvex.org/assets/discontinuity2g_grid_t.png" /> 
<br />
 <b>Figure 3.</b> <i>Left:</i> If we change $x$ from one value $x$ to a very close value $\hat{x}$, the largest value of $f$ reachable by greedy path undergoes a discontinuous change.  <i>Right:</i>  This means the greedy max function $g(x,y)$ is discontinuous in $x$.</div>
<p><br /></p>

<p>This creates a problem, since the definition of $\varepsilon$-local minimum only applies to smooth functions.</p>

<p>To solve this problem we would ideally like to smooth $g$ by convolution with a Gaussian.
Unfortunately, convolution can cause the local minima of a function to “shift”– a point which is a local minimum for $g$ may no longer be a local minimum for the convolved version of $g$ (to see why, try convolving the function $f(x) = x - 3x I(x\leq 0) + I(x \leq 0)$ with a Gaussian $N(0,\sigma^2)$ for any $\sigma&gt;0$).
To avoid this, we instead consider a “truncated” version of $g$, and then convolve this function in the $x$ variable with a Gaussian to obtain our smoothed version of $g$.</p>

<p>This allows us to define a notion of greedy min-max equilibrium.  We say that a point $(x^\star, y^\star)$ is a greedy min-max equilibrium if $y^\star$ is an approximate local maximum of $f(x^\star, \cdot)$, and $x^\star$ is an $\varepsilon$-local minimum of this smoothed version of $g(\cdot, y^\star)$.</p>

<blockquote>
  <p><b>Greedy min-max equilibrium:</b>
$(x^{\star}, y^{\star})$ is a greedy min-max equilibrium if

 
where $S(x,y):= \mathrm{smooth}_x(\mathrm{truncate}(g(x, y))$.</p>
</blockquote>

<p>Any point which is a local saddle point (talked about earlier) also satisifeis our equilibrium conditions. The converse, however, cannot be true as a local saddle point may not always exist. Further, for compactly supported convex-concave functions a point is a greedy min-max equilibrium (in an appropriate sense) if and only if it is a global min-max point. (See Section 7 and Appendix A respectively in <a href="https://arxiv.org/abs/2006.12363">our paper</a>.)</p>

<h2 id="greedy-min-max-equilibria-always-exist-and-can-be-found-efficiently">Greedy min-max equilibria always exist! (And can be found efficiently)</h2>
<p>In <a href="https://arxiv.org/abs/2006.12363">this paper</a> we show: A greedy min-max equilibrium is always guaranteed to exist provided that $f$ is uniformly bounded with Lipschitz Hessian. We do so by providing an algorithm which converges to a greedy min-max equilibrium, and, moreover, we show that it is able to do this in polynomial time from any initial point:</p>

<blockquote>
  <p><b>Main theorem:</b> Suppose that we are given access to a smooth function $f:\mathbb{R}^d \times \mathbb{R}^d \rightarrow \mathbb{R}$ and to its gradient and Hessian.  And suppose that $f$ is unformly bounded by $b&gt;0$ and has $L$-Lipschitz Hessian.
Then given any initial point, our algorithm returns an $\varepsilon$-greedy min-max equilibrium $(x^\star,y^\star)$ of $f$ in $\mathrm{poly}(b, L, d, \frac{1}{\varepsilon})$ time.</p>
</blockquote>

<p>There are a number of difficulties that our algorithm and proof must overcome:
One difficulty in designing an algorithm is that the greedy max function may be discontinuous. 
To find an approximate local minimum of a discontinuous function, our algorithm combines a Monte-Carlo hill climbing algorithm with a <a href="https://arxiv.org/abs/cs/0408007">zeroth-order optimization version</a> of stochastic gradient descent.
Another difficulty is that, while one can easily compute a greedy path from any starting point, there may be many different greedy paths which end up at different local maxima.
Searching for the greedy path which leads to the local maximum point with the largest value of $f$ may be infeasible.
In other words the greedy max function $g$ may be intractable to compute.</p>

<div style="text-align: center;">
<img width="400" alt="" src="http://www.offconvex.org/assets/greedy_paths_no_axes_t.png" /> 
<br />
 <b>Figure 4.</b>There are many different greedy paths that start at the same point $A$.  They can end up at different local maxima ($B$, $D$), with different values of $f$.  In many cases it may be intractable to search over all these paths to compute the greedy max function.
 </div>
<p><br /></p>

<p>To get around this problem, rather than computing the exact value of $g(x,y)$, we instead compute a lower bound $h(x,y)$ for the greedy max function. Since we are able to obtain this lower bound by computing only a <em>single</em> greedy path, it is much easier to compute than greedy max function.</p>

<p>In our paper, we prove that if 1) $x^\star$ is an approximate local minimum for the this lower bound $h(\cdot, y^\star)$, and  2) $y^\star$ is a an approximate local maximum for $f(x^\star, \cdot)$, then $x^\star$ is also an approximate local minimum for the greedy max $g(\cdot, y^\star)$.
This allows us to design an algorithm which obtains a greedy min-max point by minimizing the computationally tractable lower bound $h$, instead of the greedy max function which may be intractable to compute.</p>

<h2 id="to-conclude">To conclude</h2>

<p>In this post we have shown how to extend a notion of second-order equilibrium for minimization to min-max optimization which is guaranteed to exist for any function which is bounded and Lipschitz, with Lipschitz gradient and Hessian.
We have also shown that our algorithm is able to find this equilibrium in  polynomial time from any initial point.</p>

<blockquote>
  <p>Our results do not require any additional assumptions such as convexity, monotonicity, or sufficient bilinearity.</p>
</blockquote>

<p>In an upcoming blog post we will show how one can use some of the ideas from here to obtain a new min-max optimization algorithm with applications to stably training GANs.</p></div>







<p class="date">
<a href="http://offconvex.github.io/2020/06/24/equilibrium-min-max/"><span class="datestr">at June 24, 2020 10:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/094">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/094">TR20-094 |  Is it possible to improve Yao’s XOR lemma using reductions that exploit the efficiency of their oracle? | 

	Ronen Shaltiel</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Yao's XOR lemma states that for every function $f:\set{0,1}^k \ar \set{0,1}$, if $f$ has hardness $2/3$ for $P/poly$ (meaning that for every circuit $C$ in $P/poly$, $\Pr[C(X)=f(X)] \le 2/3$ on a uniform input $X$), then the task of computing $f(X_1) \oplus \ldots \oplus f(X_t)$ for sufficiently large $t$ has hardness $\half +\epsilon$ for $P/poly$.

Known proofs of this lemma cannot achieve $\epsilon=\frac{1}{k^{\omega(1)}}$, and even for $\epsilon=\frac{1}{k}$, we do not know how to replace
$P/poly$ by AC$^0[\textsc{parity}]$ (the class of constant depth circuits with the gates $\set{\textsc{and,or,not,parity}}$ of unbounded fan-in).

Recently, Grinberg, Shaltiel and Viola (FOCS 2018) (building on a sequence of earlier works) showed that these limitations cannot be circumvented by \emph{black-box reductions}. Namely, by reductions $\Red^{(\cdot)}$ that given oracle access to a function $D$ that violates the conclusion of Yao's XOR lemma, implement a circuit that violates the assumption of Yao's XOR lemma.

There are a few known reductions in the related literature on worst-case to average case reductions that are \emph{non-black box}. Specifically, the reductions of Gutfreund, Shaltiel and Ta Shma (Computational Complexity 2007) and  Hirahara (FOCS 2018)) are ``class reductions'' that are only guaranteed to succeed when given oracle access to an oracle $D$ from some efficient class of algorithms. These works seem to circumvent some black-box impossibility results.

In this paper we extend the previous limitations of Grinberg, Shaltiel and Viola to class reductions, giving evidence that class reductions cannot yield the desired improvements in Yao's XOR lemma.  To the best of our knowledge, this is the first limitation on reductions for hardness amplification that applies to class reductions.

Our technique imitates the previous lower bounds for black-box reductions, replacing the inefficient oracle used in that proof, with an efficient one that is based on limited independence, and developing tools to deal with the technical difficulties that arise following this replacement.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/094"><span class="datestr">at June 24, 2020 05:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
