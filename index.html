<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="https://blog.ilyaraz.org/rss/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.ilyaraz.org/" title="Lullaby of Cape Cod">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at February 16, 2021 12:23 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/015">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/015">TR21-015 |  Hitting Sets for Orbits of Circuit Classes and Polynomial Families | 

	Chandan Saha, 

	Bhargav Thankey</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The orbit of an $n$-variate polynomial $f(\mathbf{x})$ over a field $\mathbb{F}$ is the set $\mathrm{orb}(f) := \{f(A\mathbf{x}+\mathbf{b}) : A \in \mathrm{GL}(n,\mathbb{F}) \ \mathrm{and} \ \mathbf{b} \in \mathbb{F}^n\}$. This paper studies explicit hitting sets for the orbits of polynomials computable by certain well-studied circuit classes. This version of the hitting set problem is interesting as $\mathrm{orb}(f)$ is a natural subset of the set of affine projections of $f$. Affine projections of polynomials computable by seemingly weak circuit classes can be quite powerful. For example, the polynomial $\mathrm{IMM}_{3,d}$ -- the $(1,1)$-th entry of a product of $d$ generic $3 \times 3$ matrices -- is computable by a constant-width read-once oblivious algebraic branching program (ROABP), yet every polynomial computable by a size-$s$ general arithmetic formula is an affine projection of $\mathrm{IMM}_{3,\mathrm{poly}(s)}$. To our knowledge, no efficient hitting set construction was known for even $\mathrm{orb}(\mathrm{IMM}_{3, d})$ before this work. 

In this work, we give efficient constructions of hitting sets for the orbits of several interesting circuit classes and polynomial families. In particular, we give quasi-polynomial time hitting sets for the orbits of:

1. Low-individual-degree polynomials computable by commutative ROABP. This implies quasi-polynomial time hitting sets for the orbits of multilinear sparse polynomials and the orbits of the elementary symmetric polynomials.

2. Multilinear polynomials computable by constant-width ROABP. This implies a quasi-polynomial time hitting set for the orbit of $\mathrm{IMM}_{3,d}$.

3. Polynomials computable by constant-depth, constant-occur formulas with low-individual-degree sparse polynomials at the leaves. This implies quasi-polynomial time hitting sets for the orbits of multilinear depth-4 circuits with constant top fan-in, and also poly-time hitting sets for the orbits of the power symmetric polynomials and the sum-product polynomials. 

4. Polynomials computable by occur-once formulas with low-individual-degree sparse polynomials at the leaves. 

We say a polynomial has low individual degree if the degree of every variable in the polynomial is at most $\mathrm{poly}(\log n)$, where $n$ is the number of variables.

The first two results are obtained by building upon the rank concentration by translation technique of [Agrawal-Saha-Saxena, STOC'13]; the second result also uses the merge-and-reduce idea from [Forbes-Shpilka, APPROX'13], [Forbes-Saptharishi-Shpilka, STOC'14]. The proof of the third result applies the algebraic independence based technique of [Agrawal-Saha-Saptharishi-Saxena, STOC'12], [Beecken-Mittmann-Saxena, ICALP'11] to reduce to the case of constructing hitting sets for orbits of sparse polynomials. A similar reduction using the Shpilka-Volkovich (SV) generator based argument in [Shpilka-Volkovich, STOC'08, APPROX-RANDOM'09] yields the fourth result. The SV generator plays an important role in all the four results.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/015"><span class="datestr">at February 16, 2021 08:54 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5330">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5330">On standing up sans backbone</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<blockquote class="wp-block-quote"><p><strong>Note:</strong> To get myself into the spirit of writing this post, tonight I watched the 2019 movie <a href="https://www.amazon.com/Mr-Jones-James-Norton/dp/B089XVJB9S/ref=sr_1_1?dchild=1&amp;keywords=Mr.+Jones+%282019%29&amp;qid=1613446265&amp;s=instant-video&amp;sr=1-1">Mr. Jones</a>, about the true story of the coverup of Stalin’s 1932-3 mass famine by <em>New York Times</em> journalist <a href="https://en.wikipedia.org/wiki/Walter_Duranty">Walter Duranty</a>.  Recommended!</p></blockquote>



<p>In my <a href="https://www.scottaaronson.com/blog/?p=5310">last post</a>, I wrote that despite all my problems with Cade Metz’s <em>New York Times</em> hit piece on Scott Alexander, I’d continue talking to journalists—even Metz himself, I added, assuming he’d still talk to me after my public disparagement of his work.  Over the past few days, though, the many counterarguments in this comments section and elsewhere gradually caused me to change my mind.  I now feel like to work with Metz again, even just on some quantum computing piece, would be to reward—and to be seen as rewarding—journalistic practices that are making the world worse, and that this consideration overrides even my extreme commitment to openness.</p>



<p>At the least, before I could talk to Metz again, I’d need a better understanding of how the hit piece happened.  What was the role of the editors?  How did the original hook—namely, the rationalist community’s early rightness about covid-19—disappear entirely from the article?  How did the piece manage to evince so little <em>curiosity</em> about such an unusual subculture and such a widely-admired writer?  How did it fail so completely to engage with the rationalists’ ideas <em>as ideas</em>, instead jumping immediately to “six degrees of Peter Thiel” and other reductive games?  How did an angry SneerClubber, David Gerard, end up (according to <a href="https://twitter.com/davidgerard/status/1360735880466604040">his own boast</a>) basically dictating the NYT piece’s content?</p>



<p>It’s always ripping-off-a-bandage painful to admit when trust in another person was wildly misplaced—for then who<em> else</em> shouldn’t we trust?  But sometimes that’s the truth of it.</p>



<p>I continue to believe passionately in the centrality of good journalism to a free society.  I’ll continue to talk to journalists often, about quantum computing or whatever else.  I also recognize that the NYT is a large, heterogeneous institution (I myself <a href="https://www.nytimes.com/2011/12/06/science/scott-aaronson-quantum-computing-promises-new-insights.html">published</a> in it <a href="https://www.nytimes.com/2019/10/30/opinion/google-quantum-computer-sycamore.html">twice</a>); it’s not hard to imagine that many of its own staff take issue with the SSC piece.</p>



<p>But let’s be clear about the stakes here.  In the discussion of my last post, I <a href="https://www.scottaaronson.com/blog/?p=5310#comment-1878641">described</a> the NYT as “still the main vessel of consensus reality in human civilization.”  What’s really at issue, beyond the treatment of a single blogger, is whether the NYT can continue serving that central role in a world reshaped by social media, resurgent fascism, and entitled wokery.</p>



<p>Sure, we all know that the NYT has been disastrously wrong before: it ridiculed Goddard’s dream of spaceflight, denied the Holodomor, relegated the Holocaust to the back pages while it was happening, published the fabricated justifications for the Iraq War.  But the NYT and a few other publications were still the blockchain of reality, the engine of the consensus of all that is, the last bulwark against the conspiracists and the anti-vaxxers and the empowered fabulists and the horned insurrectionists storming the Capitol, because there was no ability to coordinate around any serious alternative.  I’m <em>still</em> skeptical that there’s a serious alternative, but I now look more positively than I did just a few days ago on attempts to create one.</p>



<p>To all those who called me naïve or a coward for having cooperated with the NYT: believe me, I’m well aware that I wasn’t born with much backbone.  (I am, after all, that guy on the Internet who famously once planned on a life of celibate asceticism, or more likely suicide, rather than asking women out and thereby risking eternal condemnation as a misogynistic sexual harasser by the normal, the popular, the socially adept, the … <em>humanities grads</em> and the <em>journalists</em>.)  But whenever I need a pick-me-up, I tell myself that rather than being ashamed about my lack of a backbone, I can take pride in having occasionally managed to stand even without one.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5330"><span class="datestr">at February 16, 2021 05:33 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=18111">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2021/02/15/pigenhole-principle/">Pigenhole Principle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Mathematics is based on the application of simple ideas over and over: From tiny nuts do big trees grow. </em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<p><a href="https://rjlipton.wordpress.com/2021/02/15/pigenhole-principle/jv/" rel="attachment wp-att-18113"><img width="150" alt="" class="alignright wp-image-18113" src="https://rjlipton.files.wordpress.com/2021/02/jv.png?w=150" /></a></p>
<p>
Jorgen Veisdal is an assistant professor at the Norwegian University of Science and Technology. He is also the editor in chief at <a href="https://medium.com/cantors-paradise">Cantor’s Paradise</a>, which is a publication of math and science essays. </p>
<p>
Today I thought we would discuss a <a href="https://medium.com/cantors-paradise/the-pigeonhole-principle-e4c637940619">post</a> of his on the famous Pigenhole Princeiple (PP).</p>
<p>
Recall the PP states that if <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" title="{n}" /> items are put into <img src="https://s0.wp.com/latex.php?latex=%7Bm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{m}" class="latex" title="{m}" /> boxes, with <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3E+m%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n &gt; m}" class="latex" title="{n &gt; m}" />, then at least one box must contain more than one item.</p>
<p>
The paradox in my opinion is that this idea has any power at all. I wonder if I could explain why it was stated as an explicit <a href="https://en.wikipedia.org/wiki/Pigeonhole_principle">principle</a> by the famous Peter Dirichlet under the name Schubfachprinzip (“drawer principle” or “shelf principle”) in 1834. </p>
<p>
Parts of mathematics not only use PP, but could not live without it. Other parts of mathematics—I believe—are almost untouched by it. Am I right about this? Number theory and combinatorics especially Ramsey theory could not survive without it. What happens in your favorite area? Is there some area of math that is almost untouched by PP?</p>
<p>
</p><table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2021/02/15/pigenhole-principle/pigeons/" rel="attachment wp-att-18114"><img width="400" alt="" class="aligncenter  wp-image-18114" src="https://rjlipton.files.wordpress.com/2021/02/pigeons.png?w=400" /></a>
</td>
</tr>
<tr>

</tr>
</tbody></table>
<p>
</p><p></p><h2> An Example of PP </h2><p></p>
<p>
The main issue is why is PP so indispensable to some areas of math. But I though it might be fun to give a sample type of proof that uses PP.</p>
<p>
Prove that however one selects 55 integers 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++1+%5Cle+x_%7B1%7D+%3C+x_%7B2%7D+%3C+x_%7B3%7D+%3C+%5Cdots+%3C+x_%7B55%7D+%5Cle+100%2C&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  1 \le x_{1} &lt; x_{2} &lt; x_{3} &lt; \dots &lt; x_{55} \le 100," class="latex" title="\displaystyle  1 \le x_{1} &lt; x_{2} &lt; x_{3} &lt; \dots &lt; x_{55} \le 100," /></p>
<p>there will be some two that differ by 9, some two that differ by 10, a pair that differ by 12, and a pair that differ by 13. Surprisingly, there need not be a pair of numbers that differ by 11. </p>
<p></p><h2> Proof </h2><p></p>
<p>Let <img src="https://s0.wp.com/latex.php?latex=%7Bf%28y%2Cx%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{f(y,x)}" class="latex" title="{f(y,x)}" /> be number of collisions when place <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{y}" class="latex" title="{y}" /> into <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" title="{x}" />. Claim 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%2Bd%2Cx%29+%5Cge+f%28x%2B1%2Cx%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  f(x+d,x) \ge f(x+1,x), " class="latex" title="\displaystyle  f(x+d,x) \ge f(x+1,x), " /></p>
<p>for <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cge+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x \ge 1}" class="latex" title="{x \ge 1}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bd+%5Cge+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d \ge 1}" class="latex" title="{d \ge 1}" /> and 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%2B1%2Cx%29+%5Cge+f%28x%2Cx-1%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  f(x+1,x) \ge f(x,x-1), " class="latex" title="\displaystyle  f(x+1,x) \ge f(x,x-1), " /></p>
<p>for <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cge+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x \ge 2}" class="latex" title="{x \ge 2}" />. </p>
<p>
Note the first is really simple. Consider the first <img src="https://s0.wp.com/latex.php?latex=%7Bx%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x+1}" class="latex" title="{x+1}" /> pigeons. They are placed into <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" title="{x}" /> places and the inequality follows. The second is about the same. Consider the first <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x}" class="latex" title="{x}" /> pigeons. There are two cases. They are all placed in <img src="https://s0.wp.com/latex.php?latex=%7Bx-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x-1}" class="latex" title="{x-1}" /> places. Then we are done. So must have some placed into the last place. But if two are there then also done. So <img src="https://s0.wp.com/latex.php?latex=%7Bx-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x-1}" class="latex" title="{x-1}" /> are placed into <img src="https://s0.wp.com/latex.php?latex=%7Bx-1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x-1}" class="latex" title="{x-1}" />. But where does the last one go? In either case we are done.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p>Are there areas that almost never use the PP? I would like to hear about areas that just do not use PP. </p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2021/02/15/pigenhole-principle/"><span class="datestr">at February 15, 2021 05:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/02/15/postdoc-at-national-university-of-singapore-apply-by-march-31-2021-2/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/02/15/postdoc-at-national-university-of-singapore-apply-by-march-31-2021-2/">Postdoc at National University of Singapore (apply by March 31, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>One post-doctoral position is available. The goal of the intended projects is to develop new frameworks and techniques for testing properties of functions and distributions on high-dimensional spaces.</p>
<p>Website: <a href="https://www.comp.nus.edu.sg/~arnab/testing-postdoc.html">https://www.comp.nus.edu.sg/~arnab/testing-postdoc.html</a><br />
Email: arnabb@nus.edu.sg</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/02/15/postdoc-at-national-university-of-singapore-apply-by-march-31-2021-2/"><span class="datestr">at February 15, 2021 11:29 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/02/15/postdoc-at-national-university-of-singapore-apply-by-march-31-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/02/15/postdoc-at-national-university-of-singapore-apply-by-march-31-2021/">Postdoc at National University of Singapore (apply by March 31, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Two post-doctoral positions are available. The goal of the intended projects is to develop statistical and computational guarantees for algorithms performing causal inference.</p>
<p>Website: <a href="https://www.comp.nus.edu.sg/~arnab/causal-postdoc.html">https://www.comp.nus.edu.sg/~arnab/causal-postdoc.html</a><br />
Email: arnabb@nus.edu.sg</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/02/15/postdoc-at-national-university-of-singapore-apply-by-march-31-2021/"><span class="datestr">at February 15, 2021 11:27 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/014">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/014">TR21-014 |  Hitting Sets and Reconstruction for Dense Orbits in VP$_e$ and $\Sigma\Pi\Sigma$ Circuits | 

	Dori Medini, 

	Amir Shpilka</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper we study polynomials in VP$_e$ (polynomial-sized formulas) and in $\Sigma\Pi\Sigma$ (polynomial-size depth-$3$ circuits) whose orbits, under the action of the affine group GL$^{aff}_n({\mathbb F})$, are dense in their ambient class. We construct hitting sets and interpolating sets for these orbits as well as give reconstruction algorithms.

As VP$=$VNC$^2$, our results for VP$_e$ translate immediately to VP with a quasipolynomial blow up in parameters.

If any of our hitting or interpolating sets could be made robust then this would immediately yield a hitting set for the superclass in which the relevant class is dense, and as a consequence also a lower bound for the superclass. Unfortunately, we also prove that the kind of constructions that we have found (which are defined in terms of k-independent polynomial maps) do not necessarily yield robust hitting sets.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/014"><span class="datestr">at February 15, 2021 08:59 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06673">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06673">Proof complexity of positive branching programs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Anupam Das, Avgerinos Delkos <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06673">PDF</a><br /><b>Abstract: </b>We investigate the proof complexity of systems based on positive branching
programs, i.e. non-deterministic branching programs (NBPs) where, for any
0-transition between two nodes, there is also a 1-transition. Positive NBPs
compute monotone Boolean functions, just like negation-free circuits or
formulas, but constitute a positive version of (non-uniform) NL, rather than P
or NC1, respectively.
</p>
<p>The proof complexity of NBPs was investigated in previous work by Buss, Das
and Knop, using extension variables to represent the dag-structure, over a
language of (non-deterministic) decision trees, yielding the system eLNDT. Our
system eLNDT+ is obtained by restricting their systems to a positive syntax,
similarly to how the 'monotone sequent calculus' MLK is obtained from the usual
sequent calculus LK by restricting to negation-free formulas.
</p>
<p>Our main result is that eLNDT+ polynomially simulates eLNDT over positive
sequents. Our proof method is inspired by a similar result for MLK by Atserias,
Galesi and Pudl\'ak, that was recently improved to a bona fide polynomial
simulation via works of Je\v{r}\'abek and Buss, Kabanets, Kolokolova and
Kouck\'y. Along the way we formalise several properties of counting functions
within eLNDT+ by polynomial-size proofs and, as a case study, give explicit
polynomial-size poofs of the propositional pigeonhole principle.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06673"><span class="datestr">at February 15, 2021 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06652">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06652">Barriers for recent methods in geodesic optimization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Franks:Cole.html">Cole Franks</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reichenbach:Philipp.html">Philipp Reichenbach</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06652">PDF</a><br /><b>Abstract: </b>We study a class of optimization problems including matrix scaling, matrix
balancing, multidimensional array scaling, operator scaling, and tensor scaling
that arise frequently in theory and in practice. Some of these problems, such
as matrix and array scaling, are convex in the Euclidean sense, but others such
as operator scaling and tensor scaling are \emph{geodesically convex} on a
different Riemannian manifold. Trust region methods, which include
box-constrained Newton's method, are known to produce high precision solutions
very quickly for matrix scaling and matrix balancing (Cohen et. al., FOCS 2017,
Allen-Zhu et. al. FOCS 2017), and result in polynomial time algorithms for some
geodesically convex problems like operator scaling (Garg et. al. STOC 2018,
B\"urgisser et. al. FOCS 2019). One is led to ask whether these guarantees also
hold for multidimensional array scaling and tensor scaling.
</p>
<p>We show that this is not the case by exhibiting instances with exponential
\emph{diameter bound}: we construct polynomial-size instances of 3-dimensional
array scaling and 3-tensor scaling whose approximate solutions all have doubly
exponential condition number. Moreover, we study convex-geometric notions of
complexity known as margin and gap, which are used to bound the running times
of all existing optimization algorithms for such problems. We show that margin
and gap are exponentially small for several problems including array scaling,
tensor scaling and polynomial scaling. Our results suggest that it is
impossible to prove polynomial running time bounds for tensor scaling based on
diameter bounds alone. Therefore, our work motivates the search for analogues
of more sophisticated algorithms, such as interior point methods, for
geodesically convex optimization that do not rely on polynomial diameter
bounds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06652"><span class="datestr">at February 15, 2021 10:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06635">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06635">ReLU Neural Networks for Exact Maximum Flow Computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hertrich:Christoph.html">Christoph Hertrich</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sering:Leon.html">Leon Sering</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06635">PDF</a><br /><b>Abstract: </b>Understanding the great empirical success of artificial neural networks (NNs)
from a theoretical point of view is currently one of the hottest research
topics in computer science. In this paper we study the expressive power of NNs
with rectified linear units from a combinatorial optimization perspective. In
particular, we show that, given a directed graph with $n$ nodes and $m$ arcs,
there exists an NN of polynomial size that computes a maximum flow from any
possible real-valued arc capacities as input. To prove this, we develop the
pseudo-code language Max-Affine Arithmetic Programs (MAAPs) and show
equivalence between MAAPs and NNs concerning natural complexity measures. We
then design a MAAP to exactly solve the Maximum Flow Problem, which translates
to an NN of size $\mathcal{O}(m^2 n^2)$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06635"><span class="datestr">at February 15, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06613">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06613">Improved LP-based Approximation Algorithms for Facility Location with Hard Capacities</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kao:Mong=Jen.html">Mong-Jen Kao</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06613">PDF</a><br /><b>Abstract: </b>We present LP-based approximation algorithms for the capacitated facility
location problem (CFL), a long-standing problem with intriguing unsettled
complexity and literature dated back to the 90s. We present an elegant
iterative rounding scheme for the MFN relaxation that yields an approximation
guarantee of $\left(10+\sqrt{67}\right)/2 \approx 9.0927$, a significant
improvement upon the previous LP-based ratio due to An et al in~2014. For CFL
with cardinality facility cost (CFL-CFC), we present an LP-based
$4$-approximation algorithm, which surpasses the long-standing ratio of~$5$ due
to Levi et al that ages up for decades since 2004. Our result considerably
deepens the current understanding for the CFL problem and indicates that an
LP-based ratio strictly better than $5$ in polynomial time for the general
problem may still be possible to pursue.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06613"><span class="datestr">at February 15, 2021 10:43 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06565">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06565">Work-Optimal Parallel Minimum Cuts for Non-Sparse Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Andrés López-Martínez, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukhopadhyay:Sagnik.html">Sagnik Mukhopadhyay</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nanongkai:Danupon.html">Danupon Nanongkai</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06565">PDF</a><br /><b>Abstract: </b>We present the first work-optimal polylogarithmic-depth parallel algorithm
for the minimum cut problem on non-sparse graphs. For $m\geq n^{1+\epsilon}$
for any constant $\epsilon&gt;0$, our algorithm requires $O(m \log n)$ work and
$O(\log^3 n)$ depth and succeeds with high probability. Its work matches the
best $O(m \log n)$ runtime for sequential algorithms [MN STOC 2020, GMW SOSA
2021]. This improves the previous best work by Geissmann and Gianinazzi [SPAA
2018] by $O(\log^3 n)$ factor, while matching the depth of their algorithm. To
do this, we design a work-efficient approximation algorithm and parallelize the
recent sequential algorithms [MN STOC 2020; GMW SOSA 2021] that exploit a
connection between 2-respecting minimum cuts and 2-dimensional orthogonal range
searching.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06565"><span class="datestr">at February 15, 2021 10:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06557">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06557">Updatable Materialization of Approximate Constraints</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kl=auml=be:Steffen.html">Steffen Kläbe</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sattler:Kai=Uwe.html">Kai-Uwe Sattler</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Baumann:Stephan.html">Stephan Baumann</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06557">PDF</a><br /><b>Abstract: </b>Modern big data applications integrate data from various sources. As a
result, these datasets may not satisfy perfect constraints, leading to sparse
schema information and non-optimal query performance. The existing approach of
PatchIndexes enable the definition of approximate constraints and improve query
performance by exploiting the materialized constraint information. As real
world data warehouse workloads are often not limited to read-only queries, we
enhance the PatchIndex structure towards an update-conscious design in this
paper. Therefore, we present a sharded bitmap as the underlying data structure
which offers efficient update operations, and describe approaches to maintain
approximate constraints under updates, avoiding index recomputations and full
table scans. In our evaluation, we prove that PatchIndexes significantly impact
query performance while achieving lightweight update support.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06557"><span class="datestr">at February 15, 2021 10:47 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06543">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06543">Computing Betweenness Centrality in Link Streams</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Simard:Fr=eacute=d=eacute=ric.html">Frédéric Simard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Magnien:Cl=eacute=mence.html">Clémence Magnien</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Latapy:Matthieu.html">Matthieu Latapy</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06543">PDF</a><br /><b>Abstract: </b>Betweeness centrality is one of the most important concepts in graph
analysis. It was recently extended to link streams, a graph generalization
where links arrive over time. However, its computation raises non-trivial
issues, due in particular to the fact that time is considered as continuous. We
provide here the first algorithms to compute this generalized betweenness
centrality, as well as several companion algorithms that have their own
interest. They work in polynomial time and space, we illustrate them on typical
examples, and we provide an implementation.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06543"><span class="datestr">at February 15, 2021 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06486">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06486">Adaptive Sampling for Fast Constrained Maximization of Submodular Function</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/q/Quinzan:Francesco.html">Francesco Quinzan</a>, Vanja Doskoč, Andreas Göbel, Tobias Friedrich <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06486">PDF</a><br /><b>Abstract: </b>Several large-scale machine learning tasks, such as data summarization, can
be approached by maximizing functions that satisfy submodularity. These
optimization problems often involve complex side constraints, imposed by the
underlying application. In this paper, we develop an algorithm with
poly-logarithmic adaptivity for non-monotone submodular maximization under
general side constraints. The adaptive complexity of a problem is the minimal
number of sequential rounds required to achieve the objective.
</p>
<p>Our algorithm is suitable to maximize a non-monotone submodular function
under a $p$-system side constraint, and it achieves a $(p +
O(\sqrt{p}))$-approximation for this problem, after only poly-logarithmic
adaptive rounds and polynomial queries to the valuation oracle function.
Furthermore, our algorithm achieves a $(p + O(1))$-approximation when the given
side constraint is a $p$-extendible system.
</p>
<p>This algorithm yields an exponential speed-up, with respect to the
adaptivity, over any other known constant-factor approximation algorithm for
this problem. It also competes with previous known results in terms of the
query complexity. We perform various experiments on various real-world
applications. We find that, in comparison with commonly used heuristics, our
algorithm performs better on these instances.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06486"><span class="datestr">at February 15, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06480">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06480">Safety of Flow Decompositions in DAGs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Khan:Shahbaz.html">Shahbaz Khan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tomescu:Alexandru_I=.html">Alexandru I. Tomescu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06480">PDF</a><br /><b>Abstract: </b>Network flows are one of the most studied combinatorial optimization problems
with innumerable applications. Any flow on a directed acyclic graph (DAG) $G$
having $n$ vertices and $m$ edges can be decomposed into a set of $O(m)$ paths,
with applications from network routing to assembly of biological sequences. In
some applications, the flow decomposition corresponds to some particular data
that need to be reconstructed from the flow, which require finding paths (or
subpaths) appearing in all possible flow decompositions, referred to as safe
paths.
</p>
<p>Recently, Ma et al. [WABI 2020] addressed a related problem in a
probabilistic framework. Later, they gave a quadratic-time algorithm based on a
global criterion, for a generalized version (AND-Quant) of the corresponding
problem, i.e., reporting if a given flow path is safe. Our contributions are as
follows:
</p>
<p>1- A simple characterization for the safety of a given path based on a local
criterion, which can be directly adapted to give an optimal linear time
verification algorithm.
</p>
<p>2- A simple enumeration algorithm that reports all maximal safe paths on a
flow network in $O(mn)$ time. The algorithm reports all safe paths using a
compact representation of the solution (called ${\cal P}_c$), which is
$\Omega(mn)$ in the worst case, but merely $O(m+n)$ in the best case.
</p>
<p>3- An improved enumeration algorithm where all safe paths ending at every
vertex are represented as funnels using $O(n^2+|{\cal P}_c|)$ space. These can
be computed and used to report all maximal safe paths, using time linear in the
total space required by funnels, with an extra logarithmic factor.
</p>
<p>Overall we present a simple characterization for the problem leading to an
optimal verification algorithm and a simple enumeration algorithm. The
enumeration algorithm is improved using the funnel structures for safe paths,
which may be of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06480"><span class="datestr">at February 15, 2021 10:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06463">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06463">A more accurate view of the Flat Wall Theorem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sau:Ignasi.html">Ignasi Sau</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stamoulis:Giannos.html">Giannos Stamoulis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Thilikos:Dimitrios_M=.html">Dimitrios M. Thilikos</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06463">PDF</a><br /><b>Abstract: </b>We introduce a supporting combinatorial framework for the Flat Wall Theorem.
In particular, we suggest two variants of the theorem and we introduce a new,
more versatile, concept of wall homogeneity as well as the notion of regularity
in flat walls. All proposed concepts and results aim at facilitating the use of
the irrelevant vertex technique in future algorithmic applications.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06463"><span class="datestr">at February 15, 2021 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06427">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06427">A Subexponential Algorithm for ARRIVAL</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/G=auml=rtner:Bernd.html">Bernd Gärtner</a>, Sebastian Haslebacher, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoang:Hung_P=.html">Hung P. Hoang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06427">PDF</a><br /><b>Abstract: </b>The ARRIVAL problem is to decide the fate of a train moving along the edges
of a directed graph, according to a simple (deterministic) pseudorandom walk.
The problem is in $NP \cap coNP$ but not known to be in $P$. The currently best
algorithms have runtime $2^{\Theta(n)}$ where $n$ is the number of vertices.
This is not much better than just performing the pseudorandom walk. We develop
a subexponential algorithm with runtime $2^{O(\sqrt{n}\log n)}$. We also give a
polynomial-time algorithm if the graph is almost acyclic. Both results are
derived from a new general approach to solve ARRIVAL instances.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06427"><span class="datestr">at February 15, 2021 10:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06387">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06387">The Distributed Discrete Gaussian Mechanism for Federated Learning with Secure Aggregation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kairouz:Peter.html">Peter Kairouz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Ziyu.html">Ziyu Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Steinke:Thomas.html">Thomas Steinke</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06387">PDF</a><br /><b>Abstract: </b>We consider training models on private data that is distributed across user
devices. To ensure privacy, we add on-device noise and use secure aggregation
so that only the noisy sum is revealed to the server. We present a
comprehensive end-to-end system, which appropriately discretizes the data and
adds discrete Gaussian noise before performing secure aggregation. We provide a
novel privacy analysis for sums of discrete Gaussians. We also analyze the
effect of rounding the input data and the modular summation arithmetic. Our
theoretical guarantees highlight the complex tension between communication,
privacy, and accuracy. Our extensive experimental results demonstrate that our
solution is essentially able to achieve a comparable accuracy to central
differential privacy with 16 bits of precision per value.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06387"><span class="datestr">at February 15, 2021 10:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06385">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06385">The Symmetry between Bandits and Knapsacks: A Primal-Dual LP-based Approach</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Li:Xiaocheng.html">Xiaocheng Li</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Chunlin.html">Chunlin Sun</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/y/Ye:Yinyu.html">Yinyu Ye</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06385">PDF</a><br /><b>Abstract: </b>In this paper, we study the bandits with knapsacks (BwK) problem and develop
a primal-dual based algorithm that achieves a problem-dependent logarithmic
regret bound. The BwK problem extends the multi-arm bandit (MAB) problem to
model the resource consumption associated with playing each arm, and the
existing BwK literature has been mainly focused on deriving asymptotically
optimal distribution-free regret bounds. We first study the primal and dual
linear programs underlying the BwK problem. From this primal-dual perspective,
we discover symmetry between arms and knapsacks, and then propose a new notion
of sub-optimality measure for the BwK problem. The sub-optimality measure
highlights the important role of knapsacks in determining algorithm regret and
inspires the design of our two-phase algorithm. In the first phase, the
algorithm identifies the optimal arms and the binding knapsacks, and in the
second phase, it exhausts the binding knapsacks via playing the optimal arms
through an adaptive procedure. Our regret upper bound involves the proposed
sub-optimality measure and it has a logarithmic dependence on length of horizon
$T$ and a polynomial dependence on $m$ (the numbers of arms) and $d$ (the
number of knapsacks). To the best of our knowledge, this is the first
problem-dependent logarithmic regret bound for solving the general BwK problem.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06385"><span class="datestr">at February 15, 2021 10:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06277">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06277">On Agnostic PAC Learning using $\mathcal{L}_2$-polynomial Regression and Fourier-based Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Heidari:Mohsen.html">Mohsen Heidari</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Szpankowski:Wojciech.html">Wojciech Szpankowski</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06277">PDF</a><br /><b>Abstract: </b>We develop a framework using Hilbert spaces as a proxy to analyze PAC
learning problems with structural properties. We consider a joint Hilbert space
incorporating the relation between the true label and the predictor under a
joint distribution $D$. We demonstrate that agnostic PAC learning with 0-1 loss
is equivalent to an optimization in the Hilbert space domain. With our model,
we revisit the PAC learning problem using methods based on least-squares such
as $\mathcal{L}_2$ polynomial regression and Linial's low-degree algorithm. We
study learning with respect to several hypothesis classes such as half-spaces
and polynomial-approximated classes (i.e., functions approximated by a
fixed-degree polynomial). We prove that (under some distributional assumptions)
such methods obtain generalization error up to $2opt$ with $opt$ being the
optimal error of the class. Hence, we show the tightest bound on generalization
error when $opt\leq 0.2$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06277"><span class="datestr">at February 15, 2021 10:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.06247">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.06247">Sample-Optimal PAC Learning of Halfspaces with Malicious Noise</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shen:Jie.html">Jie Shen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.06247">PDF</a><br /><b>Abstract: </b>We study efficient PAC learning of homogeneous halfspaces in $\mathbb{R}^d$
in the presence of malicious noise of Valiant~(1985). This is a challenging
noise model and only until recently has near-optimal noise tolerance bound been
established under the mild condition that the unlabeled data distribution is
isotropic log-concave. However, it remains unsettled how to obtain the optimal
sample complexity simultaneously. In this work, we present a new analysis for
the algorithm of Awasthi et al.~(2017) and show that it essentially achieves
the near-optimal sample complexity bound of $\tilde{O}(d)$, improving the best
known result of $\tilde{O}(d^2)$. Our main ingredient is a novel incorporation
of a Matrix Chernoff-type inequality to bound the spectrum of an empirical
covariance matrix for well-behaved distributions, in conjunction with a careful
exploration of the localization schemes of Awasthi et al.~(2017). We further
extend the algorithm and analysis to the more general and stronger nasty noise
model of Bshouty~et~al. (2002), showing that it is still possible to achieve
near-optimal noise tolerance and sample complexity in polynomial time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.06247"><span class="datestr">at February 15, 2021 10:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2102.05705">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2102.05705">A Topological Approach for Motion Track Discrimination</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Emerson:Tegan.html">Tegan Emerson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Tymochko:Sarah.html">Sarah Tymochko</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Stantchev:George.html">George Stantchev</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Edelberg:Jason_A=.html">Jason A. Edelberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wilson:Michael.html">Michael Wilson</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Olson:Colin_C=.html">Colin C. Olson</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2102.05705">PDF</a><br /><b>Abstract: </b>Detecting small targets at range is difficult because there is not enough
spatial information present in an image sub-region containing the target to use
correlation-based methods to differentiate it from dynamic confusers present in
the scene. Moreover, this lack of spatial information also disqualifies the use
of most state-of-the-art deep learning image-based classifiers. Here, we use
characteristics of target tracks extracted from video sequences as data from
which to derive distinguishing topological features that help robustly
differentiate targets of interest from confusers. In particular, we calculate
persistent homology from time-delayed embeddings of dynamic statistics
calculated from motion tracks extracted from a wide field-of-view video stream.
In short, we use topological methods to extract features related to target
motion dynamics that are useful for classification and disambiguation and show
that small targets can be detected at range with high probability.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2102.05705"><span class="datestr">at February 15, 2021 10:55 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-699230831808345084">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/02/two-examples-of-journalists-being-wrong.html">Two examples of Journalists being... Wrong. One BIG one small</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> Journalists sometimes get things wrong.</p><p>This is not news, but it is interesting when you KNOW they are wrong. </p><p>1) Scott Aaronson has a GREAT example regarding an IMPORTANT story. I recommend you to read his blog post <a href="https://www.scottaaronson.com/blog/?p=5310">here</a>. Most of the comments are good also, though they go off on some tangents (e.g., is the Universal Basic Income a progressive idea?)</p><p><br /></p><p>2) I have my own example. It is far less important than the one Scott discusses; however, inspired by Scott, I will discuss it. My example also involves Scott, but that's a coincidence. </p><p>Quanta Magazine emailed me that they wanted to talk to me about an upcoming article on <i>The Busy</i> <i>Beaver Problem</i>. Why me? Because Scott's (same Scott as above!) survey/open problems column appeared in the SIGACT News Open Problem Column that I edit. </p><p>This sounded fine (Spoiler Alert: It was fine, the errors they made were odd, not harmful).</p><p>Here is the Quanta Article (though I do not know if it is behind paywalls- I can never tell if I am getting access because I have a UMCP account of or anyone can have access or if I am breaking copyright laws by posting the link):    <a href="https://www.quantamagazine.org/the-busy-beaver-game-illuminates-the-fundamental-limits-of-math-20201210/">here</a></p><p>Here is Scotts article: <a href="https://www.scottaaronson.com/papers/bb.pdf">here</a></p><p>The interviewer asked me </p><p>a) Why did I ask Scott to write the article?</p><p>ANSWER: He had a blog post on it, and I was skeptical of why these numbers are interesting, so I asked a question in the comments. He gave a great answer, so I asked him if he wanted to write a column for my open problems column. Actually I asked him if either he or perhaps a grad student would do it- I assumed he would be too busy since his `day job' is quantum  computing. However, much to my surprise and delight he said YES he would do it.</p><p>b) Is the Busy Beaver Function important?</p><p>ANSWER: In my opinion the actual numbers are not that important but its really neat that (a) we know some of them, and (b) they are far smaller than I would have thought. Also these numbers are interesting for the following reason:  there is some  n so that proving </p><p>BB(n)=whatever it equals</p><p> is Ind of Peano Arithmetic. When I hear that I think the number must be really large. Its not. Its 27. NEAT! And stronger theories are related to bigger numbers. This is a way to order theories. For  ZF they have something in the 700's- MUCH SMALLER than I would have thought. Scott and others can even relate BB to open problems in Math! </p><p>There were some other questions also, but I don't recall what they were. </p><p>SO when the article came they mentioned me once, and its... not quite wrong but odd:</p><p><i>William Gasarch, a computer science professor at the University of Maryland College Park,</i></p><p><i>said he's less intrigued by the prospect of pinning down the Busy Beaver numbers than by </i></p><p><i>``the general concept that its actually uncomputable.'' He and other mathematicians are mainly interested in using the yardstick for gauging the difficulty of important open problems in mathematics--or for figuring out what is mathematically knowable at all. </i></p><p><br /></p><p>The oddest thing about the paragraph is they do not mention my connection to Scott and the article he wrote! I reread the article looking for something like `<i>Scotts article appeared in the SIGACT News</i> <i>Open Problems column edited by William Gasarch' </i>Nothing of that sort appears. </p><p>Without that its not clear why they are soliciting my opinion. My colleague Clyde says this is GOOD:  people will ASSUME I am some sort of expert. Am I an expert? I proofread Scott's paper so... there is that...</p><p>Also I come off as more down on BB than I really am. </p><p>Did I claim that Mathematicians are more interested in using it as a yardstick. Actually I may have said something like that. I don't know if its true. That's my bad- I should have said that I am interested in that.</p><p>After the article came out I asked the interviewer why my role was not in the article. He said it was cut by the editor. </p><p>NOW- NONE of this is important, but even on small and easily correctable things, they get it wrong. So imagine what happens on hard issues that are harder to get right. </p><p><br /></p><p>MISC: One comment on Scott's blog was about the Gell-Mann amnesia effect, see this article on it:</p><p><a href="https://www.tefter.io/bookmarks/45454/readable">here</a><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/02/two-examples-of-journalists-being-wrong.html"><span class="datestr">at February 14, 2021 08:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/013">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/013">TR21-013 |  Positive spectrahedrons: Geometric properties, Invariance principles and Pseudorandom generators | 

	Penghui Yao, 

	Srinivasan Arunachalam</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In a recent work, O'Donnell, Servedio and Tan (STOC 2019) gave explicit pseudorandom generators (PRGs) for arbitrary $m$-facet polytopes in $n$ variables with seed length poly-logarithmic in $m,n$, concluding a sequence of works in the last decade, that was started by Diakonikolas,  Gopalan,  Jaiswal,  Servedio, Viola (SICOMP 2010) and Meka, Zuckerman (SICOMP 2013) for fooling linear and polynomial threshold functions, respectively. In this work, we consider a natural extension of  PRGs for intersections of positive spectrahedrons. A positive spectrahedron  is a Boolean function $f(x)=[x_1A^1+\cdots +x_nA^n \preceq B]$ where the $A^i$s are $k\times k$ positive semidefinite matrices. We construct explicit PRGs  that $\delta$-fool  "regular" width-$M$ positive spectrahedrons (i.e., when none of the $A^i$s are dominant) over the Boolean space  with seed length $poly(\log k,\log n, M, 1/\delta)$.
    

    Our main technical contributions are the following. We first prove an invariance principle for positive spectrahedrons via the well-known Lindeberg method. As far as we are aware such a  generalization of the Lindeberg method was unknown. Second, we prove various geometric properties of positive spectrahedrons such as their noise sensitivity, Gaussian surface area and a Littlewood-Offord theorem for positive spectrahedrons. Using these results, we give applications for constructing PRGs for positive spectrahedrons, learning theory, discrepancy sets for positive spectrahedrons (over the Boolean cube) and PRGs for intersections of structured polynomial threshold functions.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/013"><span class="datestr">at February 14, 2021 02:29 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/012">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/012">TR21-012 |  On the Power and Limitations of Branch and Cut | 

	Noah Fleming, 

	Toniann Pitassi, 

	Li-Yang Tan, 

	Mika Göös, 

	Russell Impagliazzo, 

	Robert Robere, 

	Avi Wigderson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The Stabbing Planes proof system was introduced to model the reasoning carried out in practical mixed integer programming solvers. As a proof system, it is powerful enough to simulate Cutting Planes and to refute the Tseitin formulas -- certain unsatisfiable systems of linear equations mod 2 -- which are canonical hard examples for many algebraic proof systems. In a recent (and surprising) result, Dadush and Tiwari showed that these short refutations of the Tseitin formulas could be translated into quasi-polynomial size and depth Cutting Planes proofs, refuting a long-standing conjecture. This translation raises several interesting questions. First, whether all Stabbing Planes proofs can be efficiently simulated by Cutting Planes. This would allow for the substantial analysis done on the Cutting Planes system to be lifted to practical mixed integer programming solvers. Second, whether the quasi-polynomial depth of these proofs is inherent to Cutting Planes. 

In this paper we make progress towards answering both of these questions. First, we show that any Stabbing Planes proof with bounded coefficients SP* can be translated into Cutting Planes. As a consequence of the known lower bounds for Cutting Planes, this establishes the first exponential lower bounds on SP*. Using this translation, we extend the result of Dadush and Tiwari to show that Cutting Planes has short refutations of any unsatisfiable system of linear equations over a finite field. Like the Cutting Planes proofs of Dadush and Tiwari, our refutations also incur a quasi-polynomial blow-up in depth, and we conjecture that this is inherent. As a step towards this conjecture, we develop a new geometric technique for proving lower bounds on the depth of Cutting Planes proofs. This allows us to establish the first lower bounds on the depth of Semantic Cutting Planes proofs of the Tseitin formulas.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/012"><span class="datestr">at February 14, 2021 02:07 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5310">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5310">A grand anticlimax: the New York Times on Scott Alexander</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p><strong><span class="has-inline-color has-vivid-red-color">Updates (Feb. 14, 2021):</span></strong>  <a href="https://astralcodexten.substack.com/p/statement-on-new-york-times-article">Scott Alexander Siskind responds here</a>.</p>



<p>Last night, it occurred to me that despite how disjointed it feels, the <em>New York Times</em> piece does have a central thesis: namely, that rationalism is a “gateway drug” to dangerous beliefs.  And that thesis is 100% correct—insofar as <em>once you teach people that they can think for themselves about issues of consequence, some of them might think bad things</em>.  It’s just that many of us judge the benefit worth the risk!</p>



<p>Happy Valentine’s Day everyone!</p>



<p></p><hr /><p></p>



<p>Back in June, <em>New York Times</em> technology reporter Cade Metz, who I’d previously known from his reporting on quantum computing, told me that he was writing a story about Scott Alexander, Slate Star Codex, and the rationalist community.  Given my position as someone who <em>knew</em> the rationalist community without ever really being <em>part</em> of it, Cade wondered whether I’d talk with him.  I said I’d be delighted to.</p>



<p>I spent many hours with Cade, taking his calls and emails morning or night, at the playground with my kids or wherever else I was, answering his questions, giving context for his other interviews, suggesting people in the rationalist community for him to talk to, in exactly the same way I might suggest colleagues for a quantum computing story.  And then I spent just as much time urging those people to talk to Cade.  (“How could you possibly not want to talk?  It’s the <em>New York Times</em>!”)  Some of the people I suggested agreed to talk; others refused; a few were livid at me for giving a <em>New York Times</em> reporter their email addresses without asking them.  (I apologized; lesson learned.)</p>



<p>What happened next is already the stuff of Internet history: the NYT’s threat to publish Scott’s real surname; Scott deleting his blog as a way to preempt that ‘doxing’; 8,000 people, including me, signing a <a href="https://www.dontdoxscottalexander.com/">petition</a> urging the NYT to respect Scott’s wish to keep his professional and blog identities separate; Scott resigning from his psychiatry clinic and starting his own low-cost practice, <a href="https://lorienpsych.com/">Lorien Psychiatry</a>; his moving his blog, like so many other writers this year, to <a href="https://substack.com/">Substack</a>; then, a few weeks ago, his <a href="https://astralcodexten.substack.com/">triumphant return</a> to blogging under his real name of Scott Siskind.  All this against the backdrop of an 8-month period that was world-changingly historic in so many other ways: the failed violent insurrection against the United States and the ouster, by democratic means, of the president who incited it; the tragedy of covid and the long-delayed start of the vaccination campaign; the BLM protests; the well-publicized upheavals at the NYT itself, including firings for ideological lapses that would’ve made little sense to our remote ancestors of ~2010.</p>



<p>And now, as an awkward coda, the <em>New York Times</em> article itself is <a href="https://www.nytimes.com/2021/02/13/technology/slate-star-codex-rationalists.html?action=click&amp;module=Top%20Stories&amp;pgtype=Homepage">finally out</a> (<a href="https://www.deccanherald.com/business/technology/why-slate-star-codex-is-silicon-valley-s-safe-space-950727.html">non-paywalled version here</a>).</p>



<p>It could’ve been worse.  I doubt it will do lasting harm.  Of the many choices I disagreed with, I don’t know which were Cade’s and which his editors’.  But no, I was not happy with it.  If you want a feature-length, pop condensation of the rationalist community and its ideas, I preferred <a href="https://www.newyorker.com/culture/annals-of-inquiry/slate-star-codex-and-silicon-valleys-war-against-the-media">this summer’s <em>New Yorker</em> article</a> (but much better still is the <a href="https://www.amazon.com/Does-Not-Hate-You-Superintelligence-ebook/dp/B07K258VCV">book by Tom Chivers</a>).</p>



<p>The trouble with the NYT piece is not that it makes any false statements, but just that it constantly <em>insinuates</em> nefarious beliefs and motives, via strategic word choices and omission of relevant facts that change the emotional coloration of the facts that it <em>does</em> present.  I repeatedly muttered to myself, as I read: “dude, you could make <em>anything</em> sound shady with this exact same rhetorical toolkit!” </p>



<p>Without further ado, here’s a partial list of my issues:</p>



<ol><li>The piece includes the following ominous sentence: “But in late June of last year, when I approached Siskind to discuss the blog, it vanished.”  This framing, it seems to me, would be appropriate for some conman trying to evade accountability without ever explaining himself.  It doesn’t make much sense for a practicing psychiatrist who took the dramatic step of deleting his blog <em>in order to preserve his relationship with his patients</em>—thereby complying with an ethical code that’s universal among psychiatrists, even if slightly strange to the rest of us—and who immediately explained his reasoning to the entire world.  In the latter framing, of course, Scott comes across less like a fugitive on the run and more like an innocent victim of a newspaper’s editorial obstinacy.<br /></li><li>As expected, the piece devotes enormous space to the idea of rationalism as an on-ramp to alt-right extremism.  The trouble is, it never presents the idea that rationalism also can be an <em>off-ramp</em> from extremism—i.e., that it can provide a model for how even after you realize that mainstream sources are confidently wrong on some issue, you don’t respond by embracing conspiracy theories and hatreds, you respond by simply thinking carefully about each individual question rather than buying a worldview wholesale from anyone.  Nor does the NYT piece mention how Scott, precisely <em>because</em> he gives right-wing views more charity than some of us might feel they deserve, actually succeeded in dissuading some of his readers from voting for Trump—which is more success than I can probably claim in that department!  I had many conversations with Cade about these angles that are nowhere reflected in the piece.<br /></li><li>The piece gets off on a weird foot, by describing the rationalists as “a group that aimed to re-examine the world through cold and careful thought.”  Why “cold”?  Like, let’s back up a few steps: what is even the <em>connection</em> in the popular imagination between rationality and “coldness”?  To me, as to many others, the humor, humanity, and <em>warmth</em> of Scott’s writing were always among its most notable features.<br /></li><li>The piece makes liberal use of scare quotes.  Most amusingly, it puts scare quotes around the phrase “Bayesian reasoning”!<br /></li><li>The piece never mentions that many rationalists (Zvi Mowshowitz, Jacob Falkovich, Kelsey Piper…) were right about the risk of covid-19 in early 2020, and then <em>again</em> right about masks, aerosol transmission, faster-spreading variants, the need to get vaccines into arms faster, and many other subsidiary issues, even while public health authorities and the mainstream press struggled for months longer to reach the same obvious (at least in retrospect) conclusions.  This omission is significant because Cade told me, in June, that the rationalist community’s early rightness about covid was part of what <em>led him to want to write the piece in the first place</em> <em>(!)</em>.  If readers knew about that clear success, would it put a different spin on the rationalists’ weird, cultlike obsession with “Bayesian reasoning” and “consequentialist ethics” (whatever those are), or their nerdy, idiosyncratic worries about the more remote future?<br /></li><li>The piece contains the following striking sentence: “On the internet, many in Silicon Valley believe, everyone has the right not only to say what they want but to say it anonymously.”  Well, yes, except this framing makes it sound like this is a fringe belief of some radical Silicon Valley tribe, rather than just the standard expectation of most of the billions of people who’ve used the Internet for most of its half-century of existence.<br /></li><li>Despite thousands of words about the content of SSC, the piece never gives Scott a few uninterrupted sentences in his own voice, to convey his style.  This is something the <em>New Yorker</em> piece did do, and which would help readers better understand the wit, humor, charity, and self-doubt that made SSC so popular.  To see what I mean, read the NYT’s radically-abridged quotations from Scott’s now-classic riff on the Red, Blue, and Gray Tribes and decide for yourself whether they capture the <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/">spirit of the original</a> (alright, I’ll quote the relevant passage myself at the bottom of this post).  Scott has the property, shared by many of my favorite writers, that if you just properly <em>quote</em> him, the words leap off the page, wriggling free from the grasp of any bracketing explanations and making a direct run for the reader’s brain.  All the more reason to <a href="https://howthehell.substack.com/p/nyt-ssc-quoting">quote him</a>!<br /></li><li>The piece describes SSC as “astoundingly verbose.”  A more neutral way to put it would be that Scott has <em>produced a vast quantity of intellectual output</em>.  When I finish a Scott Alexander piece, only in a minority of cases do I feel like he spent more words examining a problem than its complexities really warranted.  Just as often, I’m left wanting more.<br /></li><li>The piece says that Scott once “aligned himself” with Charles Murray, then goes on to note Murray’s explosive views about race and IQ.  That might be fair enough, were it <em>also</em> mentioned that positions ascribed to Murray that Scott endorses in the <a href="https://web.archive.org/web/20200615030810/https://slatestarcodex.com/2016/05/23/three-great-articles-on-poverty-and-why-i-disagree-with-all-of-them/">relevant post</a> —namely, “hereditarian leftism” and <a href="https://en.wikipedia.org/wiki/Universal_basic_income">universal basic income</a>—are not only unrelated to race but are actually <em>progressive</em> positions.<br /></li><li>The piece says that Scott once had neoreactionary thinker <a href="https://en.wikipedia.org/wiki/Nick_Land">Nick Land</a> on his blogroll.  Again, important context is missing: this was back when Land was mainly known for his strange writings on AI and philosophy, <em>before</em> his neoreactionary turn.<br /></li><li>The piece says that Scott compared “some feminists” to Voldemort.  It didn’t explain what it took for certain specific feminists (like Amanda Marcotte) to prompt that comparison, which might have changed the coloration.  (Another thing that would’ve complicated the picture: the rationalist community’s legendary openness to alternative gender identities and sexualities, before such openness became mainstream.)<br /></li><li>Speaking of feminists—yeah, I’m a minor part of the article.  One of the few things mentioned about me is that I’ve stayed in a rationalist group house.  (If you must know: for like two nights, when I was in Bay Area, with my wife and kids.  We appreciated the hospitality!)  The piece also says that I was “turned off by the more rigid and contrarian beliefs of the Rationalists.”  It’s true that I’ve <em>disagreed</em> with many beliefs espoused by Rationalists, but not <em>because</em> they were contrarian, or because I found them noticeably more “rigid” than most beliefs—only because I thought the beliefs were mistaken!<br /></li><li>The piece describes Eliezer Yudkowsky as a “polemicist and self-described AI researcher.”  It’s true that Eliezer opines about AI despite a lack of conventional credentials in that field, and it’s also true that the typical NYT reader might find him to be comically self-aggrandizing.  But had the piece mentioned the universally recognized AI experts, like Stuart Russell, who credit Yudkowsky for a central role in the AI safety movement, wouldn’t that have changed what readers perceived as the take-home message?<br /></li><li>The piece says the following about Shane Legg and Demis Hassabis, the founders of DeepMind: “Like the Rationalists, they believed that AI could end up turning against humanity, and because they held this belief, they felt they were among the only ones who were prepared to build it in a safe way.”  This strikes me as a brilliant way to reframe a concern around AI safety as something vaguely sinister.  Imagine if the following framing had been chosen instead: “Amid Silicon Valley’s mad rush to invest in AI, here are the voices urging that it be done safely and in accord with human welfare…”</li></ol>



<p>Reading this article, some will say that they told me so, or even that I was played for a fool.  And yet I confess that, even with hindsight, I have no idea what I should have done differently, how it would’ve improved the outcome, or what I <em>will</em> do differently the next time.  Was there some better, savvier way for me to help out?  For each of the 14 points listed above, were I ever tempted to bang my head and say, “dammit, I wish I’d told Cade X, so his story could’ve reflected that perspective”—well, the truth of the matter is that I <em>did</em> tell him X!  It’s just that I don’t get to decide which X’s make the final cut, or which ideological filter they’re passed through first.</p>



<p>On reflection, then, I’ll continue to talk to journalists, whenever I have time, whenever I think I might know something that might improve their story.  I’ll continue to rank bend-over-backwards openness and honesty among my most fundamental values.  Hell, I’d even talk to Cade for a future story, assuming he’ll talk to me after all the disagreements I’ve aired here!</p>



<p>For one thing that became apparent from this saga is that I <em>do</em> have a deep difference with the rationalists, one that will likely prevent me from ever truly joining them.  Yes, there might be true and important things that one can’t say without risking one’s livelihood.  At least, there were in every <em>other</em> time and culture, so it would be shocking if Western culture circa 2021 were the lone exception.  But unlike the rationalists, I don’t feel the urge to form walled gardens in which to say those things anyway.  I simply accept that, in the age of instantaneous communication, <em>there are no walled gardens</em>: anything you say to a dozen or more people, you might as well broadcast to the planet.  Sure, we all have things we say only in the privacy of our homes or to a few friends—a privilege that I expect even the most orthodox would like to preserve, at any rate for themselves.  Beyond that, though, my impulse has always been to look for non-obvious truths that <em>can</em> be shared openly, and that might light little candles of understanding in one or two minds—and then to shout those truths from the rooftops under my own name, and learn what I can from whatever sounds come in reply.</p>



<p>So I’m thrilled that Scott Alexander Siskind has now rearranged his life to have the same privilege.  Whatever its intentions, I hope today’s <em>New York Times</em> article draws tens of thousands of curious new readers to Scott’s new-yet-old blog, <a href="https://astralcodexten.substack.com/">Astral Codex Ten</a>, so they can see for themselves what I and so many others saw in it.  I hope Scott continues blogging for decades.  And whatever obscene amount of money Substack is now paying Scott, I hope they’ll soon be paying him even more.</p>



<p></p><hr /><p></p>



<p>Alright, now for the promised quote, from <a href="https://slatestarcodex.com/2014/09/30/i-can-tolerate-anything-except-the-outgroup/">I Can Tolerate Anything Except the Outgroup</a>.</p>



<blockquote class="wp-block-quote"><p>The Red Tribe is most classically typified by conservative political beliefs, strong evangelical religious beliefs, creationism, opposing gay marriage, owning guns, eating steak, drinking Coca-Cola, driving SUVs, watching lots of TV, enjoying American football, getting conspicuously upset about terrorists and commies, marrying early, divorcing early, shouting “USA IS NUMBER ONE!!!”, and listening to country music.</p><p>The Blue Tribe is most classically typified by liberal political beliefs, vague agnosticism, supporting gay rights, thinking guns are barbaric, eating arugula, drinking fancy bottled water, driving Priuses, reading lots of books, being highly educated, mocking American football, feeling vaguely like they should like soccer but never really being able to get into it, getting conspicuously upset about sexists and bigots, marrying later, constantly pointing out how much more civilized European countries are than America, and listening to “everything except country”.</p><p>(There is a partly-formed attempt to spin off a Grey Tribe typified by libertarian political beliefs, Dawkins-style atheism, vague annoyance that the question of gay rights even comes up, eating paleo, drinking Soylent, calling in rides on Uber, reading lots of blogs, calling American football “sportsball”, getting conspicuously upset about the War on Drugs and the NSA, and listening to filk – but for our current purposes this is a distraction and they can safely be considered part of the Blue Tribe most of the time)</p><p>… Even in something as seemingly politically uncharged as going to California Pizza Kitchen or Sushi House for dinner, I’m restricting myself to the set of people who like cute artisanal pizzas or sophsticated foreign foods, which are classically Blue Tribe characteristics.</p></blockquote></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5310"><span class="datestr">at February 13, 2021 09:16 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/011">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/011">TR21-011 |  Classification of the streaming approximability of Boolean CSPs | 

	Santhoshini Velusamy, 

	Chi-Ning  Chou, 

	Madhu Sudan, 

	Alexander Golovnev</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A Boolean constraint satisfaction problem (CSP), Max-CSP$(f)$, is a maximization problem specified by a constraint $f:\{-1,1\}^k\to\{0,1\}$. An instance of the problem consists of $m$ constraint applications on $n$ Boolean variables, where each constraint application applies the constraint to $k$ literals chosen from the $n$ variables and their negations. The goal is to compute the maximum number of constraints that can be satisfied by a Boolean assignment to the $n$ variables. In the $(\gamma,\beta)$-approximation version of the problem for parameters $\gamma \geq \beta \in [0,1]$, the goal is to distinguish instances where at least $\gamma$ fraction of the constraints can be satisfied from instances where at most $\beta$ fraction of the constraints can be satisfied. 

In this work we completely characterize the approximability of all Boolean CSPs in the streaming model. Specifically, given $f$, $\gamma$ and $\beta$ we show that either (1) the $(\gamma,\beta)$-approximation version of Max-CSP$(f)$ has a probabilistic streaming algorithm using $O(\log n)$ space, or (2) for every $\epsilon &gt; 0$ the $(\gamma-\epsilon,\beta+\epsilon)$-approximation version of Max-CSP$(f)$ requires $\Omega(\sqrt{n})$ space for probabilistic streaming algorithms. Previously such a separation was known only for $k=2$. We stress that for $k=2$, there are only finitely many distinct problems to consider.

Our positive results show wider applicability of bias-based algorithms used previously by [Guruswami-Velingker-Velusamy APPROX'17], [Chou-Golovnev-Velusamy FOCS'20] by giving a systematic way to explore biases. Our negative results combine the Fourier analytic methods of [Kapralov-Khanna-Sudan SODA'15], which we extend to a wider class of CSPs, with a rich collection of reductions among communication complexity problems that lie at the heart of the negative results.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/011"><span class="datestr">at February 13, 2021 06:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/02/12/postdoc-in-algorithms-and-complexity-at-university-of-oxford-apply-by-march-26-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/02/12/postdoc-in-algorithms-and-complexity-at-university-of-oxford-apply-by-march-26-2021/">postdoc in algorithms and complexity  at University of Oxford (apply by March 26, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>4-year postdoctoral position working with Leslie Ann Goldberg from 1 Oct 2021.</p>
<p>Website: <a href="https://my.corehr.com/pls/uoxrecruit/erq_jobspec_details_form.jobspec?p_id=149618">https://my.corehr.com/pls/uoxrecruit/erq_jobspec_details_form.jobspec?p_id=149618</a><br />
Email: leslie.goldberg@cs.ox.ac.uk</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/02/12/postdoc-in-algorithms-and-complexity-at-university-of-oxford-apply-by-march-26-2021/"><span class="datestr">at February 12, 2021 11:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=838">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2021/02/11/submitting-to-icalp-2021/">Submitting to ICALP 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>I am taking advantage of the pandemic to participate in conferences where it’s usually hard for me to participate because they require intercontinental travel.  I have a paper in CSR 2021, and now am submitting a paper to ICALP 2021 (I count submission as participation, even in case the paper gets rejected).  The latter requires submissions to be formatted in a specific way, <a href="https://emanueleviola.wordpress.com/tag/utopia-tcs/">a topic discussed at length on this blog</a>.</p>



<p>Begin 12:48</p>



<p>Download the LIPICs package.</p>



<p>Try to compile their sample paper.</p>



<p>Get error message:  ! LaTeX Error: File `l3backend-dvips.def’ not found.</p>



<p>Google solution.  Says to install packages.</p>



<p>Unfortunately, I am using windows but I only have LyX, and the solution expects MixTeX.</p>



<p>Google how to install packages in LyX.</p>



<p>Can’t find anything simple.</p>



<p>Create a new document on overleaf.</p>



<p>Copy all the LIPIcs files there.</p>



<p>Try to compile their sample.</p>



<p>It works!</p>



<p>Paste my latex.</p>



<p>Usual avalanche of problems to be fixed at the speed of light.</p>



<p>Add dummy section “Introduction” which wasn’t in my paper, otherwise theorem numbers look weird.</p>



<p>Numbers still look weird.  Something’s wrong with theorem statements.</p>



<p>Replace {thm} with {theorem}</p>



<p>Looks better.  Still some wrong stuff all around, however.</p>



<p>No it wasn’t that.  Remove the dummy section.  It seems their “paragraph” environment puts strange numbers like 0.0.0.1</p>



<p>Replace \paragaph with \paragaph* everywhere</p>



<p>Actually, looks weird the way they put the ack– put back the dummy Introduction section.</p>



<p>Check page limit: <strong>no more than 12 pages, excluding references</strong></p>



<p>I’m a little over.  Does this really matter?  Apparently, <a href="https://emanueleviola.wordpress.com/2014/09/30/eliminate-all-formatting-requirements-survival-tip/">it does!</a>  Move last proof to the appendix.  Actually, last proof is kind of short, I should move the penultimate proof. Update paper organization (next time I shouldn’t put it).</p>



<p>Final look.  Fix a few indentations.</p>



<p>OK, time to actually submit.  Go to the easychair website.  They want me to re-enter all the information!?  Why, after forcing me to enter title, keywords, etc. in <em>their </em>format, are they asking me to do this again?  Can’t we just send the .tex file and extract it from there?</p>



<p>Oh come one, it’s just a few seconds of copy-paste.</p>



<p>OK, done, paper submitted.</p>



<p>End: 3:05</p>



<p>Well, next time it will be easier.  Perhaps <em>easier</em>, but not <em>easy</em> because as the reader knows there will be another missing package, another incompatible system, etc.  And of course, if the paper is rejected, then I won’t even save the time to convert it into camera-ready format.  On the other hand, the benefit is non-existent.  It would be better for everyone if in order to submit a paper you have to complete a random 1-hour task on Amazon mechanical Turk and donate the profit to charity.</p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2021/02/11/submitting-to-icalp-2021/"><span class="datestr">at February 11, 2021 01:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/010">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/010">TR21-010 |  Cryptographic Hardness under Projections for Time-Bounded Kolmogorov Complexity | 

	Eric Allender, 

	John Gouwar, 

	Shuichi Hirahara, 

	Caleb Robelle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A version of time-bounded Kolmogorov complexity, denoted KT, has received attention in the past several years, due to its close connection to circuit complexity and to the Minimum Circuit Size Problem MCSP. Essentially all results about the complexity of MCSP hold also for MKTP (the problem of computing the KT complexity of a string). Both MKTP and MCSP are hard for SZK (Statistical Zero Knowledge) under BPP-Turing reductions; neither is known to be NP-complete. Recently, some hardness results for MKTP were proved that are not (yet) known to hold for MCSP. In particular, MKTP is hard for DET (a subclass of P) under nonuniform NC^0 m-reductions.

In this paper, we improve this, to show that MKTP is hard for the (apparently larger) class NISZK_L under not only NC^0 m-reductions but even under projections. Also MKTP is hard for NISZK under P/poly m-reductions. Here, NISZK is the class of problems with non-interactive zero-knowledge proofs, and NISZK_L is the non-interactive version of the class SZK_L that was studied by Dvir et al.

As an application, we provide several improved worst-case to average-case reductions to problems in NP.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/010"><span class="datestr">at February 11, 2021 12:24 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://thmatters.wordpress.com/?p=1318">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/sigact.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://thmatters.wordpress.com/2021/02/10/sigact-award-deadlines-for-2021/">SIGACT Award deadlines for 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>From the SIGACT executive committee:</p>



<p>The deadlines to submit nominations for the Gödel Prize and the SIGACT Distinguished Service Award are coming soon. Calls for nominations for both awards can be found at the links below.</p>



<ul><li><a href="https://www.sigact.org/prizes/g%C3%B6del/g%C3%B6del_call21.pdf">Gödel Prize</a>: deadline <strong>February 28</strong>, 2021.</li><li><a href="https://sigact.org/prizes/service.html">SIGACT Distinguished Service Award</a>: deadline <strong>March 8</strong>, 2021.</li></ul></div>







<p class="date">
by shuchic <a href="https://thmatters.wordpress.com/2021/02/10/sigact-award-deadlines-for-2021/"><span class="datestr">at February 10, 2021 08:39 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://bit-player.org/?p=2296">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/hayes.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="http://bit-player.org/2021/foldable-words">Foldable Words</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://bit-player.org" title="bit-player">bit-player</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Packing up the household for a recent move, I was delving into shoeboxes, photo albums, and file folders that had not been opened in decades. One of my discoveries, found in an envelope at the back of a file drawer, was the paper sleeve from a drinking straw, imprinted with a saccharine message:</p>
<p><img src="http://bit-player.org/wp-content/uploads/2021/01/Its-a-Pleasure-to-Serve-You-recto.jpg" height="82" width="640" alt="Drinking-straw wrapper inscribed “It’s A Pleasure To Serve You”" border="0" class="centered" /></p>
<p>This flimsy slip of paper seems like an odd scrap to preserve for the ages, but when I pulled it out of the envelope, I knew instantly where it came from and why I had saved it.</p>
<p>The year was 1967. I was 17 then; I’m 71 now. Transposing those two digits takes just a flick of the fingertips. I can blithely skip back and forth from one prime number to the other. But the span of lived time between 1967 and 2021 is a chasm I cannot so easily leap across. At 17 I was in a great hurry to grow up, but I couldn’t see as far as 71; I didn’t even try. Going the other way—revisiting the mental and emotional life of an adolescent boy—is also a journey deep into alien territory. But the straw wrapper helps—it’s a Proustian <em>aide memoire</em>.</p>
<p>In the spring of 1967 I had a girlfriend, Lynn. After school we would meet at the Maple Diner, where the booths had red leatherette upholstery and formica tabletops with a boomerang motif. We’d order two Cokes and a plate of french fries to share. The waitress liked us; she’d make sure we had a full bottle of ketchup. I mention the ketchup because it was a token of our progress toward intimacy. On our first dates Lynn had put only a dainty dab on her fries, but by April we were comfortable enough to reveal our true appetites.</p>
<p>One afternoon I noticed she was fiddling intently with the wrapper from her straw, folding and refolding. I had no idea what she was up to. A teeny paper airplane she would sail over my head? When she finished, she pushed her creation across the table:</p>
<p><img src="http://bit-player.org/wp-content/uploads/2021/01/Its-a-Pleasure-to-Serve-You-folded.jpg" height="" width="250" alt="“It’s a Pleasure to Serve You” folded to read “I love You”" border="0" class="centered" /></p>
<p>What a wallop there was in that little wad of paper. At that point in our romance, the words had not yet been spoken aloud. </p>
<p>How did I respond to Lynn’s folded declaration? I can’t remember; the words are lost. But evidently I got through that awkward moment without doing any permanent damage. A year later Lynn and I were married.</p>
<p>Today, at 71, with the preserved artifact in front of me, my chief regret is that I failed to take up the challenge implicit in the word game Lynn had invented. Why didn’t I craft a reply by folding my own straw wrapper? There are quite a few messages I could have extracted by strategic deletions from “It’s a pleasure to serve you.”</p>
<div style="padding: 1em;">
<pre style="padding: 0.5em;">          <strong>i</strong><span style="color: #ccc;">tsap</span><strong>l</strong><span style="color: #ccc;">easuret</span><strong>o</strong><span style="color: #ccc;">ser</span><strong>veyou</strong>   ==&gt;   I love you.</pre>
<pre style="padding: 0.5em;">          <strong>i</strong><span style="color: #ccc;">tsa</span><strong>pleas</strong><span style="color: #ccc;">ur</span><strong>e</strong><span style="color: #ccc;">toserve</span><strong>you</strong>   ==&gt;   I please you.</pre>
<pre style="padding: 0.5em;">          <strong>it</strong><span style="color: #ccc;">sapl</span><strong>eas</strong><span style="color: #ccc;">ur</span><strong>e</strong><span style="color: #ccc;">toserve</span><strong>you</strong>   ==&gt;   I tease you.</pre>
<pre style="padding: 0.5em;">          <strong>i</strong><span style="color: #ccc;">tsa</span><strong>pleasure</strong><span style="color: #ccc;">toserve</span><strong>you</strong>   ==&gt;   I pleasure you.</pre>
<pre style="padding: 0.5em;">          <strong>i</strong><span style="color: #ccc;">tsa</span><strong>p</strong><span style="color: #ccc;">l</span><strong>e</strong><span style="color: #ccc;">a</span><strong>s</strong><span style="color: #ccc;">ure</span><strong>t</strong><span style="color: #ccc;">os</span><strong>er</strong><span style="color: #ccc;">ve</span><strong>you</strong>   ==&gt;   I pester you.</pre>
<pre style="padding: 0.5em;">          <strong>i</strong><span style="color: #ccc;">tsa</span><strong>p</strong><span style="color: #ccc;">l</span><strong>e</strong><span style="color: #ccc;">asur</span><strong>e</strong><span style="color: #ccc;">toser</span><strong>veyou</strong>   ==&gt;   I peeve you.</pre>
<pre style="padding: 0.5em;">          <strong>i</strong><span style="color: #ccc;">t</span><strong>sa</strong><span style="color: #ccc;">p</span><strong>l</strong><span style="color: #ccc;">eas</span><strong>u</strong><span style="color: #ccc;">re</span><strong>t</strong><span style="color: #ccc;">os</span><strong>e</strong><span style="color: #ccc;">rve</span><strong>you</strong>   ==&gt;   I salute you.</pre>
<pre style="padding: 0.5em;">          <strong>i</strong><span style="color: #ccc;">tsap</span><strong>lea</strong><span style="color: #ccc;">suretoser</span><strong>veyou</strong>   ==&gt;   I leave you.</pre>
</div>
<p class="indent">Not all of those statements would have been suited to the occasion of our rendezvous at the Maple Diner, but over the course of our years together—17 years, as it turned out—there came a moment for each of them.</p>
<hr />
<p>How many words can we form by making folds in the straw-paper slogan? I could not have answered that question in 1967. I couldn’t have even asked it. But times change. Enumerating all the foldable messages now strikes me as an obvious thing to do when presented with the straw wrapper. Furthermore, I have the computational means to do it—although the project was not quite as easy as I expected.</p>
<p>A first step is to be explicit about the rules of the game. We are given a source text, in this case “It’s a pleasure to serve you.” Let us ignore the spaces between words as well as all punctuation and capitalization; in this way we arrive at the normalized text “itsapleasuretoserveyou”. A word is <em>foldable</em> if all of its letters appear in the normalized text in the correct order (though not necessarily consecutively). The folding operation amounts to an editing process in which our only permitted act is deletion of letters; we are not allowed to insert, substitute, or permute. If two or more foldable words are to be combined to make a phrase or sentence, they must follow one another in the correct order without overlaps.</p>
<p>So much for foldability. Next comes the fraught question: What is a word? Linguists and lexicographers offer many subtly divergent opinions on this point, but for present purposes a very simple definition will suffice: A finite sequence of characters drawn from the 26-letter English alphabet is a word if it can legally be played in a game of Scrabble. I have been working with a word list from the 2015 edition of <a href="https://en.wikipedia.org/wiki/Collins_Scrabble_Words">Collins Scrabble Words</a>, which has about 270,000 entries. (There are a number of alternative lists, which I discuss in an appendix at the end of this article.)</p>
<p>Scrabble words range in length from 2 to 15 letters. The upper limit—determined by the size of the game board—is not much of a concern. You’re unlikely to meet a straw-paper text that folds to yield words longer than <em>sesquipedalian</em>. The absence of 1-letter words is more troubling, but the remedy is easy: I simply added the words <em>a</em>, <em>I</em>, and <em>O</em> to my copy of the Scrabble list.</p>
<p>My first computational experiments with foldable words searched for examples at random. Writing a program for random sampling is often easier than taking an exact census of a population, and the sample offers a quick glimpse of typical results. The following Python procedure generates random foldable sequences of letters drawn from a given source text, then returns those sequences that are found in the Scrabble word list. (The parameter <em>k</em> is the length of the words to be generated, and <em>reps</em> specifies the number of random trials.)</p>
<pre class="language-python"><code>def randomFoldableWords(text, lexicon, k, reps):
    normtext = normalize(text)
    n = len(normtext)
    findings = []
    for i in range(reps):
        indices = random.sample(range(n), k)
        indices.sort()
        letters = ""
        for idx in indices:
            letters += normtext[idx]
        if letters in lexicon:
            findings.append(letters)
    return findings</code></pre>
<p>Here are the six-letter foldable words found by invoking the program as follows: <code class="language-python">randomFoldableWords(scrabblewords, 6, 10000)</code>. </p>
<blockquote><p>please, plater, searer, saeter, parter, sleety, sleeve, parser, purvey, laster, islets, taster, tester, slarts, paseos, tapers, saeter, eatery, salute, tsetse, setose, salues, sparer</p></blockquote>
<p>Note that the word saeter (you could look it up—I had to) appears twice in this list. The frequency of such repetitions can yield an estimate of the total population size. A variant of the <a href="http://www.pitt.edu/~yuc2/cr/history.htm">mark-and-recapture</a> method, well-known in wildlife ecology, led me to an estimate of 92 six-letter foldable Scrabble words in the straw-wrapper slogan. The actual number turns out to be 106.</p>
<p>Samples and estimates are helpful, but they leave me wondering, What am I missing? What strange and beautiful word has failed to turn up in any of the samples, like the big fish that never takes the bait? I had to have an exhaustive list.</p>
<hr />
<p>In many word games, the tool of choice for computer-aided playing (or cheating) is the regular expression, or regex. A regex is a pattern defining a set of strings, or character sequences; from a collection of strings, a regex search will pick out those that match the pattern. For example, the regular expression <code>^.*love.*$</code> selects from the Scrabble word list all words that have the letter sequence <em>love</em> somewhere within them. There are 137 such words, including some that I would not have thought of, such as <em>rollover</em> and <em>slovenly</em>. The regex <code>^.*l.*o.*v.*e.*$</code> finds all words in which <em>l, o, v,</em> and <em>e</em> appear in sequence, whether of not they are adjacent. The set has 267 members, including such secret-lover gems as <em>bloviate</em>, <em>electropositive</em>, and <em>leftovers</em>.</p>
<p>A solution to the foldable words problem could surely be crafted with regular expressions, but I am not a regex wizard. In search of a more muggles-friendly strategy, my first thought was to extend the idea behind the random-sampling procedure. Instead of selecting foldable sequences at random, I’d generate all of them, and check each one against the word list.</p>
<p>The procedure below generates all three-letter strings that can be folded from the given text, and returns the subset of those strings that appear in the Scrabble word list:</p>
<pre><code class="language-python">def foldableStrings3(lexicon, text):
    normtext = normalize(text)
    n = len(normtext)
    words = []
    for i in range(0, n-2):
        for j in range(i+1, n-1):
            for k in range(j+1, n):
                s = normtext[i] + normtext[j] + normtext[k]
                if s in lexicon:
                    words.append(s)
    return(words)</code></pre>
<p>At the heart of the procedure are three nested loops that methodically step through all the foldable combinations: For any initial letter <code>text[i]</code> we can choose any following letter <code>text[j]</code> with<code> j &gt; i</code>; likewise <code>text[j]</code> can be followed by any <code>text[k]</code> with <code>k &gt; j</code>. This scheme works perfectly well, finding 348 instances of three-letter words. I speak of “instances” because some words appear in the list more than once; for example, <em>pee</em> can be formed in three ways. If we count only unique words, there are 137.</p>
<p>Following this model, we could write a separate routine for each word length from 1 to 15 letters, but that looks like a dreary and repetitious task. Nobody wants to write a procedure with loops nested 15 deep. An alternative is to write a meta-procedure, which would generate the appropriate procedure for each word length. I made a start on that exercise in advanced loopology, but before I got very far I realized there’s an easier way. I was wondering: In a text of <em>n</em> letters, how many foldable substrings exist—whether or not they are recognizable words? There are several ways of answering this question, but to me the most illuminating argument comes from an inclusion/​exclusion principle. Consider the first letter of the text, which in our case is the letter <em>I</em>. In the set of all foldable strings, half include this letter and half exclude it. The same is true of the second letter, and the third, and so on. Thus each letter added to the text doubles the number of foldable strings, which means the total number of strings is simply \(2^n\). (Included in this count is the empty string, made up of no letters.)</p>
<p>This observation suggests a simple algorithm for generating all the foldable strings in any <em>n</em>-letter text. Just count from \(0\) to \(2^{n} - 1\), and for each value along the way line up the binary representation of the number with the letters of the text. Then select those letters that correspond to a <code>1</code> bit, like so:</p>
<div style="padding: 1em;">
<pre style="padding: 0.5em;">                    <span style="color: #ccc;">itsa</span><strong>p</strong><span style="color: #ccc;">leasu</span><strong>re</strong><span style="color: #ccc;">to</span><strong>serve</strong><span style="color: #ccc;">you</span>
                    0000100000110011111000</pre>
</div>
<p>And so we see that the word <code>preserve</code> corresponds to the binary representation of the number <code>134392</code>.</p>
<p>Counting is something that computers are good at, so a word-search procedure based on this principle is straightforward:</p>
<pre><code class="language-python">def foldablesByCounting(lexicon, text):
    normtext = normalize(text)
    n = len(normtext)
    words = []
    for i in range(2**n - 1):
        charSeq = ''
        positions = positionsOf1Bits(i, n)
        for p in positions:
            charSeq += normtext[p]
        if charSeq in lexicon:
            words.append(charSeq)
    return(words)</code></pre>
<p>The outer loop (variable <code>i</code>) counts from \(0\) to \(2^{n} - 1\); for each of these numbers the inner loop (variable <code>p</code>) picks out the letters corresponding to 1 bits. The program produces the output expected. Unfortunately, it does so very slowly. For every character added to the text, running time roughly doubles. I haven’t the patience to plod through the \(2^22\) patterns in “itsapleasuretoserveyou”; estimates based on shorter phrases suggest the running time would be more than three hours.</p>
<hr />
<p>In the middle of the night I realized my approach to this problem was totally backwards. Instead of blindly generating all possible character strings and filtering out the few genuine words, I could march through the list of Scrabble words and test each of them to see if it’s foldable. At worst I would have to try some 270,000 words. I could speed things up even more by making a preliminary pass through the Scrabble list, discarding all words that include characters not present in the normalized text. For the text “It’s a pleasure to serve you,” the character set has just 12 members: <code>aeiloprstuvy</code>. Allowing only words formed from these letters slashes the Scrabble list down to a length of 12,816.</p>
<p>To make this algorithm work, we need a procedure to report whether or not a word can be formed by folding the given text. The simplest approach is to slide the candidate word along the text, looking for a match for each character in turn:</p>
<div style="padding: 0.5em;">
<pre>                    taste
                    <span style="color: #ccc;">itsapleasuretoserveyou</span>

                     <strong>t</strong>aste
                    <span style="color: #ccc;">i</span><strong>t</strong><span style="color: #ccc;">sapleasuretoserveyou</span>

                     <strong>t a</strong>ste
                    <span style="color: #ccc;">i</span><strong>t</strong><span style="color: #ccc;">s</span><strong>a</strong><span style="color: #ccc;">pleasuretoserveyou</span>

                     <strong>t a    s</strong>te
                    <span style="color: #ccc;">i</span><strong>t</strong><span style="color: #ccc;">s</span><strong>a</strong><span style="color: #ccc;">plea</span><strong>s</strong><span style="color: #ccc;">uretoserveyou</span>

                     <strong>t a    s   t</strong>e
                    <span style="color: #ccc;">i</span><strong>t</strong><span style="color: #ccc;">s</span><strong>a</strong><span style="color: #ccc;">plea</span><strong>s</strong><span style="color: #ccc;">ure</span><strong>t</strong><span style="color: #ccc;">oserveyou</span>

                     <strong>t a    s   t  e</strong>
                    <span style="color: #ccc;">i</span><strong>t</strong><span style="color: #ccc;">s</span><strong>a</strong><span style="color: #ccc;">plea</span><strong>s</strong><span style="color: #ccc;">ure</span><strong>t</strong><span style="color: #ccc;">os</span><strong>e</strong><span style="color: #ccc;">rveyou</span>
</pre>
</div>
<p>If every letter of the word finds a mate in the text, the word is foldable, as in the case of <code>taste</code>, shown above. But an attempt to match <code>tastes</code> would fall off the end of the text looking for a second <code>s</code>, which does not exist.</p>
<p>The following code implements this idea:</p>
<pre><code class="language-python">def wordIsFoldable(word, text):
    normtext = normalize(text)
    t = 0                      # pointer to positions in normtext
    w = 0                      # pointer to positions in word
    while t &lt; len(normtext):
        if word[w] == normtext[t]:  # matching chars in word and text
            w += 1                  # move to next char in word
        if w == len(word):          # matched all chars in word
            return(True)            # so: thumbs up
        t += 1                 # move to next char in text
    return(False)              # fell off the end: thumbs down</code></pre>
<p>All we need to do now is embed this procedure in a loop that steps through all the candidate Scrabble words, collecting those for which <code>wordIsFoldable</code> returns <code>True</code>. </p>
<p>There’s still some waste motion here, since we are searching letter-by-letter through the same text, and repeating the same searches thousands of times. The source code (available on GitHub as a <a href="https://github.com/bit-player/foldable-words">Jupyter notebook</a>) explains some further speedups. But even the simple version shown here runs in less than two tenths of a second, so there’s not much point in optimizing.</p>
<p>I can now report that there are 778 unique foldable Scrabble words in “It’s a pleasure to serve you” (including the three one-letter words I added to the list). Words that can be formed in multiple ways bring the total count to 899.</p>
<p>And so we come to the tah-dah! moment—the unveiling of the complete list. I have organized the words into groups based on each word’s starting position within the text. (By Python convention, the positions are numbered from 0 through \(n-1\).) Within each group, the words are sorted according to the position of their last character; that position is given in the subscript following the word. For example, <em>tapestry</em> is in Group 1 because it begins at position 1 in the text (the <em>t</em> in <em>It’s</em>), and it carries the subscript 19 because it ends at position 19 (the <em>y</em> in <em>you</em>). </p>
<p>This arrangement of the words is meant to aid in contructing multiword phrases. If a word ends at position \(m\), the next word in the phrase must come from a group numbered \(m+1\) or greater. </p>
<p><br /></p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 0:</b> i<sub>0</sub> it<sub>1</sub> is<sub>2</sub> its<sub>2</sub> ita<sub>3</sub> isle<sub>6</sub> ilea<sub>7</sub> isles<sub>8</sub> itas<sub>8</sub> ire<sub>11</sub> issue<sub>11</sub> iure<sub>11</sub> islet<sub>12</sub> io<sub>13</sub> iso<sub>13</sub> ileus<sub>14</sub> ios<sub>14</sub> ires<sub>14</sub> islets<sub>14</sub> isos<sub>14</sub> issues<sub>14</sub> issuer<sub>16</sub> ivy<sub>19</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 1:</b> ta<sub>3</sub> tap<sub>4</sub> tae<sub>6</sub> tale<sub>6</sub> tape<sub>6</sub> te<sub>6</sub> tala<sub>7</sub> talea<sub>7</sub> tapa<sub>7</sub> tea<sub>7</sub> taes<sub>8</sub> talas<sub>8</sub> tales<sub>8</sub> tapas<sub>8</sub> tapes<sub>8</sub> taps<sub>8</sub> tas<sub>8</sub> teas<sub>8</sub> tes<sub>8</sub> tapu<sub>9</sub> tau<sub>9</sub> talar<sub>10</sub> taler<sub>10</sub> taper<sub>10</sub> tar<sub>10</sub> tear<sub>10</sub> tsar<sub>10</sub> taleae<sub>11</sub> tare<sub>11</sub> tease<sub>11</sub> tee<sub>11</sub> tapet<sub>12</sub> tart<sub>12</sub> tat<sub>12</sub> taut<sub>12</sub> teat<sub>12</sub> test<sub>12</sub> tet<sub>12</sub> tret<sub>12</sub> tut<sub>12</sub> tao<sub>13</sub> taro<sub>13</sub> to<sub>13</sub> talars<sub>14</sub> talers<sub>14</sub> talus<sub>14</sub> taos<sub>14</sub> tapers<sub>14</sub> tapets<sub>14</sub> tapus<sub>14</sub> tares<sub>14</sub> taros<sub>14</sub> tars<sub>14</sub> tarts<sub>14</sub> tass<sub>14</sub> tats<sub>14</sub> taus<sub>14</sub> tauts<sub>14</sub> tears<sub>14</sub> teases<sub>14</sub> teats<sub>14</sub> tees<sub>14</sub> teres<sub>14</sub> terts<sub>14</sub> tests<sub>14</sub> tets<sub>14</sub> tres<sub>14</sub> trets<sub>14</sub> tsars<sub>14</sub> tuts<sub>14</sub> tasse<sub>15</sub> taste<sub>15</sub> tate<sub>15</sub> terete<sub>15</sub> terse<sub>15</sub> teste<sub>15</sub> tete<sub>15</sub> toe<sub>15</sub> tose<sub>15</sub> tree<sub>15</sub> tsetse<sub>15</sub> taperer<sub>16</sub> tapster<sub>16</sub> tarter<sub>16</sub> taser<sub>16</sub> taster<sub>16</sub> tater<sub>16</sub> tauter<sub>16</sub> tearer<sub>16</sub> teaser<sub>16</sub> teer<sub>16</sub> teeter<sub>16</sub> terser<sub>16</sub> tester<sub>16</sub> tor<sub>16</sub> tutor<sub>16</sub> tav<sub>17</sub> tarre<sub>18</sub> testee<sub>18</sub> tore<sub>18</sub> trove<sub>18</sub> tutee<sub>18</sub> tapestry<sub>19</sub> tapstry<sub>19</sub> tarry<sub>19</sub> tarty<sub>19</sub> tasty<sub>19</sub> tay<sub>19</sub> teary<sub>19</sub> terry<sub>19</sub> testy<sub>19</sub> toey<sub>19</sub> tory<sub>19</sub> toy<sub>19</sub> trey<sub>19</sub> troy<sub>19</sub> try<sub>19</sub> too<sub>20</sub> toro<sub>20</sub> toyo<sub>20</sub> tatou<sub>21</sub> tatu<sub>21</sub> tutu<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 2:</b> sap<sub>4</sub> sal<sub>5</sub> sae<sub>6</sub> sale<sub>6</sub> sea<sub>7</sub> spa<sub>7</sub> sales<sub>8</sub> sals<sub>8</sub> saps<sub>8</sub> seas<sub>8</sub> spas<sub>8</sub> sau<sub>9</sub> sar<sub>10</sub> sear<sub>10</sub> ser<sub>10</sub> slur<sub>10</sub> spar<sub>10</sub> spear<sub>10</sub> spur<sub>10</sub> sur<sub>10</sub> salse<sub>11</sub> salue<sub>11</sub> seare<sub>11</sub> sease<sub>11</sub> seasure<sub>11</sub> see<sub>11</sub> sere<sub>11</sub> sese<sub>11</sub> slae<sub>11</sub> slee<sub>11</sub> slue<sub>11</sub> spae<sub>11</sub> spare<sub>11</sub> spue<sub>11</sub> sue<sub>11</sub> sure<sub>11</sub> salet<sub>12</sub> salt<sub>12</sub> sat<sub>12</sub> saut<sub>12</sub> seat<sub>12</sub> set<sub>12</sub> slart<sub>12</sub> slat<sub>12</sub> sleet<sub>12</sub> slut<sub>12</sub> spart<sub>12</sub> spat<sub>12</sub> speat<sub>12</sub> spet<sub>12</sub> splat<sub>12</sub> spurt<sub>12</sub> st<sub>12</sub> suet<sub>12</sub> salto<sub>13</sub> so<sub>13</sub> salets<sub>14</sub> salses<sub>14</sub> saltos<sub>14</sub> salts<sub>14</sub> salues<sub>14</sub> sapless<sub>14</sub> saros<sub>14</sub> sars<sub>14</sub> sass<sub>14</sub> sauts<sub>14</sub> sears<sub>14</sub> seases<sub>14</sub> seasures<sub>14</sub> seats<sub>14</sub> sees<sub>14</sub> seres<sub>14</sub> sers<sub>14</sub> sess<sub>14</sub> sets<sub>14</sub> slaes<sub>14</sub> slarts<sub>14</sub> slats<sub>14</sub> sleets<sub>14</sub> slues<sub>14</sub> slurs<sub>14</sub> sluts<sub>14</sub> sos<sub>14</sub> spaes<sub>14</sub> spares<sub>14</sub> spars<sub>14</sub> sparts<sub>14</sub> spats<sub>14</sub> spears<sub>14</sub> speats<sub>14</sub> speos<sub>14</sub> spets<sub>14</sub> splats<sub>14</sub> spues<sub>14</sub> spurs<sub>14</sub> spurts<sub>14</sub> sues<sub>14</sub> suets<sub>14</sub> sures<sub>14</sub> sus<sub>14</sub> salute<sub>15</sub> saree<sub>15</sub> sasse<sub>15</sub> sate<sub>15</sub> saute<sub>15</sub> setose<sub>15</sub> slate<sub>15</sub> sloe<sub>15</sub> sluse<sub>15</sub> sparse<sub>15</sub> spate<sub>15</sub> sperse<sub>15</sub> spree<sub>15</sub> saeter<sub>16</sub> salter<sub>16</sub> saluter<sub>16</sub> sapor<sub>16</sub> sartor<sub>16</sub> saser<sub>16</sub> searer<sub>16</sub> seater<sub>16</sub> seer<sub>16</sub> serer<sub>16</sub> serr<sub>16</sub> slater<sub>16</sub> sleer<sub>16</sub> spaer<sub>16</sub> sparer<sub>16</sub> sparser<sub>16</sub> spearer<sub>16</sub> speer<sub>16</sub> spuer<sub>16</sub> spurter<sub>16</sub> suer<sub>16</sub> surer<sub>16</sub> sutor<sub>16</sub> sav<sub>17</sub> sov<sub>17</sub> salve<sub>18</sub> save<sub>18</sub> serre<sub>18</sub> serve<sub>18</sub> slave<sub>18</sub> sleave<sub>18</sub> sleeve<sub>18</sub> slove<sub>18</sub> sore<sub>18</sub> sparre<sub>18</sub> sperre<sub>18</sub> splore<sub>18</sub> spore<sub>18</sub> stere<sub>18</sub> sterve<sub>18</sub> store<sub>18</sub> stove<sub>18</sub> salary<sub>19</sub> salty<sub>19</sub> sassy<sub>19</sub> saury<sub>19</sub> savey<sub>19</sub> say<sub>19</sub> serry<sub>19</sub> sesey<sub>19</sub> sey<sub>19</sub> slatey<sub>19</sub> slaty<sub>19</sub> slavey<sub>19</sub> slay<sub>19</sub> sleety<sub>19</sub> sley<sub>19</sub> slurry<sub>19</sub> sly<sub>19</sub> soy<sub>19</sub> sparry<sub>19</sub> spay<sub>19</sub> speary<sub>19</sub> splay<sub>19</sub> spry<sub>19</sub> spurrey<sub>19</sub> spurry<sub>19</sub> spy<sub>19</sub> stey<sub>19</sub> storey<sub>19</sub> story<sub>19</sub> sty<sub>19</sub> suety<sub>19</sub> surety<sub>19</sub> surrey<sub>19</sub> survey<sub>19</sub> salvo<sub>20</sub> servo<sub>20</sub> stereo<sub>20</sub> sou<sub>21</sub> susu<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 3:</b> a<sub>3</sub> al<sub>5</sub> ae<sub>6</sub> ale<sub>6</sub> ape<sub>6</sub> aa<sub>7</sub> ala<sub>7</sub> aas<sub>8</sub> alas<sub>8</sub> ales<sub>8</sub> als<sub>8</sub> apes<sub>8</sub> as<sub>8</sub> alu<sub>9</sub> alar<sub>10</sub> aper<sub>10</sub> ar<sub>10</sub> alae<sub>11</sub> alee<sub>11</sub> alure<sub>11</sub> apse<sub>11</sub> are<sub>11</sub> aue<sub>11</sub> alert<sub>12</sub> alt<sub>12</sub> apart<sub>12</sub> apert<sub>12</sub> apt<sub>12</sub> aret<sub>12</sub> art<sub>12</sub> at<sub>12</sub> aero<sub>13</sub> also<sub>13</sub> alto<sub>13</sub> apo<sub>13</sub> apso<sub>13</sub> auto<sub>13</sub> aeros<sub>14</sub> alerts<sub>14</sub> altos<sub>14</sub> alts<sub>14</sub> alures<sub>14</sub> alus<sub>14</sub> apers<sub>14</sub> apos<sub>14</sub> apres<sub>14</sub> apses<sub>14</sub> apsos<sub>14</sub> apts<sub>14</sub> ares<sub>14</sub> arets<sub>14</sub> ars<sub>14</sub> arts<sub>14</sub> ass<sub>14</sub> ats<sub>14</sub> aures<sub>14</sub> autos<sub>14</sub> alate<sub>15</sub> aloe<sub>15</sub> arete<sub>15</sub> arose<sub>15</sub> arse<sub>15</sub> ate<sub>15</sub> alastor<sub>16</sub> alerter<sub>16</sub> alter<sub>16</sub> apter<sub>16</sub> aster<sub>16</sub> arere<sub>18</sub> ave<sub>18</sub> aery<sub>19</sub> alary<sub>19</sub> alay<sub>19</sub> aleatory<sub>19</sub> apay<sub>19</sub> apery<sub>19</sub> arsey<sub>19</sub> arsy<sub>19</sub> artery<sub>19</sub> artsy<sub>19</sub> arty<sub>19</sub> ary<sub>19</sub> ay<sub>19</sub> aloo<sub>20</sub> arvo<sub>20</sub> avo<sub>20</sub> ayu<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 4:</b> pe<sub>6</sub> pa<sub>7</sub> pea<sub>7</sub> plea<sub>7</sub> pas<sub>8</sub> peas<sub>8</sub> pes<sub>8</sub> pleas<sub>8</sub> plu<sub>9</sub> par<sub>10</sub> pear<sub>10</sub> per<sub>10</sub> pur<sub>10</sub> pare<sub>11</sub> pase<sub>11</sub> peare<sub>11</sub> pease<sub>11</sub> pee<sub>11</sub> pere<sub>11</sub> please<sub>11</sub> pleasure<sub>11</sub> plue<sub>11</sub> pre<sub>11</sub> pure<sub>11</sub> part<sub>12</sub> past<sub>12</sub> pat<sub>12</sub> peart<sub>12</sub> peat<sub>12</sub> pert<sub>12</sub> pest<sub>12</sub> pet<sub>12</sub> plast<sub>12</sub> plat<sub>12</sub> pleat<sub>12</sub> pst<sub>12</sub> put<sub>12</sub> pareo<sub>13</sub> paseo<sub>13</sub> peso<sub>13</sub> pesto<sub>13</sub> po<sub>13</sub> pro<sub>13</sub> pareos<sub>14</sub> pares<sub>14</sub> pars<sub>14</sub> parts<sub>14</sub> paseos<sub>14</sub> pases<sub>14</sub> pass<sub>14</sub> pasts<sub>14</sub> pats<sub>14</sub> peares<sub>14</sub> pears<sub>14</sub> peases<sub>14</sub> peats<sub>14</sub> pees<sub>14</sub> peres<sub>14</sub> perts<sub>14</sub> pesos<sub>14</sub> pestos<sub>14</sub> pests<sub>14</sub> pets<sub>14</sub> plats<sub>14</sub> pleases<sub>14</sub> pleasures<sub>14</sub> pleats<sub>14</sub> plues<sub>14</sub> plus<sub>14</sub> pos<sub>14</sub> pros<sub>14</sub> pures<sub>14</sub> purs<sub>14</sub> pus<sub>14</sub> puts<sub>14</sub> parse<sub>15</sub> passe<sub>15</sub> paste<sub>15</sub> pate<sub>15</sub> pause<sub>15</sub> perse<sub>15</sub> plaste<sub>15</sub> plate<sub>15</sub> pose<sub>15</sub> pree<sub>15</sub> prese<sub>15</sub> prose<sub>15</sub> puree<sub>15</sub> purse<sub>15</sub> parer<sub>16</sub> parr<sub>16</sub> parser<sub>16</sub> parter<sub>16</sub> passer<sub>16</sub> paster<sub>16</sub> pastor<sub>16</sub> pater<sub>16</sub> pauser<sub>16</sub> pearter<sub>16</sub> peer<sub>16</sub> perter<sub>16</sub> pester<sub>16</sub> peter<sub>16</sub> plaster<sub>16</sub> plater<sub>16</sub> pleaser<sub>16</sub> pleasurer<sub>16</sub> pleater<sub>16</sub> poser<sub>16</sub> pretor<sub>16</sub> proser<sub>16</sub> puer<sub>16</sub> purer<sub>16</sub> purr<sub>16</sub> purser<sub>16</sub> parev<sub>17</sub> pav<sub>17</sub> perv<sub>17</sub> pareve<sub>18</sub> parore<sub>18</sub> parve<sub>18</sub> passee<sub>18</sub> pave<sub>18</sub> peeve<sub>18</sub> perve<sub>18</sub> petre<sub>18</sub> pore<sub>18</sub> preeve<sub>18</sub> preserve<sub>18</sub> preve<sub>18</sub> prore<sub>18</sub> prove<sub>18</sub> parry<sub>19</sub> party<sub>19</sub> pastry<sub>19</sub> pasty<sub>19</sub> patsy<sub>19</sub> paty<sub>19</sub> pay<sub>19</sub> peatery<sub>19</sub> peaty<sub>19</sub> peavey<sub>19</sub> peavy<sub>19</sub> peeoy<sub>19</sub> peery<sub>19</sub> perry<sub>19</sub> pervy<sub>19</sub> pesty<sub>19</sub> plastery<sub>19</sub> platy<sub>19</sub> play<sub>19</sub> ploy<sub>19</sub> plurry<sub>19</sub> ply<sub>19</sub> pory<sub>19</sub> posey<sub>19</sub> posy<sub>19</sub> prey<sub>19</sub> prosy<sub>19</sub> pry<sub>19</sub> pursy<sub>19</sub> purty<sub>19</sub> purvey<sub>19</sub> puy<sub>19</sub> parvo<sub>20</sub> poo<sub>20</sub> proo<sub>20</sub> proso<sub>20</sub> pareu<sub>21</sub> patu<sub>21</sub> poyou<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 5:</b> la<sub>7</sub> lea<sub>7</sub> las<sub>8</sub> leas<sub>8</sub> les<sub>8</sub> leu<sub>9</sub> lar<sub>10</sub> lear<sub>10</sub> lur<sub>10</sub> lare<sub>11</sub> lase<sub>11</sub> leare<sub>11</sub> lease<sub>11</sub> leasure<sub>11</sub> lee<sub>11</sub> lere<sub>11</sub> lure<sub>11</sub> last<sub>12</sub> lat<sub>12</sub> least<sub>12</sub> leat<sub>12</sub> leet<sub>12</sub> lest<sub>12</sub> let<sub>12</sub> lo<sub>13</sub> lares<sub>14</sub> lars<sub>14</sub> lases<sub>14</sub> lass<sub>14</sub> lasts<sub>14</sub> lats<sub>14</sub> leares<sub>14</sub> lears<sub>14</sub> leases<sub>14</sub> leasts<sub>14</sub> leasures<sub>14</sub> leats<sub>14</sub> lees<sub>14</sub> leets<sub>14</sub> leres<sub>14</sub> leses<sub>14</sub> less<sub>14</sub> lests<sub>14</sub> lets<sub>14</sub> los<sub>14</sub> lues<sub>14</sub> lures<sub>14</sub> lurs<sub>14</sub> laree<sub>15</sub> late<sub>15</sub> leese<sub>15</sub> lose<sub>15</sub> lute<sub>15</sub> laer<sub>16</sub> laser<sub>16</sub> laster<sub>16</sub> later<sub>16</sub> leaser<sub>16</sub> leer<sub>16</sub> lesser<sub>16</sub> lor<sub>16</sub> loser<sub>16</sub> lurer<sub>16</sub> luser<sub>16</sub> luter<sub>16</sub> lav<sub>17</sub> lev<sub>17</sub> luv<sub>17</sub> lave<sub>18</sub> leave<sub>18</sub> lessee<sub>18</sub> leve<sub>18</sub> lore<sub>18</sub> love<sub>18</sub> lurve<sub>18</sub> lay<sub>19</sub> leary<sub>19</sub> leavy<sub>19</sub> leery<sub>19</sub> levy<sub>19</sub> ley<sub>19</sub> lory<sub>19</sub> lovey<sub>19</sub> loy<sub>19</sub> lurry<sub>19</sub> laevo<sub>20</sub> lasso<sub>20</sub> levo<sub>20</sub> loo<sub>20</sub> lassu<sub>21</sub> latu<sub>21</sub> lou<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 6:</b> ea<sub>7</sub> eas<sub>8</sub> es<sub>8</sub> eau<sub>9</sub> ear<sub>10</sub> er<sub>10</sub> ease<sub>11</sub> ee<sub>11</sub> ere<sub>11</sub> east<sub>12</sub> eat<sub>12</sub> est<sub>12</sub> et<sub>12</sub> euro<sub>13</sub> ears<sub>14</sub> eases<sub>14</sub> easts<sub>14</sub> eats<sub>14</sub> eaus<sub>14</sub> eres<sub>14</sub> eros<sub>14</sub> ers<sub>14</sub> eses<sub>14</sub> ess<sub>14</sub> ests<sub>14</sub> euros<sub>14</sub> erose<sub>15</sub> esse<sub>15</sub> easer<sub>16</sub> easter<sub>16</sub> eater<sub>16</sub> err<sub>16</sub> ester<sub>16</sub> erev<sub>17</sub> eave<sub>18</sub> eve<sub>18</sub> easy<sub>19</sub> eatery<sub>19</sub> eery<sub>19</sub> estro<sub>20</sub> evo<sub>20</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 7:</b> a<sub>7</sub> as<sub>8</sub> ar<sub>10</sub> ae<sub>11</sub> are<sub>11</sub> aue<sub>11</sub> aret<sub>12</sub> art<sub>12</sub> at<sub>12</sub> auto<sub>13</sub> ares<sub>14</sub> arets<sub>14</sub> ars<sub>14</sub> arts<sub>14</sub> ass<sub>14</sub> ats<sub>14</sub> aures<sub>14</sub> autos<sub>14</sub> arete<sub>15</sub> arose<sub>15</sub> arse<sub>15</sub> ate<sub>15</sub> aster<sub>16</sub> arere<sub>18</sub> ave<sub>18</sub> aery<sub>19</sub> arsey<sub>19</sub> arsy<sub>19</sub> artery<sub>19</sub> artsy<sub>19</sub> arty<sub>19</sub> ary<sub>19</sub> ay<sub>19</sub> aero<sub>20</sub> arvo<sub>20</sub> avo<sub>20</sub> ayu<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 8:</b> sur<sub>10</sub> sue<sub>11</sub> sure<sub>11</sub> set<sub>12</sub> st<sub>12</sub> suet<sub>12</sub> so<sub>13</sub> sets<sub>14</sub> sos<sub>14</sub> sues<sub>14</sub> suets<sub>14</sub> sures<sub>14</sub> sus<sub>14</sub> see<sub>15</sub> sese<sub>15</sub> setose<sub>15</sub> seer<sub>16</sub> ser<sub>16</sub> suer<sub>16</sub> surer<sub>16</sub> sutor<sub>16</sub> sov<sub>17</sub> sere<sub>18</sub> serve<sub>18</sub> sore<sub>18</sub> stere<sub>18</sub> sterve<sub>18</sub> store<sub>18</sub> stove<sub>18</sub> sesey<sub>19</sub> sey<sub>19</sub> soy<sub>19</sub> stey<sub>19</sub> storey<sub>19</sub> story<sub>19</sub> sty<sub>19</sub> suety<sub>19</sub> surety<sub>19</sub> surrey<sub>19</sub> survey<sub>19</sub> servo<sub>20</sub> stereo<sub>20</sub> sou<sub>21</sub> susu<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 9:</b> ur<sub>10</sub> ure<sub>11</sub> ut<sub>12</sub> ures<sub>14</sub> us<sub>14</sub> uts<sub>14</sub> use<sub>15</sub> ute<sub>15</sub> ureter<sub>16</sub> user<sub>16</sub> uey<sub>19</sub> utu<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 10:</b> re<sub>11</sub> ret<sub>12</sub> reo<sub>13</sub> reos<sub>14</sub> res<sub>14</sub> rets<sub>14</sub> ree<sub>15</sub> rete<sub>15</sub> roe<sub>15</sub> rose<sub>15</sub> rev<sub>17</sub> reeve<sub>18</sub> resee<sub>18</sub> reserve<sub>18</sub> retore<sub>18</sub> rore<sub>18</sub> rove<sub>18</sub> retry<sub>19</sub> rory<sub>19</sub> rosery<sub>19</sub> rosy<sub>19</sub> retro<sub>20</sub> roo<sub>20</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 11:</b> et<sub>12</sub> es<sub>14</sub> ee<sub>15</sub> er<sub>16</sub> ere<sub>18</sub> eve<sub>18</sub> eery<sub>19</sub> evo<sub>20</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 12:</b> to<sub>13</sub> te<sub>15</sub> toe<sub>15</sub> tose<sub>15</sub> tor<sub>16</sub> tee<sub>18</sub> tore<sub>18</sub> toey<sub>19</sub> tory<sub>19</sub> toy<sub>19</sub> trey<sub>19</sub> try<sub>19</sub> too<sub>20</sub> toro<sub>20</sub> toyo<sub>20</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 13:</b> o<sub>13</sub> os<sub>14</sub> oe<sub>15</sub> ose<sub>15</sub> or<sub>16</sub> ore<sub>18</sub> oy<sub>19</sub> oo<sub>20</sub> ou<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 14:</b> ser<sub>16</sub> see<sub>18</sub> sere<sub>18</sub> serve<sub>18</sub> sey<sub>19</sub> servo<sub>20</sub> so<sub>20</sub> sou<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 15:</b> er<sub>16</sub> ee<sub>18</sub> ere<sub>18</sub> eve<sub>18</sub> evo<sub>20</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 16:</b> re<sub>18</sub> reo<sub>20</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 17:</b> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 18:</b> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 19:</b> yo<sub>20</sub> you<sub>21</sub> yu<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 20:</b> o<sub>20</sub> ou<sub>21</sub> </p>
<p style="margin-bottom: 6pt;" class="undent"><b>Group 21:</b> </p>
<hr />
<p>Naturally, I’ve tried out the code on a few other well-known phrases. </p>
<p>If Lynn and I had met at a different dining establishment, she might have found a straw with the statement, “It takes two hands to handle a Whopper.” There’s quite a diverse assortment of possible messages lurking in this text, with 1,154 unique foldable words and almost 2,000 word instances. Perhaps she would have chosen the upbeat “Inhale hope.” Or, in a darker mood, “I taste woe.”</p>
<p>If we had been folding dollar bills instead of straw wrappers, “In God We Trust” might have become the forward-looking proclamation, “I go west!” Horace Greeley’s marching order on the same theme, “Go west, young man,” gives us the enigmatic “O, wet yoga!” or, perhaps more aptly, “Gunman.”</p>
<p>Jumping forward from 1967 to 2021—from the Summer of Love to the Winter of COVID—I can turn “Wear a mask. Wash your hands.” into the plaintive, “We ask: Why us?” With “Maintain social distance,” the best I can do is “A nasal dance” or “A sad stance.”</p>
<p>And then there’s “Make America Great Again.” It yields “Meme rage.” Also “Make me ragtag.”</p>
<hr />
<h4>Appendix: The Word-List Problem.</h4>
<p>In a project like this one, you might think that getting a suitable list of English words would be the easy part. In fact it seems to be the main trouble spot.</p>
<p>The Scrabble lexicon I’ve been relying on derives from a word list known as SOWPODS, compiled by two associations of Scrabble players starting in the 1980s. Current editions of the list are distributed  by a commercial publisher, Collins Dictionaries. If I understand correctly, all versions of the list are subject to copyright (see <a href="https://boardgames.stackexchange.com/questions/38366/latest-collins-scrabble-words-list-in-text-file">discussion on Stack Exchange</a>) and cannot legally be distributed without permission. But no one seems to be much bothered by that fact. Copies of the lists in plain-text format, with one word per line, are easy to find on the internet—and not just on dodgy sites that specialize in pirated material.</p>
<p>There are alternative lists without legal encumbrances. Indeed, there’s a good chance you already have one such list pre-installed on your computer. A file called <code>words</code> is included in most distributions of the Unix operating system, including MacOS; my copy of the file lives in <code>usr/share/dict/words</code>. If you don’t have or can’t find the Unix <code>words</code> file, I suggest downloading the <a href="http://www.nltk.org/nltk_data/">Natural Language Toolkit</a>, a suite of data files and Python programs that includes a lexicon almost identical to Unix words, as well as many other linguistic resources.</p>
<p>The Scrabble list has one big advantage over <code>words</code>: It includes plurals and inflected forms of verbs—not just <em>test</em> but also <em>tests</em>, <em>tested</em>, and <em>testing</em>. [Bad example; see comments below.] The <code>words</code> file is more like a list of dictionary head words, with only the stem form explicitly included. On the other hand, <code>words</code> has an abundance of names and other proper nouns, as well as abbreviations, which are excluded from the Scrabble list since they are not legal plays in the board game.</p>
<p>How about combining the two word lists? Their union has just under 400,000 entries—quite a large lexicon. Using this augmented list for the analysis of “It’s a pleasure to serve you,” my program finds an additional 219 foldable words, beyond the 778 found with the Scrabble list alone. Here they are:</p>
<blockquote><p>aaru aer aerose aes alares alaster alea alerse aleut alo alose alur aly ao apa apar aperu apus aro arry aru ase asor asse ast astor atry aueto aurore aus ausu aute e eastre eer erse esere estre eu ey iao ie ila islay ist isuret itala itea iter ito iyo l laet lao larry larve lastre lasty latro laur leo ler lester lete leto loro lu lue luo lut luteo lutose ly oer ory ovey p parsee parto passo pastose pato pau paut pavo pavy peasy perty peru pess peste pete peto petr plass platery pluto poe poy presee pretry pu purre purry puru r reve ro roer roey roy s sa saa salar salat salay saltee saltery salvy sao sapa saple sapo sare sart saur sauty sauve se seary seave seavy seesee sero sert sesuto sla slare slav slete sloo sluer soe sory soso spary spass spave spleet splet splurt spor spret sprose sput ssu stero steve stre strey stu sueve suto sutu suu t taa taar tal talao talose taluto tapeats tapete taplet tapuyo tarr tarse tartro tarve tasser tasu taur tave tavy teaer teaey teart teasy teaty teave teet teety tereu tess testor toru torve tosy tou treey tsere tst tu tue tur turr turse tute tutory u uro urs uru usee v vu y</p></blockquote>
<p>Many of the proper nouns in this list are present in the vocabulary of most English speakers: <em>Aleut, Peru, Pluto, Slav</em>; the same is true of personal names such as <em>Larry, Leo, Stu, Tess</em>. But the rest of the words are very unlikely to turn up in the smalltalk of teenage sweethearts. Indeed, the list is full of letter sequences I simply don’t recognize as English words. Please define <em>isuret, ovey, spleet,</em> or <em>sput</em>.</p>
<p>There are even bigger word lists out there. In 2006 Google extracted <a href="https://ai.googleblog.com/2006/08/all-our-n-gram-are-belong-to-you.html">13.5 million unique English words</a> from public web pages. (The sheer number implies a very liberal definition of <em>English</em> and <em>word</em>.) A good place to start exploring this archive is <a href="https://norvig.com/ngrams/">Peter Norvig’s website</a>, which offers a file with the 333,333 most frequent words from the corpus. The list begins as you might expect: <em>the, of, and, to, a, in, for</em>…; but the weirdness creeps in early. The single letters <em>c, e, s,</em> and <em>x</em> are all listed among the 100 most common “words,” and the rest of the alphabet turns up soon after. By the time we get to the end of the file, it’s mostly typos <em>(mepquest, halloweeb, scholarhips)</em>, run-together words <em>(dietsdontwork, weightlossdrugs)</em>, and hundreds of letter strings that have some phonetic or orthographic resemblance to <em>Google</em> or <em>Yahoo!</em> or both <em>(hoogol, googgl, yahhol, gofool, yogol)</em>. (I suspect that much of this rubbish was scraped not from the visible text of web pages but from metadata stuffed into headers for purposes of search-engine optimization.)</p>
<p>Applying the Google list to the search for foldable words more than doubles the volume of results, but it contributes almost nothing to the stock of words that might form interesting messages. I found 1,543 new words, beyond those that are also present in the union of the Scrabble and Unix lists. In alphabetical order, the additions begin: <em>aae, aao, aaos, aar, aare, aaro, aars, aart, aarts, aase, aass, aast, aasu, aat, aats, aatsr, aau, aaus, aav, aave, aay, aea, aeae….</em> I’m not going to be folding up any straw wrappers with those words for my sweetheart.</p>
<p>What we really need, I begin to think, is not a longer word list but a shorter and more discriminating one.</p></div>







<p class="date">
by Brian Hayes <a href="http://bit-player.org/2021/foldable-words"><span class="datestr">at February 09, 2021 08:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=810">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2021/02/09/et-al-ii/">Et Al. II</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>From <a href="https://emanueleviola.wordpress.com/2018/01/16/et-al/">Thoughts, <time datetime="2018-01-16T16:48:38-05:00">January 16, 2018</time>:</a></strong></p>



<p>The et al. citation style favors scholars whose last name comes early in the dictionary. For example, other things equal, a last name like Aaron would circulate a lot more than Zuck. This problem is compounded by the existence of highly-cited papers which deviate from alphabetical ordering of authors. They carry the message: order matters, and some of you can’t use this trick, vae victis!</p>



<p>My suggestion is to avoid et al. and instead spell out every name (as in Aaron and Zuck) or every initial (as in AZ). It isn’t perfect, but improvements like randomly permuting the order still aren’t easy to implement. The suggestion actually cannot be implemented in journals like computational complexity which punish the authors into using an idiosyncratic style which has et al. But it doesn’t matter too much; nobody reads papers in those formats anyway, as we discussed <a href="https://emanueleviola.wordpress.com/tag/utopia/">several times</a>.</p>



<p></p>



<p></p>



<p></p>



<p><strong>From the <a href="http://acm-stoc.org/stoc2021/stoc-cfp.html">STOC 2021 call for papers</a></strong>:</p>



<p></p>



<p>Authors are asked to avoid “et al.” in citations in favor of an equal mention of all authors’ surnames (unless the number of authors is very large, and if it is large, consider just using \cite{} with no “et al.”). When not listing authors’ names, citations should preferably include the first letters of the authors’ surnames (or at least the first three followed by a +, and possibly the year of publication). If using BibTeX, this can be accomplished by using \bibliographystyle{alpha}.</p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2021/02/09/et-al-ii/"><span class="datestr">at February 09, 2021 06:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-9121434197807183435">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2021/02/whence-do-research-collaborations-in.html">Whence do research collaborations (in TCS) arise?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>About ten days ago, I gave a <a href="http://icetcs.ru.is/slides/intro2icetcs2021.pdf" target="_blank">talk</a> to my colleagues at the <a href="https://en.ru.is/st/dcs/" target="_blank">Department of Computer Science at Reykjavik University</a>, introducing my personal (and admittedly very biased) view of the past, present and future of <a href="http://icetcs.ru.is/" target="_blank">ICE-TCS</a>. </p><p>After my presenta­tion, a colleague asked me how she could engage mathematicians and theoretical computer scientists in joint research. I gave her an answer off the top of my head, but it was clear that she was unconvinc­ed and felt that I was avoid­ing answering her question. (For the record, I basically told her that she should knock on our door, discuss with us the problems she was interested in solving and hope that they are of interest to us. I feel that many research collaborations arise from serendipity and that there is no recipe that is guaranteed to work.) </p><p>The thought that she felt that I might have dodged her question prompted me to look back at my own research collabo­rations and how they came about. The rest of this post is the result of that quick-and-dirty reflection. Let me state right away that my list isn't meant to be exhausti­ve and that I won't mention many of the collaborations in which I have been lucky to be involved and that I have played a crucial role in shaping my academic development.  </p><p><b>Reading papers.</b> One of my long-term research collaborations arose from reading a paper written by a colleague. His paper prompted my companion and me to ask ourselves whether we could prove a similar result to the one our colleague had shown in a different setting. We succeeded and sent him our paper. Subsequently, we invited him to visit us in Aalborg. That visit marked the start of a collaboration and friendship that has lasted for over 20 years. <br /><br /><b>Approaching a colleague via email for help in solving a problem.</b> At some point, my companion and I were thinking about a research problem that had frustrated us for a while. I remembered reading a number of papers by a colleague on related topics, so I wrote to him, describing the problem, our attempts at solving it and where we had hit a brick wall. I asked him whether he would be interested in working with us on solving it. He did and that was one of the lucky breaks I have had in my research career. Once more, that collaboration offer via email led to mutual visits, other joint papers and, IMHO even more importantly, a long-term friendship that extended beyond work. <br /> </p><p><b>Available funding and building on one's mistakes.</b> One day in 2009, an email in my mailbox alerted me to the availability of substantial funding for research collabo­ration between universities in country X and those locat­ed in Norway, Iceland and Lichtenstein. This opportunity was enticing, as I had never visited country X, so I asked myself: "Is there anyone there we might conceivably work with?'' Mulling over that question, I recalled that a colleague from country X had spotted an imprecision in a paper I had coauthored. </p><p>I wrote to him, we applied for that funding jointly and got it. That successful grant application provided the funds for many research visits involving several people in our research groups. Those visits resulted in joint papers, another successful grant application and a number of friendships. </p><p><b>Coffee breaks at conferences.</b> I have at least two exhibits under this heading. The first belongs to a previous geologic­al era (1991). I was attend­ing a conference at CMU and asked a colleague what he was working on. He told me<br />about a problem he was tackling, which I knew was also on the radar of a fellow researcher and on which I had started working independently. Eventually, after some email exchanges, that chat over coffee turned into a three-way collaboration that, thanks to my coauthors, produced one of my best papers. <br /><br />Fast forward to 2017 and I'm in Rome to deliver an invited talk at a small conference. During the coffee break follow­ing my presentation, I was approached by a young research­er, with whom I had a number of pleasant conversations during the conference. Some time later, she sent me a draft paper dealing with a topic related to the content of my invited talk. I invited her to visit our research group in Reykjavik and to join the team working on a research project for which we had funding at the time. Those coffee-break conversations led to a collaboration and friendship that I hope will last for a long time. Meeting that colleague has been another of my lucky breaks. <br /> </p><p><b>Reading groups.</b> Last, but by no means least, let me mention that my first research collaboration that did not involve my thesis supervisors arose when I read Gordon Plotkin's famous "<a href="http://homepages.inf.ed.ac.uk/gdp/publications/Domains_a4.ps">Pisa Notes (On Domain Theory)</a>" with a fellow PhD student. Reading that work led to our first joint paper in 1991 and a companionship that has lasted to this day. I heard <a href="https://www.youtube.com/watch?v=KYfmXpLCiy4&amp;list=PLEyo0HIOhDCSR8os82H_2p5M0dE70K6KL&amp;index=2" target="_blank">Orna Kupferman</a> give the following, tongue-in-cheek advice to young researchers: "Write papers with your twin-sister!" Mine might be: "Write papers with your companion in life!" </p><p>Let me conclude by saying that serendipity and an actual friendship that extends beyond the confines of scientific work were the key aspects in my most pleasant and enduring collaborations. I apologise to the colleagues from whom I have learnt much over the years (former students and postdocs, as well as others) who were the prime movers in research collaborations I did not mention in this post. </p><p> I guess that this note provides much more information than my colleague was intending to receive, but I thought I should put it out for the benefit of the young researchers at Reykjavik University and at the Gran Sasso Science Institute, and of any reader I might have. </p><p>How did your research collaborations arise? If you have anything to add to what I wrote above, and I am sure you do, add your contributions as comments to this post. <br /><br /><br /></p></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2021/02/whence-do-research-collaborations-in.html"><span class="datestr">at February 08, 2021 05:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=21161">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2021/02/08/to-cheer-you-up-in-difficult-times-20-ben-green-presents-super-polynomial-lower-bounds-for-off-diagonal-van-der-waerden-numbers-w3k/">To cheer you up in difficult times 20: Ben Green presents super-polynomial lower bounds for off-diagonal van der Waerden numbers W(3,k)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><a href="https://gilkalai.wordpress.com/2021/01/29/possible-future-polymath-projects-2009-2021/">What will be the next polymath project? click here for our post about it. </a></p>
<h2 class="title mathjax"><a href="https://arxiv.org/abs/2102.01543">New lower bounds for van der Waerden numbers</a> by Ben Green</h2>
<p><span style="color: #0000ff;"><strong>Abstract:</strong> We show that there is a red-blue colouring of <em>[N]</em> with no blue 3-term arithmetic progression and no red arithmetic progression of length <img src="https://s0.wp.com/latex.php?latex=e%5E%7BC%28%5Clog+N%29%5E%7B3%2F4%7D%28%5Clog+%5Clog+N%29%5E%7B1%2F4%7D%7D.&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="e^{C(\log N)^{3/4}(\log \log N)^{1/4}}." class="latex" title="e^{C(\log N)^{3/4}(\log \log N)^{1/4}}." /> Consequently, the two-colour van der Waerden number w(3,k) is bounded below by <img src="https://s0.wp.com/latex.php?latex=k%5E%7Bb%28k%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k^{b(k)}" class="latex" title="k^{b(k)}" />, where <img src="https://s0.wp.com/latex.php?latex=b%28k%29%3Dc%28%5Cfrac%7B%5Clog+k%7D%7B%5Clog+%5Clog+k%7D%29%5E%7B1%2F3%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="b(k)=c(\frac{\log k}{\log \log k})^{1/3}" class="latex" title="b(k)=c(\frac{\log k}{\log \log k})^{1/3}" />. Previously it had been speculated, supported by data, that <img src="https://s0.wp.com/latex.php?latex=w%283%2Ck%29%3DO%28k%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3,k)=O(k^2)" class="latex" title="w(3,k)=O(k^2)" />.</span></p>
<p><a href="https://gilkalai.files.wordpress.com/2021/02/gsm.png"><img width="640" alt="" src="https://gilkalai.files.wordpress.com/2021/02/gsm.png?w=640&amp;h=180" class="alignnone size-full wp-image-21182" height="180" /></a></p>
<p><span style="color: #ff0000;">The left side of the picture shows the world record holders for W(3,k). On the left Ben Green (LB) and in the centre Tomasz Schoen (UB). The pictures on the right shows protective mittens for people who make bold mathematical conjectures (<a href="https://gilkalai.wordpress.com/2021/01/19/what-if-they-are-all-wrong/">see Igor Pak’s post</a>) </span></p>
<p>The two-colour van der Waerden number <img src="https://s0.wp.com/latex.php?latex=w%28m%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(m,k)" class="latex" title="w(m,k)" /> is the smallest  N such that however [N] = {1, . . . , N} is coloured blue and red, there is either a blue m-term arithmetic progression or a red k-term arithmetic progression. The celebrated theorem of van der Waerden implies that <img src="https://s0.wp.com/latex.php?latex=w%28m%2C+k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(m, k)" class="latex" title="w(m, k)" /> is finite.</p>
<p>The van der Waerden number <img src="https://s0.wp.com/latex.php?latex=w%28m%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(m,k)" class="latex" title="w(m,k)" /> is analogous to the Ramsey number <img src="https://s0.wp.com/latex.php?latex=R%28m%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="R(m,k)" class="latex" title="R(m,k)" />. Finding the behaviors of <img src="https://s0.wp.com/latex.php?latex=R%28m%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="R(m,k)" class="latex" title="R(m,k)" /> is an important problem in Ramsey theory and much attention is given to <img src="https://s0.wp.com/latex.php?latex=R%28k%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="R(k,k)" class="latex" title="R(k,k)" /> and of <img src="https://s0.wp.com/latex.php?latex=R%283%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="R(3,k)" class="latex" title="R(3,k)" />. Similarly, understanding the values of <img src="https://s0.wp.com/latex.php?latex=W%28m%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="W(m,k)" class="latex" title="W(m,k)" />, and especially of <img src="https://s0.wp.com/latex.php?latex=W%28k%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="W(k,k)" class="latex" title="W(k,k)" /> and <img src="https://s0.wp.com/latex.php?latex=W%283%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="W(3,k)" class="latex" title="W(3,k)" />  are also  central problems in Ramsey theory. A big difference between van der Waerden number and Ramsey numbers is that there are density theorems for the existence of <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k" class="latex" title="k" />-terms arithmetic progressions. (Roth’s theorem for <img src="https://s0.wp.com/latex.php?latex=k%3D3&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k=3" class="latex" title="k=3" /> and Szemeredi’s theorem for general <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k" class="latex" title="k" />.) There are several important methods to derive those density theorems (including Fourier methods, ergodic methods, and Szemeredi-type regularity) and these methods, as far as I know, do not apply for ordinary Ramsey numbers. (But correct me if I am wrong here, and if I am right and you have some insights as to why ergodic methods or Fourier methods do not apply to “ordinary” Ramsey, please share.)</p>
<p>Green’s paper  studies the values of <img src="https://s0.wp.com/latex.php?latex=w%283%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3,k)" class="latex" title="w(3,k)" />. The best known upper bound is of Tomasz Schoen, <img src="https://s0.wp.com/latex.php?latex=w%283%2C+k%29%3Ce%5E%7Bk%5E%7B1-c%7D%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3, k)&lt;e^{k^{1-c}}" class="latex" title="w(3, k)&lt;e^{k^{1-c}}" /> for some constant <img src="https://s0.wp.com/latex.php?latex=c+%3E+0.&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="c &gt; 0." class="latex" title="c &gt; 0." /> The best known lower bound until the new paper, was by Li and Shu: <img src="https://s0.wp.com/latex.php?latex=w%283%2C+k%29+%5Cgg+%28k%2F+log+k%29%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3, k) \gg (k/ log k)^2" class="latex" title="w(3, k) \gg (k/ log k)^2" />. (This result, as the earlier bound by Robertson, used a probabilistic argument and relied on Lovasz’s local lemma.)</p>
<p>Several people conjectured, also based on empirical data, that <img src="https://s0.wp.com/latex.php?latex=w%283%2Ck%29+%3D+O%28k%5E2%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3,k) = O(k^2)" class="latex" title="w(3,k) = O(k^2)" /> but now Green proved a super-polynomial lower bound! This is amazing! Congratulations, Ben!</p>
<p>It is largely conjectured that the Behrend-type bounds give the correct quantitative behaviour for Roth’s theorem (and Szemeredi theorem). In rough terms what we see from Green’s example is that this might be true also for van der Waerden numbers.</p>
<p>The proof is rather involved and long, so, naturally, there is  little I can say about it, which only slightly exceeds the little I actually know about it. The overview and other fragments of the paper I looked at are very illuminating. Here are a few things that caught my eyes.</p>
<p>1) A word about Tomasz Schoen’s upper bound and important paper: <a href="https://arxiv.org/abs/2006.02877">A subexponential upper bound for van der Waerden numbers W(3,k).</a>  Among other things Schoen’s proof relies on a lemma developed by Schoen for improved Roth bound. This relies on a structure theory of Bateman and Katz.  The paper gives a nice description of the state of the art regarding the diagonal values <img src="https://s0.wp.com/latex.php?latex=w%28k%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(k,k)" class="latex" title="w(k,k)" />. (Schoen’s upper bound on <img src="https://s0.wp.com/latex.php?latex=w%283%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3,k)" class="latex" title="w(3,k)" /> follows also from the <a href="https://gilkalai.wordpress.com/2020/07/08/to-cheer-you-up-in-difficult-times-7-bloom-and-sisask-just-broke-the-logarithm-barrier-for-roths-theorem/">more recent bound for Roth’s theorem</a> by Bloom and Sisask.)</p>
<p>2) Among the people that speculated that <img src="https://s0.wp.com/latex.php?latex=w%283%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3,k)" class="latex" title="w(3,k)" /> behaves like <img src="https://s0.wp.com/latex.php?latex=k%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k^2" class="latex" title="k^2" /> is Ben Green himself. This is recorded in reference [9] of the paper. However, Green’s first reaction to this possibility was that it must be false. But he realized that some ideas for showing that it is false are themselves false.</p>
<p>3) Reference [9] in the paper is: <strong>B. J. Green, 100 open problems, manuscript, available on request</strong>. If you are curious about the list, request it!</p>
<p>4) New lower bounds in Ramsey theory are nor frequent. Thirteen years ago I described <a href="https://gilkalai.wordpress.com/2008/07/10/pushing-behrend-around/">Elkin’s improvement</a> to Behrend’s bound and a few days ago I mentioned <a href="https://gilkalai.wordpress.com/2021/02/03/to-cheer-you-up-in-difficult-times-19-nati-linial-and-adi-shraibman-construct-larger-corner-free-sets-from-better-numbers-on-the-forehead-protocols/">Linial and Shraibman’s new lower bounds</a> for the corner problem.  Green’s study started by looking at complements of 3-AP free sets. An example by Green and Julia Wolf (that followed Elkin’s result) turned out to be important for reaching some parts of Green’s strategy.</p>
<p>5) In some sense, something about the <img src="https://s0.wp.com/latex.php?latex=k%5E2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k^2" class="latex" title="k^2" /> prediction is not entirely lost. The construction gives a sort of a multi-scale behaviour where in the <img src="https://s0.wp.com/latex.php?latex=r&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="r" class="latex" title="r" />th scale the example’s cardinality is <img src="https://s0.wp.com/latex.php?latex=k%5Er&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k^r" class="latex" title="k^r" />.  (So all the empirical data comes from the <img src="https://s0.wp.com/latex.php?latex=r%3D2&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="r=2" class="latex" title="r=2" /> regime.) Ben Green boldly suggests that the true values of <img src="https://s0.wp.com/latex.php?latex=w%283%2Ck%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3,k)" class="latex" title="w(3,k)" /> might exhibit such multi-scale behaviour. He conjectures that the true value of <img src="https://s0.wp.com/latex.php?latex=w%283%2C+k%29&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="w(3, k)" class="latex" title="w(3, k)" /> is quasi-polynomial, namely it lies somewhere in between the bound given by his construction and  something like <img src="https://s0.wp.com/latex.php?latex=k%5E%7Bc%5Clog+k%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="k^{c\log k}" class="latex" title="k^{c\log k}" /> (which is Behrend-bound behaviour on the nose) .</p>
<p>6) Until Ben’s list of 100 problems becomes available to you, you may find interest in Francis Su’s <a href="https://www.francissu.com/post/100-questions-about-mathematics">100 questions about mathematics for discussion and reflection</a>.</p>
<p>7) In connection with Linial and Shraibman’s new lower bounds for the corner problem, let me mention that the best upper bound is by I.D. Shkredov. The paper is:  On a two-dimensional analog of Szemeredi’s Theorem in Abelian groups, Izvestiya of Russian Academy of Sciences, 73 (2009), 455–505.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2021/02/08/to-cheer-you-up-in-difficult-times-20-ben-green-presents-super-polynomial-lower-bounds-for-off-diagonal-van-der-waerden-numbers-w3k/"><span class="datestr">at February 08, 2021 05:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-8474138395715737050">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/02/the-victoria-delfino-problems-example.html">The Victoria Delfino Problems: an example of math problems named after a non-mathematician</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> If you Google <b>Victoria Delfino </b>you will find that she is a real estate agent in LA (well, one of the Victoria Delfino's you find is such).  After this blog is posted you may well get this post on the first Google page. </p><p>If you Google <b>Victoria Delfino Problems</b> you will find a paper:</p><p><a href="https://andrescaicedo.files.wordpress.com/2008/04/vdp-finalversion-withreferences.pdf">The fourteen Victoria Delfino Problems and their Status in the year 2015</a></p><p>(ADDED LATER: a comment pointed me to an updated version, so  you can see that- I got to a pay wall.) </p><p>How did a real estate agent get honored by having 14 problems in descriptive set theory named after her?</p><p>Possibilities before I tell you which one.</p><p>1) Real estate is her day job. Her hobby is Descriptive Set Theory. Recall that Fermat was a lawyer (or something like that- see <a href="https://en.wikipedia.org/wiki/Pierre_de_Fermat">his Wikipedia page</a>) so perhaps she is similar. Doubtful- I think math is too hard for that now.  Or at least descriptive  set theory is too hard for that now. </p><p>2) She just happened to remark one day,<i> Gee, I wonder if</i></p><p><i> ZFC + SEP(Sigma_3^1) + #   implies DET(Delta_2^1).</i> </p><p>Its just the kind of thing someone might just say. That was problem 4 of the 14. </p><p>3) There are two Victoria Delfino's- one is a realtor, one is a mathematician. While plausible, that would not be worth blogging about. </p><p>4) And now the truth: Victoria was the realtor who helped Moschovakis (a descriptive set theorist who I will henceforth describe as M) buy his house. When Tony Martin (another Desc. Set Theorist) moved to UCLA, M referred him to Victoria and she did indeed help Tony find a house. Victoria gave M a large commission which he tried to turn down. She did not want it returned, so M used the money to fund five problems. Later problems were added, but for no money. The article <i>The Fourteen... </i>linked to above has the full story. It also has the curious line: </p><p><i>Contrary to popular belief, no monetary prize is attached to further problems. </i></p><p>I didn't think any of this was so well known as to have popular believes. </p><p>ANYWAY, this is an example of a math problem named after a non-math person. Are there others? Will the name stick? Probably not- already 12 of the 14 are solved. I have noted in a prior blog (<a href="https://blog.computationalcomplexity.org/2009/08/how-much-credit-should-conjecturer-get_14.html">here</a>) once a conjecture gets proven, the one who made the conjecture gets forgotten. Or in this case the person who the conjectures is named after. </p><p>So are there other open problems in math named after non-math people? How about Theorems?</p><p>Near Misses: </p><p>Pythagoras: Not clear what he had to do with the theorem that bears his name. </p><p>L'hopital's Rule: the story could be a blog in itself, and in fact it is! Not mind, but someone else: <a href="https://andrescaicedo.wordpress.com/2013/11/05/credit/">here</a>. However L'hopital was a mathematician. </p><p>Sheldon's conjecture (see <a href="https://blog.computationalcomplexity.org/2019/10/the-sheldon-conjecture-too-late-for.html">here</a>) was named after a FICTIONAL physicist. Note that Sheldon inspired the conjecture but did not make it. It has been solved. </p><p>The Governor's  Theorem (see <a href="https://blog.computationalcomplexity.org/2013/08/how-much-trig-does-your-governor-know.html">here</a>) was named because Jeb Bush was asked for the angles of a 3-4-5 right triangle (not a fair question). </p><p>The Monty Hall Paradox.</p><p>SO- are there Open Problems, Theorems, Lemmas, any math concepts, named after non-math people? I really mean non-STEM people. If a Physicist or an Engineer or a Chemist or Biologist or...  has their name on something, that would not really be what I want.</p><p>(ADDED LATER - someone emailed me two oddly-named math things:</p><p>Belphegor's prime, <span style="background-color: white; color: #222222; font-family: Arial, Helvetica, sans-serif; font-size: small;">see </span><a href="https://en.wikipedia.org/wiki/Belphegor%27s_prime">here</a></p><p>Morrie's law- odd since Morrie is the FIRST name of who the name is honoring, see <a href="https://en.wikipedia.org/wiki/Morrie%27s_law">here</a> </p><p>)</p><p><br /></p><p>Are there any other open problems in descriptive set theory  named after realtors?</p><p><i><br /></i></p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/02/the-victoria-delfino-problems-example.html"><span class="datestr">at February 08, 2021 04:55 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1475">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1475">News for January 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>The first month of 2021 has brought with it 5 papers, covering graph testing, Boolean function testing, and distribution testing — as well as database theory. Let’s dive into it.</p>



<p><strong>Random walks and forbidden minors III: \(\mathrm{poly}(d/\varepsilon)\)-time partition oracles for minor-free graph classes</strong>, by Akash Kumar, C. Seshadhri, and Andrew Stolman (<a href="https://arxiv.org/abs/2102.00556">arXiv</a>). Minor-closed bounded-degree graphs have a very nice property: denoting by \(d\) the degree bound and \(n\) the number of edges, it is always possible to partition any such graph into components of <em>constant</em> size, \(O_\varepsilon(1)\), just by removing a linear number of edges, merely \(\varepsilon dn\) (\(\varepsilon\) being a small parameter). This is a crucial result in many graph property testing algorithms, those which rely on something called a “partition oracle”: loosely speaking, a routine which makes “few” queries to the graph, and is able to indicate which component of an underlying partition any given vertex belongs to. But what is “few” here? The first partition oracles made \(d^{\mathrm{poly}(d,1/\varepsilon)}\) queries to the graph to answer any such request. This later got significantly improved to \(d^{\mathrm{log}(d/\varepsilon)}\). Using spectral graph theory techniques previously developed by the authors (hence the “III” in the title), this work settles the question, achieving partition oracles which as good as it gets: making only \(\mathrm{poly}(d,1/\varepsilon)\) queries to the graph! This in turns has immediate consequences for graph property testing, which the paper details.</p>



<p>And since we are on the topic of oracles… more exciting news on that front:</p>



<p><strong>Spectral Clustering Oracles in Sublinear Time</strong>, by Grzegorz Gluch, Michael Kapralov, Silvio Lattanzi, Aida Mousavifar, Christian Sohler (<a href="https://arxiv.org/abs/2101.05549">arXiv</a>). Given a graph \(G\) and an integer \(k\), one often want to partition the graph into components \(C_1,C_2,\dots,C_k\), such that each \(C_i\) is well-connected and has few edges to the other \(C_j\)’s. But can we get <em>ultra</em> efficient algorithms for such spectral clusterings? Specifically, can we design oracles for them: sublinear-time algorithms which provide implicit access to an underlying “good” spectral clustering \(\hat{C}_1,\hat{C}_2,\dots,\hat{C}_k\), by returning on any query vertex \(v\) the index of the cluster \(\hat{C}_i\) to which \(v\) belongs? This paper introduces the question, and answers it in the affirmative: in more detail, it provides a spectral clustering oracle which, for any \(\varepsilon&gt;0\), has preprocessing time \(2^{\mathrm{poly}(k/\varepsilon)}n^{1/2+O(\varepsilon)}\), query time \(n^{1/2+O(\varepsilon)}\), and space \(n^{1/2+O(\varepsilon)}\); and provides access to a clustering with relative error \(O(\varepsilon\log k)\) per cluster. The paper also allows tradeoffs between query time and space, and discusses applications to the Local Computation Algorithms (LCA) model.</p>



<p>Next stop, distribution testing…</p>



<p><strong>The Sample Complexity of Robust Covariance Testing</strong>, by Ilias Diakonikolas and Daniel M. Kane (<a href="https://arxiv.org/abs/2012.15802">arXiv</a>). Suppose you have i.i.d. samples from some high-dimensional Gaussian \(\mathcal{N}(0,\Sigma)\) in \(d\) dimensions, and want to test whether the unknown covariance matrix \(\Sigma\) is the identity, versus \(\varepsilon\)-far from it (in Frobenius norm). Good news: we know how to do that, and \(\Theta(d/\varepsilon^2)\) samples are necessary and sufficient. (To <em>learn</em> \(\Sigma\), that’d be \(\Theta(d^2/\varepsilon^2)\).) Bad news: you don’t have i.i.d. samples from some high-dimensional Gaussian \(\mathcal{N}(0,\Sigma)\); what you have is i.i.d. samples from a noisy version of it, \((1-\alpha)\mathcal{N}(0,\Sigma) + \alpha B\), where \(B\) is an arbitrary “bad” distribution (not necessarily Gaussian itself). You still want to test whether the covariance \(\Sigma\) is the identity, but now you have that extra \(\alpha\) fraction of noisy samples, and you need to do that testing robustly… The good news is, you can still do that by learning the covariance matrix \(\Sigma\), robustly, with \(O(d^2/\varepsilon^2)\) samples. The bad news is the main result of this paper: that’s also the best you can do. That is, \(\Omega(d^2)\) samples are necessary: if you have to be robust to noise, testing is no longer easier than learning….</p>



<p>Onto Boolean functions!</p>



<p><strong>Junta Distance Approximation with Sub-Exponential Queries</strong>, by Vishnu Iyer, Avishay Tal, and Michael Whitmeyer (<a href="https://eccc.weizmann.ac.il/report/2021/004/">ECCC</a>). If you follow this blog, you may have seen over the past couple years a flurry of results about <em>tolerant junta testing</em>: “given query access to some Boolean function \(f\colon\{-1,1\}^n\to\{-1,1\}\), how close is \(f\) to only depending on \(k \ll n\) of its variables?”<br />This paper contains several results on this problem, including an improved bicriteria tolerant testing algorithm: an efficient algorithm to distinguish between \(\varepsilon\)-close to \(k\)-junta and \(1.1\varepsilon\)-far from \(k’\)-junta making \(\mathrm{poly}(k,1/\varepsilon)\) queries (and \(k’ = O(k/\varepsilon^2)\)). But the main result of the paper, and the one giving it its name, is for the non-relaxed version where \(k’=k\): while all previous works had a query complexity \(2^{O(k)}\), here the authors show how to break that exponential barrier, giving a fully tolerant testing algorithm with query complexity \(2^{\tilde{O}(\sqrt{k})}\)!</p>



<p>And finally, a foray into database theory:</p>



<p><strong>Towards Approximate Query Enumeration with Sublinear Preprocessing Time</strong>, by  Isolde Adler and Polly Fahey (<a href="https://arxiv.org/abs/2101.06240">arXiv</a>). In this paper, the authors are concerned with the task of (approximate) query enumeration on databases, aiming for ultra efficient (i.e., sublinear-time) algorithms. Leveraging techniques from property testing (specifically, in the bounded-degree graph model), they show the following:<br /><em>On input databases of bounded degree and bounded tree-width, every (fixed) first-order definable query can be enumerated approximately in time linear in the output size, after only a sublinear-time preprocessing phase</em>.</p>



<p>That’s all for this month! If you noticed a paper we missed, please let us know in the comments.</p></div>







<p class="date">
by Clement Canonne <a href="https://ptreview.sublinear.info/?p=1475"><span class="datestr">at February 07, 2021 10:52 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=83">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2021/02/05/thursday-feb-18-costis-daskalakis-from-mit/">Thursday Feb 18 — Costis Daskalakis from MIT</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Welcome to the Spring 2021 edition of Foundations of Data Science Virtual Talks. </p>



<p>Our first talk for the season will take place on <strong>Thursday, Feb 18</strong>th at <strong>11:00 AM Pacific Time</strong> (14:00 Eastern Time, 20:00 Central European Time, 19:00 UTC).  <strong>Costis Daskalakis</strong> from <strong>MIT</strong> will speak about “<strong>Equilibrium Computation and the Foundations of Deep Learning</strong>.”</p>



<p><a href="https://sites.google.com/view/dstheory" target="_blank" rel="noreferrer noopener">Please register here to join the virtual talk.</a></p>



<p class="has-text-align-justify"><strong>Abstract</strong>: Deep Learning has recently yielded important advances in single-agent learning challenges, much of that progress being fueled by the empirical success of gradient descent and its variants in computing local optima of non-convex optimization problems. In multi-agent learning applications, the role of single-objective optimization is played by equilibrium computation, yet our understanding of its complexity in settings that are relevant for Deep Learning remains sparse. In this talk we focus on min-max optimization of nonconvex-nonconcave objectives, which has found applications in GANs, and other adversarial learning problems. Here, not only are there no known gradient-descent based methods converging to even local and approximate min-max equilibria, but the computational complexity of identifying them remains poorly understood. We show that finding approximate local min-max equilibria of Lipschitz and smooth objectives requires a number of queries to the function and its gradient that is exponential in the relevant parameters, in sharp contrast to the polynomial number of queries required to find approximate local minima of non convex objectives. Our oracle lower bound is a byproduct of a complexity-theoretic result showing that finding approximate local min-max equilibria is computationally equivalent to finding Brouwer fixed points, and Nash equilibria in non zero-sum games, and thus PPAD-complete.</p>



<p>Minimal complexity theory knowledge will be assumed in the talk. Joint work with Stratis Skoulakis and Manolis Zampetakis.</p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>.</p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2021/02/05/thursday-feb-18-costis-daskalakis-from-mit/"><span class="datestr">at February 05, 2021 03:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-7077954644615536585">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2021/02/support-research-in-foundations-of.html">Support research in the Foundations of Computing at the University of Leicester!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In an ideal world, university administrators would support the work of the top-class academics employed by their institution, especially if they attract students, have a high research standing within their communities and bring in substantial funding from competitive research funds. After all, to quote <a href="https://en.wikipedia.org/wiki/Isidor_Isaac_Rabi" target="_blank">Isidor Isaac Rabi</a>, "<a href="https://academicanchor.wordpress.com/2012/08/09/dwight-eisenhower-and-university-faculty/" target="_blank">the faculty are the university</a>" and the most valuable currency for an academic institution is reputation. </p><p>Unfortunately, university administrations the world over repeatedly surprise me by making structural changes that affect some of their very best academics and actually <i>reduce</i> the reputation of their institutions in the eyes of the community at large. </p><p>The latest example comes from the University of Leicester, where, as stated <a href="https://www.ipetitions.com/petition/foco-is-not-redundant" target="_blank">here</a>, </p><p style="margin-left: 40px; text-align: left;">[the] University VC proposes to merge Informatics and Mathematics into a  combined school focussed exclusively on AI, data science, computational  modelling and "digitalisation". This includes the proposal to cease  research in Foundations of Computer Science (FoCo) where research is  "highly theoretical and not directly linked with applications",  retaining staff only if the research they have published in the past (!)  aligns well with the new desired focus on foundations of AI,  computational modelling, data science and digitalisation. Staff have  been given no opportunity to alter their research to fit with the  proposed new direction. The plan is <u>to make redundant (in the middle of a pandemic) all (up to 10) staff in foundations of computer science</u> whose past research is deemed not to be a good enough fit with the new strategic priorities. </p><p>See also <a href="https://www.uculeicester.org.uk/ucu/first-statement-on-threatened-compulsory-redundancies/" target="_blank">this statement</a> by the University and College Union of the University of Leicester. </p><p>I might be biased, but I find it inconceivable that one can think of building a world-class research programme in AI, data science and computational modelling without building on existing strengths in the Foundations of Computer Science and Mathematics. What my crystal ball tells me is that the strong Leicester academics who might be affected by the planned restructuring will find positions elsewhere and that the University of Leicester is shooting itself in the foot. Which high-profile academic would be enticed to join a university that has shown so little consideration for its existing areas of strength and where one's job might be in danger when the buzzwords du jour change, as they undoubtedly will? </p><p>I encourage you to sign the <a href="https://www.ipetitions.com/petition/foco-is-not-redundant" target="_blank">petition</a> in support of our Leicester colleagues. Kudos to <a href="https://en.wikipedia.org/wiki/Isobel_Armstrong" target="_blank">Isobel Armstrong</a>, FBA, for <a href="https://twitter.com/leicesterucu/status/1355277601980489729" target="_blank">returning her honorary doctorate</a> to the University of Leicester upon hearing of their plans!<br /></p></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2021/02/support-research-in-foundations-of.html"><span class="datestr">at February 05, 2021 11:30 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=528">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2021/02/04/tcs-talk-wednesday-february-17-william-hoza-ut-austin/">TCS+ talk: Wednesday, February 17 — William Hoza, UT Austin</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Welcome back for a new season of TCS+! Our talks are back to a fortnightly schedule, with an exciting slate of speakers ahead of us.</p>
<p>The first TCS+ talk will take place in two weeks, Wednesday, February 17th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 19:00 Central European Time, 18:00 UTC). <strong>William Hoza</strong> from UT Austin will speak about “<em>Fooling Constant-Depth Threshold Circuits</em>” (abstract below). You can reserve a spot as an individual or a group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. Due to security concerns, <em>registration is required</em> to attend the interactive talk. (The talk will be recorded and posted on our website and <a href="https://www.youtube.com/user/TCSplusSeminars/videos">YouTube channel</a> afterwards, so people who did not sign up will still be able to watch the talk.) As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote class="wp-block-quote"><p>Abstract: We present the first non-trivial pseudorandom generator (PRG) for linear threshold (LTF) circuits of arbitrary constant depth and super-linear size. This PRG fools circuits with depth <img src="https://s0.wp.com/latex.php?latex=d&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="d" class="latex" title="d" /> and <img src="https://s0.wp.com/latex.php?latex=n%5E%7B1+%2B+%5Cdelta%7D&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="n^{1 + \delta}" class="latex" title="n^{1 + \delta}" /> wires, where <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3D+%5Cexp%28-O%28d%29%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="\delta = \exp(-O(d))" class="latex" title="\delta = \exp(-O(d))" />, using seed length <img src="https://s0.wp.com/latex.php?latex=O%28n%5E%7B1+-+%5Cdelta%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="O(n^{1 - \delta})" class="latex" title="O(n^{1 - \delta})" /> and with error <img src="https://s0.wp.com/latex.php?latex=%5Cexp%28-n%5E%7B%5Cdelta%7D%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="\exp(-n^{\delta})" class="latex" title="\exp(-n^{\delta})" />. This tightly matches the best known lower bounds for this circuit class. As a consequence of our result, all the known hardness for LTF circuits has now effectively been translated into pseudorandomness. This brings the extensive effort in the last decade to construct PRGs and deterministic circuit-analysis algorithms for this class to the point where any subsequent improvement would yield breakthrough lower bounds.</p>
<p>A key ingredient in our construction is a pseudorandom restriction procedure that has tiny failure probability, but simplifies the function to a non-natural “hybrid computational model” that combines decision trees and LTFs. As part of our proof we also construct an “extremely low-error” PRG for the class of functions computable by an arbitrary function of s linear threshold functions that can handle even the extreme setting of parameters <img src="https://s0.wp.com/latex.php?latex=s+%3D+n%2F%5Cmathrm%7Bpolylog%7D%28n%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="s = n/\mathrm{polylog}(n)" class="latex" title="s = n/\mathrm{polylog}(n)" /> and <img src="https://s0.wp.com/latex.php?latex=%5Cepsilon+%3D+%5Cexp%28-n%2F%5Cmathrm%7Bpolylog%7D%28n%29%29&amp;bg=fff&amp;fg=444444&amp;s=0&amp;c=20201002" alt="\epsilon = \exp(-n/\mathrm{polylog}(n))" class="latex" title="\epsilon = \exp(-n/\mathrm{polylog}(n))" />.</p>
<p>Joint work with Pooya Hatami, Avishay Tal, and Roei Tell.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2021/02/04/tcs-talk-wednesday-february-17-william-hoza-ut-austin/"><span class="datestr">at February 05, 2021 03:51 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
