<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at August 19, 2020 05:21 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17421">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/">Logical Complexity of Proofs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>If you cannot find proofs, talk about them.</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/rr/" rel="attachment wp-att-17427"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/rr.png?w=300&amp;h=119" class="alignright size-medium wp-image-17427" height="119" /></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Robert Reckhow with his advsior Stephen Cook famously started the formal study of the complexity of proofs with their 1979 <a href="https://www.cs.toronto.edu/~sacook/homepage/cook_reckhow.pdf">paper</a>. They were interested in the length of the shortest <a href="https://en.wikipedia.org/wiki/Proof_complexity">proofs</a> of propositional statements. Georg Kreisel and others may have looked at proof length earlier, but one of the key insights of Reckhow and Cook is that low level propositional logic is important.</p>
<p>
Today I thought we might look at the complexity of proofs.</p>
<p>
Cook and Reckhow were motivated by issues like: How hard is it to prove that a graph has no clique of a certain size? Or how hard to prove that some program halts on all inputs of length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />? All of these questions ask about the length of proofs in a precise sense. Proofs have been around forever, back to Euclid at least, but Cook and Reckhow were the first to formally study the lengths of proofs. </p>
<p>
They were not directly interested in actual proofs. The kind you can find in the <a href="https://arxiv.org/archive/math">arXiv</a> or in a math journal, or at a conference—online or not. The kind that are in their paper.<br />
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/paper-5/" rel="attachment wp-att-17432"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/paper.png?w=300&amp;h=60" class="aligncenter size-medium wp-image-17432" height="60" /></a></p>
<p>We are talking today about these types of proofs. Not proofs that graphs have cliques. But proofs that a no planar graph can have a <img src="https://s0.wp.com/latex.php?latex=%7B5%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{5}" class="latex" title="{5}" /> clique. </p>
<p><a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/unknown-144/" rel="attachment wp-att-17430"><img src="https://rjlipton.files.wordpress.com/2020/08/unknown.png?w=600" alt="" class="aligncenter size-full wp-image-17430" /></a></p>
<p>
</p><p></p><h2> Proofs </h2><p></p>
<p></p><p>
Proofs are what we strive to find ever day. They the coin that measures progress in a mathematical field like complexity theory. We do sometimes work out examples, sometimes do computations to confirm conjectures on small examples, sometimes consider analogies to other proofs. But mostly we want to understand proofs. We want to create new ones and understand others proofs. </p>
<p>
Years ago when studying the graph isomorphism problem, I did some extensive computations for the random case. That is for the case of isomorphism for a random dense graphs against a worst case other graph. The computations helped me improve my result. It did not yield a proof, of course, but helped me realize that a certain lemma could be improved from a bound <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\log n}" class="latex" title="{\log n}" /> to <img src="https://s0.wp.com/latex.php?latex=%7BO%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{O(1)}" class="latex" title="{O(1)}" />. My results were dominated by <a href="https://www.researchgate.net/profile/Stanley_Selkow/publication/220618511_Random_Graph_Isomorphism/links/00463537d337e6a35d000000/Random-Graph-Isomorphism.pdf">paper</a> of Laszlo Babai, Paul Erdös, and Stanley Selkow. Oh well. </p>
<p>
</p><p></p><h2> Proofs Complexity </h2><p></p>
<p></p><p>
There are several measures of complexity for proofs. One is the length. Long proofs are difficult to find, difficult to write up, difficult to read, and difficult to check. Another less obvious measure is the logical structure of a proof. What does this mean?</p>
<p>
Our idea is that a proof can be modeled by a formula from propositional logic. The <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> is what we are trying to prove and the letters <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and so on are for statements we already know.  </p>
<li>
<img src="https://s0.wp.com/latex.php?latex=%7B%28A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(A \rightarrow P)}" class="latex" title="{(A \rightarrow P)}" />  This is a direct proof. <p></p>
</li><li>
<img src="https://s0.wp.com/latex.php?latex=%7B%28%5Cneg+P+%5Crightarrow+%5Cneg+A%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(\neg P \rightarrow \neg A)}" class="latex" title="{(\neg P \rightarrow \neg A)}" />  This is a proof by contradiction. <p></p>
</li><li>
<img src="https://s0.wp.com/latex.php?latex=%7B%28+A+%5Cvee+%5Cneg+A+%5Crightarrow+P%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{( A \vee \neg A \rightarrow P)}" class="latex" title="{( A \vee \neg A \rightarrow P)}" />  This is proof that uses a statement <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> that may be true or false. <p></p>
<p>
The last is a slight cheat, we use <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Cvee+%5Cneg+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A \vee \neg A}" class="latex" title="{A \vee \neg A}" /> to stand for a kind of axiom. A perfect example is from number theory. Let <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28X%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi(X)}" class="latex" title="{\pi(X)}" /> be the number of primes less than <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and the function <img src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{li(x)}" class="latex" title="{li(x)}" /> the <a href="https://en.wikipedia.org/w/index.php?title=Logarithmic_integral_function&amp;action=edit&amp;section=1">logarithmic function</a>. 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%3D+%5Cint_0%5Ex+%5Cfrac%7Bdt%7D%7B%5Cln+t%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. " class="latex" title="\displaystyle  li(x) = \int_0^x \frac{dt}{\ln t}. " /></p>
<p>The prime number <a href="https://en.wikipedia.org/wiki/Prime_number_theorem">theorem</a> says that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+%3D+li%28x%29+%2B+E%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) = li(x) + E(x), " class="latex" title="\displaystyle  \pi(x) = li(x) + E(x), " /></p>
<p>an error term. </p>
<p></p><p></p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/graph/" rel="attachment wp-att-17425"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/graph.png?w=300&amp;h=171" class="aligncenter size-medium wp-image-17425" height="171" /></a>
</td>
</tr>
<tr>
</tr>
</tbody></table>
<p>
It was noted that <img src="https://s0.wp.com/latex.php?latex=%7Bli%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{li(x)}" class="latex" title="{li(x)}" /> is larger than <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpi%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pi(x)}" class="latex" title="{\pi(x)}" /> for known values. The obvious question was that could 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++li%28x%29+%5Cge+%5Cpi%28x%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  li(x) \ge \pi(x), " class="latex" title="\displaystyle  li(x) \ge \pi(x), " /></p>
<p>be always true? If so this would be an interesting inequality. In 1914 John Littlewood famously <a href="https://www.google.com/books/edition/_/2SUrpE8NK6sC?hl=en&amp;gbpv=1&amp;pg=PA33&amp;dq=John+Littlewood+pi+nd+li">proved</a> that this was not true: </p>
<blockquote><p><b>Theorem 1</b> <em> If the Riemann Hypothesis is true: 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) - li(x) " class="latex" title="\displaystyle  \pi(x) - li(x) " /></p>
<p>is infinitely often positive and negative. If the Riemann Hypothesis is false: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) - li(x) " class="latex" title="\displaystyle  \pi(x) - li(x) " /></p>
</em><p><em>is infinitely often positive and negative. </em>
</p></blockquote>
<p></p><p>
Thus he proved that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpi%28x%29+-+li%28x%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \pi(x) - li(x) " class="latex" title="\displaystyle  \pi(x) - li(x) " /></p>
<p>is infinitely often positive and negative whether the the Riemann is true or not. </p>
<p>
</p><p></p><h2> Proofs in Trouble </h2><p></p>
<p></p><p>
A sign of a proof in danger is, in my opinion, is not just the length. A better measure I think is the logical flow of proof. I know of no actual proof that uses this structure: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28A+%5Crightarrow+B%29+%5Crightarrow+%28%28A+%5Cvee+C%29+%5Crightarrow+%28B+%5Cvee+C%29%29+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) " class="latex" title="\displaystyle  (A \rightarrow B) \rightarrow ((A \vee C) \rightarrow (B \vee C)) " /></p>
<p>Do you? Even if your proof is only a few lines or even pages, if the high level flow was the above tautology I would be worried. </p>
<p>
Another example is <img src="https://s0.wp.com/latex.php?latex=%7BP+%5Crightarrow+P%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P \rightarrow P}" class="latex" title="{P \rightarrow P}" />. This of course is a circular proof. It seems hard to believe we would actually do this, but it has happen. The key is that no one says: I will assume the theorem to prove it. The flaw is disguised better than that.</p>
<p>
I cannot formally define this measure. Perhaps it is known, but I do think that it would be an additional measure. For actual proofs, ones we use every day, perhaps it would be valuable. I know I have looked at an attempted proof of X and noticed the logical flow in this sense was too complex. So complex that it was wrong. The author of the potential proof was me. </p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Is this measure, the logical flow of a proof, of any interest? </p>
<p></p></li></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/08/19/logical-complexity-of-proofs/"><span class="datestr">at August 19, 2020 01:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-25562705.post-41257542542066199">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/roth.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://aaronsadventures.blogspot.com/2020/08/moment-multicalibration-for-uncertainty.html">Moment Multicalibration for Uncertainty Estimation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
This blog post is about<a href="https://arxiv.org/abs/2008.08037" target="_blank"> a new paper</a> that I'm excited about, which is joint work with <a href="https://www.cis.upenn.edu/~chrjung/" target="_blank">Chris Jung</a>,<a href="https://economics.sas.upenn.edu/people/changhwa-lee" target="_blank"> Changhwa Lee</a>, <a href="https://sites.google.com/view/malleshpai/">Mallesh Pai</a>, and <a href="https://sites.google.com/site/quaerereverum9/">Ricky Vohra</a>. <div><br /></div><div>Suppose you are diagnosed with hypertension, and your doctor recommends that you take a certain drug to lower your blood pressure. The latest research, she tells you, finds that the drug lowers diastolic blood pressure by an average of 10 mm Hg. You remember your statistics class from college, and so you ask about confidence intervals. She looks up the paper, and tells you that it reports a 95% confidence interval of [5, 15]. How should you interpret this? </div><div><br /></div><div>What you might naively hope is that [5, 15] represents a <i>conditional prediction interval</i>. If you have some set of observable features $x$, and a label $y$ (in this case corresponding to your decrease in diastolic blood pressure after taking the drug), a 95% conditional prediction interval would promise that:</div><div>$$\Pr_y [y \in [5, 15] | x] \geq 0.95$$</div><div><br /></div><div>In other words, a conditional prediction interval would promise that given all of your observed features, <i>over the unrealized/unmeasured randomness of the world</i>, there is a 95% chance that your diastolic blood pressure will decrease by between 5 and 15 points. </div><div><br /></div><div>But if you think about it, coming up with a conditional prediction interval is essentially impossible in a rich feature space. If $x$ contains lots of information about you, then probably there was nobody in the original study population that exactly matched your set of features $x$, and so we have no information at all about the conditional distribution on $y$ given $x$ --- i.e. no samples at all from the distribution over which our coverage probability supposedly holds! So how can you expect any sort of promise at all? There are two typical ways around this difficulty. </div><div><br /></div><div>The first is to make heroic assumptions about the data generation process. For example, if we assume that the world looks like an ordinary least squares model, and that there is a linear relationship between $y$ and $x$, then we can form a confidence region around the parameters of the model, and from that derive prediction intervals. But these prediction intervals are not valid if the model fails to hold, which it inevitably will. </div><div><br /></div><div>The second is to give up on conditional prediction intervals, and instead give <i>marginal prediction intervals</i>. This is what the <a href="https://arxiv.org/abs/0706.3188" target="_blank">conformal prediction</a> literature aims to do. A marginal prediction interval looks quite similar to a conditional prediction interval (at least syntactically), and promises:</div><div>$$\Pr_{(x,y)} [y \in [5, 15] ] \geq 0.95$$</div><div><br /></div><div>Rather than conditioning on your features $x$, a marginal prediction interval averages over all people, and promises that 95% of people who take the drug have their diastolic blood pressure lowered by between 5 and 15 points. But the semantics of this promise are quite different than that of a conditional prediction interval. Because the average is now taken over a large, heterogeneous population, very little is promised to <i>you</i>. For example, it might be that for patients in your demographic group (e.g. middle aged women with Sephardic Jewish ancestry and a family history of diabetes) that the drug is actually expected to raise blood pressure rather than lower it. Because this subgroup represents less than 5% of the population, it is entirely consistent with the marginal prediction interval being correct. Of course, if you are lucky, then perhaps someone has conducted a study of people from this demographic group and has computed marginal prediction intervals over it! But what if there are multiple different groups that you are a member of, over which the results seem to conflict? For example, you might also have a low BMI value and have unusually good cholesterol readings --- features of a group for which the drug works unusually well. Which uncertainty estimate should you trust, if you are a member of both groups? </div><div><br /></div><div>These concerns actually arise already when we think about the semantics of mean estimations ("the expected drop in blood pressure amongst patients who take this drug is 10 mm Hg"). Ideally, if you were a patient with features $x$, then 10 would be an estimate of $\mathbb{E}[y | x]$. But just as with uncertainty estimation, in a large feature space, we typically have no information about the distribution on $y$ conditional on $x$ (because we have never met anyone exactly like <i>you</i> before), and so instead what we have is just an estimate of $\mathbb{E}[y]$ --- i.e. averaging over people. If you have a method of making predictions $f(x)$ as a function of features $x$, then a standard performance metric is <i>calibration</i> --- which informally asks that for every prediction $p$, amongst all people for whom we predicted $f(x) = p$, the average of the realized labels $y$ should be $p$. Again, estimates of this form promise little to individuals, because they are averages over a large and heterogeneous population.   </div><div><br /></div><div>Several years ago, <a href="https://arxiv.org/abs/1711.08513" target="_blank">Hebert-Johnson et al.</a> proposed a nice way to interpolate between the (impossible) ideal of offering conditional mean predictions  $f(x) = \mathbb{E}[y | x]$, and the weak guarantee of merely offering calibrated predictions $f$. Roughly speaking, they proposed to specify a very large collection of potentially intersecting groups $G$ (representing e.g. demographic groups like Sephardic Jewish women with a family history of diabetes, and hypertensive patients with low cholesterol and BMI values, etc) and to ask that a trained predictor be <i>simultaniously</i> calibrated on each sufficiently large group in $G$. They showed how to accomplish this using a polynomially sized sample from the underlying distribution, with polynomial running time overhead, on top of the cost of solving learning problems over $G$. </div><div><br /></div><div>In our paper, we --- roughly speaking --- show how to accomplish the same thing, but for variances and other higher moments, in addition to just means. And our "multicalibrated moment estimates" can be used to construct prediction intervals in exactly the same way that real moments of the conditional label distribution could be used. If you used the real (unknown) label distribution moments, you would have gotten conditional prediction intervals. If you use our multi-calibrated moments, you get marginal prediction intervals that are simultaneously valid as averaged over each of the groups in $G$. So, for example, our hypertensive patient above could interpret her prediction interval --- if it was constructed from multicalibrated moment estimates computed from her features --- as an average over each of the demographic groups that she is a member of (so long as they are contained within $G$), and all of those interpretations would be simultaneously valid. </div><div><br /></div><div>I'll leave the details to the paper --- including what exactly we mean by "moment multicalibration". I'll just note that a major difficulty is that variances and higher moments --- unlike expectations --- do not combine linearly, so it is no longer sensible to ask that "amongst all people for whom we predicted variance v, the true variance should be v" --- because even the true conditional label variances do not satisfy this property. But it <i>is </i>sensible to ask that a pair of mean and moment predictions be calibrated in this way: "amongst all people for whom we predicted mean $\mu$ and variance v, the true mean should be $\mu$ and the true variance should be $v$." This is what we call "mean-conditioned moment calibration", and it is satisfied by the true distributional moments. </div><div><br /></div><div>The paper is here: <a href="https://arxiv.org/abs/2008.08037">Moment Multicalibration for Uncertainty Estimation</a>.</div><div><br /></div></div>







<p class="date">
by Aaron (noreply@blogger.com) <a href="http://aaronsadventures.blogspot.com/2020/08/moment-multicalibration-for-uncertainty.html"><span class="datestr">at August 19, 2020 11:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/126">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/126">TR20-126 |  Indistinguishability Obfuscation from Well-Founded Assumptions | 

	Aayush  Jain, 

	Huijia Lin, 

	Amit Sahai</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this work, we show how to construct indistinguishability obfuscation from subexponential hardness of four well-founded assumptions. We prove:

Let $\tau \in (0,\infty), \delta \in (0,1), \epsilon \in (0,1)$ be arbitrary constants. Assume sub-exponential security of the following assumptions, where $\lambda$ is a security parameter, and the parameters $\ell,k,n$ below are large enough polynomials in $\lambda$:

- The SXDH assumption on asymmetric bilinear groups of a prime order $p = O(2^\lambda)$,

- The LWE assumption over $\mathbb{Z}_{p}$ with subexponential modulus-to-noise ratio $2^{k^\epsilon}$, where $k$ is the dimension of the LWE secret,

- The LPN assumption over $\mathbb{Z}_p$ with polynomially many LPN samples and error rate $1/\ell^\delta$, where $\ell$ is the dimension of the LPN secret,

- The existence of a Boolean PRG in $\mathsf{NC}^0$ with stretch $n^{1+\tau}$,
 
Then, (subexponentially secure) indistinguishability obfuscation for all polynomial-size circuits exists.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/126"><span class="datestr">at August 19, 2020 11:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08071">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08071">Robust Mean Estimation on Highly Incomplete Data with Arbitrary Outliers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hu:Lunjia.html">Lunjia Hu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Reingold:Omer.html">Omer Reingold</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08071">PDF</a><br /><b>Abstract: </b>We study the problem of robustly estimating the mean of a $d$-dimensional
distribution given $N$ examples, where $\varepsilon N$ examples may be
arbitrarily corrupted and most coordinates of every example may be missing.
Assuming each coordinate appears in a constant factor more than $\varepsilon N$
examples, we show algorithms that estimate the mean of the distribution with
information-theoretically optimal dimension-independent error guarantees in
nearly-linear time $\widetilde O(Nd)$. Our results extend recent work on
computationally-efficient robust estimation to a more widely applicable
incomplete-data setting.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08071"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08032">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08032">Amortized Edge Sampling</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eden:Talya.html">Talya Eden</a>, Saleet Mossel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rubinfeld:Ronitt.html">Ronitt Rubinfeld</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08032">PDF</a><br /><b>Abstract: </b>We present a sublinear time algorithm that allows one to sample multiple
edges from a distribution that is pointwise $\epsilon$-close to the uniform
distribution, in an \emph{amortized-efficient} fashion. We consider the
adjacency list query model, where access to a graph $G$ is given via degree and
neighbor queries.
</p>
<p>The problem of sampling a single edge in this model has been considered by
Eden and Rosenbaum (SOSA 18). Let $n$ and $m$ denote the number of vertices and
edges of $G$, respectively. Eden and Rosenbaum provided upper and lower bounds
of $\Theta^*(n/\sqrt m)$ for sampling a single edge in general graphs (where
$O^*(\cdot)$ suppresses $\textrm{poly}(1/\epsilon)$ and $\textrm{poly}(\log n)$
dependencies). We ask whether the query complexity lower bound for sampling a
single edge can be circumvented when multiple samples are required. That is,
can we get an improved amortized per-sample cost if we allow a more costly
preprocessing phase? We answer in the affirmative.
</p>
<p>We present an algorithm that, if one knows the number of required samples $q$
in advance, has an overall cost of $O^*(\sqrt q \cdot(n/\sqrt m))$, which is
strictly preferable to $O^*(q\cdot (n/\sqrt m))$ cost resulting from $q$
invocations of the algorithm by Eden and Rosenbaum. More generally, for an
input parameter $x&gt;1$, our algorithm has a preprocessing phase with
$O^*(n/(x\cdot d_{avg}))$ cost, which then allows an $O(x/\epsilon)$ per-sample
cost, where $d_{avg}$ denotes the average degree of the graph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08032"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.08007">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.08007">Differentially Private Clustering: Tight Approximation Ratios</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Ghazi:Badih.html">Badih Ghazi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kumar:Ravi.html">Ravi Kumar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Manurangsi:Pasin.html">Pasin Manurangsi</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.08007">PDF</a><br /><b>Abstract: </b>We study the task of differentially private clustering. For several basic
clustering problems, including Euclidean DensestBall, 1-Cluster, k-means, and
k-median, we give efficient differentially private algorithms that achieve
essentially the same approximation ratios as those that can be obtained by any
non-private algorithm, while incurring only small additive errors. This
improves upon existing efficient algorithms that only achieve some large
constant approximation factors.
</p>
<p>Our results also imply an improved algorithm for the Sample and Aggregate
privacy framework. Furthermore, we show that one of the tools used in our
1-Cluster algorithm can be employed to get a faster quantum algorithm for
ClosestPair in a moderate number of dimensions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.08007"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07968">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07968">Four short stories on surprising algorithmic uses of treewidth</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Marx:D=aacute=niel.html">Dániel Marx</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07968">PDF</a><br /><b>Abstract: </b>This article briefly describes four algorithmic problems where the notion of
treewidth is very useful. Even though the problems themselves have nothing to
do with treewidth, it turns out that combining known results on treewidth
allows us to easily describe very clean and high-level algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07968"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07898">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07898">Minimum Eccentricity Shortest Path Problem with Respect to Structural Parameters</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Martin Kučera, Ondřej Suchý <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07898">PDF</a><br /><b>Abstract: </b>The Minimum Eccentricity Shortest Path Problem consists in finding a shortest
path with minimum eccentricity in a given undirected graph. The problem is
known to be NP-complete and W[2]-hard with respect to the desired eccentricity.
We present fpt algorithms for the problem parameterized by the modular width,
distance to cluster graph, the combination of distance to disjoint paths with
the desired eccentricity, and maximum leaf number.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07898"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07834">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07834">Planar L-Drawings of Bimodal Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Angelini:Patrizio.html">Patrizio Angelini</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chaplick:Steven.html">Steven Chaplick</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cornelsen:Sabine.html">Sabine Cornelsen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lozzo:Giordano_Da.html">Giordano Da Lozzo</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07834">PDF</a><br /><b>Abstract: </b>In a planar L-drawing of a directed graph (digraph) each edge e is
represented as a polyline composed of a vertical segment starting at the tail
of e and a horizontal segment ending at the head of e. Distinct edges may
overlap, but not cross. Our main focus is on bimodal graphs, i.e., digraphs
admitting a planar embedding in which the incoming and outgoing edges around
each vertex are contiguous. We show that every plane bimodal graph without
2-cycles admits a planar L-drawing. This includes the class of upward-plane
graphs. Finally, outerplanar digraphs admit a planar L-drawing - although they
do not always have a bimodal embedding - but not necessarily with an
outerplanar embedding.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07834"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07764">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07764">New Quality Metrics for Dynamic Graph Drawing</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Meidiana:Amyra.html">Amyra Meidiana</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hong:Seok=Hee.html">Seok-Hee Hong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/e/Eades:Peter.html">Peter Eades</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07764">PDF</a><br /><b>Abstract: </b>In this paper, we present new quality metrics for dynamic graph drawings.
Namely, we present a new framework for change faithfulness metrics for dynamic
graph drawings, which compare the ground truth change in dynamic graphs and the
geometric change in drawings. More specifically, we present two specific
instances, cluster change faithfulness metrics and distance change faithfulness
metrics. We first validate the effectiveness of our new metrics using
deformation experiments. Then we compare various graph drawing algorithms using
our metrics. Our experiments confirm that the best cluster (resp. distance)
faithful graph drawing algorithms are also cluster (resp. distance) change
faithful.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07764"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07644">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07644">Lazy caterer jigsaw puzzles: Models, properties, and a mechanical system-based solver</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Peleg Harel, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Ben=Shahar:Ohad.html">Ohad Ben-Shahar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07644">PDF</a><br /><b>Abstract: </b>Jigsaw puzzle solving, the problem of constructing a coherent whole from a
set of non-overlapping unordered fragments, is fundamental to numerous
applications, and yet most of the literature has focused thus far on less
realistic puzzles whose pieces are identical squares. Here we formalize a new
type of jigsaw puzzle where the pieces are general convex polygons generated by
cutting through a global polygonal shape with an arbitrary number of straight
cuts, a generation model inspired by the celebrated Lazy caterer's sequence. We
analyze the theoretical properties of such puzzles, including the inherent
challenges in solving them once pieces are contaminated with geometrical noise.
To cope with such difficulties and obtain tractable solutions, we abstract the
problem as a multi-body spring-mass dynamical system endowed with hierarchical
loop constraints and a layered reconstruction process. We define evaluation
metrics and present experimental results to indicate that such puzzles are
solvable completely automatically.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07644"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07637">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07637">Drawing Shortest Paths in Geodetic Graphs</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cornelsen:Sabine.html">Sabine Cornelsen</a>, Maximilian Pfister, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/F=ouml=rster:Henry.html">Henry Förster</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gronemann:Martin.html">Martin Gronemann</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoffmann:Michael.html">Michael Hoffmann</a>, Stephen Kobourov, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schneck:Thomas.html">Thomas Schneck</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07637">PDF</a><br /><b>Abstract: </b>Motivated by the fact that in a space where shortest paths are unique, no two
shortest paths meet twice, we study a question posed by Greg Bodwin: Given a
geodetic graph $G$, i.e., an unweighted graph in which the shortest path
between any pair of vertices is unique, is there a philogeodetic drawing of
$G$, i.e., a drawing of $G$ in which the curves of any two shortest paths meet
at most once? We answer this question in the negative by showing the existence
of geodetic graphs that require some pair of shortest paths to cross at least
four times. The bound on the number of crossings is tight for the class of
graphs we construct. Furthermore, we exhibit geodetic graphs of diameter two
that do not admit a philogeodetic drawing.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07637"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07633">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07633">SF-GRASS: Solver-Free Graph Spectral Sparsification</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Ying.html">Ying Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhao:Zhiqiang.html">Zhiqiang Zhao</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Feng:Zhuo.html">Zhuo Feng</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07633">PDF</a><br /><b>Abstract: </b>Recent spectral graph sparsification techniques have shown promising
performance in accelerating many numerical and graph algorithms, such as
iterative methods for solving large sparse matrices, spectral partitioning of
undirected graphs, vectorless verification of power/thermal grids,
representation learning of large graphs, etc. However, prior spectral graph
sparsification methods rely on fast Laplacian matrix solvers that are usually
challenging to implement in practice. This work, for the first time, introduces
a solver-free approach (SF-GRASS) for spectral graph sparsification by
leveraging emerging spectral graph coarsening and graph signal processing (GSP)
techniques. We introduce a local spectral embedding scheme for efficiently
identifying spectrally-critical edges that are key to preserving graph spectral
properties, such as the first few Laplacian eigenvalues and eigenvectors. Since
the key kernel functions in SF-GRASS can be efficiently implemented using
sparse-matrix-vector-multiplications (SpMVs), the proposed spectral approach is
simple to implement and inherently parallel friendly. Our extensive
experimental results show that the proposed method can produce a hierarchy of
high-quality spectral sparsifiers in nearly-linear time for a variety of
real-world, large-scale graphs and circuit networks when compared with the
prior state-of-the-art spectral method.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07633"><span class="datestr">at August 19, 2020 01:25 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07590">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07590">Cardinality estimation using Gumbel distribution</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Aleksander Łukasiewicz, Przemysław Uznański <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07590">PDF</a><br /><b>Abstract: </b>Cardinality estimation is the task of approximating the number of distinct
elements in a large dataset with possibly repeating elements. LogLog and
HyperLogLog (c.f. Durand and Flajolet [ESA 2003], Flajolet et al. [Discrete
Math Theor. 2007]) are small space sketching schemes for cardinality
estimation, which have both strong theoretical guarantees of performance and
are highly effective in practice. This makes them a highly popular solution
with many implementations in big-data systems (e.g. Algebird, Apache
DataSketches, BigQuery, Presto and Redis). However, despite having simple and
elegant formulation, both the analysis of LogLog and HyperLogLog are extremely
involved -- spanning over tens of pages of analytic combinatorics and complex
function analysis.
</p>
<p>We propose a modification to both LogLog and HyperLogLog that replaces
discrete geometric distribution with a continuous Gumbel distribution. This
leads to a very short, simple and elementary analysis of estimation guarantees,
and smoother behavior of the estimator.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07590"><span class="datestr">at August 19, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07556">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07556">On the Complexity Reduction of Uplink Sparse Code Multiple Access for Spatial Modulation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Al=Nahhal:Ibrahim.html">Ibrahim Al-Nahhal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dobre:Octavia_A=.html">Octavia A. Dobre</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Ikki:Salama.html">Salama Ikki</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07556">PDF</a><br /><b>Abstract: </b>Multi-user spatial modulation (SM) assisted by sparse code multiple access
(SCMA) has been recently proposed to provide uplink high spectral efficiency
transmission. The message passing algorithm (MPA) is employed to detect the
transmitted signals, which suffers from high complexity. This paper proposes
three low-complexity algorithms for the first time to the SM-SCMA. The first
algorithm is referred to as successive user detection (SUD), while the second
algorithm is the modified version of SUD, namely modified SUD (MSUD). Then, for
the first time, the tree-search of the SM-SCMA is constructed. Based on that
tree-search, another variant of the sphere decoder (SD) is proposed for the
SM-SCMA, referred to as fixed-complexity SD (FCSD). SUD provides a benchmark
for decoding complexity at the expense of bit-error-rate (BER) performance.
Further, MSUD slightly increases the complexity of SUD with a significant
improvement in BER performance. Finally, FCSD provides a near-optimum BER with
a considerable reduction of the complexity compared to the MPA decoder and also
supports parallel hardware implementation. The proposed algorithms provide
flexible design choices for practical implementation based on system design
demands. The complexity analysis and Monte-Carlo simulations of the BER are
provided for the proposed algorithms.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07556"><span class="datestr">at August 19, 2020 01:20 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07344">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07344">An Algorithmic Study of the Hypergraph Tur\'{a}n Problem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guruswami:Venkatesan.html">Venkatesan Guruswami</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sandeep:Sai.html">Sai Sandeep</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07344">PDF</a><br /><b>Abstract: </b>We propose an algorithmic version of the hypergraph Tur\'{a}n problem (AHTP):
given a $t$-uniform hypergraph $H=(V,E)$, the goal is to find the smallest
collection of $(t-1)$-element subsets of $V$ such that every hyperedge $e \in
E$ contains one of these subsets. In addition to its inherent combinatorial
interest---for instance, the $t=3$ case is connected to Tuza's famous
conjecture on covering triangles of a graph with edges---variants of AHTP arise
in recently proposed reductions to fundamental Euclidean clustering problems.
</p>
<p>AHTP admits a trivial factor $t$ approximation algorithm as it can be cast as
an instance of vertex cover on a structured $t$-uniform hypergraph that is a
``blown-up'' version of $H$. Our main result is an approximation algorithm with
ratio $\frac{t}{2}+o(t)$. The algorithm is based on rounding the natural LP
relaxation using a careful combination of thresholding and color coding.
</p>
<p>We also present results motivated by structural aspects of the blown-up
hypergraph. The blown-up is a $\textit{simple}$ hypergraph with hyperedges
intersecting in at most one element. We prove that vertex cover on simple
$t$-uniform hypergraphs is as hard to approximate as general $t$-uniform
hypergraphs. The blown-up hypergraph further has many forbidden structures,
including a ``tent'' structure for the case $t=3$. Whether a generalization of
Tuza's conjecture could also hold for tent-free $3$-uniform hypergraphs was
posed in a recent work. We answer this question in the negative by giving a
construction based on combinatorial lines that is tent-free, and yet needs to
include most of the vertices in a vertex cover.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07344"><span class="datestr">at August 18, 2020 11:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07252">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07252">W[1]-Hardness of the k-Center Problem Parameterized by the Skeleton Dimension</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Johannes Blum <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07252">PDF</a><br /><b>Abstract: </b>In the $k$-Center problem, we are given a graph $G=(V,E)$ with positive edge
weights and an integer $k$ and the goal is to select $k$ center vertices $C
\subseteq V$ such that the maximum distance from any vertex to the closest
center vertex is minimized. On general graphs, the problem is NP-hard and
cannot be approximated within a factor less than $2$.
</p>
<p>Typical applications of the $k$-Center problem can be found in logistics or
urban planning and hence, it is natural to study the problem on transportation
networks. Such networks are often characterized as graphs that are (almost)
planar or have low doubling dimension, highway dimension or skeleton dimension.
It was shown by Feldmann and Marx that $k$-Center is W[1]-hard on planar graphs
of constant doubling dimension when parameterized by the number of centers $k$,
the highway dimension $hd$ and the pathwidth $pw$. We extend their result and
show that even if we additionally parameterize by the skeleton dimension
$\kappa$, the $k$-Center problem remains W[1]-hard. Moreover, we prove that
under the Exponential Time Hypothesis there is no exact algorithm for
$k$-Center that has runtime $f(k,hd,pw,\kappa) \cdot \vert V \vert^{o(pw +
\kappa + \sqrt{k+hd})}$ for any computable function $f$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07252"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07216">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07216">Algorithm for SIS and MultiSIS problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Semaev:Igor.html">Igor Semaev</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07216">PDF</a><br /><b>Abstract: </b>SIS problem has numerous applications in cryptography. Known algorithms for
solving that problem are exponential in complexity. A new algorithm is
suggested in this note, its complexity is sub-exponential for a range of
parameters.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07216"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07159">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07159">Probabilistic Skyline Query Processing over Uncertain Data Streams in Edge Computing Environments</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lai:Chuan=Chi.html">Chuan-Chi Lai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Liu:Chuan=Ming.html">Chuan-Ming Liu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Yan=Lin.html">Yan-Lin Chen</a>, Li-Chun Wang <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07159">PDF</a><br /><b>Abstract: </b>With the advancement of technology, the data generated in our lives is
getting faster and faster, and the amount of data that various applications
need to process becomes extremely huge. Therefore, we need to put more effort
into analyzing data and extracting valuable information. Cloud computing used
to be a good technology to solve a large number of data analysis problems.
However, in the era of the popularity of the Internet of Things (IoT),
transmitting sensing data back to the cloud for centralized data analysis will
consume a lot of wireless communication and network transmission costs. To
solve the above problems, edge computing has become a promising solution. In
this paper, we propose a new algorithm for processing probabilistic skyline
queries over uncertain data streams in an edge computing environment. We use
the concept of a second skyline set to filter data that is unlikely to be the
result of the skyline. Besides, the edge server only sends the information
needed to update the global analysis results on the cloud server, which will
greatly reduce the amount of data transmitted over the network. The results
show that our proposed method not only reduces the response time by more than
50% compared with the brute force method on two-dimensional data but also
maintains the leading processing speed on high-dimensional data.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07159"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07023">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07023">Selection on $X_1 + X_1 + \cdots X_m$ via Cartesian product tree</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kreitzberg:Patrick.html">Patrick Kreitzberg</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lucke:Kyle.html">Kyle Lucke</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pennington:Jake.html">Jake Pennington</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Serang:Oliver.html">Oliver Serang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07023">PDF</a><br /><b>Abstract: </b>Selection on the Cartesian product is a classic problem in computer science.
Recently, an optimal algorithm for selection on $X+Y$, based on soft heaps, was
introduced. By combining this approach with layer-ordered heaps (LOHs), an
algorithm using a balanced binary tree of $X+Y$ selections was proposed to
perform $k$-selection on $X_1+X_2+\cdots+X_m$ in $o(n\cdot m + k\cdot m)$,
where $X_i$ have length $n$. Here, that $o(n\cdot m + k\cdot m)$ algorithm is
combined with a novel, optimal LOH-based algorithm for selection on $X+Y$
(without a soft heap). Performance of algorithms for selection on
$X_1+X_2+\cdots+X_m$ are compared empirically, demonstrating the benefit of the
algorithm proposed here.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07023"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.07003">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.07003">$k$-Forrelation Optimally Separates Quantum and Classical Query Complexity</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bansal:Nikhil.html">Nikhil Bansal</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sinha:Makrand.html">Makrand Sinha</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.07003">PDF</a><br /><b>Abstract: </b>Aaronson and Ambainis (SICOMP `18) showed that any partial function on $N$
bits that can be computed with an advantage $\delta$ over a random guess by
making $q$ quantum queries, can also be computed classically with an advantage
$\delta/2$ by a randomized decision tree making
${O}_q(N^{1-\frac{1}{2q}}\delta^{-2})$ queries. Moreover, they conjectured the
$k$-Forrelation problem -- a partial function that can be computed with $q =
\lceil k/2 \rceil$ quantum queries -- to be a suitable candidate for exhibiting
such an extremal separation. We prove their conjecture by showing a tight lower
bound of $\widetilde{\Omega}_k(N^{1-1/k})$ for the randomized query complexity
of $k$-Forrelation, where the advantage $\delta = 1/\mathrm{polylog}^k(N)$ and
$\widetilde{\Omega}_k$ hides $\mathrm{polylog}^k(N)$ factors. Our proof relies
on classical Gaussian tools, in particular, Gaussian interpolation and Gaussian
integration by parts, and in fact, shows a more general statement, that to
prove lower bounds for $k$-Forrelation against a family of functions, it
suffices to bound the $\ell_1$-weight of the Fourier coefficients at levels $k,
2k, 3k, \ldots, (k-1)k$ for functions in the family.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.07003"><span class="datestr">at August 18, 2020 11:20 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.06909">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.06909">Geodesic Paths for Image Segmentation with Implicit Region-based Homogeneity Enhancement</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Da.html">Da Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhu:Jian.html">Jian Zhu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zhang:Xinxin.html">Xinxin Zhang</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shu:Minglei.html">Minglei Shu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen:Laurent_D=.html">Laurent D. Cohen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.06909">PDF</a><br /><b>Abstract: </b>Minimal paths are considered as a powerful and efficient tool for boundary
detection and image segmentation due to its global optimality and
well-established numerical solutions such as fast marching algorithm. In this
paper, we introduce a flexible interactive image segmentation model based on
the minimal geodesic framework in conjunction with region-based homogeneity
enhancement. A key ingredient in our model is the construction of Finsler
geodesic metrics, which are capable of integrating anisotropic and asymmetric
edge features, region-based homogeneity and/or curvature regularization. This
is done by exploiting an implicit method to incorporate the region-based
homogeneity information to the metrics used. Moreover, we also introduce a way
to build objective simple closed contours, each of which is treated as the
concatenation of two disjoint open paths. Experimental results prove that the
proposed model indeed outperforms state-of-the-art minimal paths-based image
segmentation approaches.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.06909"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.06805">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.06805">Stronger Lower Bounds for Polynomial Time Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Salamon:Andr=aacute=s_Z=.html">András Z. Salamon</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wehar:Michael.html">Michael Wehar</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.06805">PDF</a><br /><b>Abstract: </b>We reinvestigate the classical topic of limited nondeterminism, to prove
stronger conditional lower bounds for polynomial time problems. In particular,
we show that CircuitSAT for circuits with m gates and log(m) inputs (denoted by
log-CircuitSAT) is not solvable in quasilinear time unless the exponential time
hypothesis (ETH) is false. In other words, a polynomial time improvement for
log-CircuitSAT would lead to an exponential time improvement for NP-complete
problems.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.06805"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.06801">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.06801">On Partial Differential Encodings, with Application to Boolean Circuits</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gnang:Edinah_K=.html">Edinah K. Gnang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.06801">PDF</a><br /><b>Abstract: </b>We argue that a better understanding of arithmetic circuit complexity is
central to Boolean circuit complexity and not merely a first step. We do this
by showing that Boolean circuit complexity upperbound the Kolomogorov
complexity of certain partial derivative incarnations of Turing machines.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.06801"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.06740">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.06740">Finding a Shortest Even Hole in Polynomial Time</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cheong:Hou=Teng.html">Hou-Teng Cheong</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lu:Hsueh=I.html">Hsueh-I Lu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.06740">PDF</a><br /><b>Abstract: </b>An even (respectively, odd) hole in a graph is an induced cycle with even
(respectively, odd) length that is at least four. Bienstock [DM 1991 and 1992]
proved that detecting an even (respectively, odd) hole containing a given
vertex is NP-complete. Conforti, Chornu\'ejols, Kappor, and Vu\v{s}kovi\'{c}
[FOCS 1997] gave the first known polynomial-time algorithm to determine whether
a graph contains even holes. Chudnovsky, Kawarabayashi, and Seymour [JGT 2005]
estimated that Conforti et al.'s algorithm runs in $O(n^{40})$ time on an
$n$-vertex graph and reduced the required time to $O(n^{31})$. Subsequently,
da~Silva and Vu\v{s}kovi\'{c}~[JCTB 2013], Chang and Lu [JCTB 2017], and Lai,
Lu, and Thorup [STOC 2020] improved the time to $O(n^{19})$, $O(n^{11})$, and
$O(n^9)$, respectively. The tractability of determining whether a graph
contains odd holes has been open for decades until the algorithm of Chudnovsky,
Scott, Seymour, and Spirkl [JACM 2020] that runs in $O(n^9)$ time, which Lai et
al. also reduced to $O(n^8)$. By extending Chudnovsky et al.'s techniques for
detecting odd holes, Chudnovsky, Scott, and Seymour [Combinatorica 2020 to
appear] (respectively, [arXiv 2020]) ensured the tractability of finding a long
(respectively, shortest) odd hole. They also ensured the NP-hardness of finding
a longest odd hole, whose reduction also works for finding a longest even hole.
Recently, Cook and Seymour ensured the tractability of finding a long even
hole. An intriguing missing piece is the tractability of finding a shortest
even hole, left open for at least 15 years by, e.g., Chudnovsky et al. [JGT
2005] and Johnson [TALG 2005]. We resolve this long-standing open problem by
giving the first known polynomial-time algorithm, running in $O(n^{31})$ time,
for finding a shortest even hole in an $n$-vertex graph that contains even
holes.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.06740"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.06700">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.06700">On Efficient Low Distortion Ultrametric Embedding</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Cohen=Addad:Vincent.html">Vincent Cohen-Addad</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/S=:Karthik_C=.html">Karthik C. S.</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lagarde:Guillaume.html">Guillaume Lagarde</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.06700">PDF</a><br /><b>Abstract: </b>A classic problem in unsupervised learning and data analysis is to find
simpler and easy-to-visualize representations of the data that preserve its
essential properties. A widely-used method to preserve the underlying
hierarchical structure of the data while reducing its complexity is to find an
embedding of the data into a tree or an ultrametric. The most popular
algorithms for this task are the classic linkage algorithms (single, average,
or complete). However, these methods on a data set of $n$ points in
$\Omega(\log n)$ dimensions exhibit a quite prohibitive running time of
$\Theta(n^2)$.
</p>
<p>In this paper, we provide a new algorithm which takes as input a set of
points $P$ in $\mathbb{R}^d$, and for every $c\ge 1$, runs in time
$n^{1+\frac{\rho}{c^2}}$ (for some universal constant $\rho&gt;1$) to output an
ultrametric $\Delta$ such that for any two points $u,v$ in $P$, we have
$\Delta(u,v)$ is within a multiplicative factor of $5c$ to the distance between
$u$ and $v$ in the "best" ultrametric representation of $P$. Here, the best
ultrametric is the ultrametric $\tilde\Delta$ that minimizes the maximum
distance distortion with respect to the $\ell_2$ distance, namely that
minimizes $\underset{u,v \in P}{\max}\ \frac{\tilde\Delta(u,v)}{\|u-v\|_2}$.
</p>
<p>We complement the above result by showing that under popular complexity
theoretic assumptions, for every constant $\varepsilon&gt;0$, no algorithm with
running time $n^{2-\varepsilon}$ can distinguish between inputs in
$\ell_\infty$-metric that admit isometric embedding and those that incur a
distortion of $\frac{3}{2}$.
</p>
<p>Finally, we present empirical evaluation on classic machine learning datasets
and show that the output of our algorithm is comparable to the output of the
linkage algorithms while achieving a much faster running time.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.06700"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.06591">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.06591">New Techniques for Proving Fine-Grained Average-Case Hardness</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dalirrooyfard:Mina.html">Mina Dalirrooyfard</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lincoln:Andrea.html">Andrea Lincoln</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Williams:Virginia_Vassilevska.html">Virginia Vassilevska Williams</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.06591">PDF</a><br /><b>Abstract: </b>The recent emergence of fine-grained cryptography strongly motivates
developing an average-case analogue of Fine-Grained Complexity (FGC).
</p>
<p>This paper defines new versions of OV, $k$SUM and zero-$k$-clique that are
both worst-case and average-case fine-grained hard assuming the core hypotheses
of FGC. We then use these as a basis for fine-grained hardness and average-case
hardness of other problems. The new problems represent their inputs in a
certain ``factored'' form. We call them ``factored''-OV,
``factored''-zero-$k$-clique and ``factored''-$3$SUM. We show that
factored-$k$-OV and factored $k$SUM are equivalent and are complete for a class
of problems defined over Boolean functions. Factored zero-$k$-clique is also
complete, for a different class of problems.
</p>
<p>Our hard factored problems are also simple enough that we can reduce them to
many other problems, e.g.~to edit distance, $k$-LCS and versions of Max-Flow.
We further consider counting variants of the factored problems and give
WCtoACFG reductions for them for a natural distribution. Through FGC reductions
we then get average-case hardness for well-studied problems like regular
expression matching from standard worst-case FGC assumptions.
</p>
<p>To obtain our WCtoACFG reductions, we formalize the framework of [Boix-Adsera
et al. 2019] that was used to give a WCtoACFG reduction for counting
$k$-cliques. We define an explicit property of problems such that if a problem
has that property one can use the framework on the problem to get a WCtoACFG
self reduction. We then use the framework to slightly extend Boix-Adsera et
al.'s average-case counting $k$-cliques result to average-case hardness for
counting arbitrary subgraph patterns of constant size in $k$-partite graphs...
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.06591"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2008.06554">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2008.06554">On the Hardness of Massively Parallel Computation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chung:Kai=Min.html">Kai-Min Chung</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Ho:Kuan=Yi.html">Kuan-Yi Ho</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sun:Xiaorui.html">Xiaorui Sun</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2008.06554">PDF</a><br /><b>Abstract: </b>We investigate whether there are inherent limits of parallelization in the
(randomized) massively parallel computation (MPC) model by comparing it with
the (sequential) RAM model. As our main result, we show the existence of hard
functions that are essentially not parallelizable in the MPC model. Based on
the widely-used random oracle methodology in cryptography with a cryptographic
hash function $h:\{0,1\}^n \rightarrow \{0,1\}^n$ computable in time $t_h$, we
show that there exists a function that can be computed in time $O(T\cdot t_h)$
and space $S$ by a RAM algorithm, but any MPC algorithm with local memory size
$s &lt; S/c$ for some $c&gt;1$ requires at least $\tilde{\Omega}(T)$ rounds to
compute the function, even in the average case, for a wide range of parameters
$n \leq S \leq T \leq 2^{n^{1/4}}$. Our result is almost optimal in the sense
that by taking $T$ to be much larger than $t_h$, \textit{e.g.}, $T$ to be
sub-exponential in $t_h$, to compute the function, the round complexity of any
MPC algorithm with small local memory size is asymptotically the same (up to a
polylogarithmic factor) as the time complexity of the RAM algorithm. Our result
is obtained by adapting the so-called compression argument from the data
structure lower bounds and cryptography literature to the context of massively
parallel computation.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2008.06554"><span class="datestr">at August 18, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/125">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/125">TR20-125 |  Efficient reconstruction of depth three circuits with top fan-in two | 

	Gaurav  Sinha</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In this paper we develop efficient randomized algorithms to solve the black-box reconstruction problem for polynomials(over finite fields) computable by depth three arithmetic circuits with alternating addition/multiplication gates, such that top(output) gate is an addition gate with in-degree $2$. Such circuits naturally compute polynomials of the form $G\times(T_1 + T_2)$, where $G,T_1,T_2$ are product of affine forms computed at the first(addition) layer in the circuit, and polynomials $T_1,T_2$ have no common factors. Rank of such a circuit is defined to be the dimension of vector space spanned by all affine factors of $T_1$ and $T_2$. For any polynomial $f$ computable by such a circuit, $rank(f)$ is defined to be the minimum rank of any such circuit computing it. Our work develops randomized algorithms, which take as input a black-box computing polynomial $f$, with coefficients in a finite field $\mathbb{F}$, exhibiting such a circuit. Here are the results. 

$[$Low rank$]:$ When $5\leq r = rank(f) = O(\log^3 d)$, it runs in time $(nd^{\log^3d}\log |\mathbb{F}|)^{O(1)}$ and outputs a depth three circuit computing $f$ (with high probability), with top addition gate having in-degree $\leq d^{rank(f)}$.

$[$High rank$]:$ When $rank(f) = \Omega(\log^3 d)$, it runs in time $(nd\log |\mathbb{F}|)^{O(1)}$, and with high probability outputs a depth three circuit computing $f$, with top addition gate having in-degree $2$.

Prior to our work, black-box reconstruction for this circuit class was addressed in [Shp07, KS09, Sin16b]. Reconstruction algorithm in [Shp07] runs in time quasi-polynomial in $n,d,|\mathbb{F}|$ and that in [KS09] is quasi-polynomial in $d,|\mathbb{F}|$. Algorithm in [Sin16b] works only for polynomials over characteristic zero fields. Thus ours is the first blackbox reconstruction algorithm for this class of circuits that runs in time polynomial in $\log |\mathbb{F}|$. This problem has been mentioned as an open problem in [GKL12] (STOC 2012). In the high rank case, our algorithm runs in $(nd\log|\mathbb{F}|)^{O(1)}$ time, thereby significantly improving the existing algorithms in [Shp07, KS09].</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/125"><span class="datestr">at August 17, 2020 07:11 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/124">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/124">TR20-124 |  A Strong XOR Lemma for Randomized Query Complexity | 

	Joshua Brody, 

	JaeTak Kim, 

	Peem Lerdputtipongporn, 

	Hariharan Srinivasulu</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give a strong direct sum theorem for computing $XOR \circ g$.  Specifically, we show that the randomized query complexity of computing the XOR of $k$ instances of $g$ satisfies $\bar{R}_\varepsilon(XOR \circ g)=\Theta(\bar{R}_{\varepsilon/k}(g))$.  This matches the naive success amplification bound and answers a question of Blais and Brody.

As a consequence of our strong direct sum theorem, we give a total function $g$ for which $R(XOR \circ g) = \Theta(k\log(k)R(g))$, answering an open question from Ben-David et al.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/124"><span class="datestr">at August 17, 2020 01:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/123">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/123">TR20-123 |  An Optimal Tester for k-Linear | 

	Nader Bshouty</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
A Boolean function $f:\{0,1\}^n\to \{0,1\}$ is $k$-linear if it returns the sum (over the binary field $F_2$) of $k$ coordinates of the input. In this paper, we study property testing of the classes $k$-Linear, the class of all $k$-linear functions, and $k$-Linear$^*$, the class $\cup_{j=0}^kj$-Linear.
We give a non-adaptive distribution-free two-sided $\epsilon$-tester for $k$-Linear that makes
$$O\left(k\log k+\frac{1}{\epsilon}\right)$$ queries.
This matches the lower bound known from the literature.

We then give a non-adaptive distribution-free one-sided $\epsilon$-tester for $k$-Linear$^*$ that makes the same number of queries and show that any non-adaptive uniform-distribution one-sided $\epsilon$-tester for $k$-Linear must make at least $ \tilde\Omega(k)\log n+\Omega(1/\epsilon)$ queries. The latter bound, almost matches the upper bound $O(k\log n+1/\epsilon)$ known from the literature. We then show that any adaptive uniform-distribution one-sided $\epsilon$-tester for $k$-Linear must make at least $\tilde\Omega(\sqrt{k})\log n+\Omega(1/\epsilon)$ queries.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/123"><span class="datestr">at August 17, 2020 01:17 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6748297921609096715">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2019/04/what-if-history-of-science-factoring.html">Mathematics is not commutative</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In my poll of P vs NP and other issues, one of the questions was<br />
<br />
<br />
                             <i>Is factoring in P?</i><br />
<i><br /></i>
One of the most interesting answers was<br />
<br />
<br />
                            <i> I don't really see why it shouldn't be. - Peter Shor</i><br />
<i><br /></i>
Recall that Peter Shor proved Factoring is in Quantum-P which lead to intense interest in Quantum Computing.<br />
<br />
1) What if factoring was in P and this was shown before Shor's algorithm? Would Shor or someone else have ever proven factoring in quantum P? Would there be as much intense interest in quantum computing as there is now? Perhaps by physicists more than CS people?<br />
<br />
2) What if factoring was in P and this was shown before RSA? Where would crypto be now? Zip drives with a googleplex random (or nearly random) bits and more 1-time pads? More lattice based crypto? Or RSA but with larger numbers? This may depend on how good the factoring algorithm is.<br />
<br />
3) More generally, how much does the order of events matter for science?<br />
<br />
a) If the Banach-Tarski paradox was discovered early on, would we have just tossed out the Axiom of Choice before so much more was build on it? Darling thinks we should toss out AC NOW because of Banach-Tarski.<br />
<br />
b) In the model of set theory L you can do ALL of math except some parts of set theory and maybe a few other things (note quite: Harvey Friedman has found some combinatorial statements that need large cardinals to prove). Had L been discovered earlier then could we all now be working in L (except a few people who look at other models, but they are not in the mainstream)? We might know more about L and less about forcing. We would KNOW that AC and CH are true. Or we would think we know.<br />
<br />
c) If  Engineers were the first ones to look at SAT and reductions, might they have been content to know that  if SAT \le A then A is probably hard? No need for the Cook-Levin Theorem! And then when someone proved Cook-Levin would the Engineers not really cares since they already knew SAT was hard?<br />
<br />d) I can imagine Ramsey's Theorem being discovered much later for some application, or perhaps never being discovered at all.<div><br /></div><div>e) VDW's theorem has so few application, I can imagine it never being discovered. </div><div><br /></div><div>4) There are cases where if A was discovered before B then B has an easy proof, whereas if B was discovered before A, then B has a hard proof. I'll give one example:</div><div><br /></div><div>Given HALT is undecidable, Godel's theorem is easy.</div><div><br /></div><div>Assume HALT is undecidable. </div><div><br /></div><div>Let STAT(e) be the statement M_e(0) does not  halt.</div><div><br /></div><div>There is some e such that M_e(0) does not halt  but ZFC cannot prove this.</div><div><br /></div><div>PROOF: Assume, By Way of Contradiction that for all e such that M_e(0) does not halt,</div><div>ZFC could prove this. Then HALT is DECIDABLE:</div><div><br />Given e, run M_e(0) and at the same time enumerate all proofs in ZFC. It is guaranteed that</div><div>you will either find M_e(0) halts or a proof that M_e(0) does not halt. Hence you will,</div><div>in finite time, know if M_e(0) halts OR NOT.</div><div><br /></div><div>END OF PROOF</div><div><br /></div><div>Is the sequence of events where HALT is proven undecidable  before Godel's theorem plausible.</div><div>I  think so</div><div><br /></div><div>I INVITE my readers to give there own examples of when Math is not commutative- meaning that</div><div>the order of events matters.</div><div>
<br /></div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2019/04/what-if-history-of-science-factoring.html"><span class="datestr">at August 17, 2020 12:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/122">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/122">TR20-122 |  Size Bounds on Low Depth Circuits for Promise Majority | 

	Joshua Cook</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give two results on the size of AC0 circuits computing promise majority. $\epsilon$-promise majority is majority promised that either at most an $\epsilon$ fraction of the input bits are 1, or at most $\epsilon$ are 0.

First, we show super quadratic lower bounds on both monotone and general depth 3 circuits for promise majority.

For any $\epsilon \in (0, 1/2)$, monotone depth 3 AC0 circuits for $\epsilon$-promise majority have size 
$\tilde{\Omega}\left(\epsilon^3 n^{2 + \frac{\ln(1 - \epsilon)}{\ln(\epsilon)}}\right)$
         
For any $\epsilon \in (0, 1/2)$, general depth 3 AC0 circuits for $\epsilon$-promise majority have size
$\tilde{\Omega}\left(\epsilon^3 n^{2 + \frac{\ln(1 - \epsilon^2)}{2\ln(\epsilon)}}\right)$

These are the first nontrivial size lower bounds on depth 3 promise majority circuits for $\epsilon &lt; 0.45$.
        
Second, we give both uniform and non-uniform sub-quadratic size constant depth circuits for promise majority.

For integer $k \geq 1$, constant $\epsilon \in (0, 1/2)$, there exists monotone non uniform AC0 circuits of depth $2 + 2 \cdot k$ computing $\epsilon$-promise majority with size
$\tilde{O}\left(n^{\frac{1}{1 - 2^{-k}}}\right)$

For integer $k \geq 1$, constant $\epsilon \in (0, 1/2)$, there exists monotone uniform AC0 circuit of depth $2 + 2 \cdot k$ computing $\epsilon$-promise majority with size
$n^{\frac{1}{1 - \left(\frac{2}{3}\right)^k} + o(1)}$

These circuits are based on incremental improvements to existing depth 3 circuits for promise majority given by Ajtai and Viola combined with a divide and conquer strategy.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/122"><span class="datestr">at August 16, 2020 02:37 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/121">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/121">TR20-121 |  Fractional Pseudorandom Generators from the $k$th Fourier Level | 

	Eshan Chattopadhyay, 

	Jason Gaitonde, 

	Abhishek Shetty</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
In recent work by Chattopadhyay et al.[CHHL19,CHLT19], the authors exhibit a simple and flexible construction of pseudorandom generators for classes of Boolean functions that satisfy $L_1$ Fourier bounds. [CHHL19] show that if a class satisfies such tail bounds at all levels, this implies a PRG whose seed length depends on the quality of these bounds through their innovative random walk framework that composes together fractional PRGs that polarize quickly to the Boolean hypercube. On the other hand, [CHLT19] show that, by derandomizing the analysis of [RT19], just level-two Fourier bounds suffice to construct a pseudorandom generator using their framework; as this is a much weaker assumption on the class, [CHLT19] naturally obtain exponentially worse dependence on the error in the seed length compared to [CHHL19]. Moreover, this derandomization relies on simulating nearly independent Gaussians for the fractional pseudorandom generator, which necessitates the  polynomial dependence on $1/\epsilon$ in each fractional step.
    
    In this work, we attempt to bridge the gap between these two results. Namely, we partially answer an open question by [CHLT19] that nearly interpolates between them. In particular, we show that if one has bounds up to the level-$k$ $L_1$ Fourier mass of a closely related class of functions, where $k&gt;2$, one can obtain improved seed length, the degree to which is determined by how high $k$ can be taken. Our analysis shows that for error $\epsilon=1/\text{poly}(n)$, one needs control at just level $O(\log n)$ to recover the seed length of [CHHL19], without assumptions on the entire tail. We avoid this by providing a simple, alternate analysis of their fractional PRG that instead relies on Taylor's theorem and $p$-biased Fourier analysis to avoid assumptions on the weights of the higher-order terms. This further allows us to show that this framework can handle the class of low-degree polynomials over $\mathbb{F}_2$, with slightly worse dependence than the current state-of-the-art, which was not previously known. We hope that this alternate analysis will be fruitful in improving the understanding of this new and powerful framework.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/121"><span class="datestr">at August 16, 2020 02:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://differentialprivacy.org/privacy-composition/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/dp.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://differentialprivacy.org/privacy-composition/">Why Privacy Needs Composition</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>We’re back!  In our last <a href="https://differentialprivacy.org/\average-case-dp">post</a> we discussed some of the subtle pitfalls of formulating the assumptions underlying average-case relaxations of differential privacy.  This time we’re going to look at the composition property of differential privacy—that is, the fact that running two independent differentially private algorithms on your data and combining their outputs is still differentially private. This is a key property of differential privacy and is actually closely related to the worst-case nature of differential privacy.</p>

<p>Composition is really the crucial property that has made differential privacy successful. Data analysis doesn’t happen in a vacuum, and the greatest threat to privacy comes from combining multiple pieces of information. These pieces of information can come from a single source that releases detailed statistics, or they could come from separate sources. So it’s critical to understand how the composition of multiple pieces of information can affect privacy.</p>

<p>In this post we’ll give some examples to illustrate why we need composition, and why composition is challenging for average-case relaxations of differential privacy.  Composition is what allows you to design sophisticated differentially private algorithms out of simple building blocks, and it’s what allows one organization to release differentially private statistics without having to understand the entire ecosystem of related information that has been or will be released.  As we’ll see, the challenges of composing average-case privacy guarantees are also very closely related to the subtleties that arise in thinking about the adversary’s beliefs.</p>

<h3 id="differencing-attacks">Differencing Attacks</h3>

<p>Let’s start with a simple example of composition that was alluded to in our last post.</p>

<p>You’ve just started a new job and signed up for the health insurance provided by your employer. Thus, your employer is able to obtain aggregated data from the insurance provider. In particular, your employer can ask “How many of our employees have submitted claims for condition X?”  However, your employer should not be able to find out whether or not <em>you</em> have condition X. 
For concreteness, condition X could be a mental health condition, drug addiction, being pregnant, terminal cancer, or an expensive chronic illness. Each of these could result in some kind of employment discrimination.</p>

<p>The employer may find out that 417 employees have condition X.  That’s OK; on its own, this number reveals very little about whether or not <em>you</em> have condition X, as long as your employer is uncertain about how many employees <em>other than you</em> have condition X.  We can formalize this as some kind of average-case or Bayesian privacy guarantee. Thus the health-insurance company is comfortable releasing this number exactly.  But, yesterday, before you started your job, it also seemed reasonable to allow your employer to ask the exact same question, and yesterday the answer was 416. Thus your employer concludes that you have condition X.</p>

<p>In this example, we see how two pieces of information—the count before you started and the count after you started—each of which seems innocuous on its own can be combined to reveal private information. This is a simple example of a <em>differencing attack</em> and composition is important in part because it prevents these attacks.</p>

<p>This example involves only two pieces of information. However, an attack could combine many pieces of information. For example, the counts could be broken down by sex, race/ethnicity, age, location, and tobacco use.<sup id="fnref:1"><a href="https://differentialprivacy.org/feed.xml#fn:1" class="footnote">1</a></sup> Additional data may also be obtained from other sources, such as public records, social media, voluntary disclosures, healthcare providers, financial records, employment records, or even illicit sources. The possibilities for attacks grow rapidly as more information is made available. And an employer is only one example of a potential privacy adversary.</p>

<p>The point of this example is that it’s easy to argue that one piece of information is harmless to privacy by making plausible-looking assumptions about the adversary. But this intuition rapidly breaks down once you consider the bigger picture where there are many pieces of information that can complete the puzzle. That’s why we need rigorous methods for understanding privacy and its composition.</p>

<h3 id="quantifying-composition">Quantifying Composition</h3>

<p>How does differential privacy prevent a differencing attack like the one we just discussed? The simplest way is to add a little bit of random noise to each answer. On the first day, instead of releasing the exact count 416, we could release a noisy count, say, 420. Then on the second day, instead of releasing the true count 417, we release another noisy count, say, 415. More precisely, it is common to add noise to counts drawn from a Laplace or Gaussian distribution.  These figures are still close enough to the true values to be useful, but the difference of 1 is now obscured by the noise, so your privacy is protected.</p>

<p>Since the noise is unknown to <em>any</em> potential adversary, it introduces uncertainty that protects the contribution that an individual makes to the count. Taking the difference of two independent noisy counts results in something that is still noisy. However, we must be careful to quantify this privacy guarantee, particularly when it comes to composition.</p>

<p>So, how much noise do we need to add? Let’s go back to the example and suppose the insurance company provides noisy answers where the noise has mean zero and some fixed variance. Your employer could simply ask the same question again and again and each time receive a different noisy answer. Averaging these noisy answers will effectively reduce the variance of the added noise and allow the true answer to be discerned. That leaves us back where we started.</p>

<p>The moral of this revised example is that the scale of the noise must increase if we allow more access to the data, so more questions means more noise in each answer.<sup id="fnref:2"><a href="https://differentialprivacy.org/feed.xml#fn:2" class="footnote">2</a></sup> 
Asking the same question again and again may seem silly. There are easy ways to defend against this and some similar attacks. (E.g., by returning the same answer each time instead of generating fresh noise.) But, unfortunately, the underlying phenomenon cannot be circumvented. One of the seminal works that led to differential privacy <a href="https://dl.acm.org/doi/10.1145/773153.773173" title="Irit Dinur, Kobbi Nissim. Revealing Information While Preserving Privacy. PODS 2003"><strong>[DN03]</strong></a> showed that there is an inherent tradeoff between the number of questions to be answered and the amount of noise that needs to be added to protect privacy. The general attack is simple: Instead of asking the same query again and again, the attacker asks “random” queries.<sup id="fnref:3"><a href="https://differentialprivacy.org/feed.xml#fn:3" class="footnote">3</a></sup> This attack only requires basic linear algebra and, importantly, has been demonstrated on real systems <a href="https://arxiv.org/abs/1810.05692" title="Aloni Cohen, Kobbi Nissim. Linear Program Reconstruction in Practice. 2018."><strong>[CN18]</strong></a>.</p>

<h3 id="adaptive-composition">Adaptive Composition</h3>

<p>There are actually two kinds of composition to consider. There is <strong>non-adaptive composition</strong>, where the questions to be asked are pre-specified and thus independent of the data, and there is <strong>adaptive composition</strong>, where the questions may themselves depend on the results of prior access to the data. Adaptive composition arises in an interactive system where queries are submitted one-by-one and each answer is returned before the next query is submitted. So far, we have really only considered non-adaptive composition.</p>

<p>Any interactive system must take adaptive composition into account.  A natural algorithm which asks adaptive questions is gradient descent for minimizing a function that is determined by private data (e.g., for logistic regression on medical records). At each step, the algorithm asks for a gradient of the function, which depends on the private data, at the current point. Then the point is updated according to the reported gradient and the process repeats. Since the updated point depends on the previous answer, the next gradient computation is adaptive.</p>

<p>The good news is that differential privacy can handle adaptive composition just fine.  However, to handle adaptive composition, it’s really important that you have a worst-case privacy definition like differential privacy. As we will see below, average-case variants of differential privacy cannot handle adaptive composition. Intuitively, the problem is that whatever distributional assumption you might make about the data or query a priori is unlikely to hold when you condition on past interactions with the same data or related data.</p>

<p>Here’s a technical example that shows the difficulty of adaptive composition. Our data \(x \in \{-1,+1\}^n\) is a vector of \(n\) bits, one bit per person.<sup id="fnref:4"><a href="https://differentialprivacy.org/feed.xml#fn:4" class="footnote">4</a></sup>  Because we’re considering average-case differential privacy, we’ll model this vector as uniformly random.  Consider the following slightly odd algorithm \(M_2(x,v)\)—it takes a vector \(v \in \{-1,+1\}^n\) from the user, and, if the correlation \(\langle x, v \rangle / n\) between \(v\) and \(x\) is smaller than \(\varepsilon/2\), the query returns \(\emptyset\), but, if the correlation between \(v\) and \(x\) is larger than \(\varepsilon/2\), the query returns the dataset \(x\).  In isolation this algorithm satisfies an average-case version of differential privacy, because if \(n\) is large enough and \(x\) is uniformly random, then it’s very unlikely that the user can guess a vector \(v\) that causes this algorithm to output anything other than \(\emptyset\).  This algorithm may seem contrived; it is a simple stand-in for any algorithm that behaves very well most of the time, but fails completely on some rare inputs.</p>

<p>Now, consider another, more familiar differentially private algorithm called randomized response <a href="https://www.jstor.org/stable/2283137?seq=1" title="Stanley Warner. Randomized Response: A Survey Technique for Eliminating Evasive Answer Bias. Journal of the American Statistical Association 1965."><strong>[W65]</strong></a>.  For those not familiar, this algorithm \(M_1(x)\) outputs a vector \(y \in \{-1,+1\}^n\), where \(y_i\) is slightly more likely to be \(x_i\) than \(-x_i\).  Specifically, we set \(y_i = x_i\) with probability \((1+\varepsilon)/2\) and \(y_i = - x_i\) otherwise. This satisfies \(\log(\frac{1+\varepsilon}{1-\varepsilon})\)-differential privacy or, roughly, \(2\varepsilon\)-differential privacy. The upshot is that we obtain a vector \(y\) where the correlation between \(x\) and \(y\) is about \(\varepsilon\), i.e. \(\langle x , y \rangle / n \approx \varepsilon\).</p>

<p>OK, so \(M_1\) and \(M_2\) both satisfy strong average-case versions of differential privacy when the data is uniform, but what about their composition?  Well, the bad news is that running \(y = M_1(x)\) followed by \(M_2(x,y)\) is going to return the dataset \(x\) with probability approaching 100%!  That’s because \(y\) was designed precisely to be a vector with correlation about \(\varepsilon\) with \(x\), and this is exactly the key that gets \(M_2\) to unlock the dataset.</p>

<p>What went wrong here is that, even if \(x\) really is uniformly random, it’s very far from it when conditioned on the output \(y=M_1(x)\). To analyze \(M_2(x,y)\) we must look at the distribution of \(x\) conditioned on \(y\). This distribution is going to be messy and may as well be a worst-case distribution, which means we must leave the realm of average-case privacy.</p>

<h3 id="conclusion">Conclusion</h3>
<p>Composition guarantees that, as long as each part of your system is differentially private, then the overall system is too. It would be difficult to build sophisticated systems without this property. And it’s what allows one organization to release differentially private statistics without having to worry about what other information might be out there. In short, composition is what allows differential privacy to deal with the complexities of the real world.</p>

<p>It is unlikely that differential privacy would have taken off as a field of research without this composition property. Any proposal for an alternative approach to privacy-preserving data analysis should first be evaluated in terms of how it handles composition.</p>

<p>This post only scratches the surface. In particular, we haven’t talked about the quantitative aspects of composition; that’s where the fun really begins. We will leave you with some pointers to further reading on the topic:</p>

<ul>
  <li><a href="http://www.annualreviews.org/eprint/E84vbD3Yzw4ff7YPAjnv/full/10.1146/annurev-statistics-060116-054123" title="Cynthia Dwork, Adam Smith, Thomas Steinke, Jonathan Ullman. Exposed! A Survey of Attacks on Private Data. Annual Review of Statistics and its Applications 2017."><strong>[DSSU17]</strong></a> This is a survey of attacks which explains quantitatively the relationship between noise, number of questions, and privacy risks.</li>
  <li><a href="https://arxiv.org/abs/1311.0776" title="Peter Kairouz, Sewoong Oh, Pramod Viswanath. The Composition Theorem for Differential Privacy. ICML 2015."><strong>[KOV15]</strong></a> <a href="https://arxiv.org/abs/1507.03113" title="Jack Murtagh, Salil Vadhan. The Complexity of Computing the Optimal Composition of Differential Privacy. TCC 2016"><strong>[MV15]</strong></a> <a href="https://arxiv.org/abs/1603.01887" title="Cynthia Dwork, Guy Rothbum. Concentrated Differential Privacy. 2016."><strong>[DR16]</strong></a> <a href="https://arxiv.org/abs/1605.02065" title="Mark Bun, Thomas Steinke. Concentrated Differential Privacy: Simplifications, Extensions, and Lower Bounds. TCC 2016."><strong>[BS16]</strong></a> <a href="https://arxiv.org/abs/1702.07476" title="Ilya Mironov. Renyi Differential Privacy. CSF 2017."><strong>[M17]</strong></a> <a href="https://arxiv.org/abs/1905.02383" title="Jinshuo Dong, Aaron Roth, Weijie Su. Gaussian Differential Privacy. Journal of the Royal Statistical Society: Series B. 2020"><strong>[DRS19]</strong></a> On the positive side, these papers analyze how differential privacy composes, yielding sharp quantitative bounds.</li>
</ul>

<hr />

<div class="footnotes">
  <ol>
    <li id="fn:1">
      <p>A good rule of thumb is that, if the number of released values is much larger than the number of people, then a privacy attack is probably possible. This is analogous to the rule from algebra that, if the number of constraints (released values) is greater than the number of unknown variables (people’s data), then the unknowns can be worked out. <a href="https://differentialprivacy.org/feed.xml#fnref:1" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:2">
      <p>Exactly quantifying how much noise is needed as the number of questions grows leads to the concept of a “privacy budget.” That is, we must precisely quantify how differential privacy degrades under composition. This is a very deep topic and is something we hope to discuss in future posts. <a href="https://differentialprivacy.org/feed.xml#fnref:2" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:3">
      <p>The queries do not need to be random <strong><a href="https://iacr.org/archive/crypto2008/51570469/51570469.pdf" title="Cynthia Dwork, Sergey Yekhanin. New Efficient Attacks on Statistical Disclosure Control Mechanisms. CRYPTO 2008">[DY08]</a></strong>. The queries simply need to be “sufficiently distinct”, which can be formulated precisely as being nearly orthogonal vectors. Random, or even pseudorandom queries (e.g., hash functions), will almost certainly satisfy this property. In general, it is fairly likely that a set of queries will have this property and allow a reconstruction attack; that is, it is hard to <em>avoid</em> this phenomenon. <a href="https://differentialprivacy.org/feed.xml#fnref:3" class="reversefootnote">↩</a></p>
    </li>
    <li id="fn:4">
      <p>This representation of the dataset as a vector of bits \(x \in \{-1,+1\}^n \) is an abstraction. The entries in the dataset would actually be something like a set of pairs \( ( u_i, x_i ) \) for \(i = 1, \cdots, n \), where \(u_i\) is various information that identifies the individual concerned (name, address, race, date of birth, etc.). <a href="https://differentialprivacy.org/feed.xml#fnref:4" class="reversefootnote">↩</a></p>
    </li>
  </ol>
</div></div>







<p class="date">
by Jonathan Ullman <a href="https://differentialprivacy.org/privacy-composition/"><span class="datestr">at August 16, 2020 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/08/15/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/08/15/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p>Two sites on toroidal polyhedra: <a href="https://www.spektrum.de/alias/raeumliche-geometrie/bonnie-stewarts-hohlkoerper/681891">Bonnie Stewarts Hohlkörper</a> and <a href="http://polyhedra.doskey.com/Stewart00.html">Alex Doskey’s virtual reality models of Stewart’s polyhedra</a> (<a href="https://mathstodon.xyz/@11011110/104618649607830730">\(\mathbb{M}\)</a>). Found while researching a new WP article on Stewart’s book <em><a href="https://en.wikipedia.org/wiki/Adventures_Among_the_Toroids">Adventures Among the Toroids</a></em>. The first link is in German but readable through Google translate and has lots of pretty pictures. The second needs VR software to be usable.</p>
  </li>
  <li>
    <p><a href="https://www.robertdickau.com/mapfolding.html">The map folding problem, illustrated by Robert Dickau</a> (<a href="https://mathstodon.xyz/@11011110/104630030819531499">\(\mathbb{M}\)</a>). See <a href="https://www.robertdickau.com/default.html#math">Dickau’s home page</a> for many more mathematical illustrations, mostly of combinatorial enumeration problems and fractals.</p>
  </li>
  <li>
    <p>For some reason I wanted the name of a surface of revolution of a circular arc less than \(\pi\) around its chord (<a href="https://mathstodon.xyz/@11011110/104635297508909080">\(\mathbb{M}\)</a>). <a href="https://en.wikipedia.org/wiki/Lemon_(geometry)">Wikipedia said “lemon”</a> but sourced to MathWorld so I thought maybe MathWorld had made it up. Not so. Better sources say the same. And the surface for the complementary arc is an “apple”. It looks like a North American football but <a href="http://modellsammlung.uni-goettingen.de/index.php?lang=en&amp;r=5&amp;sr=17&amp;m=182">a “football” is a different surface of revolution, of constant positive Gaussian curvature</a>.</p>
  </li>
  <li>
    <p><a href="https://link.springer.com/journal/454/64/2">Special issue of <em>Discrete &amp; Computational Geometry</em> in memory of Branko Grünbaum</a> (<a href="https://mathstodon.xyz/@11011110/104643955543481823">\(\mathbb{M}\)</a>). I think many of the research papers in it are interesting but I want to draw particular attention to <a href="https://link.springer.com/article/10.1007/s00454-020-00214-y">the preface by Gil Kalai, Bojan Mohar, and Isabella Novik</a>, which provides a nice brief survey both of Grünbaum’s many contributions to discrete geometry and of the lines of active research they have led to.</p>
  </li>
  <li>
    <p><a href="http://gallery.bridgesmathart.org/exhibitions/2020-Bridges-Conference">2020 Bridges Conference Mathematical Art Gallery</a> (<a href="https://mathstodon.xyz/@11011110/104646771923669610">\(\mathbb{M}\)</a>). Many are great but a couple of my favorites are <a href="http://gallery.bridgesmathart.org/exhibitions/2020-bridges-conference/conan-chadbourne">Conan Chadbourne’s grid partition enumeration</a> and <a href="http://gallery.bridgesmathart.org/exhibitions/2020-bridges-conference/mdlevin_publicmsncom">Martin Levin’s ten-tetrahedron tensegrity</a>. I didn’t participate but apparently the Bridges conference itself was held virtually a few days ago; see <a href="https://2020.bridgesmathart.org/">the conference site</a> for more including papers and videos.</p>
  </li>
  <li>
    <p><a href="https://felixboiii.github.io/paper-plotter/">Paper plotter</a> (<a href="https://mathstodon.xyz/@11011110/104655233453519187">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24091297">via</a>): tool to make 3d paper cut-and-assemble models of the graphs of bivariate functions.</p>
  </li>
  <li>
    <p>Kowhaiwhai (<a href="https://mathstodon.xyz/@11011110/104663925881930344">\(\mathbb{M}\)</a>).  are repeating decorative patterns used in New Zealand on Maori buildings. <a href="https://natlib.govt.nz/photos?text=kowhaiwhai&amp;commit=Search">The National Library of NZ has a number of good examples</a>, including the <a href="https://natlib.govt.nz/records/23146518">sketches of patterns by Tamati Ngakoho (top) and of a traditional Arawa pattern (bottom)</a> shown below. There’s also <a href="http://www.maori.org.nz/whakairo/default.php?pid=sp55&amp;parent=52">a brief guide to their interpretation online</a>. I can’t find much analysis of their structure, though, beyond pointing to frieze groups for their symmetries. The part that interests me more is their fractal-like swooping structure, reminiscent of (and in some cases directly modeled on) fern fronds.</p>
  </li>
</ul>

<p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/Kowhaiwhai.jpg" alt="Godber, Albert Percy, 1875-1949. Godber, Albert Percy, 1876-1949. Drawings of Maori rafter patterns or kowhaiwhai. 16. 22W. MA22; 17. 21W. MA21; and, 18. 25W. MA25. Puhoro. [1939-1947]. Ref: E-302-q-1-016/018. Alexander Turnbull Library, Wellington, New Zealand. From https://natlib.govt.nz/records/23146518" /></p>

<ul>
  <li>
    <p><a href="https://www.wired.com/story/why-wikipedia-decided-to-stop-calling-fox-a-reliable-source/">Why Wikipedia decided to stop calling Fox a reliable source</a> (<a href="https://mathstodon.xyz/@11011110/104666160845673755">\(\mathbb{M}\)</a>). Note however that Fox has not actually been deemed unreliable, in general. <a href="https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources/Noticeboard/Archive_303#RfC:_Fox_News">The discussion had a no-consensus close</a>.</p>
  </li>
  <li>
    <p><a href="https://sinews.siam.org/Details-Page/untangling-random-polygons-and-other-things">Untangling random polygons</a> (<a href="https://mathstodon.xyz/@11011110/104677553383067578">\(\mathbb{M}\)</a>): repeatedly rescaling midpoint polygons always leads to an ellipse.</p>
  </li>
  <li>
    <p><a href="https://www.atlasobscura.com/articles/kek-lapis-sarawak">The mesmerizing geometry of Malaysia’s most complex cakes:
Bold colors and designs set kek lapis Sarawak apart</a> (<a href="https://mathstodon.xyz/@11011110/104680812259935603">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=24116775">via</a>). As seen on The Great British Bake Off. These cakes have many parallel layers in bright colors, cut and rearranged to form complex designs. Mostly they involve 45 and 90-degree angles but at least one of the examples uses hexagonal symmetry instead.</p>
  </li>
  <li>
    <p>My Google Scholar profile has mildly broken down (<a href="https://mathstodon.xyz/@11011110/104683176033821672">\(\mathbb{M}\)</a>). When I go there, it offers me two new profiles to link as my coauthors: Man-Kwun Chiu and Matí Korman. They are indeed coauthors, from my new CCCG papers. But when I click to accept them as listed coauthors, it tells me I have too many coauthors, refuses to add them, and returns to offering me new profiles to link. I can see no way out of this other than to not accept my coauthors, which would be wrong. Google, fix this limitation!</p>
  </li>
  <li>
    <p>A use for old CDs: <a href="https://momath.org/home/math-monday-those-circles-are-great/">cut them up and glue the pieces together to make visualizations of great circle arrangements on the sphere</a> (<a href="https://mathstodon.xyz/@11011110/104690896919723051">\(\mathbb{M}\)</a>). The mathematical question posed by this is: for which numbers of great circles is it possible to make an arrangement in which all the arcs between pairs of neighbors have equal lengths?</p>
  </li>
  <li>
    <p><a href="https://thonyc.wordpress.com/">The Renaissance Mathematicus</a> (<a href="https://mathstodon.xyz/@pkra/104694183591138626">\(\mathbb{M}\)</a>), an interesting blogger on the history of science. See also the <a href="https://thonyc.wordpress.com/2020/08/15/keep-the-renaissance-mathematicus-online/">crowdfunding drive to replace their old creaky iMac</a>, from which I found this.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/08/15/linkage.html"><span class="datestr">at August 15, 2020 05:02 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=20069">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/">To cheer you up in difficult times 9: Alexey Pokrovskiy proved that Rota’s Basis Conjecture holds asymptotically</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<h2><a href="https://gilkalai.files.wordpress.com/2020/08/alexeypokrovskiy.jpg"><img width="209" alt="" src="https://gilkalai.files.wordpress.com/2020/08/alexeypokrovskiy.jpg?w=209&amp;h=300" class="alignnone size-medium wp-image-20075" height="300" /></a></h2>
<h2>Pokrovskiy’s startling morning  <strong><span style="color: #ff0000;">r</span><span style="color: #0000ff;">ai</span><span style="color: #ff6600;">n</span><span style="color: #ff9900;">b</span><span style="color: #ff00ff;">o</span><span style="color: #800080;">w</span></strong></h2>
<p><a href="https://arxiv.org/abs/2008.06045">Rota’s Basis Conjecture holds asymptotically</a>, by Alexey <span style="color: #000000;">Pokrovskiy</span></p>
<p><strong>Abstract:</strong> Rota’s Basis Conjecture is a well known problem from matroid theory, that states that for any collection of n bases in a rank n matroid, it is possible to decompose all the elements into n disjoint rainbow bases. Here an asymptotic version of this is proved. We show that it is possible to find <em>n − o(n)</em> disjoint rainbow independent sets of size <em>n − o(n)</em>.</p>
<p>A <strong><span style="color: #ff0000;">r</span><span style="color: #0000ff;">ai</span><span style="color: #ff6600;">n</span><span style="color: #ff9900;">b</span><span style="color: #ff00ff;">o</span><span style="color: #800080;">w </span></strong><span style="color: #800080;"><span style="color: #000000;">basis is a basis with one element from each collection.</span></span></p>
<p>(I thank Nati Linial for telling me about it.)</p>
<p>Another way to formulate Rota’s basis conjecture (for representable matroids) is that if <em>B</em><sub>1</sub>, <em>B</em><sub>2</sub>, …, <em>B<sub>n</sub></em> are <em>n</em> bases of an <em>n</em>-dimensional vector space <em>V</em> (not necessarily distinct or disjoint), then there exists an <em>n</em> × <em>n</em> grid of vectors (<em>v<sub>ij</sub></em>) such that</p>
<p>1. the <em>n</em> vectors in row <em>i</em> are the members of the <em>i</em>th basis <em>B<sub>i</sub></em> (in some order), and</p>
<p>2. in each column of the matrix, the <em>n</em> vectors in that column form a basis of <em>V</em>.</p>
<p>If all the bases are the standard basis then this reduces to the existence of <a href="https://en.wikipedia.org/wiki/Latin_square">Latin squares</a>.</p>
<p><strong>Unrelated trivia question:</strong>  AGC-GTC-TGC-GTC-TGC-GAC-GATC-? what comes next in the sequence?</p>
<p>We mentioned Rota’s basis conjecture in various earlier posts.  A classic paper on the subject is the <a href="https://gilkalai.files.wordpress.com/2017/02/huang-rota.pdf">1989 paper by Rosa Huang and Gian Carlo-Rota</a>. Three and a half years ago Timothy Chow lunched a polymath project (Polymath 12) to solve it. (Here is my<a href="https://gilkalai.wordpress.com/2017/02/26/timothy-chow-launched-polymath12-on-rota-basis-conjecture-and-other-news/"> post on the project with various variants of the conjecture</a>, the <a href="https://polymathprojects.org/2017/02/23/rotas-basis-conjecture-polymath-12/">first post on the polymath blog</a>, and the <a href="https://asone.ai/polymath/index.php?title=Rota%27s_conjecture">wiki</a>). See <a href="https://gilkalai.wordpress.com/2014/08/08/jim-geelen-bert-gerards-and-geo%ef%ac%80-whittle-solved-rotas-conjecture-on-matroids/">this post</a> for several famous conjectures by Rota, and this post about the related <a href="https://gilkalai.wordpress.com/2017/03/15/test-your-intuition-about-the-alon-tarsi-conjecture/">Alon-Tarsi conjecture</a>.</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/08/14/to-cheer-you-up-in-difficult-times-9-alexey-pokrovskiy-proved-that-rotas-basis-conjecture-holds-asymptotically/"><span class="datestr">at August 14, 2020 10:09 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=17416">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/08/13/thanks-to-an-explainer/">Thanks to An Explainer</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Conrad explains all</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.wordpress.com/thanks-to-an-explainer/keithconrad/" rel="attachment wp-att-17410"><img src="https://rjlipton.files.wordpress.com/2020/08/keithconrad.jpg?w=600" alt="" class="aligncenter size-full wp-image-17410" /></a>
</td>
</tr>
<tr>
</tr>
</tbody>
</table>
<p>
Keith Conrad is a professor in the mathematics department at UCONN—the University of Connecticut. My dear wife Kathryn Farley and I are about to move to join him—not as faculty but as another resident of the “Constitution State.”</p>
<p>
Today we thank him for his work on explaining mathematics.</p>
<p>
Conrad is a prolific writer of articles on mathematics. He makes hard concepts clear, he makes easy concepts interesting. He has a sense of humor; his <a href="https://kconrad.math.uconn.edu">website</a> is filled with fun of all kinds.</p>
<p>
He has interesting license plates, photos of streets that bear his first name, a Russian <a href="https://kconrad.math.uconn.edu/">update</a> to Tom Lehrer’s “Elements” song, and more links to others’ items. </p>
<p>
If you’d like a video example of fun see <a href="http://i.stack.imgur.com/d2OKd.gif">this</a> for a short video illusion. Too bad it is an illusion and it does not work in reality. As a chocolate lover I wish it worked—free chocolate forever. A similar <a href="https://en.wikipedia.org/wiki/Missing_square_puzzle">illusion</a> with a triangle was once featured by Martin Gardner, leading Ken as a teenager to make a cardboard cutout version overlaid on a map of the Bermuda Triangle as an “explanation” of disappearances there.</p>
<p>
</p><p></p><h2> Articles </h2><p></p>
<p></p><p>
I have not yet met Conrad in person, but have enjoyed reading his articles on math of all kinds. He has a giant <img src="https://s0.wp.com/latex.php?latex=%7B63+%5Ctimes+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{63 \times 4}" class="latex" title="{63 \times 4}" /> <a href="https://kconrad.math.uconn.edu/blurbs/">grid</a> of clickable titles, grouped by subject area. </p>
<p>
For an example, he has a <a href="https://kconrad.math.uconn.edu/blurbs/galoistheory/numbersoncircle.pdf">title</a> “Roots on a Circle.” The file name says “numbers on a circle” and the essay begins disarmingly enough with a picture of the 7th roots of unity. The next page shows a simple polynomial where most but not all roots lie on the circle:</p>
<p><a href="https://rjlipton.wordpress.com/thanks-to-an-explainer/lehmerspolynomialroots/" rel="attachment wp-att-17412"><img width="300" alt="" src="https://rjlipton.files.wordpress.com/2020/08/lehmerspolynomialroots.jpg?w=300&amp;h=161" class="aligncenter size-medium wp-image-17412" height="161" /></a></p>
<p>
This is enough to draw you in and stay attached as things become more complicated beginning on page 3. It helps that Conrad does not stint on algebraic details. This essay supplements a cautionary tale in mathematics: a <a href="https://mathoverflow.net/questions/15444/examples-of-eventual-counterexamples">link</a> to a MathOverflow list whose top item is that the factors of <img src="https://s0.wp.com/latex.php?latex=%7Bx%5En+-+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x^n - 1}" class="latex" title="{x^n - 1}" /> over <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BQ%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathbb{Q}}" class="latex" title="{\mathbb{Q}}" /> have no coefficient of absolute value greater than <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+1%2C%5Cdots%2C104%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 1,\dots,104}" class="latex" title="{n = 1,\dots,104}" />. Before you try to prove this by induction check out <img src="https://s0.wp.com/latex.php?latex=%7Bn+%3D+105%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n = 105}" class="latex" title="{n = 105}" />.</p>
<p>
</p><p></p><h2> Finite Groups </h2><p></p>
<p></p><p>
One of my favorite articles is <a href="https://kconrad.math.uconn.edu/blurbs/grouptheory/order.pdf">titled</a>, “Orders Of Elements In A Group.” Conrad starts with the humble concept of the order of an element in a group. Then he builds up a theory that explains various properties of order. </p>
<p>
I especially like that he supplies examples to help you with your intuition. For me, and Ken, finite groups are just counter-intuitive. Groups have magical properties but my naive conjectures about them usually fail. Conrad’s article ends with a discussion of primality testing which is dear to us in complexity theory.</p>
<p>
</p><p></p><h2> Finite Groups that Encode Information </h2><p></p>
<p></p><p>
I recently needed a finite group with a certain structure. In complexity theory we sometimes use matrices to encode information in a way that makes an algorithm more efficient. Algorithms like matrices since they can be stored and multiplied efficiently. As an example, suupose that we have two matrices <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> so that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++AB+%3D+-BA.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  AB = -BA. " class="latex" title="\displaystyle  AB = -BA. " /></p>
<p>That is the matrices anti-commute. Then we can use such matrices to encode information about a string <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> of <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A,B}" class="latex" title="{A,B}" />‘s. Every string <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" /> can be written as: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cpm+A%5E%7Bk%7DB%5E%7Bl%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \pm A^{k}B^{l}. " class="latex" title="\displaystyle  \pm A^{k}B^{l}. " /></p>
<p>The <img src="https://s0.wp.com/latex.php?latex=%7B%5Cpm%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\pm}" class="latex" title="{\pm}" /> encodes the number of inversions in the string <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S}" class="latex" title="{S}" />. That is the number of times <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> is followed by an <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cdots+B+%5Cdots+A+%5Cdots+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \dots B \dots A \dots " class="latex" title="\displaystyle  \dots B \dots A \dots " /></p>
<p>So <img src="https://s0.wp.com/latex.php?latex=%7BABBA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{ABBA}" class="latex" title="{ABBA}" /> has <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" /> inversions, and <img src="https://s0.wp.com/latex.php?latex=%7BAAABA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{AAABA}" class="latex" title="{AAABA}" /> has <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. Here are matrices that <a href="https://en.wikipedia.org/wiki/Generalized_Clifford_algebra">anti-commute</a>. </p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A+%3D+%5Cbegin%7Bpmatrix%7D+0%261%5C%5C+1%260+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  A = \begin{pmatrix} 0&amp;1\\ 1&amp;0 \end{pmatrix}" class="latex" title="\displaystyle  A = \begin{pmatrix} 0&amp;1\\ 1&amp;0 \end{pmatrix}" /></p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++B+%3D+%5Cbegin%7Bpmatrix%7D+1%260%5C%5C+0%26-1+%5Cend%7Bpmatrix%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  B = \begin{pmatrix} 1&amp;0\\ 0&amp;-1 \end{pmatrix}" class="latex" title="\displaystyle  B = \begin{pmatrix} 1&amp;0\\ 0&amp;-1 \end{pmatrix}" /></p>
<p>
We can do even better. There are matrices so that 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++AB+%3D+%5Clambda+BA%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  AB = \lambda BA, " class="latex" title="\displaystyle  AB = \lambda BA, " /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> is a root of unity. They exist as the example below shows for fourth roots of unity. But finding such matrices was curiously hard, at least for me. Lots of web searching.</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A+%3D+%5Cbegin%7Bpmatrix%7D+0%261%260%260%5C%5C+0%260%261%260%5C%5C+0%260%260%261%5C%5C+1%260%260%260+%5Cend%7Bpmatrix%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  A = \begin{pmatrix} 0&amp;1&amp;0&amp;0\\ 0&amp;0&amp;1&amp;0\\ 0&amp;0&amp;0&amp;1\\ 1&amp;0&amp;0&amp;0 \end{pmatrix} " class="latex" title="\displaystyle  A = \begin{pmatrix} 0&amp;1&amp;0&amp;0\\ 0&amp;0&amp;1&amp;0\\ 0&amp;0&amp;0&amp;1\\ 1&amp;0&amp;0&amp;0 \end{pmatrix} " /></p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++B+%3D+%5Cbegin%7Bpmatrix%7D+1%260%260%260%5C%5C+0%26i%260%260%5C%5C+0%260%26-1%260%5C%5C+0%260%260%26-i+%5Cend%7Bpmatrix%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  B = \begin{pmatrix} 1&amp;0&amp;0&amp;0\\ 0&amp;i&amp;0&amp;0\\ 0&amp;0&amp;-1&amp;0\\ 0&amp;0&amp;0&amp;-i \end{pmatrix} " class="latex" title="\displaystyle  B = \begin{pmatrix} 1&amp;0&amp;0&amp;0\\ 0&amp;i&amp;0&amp;0\\ 0&amp;0&amp;-1&amp;0\\ 0&amp;0&amp;0&amp;-i \end{pmatrix} " /></p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Conrad’s articles are helpful. In a wide variety of topics he presents both theorems and history of math concepts. What I find most attractive is the examples and additional comments that pepper his writing. </p>
<p>
Check him out.</p></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/08/13/thanks-to-an-explainer/"><span class="datestr">at August 13, 2020 06:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-27705661.post-5601291488610843158">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aceto.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://processalgebra.blogspot.com/2020/08/an-interview-with-jos-baeten-outgoing.html">An interview with Jos Baeten, outgoing director of the CWI</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>After nine years, <a href="https://www.cwi.nl/people/jos-baeten" target="_blank">Jos Baeten</a> will step down as general director of <a href="https://www.cwi.nl/" target="_blank">CWI</a> on 30 September 2020 and there will be a <a href="https://www.cwi.nl/events/2020/farewell-symposium-jos-baeten/symposium-retirement-jos-baeten" target="_blank">retirement symposium</a> in his honour on 1 October 2020. (Jos Baeten's successor will be <a href="https://www.tue.nl/en/research/researchers/ton-de-kok/" target="_blank">Tom de Kok</a>. You can read the CWI news item related to Tom de Kok's appointment <a href="https://www.cwi.nl/news/2020/ton-de-kok-appointed-new-director-of-cwi" target="_blank">here</a>. Tom de Kok, just like Jos Baeten before him, joins CWI from Eindhoven University of Technology.) </p><p>Jos Baeten has been one of the prime movers in the development of process algebra since 1987, and has been the driving force behind the CONCUR conference series and the CONCUR Basic Research Actions in the late 1980s and the early 1990s. Apart from being general director of CWI, he has served the TCS community in a variety of roles and organisations, and has helped to connect the work of the concurrency-theory community with that done in control and mechanical engineering. He has also supervised more than 30 PhD theses. </p><p>I asked Jos a few questions via email and I am happy to share his answers with the readers of this blog. Thanks to Jos for all the contributions he has given to the research community throughout his career, and for sharing his opinions and reminiscences with us! </p><p><b>The interview</b> </p><p><b>Luca:</b> Let's start from the beginning. If I remember correctly, your background was in model theory. Could you tell us what prompted you to move to doing research in computer science? </p><p><b>Jos:</b> I have a Master in logic and foundations of mathematics (with a minor in philosophy) from Utrecht University, with a Master’s thesis on lambda calculus, and a PhD in logic and foundations of mathematics from the University of Minnesota, with a PhD thesis on definability theory (a cross between recursion theory and set theory) entitled "<a href="https://link.springer.com/chapter/10.1007/BFb0099378" target="_blank">Filters and ultrafilters over definable subsets of admissible ordinals</a>". Returning from the US, I got a job teaching undergraduate maths at Delft University. But I wanted getting into research, and meeting <a href="https://staff.fnwi.uva.nl/j.a.bergstra/" target="_blank">Jan Bergstra</a> he said there were lots of opportunities in computer science research, not in maths. Writing a paper with him and <a href="https://www.cs.vu.nl/~jwk/" target="_blank">Jan Willem Klop</a> on term rewriting systems would qualify me, he said. So it happened, and I got a postdoc at CWI in the framework of the ESPRIT I project. I kept on doing maths, but it was called computer science. </p><p><b>Luca:</b> I have heard that you were recruited by Jan Bergstra and Jan Willem Klop to work within their group at the CWI, and that <a href="http://theory.stanford.edu/~rvg/" target="_blank">Rob van Glabbeek</a> joined the team soon after you. Could you tell us about the environment at the CWI at that time? It must have been a very exciting place to be with all the activity related to work on <a href="https://en.wikipedia.org/wiki/Algebra_of_communicating_processes#:~:text=The%20algebra%20of%20communicating%20processes,process%20algebras%20or%20process%20calculi." target="_blank">ACP</a> and related topics. </p><p><b>Jos:</b> It was a heady period. The group of Jan and Jan Willem was expanding rapidly on EU money, with me, Rob van Glabbeek and <a href="http://www.cs.ru.nl/~fvaan/" target="_blank">Frits Vaandrager.</a> I really liked ACP and doing universal algebra. </p><p><b>Luca:</b> What was your first paper in CS about? Which paper from your initial period at the CWI are you most proud of? </p><p><b>Jos:</b> My first paper was "<a href="https://www.researchgate.net/publication/225810594_Term_rewriting_systems_with_priorities" target="_blank">On term rewriting, Term rewriting systems with priorities</a>". I am most proud of my first ACP paper, "<a href="https://pure.tue.nl/ws/files/2137499/335911.pdf" target="_blank">Syntax and defining equations for an interrupt mechanism in process algebra</a>". This is about adding the priority operator. For axiomatisation, it needed an auxiliary operator that later turned out to be almost optimal. I came up with an axiomatisation, and Jan Bergstra forced me to prove it correct by doing all the critical pairs. I found a small error in pair 101 (of the 102 pairs), corrected it and proved the result correct. This all in a couple of weeks. </p><p><b>Luca:</b> Let's move on to the CONCUR project: How did it come about and what was its legacy? I recall that you came to visit <a href="https://www.scss.tcd.ie/Matthew.Hennessy/" target="_blank">Matthew Hennessy</a> at the University of Sussex when I was a PhD student there to discuss the CONCUR proposal. How did you become involved in leading such a large and high profile group of researchers so early in your career at the CWI? What was it like to lead the CONCUR project?  <br /></p><p><b>Jos:</b> This is again due to Jan Bergstra: he believes in delegating responsibilities quickly. When the new instrument of Basic Research Action came up in the EU, he wanted a BRA with <a href="https://en.wikipedia.org/wiki/Tony_Hoare" target="_blank">Hoare</a>, <a href="https://en.wikipedia.org/wiki/Robin_Milner" target="_blank">Milner </a>and Hennessy. I got the assignment and made a trip to the UK visiting all three, and got all of them on board. The idea of the project was unification, but that did not come about, everyone kept doing their own thing. We did, however, produce excellent papers, including the curious </p><p>J.C.M. Baeten, J.A. Bergstra, C.A.R. Hoare, R. Milner, J. Parrow &amp; R. de Simone, The variety of process algebra. Deliverable ESPRIT Basic Research Action 3006, CONCUR, University of Edinburgh 1991 </p><p><b>Luca:</b> How would you summarize the history of the conference CONCUR? Can it be split into different periods, and if so, what characterizes them? </p><p><b>Jos:</b> CONCUR 90, which was the first CONCUR conference, was organised by BRA CONCUR, but with speakers from all 5 BRA’s in the area of concurrency; in 1991 Milner did not want such a conference to occur in Edinburgh, so Jan Bergstra and I did it again in Amsterdam. Then, we involved <a href="https://www.cs.stonybrook.edu/people/faculty/ScottSmolka" target="_blank">Scott Smolka</a> for 1992 and after that, it was established, with a steering committee comprised of representatives from the 5 BRAs and Scott. As of 1993, it was firmly established, we found a niche and time period (end of August, beginning of September). All branches of concurrency were involved from the start, and over the years, it shows fashion clearly, for instance in certain years there was a lot of <a href="https://en.wikipedia.org/wiki/%CE%A0-calculus" target="_blank">pi-calculus</a>. </p><p><b>Luca:</b> In the 80s and the 90s there were three "schools" in process algebra,     the ACP, CCS, and CSP schools. With the benefit of hindsight, which were heir main contributions? To which extent have they converged? Is this classification still important for current research? </p><p><b>Jos:</b> I refer to my paper  <br /></p><p>J.C.M. Baeten, <a href="https://pure.tue.nl/ws/files/2154050/200402.pdf" target="_blank">A brief history of process algebra</a>. Theoretical Computer Science 335 (2/3), 2005, pp. 131-146.  <br /></p><p>I do a comparison in there. In my opinion, the book  <br /></p><p>J.C.M. Baeten, T. Basten and M.A. Reniers, <a href="https://www.cambridge.org/core/books/process-algebra-equational-theories-of-communicating-processes/0A091BDAA17DA4D3D30FCD6F52E0E6B8" target="_blank">Process Algebra: Equational Theories for Communicating Processes</a>. Cambridge Tract in Theoretical Computer Science 50, Cambridge University Press 2010  <br /></p><p>has the unification, presenting all three in the same framework. However, process algebra is out of fashion, so who cares? </p><p><b>Luca:</b>  When did you become interested in supervisory control? What motivated you to apply techniques from process algebra in that research field? Looking at the outcome of that work, both in theory and in practice, that was a very good move! Could you tell us about the position you had in Mechanical Engineering? How did it come about and what was it like to work in that department? </p><p><b>Jos:</b> More than 20 years in the department of computer science, having been dean twice, I got to know the university very well indeed. <a href="https://research.tue.nl/en/persons/je-koos-rooda" target="_blank">Koos Rooda</a>, professor of systems engineering at Mechanical Engineering, requested my assistance to get more software engineering into systems engineering, to replace his cooperation with Martin Rem, who became rector. In particular, he was interested in the combination of discrete event reasoning (i.e., process algebra) with the continuous mathematics of systems and control. Having done process algebra with timing and probabilities, I was willing to take up this challenge. Upon his retirement, with the vigorous backing of the dean of Mechanical Engineering at the time, I took over his position. At mid-life, I was ready for a change. I liked the hands-on attitude of mechanical engineering students, who are no good at theory or proofs, but are very good in using mathematics and trying out software tools. But then, I was asked to apply to the vacancy of director of CWI. This was the job I had always wanted. I had enjoyed being dean and doing research management, and CWI is a very prestigious institute with (at that time) very independent management. </p><p> </p><p><b>Luca:</b> Back at CWI: What skills do you think one needs to be the director of such a high-profile institute? What was your vision for the CWI and how much of it did you manage to achieve? What role do you think the CWI can/should have in the coming decade and beyond? </p><p><b>Jos:</b> The most important skill is hiring those early career scientists that grow out to become top scientists. Internally, you have to manage your key personnel, operating by consensus and compromise. Externally, you have to find your way in national science politics and always justify your existence. The growing tension between Dutch universities and Dutch extra-university research institutes has almost defeated me, but I managed to complete my term until retirement, and leave CWI in good shape, to my opinion. I managed to keep the excellent reputation of the institute, and also managed to bring in dynamics, rejuvenation and new subjects. What I did not achieve, is that CWI again becomes a publisher, and publishes diamond journals. </p><p><b>Luca:</b> You have played a role in organizations such as the EATCS, ERCIM and IFIP. Do you think that such societies still play a role today? How do think they should evolve to fulfill their mission? </p><p><b>Jos:</b> I do, but they have to keep evolving if they want to stay relevant. It is a pity that the EATCS could not take a role in the open access movement (you certainly made a very good effort!). I think ERCIM is doing ok, but not great. IFIP, I think, has become irrelevant. </p><p><b>Luca:</b> You have been a strong supporter of open access. What is your opinion of the state of play in open access and what do you think we could do to move forward? </p><p><b>Jos:</b> Progress is slow but exists. I am a strong advocate of Plan S, that has really set some things in motion. A key point is that it looks like we can achieve immediate green, and still allow all researchers to submit articles wherever they want. I do not like the way it is going with transformative agreements, you'd think that by now, publishers would be putting all their efforts to become sellers of data analytics services.</p><p><b>Acknowledgements:</b> I thank <a href="https://www7.in.tum.de/~esparza/" target="_blank">Javier Esparza</a>, the chair of the CONCUR Steering Committee, for contributing some the questions to Jos.  <br /></p></div>







<p class="date">
by Luca Aceto (noreply@blogger.com) <a href="http://processalgebra.blogspot.com/2020/08/an-interview-with-jos-baeten-outgoing.html"><span class="datestr">at August 13, 2020 05:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-6597301440817356598">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/08/simons-institute-gets-another-decade.html">Simons Institute Gets Another Decade</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p> <a href="https://simons.berkeley.edu/news/simons-foundation-announces-new-355-million-grant-simons-institute-theory-computing-press">Great news</a> out of the Simons Institute.</p><blockquote><p>The Simons Foundation has ensured a second decade of research and innovation for the Simons Institute for the Theory of Computing, based at UC Berkeley, through a $35.5 million grant. The grant, which will begin in 2022, after the conclusion of the Simons Institute's first 10 years, will support the Simons Institute's mission and activities through June 2032.</p></blockquote><p>Congrats to Shafi Goldwasser and her team and of course a special thanks to Jim Simons and his foundation for their support for the theory community. </p><p>Time flies. I remember when I was on Team Chicago in the final rounds back in 2011. We lost but the theory community won as Berkeley did the institute well with amazing collaborative spaces, thanks mainly I hear from Alistair Sinclair, and the strong programs and workshops organized by the many volunteers across the theory community. </p><p>The institute started right when I started as a department chair so I never had the opportunity for the true Simons experience, joining for a semester-long program. When I did sneak away for a week at Simons I purposely avoided the workshops for Simons is at its best when strong researchers, connected by one of the programs, just talk, work and socialize together. I joined an amazing collection of complexity theorists to form a rather mediocre pub trivia team.</p><p>Even if you never make it there, the institute has a great <a href="https://www.youtube.com/user/SimonsInstitute">collection of videos</a> of its workshops, talks and celebrations. COVID-19 has driven Simons on-line but that just opens up their <a href="https://simons.berkeley.edu/workshops">workshops</a> and other events to a wider audience.</p><p>Congrats again to the Simons Institute for what it's given to the theory community and to its next dozen years with hopefully many more to follow!</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/08/simons-institute-gets-another-decade.html"><span class="datestr">at August 13, 2020 02:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
