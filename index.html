<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" class="message" title="internal server error">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" class="message" title="internal server error">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" class="message" title="internal server error">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" class="message" title="internal server error">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" class="message" title="internal server error">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://differentialprivacy.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://differentialprivacy.org" title="Differential Privacy">DifferentialPrivacy.org</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" class="message" title="internal server error">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" class="message" title="internal server error">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" class="message" title="internal server error">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" class="message" title="internal server error">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="https://blogs.oregonstate.edu:443/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" class="message" title="internal server error">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" class="message" title="internal server error">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="403: forbidden">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" class="message" title="internal server error">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" class="message" title="internal server error">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" class="message" title="internal server error">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" class="message" title="internal server error">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="https://toc4fairness.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://toc4fairness.org" title="TOC for Fairness">TOC for Fairness</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" class="message" title="internal server error">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" class="message" title="internal server error">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="internal server error">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" class="message" title="internal server error">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at March 09, 2021 01:42 PM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/034">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/034">TR21-034 |  Robust Self-Ordering versus Local Self-Ordering | 

	Oded Goldreich</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study two notions that refers to asymmetric graphs, which we view as graphs having a unique ordering that can be reconstructed by looking at an unlabeled version of the graph.

A {\em local self-ordering} procedure for a graph $G$ is given oracle access to an arbitrary isomorphic copy of $G$, denoted $G'$, and a vertex $v$ in $G'$, and is required to identify the name (or location) of $v$ in $G$, while making few (i.e., polylogarithmically many) queries to $G'$.
A graph $G=(V,E)$ is {\em robustly self-ordered} if the size of the symmetric difference between $E$ and the edge-set of the graph obtained by permuting $V$ using any permutation $\pi:V\to V$ is proportional to the number of non-fixed-points of $\pi$ and to the maximal degree of $G$; that is, any permutation of the vertices that displaces $t$ vertices must ``displace'' $\Omega(t\cdot d)$ edges, where $d$ is the maximal degree of the graph. 

We consider the relation between these two notions in two regimes: The bounded-degree graph regime, where oracle access to a graph means oracle access to its incidence function, and the dense graph regime, where oracle access to the graph means access to its adjacency predicate. 

We show that, {\em in the bounded-degree regime}, robustly self-ordering and local self-ordering are almost orthogonal; that is, even extremely strong versions of one notion do not imply very weak versions of the other notion. 
Specifically, we present very efficient local self-ordering procedures for graphs that possess derangements that are almost automorphisms (i.e., a single incidence is violated).  
One the other hand, we show robustly self-ordered graphs having no local self-ordering procedures even when allowing a number of queries that is a square root of the graph's size. 

{\em In the dense graph regime}, local self-ordering procedures are shown to yield a quantitatively weaker version of the robust self-ordering condition, in which the said proportion is off by a factor that is related to the query complexity of the local self-ordering procedure. Furthermore, we show that this quantitatively loss is inherent.
On the other hand, we show how to transform any robustly self-ordered graph 
into one having a local self-ordering procedure, while preserving the robustness condition. Combined with prior work, this yields explicit constructions of graphs that are both robustly and locally self-ordered, and an application to property testing.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/034"><span class="datestr">at March 09, 2021 09:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/03/08/more-mathematics-books">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/03/08/more-mathematics-books.html">More mathematics books by women</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>A year ago, for International Women’s Day, I made <a href="https://11011110.github.io/blog/2020/03/08/mathematics-books-women.html">a list of mathematics books by women covered by then-new Wikipedia articles</a>. I thought it would be worthwhile to revisit the same topic and list several more mathematics books with at least one female author, at many different levels of audience, and again covered by new Wikipedia articles. They are (alphabetical by title):</p>

<ul>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Algorithmic_Combinatorics_on_Partial_Words">Algorithmic Combinatorics on Partial Words</a></em> (2008), Francine Blanchet-Sadri. Partial words are strings with “don’t care” symbols; Blanchet-Sadri looks at the combinatorics of repeated patterns within these strings.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Algorithmic_Geometry">Algorithmic Geometry</a></em> (1995), Jean-Daniel Boissonnat and Mariette Yvinec. One of several standard computational geometry textbooks; this is the French one, but it has also been published in translation into English.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Algorithmic_Puzzles">Algorithmic Puzzles</a></em> (2011), Anany and Maria Levitin. A nice collection of classic logic puzzles involving algorithmic thinking.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Braids,_Links,_and_Mapping_Class_Groups">Braids, Links, and Mapping Class Groups</a></em> (1975), Joan Birman. A classic research monograph on the topology of braid groups.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Code_of_the_Quipu">Code of the Quipu</a></em> (1981), Marcia and Robert Ascher. A general-audience book on how the Inca used knotted strings to record numbers and other information.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Combinatorics:_The_Rota_Way">Combinatorics: The Rota Way</a></em> (2009), Joseph P. S. Kung, Catherine Yan, and (posthumously) Gian-Carlo Rota. A graduate textbook on algebraic combinatorics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Combinatorics_of_Experimental_Design">Combinatorics of Experimental Design</a></em> (1987), Anne Penfold Street and her daughter Deborah Street. A textbook on the design of experiments, an area that crosses between statistics and combinatorics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Computability_in_Analysis_and_Physics">Computability in Analysis and Physics</a></em> (1989), Marian Pour-El and J. Ian Richards. A research monograph on problems involving differential equations including the wave equation whose initial conditions are continuous and computable, but that evolve to states whose values cannot be computed.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Diophantus_and_Diophantine_Equations">Diophantus and Diophantine Equations</a></em> (1972), Isabella Bashmakova. A somewhat idiosyncratic history based on the idea that Diophantus knew some very general techniques for finding rational-number solutions to equations, that can be inferred from the much more specific solutions to individual equations that have survived to us.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Elementary_Number_Theory,_Group_Theory_and_Ramanujan_Graphs">Elementary Number Theory, Group Theory, and Ramanujan Graphs</a></em> (2003), Giuliana Davidoff, Peter Sarnak, and Alain Valette. An attempt to make the construction of expander graphs accessible to undergraduate mathematics students.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Equivalents_of_the_Axiom_of_Choice">Equivalents of the Axiom of Choice</a></em> (1963, updated 1985), Herman and Jean Rubin. A large catalog of problems in mathematics whose solution is equivalent to the axiom of choice, from a time when the independence of choice from ZF set theory had not been proven.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Erd%C5%91s_on_Graphs">Erdős on Graphs: His Legacy of Unsolved Problems</a></em> (1998), 
Fan Chung and Ronald Graham. The open problems in graph theory from this book have been further collected and updated on a web site, <a href="http://www.math.ucsd.edu/~erdosproblems/">Erdős’s Problems on Graphs</a>, maintained by Chung.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Extensions_of_First_Order_Logic">Extensions of First Order Logic</a></em> (1996), María Manzano. Attempts to unify second-order logic, modal logic, and dynamic logic, by translating them all into many-sorted logic.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Fat_Chance:_Probability_from_0_to_1">Fat Chance: Probability from 0 to 1</a></em> (2019), Benedict Gross, Joe Harris, and Emily Riehl. A general-audience undergraduate textbook on probability theory based on a metaphor of games of chance.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Fractal_Dimension_of_Architecture">The Fractal Dimension of Architecture</a></em> (2016), Michael J. Ostwald and Josephine Vaughan. Studies the fractal dimension of floor plans as a way to model the changing demands on the complexity of housing structures and to classify buildings by architect and style.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Geometry_of_Numbers">The Geometry of Numbers</a></em> (2000), Carl D. Olds, Anneli Cahn Lax, and Giuliana Davidoff. A textbook on connections between number theory and integer grids, rescued twice from the posthumous works of its first two coauthors.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_History_of_Mathematical_Tables">The History of Mathematical Tables: from Sumer to Spreadsheets</a></em> (2003), Martin Campbell-Kelly, Mary Croarken, Raymond Flood, and Eleanor Robson. An edited volume with chapters on tables from many different periods in mathematical history.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Incidence_and_Symmetry_in_Design_and_Architecture">Incidence and Symmetry in Design and Architecture</a></em> (1983), Jenny Baglivo and Jack E. Graver. A textbook on graph theory and symmetry aimed at architecture students, also including interesting material on structural rigidity.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_the_Theory_of_Error-Correcting_Codes">Introduction to the Theory of Error-Correcting Codes</a></em> (1982, updated 1989 and 1998), Vera Pless. An advanced undergraduate textbook centered on algebraic constructions of linear block codes.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_3-Manifolds">Introduction to 3-Manifolds</a></em> (2014), Jennifer Schultens. An introductory graduate textbook on low-dimensional topology, leading up to the use of normal surfaces and Heegard splittings.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Journey_into_Geometries">Journey into Geometries</a></em> (1991), Márta Svéd. A conversational Alice-in-wonderland-inspired tour of non-Euclidean geometry.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Knots_Unravelled">Knots Unravelled: From String to Mathematics</a></em> (2011), Meike Akveld and Andrew Jobbings. Knot theory for schoolchildren, centered on knot invariants.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Lectures_in_Geometric_Combinatorics">Lectures in Geometric Combinatorics</a></em> (2006), Rekha R. Thomas. An advanced undergraduate or introductory graduate textbook on the combinatorics of convex polytopes and their connections to abstract algebra through secondary polytopes and toric varieties.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Making_Mathematics_with_Needlework">Making Mathematics with Needlework: Ten Papers and Ten Projects</a></em> (2008), sarah-marie belcastro and Carolyn Yackel. The projects come from eight different contributors and include photos, instructions, mathematical analyses, and teaching activities.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mathematical_Excursions">Mathematical Excursions: Side Trips along Paths Not Generally Traveled in Elementary Courses in Mathematics</a></em> (1933), Helen Abbot Merrill. An early book on recreational mathematics, aimed at getting high school students interested in mathematics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mathematics_in_India">Mathematics in India: 500 BCE–1800 CE</a></em> (2009), Kim Plofker. Organized chronologically, this has become the standard overview of this large topic. It also includes material on the history of astronomy in India, which was often tied to the mathematics of its era.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Mathematics_of_Chip-Firing">The Mathematics of Chip-Firing</a></em> (2018), Caroline Klivans. A textbook on chip-firing games and abelian sandpile models.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Markov_Chains_and_Mixing_Times">Markov Chains and Mixing Times</a></em> (2009, 2017), David A. Levin and Yuval Peres, with contributions by Elizabeth Wilmer. A graduate-level text and research reference on how quickly random walks converge to their stable distributions.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mirrors_and_Reflections">Mirrors and Reflections: The Geometry of Finite Reflection Groups</a></em> (2009), Alexandre V. and Anna Borovik. An undergraduate textbook on the classification of finite reflection groups and their associated root systems.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Pioneering_Women_in_American_Mathematics">Pioneering Women in American Mathematics: The Pre-1940 PhD’s</a></em> (2009), Judy Green and Jeanne LaDuke. Biographical profiles of over 200 women who earned doctorates in mathematics in the US before 1940, with some background material on what it was like for women to work in mathematics in those times.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Playing_with_Infinity">Playing with Infinity: Mathematical Explorations and Excursions</a></em> (1955, translated into English 1961), Rózsa Péter. An attempt to explain the nature of mathematics and of the infinite in mathematics to non-mathematicians, based on a series of letters from Péter to a literary friend.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Point_Processes">Point Processes</a></em> (1980), David Cox and Valerie Isham. A research reference on processes that randomly place points on the real line or other geometric spaces.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Power_in_Numbers:_The_Rebel_Women_of_Mathematics">Power in Numbers: The Rebel Women of Mathematics</a></em> (2018), Talithia Williams. A selection of profiles of famous women mathematicians, aimed at motivating young women to become mathematicians.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Primality_Testing_for_Beginners">Primality Testing for Beginners</a></em> (2009, translated into English 2014), Lasse Rempe-Gillen and Rebecca Waldecker. An undergraduate text on primality testing algorithms, based on a course from a summer research program for undergraduates.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Quantum_Computing:_A_Gentle_Introduction">Quantum Computing: A Gentle Introduction</a></em> (2011), Eleanor Rieffel and Wolfgang Polak. One of many texts on this fast-moving subject.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Robust_Regression_and_Outlier_Detection">Robust Regression and Outlier Detection</a></em> (1987), Peter Rousseeuw and Annick M. Leroy. A monograph on statistical methods that can tolerate the total corruption of a large fraction of the data points that they analyze, and still produce meaningful results.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Two-Sided_Matching">Two-Sided Matching: A Study in Game-Theoretic Modeling and Analysis</a></em> (1990), Alvin E. Roth and Marilda Sotomayor. A survey of methods related to stable matching, aimed at economics practitioners and focused on applications.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/When_Topology_Meets_Chemistry">When Topology Meets Chemistry: A Topological Look At Molecular Chirality</a></em> (2000), Erica Flapan. Many biomolecules are different than their mirror images; classical examples include sugars, whose mirrored molecules may taste different and have different effects. This undergraduate-level text studies how to model this effect using a combination of graph theory and knot theory.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Women_in_Mathematics">Women in Mathematics</a></em> (1974), Lynn Osen. This is the one that based its coverage of Hypatia on an early-20th-century children’s book that gave her a made-up backstory and attributed made-up modern rationalist quotes to her. Not recommended, and included mainly as a warning not to use this as a reference.</p>
  </li>
</ul>

<p>To keep from ending on a sour note, I’ll add one more, that I found recently on Wikipedia (although the article there is very old) and I think is worthy of expansion: <em><a href="https://en.wikipedia.org/wiki/Logic_Made_Easy">Logic Made Easy: How to Know When Language Deceives You</a></em> (2004), Deborah J. Bennett, a popular-audience book on how to translate English phrases into logical formalisms and use that translation to understand more clearly what they mean.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/105857580884627445">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/03/08/more-mathematics-books.html"><span class="datestr">at March 08, 2021 06:28 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/033">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/033">TR21-033 |  Automating Tree-Like Resolution in Time $n^{o(\log n)}$ Is ETH-Hard | 

	Susanna de Rezende</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show that tree-like resolution is not automatable in time $n^{o(\log n)}$ unless ETH is false. This implies that, under ETH, the algorithm given by Beame and Pitassi (FOCS 1996) that automates tree-like resolution in time $n^{O(\log n)}$ is optimal. We also provide a simpler proof of the result of Alekhnovich and Razborov (FOCS 2001) that unless the fixed parameter hierarchy collapses, tree-like resolution is not automatable in polynomial time. The proof of our results builds on a joint work with Göös, Nordström, Pitassi, Robere and Sokolov (STOC 2021), which presents a simplification of the recent breakthrough of Atserias and Müller (FOCS 2019).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/033"><span class="datestr">at March 08, 2021 05:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-61276742347305278">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/03/when-do-i-need-to-warn-about-spoilers.html">When do I need to warn about Spoilers?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In a recent post <a href="https://blog.computationalcomplexity.org/2021/02/using-number-of-phds-as-measure-of.html">here</a> I mentioned in passing a plot point from the last season of The Big Bang Theory. Note that the last season was in 2019.  WARNING- do not read that post if you are watching The Big Bang Theory and do not want a plot point revealed. </p><p>Someone who perhaps thinks Lance and I are the same person (are we? See <a href="https://blog.computationalcomplexity.org/2014/04/i-am-bill-gasarch.html">here</a>) left Lance a tweet complaining about the spoiler. At least I think they are complaining. The tweet is in Spanish and its <a href="https://twitter.com/deoxyt2/status/1366120364070338560">here</a>.</p><p>Either</p><p>1) Some country is two years behind America on showing The Big Bang Theory. </p><p>2) The person who tweeted has them on DVR (or something like that) and is watching them a few years after they air (I watched Firefly on a DVD I borrowed from a friend 10 years after it went off he air. Ask your grandparents what a DVD used to be.) </p><p>3) They are kidding us and making fun of the notion of spoilers.</p><p>This raises the question: When is it okay to post spoilers without warning? A few random thoughts:</p><p>1) ``Don't tell me who won the superb owl! I have it on tape and want to watch it without knowing who won!''  This always seemed odd to me.  Routing for events to happen that have already happened seems weird to me. When I was 10 years old I was in New York listening to a Knicks-Celtics Basketball game on the radio and during halftime I accidentally found a Boston radio station that had the game 30 minutes later (I did not realize that the channel I was on originally was 30 minutes behind). So I heard how the game ended, then switched back <i>listening to a game knowing how it would end. </i>I didn't route for my team (the Knicks, who lost) but it just felt very weird listening to it. If I had thought of it I might have noticed how the different broadcasts differ and got a paper out of the data, but as a 10 year old I was not thinking about how to pad my resume quite yet. </p><p>2) I like seeing a mystery twice- first time I don't know who did it, second time I do but can look for clues I missed the first time.</p><p>3) I would have thought 2 years after a show is off the air its fine to spoil. But... maybe not.</p><p>4) It also matters how important the plot point is. I didn't think the plot point I revealed was that important. </p><p>5) Many TV shows are predictable so I am not sure what `spoiler' even means. If I said to Darling:</p><p><i> The bad guy is an unimportant character we meet in the first 10 minutes.</i></p><p>that does not show I've seen it before. It shows that I am a master of TV-logic.</p><p>6) With Arc TV shows this is more of a problem. While it was possible to spoil an episode (Captain Kir will survive but Ensign Red Shirt will bite the dust) it was impossible to spoil a long-term arc. TV has gotten to complicated. And I say that without having watched Game of Thrones. </p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/03/when-do-i-need-to-warn-about-spoilers.html"><span class="datestr">at March 08, 2021 02:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03868">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03868">Decomposable Submodular Function Minimization via Maximum Flow</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Axiotis:Kyriakos.html">Kyriakos Axiotis</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Karczmarz:Adam.html">Adam Karczmarz</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mukherjee:Anish.html">Anish Mukherjee</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sankowski:Piotr.html">Piotr Sankowski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vladu:Adrian.html">Adrian Vladu</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03868">PDF</a><br /><b>Abstract: </b>This paper bridges discrete and continuous optimization approaches for
decomposable submodular function minimization, in both the standard and
parametric settings.
</p>
<p>We provide improved running times for this problem by reducing it to a number
of calls to a maximum flow oracle. When each function in the decomposition acts
on $O(1)$ elements of the ground set $V$ and is polynomially bounded, our
running time is up to polylogarithmic factors equal to that of solving maximum
flow in a sparse graph with $O(\vert V \vert)$ vertices and polynomial integral
capacities.
</p>
<p>We achieve this by providing a simple iterative method which can optimize to
high precision any convex function defined on the submodular base polytope,
provided we can efficiently minimize it on the base polytope corresponding to
the cut function of a certain graph that we construct. We solve this
minimization problem by lifting the solutions of a parametric cut problem,
which we obtain via a new efficient combinatorial reduction to maximum flow.
This reduction is of independent interest and implies some previously unknown
bounds for the parametric minimum $s,t$-cut problem in multiple settings.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03868"><span class="datestr">at March 08, 2021 10:51 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03862">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03862">Harnessing Geometric Constraints from Auxiliary Labels to Improve Embedding Functions for One-Shot Learning</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Ramakrishnan:Anand.html">Anand Ramakrishnan</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Pham:Minh.html">Minh Pham</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Whitehill:Jacob.html">Jacob Whitehill</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03862">PDF</a><br /><b>Abstract: </b>We explore the utility of harnessing auxiliary labels (e.g., facial
expression) to impose geometric structure when training embedding models for
one-shot learning (e.g., for face verification). We introduce novel geometric
constraints on the embedding space learned by a deep model using either
manually annotated or automatically detected auxiliary labels. We contrast
their performances (AUC) on four different face datasets(CK+, VGGFace-2, Tufts
Face, and PubFig). Due to the additional structure encoded in the embedding
space, our methods provide a higher verification accuracy (99.7, 86.2, 99.4,
and 79.3% with our proposed TL+PDP+FBV loss, versus 97.5, 72.6, 93.1, and 70.5%
using a standard Triplet Loss on the four datasets, respectively). Our method
is implemented purely in terms of the loss function. It does not require any
changes to the backbone of the embedding functions.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03862"><span class="datestr">at March 08, 2021 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03653">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03653">GraphMineSuite: Enabling High-Performance and Programmable Graph Mining Algorithms with Set Algebra</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Besta:Maciej.html">Maciej Besta</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/v/Vonarburg=Shmaria:Zur.html">Zur Vonarburg-Shmaria</a>, Yannick Schaffner, Leonardo Schwarz, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kwasniewski:Grzegorz.html">Grzegorz Kwasniewski</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gianinazzi:Lukas.html">Lukas Gianinazzi</a>, Jakub Beranek, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/j/Janda:Kacper.html">Kacper Janda</a>, Tobias Holenstein, Sebastian Leisinger, Peter Tatkowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/o/Ozdemir:Esref.html">Esref Ozdemir</a>, Adrian Balla, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Copik:Marcin.html">Marcin Copik</a>, Philipp Lindenberger, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kalvoda:Pavel.html">Pavel Kalvoda</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Konieczny:Marek.html">Marek Konieczny</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mutlu:Onur.html">Onur Mutlu</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Hoefler:Torsten.html">Torsten Hoefler</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03653">PDF</a><br /><b>Abstract: </b>We propose GraphMineSuite (GMS): the first benchmarking suite for graph
mining that facilitates evaluating and constructing high-performance graph
mining algorithms. First, GMS comes with a benchmark specification based on
extensive literature review, prescribing representative problems, algorithms,
and datasets. Second, GMS offers a carefully designed software platform for
seamless testing of different fine-grained elements of graph mining algorithms,
such as graph representations or algorithm subroutines. The platform includes
parallel implementations of more than 40 considered baselines, and it
facilitates developing complex and fast mining algorithms. High modularity is
possible by harnessing set algebra operations such as set intersection and
difference, which enables breaking complex graph mining algorithms into simple
building blocks that can be separately experimented with. GMS is supported with
a broad concurrency analysis for portability in performance insights, and a
novel performance metric to assess the throughput of graph mining algorithms,
enabling more insightful evaluation. As use cases, we harness GMS to rapidly
redesign and accelerate state-of-the-art baselines of core graph mining
problems: degeneracy reordering (by up to &gt;2x), maximal clique listing (by up
to &gt;9x), k-clique listing (by 1.1x), and subgraph isomorphism (by up to 2.5x),
also obtaining better theoretical performance bounds.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03653"><span class="datestr">at March 08, 2021 10:52 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03468">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03468">Compressed Communication Complexity of Hamming Distance</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Shiori Mitsuya, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nakashima:Yuto.html">Yuto Nakashima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/i/Inenaga:Shunsuke.html">Shunsuke Inenaga</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bannai:Hideo.html">Hideo Bannai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/t/Takeda:Masayuki.html">Masayuki Takeda</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03468">PDF</a><br /><b>Abstract: </b>We consider the communication complexity of the Hamming distance of two
strings. Bille et al. [SPIRE 2018] considered the communication complexity of
the longest common prefix (LCP) problem in the setting where the two parties
have their strings in a compressed form, i.e., represented by the Lempel-Ziv 77
factorization (LZ77) with/without self-references. We present a randomized
public-coin protocol for a joint computation of the Hamming distance of two
strings represented by LZ77 without self-references. While our scheme is
heavily based on Bille et al.'s LCP protocol, our complexity analysis is
original which uses Crochemore's C-factorization and Rytter's AVL-grammar. As a
byproduct, we also show that LZ77 with/without self-references are not
monotonic in the sense that their sizes can increase by a factor of 4/3 when a
prefix of the string is removed.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03468"><span class="datestr">at March 08, 2021 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03394">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03394">Point Cloud based Hierarchical Deep Odometry Estimation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CG updates on arXiv.org">arXiv.org: Computational geometry</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Nowruzi:Farzan_Erlik.html">Farzan Erlik Nowruzi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kolhatkar:Dhanvin.html">Dhanvin Kolhatkar</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kapoor:Prince.html">Prince Kapoor</a>, Robert Laganiere <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03394">PDF</a><br /><b>Abstract: </b>Processing point clouds using deep neural networks is still a challenging
task. Most existing models focus on object detection and registration with deep
neural networks using point clouds. In this paper, we propose a deep model that
learns to estimate odometry in driving scenarios using point cloud data. The
proposed model consumes raw point clouds in order to extract frame-to-frame
odometry estimation through a hierarchical model architecture. Also, a local
bundle adjustment variation of this model using LSTM layers is implemented.
These two approaches are comprehensively evaluated and are compared against the
state-of-the-art.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03394"><span class="datestr">at March 08, 2021 11:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03346">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03346">Maximising the total weight of on-time jobs on parallel machines subject to a conflict graph</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zinder:Yakov.html">Yakov Zinder</a>, Joanna Berlińska, Charlie Peter <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03346">PDF</a><br /><b>Abstract: </b>The paper considers scheduling on parallel machines under the constraint that
some pairs of jobs cannot be processed concurrently. Each job has an associated
weight, and all jobs have the same deadline. The objective is to maximise the
total weight of on-time jobs. The problem is known to be strongly NP-hard in
general. A polynomial-time algorithm for scheduling unit execution time jobs on
two machines is proposed. The performance of a broad family of approximation
algorithms for scheduling unit execution time jobs on more than two machines is
analysed. For the case of arbitrary job processing times, two integer linear
programming formulations are proposed and compared with two formulations known
from the earlier literature. An iterated variable neighborhood search algorithm
is also proposed and evaluated by means of computational experiments.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03346"><span class="datestr">at March 08, 2021 11:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03337">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03337">Revisiting Priority $k$-Center: Fairness and Outliers</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bajpai:Tanvi.html">Tanvi Bajpai</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chakrabarty:Deeparnab.html">Deeparnab Chakrabarty</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chekuri:Chandra.html">Chandra Chekuri</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/n/Negahbani:Maryam.html">Maryam Negahbani</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03337">PDF</a><br /><b>Abstract: </b>In the Priority $k$-Center problem, the input consists of a metric space
$(X,d)$, an integer $k$ and for each point $v \in X$ a priority radius $r(v)$.
The goal is to choose $k$-centers $S \subseteq X$ to minimize $\max_{v \in X}
\frac{1}{r(v)} d(v,S)$. If all $r(v)$'s were uniform, one obtains the classical
$k$-center problem. Plesn\'ik [Plesn\'ik, Disc. Appl. Math. 1987] introduced
this problem and gave a $2$-approximation algorithm matching the best possible
algorithm for vanilla $k$-center. We show how the problem is related to two
different notions of fair clustering [Harris et al., NeurIPS 2018; Jung et al.,
FORC 2020]. Motivated by these developments we revisit the problem and, in our
main technical contribution, develop a framework that yields constant factor
approximation algorithms for Priority $k$-Center with outliers. Our framework
extends to generalizations of Priority $k$-Center to matroid and knapsack
constraints, and as a corollary, also yields algorithms with fairness
guarantees in the lottery model of Harris et al.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03337"><span class="datestr">at March 08, 2021 10:49 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03294">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03294">An Almost Optimal Edit Distance Oracle</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Charalampopoulos:Panagiotis.html">Panagiotis Charalampopoulos</a>, Paweł Gawrychowski, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/m/Mozes:Shay.html">Shay Mozes</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Weimann:Oren.html">Oren Weimann</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03294">PDF</a><br /><b>Abstract: </b>We consider the problem of preprocessing two strings $S$ and $T$, of lengths
$m$ and $n$, respectively, in order to be able to efficiently answer the
following queries: Given positions $i,j$ in $S$ and positions $a,b$ in $T$,
return the optimal alignment of $S[i \mathinner{.\,.} j]$ and $T[a
\mathinner{.\,.} b]$. Let $N=mn$. We present an oracle with preprocessing time
$N^{1+o(1)}$ and space $N^{1+o(1)}$ that answers queries in $\log^{2+o(1)}N$
time. In other words, we show that we can query the alignment of every two
substrings in almost the same time it takes to compute just the alignment of
$S$ and $T$. Our oracle uses ideas from our distance oracle for planar graphs
[STOC 2019] and exploits the special structure of the alignment graph.
Conditioned on popular hardness conjectures, this result is optimal up to
subpolynomial factors. Our results apply to both edit distance and longest
common subsequence (LCS).
</p>
<p>The best previously known oracle with construction time and size
$\mathcal{O}(N)$ has slow $\Omega(\sqrt{N})$ query time [Sakai, TCS 2019], and
the one with size $N^{1+o(1)}$ and query time $\log^{2+o(1)}N$ (using a planar
graph distance oracle) has slow $\Omega(N^{3/2})$ construction time [Long &amp;
Pettie, SODA 2021]. We improve both approaches by roughly a $\sqrt N$ factor.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03294"><span class="datestr">at March 08, 2021 11:04 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2103.03264">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2103.03264">Quantum routing with fast reversals</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Bapat:Aniruddha.html">Aniruddha Bapat</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Childs:Andrew_M=.html">Andrew M. Childs</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gorshkov:Alexey_V=.html">Alexey V. Gorshkov</a>, Samuel King, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Schoute:Eddie.html">Eddie Schoute</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Shastri:Hrishee.html">Hrishee Shastri</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2103.03264">PDF</a><br /><b>Abstract: </b>We present methods for implementing arbitrary permutations of qubits under
interaction constraints. Our protocols make use of previous methods for rapidly
reversing the order of qubits along a path. Given nearest-neighbor interactions
on a path of length $n$, we show that there exists a constant $\epsilon \approx
0.034$ such that the quantum routing time is at most $(1-\epsilon)n$, whereas
any swap-based protocol needs at least time $n-1$. This represents the first
known quantum advantage over swap-based routing methods and also gives improved
quantum routing times for realistic architectures such as grids. Furthermore,
we show that our algorithm approaches a quantum routing time of $2n/3$ in
expectation for uniformly random permutations, whereas swap-based protocols
require time $n$ asymptotically. Additionally, we consider sparse permutations
that route $k \le n$ qubits and give algorithms with quantum routing time at
most $n/3 + O(k^2)$ on paths and at most $2r/3 + O(k^2)$ on general graphs with
radius $r$.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2103.03264"><span class="datestr">at March 08, 2021 11:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5371">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5371">Another axe swung at the Sycamore</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>So there’s an interesting new paper on the arXiv by Feng Pan and Pan Zhang, entitled <a href="https://arxiv.org/abs/2103.03074">“Simulating the Sycamore supremacy circuits.”</a>  It’s about a new tensor contraction strategy for classically simulating Google’s 53-qubit quantum supremacy experiment from Fall 2019.  Using their approach, and using just 60 GPUs running for a few days, the authors say they managed to generate a million <em>correlated</em> 53-bit strings—meaning, strings that all agree on a specific subset of 20 or so bits—that achieve a high linear cross-entropy score.</p>



<p>Alas, I haven’t had time this weekend to write a “proper” blog post about this, but several people have by now emailed to ask my opinion, so I thought I’d share the brief response I sent to a journalist.</p>



<p>This does look like a significant advance on simulating Sycamore-like random quantum circuits!  Since it’s based on tensor networks, you don’t need the literally largest supercomputer on the planet filling up tens of petabytes of hard disk space with amplitudes, as in the brute-force strategy <a href="https://arxiv.org/abs/1910.09534">proposed by IBM</a>.  Pan and Zhang’s strategy seems most similar to the strategy previously <a href="https://arxiv.org/pdf/2005.06787.pdf">proposed by Alibaba</a>, with the key difference being that the new approach generates millions of correlated samples rather than just one.</p>



<p>I guess my main thoughts for now are:</p>



<ol><li>Once you knew about this particular attack, you could evade it and get back to where we were before by switching to a more sophisticated verification test — namely, one where you not only computed a Linear XEB score for the observed samples, you <em>also</em> made sure that the samples didn’t share too many bits in common.  (Strangely, though, the paper never mentions this point.)</li><li>The other response, of course, would just be to redo random circuit sampling with a slightly bigger quantum computer, like the ~70-qubit devices that Google, IBM, and others are now building!</li></ol>



<p>Anyway, very happy for thoughts from anyone who knows more.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5371"><span class="datestr">at March 07, 2021 07:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=18263">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2021/03/07/advancing-and-counting/">Advancing and Counting</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><font color="#0044cc"><br />
<em>Announcing tomorrow’s Women in Data Science workshop (global start tonight 8pm ET), plus a US State Department event for International Women’s Day (also March 8)</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/03/dr.png"><img width="145" alt="" src="https://rjlipton.files.wordpress.com/2021/03/dr.png?w=145&amp;h=175" class="alignright wp-image-18265" height="175" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Santa Fe Inst. external faculty <a href="https://www.scs.gatech.edu/news/610412/dana-randall-named-external-faculty-santa-fe-institute">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Dana Randall is an ADVANCE Professor of Computing and also is an Adjunct Professor of Mathematics at the Georgia Institute of Technology. She is a terrific <a href="https://www.youtube.com/watch?v=MhYpfBUjQFQ">speaker</a> and <a href="https://www.ratemyprofessors.com/ShowRatings.jsp?tid=1579140">teacher</a> and leader. Her class ratings are off the charts. See also <a href="http://www.ams.org/publicoutreach/students/mathgame/arl2009">AMS</a> for her past special talks.</p>
<p>
Today I thought we would discuss her research and its connections to complexity theory and to physics and to math in general.</p>
<p>
Dana does research into the boundary between math and physics. At the highest level Dana seeks to understand random processes, especially those connected to physical systems. The difficulty, in my opinion, is that sometimes the random system is not artificial. This means that we have no control over the system, and this makes the analysis of its behavior that much harder. </p>
<p>
Another way to say this is: we often fare better when we can control the exact random process. When someone else gets to decide on what the process is, we are often in trouble. The system might behave badly, or even worse, might be hard to understand. Nature is often that way—not always thinking about making the analysis of a system easy.</p>
<p>
</p><h2> Shuffling </h2><p></p>
<p>
Let’s make this concrete. Suppose that you or Dana were presented with three methods for shuffling a deck of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> cards—when we play cards <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%7B52%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{52}" class="latex" />. Imagine the methods are: </p>
<ol>
<li>This method selects <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> numbers in the range <img src="https://s0.wp.com/latex.php?latex=%7B%5B1%2Cn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{[1,n]}" class="latex" /> and checks for repeats. If there are, then try again. Use the permutation to shuffle.
</li><li>This method takes a deck of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> numbers and repeatedly shuffles them.
</li><li>This method executes the following code:
</li></ol>
<p><a href="https://rjlipton.files.wordpress.com/2021/03/qscode.png"><img width="550" alt="" src="https://rjlipton.files.wordpress.com/2021/03/qscode.png?w=550&amp;h=100" class="aligncenter wp-image-18266" height="100" /></a></p>
<p>The task of understanding these methods is before us. The first (1) is slow, even for modest size <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />. The chance of getting a permutation on a given trial is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bn%21%7D%7Bn%5En%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{n!}{n^n}}" class="latex" />, which for <img src="https://s0.wp.com/latex.php?latex=%7Bn%3D+52%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n= 52}" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%7B4.7257911+%5Ctimes+10%5E%7B-22%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{4.7257911 \times 10^{-22}}" class="latex" />, which equals </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++0.00000000000000000000047257911.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  0.00000000000000000000047257911. " class="latex" /></p>
<p>But it does generate a fair shuffle—all possible ones are equally likely. And the proof of this is easy. The second (2) is more complicated. The final shuffle depends on the number and manner we use to shuffle the deck. The final analysis is messy.</p>
<p>
The third one (3) is due to Ronald Fisher and Frank Yates, who discovered it in 1938. It has an elegant, but nontrivial, analysis. It is both exact in that all orderings are equally likely, and it takes time linear in <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />. The <a href="https://en.wikipedia.org/wiki/Fisher-Yates_shuffle">history</a> of it is:</p>
<blockquote><p><b> </b> <em> The modern version of the Fisher-Yates shuffle, designed for computer use, was introduced by Richard Durstenfeld in 1964 and popularized by Donald Knuth in The Art of Computer Programming as “Algorithm P (Shuffling)” […apparently unawares; Fisher and Yates were acknowledged in later editions of Knuth’s text…]</em>
</p></blockquote>
<p>
My guess is that Dana, if given these methods, would not be interested in (1): too slow on one hand and trivial on the other. Nor interested in (2): not elegant and messy. Perhaps (3) would accord with her work: it has a nice analysis and runs in linear time. </p>
<p>
</p><h2> Advancing </h2><p></p>
<p>
As we said earlier, Dana is part of <a href="http://www.advance.gatech.edu/team/gt-advance-professors">ADVANCE</a> at Georgia Tech: </p>
<blockquote><p><b> </b> <em> Georgia Tech’s ADVANCE Program seeks to develop systemic and institutional approaches that increase the representation, full participation, and advancement of women and minorities in academic STEM careers—thus contributing to a more diverse workforce, locally and nationally. </em>
</p></blockquote>
<p>
Dana has been and is a leader in helping advance these goals. It is especially relevant since this Monday, March 8th is special. It is <i>Celebrate International Women’s Day with WiDS</i>. See <a href="https://www.widsconference.org/conference.html">this</a> for details:</p>
<blockquote><p><b> </b> <em> Join us for the 24-hour virtual WiDS Worldwide Conference. We’ll follow the sun, bringing you speakers from around the world on International Women’s Day beginning at 1:00 am GMT March 8 (5:00 pm PST March 7). </em>
</p></blockquote>
<p>
In making a collage of their speaker <a href="https://www.widsconference.org/speakers.html">page</a>, we have compressed and rearranged it somewhat. And we have added the logo for the <a href="https://www.widsconference.org/regional-events-2021.html">regional events</a> happening around the globe (some already past) and one for their sponsors.</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2021/03/widsspeakers.png"><img width="600" alt="" src="https://rjlipton.files.wordpress.com/2021/03/widsspeakers.png?w=600&amp;h=590" class="aligncenter size-large wp-image-18268" height="590" /></a></p>
<p></p><p><br />
If you could not take time to follow all the talks, you might take a few for a sample. Maybe you would figure that taking the first four speakers in alphabetical order, or the last four, would be as random a sample as any—after all, what’s in a name?  Well, if you took the last four, you would actually get three of the four <a href="https://www.widsconference.org/conference.html">keynote</a> speakers. Sometimes procedures that we hope would give “random” samples in fact give special ones. That takes us back to one more topic in Randall’s work.</p>
<p>
</p><h2> Counting </h2><p></p>
<p>
One benefit of a random process is that under good conditions it can give us an accurate small sampling of a large and complex system. We have <a href="https://rjlipton.wordpress.com/2016/08/14/a-surprise-for-big-data-analytics/">mentioned</a> dimension reduction in this context. A simpler task is just to get an approximate count of entities in the system. Sometimes one can control the system, but sometimes not.</p>
<p>
One success is represented by a <a href="https://www.sciencedirect.com/science/article/pii/S0166218X15002255">paper</a> with Sarah Miracle of the University of St. Thomas. It is about counting colorings in multigraphs <img src="https://s0.wp.com/latex.php?latex=%7BG+%3D+%28V%2CE%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{G = (V,E)}" class="latex" /> that do not violate simple constraints on the edges <img src="https://s0.wp.com/latex.php?latex=%7B%28u%2Cv%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(u,v)}" class="latex" />. Each edge has a forbidden pair <img src="https://s0.wp.com/latex.php?latex=%7B%28c%2Cc%27%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(c,c')}" class="latex" /> of colors, and a coloring <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\chi}" class="latex" /> defined on <img src="https://s0.wp.com/latex.php?latex=%7BV%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{V}" class="latex" /> is legal provided it does not have both <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%28u%29+%3D+c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\chi(u) = c}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cchi%28v%29+%3D+c%27%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\chi(v) = c'}" class="latex" />. Multiple edges between <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{u}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{v}" class="latex" /> can enforce multiple such constraints. Several natural problems can be represented via this one. The paper is one where their Markov Chain methods do well.</p>
<p>
A second recent <a href="https://arxiv.org/pdf/1611.03385.pdf">paper</a> uses Markov chains to count elements of a given rank in finite partially ordered sets. The chains should be biased according to the structure of the Hasse diagram of the poset. The trick in the paper is a way to balance the bias so as to prevent states that need to be counted from have too low frequency. This enables a direct analysis of the mixing time. The notable application was the first provably efficient ways to sample uniformly from certain kinds of partitions of <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />, for <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> quite large. </p>
<p>
The flip side—a phase change being a kind of a flip—is represented by other work with myriad collaborators that is summarized in a wonderful <a href="http://dimacs.rutgers.edu/events/details?eID=1409">talk</a> she gave at a <a href="http://dimacs.rutgers.edu/events/details?eID=1226&amp;loc=1409#1409">workshop</a> marking the 30th anniversary of DIMACS. As with an earlier <a href="https://drops.dagstuhl.de/opus/volltexte/2017/8021/pdf/LIPIcs-DISC-2017-3.pdf">version</a> at a Schloss Dagstuhl workshop, the talk was titled, “Phase Transitions and Emergent Phenomena in Algorithms and Applications”: </p>
<blockquote><p><b> </b> <em> Markov chain Monte Carlo methods have become ubiquitous across science and engineering as a means of exploring large configuration spaces. The idea is to walk among the configurations so that even though you explore a very small part of the space, samples will be drawn from a desirable distribution. Over the last 30 years there have been tremendous advances in the design and analysis of efficient sampling algorithms for this purpose, largely building on insights from statistical physics. One of the striking discoveries has been the realization that many natural Markov chains undergo a phase transition where they change from being efficient to inefficient as some parameter of the system is varied. </em>
</p></blockquote>
<p>
Here are a <a href="https://www.youtube.com/watch?v=IYkikVLkpoU">video</a> and <a href="http://dimacs.rutgers.edu/tools/fileman/Uploads/Documents/DIMACS-30/Randall_DIMACS30.pdf">slides</a>. The first main slide is about <em>programmable active matter</em> and it interests me especially to see DNA computing included. These systems can have <em>emergent behavior</em>, and while that can ruin randomized procedures that would bank on the system staying stable, it opens other opportunities. </p>
<p>
I, Dick, have run into this type of issue before. I have been on the wrong side, with theorems that were weak because we assumed the process could not be changed. Others who followed us changed the process—got stronger results with easier proofs. Is there a name for this?</p>
<p>
</p><h2> Open Problems </h2><p></p>
<p>
Take a look at the <a href="https://www.widsconference.org/conference.html">talks</a> for the WiDS Worldwide Conference this Monday. </p>
<p>
Ken also notes another event happening tomorrow: a 10am <a href="https://www.state.gov/2021-international-women-of-courage-award-recipients-announced/">ceremony</a> for the International Women of Courage Award. His friend the Iranian chess arbiter Shohreh Bayat is among the honorees, after a story told in her own words <a href="https://www.washingtonpost.com/opinions/i-loosened-my-hijab-at-a-chess-championship-now-im-afraid-to-return-to-iran/2020/02/17/1a670f66-5194-11ea-9e47-59804be1dcfb_story.html">here</a> in the Washington Post. Ken was working with her, on statistical assurance against cheating in the championship match, at the time. The ceremony starts at 10am ET hosted by the US Department of State, with opening remarks by Dr. Jill Biden.</p>
<p>
We must add that there is something that is hard about the type of random processes that Dana studies. We tried to explain what makes her work deep, but perhaps we did not properly explain it. </p>
<p></p><p><br />
[added global start time of workshop to subtitle]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2021/03/07/advancing-and-counting/"><span class="datestr">at March 07, 2021 05:34 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=5711">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/self-concordant-analysis-for-logistic-regression/">Going beyond least-squares – II : Self-concordant analysis for logistic regression</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text"><a href="https://francisbach.com/self-concordant-analysis-newton/">Last month</a>, we saw that self-concordance is a key property in optimization, to use local quadratic approximations in the sharpest possible way. In particular it was an affine-invariant quantity leading to a simple and elegant analysis of Newton method. The key assumption was a link between third and second-order derivatives, which took the following form for one-dimensional functions, $$|f^{\prime\prime\prime}(x)| \leqslant 2 f^{\prime\prime}(x)^{3/2}.$$ Alas, some of the most classical smooth functions appearing in machine learning are not self-concordant with this particular link between derivatives. The main example is the logistic loss, which is widely used across machine learning.</p>



<p class="justify-text">Indeed, if we take this logistic loss function \(f(x) = \log ( 1 + \exp(-x))\), it satisfies $$ f^\prime(x) =  \frac{ -\exp(-x)}{1+\exp(-x)} =\  – \frac{1}{1+\exp(x)} = \ – \sigma(-x),$$ where \(\sigma\) is the usual <a href="https://en.wikipedia.org/wiki/Sigmoid_function">sigmoid function</a> defined as \(\sigma(x) = \frac{1}{1+\exp(-x)}\), and which is increasing from \(0\) to \(1\). We then have \(f^{\prime\prime}(x) = \sigma(x) ( 1- \sigma(x) )\) and \(f^{\prime \prime \prime}(x) = \sigma(x) ( 1- \sigma(x) )( 1 – 2 \sigma(x) )\) leading to $$|f^{\prime\prime\prime}(x)| \leqslant f^{\prime\prime}(x).$$ See below for plots of the logistic loss (left) and its derivatives (right).</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full is-resized"><img width="639" alt="" src="https://francisbach.com/wp-content/uploads/2021/03/losses_logistic.png" class="wp-image-5795" height="267" /></figure></div>



<p class="justify-text">There is thus a link between third and second-order derivatives, but <em>without the power \(3/2\)</em>. Does this difference really matter? In this post, I will show how some properties from classical self-concordance can be extended to this slightly different notion. We will then present applications to stochastic gradient descent as well as the statistical analysis of generalized linear models, and in particular logistic regression.</p>



<p class="justify-text">I will describe applications to Newton method for large-scale logistic regression [<a href="https://papers.nips.cc/paper/8980-globally-convergent-newton-methods-for-ill-conditioned-generalized-self-concordant-losses.pdf">8</a>] in later posts (you read well: Newton method for large-scale machine learning can be useful, in particular for severely ill-conditioned problems).</p>



<h2>\(\nu\)-self-concordance</h2>



<p class="justify-text">A function \(f: C \subset \mathbb{R} \to \mathbb{R}\) is said \(\nu\)-self-concordant on the open interval \(C\) if and only if it is convex, three-times differentiable on \(C\), and there exists \(R &gt; 0\), such that $$\tag{1}\forall x \in C, \  |f^{\prime\prime\prime}(x)| \leqslant R f^{\prime\prime}(x)^{\nu\: \!  /2}.$$ </p>



<p class="justify-text">Note the difference with classical self-concordance (which corresponds to \(\nu=3\) and \(R=2\)). All positive powers are possible (see [<a href="https://link.springer.com/content/pdf/10.1007/s10107-018-1282-4.pdf">1</a>]), but we will focus primarily on \(\nu=2\), for which most of the properties below were derived in [<a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F09-EJS521">2</a>].</p>



<p class="justify-text">Note that the definition above in one dimension is still “affine-invariant” if the constant \(R\) is allowed to change (that is, if it is true for \(f\), it is true for \(x \mapsto f(ax)\) for any \(a\)). However, unless \(\nu = 3\), this will not be true in higher dimension, and therefore, the analysis of Newton method will be more complicated.</p>



<p class="justify-text">For a convex function defined on a convex subset \(C\) of \(\mathbb{R}\), we need the same property along all rays, or equivalently, if \(f^{\prime\prime\prime}(x)[h,h^\prime,h^{\prime\prime}]= \sum_{i,j,k=1}^d h_i h_j^\prime h^{\prime\prime}_k \frac{\partial^3 f}{\partial x_i \partial x_j \partial x_k}(x)\) is the third-order tensor (with three different arguments, as needed below) and \(f^{\prime\prime}(x)[h,h] = \sum_{i,j=1}^d h_i h_j  \frac{\partial^2 f}{\partial x_i \partial x_j}(x)\) the symmetric second-order one, then there exists \(R\) such that $$\tag{2} \forall x \in C, \ \forall h \in \mathbb{R}^d , \ |f^{\prime\prime\prime}(x)[h,h^\prime,h^{\prime}]| \leqslant R \| h\| \cdot f^{\prime\prime}(x)[h^\prime,h^{\prime}],$$ where \(\| h\|\) is the standard Euclidean norm of \(h\). Note here the difference with classical self-concordance where we could consider the symmetric third-order tensor (that is, no need for \(h^\prime\) and \(h^{\prime\prime}\)), and only the Euclidean norm based on the Hessian \(f^{\prime\prime}(x)\) was used.</p>



<p class="justify-text"><strong>Examples. </strong>One can check that if \(f\) and \(g\) are \(2\)-self-concordant, then so is their average \(\frac{1}{2} ( f+g ) \) with the same constant \(R\) (this is one key advantage over \(3\)-self-concordance). Moreover, if \(f\) is \(2\)-self-concordant with constant \(R\), then \(g(x) = f(Ax)\) is also \(2\)-self concordant, with constant \(R \| A\|_{\rm op}\).</p>



<p class="justify-text">Classical examples are all linear and quadratic functions (with constant \(R = 0\)), the exponential function and the logistic loss \(f(x) = \log(1+\exp(-x))\), both with constant \(R=1\). This extends to the “log-sum-exp” function \(f(x) = \log\big( \sum_{i=1}^d \exp(x_i)\big)\), which is \(2\)-self-concordant with constant \(R = \sqrt{2}\). More generally, as shown at the end of the post, any log-partition function of the form $$ f(x) = \log \Big( \int_\mathcal{A} \exp( \varphi(a)^\top x) d\mu(a) \Big) $$ arising from <a href="https://en.wikipedia.org/wiki/Generalized_linear_model">generalized linear models</a> with bounded features, will be \(2\)-self-concordant, with constant the diameter of the set of features. Thus, self-concordance applies to all generalized linear models with the canonical link function. This includes <a href="https://en.wikipedia.org/wiki/Multinomial_logistic_regression">softmax regression</a> (for multiple classses), <a href="https://en.wikipedia.org/wiki/Conditional_random_field">conditional random fields</a>, and of course logistic regression which I will focus on below.</p>



<p class="justify-text"><strong>Logistic regression.</strong> The most classical example is thus logistic regression, with $$f(x) = \frac{1}{n} \sum_{i=1}^n \log(1 + \exp( – x^\top a_i b_i ) ),$$ for observations \((a_i,b_i) \in \mathbb{R}^d \times \{-1,1\}\). See an example below in \(d=2\) dimensions.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-full"><img width="660" alt="" src="https://francisbach.com/wp-content/uploads/2021/03/video_log_reg.gif" class="wp-image-5814" height="261" />Logistic regression in two dimensions: data space with \(a_i \in \mathbb{R}^2\) represented with a different color/mark depending on the label \(b_i\) (left), parameter space (right) with level sets of the objective function \(f\) and its minimizer (purple asterisk).</figure></div>



<p class="justify-text"><strong>Properties in one dimension.</strong>  Mimicking what was done <a href="https://francisbach.com/self-concordant-analysis-newton/">last month</a>, a nice reformulation of Eq. (1) (which is one-dimensional) is $$ \big| \frac{d}{dx} \big( \! \log( f^{\prime\prime}(x)) \big) \big| = \big|   f^{\prime\prime\prime}(x)  f^{\prime \prime}(x)^{-1} \big| \leqslant R,$$ which allows to define upper and lower bounds on \(f^{\prime \prime}(x)\) by integration, as, for \(x &gt; 0\), $$ – Rx \leqslant \log( f^{\prime\prime}(x))  \, – \log(f^{\prime\prime}(0)) \leqslant Rx,$$ which can be transformed into (by isolating \(f^{\prime\prime}(x)\)): $$ \tag{3}  f^{\prime\prime}(0) \exp(\  – R x ) \leqslant f^{\prime\prime}(x) \leqslant f^{\prime\prime}(0) \exp( R x ).$$ We thus obtain global upper and lower bounds on \(f^{\prime\prime}(x)\).</p>



<p class="justify-text">We can then integrate Eq. (3) twice between \(0\) and \(x\) to obtain lower and upper bounds on \(f^\prime\) and then \(f\): $$  f^{\prime\prime}(0) \frac{1-\exp( \ – R x )}{R} \leqslant f^\prime(x)-f^\prime(0) \leqslant f^{\prime\prime}(0) \frac{\exp( R x )\  – 1}{R},$$ and  $$ \tag{4} \!\!\!\!\!\! f^{\prime\prime}(0) \frac{\exp( \ – R x ) + Rx \ – 1}{R^2}\leqslant f(x) \ – f(0) \ – f^\prime(0) x \leqslant  f^{\prime\prime}(0) \frac{\exp( R x ) \ – Rx \ – 1}{R^2}.$$ We thus get a bound $$f(x) \ – f(0) \ – f^\prime(0) x \in f^{\prime\prime}(0) \frac{x^2}{2} \cdot [ \rho(-Rx), \rho(Rx) ],$$ with \(\displaystyle \rho(u) =\ \frac{\exp( u ) \ – u\  – 1}{u^2 / 2 } \sim 1 \) when \(u\to 0\), that is, the second-order expansion is tight at \(x =0\), but leads to global lower and upper bounds. These upper and lower Taylor expansions are illustrated below.</p>



<div class="wp-block-image"><figure class="aligncenter size-large is-resized"><img width="292" alt="" src="https://francisbach.com/wp-content/uploads/2021/03/rho_log.png" class="wp-image-5792" height="227" /></figure></div>



<p class="justify-text"><strong>Properties in multiple dimensions.</strong> The properties above in Eq. (3) and (4) directly extend to multiple dimensions. For any \(x \in C\), then for any \(\Delta \in \mathbb{R}^d\), we have upper and lower bounds for the Hessian, the gradient (not presented below) and the functions value at \(x + \Delta\), that is, denoting by \(\| \cdot \|\) the standard Euclidean norm $$\tag{5}\exp(\ – R\|\Delta\|) f^{\prime \prime}(x) \preccurlyeq  f^{\prime \prime}(x+\Delta) \preccurlyeq \exp( R\|\Delta\|)  f^{\prime \prime}(x),$$ and $$\tag{6} \!\!\!\!\!\!\!\!\! \frac{ \Delta^\top f^{\prime \prime}(x) \Delta}{2} \rho(-R \|\Delta\|_2) \leqslant f(x+\Delta)\ -f(x) \ – f^\prime(x)^\top \Delta \leqslant \frac{ \Delta^\top f^{\prime \prime}(x) \Delta}{2} \rho(R \|\Delta\|_2).\! $$ These approximations are “second-order tight” at \(\Delta=0\), that is, the term in \(f^{\prime\prime}(x)\) in Taylor expansion around \(x\) is exact. These can be derived by considering \(g(t) = f(x+ t\Delta)\), which is \(2\)-self-concordant with constant \(R \|\Delta\|_2\), and applying the one-dimensional properties above in Eqs. (2) and (3) between \(0\) and \(1\).</p>



<p class="justify-text"><strong>Avoiding exponentially decaying constants.</strong> In this post, I will focus primarily on the use self-concordant functions in optimization (stochastic gradient descent in this post and Newton method in another post) as well as in statistics.</p>



<p class="justify-text">The main benefit of using self-concordance is to avoid exponential constants traditionally associated with the analysis of logistic regression. Indeed, for the logistic loss, the second-derivative at \(x\) is is equal to \(\sigma(x) ( 1 – \sigma(x) )\) and is equivalent to \(\exp(-|x|)\) when  \(| x| \) is large. Thus, if we are willing to only apply the logistic loss to small values of \(|x|\), let’s say less than \(M\), then the logistic loss is strongly-convex with constant greater than \(\exp(-M)\). Therefore, we can apply many results in optimization and statistics that apply to such losses. However, all of these results will be impacted by the constant \(\exp(-M)\), which is strictly positive but can be very small. With self-concordance, the analysis will get rid of these annoying constants and replace them by eigenvalues of Hessian matrices at the optimum, which are typically much larger (note that in the worst case, the exponential constants are unavoidable [<a href="http://proceedings.mlr.press/v35/hazan14a.pdf">3</a>]).</p>



<h2>Adaptivity of stochastic gradient descent</h2>



<p class="justify-text">I have not written about stochastic gradient descent for quite a while. Self-concordance gives me the occasion to talk about <em>adaptivity</em>.</p>



<p class="justify-text">It is well known that for smooth convex functions, gradient descent will converge exponentially fast if the function is also strongly-convex (essentially all eigenvalues of all Hessians being strictly positive). If the problem is ill-conditioned, then the exponential convergence rate turns into a rate of \(O(1/t)\) where \(t\) is the number of iterations. Gradient descent is <em>adaptive</em> as the exact same algorithm (with constant step-size or line-search) can be applied without the need to know the strong-convexity parameter. Moreover, if locally around the global optimum, the Hessians are better conditioned, gradient descent will also benefit from it. Therefore, gradient descent is great! What about stochastic gradient descent (SGD)?</p>



<p class="justify-text">It turns out that similar adaptivity exists for a well-defined version of SGD, and that self-concordance is one way to achieve simple non-asymptotic bounds (asymptotic bounds exist more generally [4]).</p>



<p class="justify-text"><strong>Logistic regression. </strong>We consider the logistic regression problem where we aim to minimize the expectation $$f(x) = \mathbb{E}_{a,b} \log( 1 + \exp(-b a^\top x) ) = \mathbb{E}_{a,b} g(x|a,b) ,$$ where \((a,b) \in \mathbb{R}^d \times \{-1,1\}\) is a pair of input \(a\) and output \(b\) (hopefully, the machine learning police will excuse my use of \(x\) as the parameter and not the input). We are given \(n\) independent and identically distributed observations \((a_1,b_1),\dots, (a_n,b_n)\) and we aim at finding the minimizer \(x_\ast\) of \(f\) (which is the logistic loss on unseen data), which we assume to exist. We assume that the feature norms \(\|a\|\) are almost surely bounded by \(R\).</p>



<p>Note here that we are not trying to minimize the empirical risk and by using a single pass, we obtain bounds on the generalization performance. This is one of the classical benefits of SGD.</p>



<p class="justify-text"><strong>Averaged stochastic gradient descent.</strong> We consider the stochastic gradient recursion: $$x_i = x_{i-1} – \gamma_i g^\prime(x_{i-1}|a_i,b_i),$$ for \(i=1,\dots,n\), with a single pass over the data. We also consider the average iterate \(\bar{x}_n = \frac{1}{n+1} \sum_{i=0}^{n} x_i\). </p>



<p class="justify-text">Standard results from the stochastic gradient descent literature [<a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">5</a>, <a href="https://papers.nips.cc/paper/2011/file/40008b9a5380fcacce3976bf7c08af5b-Paper.pdf">6</a>] show that if \(\gamma_i = \frac{1}{R^2 \sqrt{i}}\), then, up to universal (small) constants, $$ \mathbb{E} f(\bar{x}_i)\  – f(x_\ast) \leqslant (1 + R^2 \| x_0 – x_\ast\|^2) \frac{\log n}{\sqrt{n}}.$$ If in addition, the function \(f\) is \(\mu\)-strongly-convex, then with the step-size \(\gamma_i = \frac{1}{\mu i}\), up to universal (small) constants, $$ \mathbb{E} f(\bar{x}_i) \ – f(x_\ast) \leqslant   \frac{R^2 \log n}{n\mu}.$$ The strongly convex result seems beneficial as we get a rate in \(O(( \log n) / n)\) instead of \(O(( \log n) / \sqrt{n})\), <em>but</em>, (1) it depends on \(\mu\), which can be very small in problems in high dimension \(d\), (2) it depends on this global strong-convexity constant \(\mu\), that is a lower bound on all Hessians, which is zero for logistic regression unless a projection step is used (and with exponentially small constant as explained above), and (3) the step-size has to be adapted. </p>



<p class="justify-text"><strong>Adaptivity. </strong>Wouldn’t it be great if these three problems could be solved at once? This is what I worked on a few years ago [<a href="http://">7</a>], where I showed that for constant step-size \(\gamma\) proportional to \(\frac{1}{R^2 \sqrt{n}}\) (thus dependent on the total number of gradient steps), we have. up to constants: $$ \mathbb{E} f(\bar{x}_i)\ – f(x_\ast) \leqslant (1 + R^2 \| x_0 – x_\ast\|^2) \frac{1}{\sqrt{n}},$$ <em>and</em> $$ \mathbb{E} f(\bar{x}_i)\ – f(x_\ast) \leqslant (1 + R^4 \| x_0 – x_\ast\|^4) \frac{R^2 }{\mu_\ast n},$$ where \(\mu_\ast\) is the smallest eigenvalue of the Hessian \(f^{\prime\prime}(x_\ast)\) <em>at the optimum</em>. The two bounds are always satisfied and one can be bigger than the other depending on \(n\) and the condition number \(R^2 / \mu_\ast\).</p>



<p class="justify-text">We thus get (almost) the best of all worlds! The proof relies strongly on self-concordance and applies to all generalized linear models. Note that (a) no new algorithm is proposed here, I am simply providing partial theoretical justifications why a classical algorithm works so well, (b) this is <em>only an upper-bound</em> on performance (more on this below).</p>



<h2>Generalization bounds for generalized linear models</h2>



<p class="justify-text">Beyond optimization, the use of self-concordant can make the non-asymptotic <em>statistical</em> analysis of logistic regression, and more generally all generalized linear models, sharper in the regularized unregularized setting [<a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F09-EJS521">2</a>, <a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F20-EJS1780">10</a>], with \(\ell_1\)-norm [<a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F20-EJS1780">10</a>], or with non-parametric kernel-based models [<a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F09-EJS521">2</a>, <a href="http://proceedings.mlr.press/v99/marteau-ferey19a/marteau-ferey19a.pdf">9</a>]. The first benefit is to avoid exponential constants associated with usual strong-convexity arguments of the loss (which can also be achieved with other tools, see [<a href="http://proceedings.mlr.press/v9/kakade10a/kakade10a.pdf">11</a>]). But there is another important benefit that requires some digression.</p>



<p class="justify-text"><strong>Asymptotic statistics is great…</strong> Supervised learning through empirical risk minimization is the workhorse of machine learning. It can be analyzed from different perspectives and with different tools. As shown in the great book by Aad Van der Vaart [12], asymptotics statistics is a very clean way of understanding the behavior of statistical estimators when the number of observations \(n\) goes to infinity. </p>



<p class="justify-text">Empirical risk minimization is indeed an example of M-estimation problems (estimators based on minimizing the empirical average of some loss functions), and it is known that under general conditions, the estimator has a known asymptotic mean and variance (with the traditional <a href="https://en.wikipedia.org/wiki/Fisher_information">Fisher information matrices</a>), which leads to an asymptotic equivalent of the unseen population risk (e.g., the “test error”). We recover the usual \(d/n\) bound for unregularized problems as well as dimension-independent results when using regularization with squared Euclidean norms (then with worse dependence in \(n\)).</p>



<p class="justify-text">Because we deal with <em>limits</em>, one can formally compare two methods by favoring the one with the smallest asymptotic risk. This is not possible when non-asymptotic <em>upper bounds</em> are available: the fact that they are true for all \(n\) is a strong benefit, but since they are only bounds, they don’t say anything about which method is best.</p>



<p class="justify-text"><strong>… But it is only asymptotic.</strong> Of course, these comparisons are only true in the limit of large \(n\), and, in particular for high-dimensional problems (e.g., data and/or parameters in large dimensions), we are unlikely to be in the asymptotic regime. So we cannot really rely only on letting \(n\) go to infinity. Moreover, these asymptotic limits typically depend on some information which is not available at training time. But does this mean that we have to throw away all asymptotic results?</p>



<p class="justify-text"><strong>Self-concordance to the rescue.</strong> Since many of the asymptotic results are obtained by second-order Taylor expansions, we need non-asymptotic ways of dealing with these expansions, which is exactly what self-concordance allows you to do (with some extra effort of course). Therefore the best of both worlds can be achieved with such tools; see, e.g., [<a href="http://proceedings.mlr.press/v99/marteau-ferey19a/marteau-ferey19a.pdf">9</a>, <a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F20-EJS1780">10</a>], for examples of analysis, and [<a href="https://projecteuclid.org/download/pdfview_1/euclid.aos/1360332187">13</a>, <a href="https://papers.nips.cc/paper/2015/file/acf4b89d3d503d8252c9c4ba75ddbf6d-Paper.pdf">14</a>] for other tools that can achieve similar results. It is then possible to prove that some asymptotic expansions are valid non-asymptotically.</p>



<h2>Conclusion</h2>



<p class="justify-text">In this post I focused on two aspects of self-concordant analysis for logistic regression and its extensions, namely adaptivity of stochastic gradient descent and statistical generalization bounds.</p>



<p class="justify-text">In a later post, I will go back to Newton’s method, where the lack of affine invariance of \(2\)-self-concordance makes the analysis more complicated. However it will come with some interesting benefits for large-scale severely ill-conditioned problems [<a href="https://papers.nips.cc/paper/8980-globally-convergent-newton-methods-for-ill-conditioned-generalized-self-concordant-losses.pdf">8</a>]. You may wonder why we should bother with Newton method for large-scale machine learning when stochastic gradient descent, with or without variance reduction, seems largely enough. Stay tuned!</p>



<h2>References</h2>



<p class="justify-text">[1] Tianxiao Sun, and Quoc Tran-Dinh. <a href="https://link.springer.com/content/pdf/10.1007/s10107-018-1282-4.pdf">Generalized self-concordant functions: a recipe for Newton-type methods</a>. <em>Mathematical Programming</em> 178(1): 145-213, 2019.<br />[2] Francis Bach. <a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F09-EJS521">Self-Concordant Analysis for Logistic Regression</a>. Electronic Journal of Statistics, 4, 384-414, 2010.<br />[3] Elad Hazan, Tomer Koren, and Kfir Y. Levy. <a href="http://proceedings.mlr.press/v35/hazan14a.pdf">Logistic regression: Tight bounds for stochastic and online optimization</a>. Proceedings of the International Conference on Learning Theory (COLT), 2014.<br />[4] Boris T. Polyak, and Anatoli B. Juditsky. Acceleration of stochastic approximation by averaging. SIAM journal on control and optimization, 30(4):838-855, 1992.<br />[5] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, and Alexander Shapiro. <a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">Robust stochastic approximation approach to stochastic programming</a>. SIAM Journal on optimization, 19(4), 1574-1609, 2009.<br />[6] Francis Bach, and Eric Moulines. <a href="https://papers.nips.cc/paper/2011/file/40008b9a5380fcacce3976bf7c08af5b-Paper.pdf">Non-asymptotic analysis of stochastic approximation algorithms for machine learning</a>. Advances in Neural Information Processing Systems (NIPS), 2011.<br />[7] Francis Bach. <a href="http://jmlr.org/papers/volume15/bach14a/bach14a.pdf">Adaptivity of averaged stochastic gradient descent to local strong convexity for logistic regression</a>. Journal of Machine Learning Research, 15(Feb):595−627, 2014.<br />[8] Ulysse Marteau-Ferey, Francis Bach, Alessandro Rudi. <a href="https://papers.nips.cc/paper/8980-globally-convergent-newton-methods-for-ill-conditioned-generalized-self-concordant-losses.pdf">Globally convergent Newton methods for ill-conditioned generalized self-concordant Losses</a>. Advances in Neural Information Processing Systems (NeurIPS), 2019.<br />[9] Ulysse Marteau-Ferey, Dmitrii Ostrovskii, Francis Bach, Alessandro Rudi. <a href="http://proceedings.mlr.press/v99/marteau-ferey19a/marteau-ferey19a.pdf">Beyond Least-Squares: Fast Rates for Regularized Empirical Risk Minimization through Self-Concordance</a>. Proceedings of the International Conference on Learning Theory (COLT), 2019<br />[10] Dmitrii Ostrovskii, <a href="https://projecteuclid.org/journalArticle/Download?urlid=10.1214%2F20-EJS1780">Francis Bach. Finite-sample Analysis of M-estimators using Self-concordance</a>. Electronic Journal of Statistics, 15(1):326-391, 2021.<br />[11] Sham Kakade, Ohad Shamir, Karthik Sridharan, and Ambuj Tewari. <a href="http://proceedings.mlr.press/v9/kakade10a/kakade10a.pdf">Learning exponential families in high-dimensions: Strong convexity and sparsity</a>. In Proceedings of the international conference on artificial intelligence and statistics (AISTATS), 2010.<br />[12] Aad W. Van der Vaart. Asymptotic Statistics. Cambridge University Press, 2000.<br />[13] Vladimir Spokoiny. <a href="https://projecteuclid.org/download/pdfview_1/euclid.aos/1360332187">Parametric estimation. Finite sample theory</a>. The Annals of Statistics, 40(6), 2877-2909, 2012.<br />[14] Tomer Koren, and Kfir Y. Levy. <a href="https://papers.nips.cc/paper/2015/file/acf4b89d3d503d8252c9c4ba75ddbf6d-Paper.pdf">Fast Rates for Exp-concave Empirical Risk Minimization</a>. Advances in Neural Information Processing Systems (NIPS), 2015.<br /></p>



<h2>Self-concordance for generalized linear models</h2>



<p class="justify-text">We consider a probability distribution on some set \(\mathcal{A}\), with density $$\exp\big( \varphi(a)^\top x) \ – f(x) \big)$$ with respect to the positive measure \(d\mu\), with \(f(x)\) the log-partition function, defined so that the total mass is one, that is, $$ f(x) = \log \Big( \int_\mathcal{A} \exp( \varphi(a)^\top x) d\mu(a) \Big). $$ We assume the feature vector \(\varphi(a)\) and the parameter \(x\) are in \(\mathbb{R}^d\).</p>



<p class="justify-text">The theory of <a href="https://en.wikipedia.org/wiki/Exponential_family">exponential families</a> tells us that the function \(f(x)\) is the “cumulant generating” function. That is, the cumulants of \(\varphi(a)\) for the probability distribution defined by \(x\), are exactly the derivatives of \(f\) taken at \(x\). More precisely, for the usual mean and covariance matrix, we get $$ \mathbb{E}_{a|x} \varphi(a) = f^\prime (x),$$ $$ \mathbb{E}_{a|x} \big(\varphi(a) \ –  f^\prime (x)\big) \otimes \big(\varphi(a) \ – f^\prime (x)\big) = f^{\prime\prime}(x).$$ For the third order cumulant, we get: $$ \mathbb{E}_{a|x} \big(\varphi(a)\  – f^\prime (x)\big)\otimes \big(\varphi(a)\  – f^\prime (x)\big) \otimes \big(\varphi(a) \ – f^\prime (x)\big) = f^{\prime\prime\prime}(x).$$ Thus, for any \(h \in \mathbb{R}^d\), \(\big(\varphi(a) \ – f^\prime (x)\big)^\top h \leqslant \| h\| D\), where \(D\) is the diameter of the set \(\{ \varphi(a), \ a \in \mathcal{A} \}\), which leads to the desired \(2\)-self-concordance property.</p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/self-concordant-analysis-for-logistic-regression/"><span class="datestr">at March 07, 2021 04:06 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=848">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2021/03/07/questions-on-the-future-of-lower-bounds/">Questions on the future of lower bounds</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Will any of the yellow books be useful?</p>



<figure class="wp-block-image"><img src="https://media.springernature.com/w153/springer-static/cover/book/9783030276447.jpg" alt="https://media.springernature.com/w153/springer-static/cover/book/9783030276447.jpg" /></figure>



<p>Book 576 (not pictured) was saved just in time from the paper mill.  It was rumored that Lemma 76.7.(ii) could have applications to lower bounds.  Upon closer inspection, that lemma has a one-line proof by linearity of expectation if you change the constant 17 to 19.  This change does not affect the big-Oh.</p>



<p>Will the study of randomness lead to the answer to any of the questions that are open since before randomness became popular? I think it’s a coin-toss.</p>



<p>Will there be any substance to the belief that algebraic lower bounds must be proved <em>first</em>?</p>



<p>Will the people who were mocked for working on DLOGTIME uniformity, top fan-in k circuits, or ZFC independence have the last laugh?</p>



<p>Will someone switch the circuit breaker and lit up CRYPT, DERAND, and PCPOT, or will they remain unplugged amusement parks where you sit in the roller coaster, buckle up, and pretend?</p>



<p>Will diagonalization be forgotten, or will it continue to frustrate combinatorialists with lower bounds they can’t match for functions they don’t care about?</p>



<p>Will decisive progress be made tonight, or will it take centuries?</p>



<p>Only Ketan Mulmuley knows for sure.</p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2021/03/07/questions-on-the-future-of-lower-bounds/"><span class="datestr">at March 07, 2021 11:52 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://ptreview.sublinear.info/?p=1485">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1485">News for February 2021</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>We got quite some action last month. We saw five papers. A lot of action in graph world and some action in quantum property testing which we hope you will find appetizing. Also included is a result on sampling uniformly random <em>graphlets</em>. </p>



<p><strong>Testing Hamiltonicity (and other problems) in Minor-Free Graphs</strong>, by Reut Levi and Nadav Shoshan (<a href="https://arxiv.org/abs/2102.11728">arXiv</a>). Graph Property Testing has been explored pretty well for dense graphs (and reasonably well for bounded degree graphs). However, testing properties in the general case still remains an elusive goal. This paper makes contributions in this direction and as a first result it gives an algorithm for testing Hamiltonicity <em>in minor free graphs</em> (with two sided error) with running time \(poly(1/\varepsilon)\). Let me begin by pointing out that Hamiltonicity is an irksome property to test in the following senses.</p>



<ul><li>It is neither monotone nor additive. So the partition oracle based algorithms do not immediately imply a tester (with running time depending only on \(\varepsilon\) for Hamiltonicity. This annoyance bugs you even in the bounded degree case.</li><li> Czumaj and Sohler characterized what graph properties are testable with one-sided error in general planar graphs. In particular, they show a property of general planar graphs is testable <em>iff</em> this property can be reduced to testing for a finite family of finite forbidden subgraphs. Again, Hamiltonicity does not budge to this result. </li><li>There are (concurrent) results by Goldreich and Adler-Kohler which show that with one-sided error, Hamiltonicity cannot be tested with \(o(n)\) queries. </li></ul>



<p>The paper shows that distance to Hamiltonicity can be exactly captured in terms of a certain combinatorial parameter. Thereafter, the paper tries to estimate this parameter after cleaning up the graph a little. This allows them to estimate the distance to Hamiltonicity and thus also implies a tolerant tester (restricted to mino-free graphs).</p>



<p><strong>Testing properties of signed graphs</strong>, by Florian Adriaens, Simon Apers (<a href="https://arxiv.org/abs/2102.07587">arXiv</a>). Suppose I give you a graph \(G=(V,E)\) where all edges come with a label: which is either “positive” or “negative”. Such signed graphs are used to model various scientific phenomena. Eg, you can use these to model interactions between individuals in social networks into two categories like friendly or antagonistic.</p>



<p>This paper considers property testing problems on signed graphs. The notion of farness from the property extends naturally to these graphs (both in the dense graph model and the bounded degree model). The paper contains explores three problems in both of these models: signed triangle freeness, balance and clusterability. Below I will zoom into the tester for clusterability in the bounded degree setting developed In the paper. A signed graph is considered clusterable if you can partition the vertex set into some number of components such that the edges within any component are all positive and the edges running across components are all negative.</p>



<p>The paper exploits a forbidden subgraph characterization of clusterability which shows that any cycle with exactly one negative edge is a certificate of non-clusterability of \(G\). The tester runs multiple random walks from a handful of start vertices to search for these “bad cycles” by building up on ideas in the seminal work of Goldreich and Ron for testing bipariteness. The authors put all of these ideas together and give a \(\widetilde{O}(\sqrt n)\) time one-sided tester for clusterability in signed graphs.</p>



<p></p>



<p><strong>Local Access to Random Walks</strong>, by Amartya Shankha Biswas, Edward Pyne, Ronitt Rubinfeld (<a href="https://arxiv.org/abs/2102.07740">arXiv</a>). Suppose I give you a gigantic graph (with bounded degree) which does not fit in your main memory and I want you to solve some computational problem which requires you to solve longish random walks of length \(t\). And lots of them. It would be convenient to not spend \(\Omega(t)\) units of time performing every single walk. Perhaps it would work just as well for you to have an oracle which provides query access to a \(Position(G,s,t)\) oracle which returns the position of a walk from \(s\) at time \(t\) of your choice. Of course, you would want the sequence of vertices returned to behave consistently with some actual random walk sampled from the distribution of random walks starting at \(s\). Question is: Can I build you this primitive? This paper answers this question in affirmative  and shows that for graphs with spectral gap \(\Delta\), this can be achieved with running time \(\widetilde{O}(\sqrt n/\Delta)\) per query. And you get the guarantee that the joint distribution of the vertices you return at queried times is \(1/poly(n)\) close to the uniform distribution over such walks in \(\ell_1\).  Thus, for a random \(d\)-regular graph, you get running times of the order \(\widetilde{O}(\sqrt n)\) per query. The authors also show tightness of this result by showing to get subconstant error in \(\ell_1\), you necessarily need \(\Omega(\sqrt n/\log n)\) queries in expectation.</p>



<p></p>



<p><strong>Efficient and near-optimal algorithms for sampling connected subgraphs</strong>, by Marco Bressan (<a href="https://arxiv.org/abs/2007.12102">arXiv</a>). As the title suggests, this paper considers efficient algorithms for sampling a uniformly random \(k\)-graphlet from a given graph \(G\) (for \(k \geq 3\)). Recall, a \(k\)-graphlet refers to a collection of \(k\)-vertices which induce a connected graph in \(G\). The algorithm considered in the paper is pretty simple. You just define a Markov Chain \(\mathcal{G}_k\) with all \(k\)-graphlets as its state space. Two states in \(\mathcal{G}_k\) are adjacent <em>iff</em> their intersection is a \((k-1)\)-graphlet. To obtain a uniformly random sample, a classical idea is to just run this Markov Chain and obtain an \(\varepsilon\)-uniform sample. However, the gap between upper and lower bounds on the mixing time of this walk is of the order \(\rho^{k-1}\) where \(\rho = \Delta/\delta\) (that is the ratio of maximum and minimum degrees to the power \(k-1\)). The paper closes this gap up to logarithmic factors and shows that the mixing time of the walk is at most \(t_{mix}(G) \rho^{k-1} \log(n/\varepsilon)\). It also proves an almost matching lower bound. Further, the paper also presents an algorithm with event better running time to return an almost uniform \(k\)-graphlet. This exploits a previous observation: sampling a uniformly random \(k\)-graphlet is equivalent to sampling a uniformly random edge in \(\mathcal{G}_{k-1}\). The paper then proves a lemma which upperbounds the relaxation time of walks in \(\mathcal{G}_k\) to walks in \(\mathcal{G}_{k-1}\). And then you upperbound the mixing time in terms of the relaxation time to get an improved expected running time of the order \(O(t_{mix}(G) \cdot \rho^{k-2} \cdot \log(n/\varepsilon)\).</p>



<p></p>



<p><strong>Toward Instance-Optimal State Certification With Incoherent Measurements</strong>, by Sitan Chen, Jerry Li, Ryan O’Donnell (<a href="https://arxiv.org/abs/2102.13098">arXiv</a>). The problem of quantum state certification has gathered interest over the last few years. Here is the setup: you are given a quantum state \(\sigma \in \mathbb{C}^{d \times d}\) and you are also given \(N\) copies of an unknown state \(\rho\). You want to distinguish between the following two cases: Does \(\rho = \sigma\) or is \(\sigma\) at least \(\varepsilon\)-far from \(\rho\) in trace norm? Badescu et al showed in a recent work that if entangled measurements are allowed, you can do this with a mere \(O(d/\varepsilon^2)\) copies of \(\rho\). But using entangled states comes with its own share of problems. On the other hand if you disallow entanglement, as Bubeck et al show, you need \(\Omega(d^{3/2}/\varepsilon^2)\) measurements. This paper asks: for which states \(\sigma\) can you improve upon this bound. The work takes inspirations from <em>a la</em> “instance optimal” bounds for identity testing. Authors show a fairly general result which (yet again) confirms that the quantum world is indeed weird. In particular, the main result of the paper implies that the copy complexity of (the quantum analog of) identity testing in the quantum world (with non-adaptive queries) grows as \(\Theta(d^{1/2}/\varepsilon^2)\). That is, the number of quantum measurements you need increases with \(d\) (which is the stark opposite of the behavior you get in the classical world).</p></div>







<p class="date">
by Akash <a href="https://ptreview.sublinear.info/?p=1485"><span class="datestr">at March 06, 2021 05:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/032">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/032">TR21-032 |  Fiat-Shamir via List-Recoverable Codes (or: Parallel Repetition of GMW is not Zero-Knowledge) | 

	Ron Rothblum, 

	Justin Holmgren, 

	Alex Lombardi</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Shortly after the introduction of zero-knowledge proofs, Goldreich, Micali and Wigderson (CRYPTO '86) demonstrated their wide applicability by constructing  zero-knowledge proofs for the NP-complete problem of graph 3-coloring. A long-standing open question has been whether parallel repetition of their protocol preserves zero knowledge. In this work, we answer this question in the negative, assuming a a standard cryptographic assumption (i.e., the hardness of learning with errors (LWE)).

Leveraging a connection observed by Dwork, Naor, Reingold, and Stockmeyer (FOCS '99), our negative result is obtained by making positive progress on a related fundamental problem in cryptography: securely instantiating the Fiat-Shamir heuristic for eliminating interaction in public-coin interactive protocols. A recent line of works has shown how to instantiate the heuristic securely, albeit only for a limited class of protocols.

Our main result shows how to instantiate Fiat-Shamir for parallel repetitions of much more general interactive proofs. In particular, we construct hash functions that, assuming LWE, securely realize the Fiat-Shamir transform for the following rich classes of protocols:

- The parallel repetition of any ``commit-and-open'' protocol (such as the GMW protocol mentioned above), when a specific (natural) commitment scheme is used.  Commit-and-open protocols are a ubiquitous paradigm for constructing general purpose public-coin zero knowledge proofs.

- The parallel repetition of any base protocol that (1) satisfies a stronger notion of soundness called round-by-round soundness, and (2) has an efficient procedure, using a suitable trapdoor, for recognizing ``bad verifier randomness'' that would allow the prover to cheat.

Our results are obtained by establishing a new connection between the Fiat-Shamir transform and  list-recoverable codes.  In contrast to the usual focus in coding theory, we focus on a parameter regime in which the input lists are extremely large, but the rate can be small.  We give a (probabilistic) construction based on Parvaresh-Vardy codes (FOCS '05) that suffices for our applications.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/032"><span class="datestr">at March 05, 2021 11:22 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/031">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/031">TR21-031 |  Upper Bound for Torus Polynomials | 

	Vaibhav Krishan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We prove that all functions that have low degree torus polynomials approximating them with small error also have $MidBit^+$ circuits computing them. This serves as a partial converse to the result that all $ACC$ functions have low degree torus polynomials approximating them with small error, by Bhrushundi, Hosseini, Lovett and Rao (ITCS 2019).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/031"><span class="datestr">at March 05, 2021 02:14 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=18238">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2021/03/04/wsj-meets-group-algorithms/">WSJ Meets Group Algorithms</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Our whole life is solving puzzles. — Ernő Rubik</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/03/jf-1.png"><img width="163" alt="" src="https://rjlipton.files.wordpress.com/2021/03/jf-1.png?w=163&amp;h=120" class="alignright wp-image-18244" height="120" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="http://www.ws.binghamton.edu/fridrich/pressconnects_com%20%2009-11-03%20%20News%20Story.htm">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Jessica Fridrich is a Distinguished Professor of Electrical and Computer Engineering at Binghamton University. She is an expert on data hiding, that is, <a href="https://en.wikipedia.org/wiki/Steganography">steganography</a>. She has over 34,000 citations—impressive. A lot more than most of us. She also has <a href="http://www.ws.binghamton.edu/fridrich/cube.html">worked</a> on the famous Rubik’s cube.</p>
<p>
Today we look at her work on Rubik’s cube, the WSJ’s interest in Rubik’s cube, and what both say—and don’t say—about fundamental algorithms.<br />
<span id="more-18238"></span></p>
<p>
By the way, WSJ stands for the Wall Street Journal—the American <a href="https://en.wikipedia.org/wiki/The_Wall_Street_Journal">newspaper</a> of business. The WSJ has shown great interest in the Rubik’s cube puzzle and has run many articles over the years on it.</p>
<p>
Recall the cube puzzle was invented…of course you know all about Rubik’s cube. You probably have owned one at one time. Right. Just for a <a href="https://en.wikipedia.org/wiki/Rubik%27s_Cube">refresher</a>: </p>
<blockquote><p><b> </b> <em> The Rubik’s Cube is a 3-D combination puzzle invented in 1974 by Hungarian sculptor and professor of architecture Ernő Rubik. As of January 2009, 350 million cubes had been sold worldwide, making it the world’s top-selling puzzle game. It is widely considered to be the world’s best-selling toy. </em>
</p></blockquote>
<p>
But you may not know all about Fridrich.</p>
<p></p><h2> Speed Solving </h2><p></p>
<p>
Fridrich was one of the progenitors of <em>speed cubing</em>. She took part in the First World Championship in 1982 in Budapest, next-door to her native Czechoslovakia. She finished in the middle of the pack with a time of <b>29.11</b> seconds from a randomly well-mixed starting cube position. Her thoughts on how the cubes could be better prepared for speed are recorded on her <a href="http://www.ws.binghamton.edu/fridrich/cubewrld.html">page</a> about the tournament.</p>
<p>
At the Second World Championship, she improved her average time to <b>20.48</b> seconds and placed <a href="https://www.worldcubeassociation.org/competitions/WC2003">2nd</a>. She had the two fastest solves in the finals but lost on average-of-median-three-of-five.  That championship took place in Toronto—in <b>2003</b>. She is at a loss to explain why there was such a gap. Usually an athlete—in this case a mathlete?—is on the downswing nearing age 40, but even as a self-described “<a href="http://ws2.binghamton.edu/fridrich/history.html">old-timer</a>,” she fended off all but one of a whole next generation. </p>
<p>
Much of the credit goes to her solving method. She originated the “O” and “P” parts of the <a href="https://en.wikipedia.org/wiki/CFOP_method">CFOP</a> method. CFOP stands for: Cross, First 2 Layers, Orient Last Layer, Permute Last Layer. Versions of this are used my most top “cubers” to this day, and her name is often affixed to the method. In a 2008 profile of her, the New York Times <a href="https://www.nytimes.com/2008/12/16/science/16prof.html?_r=1&amp;em">quoted</a> the 2003 winner as saying that Fridrich found the route up the mountain while the rest of the cubers optimize traversing ledges along it. And in 2012, the NYT <a href="https://london2012.blogs.nytimes.com/2012/06/25/master-of-the-shot-put-and-the-cube/?searchResultPosition=5">quoted</a> Olympic shot-putter Reese Hoffa as wanting “to learn the Fridrich Method of solving the puzzle, ‘which is what all of the best cubers use.'” </p>
<p>
At this point, knowing our interest in chess, you might expect a <a href="https://en.wikipedia.org/wiki/The_Queen's_Gambit_(novel)"><i>Queen’s</i></a> <a href="https://en.wikipedia.org/wiki/The_Queen's_Gambit_(miniseries)"><i>Gambit</i></a> reference. But what we have here is not a story of Beth Harmon coming back from a life <a href="https://www.thereviewgeek.com/thequeensgambit-e6review/">adjournment</a> or Roy Hobbs in <a href="https://en.wikipedia.org/wiki/The_Natural"><i>The</i></a> <a href="https://en.wikipedia.org/wiki/The_Natural_(film)"><i>Natural</i></a> rejoining baseball almost 20 years after being shot. It’s about going overseas, earning a PhD, getting two research positions, writing early papers (under the <a href="https://dblp.org/pid/29/4038.html">name</a> Jiri Fridrich), transitioning, then getting a faculty position leading to tenure while developing mathematical formulas and writing tons of code for systems to <a href="https://www.nytimes.com/2004/07/22/technology/what-s-next-for-doctored-photos-a-new-flavor-of-digital-truth-serum.html?searchResultPosition=16">source</a> photos and catch digital pirates and pornographers and other image fraudsters, then coming back to light up an <img src="https://s0.wp.com/latex.php?latex=%7B8+%5Ctimes+8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{8 \times 8}" class="latex" /> or <img src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3 \times 3 \times 3}" class="latex" /> universe. Not to mention doing her own stunning <a href="https://www.jessicafridrich.com/">photo art</a> of the American Southwest.</p>
<p></p><h2> Quicker Times and Cubes </h2><p></p>
<p>
Since 2003, the <a href="https://en.wikipedia.org/wiki/Speedcubing#Competitions">championships</a> have been held every other year, thought the 2021 championships set for the Netherlands are uncertain owing to the pandemic. The youngsters soon broke through en-masse, and it strikes me that the cube technology improved so that the cubes are springier and lighter. The winning time fell almost 5 seconds to <b>15.10</b> in 2005 and hit <b>6.74</b> in 2019. That was not the world record, however—an incredible <b>3.47</b> seconds in 2018 by Yusheng Du, beating the previous record of Feliks Zemdegs by a whopping 3/4 of a second.</p>
<p>
Fridrich, however, must claim a distinction no one may ever match. She learned how to solve the cube and traced out the performance of methods of doing so in 1981, months before she saw a cube, let alone owned one. Despite the “Bűvös Kocka” (“Magic Cube,” as Rubik called it) having been on shelves in neighboring Hungary for four years, with worldwide marketing by early 1980, they were hard to come by in her home city, Ostrava. </p>
<p>
She found an article on solving the cube in a Russian magazine. It laid out the concept of group theory and the role of group commutators, which she learned to apply creatively in order to streamline actions. The first time she touched a cube was to help a friend put his back the way it was. A family visiting from France let her keep one, and later in 1981 she was finally able to purchase a few more. This invites analogy to working out chess without a board on a bedroom ceiling as depicted in <em>The Queen’s Gambit</em>.</p>
<p>
We—Dick and Ken—must admit that neither of us has ever done this with the cubes we own, not fast, not slow. Yet we do understand the theory behind it. We believe we do. </p>
<p></p><h2> Group Theory of the Cube </h2><p></p>
<p>
I (Dick) plan on explaining the theory by using a new toy that I have invented: The <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathit%7Bslider%7D%5E%7BTM%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathit{slider}^{TM}}" class="latex" />. 	</p>
<p><a href="https://rjlipton.files.wordpress.com/2021/03/slidercubes.png"><img width="96" alt="" src="https://rjlipton.files.wordpress.com/2021/03/slidercubes.png?w=96&amp;h=45" class="aligncenter wp-image-18247" height="45" /></a></p>
<p>
We will write the state as <img src="https://s0.wp.com/latex.php?latex=%7Bxyz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{xyz}" class="latex" /> where each of <img src="https://s0.wp.com/latex.php?latex=%7Bx%2Cy%2Cz%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{x,y,z}" class="latex" /> is one of <font color="red">1</font>, <font color="green">2</font>, or <font color="blue">3</font>. The operations allowed are the <i>cyclic shift</i> <img src="https://s0.wp.com/latex.php?latex=%7BC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{C}" class="latex" />, which does 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++xyz+%5Crightarrow+zxy%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  xyz \rightarrow zxy, " class="latex" /></p>
<p>and the <i>flip</i> <img src="https://s0.wp.com/latex.php?latex=%7BF%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{F}" class="latex" /> of the initial two elements: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++xyz+%5Crightarrow+yxz.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  xyz \rightarrow yxz. " class="latex" /></p>
<p>
Note there are 6 possible states. For the real Rubik’s cube, the number of states is just a little bit larger: <b>43,252,003,274,489,856,000</b>. But the basic concept is the same. Suppose we are given the state 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++132.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  132. " class="latex" /></p>
<p>How fast can you get the initial state <img src="https://s0.wp.com/latex.php?latex=%7B123%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{123}" class="latex" />? Apply <img src="https://s0.wp.com/latex.php?latex=%7BFCC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{FCC}" class="latex" />: 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++132+%5Crightarrow+312+%5Crightarrow+231+%5Crightarrow+123+.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  132 \rightarrow 312 \rightarrow 231 \rightarrow 123 . " class="latex" /></p>
<p>
This is a special case of the general <a href="https://kconrad.math.uconn.edu/blurbs/grouptheory/genset.pdf">result</a> that any symmetric group is <a href="https://groupprops.subwiki.org/wiki/Symmetric_group_on_a_finite_set_is_2-generated">generated</a> by two operations: a full cycle and a single flip. The key with the actual Rubik’s cube is since the group is larger and it has more operations that can be applied finding the group operations may be more difficult. But there are algorithms that can find them. See <a href="https://kconrad.math.uconn.edu/blurbs/grouptheory/gpaction.pdf">this</a> for another article by Keith Conrad. </p>
<p>
There are many more pages like that on the cube. But Fridrich still shows the <a href="http://www.ws.binghamton.edu/fridrich/system.html">seminal page</a> she posted in “Winter 1996/97.” It links to other pages, ones that also credit other people, such as <a href="http://www.ws.binghamton.edu/fridrich/Mike/middle.html">this</a> explaining the algorithms in great pictorial detail. This was in the infancy of the Internet. Her pages are often credited with spurring the turn-of-the-millennium boom in Rubik’s cube which led to the revival of the championships in 2003. A 2016 New York Post <a href="https://nypost.com/2016/10/31/how-the-internet-brought-the-rubiks-cube-back-to-life/">article</a> whose URL is titled, “how the Internet brought the Rubik’s cube back to life,” says: </p>
<blockquote><p><b> </b> <em> The seeds for Rubik’s Cube’s rediscovery were sown on the internet. In the mid-1990s, a Rubik’s Cube champion-turned-computer-science professor at SUNY Binghamton posted her secrets of the Cube on a primitive Web 1.0 site on the university’s servers. Jessica Fridrich’s method spread and is today the most widely used technique to solve the puzzle. </em>
</p></blockquote>
<p>
See also this <a href="https://uncletyson.wordpress.com/tag/dan-knights/">telling</a> by the 2003 winner, Dan Knights. This shows how one person using spare time on the Internet can power up business.</p>
<p></p><h2> Enter the WSJ </h2><p></p>
<p>
The WSJ has had an interest in Rubik’s cube for years. They had a long feature <a href="https://www.wsj.com/articles/how-to-teach-professors-humility-hand-them-a-rubiks-cube-11614352261">article</a> last week titled, “How to Teach Professors Humility? Hand Them a Rubik’s Cube,” by Melissa Korn. It describes a faculty development challenge among several small colleges in which professors became students again. Last month they also had an <a href="https://www.wsj.com/articles/seeing-things-with-the-power-of-symmetry-11612461325">article</a> on symmetry by the mathematician Eugenia Cheng that mentioned the cube.</p>
<p>
I recall several features the WSJ has run on the cube and its solvers. The 2011 <a href="https://www.wsj.com/articles/SB10001424052970204319004577088513615125328">article</a>, “One Cube, Many Knockoffs, Quintillions of Possibilities,” led off with the Polish teenager Michal Pleskowicz winning the 2011 world championship with a time of <b>8.65</b> seconds, then discussed the performance of pirated cubes: “One reason Mr. Pleskowicz and a new generation of Rubik’s fanatics can solve the notoriously difficult puzzle in record time: They don’t use Rubik’s Cubes at all, instead substituting souped-up Chinese knockoffs engineered for speed…” Their 2014 <a href="https://www.wsj.com/articles/SB10001424052702304518704579523513594900696">article</a>, “Rubik’s Cube Proves It’s Hip to Be Square,” profiled both Rubik and speed-solvers. </p>
<p>
The <a href="https://www.wsj.com/articles/a-thinking-persons-guide-to-the-rubiks-cube-1517586702">feature</a> I recall best was in 2018. It was titled, “A Thinking Person’s Guide to the Rubik’s Cube,” and subtitled, “What’s the best solution method—theory, algorithms or chance?” It was also by Eugenia Cheng. She begins by confessing, “I have always loved playing with a Rubik’s Cube, which combines logic with a satisfying tactile activity. I can solve it—getting each of the six sides to be one color—but not particularly quickly or cleverly.” </p>
<p>
They also like its use for analogies. Scrolling through their advanced search—both Ken and I subscribe to the WSJ—we find:</p>
<ul>
<li><a href="https://www.wsj.com/articles/close-reopen-repeat-restaurants-dont-know-what-covid-19-will-dish-out-next-11613138412">2/12/21</a>: “Running restaurants is now ‘a bit of a Rubik’s Cube,’ said Mr. Mosier, who reopened his casual cafes in late January.”
</li><li><a href="https://www.wsj.com/articles/reopening-schools-is-so-complicated-new-york-struggles-to-schedule-classes-11597939473">8/20/20</a>, headline: “Reopening Schools Is So Complicated, New York Is Struggling to Schedule Classes Nation’s largest district is still hashing out basic details about the school day; ‘a multidimensional Rubik’s Cube’ of challenges.”
</li><li><a href="https://www.wsj.com/articles/new-u-s-rules-on-foreign-students-put-universitiesin-dilemma-11594149280">7/7/20</a>: “The new [pandemic] rules have created a Rubik’s Cube of decisions for schools, which face unique challenges with each of their international student populations.”
</li><li><a href="https://www.wsj.com/articles/an-l-a-home-asking-62-million-includes-a-playful-perk-a-model-racetrack-11590523214">5/26/20</a>, about a home selling for $62 million: “Designed by Seattle-based architecture firm Olson Kundig, the house has interlocking boxes and planes resembling a Rubik’s cube…”
</li><li><a href="https://www.wsj.com/articles/president-trump-announces-19-billion-relief-program-for-farmers-11587165759">4/17/20</a>, quoting Agriculture Secretary Sonny Perdue on the coronavirus relief program for farmers: “It will be a logistical Rubik’s Cube.”
</li><li><a href="https://www.wsj.com/articles/he-wanted-something-more-from-retirement-so-he-got-three-jobs-11573743922">11/14/19</a>, about a retiree who started teaching business classes, keeping books for a non-profit business, and working on a ferry dock: “My society consists of able-bodied seamen, boat captains, truckers hauling bait and lobsters, fishermen, islanders and wide-eyed vacationers,” says Mr. Marshall. It’s “a constant Rubik’s cube. You never know what you’ll find.”
</li></ul>
<p>
In all, using the WSJ advanced search, we find 239 hits for “Rubik” going back to 1980. We should mention in-passing that one of them is their 7/17/20 <a href="https://www.wsj.com/articles/ron-graham-dazzled-admirers-with-math-and-juggling-feats-11594994403">obituary</a> for Ron Graham. We also find 7 hits for “Fridrich” over the same span. But they are all about the housing market, involving the Nashville-based realty Fridrich and Clarke.</p>
<p></p><h2> Open Problems </h2><p></p>
<p>
I am happy to see that the WSJ has published multiple articles on a particular algorithmic task. I like that algorithms have been the center of articles. I wish they would talk more about important algorithms. Solving a Rubik’s cube is not an algorithm that is used every day: What about: </p>
<ul>
<li>Sorting
</li><li>Searching
</li><li>Dynamic Programming
</li><li>Fast Arithmetic
</li></ul>
<p>They do have Eugenia Cheng, who wrote a <a href="https://www.wsj.com/articles/algorithms-arent-just-for-computers-11557407055">column</a> comparing sorting algorithms. And they have written on algorithms used in <a href="https://www.wsj.com/graphics/journey-inside-a-real-life-trading-algorithm/">trading</a> and on <a href="https://www.wsj.com/articles/social-media-algorithms-rule-how-we-see-the-world-good-luck-trying-to-stop-them-11610884800">social</a>–<a href="https://www.wsj.com/articles/how-google-interferes-with-its-search-algorithms-and-changes-your-results-11573823753">media</a> <a href="https://www.wsj.com/articles/how-to-win-friends-and-influence-algorithms-11555246800">platforms</a> and for <a href="https://www.wsj.com/articles/algorithms-used-in-policing-face-policy-review-11591003801">policing</a> and <a href="https://www.wsj.com/articles/SB10001424052702304626104579121251595240852">parole</a> and <a href="https://www.wsj.com/articles/algorithm-helps-new-york-decide-who-goes-free-before-trial-11600610400">bail</a> decisions. But that tends away from <em>fundamental algorithms</em> where the math is the matter.</p>
<p>
A 2018 WSJ <a href="https://www.wsj.com/articles/dont-believe-the-algorithm-1536157620">article</a> by Hannah Fry titled “Don’t Believe the Algorithm,” which begins with flaws in using facial recognition to find wanted suspects, brings us back toward Fridrich’s research. Might this all also raise discussion of “algorithms” for what and whom to cover?</p>
<p>
[fixed name at end]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2021/03/04/wsj-meets-group-algorithms/"><span class="datestr">at March 05, 2021 12:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=5359">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=5359">The Zen Anti-Interpretation of Quantum Mechanics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>As I lay bedridden this week, knocked out by my second dose of the Moderna vaccine, I decided I should blog some more half-baked ideas because what the hell?  It feels therapeutic, I have tenure, and anyone who doesn’t like it can close their broswer tab.</p>



<p>So: although I’ve written tens of thousands <a href="https://www.pbs.org/wgbh/nova/article/can-quantum-computing-reveal-the-true-meaning-of-quantum-mechanics/">of</a> <a href="https://arxiv.org/abs/1306.0159">words</a>, <a href="https://www.scottaaronson.com/papers/philos.pdf">on</a> <a href="https://www.scottaaronson.com/blog/?p=1103">this</a> <a href="https://www.scottaaronson.com/blog/?p=3628">blog</a> <a href="https://www.scottaaronson.com/democritus/">and</a> <a href="https://www.scottaaronson.com/qclec.pdf">elsewhere</a>, about interpretations of quantum mechanics, again and again I’ve dodged the question of which interpretation (if any) I <em>really believe myself</em>.  Today, at last, I’ll emerge from the shadows and tell you precisely where I stand.</p>



<p>I hold that all interpretations of QM are just crutches that are better or worse at helping you along to the Zen realization that <strong>QM is what it is and doesn’t need an interpretation</strong>.  As Sidney Coleman <a href="https://arxiv.org/abs/2011.12671">famously argued</a>, what needs reinterpretation is not QM itself, but all our <em>pre</em>-quantum philosophical baggage—the baggage that leads us to demand, for example, that a wavefunction |ψ⟩ either be “real” like a stubbed toe or else “unreal” like a dream.  Crucially, because this philosophical baggage differs somewhat from person to person, the “best” interpretation—meaning, the one that leads most quickly to the desired Zen state—can also differ from person to person.  Meanwhile, though, thousands of physicists (and chemists, mathematicians, quantum computer scientists, etc.) have approached the Zen state merely by spending decades working with QM, never worrying much about interpretations at all.  This is probably the truest path; it’s just that most people lack the inclination, ability, or time.</p>



<p>Greg Kuperberg, one of the smartest people I know, once told me that the problem with the Many-Worlds Interpretation is not that it says anything wrong, but only that it’s “melodramatic” and “overwritten.”  Greg is far along the Zen path, probably further than me.</p>



<p>You shouldn’t confuse the Zen Anti-Interpretation with “Shut Up And Calculate.”  The latter phrase, mistakenly attributed to Feynman but really due to David Mermin, is something one might say at the <em>beginning</em> of the path, when one is as a baby.  I’m talking here only about the <em>endpoint</em> of path, which one can approach but never reach—the endpoint where you intuitively understand exactly what a Many-Worlder, Copenhagenist, or Bohmian would say about any given issue, and also how they’d respond to each other, and how they’d respond to the responses, etc. but after years of study and effort you’ve <em>returned</em> to the situation of the baby, who just sees the thing for what it is.</p>



<p>I don’t mean to say that the interpretations are all interchangeable, or equally good or bad.  If you had to, you could call even me a “Many-Worlder,” but <em>only</em> in the following limited sense: that in fifteen years of teaching quantum information, my experience has consistently been that for <em>most</em> students, <a href="https://en.wikipedia.org/wiki/Many-worlds_interpretation">Everett’s crutch</a> is the best one currently on the market.  At any rate, it’s the one that’s the most like a straightforward <em>picture</em> of the equations, and the least like a wobbly tower of words that might collapse if you utter any wrong ones.  Unlike Bohr, Everett will never make you feel stupid for asking the questions an inquisitive child would ask; he’ll simply give you answers that are as clear, logical, and internally consistent as they are metaphysically extravagant.  That’s a start.</p>



<p>The <a href="https://en.wikipedia.org/wiki/Copenhagen_interpretation">Copenhagen Interpretation</a> retains a place of honor as the <em>first</em> crutch, for decades the <em>only</em> crutch, and the one closest to the spirit of positivism.  Unfortunately, <em>wielding</em> the Copenhagen crutch requires mad philosophical skillz—which parts of the universe should you temporarily regard as “classical”?  which questions should be answered, and which deflected?—to the point where, if you’re capable of all that verbal footwork, then why do you even <em>need</em> a crutch in the first place?  In the hands of amateurs—meaning, alas, nearly everyone—Copenhagen often leads <em>away</em> <em>from</em> rather than toward the Zen state, as one sees with the generations of New-Age bastardizations about “observations creating reality.”</p>



<p>As for <a href="https://en.wikipedia.org/wiki/De_Broglie%E2%80%93Bohm_theory">deBroglie-Bohm</a>—well, that’s a weird, interesting, baroque crutch, one whose actual details (the preferred basis and the guiding equation) are historically contingent and tied to specific physical systems.  It’s probably the right crutch for <em>someone</em>—it gets eternal credit for having led Bell to discover the Bell inequality—but its quirks definitely need to be discarded along the way.</p>



<p>Note that, among those who approach the Zen state, many might still call themselves Many-Worlders or Copenhagenists or Bohmians or whatever—just as those far along in spiritual enlightenment might still call themselves Buddhists or Catholics or Muslims or Jews (or atheists or agnostics)—even though, by that point, they might have more in common with each other than they do with their supposed coreligionists or co-irreligionists.</p>



<p>Alright, but isn’t all this Zen stuff just a way to dodge the <em>actual, substantive</em> questions about QM, by cheaply claiming to have transcended them?  If that’s your charge, then please help yourself to the following FAQ about the details of the Zen Anti-Interpretation.</p>



<ol><li><strong>What is a quantum state?</strong>  It’s a unit vector of complex numbers (or if we’re talking about mixed states, then a trace-1, Hermitian, positive semidefinite matrix), which encodes everything there is to know about a physical system.<br /></li><li><strong>OK, but are the quantum states “ontic” (really out in the world), or “epistemic” (only in our heads)?</strong>  Dude.  Do “basketball games” really exist, or is that just a phrase we use to summarize our knowledge about certain large agglomerations of interacting quarks and leptons?  Do even the “quarks” and “leptons” exist, or are those just words for excitations of the more fundamental fields?  Does “jealousy” exist?  Pretty much<em> all</em> our concepts are complicated grab bags of “ontic” and “epistemic,” so it shouldn’t surprise us if quantum states are too.  Bad dichotomy.<br /></li><li><strong>Why are there probabilities in QM?</strong>  Because QM <em>is</em> a (the?) generalization of probability theory to involve complex numbers, whose squared absolute values are probabilities.  It <em>includes</em> probability as a special case.<br /></li><li><strong>But why do the probabilities obey the Born rule?</strong>  Because, once the unitary part of QM has picked out the 2-norm as being special, for the probabilities <em>also</em> to be governed by the 2-norm is pretty much the only possibility that makes mathematical sense; there are many nice theorems formalizing that intuition under reasonable assumptions.<br /></li><li><strong>What is an “observer”?</strong>  It’s exactly what modern decoherence theory says it is: a particular kind of quantum system that interacts with other quantum systems, becomes entangled with them, and thereby records information about them—reversibly in principle but irreversibly in practice.<br /></li><li><strong>Can observers be manipulated in coherent superposition, as in the <a href="https://en.wikipedia.org/wiki/Wigner%27s_friend">Wigner’s Friend</a> scenario?</strong>  If so, they’d be radically unlike any physical system we’ve ever had direct experience with.  So, are you asking whether such “observers” would be <em>conscious</em>, or if so what they’d be conscious of?  Who the hell knows?<br /></li><li><strong>Do “other” branches of the wavefunction—ones, for example, where my life took a different course—exist in the same sense this one does?</strong>  If you start with a quantum state for the early universe and then time-evolve it forward, then yes, you’ll get not only “our” branch but also a proliferation of other branches, in the overwhelming majority of which Donald Trump was never president and civilization didn’t grind to a halt because of a bat near Wuhan.  But how could we possibly know whether anything “breathes fire” into the other branches and makes them real, when we have no idea what breathes fire into <em>this</em> branch and makes <em>it</em> real?  This is not a dodge—it’s just that a simple “yes” or “no” would fail to do justice to the enormity of such a question, which is above the pay grade of physics as it currently exists. <br /></li><li><strong>Is this it?  Have you brought me to the end of the path of understanding QM?</strong>  No, I’ve just pointed the way toward the <em>beginning</em> of the path.  The most fundamental tenet of the Zen Anti-Interpretation is that there’s no shortcut to actually <a href="https://www.scottaaronson.com/qclec.pdf">working</a> <a href="https://www.amazon.com/Quantum-Mechanics-Theoretical-Leonard-Susskind/dp/0465062903/ref=asc_df_0465062903/?tag=hyprod-20&amp;linkCode=df0&amp;hvadid=312014159412&amp;hvpos=&amp;hvnetw=g&amp;hvrand=7852945785672685485&amp;hvpone=&amp;hvptwo=&amp;hvqmt=&amp;hvdev=c&amp;hvdvcmdl=&amp;hvlocint=&amp;hvlocphy=9028280&amp;hvtargid=pla-435140302691&amp;psc=1">through</a> the Bell inequality, quantum teleportation, Shor’s algorithm, the Kochen-Specker and PBR theorems, possibly even a … <em>photon</em> or a <em>hydrogen atom</em>, so you can see quantum probability in action and be enlightened.  I’m further along the path than I was twenty years ago, but not as far along as some of my colleagues.  Even the greatest quantum Zen masters will be able to get further when new quantum phenomena and protocols are discovered in the future.  All the same, though—and this is another major teaching of the Zen Anti-Interpretation—there’s more to life than achieving greater and greater clarity about the foundations of QM.  And on that note…</li></ol>



<p>To those who asked me about Claus Peter Schnorr’s <a href="https://eprint.iacr.org/2021/232">claim</a> to have discovered a fast <em>classical</em> factoring algorithm, thereby “destroying” (in his words) the RSA cryptosystem, see (e.g.) <a href="https://twitter.com/inf_0_/status/1367376526300172288?fbclid=IwAR19Ip7XyoPjHfm9WBzqiUkQpxUVLGfVTgLGQmmncgrkUsvcLIrkzbOPw_U">this Twitter thread by Keegan Ryan</a>, which explains what certainly <em>looks</em> like a fatal error in Schnorr’s paper.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=5359"><span class="datestr">at March 04, 2021 11:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2021-03-03-2-round-bft-smr-with-n-equals-4-f-equals-1/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2021-03-03-2-round-bft-smr-with-n-equals-4-f-equals-1/">2-round BFT SMR with n=4, f=1</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Guest post by Zhuolun Xiang In the previous post, we presented a summary of our good-case latency results for Byzantine broadcast and Byzantine fault tolerant state machine replication (BFT SMR), where the good case measures the latency to commit given that the leader/broadcaster is honest. In this post, we describe...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2021-03-03-2-round-bft-smr-with-n-equals-4-f-equals-1/"><span class="datestr">at March 03, 2021 11:37 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/030">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/030">TR21-030 |  Hardness of Constant-round Communication Complexity | 

	Rahul Ilango, 

	Shuichi Hirahara, 

	Bruno Loff</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
How difficult is it to compute the communication complexity of a two-argument total Boolean function $f:[N]\times[N]\to\{0,1\}$, when it is given as an $N\times N$ binary matrix? In 2009, Kushilevitz and Weinreb showed that this problem is cryptographically hard, but it is still open whether it is NP-hard. 

In this work, we show that it is NP-hard to approximate the size (number of leaves) of the smallest constant-round protocol for a two-argument total Boolean function $f:[N]\times[N]\to\{0,1\}$, when it is given as an $N\times N$ binary matrix. Along the way to proving this, we show a new *deterministic* variant of the round elimination lemma, which may be of independent interest.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/030"><span class="datestr">at March 02, 2021 09:31 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/03/02/faculty-at-universidad-catolica-de-chile-apply-by-april-10-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/03/02/faculty-at-universidad-catolica-de-chile-apply-by-april-10-2021/">Faculty at Universidad Católica de Chile (apply by April 10, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Institute for Mathematical and Computational Engineering at Universidad Católica de Chile offers one or more full-time positions. We invite applications from candidates in the areas of Data Science, Machine Learning, Optimization, Statistics and Stochastic, although other areas from Computational Science and Engineering, Optimization and Applied Mathematics will also be considered.</p>
<p>Website: <a href="http://imc.uc.cl/index.php/noticias/183-open-position-at-the-institute-for-mathematical-and-computational-engineering-uc">http://imc.uc.cl/index.php/noticias/183-open-position-at-the-institute-for-mathematical-and-computational-engineering-uc</a><br />
Email: pbarcelo@uc.cl</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/03/02/faculty-at-universidad-catolica-de-chile-apply-by-april-10-2021/"><span class="datestr">at March 02, 2021 03:50 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://theorydish.blog/?p=1842">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/theorydish.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://theorydish.blog/2021/03/02/automated-design-of-error-correcting-codes-part-1/">Automated Design of Error-Correcting Codes, Part 1</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p><strong>Introduction. </strong>For nearly a century, error-correcting codes (ECCs) have been used for allowing communication even when the used communication channel is corrupted by noise. Beyond communication, error-correcting codes have found a variety of other uses, from<a href="https://en.wikipedia.org/wiki/Multiclass_classification"> multiclass learning</a> to even <a href="https://arxiv.org/pdf/1002.3864.pdf">showing hardness of approximation</a>. As such, understanding the rich world of error-correcting codes is essential for progress in all of these domains.</p>



<p>In our setting, imagine Alice wants to send a message to Bob of length <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k" class="latex" />, but the channel between them is corrupted by noise. To overcome this, Alice uses an <em>encoder</em> to turn her message into a longer, redundant string of length <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="n" class="latex" />. Then, Bob receives this transmission and uses a <em>decoder</em> to (hopefully) recover the original message of length <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k" class="latex" />. Two important properties are the <em>rate</em> <img src="https://s0.wp.com/latex.php?latex=k%2Fn&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k/n" class="latex" /> of the code (essentially what fraction of the transmission is “information”) and the <em>bit error rate (BER)</em> which is the (expected) number of decoding errors divided by <img src="https://s0.wp.com/latex.php?latex=k&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k" class="latex" />. Desirable properties are to make the rate as large as possible and the BER as small as possible.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="526" alt="" src="https://lh3.googleusercontent.com/9y96GkfFf6FBCUKoufmsqUGfXt7VmrDqAuCQI1IaOfy4DB-VmJWEvSwL9c1mj9QP9gVYq49haRBI96eNMx5qPpr3BFhhGuWvTv4wixNbLLuTuSnI3xv36xaVa64D3DvshMs_XwmT" height="353" /></figure></div>



<p class="has-text-align-center">Basic ECC paradigm.</p>



<p>Since the days of <a href="https://en.wikipedia.org/wiki/Claude_Shannon">Claude Shannon</a>, many error-correcting codes have been discovered, such as <a href="https://en.wikipedia.org/wiki/Reed%E2%80%93Solomon_error_correction">Reed-Solomon codes</a> and <a href="https://en.wikipedia.org/wiki/BCH_code">BCH codes</a>. Each error-correcting code has its own tradeoffs (e.g., some have higher rate, some are more resistant to special kinds of channel corruptions, etc.). With the large number of ECCs which have been discovered, it can sometimes be overwhelming what the proper error correcting code is for a given application. Further, if the application is sufficiently specialized there may be <em>no </em>known ECC which meets your needs. Such concerns motivate the <em>automation</em> <em>of error correcting codes</em>, which is the main topic of this blog post. </p>



<p>I’m using the word “automation” to cover a variety of tasks which various computational methods could assist with in the study of ECCs:</p>



<ol><li>Existence — Does the code I want even exist?</li><li>Encoding — What is the “best” way to convert my messages into a code?</li><li>Decoding — How do I recover from noisy transmissions?</li><li>Verification — Is the proposed ECC design provably correct?</li><li>Selection — Which ECC from a given class should I use for a given application?</li></ol>



<p>Each of these facets of the automation of ECCs is a whole field of research! In this and the subsequent post, I will discuss at a high level two types of techniques which have been used to approach these questions: “Formal Methods” and “Machine Learning.” We’ll cover formal methods in this post, and in the next post we will cover machine learning methods.</p>



<p><strong>Formal Methods. </strong>The field of Formal Methods strives to give <em>provable guarantees</em> for various computational questions by reducing them to formal logic. Although formal methods are mostly used for software and hardware verification (that is, making sure they are “bug free”), such tools are also used by mathematicians to show the validity of mathematical statements that would be difficult to prove by hand. For example, the <a href="https://en.wikipedia.org/wiki/Kepler%27s_conjecture">Kepler conjecture</a>, a question of what is the best way to pack spheres in three dimensions–essentially finding an optimal error-correcting code in Euclidean space–was only firmly proved by <a href="https://github.com/flyspeck/flyspeck">Thomas Hales and his team</a> through the use of automated theorem-proving tools.</p>



<p>A line of work for using formal methods to directly construct practical ECCs was initiated by <a href="https://ieeexplore.ieee.org/abstract/document/5699220">Shamshiri and Cheng</a> in 2010. In their work, they are motivated by designing error-correcting codes for static random-access memory (SRAM), the kind that is often used for CPU caches. When using SRAM (pictured below), a worry is that cosmic rays could hit some of the bits, causing them to flip. Further, it is not uncommon for a group of consecutive bits to flip. As such, it is desirable to esure that the error correcting code can correct either <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="g" class="latex" /> <em>global </em>errors or <img src="https://s0.wp.com/latex.php?latex=l&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="l" class="latex" /> <em>local</em> errors. Correcting global errors is a common property of error correcting codes, such as BCH codes or the <a href="https://en.wikipedia.org/wiki/Binary_Golay_code">Golay code</a>. However, local error correction is a much less common property to guarantee. Thus, the authors use a <em>SAT solver</em> to construct error correcting codes with the properties they desire.</p>



<div class="wp-block-image"><figure class="aligncenter is-resized"><img width="529" alt="" src="https://lh4.googleusercontent.com/qQRzeu2F2XzrjAl6DyPPWAnBVOKOSODIBX4RPBuz0aAMqErYxC2ZyAbtWy3z8ORU4rvMT9UEMI8-C7boHeKEijFwrKY2pRaneEm1lsAoKBUHpQQ1rcMpaLBZs8zAwr2yviMGJPyG" height="318" /></figure></div>



<p class="has-text-align-center">Static random-access memory (source: <a href="https://en.wikipedia.org/wiki/File:Hyundai_RAM_HY6116AP-10.jpg" rel="prettyphoto">Wikipedia</a>)</p>



<p>Assuming that the code to be construction is linear (the encoding map is a linear function over the field <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+F_2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbb F_2" class="latex" />), then the error correcting code can be described by a <a href="https://en.wikipedia.org/wiki/Parity-check_matrix">parity check matrix</a> M in <img src="https://s0.wp.com/latex.php?latex=%7B0%2C1%7D%5E%7B%28n-k%29+%5Ctimes+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0,1}^{(n-k) \times n}" class="latex" />. The key observation the authors make is that for M to be a proper error correcting code, every error pattern <img src="https://s0.wp.com/latex.php?latex=p&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="p" class="latex" /> (i.e., vectors with hamming weight at most <img src="https://s0.wp.com/latex.php?latex=g&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="g" class="latex" /> or consecutive errors in a block of length <img src="https://s0.wp.com/latex.php?latex=l&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="l" class="latex" />) must have <img src="https://s0.wp.com/latex.php?latex=Mp&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="Mp" class="latex" /> be a distinct vector. For instance  <img src="https://s0.wp.com/latex.php?latex=M%280%2C+1%2C+0%2C+0%2C+1%29+%5Cneq+M%281%2C1%2C1%2C0%2C0%29&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="M(0, 1, 0, 0, 1) \neq M(1,1,1,0,0)" class="latex" /> if <img src="https://s0.wp.com/latex.php?latex=g+%3D+2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="g = 2" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=l+%3D+3&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="l = 3" class="latex" />.</p>



<p>These Boolean constraints can be expressed in conjunctive normal form, i.e., a SAT instance. As such a SAT-solver can be used to determine if there exists a matrix M with the given properties for a given k and n. For instance, they are able to find an error correcting code with parameters <img src="https://s0.wp.com/latex.php?latex=k+%3D+16%2C+n+%3D+26%2C+g+%3D+2&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="k = 16, n = 26, g = 2" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=l+%3D+4&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="l = 4" class="latex" />. In their follow-up work [<a href="https://ieeexplore.ieee.org/abstract/document/6139156">Shamshi, Ghofrani, Cheng, 2011]</a>, they use this error-correcting code for modeling an “on-chip network” between CPU cores in a multi-core processor<strong>.</strong></p>



<p>Another line of work led by Ben Curtis (see the <a href="https://cs.uwaterloo.ca/~cbright/reports/cacm-preprint.pdf">survey by Curtis, Kotsireas, and Ganesh</a>) has been seeking to construct ECC-like combinatorial objects. An example of such an object is a Hadamard matrix: a square matrix with <img src="https://s0.wp.com/latex.php?latex=%5Cpm+1&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\pm 1" class="latex" /> entries such that every row and column is orthogonal in <img src="https://s0.wp.com/latex.php?latex=%5Cmathbb+R%5En&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\mathbb R^n" class="latex" />. In fact, the authors search for a special type of Hadamard matrix made up of a quartet Williamson matrices which have an intricate algebraic structure. They find these objects by using an algorithm which goes back-and-forth between a SAT solver with a CAS (computer algebraic system) to help narrow the search space. </p>



<p>Formal Methods have further applications in error-correcting codes for <a href="https://ieeexplore.ieee.org/abstract/document/6649704">distributed cloud storage</a> and <a href="https://arxiv.org/pdf/1804.02317.pdf">value-deviation-bounded codes</a>.</p>



<p>This concludes our first post. In the next post, we will cover machine learning methods. </p>



<p>Are you aware of other examples or applications of automation to error-correcting codes? If so, please leave a comment.</p>



<p><strong>Acknowledgments. </strong>I would like to thank my quals committee, Aviad Rubinstein, Moses Charikar, and Mary Wootters for valuable feedback. </p></div>







<p class="date">
by jbrakensiek <a href="https://theorydish.blog/2021/03/02/automated-design-of-error-correcting-codes-part-1/"><span class="datestr">at March 02, 2021 03:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/03/01/associate-professor-at-kth-royal-institute-of-technology-apply-by-april-15-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/03/01/associate-professor-at-kth-royal-institute-of-technology-apply-by-april-15-2021/">Associate professor at KTH Royal Institute of Technology (apply by April 15, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>KTH Royal Institute of Technology, School of Electrical Engineering and Computer Science has a vacancy for one Associate Professor with specialization in Foundations of Data Science. The position will be permanent and full time, to start as soon as possible.</p>
<p>Website: <a href="https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:366029/where:4/">https://www.kth.se/en/om/work-at-kth/lediga-jobb/what:job/jobID:366029/where:4/</a><br />
Email: tenuretrack@eecs.kth.se</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/03/01/associate-professor-at-kth-royal-institute-of-technology-apply-by-april-15-2021/"><span class="datestr">at March 01, 2021 09:54 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/029">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/029">TR21-029 |  Public-Coin Statistical Zero-Knowledge Batch Verification against Malicious Verifiers | 

	Inbar Kaslasi, 

	Ron Rothblum, 

	Prashant Nalini Vasudevan</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Suppose that a problem $\Pi$ has a statistical zero-knowledge (SZK) proof with communication complexity $m$. The question of batch verification for SZK asks whether one can prove that $k$ instances $x_1,\ldots,x_k$ all belong to $\Pi$ with a statistical zero-knowledge proof whose communication complexity is better than $k \cdot m$ (which is the complexity of the trivial solution of executing the original protocol independently on each input).

In a recent work, Kaslasi et al. (TCC, 2020) constructed such a batch verification protocol for any problem having a non-interactive SZK (NISZK) proof-system. Two drawbacks of their result are that their protocol is private-coin and is only zero-knowledge with respect to the honest verifier.

In this work, we eliminate these two drawbacks by constructing a public-coin malicious-verifier SZK protocol for batch verification of NISZK. Similarly to the aforementioned prior work, the communication complexity of our protocol is $\big(k+poly(m) \big) \cdot polylog(k,m)$</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/029"><span class="datestr">at March 01, 2021 04:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://offconvex.github.io/2021/03/01/beyondlogconcave2/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/convex.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="http://offconvex.github.io/2021/03/01/beyondlogconcave2/">Beyond log-concave sampling (Part 2)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In our previous <a href="http://www.offconvex.org/2020/09/19/beyondlogconvavesampling">blog post</a>, we introduced the challenges of sampling distributions beyond log-concavity. 
We first introduced the problem of sampling from a distibution $p(x) \propto e^{-f(x)}$ given value or gradient oracle access to $f$, as an analogous problem to black-box optimization with oracle access. We introduced the natural algorithm for sampling in this setup: Langevin Monte Carlo, a Markov Chain reminiscent of noisy gradient descent,</p>

\[x_{t+\eta} = x_t - \eta \nabla f(x_t) + \sqrt{2\eta}\xi_t,\quad \xi_t\sim N(0,I).\]

<p>Finally, we laid out the challenges when $f$ is not convex; in particular, LMC can suffer from slow mixing.</p>

<p>In this and the coming post, we describe two of our recent works tackling this problem. We identify two kinds of structure beyond log-concavity under which we can design provably efficient algorithms:  <em>multi-modality</em> and <em>manifold structure in the level sets</em>. These structures commonly occur in practice, especially in problems involving statistical inference and posterior sampling in generative models.</p>

<p>In this post, we will focus on multimodality, covered by the paper <a href="https://arxiv.org/abs/1812.00793">Simulated tempering Langevin Monte Carlo</a> by Rong Ge, Holden Lee, and Andrej Risteski.</p>

<h1 id="sampling-multimodal-distributions-with-simulated-tempering">Sampling multimodal distributions with simulated tempering</h1>

<p>The classical scenario in which Langevin takes exponentially long to mix is when $p$ is a mixture of two well-separated gaussians. In broadest generality, this was considered by <a href="http://www.ems-ph.org/journals/show_abstract.php?issn=1435-9855%20&amp;vol=6&amp;iss=4&amp;rank=1">Bovier et al. 2004</a> who used tools from metastable processes to show that transitioning from one peak to another can take exponential time. Roughly speaking, they show the transition time is proportional to the “energy barrier” a particle has to cross. If the gaussians have unit variance and means at distance $2r$, then the probability density at a point midway in between is $\propto e^{-r^2/2}$, and this energy barrier is $\propto e^{r^2/2}$. Thus, the mixing time is exponential. Qualitatively, the intuition for this phenomenon is simple to describe: if started at point A, the drift (i.e. gradient) term will push the walk towards A, so long as it’s close to the basin around A; hence, to transition from A to B (through C) the Gaussian noise must persistenly counteract the gradient term.</p>

<center>
<img width="500" src="http://www.andrew.cmu.edu/user/aristesk/animation_bovier.gif" />
</center>

<p>Hence Langevin on its own will not work even in very simple multimodal settings.</p>

<p>In <a href="https://arxiv.org/abs/1812.00793">our paper</a>, we show that combining Langevin Monte Carlo with a temperature-based heuristic called <em>simulated tempering</em> can significantly speed up mixing for multimodal distributions, where the number of modes is not too large, and the modes “look similar.”</p>

<p>More precisely, we show:</p>

<blockquote>
  <p><strong>Theorem (Ge, Lee, Risteski ‘18, informal)</strong>: If $p(x)$ is a mixture of $k$ shifts of a strongly log-concave distribution in $d$ dimensions (e.g. Gaussian), an algorithm based on simulated tempering and Langevin Monte Carlo that runs in time poly($d,k, 1/\varepsilon$) produces samples from a distribution $\varepsilon$-close to $p$ in total variation distance.</p>
</blockquote>

<p>The main idea is to create a meta-Markov chain (the simulated tempering chain) which has two types of moves: change the current “temperature” of the sample, or move “within” a temperature. The main intuition behind this is that at higher temperatures, the distribution is flatter, so the chain explores the landscape faster (see the figure below).</p>

<center> 
<img src="http://www.andrew.cmu.edu/user/aristesk/animation_tempering.gif" />
</center>

<p>More formally, the distribution at inverse temperature $\beta$ is given by $p_\beta(x) \propto e^{-\beta f(x)}$. The Langevin chain which corresponds to $\beta$ is given by</p>

\[x_{t+\eta} = x_t - \eta \beta \nabla f(x_t) + \sqrt{2\eta}\xi_t,\quad \xi_t\sim N(0,I).\]

<p>As in the figure above, a high temperature (low $\beta&lt;1$) flattens out the distribution and causes the chain to mix faster (top distribution in figure). However, we can’t merely run Langevin at a higher temperature, because the stationary distribution of the high-temperature chain is wrong: it’s $p_\beta(x)$. The idea behind simulated tempering is to run Langevin chains at different temperatures, sometimes swapping to another temperature to help lower-temperature chains explore. To maintain the right stationary distributions at each temperature, we use a Metropolis-Hastings filtering step.</p>

<p>More formally, choosing a suitable sequence $0&lt; \beta_1&lt; \cdots &lt;\beta_L=1$, we define the simulated tempering chain as follows.</p>

<p><img width="300" style="float: right;" src="http://holdenlee.github.io/pics/stl.png" /></p>

<ul>
  <li>The <em>state space</em> is a pair of a temperature and location in space $(i, x), i \in [L], x \in \mathbb{R}^d$.<br />
</li>
  <li>The <em>transitions</em> are defined as follows.
    <ul>
      <li>If the current point is $(i,x)$, then <em>evolve</em> $x$ according to Langevin diffusion with inverse temperature $\beta_i$.</li>
      <li>Propose swaps with some rate $\lambda &gt;0$. Proposing a swap means attempting to move to a neighboring chain, i.e. change $i$ to $i’=i\pm 1$. With probability $\min{p_{i’}(x)/p_i(x), 1}$, the transition is accepted. Otherwise, stay at the same point. This is a <em>Metropolis-Hastings step</em>; its purpose is to preserve the stationary distribution.</li>
    </ul>
  </li>
</ul>

<p>Finally, it’s not too hard to see that at the stationary distribution, the samples at the $L$th level ($\beta_L=1$) are the desired samples.</p>

<h2 id="proof-idea-decomposition-theorem">Proof idea: decomposition theorem</h2>

<p>The main strategy is inspired by Madras and Randall’s <a href="https://www.jstor.org/stable/2699896">Markov chain decomposition theorem</a>, which gives a criterion for a Markov chain to mix rapidly: partition the state space into sets, and show that</p>

<ol>
  <li>The Markov chain mixes rapidly when restricted to each set of the partition.</li>
  <li>The <em>projected</em> Markov Chain, which we define momentarily, mixes rapidly. If there are $m$ sets, the projected chain $\overline M$ is defined on the state space ${1,\ldots, m}$, and transition probabilities are given by average probability flows between the corresponding sets.</li>
</ol>

<p>To implement this strategy, we first have to specify the partition. In fact, we roughly show that there is a partition of $[L] \times \mathbb{R}^d$ in which:</p>

<ol>
  <li>The simulated tempering Langevin chain mixes fast within each of the sets.</li>
  <li>The “volume” of the sets (under the stationary distribution of the tempering chain) is not too small.
</li>
</ol>

<p>In applying the Madras-Randall framework with this partition, it’s clear that point (1) above satisfies requirement (1) for the framework; point (2) ensures that the projected Markov chain has no “bottlenecks” and hence that it mixes rapidly (requirement (2)). More precisely, we can show rapid mixing either through the method of canonical paths or Cheeger’s inequality. To do this, we exhibit a “good-probability” path between any two sets in the partition, going through the highest temperature.</p>

<p>The intuition for why this path works is illustrated in the figure below: when transitioning from the set corresponding to the left mode at level $L$ to the right mode at level $L$, each of the steps up/down the temperatures are accepted with good probability if the neighboring temperatures are not too different; at the highest temperature, the chain mixes fast by point (1), and since each of the sets are not too small by point (2), there is a reasonable probability to end at the right mode at the highest temperature.</p>

<center>
<img src="http://www.andrew.cmu.edu/user/aristesk/animation_conductance.gif" />
</center>



<p>Intuitively, the partition should track the “modes” of the distribution, but a technical hurdle in implementing this plan is in defining the partition when the modes overlap. One can either do this spectrally (i.e. showing that the Langevin chain has a spectral gap, and use theorems about <a href="https://arxiv.org/abs/1309.3223">spectral graph partitioning</a>, as we did in the <a href="https://arxiv.org/abs/1710.02736">first version</a> of the paper), or use a functional “soft decomposition theorem” which is a more flexible version of the classical decomposition theorem, which we use in a <a href="https://arxiv.org/abs/1812.00793">later version</a> of the paper.</p></div>







<p class="date">
<a href="http://offconvex.github.io/2021/03/01/beyondlogconcave2/"><span class="datestr">at March 01, 2021 02:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/03/01/phd-thesis-at-lamsade-paris-dauphine-apply-by-april-30-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/03/01/phd-thesis-at-lamsade-paris-dauphine-apply-by-april-30-2021/">PhD. Thesis at LAMSADE (Paris Dauphine) (apply by April 30, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>PhD. Thesis offer in Paris Dauphine University “Algorithmic aspects of intersection graphs”</p>
<p>Website: <a href="https://www.lamsade.dauphine.fr/fileadmin/mediatheque/lamsade/documents/propositions_theses_2020/murat.pdf">https://www.lamsade.dauphine.fr/fileadmin/mediatheque/lamsade/documents/propositions_theses_2020/murat.pdf</a><br />
Email: florian.sikora@dauphine.fr</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/03/01/phd-thesis-at-lamsade-paris-dauphine-apply-by-april-30-2021/"><span class="datestr">at March 01, 2021 10:35 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2021-02-28-good-case-latency-of-byzantine-broadcast-a-complete-categorization/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2021-02-28-good-case-latency-of-byzantine-broadcast-a-complete-categorization/">Good-case Latency of Byzantine Broadcast: a Complete Categorization</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Guest post by Zhuolun Xiang State Machine Replication and Broadcast Many existing permission blockchains are built using Byzantine fault-tolerant state machine replication (BFT SMR), which ensures all honest replicas agree on the same sequence of client inputs. Most of the practical solutions for BFT SMR are based on the Primary-Backup...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2021-02-28-good-case-latency-of-byzantine-broadcast-a-complete-categorization/"><span class="datestr">at February 28, 2021 06:07 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-5663884325046890461">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/02/using-number-of-phds-as-measure-of.html">Using number-of-PhD's as a measure of smartness is stupid.</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>In <i>Thor:Ragnorak</i> Bruce Banner mentions that he has 7 PhDs. Gee, I wonder how he managed to slip that into a conversation casually.  Later in the movie:</p><p><br /></p><p>Bruce: I don't know how to fly one of those (it an Alien Spacecraft)</p><p>Thor: You're a scientist. Use one of your PhD's </p><p>Bruce: None of them are for flying alien spaceships.</p><p><br /></p><p>On the episode <i>Double Date </i>of Archer (Season 11, Episode 6) Gabrielle notes that she has 2 PhD's whereas Lana only has 1 PhD. </p><p><br /></p><p>I am sure there are other examples of a work of fiction using <i>number of PhDs </i>as a way to say that someone is smart. In reality the number of PhD's one has is... not really a thing. </p><p>In reality if a scientist wants to do work in another field they... do work in that field.</p><p>Godel did research in Physics in the 1950's, but it would have been silly to go back and get a PhD in it.</p><p>Fortnow did research in Economics, but it would have been silly to go back and get a PhD in it. </p><p>Amy Farrah Fowler worked in neurobiology and then in Physics. Her Nobel prize in physics (with Sheldon Cooper) is impressive, getting a PhD in Physics would be ... odd. Imagine someone looking at here resume: <i>She has a Nobel Prize in Physics, but does she have a PhD? Did she pass her qualifying</i> <i>exams?</i>  This is the flip side of what I mentioned in a prior post about PhD's: <i>Not only does Dr. Doom want to take over the world, but his PhD is from The University of Latveria, which is not accredited. </i></p><p>There are other examples.</p><p>There ARE some people who get two PhDs for reasons of job market or other such things. That's absolutely fine of course. However, I wonder if in the real world they brag about it. I doubt it. </p><p>Is there anyone who has 3 PhDs? I would assume yes, but again, I wonder if they brag about it. Or should. </p><p>WHY do TV and movies use number-of-PhDs as a sign of genius? I do not know- especially since there are BETTER ways say someone is a genius in a way the audience can understand:  number-of-Nobel-prizes, number-of-times-mentioned-in-complexityblog,  number of Dundie's (see <a href="https://theoffice.fandom.com/wiki/Dundie">here</a>), etc. </p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p><p><br /></p></div>







<p class="date">
by gasarch (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/02/using-number-of-phds-as-measure-of.html"><span class="datestr">at February 28, 2021 05:42 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2021/02/28/linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2021/02/28/linkage.html">Linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="http://acm-stoc.org/stoc2021/accepted-papers.html">STOC 2021 accepted papers</a> (<a href="https://mathstodon.xyz/@11011110/105748480557219533">\(\mathbb{M}\)</a>).</p>
  </li>
  <li>
    <p><a href="https://randomascii.wordpress.com/2021/02/16/arranging-invisible-icons-in-quadratic-time/">Arranging invisible icons in quadratic time</a> (<a href="https://mathstodon.xyz/@11011110/105756917532905626">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=26152335">via</a>). Yet another instance where using a too-slow algorithm causes a UI hang, with the twist that the better solution would not be to replace it with a faster algorithm, but instead to not do the useless thing that the bad algorithm does at all.</p>
  </li>
  <li>
    <p><a href="https://joshdata.me/iceberger.html">Fun with shapes: draw an iceberg and see which way up and how deep it would float</a> (<a href="https://mathstodon.xyz/@11011110/105768276511155377">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=26201160">via</a>, <a href="https://www.metafilter.com/190533/Iceberger">via2</a>, <a href="https://boingboing.net/2021/02/20/make-your-own-iceberg-with-iceberger.html">via3</a>). Inspired by <a href="https://mobile.twitter.com/GlacialMeg/status/1362557149147058178">a twitter thread by Megan Thompson-Munson</a> pointing out that many supposed photos or illustrations of icebergs are fake and wrong.</p>
  </li>
  <li>
    <p>Draw an infinite subgraph of the 3d integer lattice in which each vertex has four co-planar neighbors, in a perpendicular plane to each of its neighbors (<a href="https://mathstodon.xyz/@11011110/105771494222747316">\(\mathbb{M}\)</a>). This completely determines the subgraph, which is 4-regular and highly symmetric. It is the graph of adjacencies of the cubes in the <a href="https://en.wikipedia.org/wiki/Tetrastix">tetrastix structure</a>. Does this graph have a name and history?</p>
  </li>
  <li>
    <p><a href="https://cacm.acm.org/magazines/2021/3/250708-gender-trends-in-computer-science-authorship">Gender trends in computer science authorship</a> (<a href="https://mathstodon.xyz/@11011110/105781841287243050">\(\mathbb{M}\)</a>). Takeaways for me (mostly from the barely-readable Fig. 4) are:</p>

    <ul>
      <li>
        <p>Roughly one in four coauthors of CS research publications are currently female, up from a big dip of one in seven in the 1970s to 1990s.</p>
      </li>
      <li>
        <p>Mathematics started lower and is currently more or less the same.</p>
      </li>
      <li>
        <p>We are not on track to gender parity.</p>
      </li>
    </ul>
  </li>
  <li>
    <p>I’m sad that the only way to find a viewable version of the 1991 short film <em><a href="https://en.wikipedia.org/wiki/Not_Knot">Not Knot</a></em> (on the hyperbolic geometry of knot complements) seems to be through pirate copies (<a href="https://mathstodon.xyz/@11011110/105785401264334824">\(\mathbb{M}\)</a>). Or you could pay $45 to Amazon for a copy on DVD. Do most people still have DVD players? At least they’re not still trying to sell it on VHS only.</p>
  </li>
  <li>
    <p><a href="https://cscresearchblog.wordpress.com/2018/11/16/karp-sipser-heuristic-and-reductions/">On the slow spread of knowledge of nice theorems</a> (<a href="https://mathstodon.xyz/@11011110/105793165233864617">\(\mathbb{M}\)</a>), an amusing cartoon at the end of a longer blog post on fast graph matching heuristics.</p>
  </li>
  <li>
    <p>Today’s LaTeX formatting tip (<a href="https://mathstodon.xyz/@11011110/105796107362586793">\(\mathbb{M}\)</a>): You know that bug where amsthm + hyperref, with one numbering for theorems and lemmas and corollaries and whatever, causes <code class="language-plaintext highlighter-rouge">\autoref</code> to call them theorems even when they’re really lemmas and corollaries and whatever? If you don’t, you’re lucky. Anyway, there’s a very simple workaround: after loading amsthm and hyperref, add one more package:</p>

    <p><code class="language-plaintext highlighter-rouge">\usepackage[capitalize,nameinlink]{cleveref}</code></p>

    <p>Then, just use <code class="language-plaintext highlighter-rouge">\cref</code> everywhere you were using <code class="language-plaintext highlighter-rouge">\autoref</code>. Problem solved!</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Lloyd%27s_algorithm">Lloyd’s algorithm</a> animated for 3d points (<a href="https://mathstodon.xyz/@tpfto/105553548210257285">\(\mathbb{M}\)</a>). See also <a href="https://mathstodon.xyz/@tpfto/105803635782297523">the spherical version</a>.</p>
  </li>
  <li>
    <p><a href="https://rjlipton.wordpress.com/2021/02/27/new-old-ancient-results/">Applications of the no-3-in-line problem and cap-sets to complexity theory</a> (<a href="https://mathstodon.xyz/@11011110/105807834096788492">\(\mathbb{M}\)</a>). “What is most curious to us is that for matrix multiplication, the cap-set related technique frustrates a better complexity upper bound, whereas [for linear algebraic circuits] it frustrates a better lower bound.”</p>
  </li>
  <li>
    <p><a href="https://www.bldgblog.com/2013/08/tensioned-suspension/">Tensioned suspension</a> (<a href="https://mathstodon.xyz/@11011110/105811049795181041">\(\mathbb{M}\)</a>, <a href="https://news.ycombinator.com/item?id=9093187">via</a>): sculptures by Dan Grayber in which the weight of mechanical linkages causes them to push out against the sides of their glass enclosures, seemingly causing them to hang suspended in air. More at <a href="http://www.dangrayber.com/">Grayber’s web site</a>.</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2021/02/28/linkage.html"><span class="datestr">at February 28, 2021 04:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=18225">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2021/02/27/new-old-ancient-results/">New, Old, Ancient Results</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Nonexistence theorems and attempts at lower bounds</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/02/jgcropped.jpg"><img width="141" alt="" src="https://rjlipton.files.wordpress.com/2021/02/jgcropped.jpg?w=141&amp;h=168" class="alignright wp-image-18228" height="168" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://home.cs.colorado.edu/~jgrochow/">src</a></font></td>
</tr>
</tbody>
</table>
<p>
Joshua Grochow is an assistant professor in Computer Science and Mathematics at the University of Colorado at Boulder. He was a student of Ketan Mulmuley and Lance Fortnow at Chicago; his <a href="https://home.cs.colorado.edu/~jgrochow/grochow-thesis.pdf">dissertation</a> and <a href="https://arxiv.org/pdf/1304.6333.pdf">some</a> <a href="https://arxiv.org/pdf/1112.2012.pdf">subsequent</a> <a href="https://arxiv.org/pdf/1605.02815.pdf">papers</a> did much to widen the horizons of the “Geometric Complexity Theory” (GCT) program. He is also a gifted expositor.</p>
<p>
Today we will highlight some of his work and some of his exposition of new and old theorems.<br />
<span id="more-18225"></span></p>
<p>
An ancient one is Stephen Mahaney’s famous theorem on the nonexistence of sparse <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP}}" class="latex" />-complete sets (unless <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP+%3D+P%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathsf{NP = P}}" class="latex" />). Grochow <a href="https://arxiv.org/pdf/1610.05825.pdf">discusses</a> a simpler proof of the theorem by Manindra Agrawal and gives some further impacts on GCT. </p>
<p>
A recent <a href="https://drops.dagstuhl.de/opus/volltexte/2021/13570/pdf/LIPIcs-ITCS-2021-31.pdf">one</a> with Youming Qiao is on an old topic and is in the 2021 Innovations in Theoretical Computer Science conference. It is titled, “On the Complexity of Isomorphism Problems for Tensors, Groups, and Polynomials I: Tensor Isomorphism-Completeness,” and grows out of a 2019 <a href="https://arxiv.org/abs/1907.00309">paper</a> by the same authors. </p>
<p>
This came to my attention through communications with Grochow’s <a href="https://michaellevet.github.io">student</a>, Michael Levet. Indeed, Levet is the reason for my putting this all together. He raised through email some questions about an ancient result of mine on group isomorphism. I reported <a href="https://rjlipton.wordpress.com/2013/05/11/advances-on-group-isomorphism/">previously</a>:</p>
<blockquote><p><b> </b> <em> Long ago Bob Tarjan and Zeke Zalcstein and I made a simple observation: Group isomorphism could be done in time 	</em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++n%5E%7B%5Clog_%7B2%7D+n+%2B+O%281%29%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  n^{\log_{2} n + O(1)}. " class="latex" /></p>
</em><p><em>This relies on the easy-to-prove fact that every group has at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Clog_%7B2%7D+n%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\log_{2} n}" class="latex" /> generators. We have discussed this idea earlier <a href="https://rjlipton.wordpress.com/2011/10/08/an-annoying-open-problem/">here</a>. </em>
</p></blockquote>
<p>
Levet raised an issue about related observations of mine—ones that were misleading at best. I think he has a good point and we are still trying to unravel exactly what I meant back then. I applaud him for reading ancient stuff, for trying to extend it, and for working on such problems. I wish him well.</p>
<p>
</p><h2> No Three In a Row </h2><p></p>
<p>While Levet and I work that out and think about Grochow’s paper on isomorphism problems with Qiao, Ken and I want to highlight a different expository <a href="https://www.ams.org/journals/bull/2019-56-01/S0273-0979-2018-01648-0/S0273-0979-2018-01648-0.pdf">paper</a> by Grochow on news from 2016 that we <a href="https://rjlipton.wordpress.com/2016/06/15/polynomial-prestidigitation/">covered</a> then. Grochow’s paper appeared in the <em>AMS Bulletin</em> and is titled, “New Applications Of The Polynomial Method: The Cap Set Conjecture And Beyond.” </p>
<p>
To lead in to the subject, here is a <a href="https://archive.org/stream/amusementsinmath00dude#page/94/mode/2up">problem</a> from 1917 by the English puzzlemaster Henry Dudeney titled, “A Puzzle With Pawns”:</p>
<blockquote><p><b> </b> <em> Place two pawns in the middle of the chess- board, one at Q 4 and the other at K 5. Now, place the remaining fourteen pawns (sixteen in all) so that no three shall be in a straight line in any possible direction. Note that I purposely do not say queens, because by the words ” any possible direction ” I go beyond attacks on diagonals. The pawns must be regarded as mere points in space — at the centres of the squares. </em>
</p></blockquote>
<p>
Sixteen is obviously the maximum possible for a standard <img src="https://s0.wp.com/latex.php?latex=%7B8+%5Ctimes+8%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{8 \times 8}" class="latex" /> chessboard because a seventeenth pawn would make three in some row and some column. For an <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Ctimes+r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r \times r}" class="latex" /> board, the limit is <img src="https://s0.wp.com/latex.php?latex=%7B2r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2r}" class="latex" /> by similar reasoning—this is an example of the <em>pigeonhole principle</em> which we just <a href="https://rjlipton.wordpress.com/2021/02/15/pigenhole-principle/">mentioned</a>. </p>
<p>
It is possible to achieve the maximum for all <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> up to <img src="https://s0.wp.com/latex.php?latex=%7B46%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{46}" class="latex" /> and then the only other cases known are <img src="https://s0.wp.com/latex.php?latex=%7B48%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{48}" class="latex" />, <img src="https://s0.wp.com/latex.php?latex=%7B50%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{50}" class="latex" />, and <img src="https://s0.wp.com/latex.php?latex=%7B52%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{52}" class="latex" />. That’s it. Here are solutions for <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r = 10}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+52%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r = 52}" class="latex" />. The latter was found by Achim Flammenkamp, whose <a href="http://wwwhomes.uni-bielefeld.de/achim/no3in/readme.html">page</a> has encyclopedic information. On the former, the pieces are positioned on gridpoints like stones in Go, which seems a better context for this problem than chess. </p>
<table style="margin: auto;">
<tbody><tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2021/02/3inarow20and52.jpg"><img width="550" alt="" src="https://rjlipton.files.wordpress.com/2021/02/3inarow20and52.jpg?w=550&amp;h=257" class="aligncenter wp-image-18230" height="257" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite of <a href="https://en.wikipedia.org/wiki/No-three-in-line_problem">src1</a>, <a href="https://mathworld.wolfram.com/No-Three-in-a-Line-Problem.html">src2</a></font>
</td>
</tr>
</tbody></table>
<p>
The conjecture is not only that a <img src="https://s0.wp.com/latex.php?latex=%7B2n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2n}" class="latex" />-size solution exists for only finitely many <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />, but also that the maximum size for all sufficiently large <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> is bounded by <img src="https://s0.wp.com/latex.php?latex=%7Bcr%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{cr}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3C+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c &lt; 2}" class="latex" />, indeed, with <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3C+1.815%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c &lt; 1.815}" class="latex" />. It is known that <img src="https://s0.wp.com/latex.php?latex=%7B%281.5-%5Cepsilon_r%29r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(1.5-\epsilon_r)r}" class="latex" /> stones can always be placed with no three collinear, where the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon_r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon_r}" class="latex" /> depends on the closeness of a prime to <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Br%7D%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\frac{r}{2}}" class="latex" />. </p>
<p>
The problem can be taken to dimensions <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cge+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n \ge 3}" class="latex" /> that are beyond the plane. We can also extend what is meant by a “line” via various notions of wrapping-around. Then the question is how close the maximum size can stay to being linear in the size of the space—as <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> and/or the size <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> of an individual dimension increase.</p>
<p>
</p><h2> Not As Easy As Tic-Tac-Toe </h2><p></p>
<p>
The theme of the no-three-in-a-line problem is fundamental to combinatorics. There are tons of problems of the form: </p>
<blockquote><p><b> </b> <em> How many objects can one place, so that no pattern of some certain type exists? </em>
</p></blockquote>
<p>
In <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />-dimensional space the smallest <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> of interest is <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r = 3}" class="latex" />. This means playing on higher-dimensional versions of the <img src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3 \times 3}" class="latex" /> grid and <img src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3 \times 3 \times 3}" class="latex" /> cube. Then the only Euclidean lines are the kind we know from tic-tac-toe: straight across or down, or diagonal. </p>
<p>
For dimension <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cgeq+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n \geq 3}" class="latex" /> there are other kinds of diagonals, such as within a face or through the center of the cube, but they all win at <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />-dimensional tic-tac-toe. So the problem becomes: what is the maximum number of moves you can make by yourself without creating a win at tic-tac-toe? The <em>cap-set problem</em> adds a twist by extending the notion of what is a <em>line</em>. It is like playing tic-tac-toe on a floor of <img src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3 \times 3}" class="latex" /> tiles where a play in one tile is replicated in all of them. Then you can make a line by playing in a corner and in the middle of the two opposite edges, as shown at left in the following diagram (original drawing).</p>
<p>
<a href="https://rjlipton.files.wordpress.com/2021/02/lineandcapset3x3.png"><img width="550" alt="" src="https://rjlipton.files.wordpress.com/2021/02/lineandcapset3x3.png?w=550&amp;h=222" class="aligncenter wp-image-18231" height="222" /></a></p>
<p>
The four orange O’s at right have no 3-in-a-line even with this extended notion of line. Note that the four blank cells in the top two rows also avoid putting 3 in a line. Four is the maximum, however: it is not possible to have a drawn game in extended <img src="https://s0.wp.com/latex.php?latex=%7B3+%5Ctimes+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3 \times 3}" class="latex" /> tic-tac-toe. </p>
<p>
The theorem <a href="https://arxiv.org/pdf/1605.09223v1.pdf">proved</a> by Jordan Ellenberg and Dion Gijswijt in 2016 is that the upper bound is not only a vanishing fraction of the size <img src="https://s0.wp.com/latex.php?latex=%7B3%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3^n}" class="latex" /> of the space as <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> grows, it is bounded by <img src="https://s0.wp.com/latex.php?latex=%7Bc%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c^n}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3C+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c &lt; 3}" class="latex" />. Namely:</p>
<blockquote><p><b>Theorem 1</b> <em> Every cap set in the <img src="https://s0.wp.com/latex.php?latex=%7B3%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3^n}" class="latex" />-cube has size at most <img src="https://s0.wp.com/latex.php?latex=%7B2.756%5En%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2.756^n}" class="latex" />. </em>
</p></blockquote>
<p>
</p><h2> Using Polynomials </h2><p></p>
<p>There is a simple way to express the extended notion of “line” that works for all dimensions <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />: Number the coordinates of each dimension <img src="https://s0.wp.com/latex.php?latex=%7B0%2C1%2C2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{0,1,2}" class="latex" />. Make the space <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B0%2C1%2C2%5C%7D%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\{0,1,2\}^n}" class="latex" /> with addition modulo <img src="https://s0.wp.com/latex.php?latex=%7Bq+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{q = 3}" class="latex" />, that is, make it <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D_3%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbb{Z}_3^n}" class="latex" />. Then the condition for three points <img src="https://s0.wp.com/latex.php?latex=%7BA%2CB%2CC%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A,B,C}" class="latex" /> to be in a line is simply </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A+%2B+B+%3D+2C.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  A + B = 2C. " class="latex" /></p>
<p>It is easy to write polynomial equations over the field <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BF%7D_3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbb{F}_3}" class="latex" /> to express the property of a set having such a line. What was unexpected, until Ernie Croot, Vsevolod Lev, and Péter Pál Pach solved a related problem with <img src="https://s0.wp.com/latex.php?latex=%7Bq+%3D+4%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{q = 4}" class="latex" />, was that there would be</p>
<blockquote><p><b> </b> <em> “an ingeniously simple way to split the polynomial[s] into pieces with smaller exponents, which led to a bound on the size of collections with no [lines].” </em>
</p></blockquote>
<p>
The quotation comes from an <a href="https://www.quantamagazine.org/set-proof-stuns-mathematicians-20160531">article</a> by Erica Klarreich for <em>Quanta</em> right then in 2016. A 2016 AMS Feature <a href="http://www.ams.org/publicoutreach/feature-column/fc-2016-08">column</a> by David Austin covers how to make this say a set <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" /> of points is a cap set modulo 3: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++S+%5Cuplus+S+%5Ccap+2S+%3D+%5Cemptyset%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  S \uplus S \cap 2S = \emptyset, " class="latex" /></p>
<p>where we (not Austin) write <img src="https://s0.wp.com/latex.php?latex=%7BS+%5Cuplus+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S \uplus S}" class="latex" /> to mean the set of sums <img src="https://s0.wp.com/latex.php?latex=%7Ba+%2B+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a + b}" class="latex" /> where <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb+%5Cin+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a,b \in S}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb+%5Cneq+a%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{b \neq a}" class="latex" />. If there is an element <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> in the intersection then <img src="https://s0.wp.com/latex.php?latex=%7Ba+%2B+b+%3D+r+%3D+2c%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a + b = r = 2c}" class="latex" />, and since <img src="https://s0.wp.com/latex.php?latex=%7B3c+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{3c = 0}" class="latex" />, we get <img src="https://s0.wp.com/latex.php?latex=%7Ba+%2B+b+%2B+c+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a + b + c = 0}" class="latex" /> with <img src="https://s0.wp.com/latex.php?latex=%7Ba%2Cb%2Cc%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a,b,c}" class="latex" /> in <img src="https://s0.wp.com/latex.php?latex=%7BS%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S}" class="latex" /> and all distinct, a contradiction. (If <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3D+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{c = b}" class="latex" /> then <img src="https://s0.wp.com/latex.php?latex=%7Ba+%2B+2b+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a + 2b = 0}" class="latex" />, so <img src="https://s0.wp.com/latex.php?latex=%7Ba+%3D+b%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{a = b}" class="latex" />.) Let <img src="https://s0.wp.com/latex.php?latex=%7Bm_d%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{m_d}" class="latex" /> stand for the number of monomials of degree at most <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" /> in the <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> variables. The key first insight is:</p>
<blockquote><p><b>Lemma 2</b> <em> If a polynomial <img src="https://s0.wp.com/latex.php?latex=%7Bp%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p(x_1,\dots,x_n)}" class="latex" /> of degree <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" /> vanishes on <img src="https://s0.wp.com/latex.php?latex=%7BS%5Cuplus+S%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S\uplus S}" class="latex" />, then <img src="https://s0.wp.com/latex.php?latex=%7Bp%28x%29+%3D+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p(x) = 0}" class="latex" /> for all but at most <img src="https://s0.wp.com/latex.php?latex=%7B2m_%7Bd%2F2%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2m_{d/2}}" class="latex" /> points of <img src="https://s0.wp.com/latex.php?latex=%7B2S%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2S}" class="latex" />. </em>
</p></blockquote>
<p>
One could first try to interpret this as saying that <img src="https://s0.wp.com/latex.php?latex=%7BS+%5Cuplus+S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{S \uplus S}" class="latex" /> “looks like” <img src="https://s0.wp.com/latex.php?latex=%7B2S%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2S}" class="latex" /> to polynomials <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p}" class="latex" /> of “low” degree <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" />. However, if <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" /> stays low relative to <img src="https://s0.wp.com/latex.php?latex=%7B%7CS%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{|S|}" class="latex" /> then the “if” part would hold vacuously, opposing the goal of bounding <img src="https://s0.wp.com/latex.php?latex=%7B%7CS%7C%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{|S|}" class="latex" /> and making the whole idea self-defeating. In fact, the important tension comes when <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" /> is intermediate: <img src="https://s0.wp.com/latex.php?latex=%7Bd+%3D+%28q-1%29n%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d = (q-1)n/3}" class="latex" />, which for <img src="https://s0.wp.com/latex.php?latex=%7Bq+%3D+3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{q = 3}" class="latex" /> makes <img src="https://s0.wp.com/latex.php?latex=%7Bd%2F2+%3D+n%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d/2 = n/3}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bd+%3D+2n%2F3%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d = 2n/3}" class="latex" /> neatly occupy the middle of the range <img src="https://s0.wp.com/latex.php?latex=%7B%5C%7B1%2C%5Cdots%2Cn%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\{1,\dots,n\}}" class="latex" />.</p>
<p>
The proof also uses the trick that if a product of two monomials has degree <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{d}" class="latex" /> then one of them must have degree at most <img src="https://s0.wp.com/latex.php?latex=%7B%5Clfloor+d%2F2%5Crfloor%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\lfloor d/2\rfloor}" class="latex" />. As I (Ken writing these sections) <a href="https://rjlipton.wordpress.com/2016/06/15/polynomial-prestidigitation/">wrote</a> about it back in 2016, this reminds of Roman Smolensky’s degree-halving <a href="https://rjlipton.wordpress.com/2012/03/11/a-note-on-distributions-and-approximation/">trick</a> in his celebrated 1987 <a href="https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.463.883&amp;rep=rep1&amp;type=pdf">theorem</a> on lower bounds for mod-<img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p}" class="latex" /> versus mod-<img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{q}" class="latex" />. This trick, however, runs from <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" /> to <img src="https://s0.wp.com/latex.php?latex=%7Bn%2F2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n/2}" class="latex" /> for all moduli. </p>
<p>
In any event, the 2016 papers were a new form of the polynomial method that led to striking new results. What Grochow’s survey does for us now is bring out wider implications of this ingenuity.</p>
<p>
</p><h2> Applications in Complexity </h2><p></p>
<p>Grochow’s four application areas in section 4 of his survey are:</p>
<ol>
<li>
Progress on various forms of `sunflower’ conjectures. <p></p>
</li><li>
Barriers to attempts to show that the exponent of matrix multiplication is <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{2}" class="latex" />. <p></p>
</li><li>
Removing edges to make graphs triangle-free. <p></p>
</li><li>
Matrix rigidity and lower bounds.
</li></ol>
<p>
We say a little more about the last of these. For any <img src="https://s0.wp.com/latex.php?latex=%7BN+%5Ctimes+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N \times N}" class="latex" /> matrix <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7Br+%5Cleq+N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r \leq N}" class="latex" /> define the <em>rigidity</em> <img src="https://s0.wp.com/latex.php?latex=%7BR_A%28r%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{R_A(r)}" class="latex" /> to be the minimum number of entries in which <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A}" class="latex" /> differs from some matrix of rank (at most) <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" />. The highest possible rigidity for rank <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> is <img src="https://s0.wp.com/latex.php?latex=%7B%28N+-+r%29%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(N - r)^2}" class="latex" />, since zeroing out an <img src="https://s0.wp.com/latex.php?latex=%7B%28n-r%29%5Ctimes%28n-r%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{(n-r)\times(n-r)}" class="latex" /> block leaves a matrix of rank at most <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" />. Sufficiently random matrices meet this upper bound with high probability, but the best lower bounds for explicit families of matrices are <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28%5Cfrac%7BN%5E2%7D%7Br%7D%5Clog%5Cfrac%7BN%7D%7Br%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\Omega(\frac{N^2}{r}\log\frac{N}{r})}" class="latex" />, which is only quasi-linear when <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> is close to <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N}" class="latex" />. The question is whether we can inch this up to <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28n%5E%7B1%2B%5Cepsilon%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\Omega(n^{1+\epsilon})}" class="latex" /> for some <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon &gt; 0}" class="latex" />.</p>
<blockquote><p><b>Definition 3</b> <em> A family of matrices <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_N}" class="latex" /> is <em>significantly rigid</em> if there is an <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon+%3E+0%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon &gt; 0}" class="latex" /> such that taking <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+%5Cfrac%7BN%7D%7B%5Clog%5Clog+N%7D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r = \frac{N}{\log\log N}}" class="latex" /> makes <img src="https://s0.wp.com/latex.php?latex=%7BR_%7BA_N%7D%28r%29+%3D+%5COmega%28N%5E%7B1%2B%5Cepsilon%7D%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{R_{A_N}(r) = \Omega(N^{1+\epsilon})}" class="latex" />. </em>
</p></blockquote>
<p>
The interest in this definition comes from a lack of lower bounds on linear algebraic circuits computing natural families <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_N}" class="latex" /> of linear transformations that seems even more extreme than our lack of super-linear lower bounds on Boolean circuits, nor better than <img src="https://s0.wp.com/latex.php?latex=%7B%5COmega%28N%5Clog+N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\Omega(N\log N)}" class="latex" /> for general algebraic circuits computing polynomials in <img src="https://s0.wp.com/latex.php?latex=%7BN%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N}" class="latex" /> variables of degree <img src="https://s0.wp.com/latex.php?latex=%7BB%5E%7BO%281%29%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{B^{O(1)}}" class="latex" />. It is still consistent with our knowledge that every natural family <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_N}" class="latex" /> can be computed by linear algebraic circuits of <img src="https://s0.wp.com/latex.php?latex=%7BO%28N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{O(N)}" class="latex" /> size <b>and</b> <img src="https://s0.wp.com/latex.php?latex=%7BO%28%5Clog+N%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{O(\log N)}" class="latex" /> depth. Leslie Valiant in 1977 proved the following sufficient condition to improve this state of affairs.</p>
<blockquote><p><b>Theorem 4</b> <em> Every significantly rigid family <img src="https://s0.wp.com/latex.php?latex=%7BA_N%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{A_N}" class="latex" /> cannot be computed by linear algebraic circuits of linear size and logarithmic depth. </em>
</p></blockquote>
<p>
So for coming on half a century the question has been:</p>
<blockquote><p><b> </b> <em> Can we construct a natural explicit family of significantly rigid matrices? </em>
</p></blockquote>
<p>
Beliefs that the Hadamard matrices provided such a family were <a href="https://arxiv.org/pdf/1611.05558.pdf">refuted</a> by Josh Alman and Ryan Williams at STOC 2017, and <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.38.3100">known</a> <a href="https://core.ac.uk/download/pdf/82556808.pdf">results</a> for Vandermonde matrices do not have <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r}" class="latex" /> close enough to <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />. </p>
<p>
One hope had been to derive such matrices from explicit functions <img src="https://s0.wp.com/latex.php?latex=%7Bf_n%28x_1%2C%5Cdots%2Cx_n%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{f_n(x_1,\dots,x_n)}" class="latex" /> over <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathbb%7BZ%7D_p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\mathbb{Z}_p}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{p}" class="latex" /> prime by taking <img src="https://s0.wp.com/latex.php?latex=%7BN+%3D+p%5En%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{N = p^n}" class="latex" /> and defining </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A_%7Bf_n%7D%5B%5Cvec%7Bx%7D%2C%5Cvec%7By%7D%5D+%3D+f%28x_1+%2B+y_1%2C%5Cdots%2Cx_n+%2B+y_n%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  A_{f_n}[\vec{x},\vec{y}] = f(x_1 + y_1,\dots,x_n + y_n). " class="latex" /></p>
<p>Unfortunately, the polynomial method for cap sets shows that no such attempt can work. Zeev Dvir and Benjamin Edelman <a href="https://theoryofcomputing.org/articles/v015a008/">proved</a> that no matter how <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{f}" class="latex" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Cepsilon%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\epsilon}" class="latex" /> are chosen, there is <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{\delta &gt; 0}" class="latex" /> such that for all large enough <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{n}" class="latex" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++R_%7BA_%7Bf_n%7D%7D%28N%5E%7B1-%5Cdelta%7D%29+%3C+n%5E%7B1%2B%5Cepsilon%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="\displaystyle  R_{A_{f_n}}(N^{1-\delta}) &lt; n^{1+\epsilon}. " class="latex" /></p>
<p>This means we cannot get <img src="https://s0.wp.com/latex.php?latex=%7BR_%7BA_%7Bf_n%7D%7D%28r%29+%3D+%5COmega%28n%5E%7B1%2B%5COmega%281%29%7D%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{R_{A_{f_n}}(r) = \Omega(n^{1+\Omega(1)})}" class="latex" /> for <img src="https://s0.wp.com/latex.php?latex=%7Br+%3D+%5Cfrac%7BN%7D%7B%5Clog%5Clog+N%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0&amp;c=20201002" alt="{r = \frac{N}{\log\log N}}" class="latex" />, indeed, far from it. What is most curious to us is that for matrix multiplication, the cap-set related technique frustrates a better complexity upper bound, whereas here it frustrates a better lower bound.</p>
<p>
</p><h2> Open Problems </h2><p></p>
<p>What further applications can we find for the polynomial method?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2021/02/27/new-old-ancient-results/"><span class="datestr">at February 27, 2021 08:10 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2021/028">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2021/028">TR21-028 |  Branching Programs with Bounded Repetitions and $\mathrm{Flow}$ Formulas | 

	Anastasia Sofronova, 

	Dmitry Sokolov</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Restricted branching programs capture various complexity measures like space in Turing machines or length of proofs in proof systems. In this paper, we focus on the application in the proof complexity that was discovered by Lovasz et al. '95 who showed the equivalence between regular Resolution and read-once branching programs for ``unsatisfied clause search problem'' ($\mathrm{Search}_{\varphi}$). This connection is widely used, in particular, in the recent breakthrough result about the Clique problem in regular Resolution by Atserias et al. '18.

We study the branching programs with bounded repetitions, so-called $(1, +k)$-BPs (Sieling '96) in application to the $\mathrm{Search}_{\varphi}$ problem. On the one hand, it is a natural generalization of read-once branching programs. On the other hand, this model gives a powerful proof system that can efficiently certify the unsatisfiability of a wide class of formulas that is hard for Resolution (Knop '17).


We deal with $\mathrm{Search}_{\varphi}$ that is ``relatively easy'' compared to all known hard examples for the $(1, +k)$-BPs. We introduce the first technique for proving exponential lower bounds for the $(1, +k)$-BPs on $\mathrm{Search}_{\varphi}$. To do it we combine a well-known technique for proving lower bounds on the size of branching programs (Sieling '96; Sieling, Wegener '94; Jukna, Razborov '98) with the modification of the ``closure'' technique (Alekhnovich et al. 04; Alekhnovich, Razborov '03). In contrast with the most Resolution lower bounds, our technique uses not only ``local'' properties of the formula, but also a ``global'' structure. Our hard examples are based on the $\mathrm{Flow}$ formulas introduced in (Alekhnovich, Razborov '03).</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2021/028"><span class="datestr">at February 27, 2021 07:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/02/26/phd-position-at-university-of-amsterdam-apply-by-march-18-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/02/26/phd-position-at-university-of-amsterdam-apply-by-march-18-2021/">PhD position at University of Amsterdam (apply by March 18, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The University of Amsterdam encourages applications for an open PhD position in the theory of quantum computing and quantum networks. Potential research topics include multi-party quantum computation, secure positioning, and multi-party communication complexity.</p>
<p>Website: <a href="https://www.uva.nl/shared-content/uva/en/vacancies/2021/02/21-069-phd-position-on-the-theory-of-quantum-networks.html">https://www.uva.nl/shared-content/uva/en/vacancies/2021/02/21-069-phd-position-on-the-theory-of-quantum-networks.html</a><br />
Email: f.speelman@uva.nl</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/02/26/phd-position-at-university-of-amsterdam-apply-by-march-18-2021/"><span class="datestr">at February 26, 2021 10:38 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/02/26/faculty-at-krea-university-india-apply-by-may-1-2021-2/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/02/26/faculty-at-krea-university-india-apply-by-may-1-2021-2/">Faculty at KREA University, India (apply by May 1, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Krea University, an upcoming liberal arts university located near Chennai, India, is looking for dynamic tenure track faculty across disciplines and experience levels in computer science.</p>
<p>Open House, 27th Feb 2021 9:00 AM [IST]:<br />
<a href="https://krea.edu.in/wp-content/uploads/2021/02/cshiringopenhouse.pdf">https://krea.edu.in/wp-content/uploads/2021/02/cshiringopenhouse.pdf</a></p>
<p>Website: <a href="https://jobs.acm.org/jobs/assistant-associate-professor-computer-science-sri-city-andhra-pradesh-517646-121295350-d">https://jobs.acm.org/jobs/assistant-associate-professor-computer-science-sri-city-andhra-pradesh-517646-121295350-d</a><br />
Email: sias.chair_sciences@krea.edu.in</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/02/26/faculty-at-krea-university-india-apply-by-may-1-2021-2/"><span class="datestr">at February 26, 2021 08:49 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/02/25/tenure-track-open-rank-at-university-of-illinois-urbana-champaign-apply-by-june-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/02/25/tenure-track-open-rank-at-university-of-illinois-urbana-champaign-apply-by-june-1-2021/">Tenure Track (Open Rank) at University of Illinois, Urbana-Champaign (apply by March 15, 2021; or as soon as possible)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The Department of Computer Science at the University of Illinois Urbana-Champaign invites applications for full-time tenure-track faculty positions at all levels (Assistant Professor, Associate Professor, Full Professor). We particularly encourage applications in quantum computing, but also welcome applications from exceptional candidates in other areas.</p>
<p>Website: <a href="https://cs.illinois.edu/about/positions/faculty-positions">https://cs.illinois.edu/about/positions/faculty-positions</a><br />
Email: chekuri@illinois.edu</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/02/25/tenure-track-open-rank-at-university-of-illinois-urbana-champaign-apply-by-june-1-2021/"><span class="datestr">at February 25, 2021 10:59 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-2202248828009562800">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2021/02/complexity-is-enemy-of-speed.html">Complexity is the Enemy of Speed</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>The title of this post came from an <a href="https://www.wsj.com/articles/connecticuts-covid-vaccine-lesson-11614124012">opinion piece</a> in the Wall Street Journal yesterday on vaccine distribution. Many attempts to get the vaccines to the right groups first have slowed down distribution and sometime even caused <a href="https://www.nbcnews.com/news/us-news/thousands-covid-19-vaccines-wind-garbage-because-fed-state-guidelines-n1254364">vaccines to go to waste</a>. Rules to help spread vaccines across minority groups often backfire. Often when some rules lead to inequity, we try to fix it with more rules when we need less much less. Attempts to distribute vaccines to multiple medical and pharmacy sites have made it difficult to get appointments even if you are eligible.</p><p>Randomness is the simplest way to fairness. The movie Contagion got it right, just choose birthdays by picking balls from a bin to distribute the vaccine. Then people can just show up at a few chosen sites with proof of birthday. No need to sign up.</p><p>You could argue to add back conditions like age, medical conditions, jobs but that just leads you down the same problematic path. The fastest way to get past this pandemic is to get vaccines into arms. Trust the randomness.</p></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2021/02/complexity-is-enemy-of-speed.html"><span class="datestr">at February 25, 2021 02:19 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2021/02/25/faculty-at-krea-university-india-apply-by-may-1-2021/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2021/02/25/faculty-at-krea-university-india-apply-by-may-1-2021/">Faculty at KREA University, India (apply by May 1, 2021)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Krea University, an upcoming liberal arts university located near Chennai, India, is looking for dynamic tenure track faculty across disciplines and experience levels in computer science.</p>
<p>Open House, 27th Feb 2021 9:00 AM [IST]:<br />
<a href="https://krea.edu.in/wp-content/uploads/2021/02/cshiringopenhouse.pdf">https://krea.edu.in/wp-content/uploads/2021/02/cshiringopenhouse.pdf</a></p>
<p>Website: <a href="https://jobs.acm.org/jobs/assistant-associate-professor-computer-science-sri-city-andhra-pradesh-517646-121295350-d">https://jobs.acm.org/jobs/assistant-associate-professor-computer-science-sri-city-andhra-pradesh-517646-121295350-d</a><br />
Email: sias.chair_sciences@krea.edu.in</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2021/02/25/faculty-at-krea-university-india-apply-by-may-1-2021/"><span class="datestr">at February 25, 2021 09:47 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
