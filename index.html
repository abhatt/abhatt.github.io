<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>











<head>
<title>Theory of Computing Blog Aggregator</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<meta name="generator" content="http://intertwingly.net/code/venus/">
<link rel="stylesheet" href="css/twocolumn.css" type="text/css" media="screen">
<link rel="stylesheet" href="css/singlecolumn.css" type="text/css" media="handheld, print">
<link rel="stylesheet" href="css/main.css" type="text/css" media="@all">
<link rel="icon" href="images/feed-icon.png">
<script type="text/javascript" src="library/MochiKit.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/javascript" src="js/main.js"></script> 
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
    "HTML-CSS": { availableFonts: [],
      webFont: 'TeX' }
});
</script>
 <script type="text/javascript" 
	 src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML-full">
 </script>

<script type="text/javascript">
var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));
</script>
<script type="text/javascript">
var pageTracker = _gat._getTracker("UA-2793256-2");
pageTracker._trackPageview();
</script>
<link rel="alternate" href="http://www.cstheory-feed.org/atom.xml" title="" type="application/atom+xml">
</head>

<body onload="onLoadCb()">
<div class="sidebar">
<div style="background-color:#feb; border:1px solid #dc9; padding:10px; margin-top:23px; margin-bottom: 20px">
Stay up to date
</ul>
<li>Subscribe to the <A href="atom.xml">RSS feed</a></li>
<li>Follow <a href="http://twitter.com/cstheory">@cstheory</a> on Twitter</li>
</ul>
</div>

<h3>Blogs/feeds</h3>
<div class="subscriptionlist">
<a class="feedlink" href="http://aaronsadventures.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://aaronsadventures.blogspot.com/" title="Adventures in Computation">Aaron Roth</a>
<br>
<a class="feedlink" href="https://adamsheffer.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamsheffer.wordpress.com" title="Some Plane Truths">Adam Sheffer</a>
<br>
<a class="feedlink" href="https://adamdsmith.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://adamdsmith.wordpress.com" title="Oddly Shaped Pegs">Adam Smith</a>
<br>
<a class="feedlink" href="https://polylogblog.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://polylogblog.wordpress.com" title="the polylogblog">Andrew McGregor</a>
<br>
<a class="feedlink" href="http://corner.mimuw.edu.pl/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://corner.mimuw.edu.pl" title="Banach's Algorithmic Corner">Banach's Algorithmic Corner</a>
<br>
<a class="feedlink" href="http://www.argmin.net/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://benjamin-recht.github.io/" title="arg min blog">Ben Recht</a>
<br>
<a class="feedlink" href="https://cstheory-jobs.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<br>
<a class="feedlink" href="https://cstheory-events.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">CS Theory StackExchange (Q&A)</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="404: not found">Center for Computational Intractability</a>
<br>
<a class="feedlink" href="https://blog.computationalcomplexity.org/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<br>
<a class="feedlink" href="https://11011110.github.io/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<br>
<a class="feedlink" href="https://daveagp.wordpress.com/category/toc/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://daveagp.wordpress.com" title="toc – QED and NOM">David Pritchard</a>
<br>
<a class="feedlink" href="https://decentdescent.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentdescent.org/" title="Decent Descent">Decent Descent</a>
<br>
<a class="feedlink" href="https://decentralizedthoughts.github.io/feed" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<br>
<a class="feedlink" href="https://eccc.weizmann.ac.il//feeds/reports/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<br>
<a class="feedlink" href="https://minimizingregret.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://minimizingregret.wordpress.com" title="Minimizing Regret">Elad Hazan</a>
<br>
<a class="feedlink" href="https://emanueleviola.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<br>
<a class="feedlink" href="https://3dpancakes.typepad.com/ernie/atom.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://3dpancakes.typepad.com/ernie/" title="Ernie's 3D Pancakes">Ernie's 3D Pancakes</a>
<br>
<a class="feedlink" href="https://dstheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<br>
<a class="feedlink" href="https://francisbach.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<br>
<a class="feedlink" href="https://gilkalai.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<br>
<a class="feedlink" href="http://blogs.oregonstate.edu/glencora/tag/tcs/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blogs.oregonstate.edu/glencora" title="tcs – Glencora Borradaile">Glencora Borradaile</a>
<br>
<a class="feedlink" href="https://research.googleblog.com/feeds/posts/default/-/Algorithms" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://research.googleblog.com/search/label/Algorithms" title="Research Blog">Google Research Blog: Algorithms</a>
<br>
<a class="feedlink" href="https://gradientscience.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://gradientscience.org/" title="gradient science">Gradient Science</a>
<br>
<a class="feedlink" href="http://grigory.us/blog/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://grigory.github.io/blog" title="The Big Data Theory">Grigory Yaroslavtsev</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Ilya Razenshteyn</a>
<br>
<a class="feedlink" href="https://tcsmath.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsmath.wordpress.com" title="tcs math">James R. Lee</a>
<br>
<a class="feedlink" href="https://kamathematics.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://kamathematics.wordpress.com" title="Kamathematics">Kamathematics</a>
<br>
<a class="feedlink" href="" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a class="message" title="internal server error">Learning with Errors: Student Theory Blog</a>
<br>
<a class="feedlink" href="http://processalgebra.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://processalgebra.blogspot.com/" title="Process Algebra Diary">Luca Aceto</a>
<br>
<a class="feedlink" href="https://lucatrevisan.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<br>
<a class="feedlink" href="https://mittheory.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mittheory.wordpress.com" title="Not so Great Ideas in Theoretical Computer Science">MIT CSAIL student blog</a>
<br>
<a class="feedlink" href="http://mybiasedcoin.blogspot.com/feeds/posts/default" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mybiasedcoin.blogspot.com/" title="My Biased Coin">Michael Mitzenmacher</a>
<br>
<a class="feedlink" href="http://blog.mrtz.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.mrtz.org/" title="Moody Rd">Moritz Hardt</a>
<br>
<a class="feedlink" href="http://mysliceofpizza.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://mysliceofpizza.blogspot.com/search/label/aggregator" title="my slice of pizza">Muthu Muthukrishnan</a>
<br>
<a class="feedlink" href="https://nisheethvishnoi.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://nisheethvishnoi.wordpress.com" title="Algorithms, Nature, and Society">Nisheeth Vishnoi</a>
<br>
<a class="feedlink" href="http://www.solipsistslog.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.solipsistslog.com" title="Solipsist's Log">Noah Stephens-Davidowitz</a>
<br>
<a class="feedlink" href="http://www.offconvex.org/feed.xml" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://offconvex.github.io/" title="Off the convex path">Off the Convex Path</a>
<br>
<a class="feedlink" href="http://paulwgoldberg.blogspot.com/feeds/posts/default/-/aggregator" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://paulwgoldberg.blogspot.com/search/label/aggregator" title="Paul Goldberg">Paul Goldberg</a>
<br>
<a class="feedlink" href="https://ptreview.sublinear.info/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<br>
<a class="feedlink" href="https://rjlipton.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<br>
<a class="feedlink" href="http://www.contrib.andrew.cmu.edu/~ryanod/index.php?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://www.contrib.andrew.cmu.edu/~ryanod" title="Analysis of Boolean Functions">Ryan O'Donnell</a>
<br>
<a class="feedlink" href="https://blogs.princeton.edu/imabandit/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blogs.princeton.edu/imabandit" title="I’m a bandit">S&eacute;bastien Bubeck</a>
<br>
<a class="feedlink" href="https://sarielhp.org/blog/?feed=rss2" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://sarielhp.org/blog" title="Vanity of Vanities, all is Vanity">Sariel Har-Peled</a>
<br>
<a class="feedlink" href="https://www.scottaaronson.com/blog/?feed=atom" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<br>
<a class="feedlink" href="https://blog.simons.berkeley.edu/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://blog.simons.berkeley.edu" title="Calvin Café: The Simons Institute Blog">Simons Institute blog</a>
<br>
<a class="feedlink" href="https://tcsplus.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<br>
<a class="feedlink" href="http://feeds.feedburner.com/TheGeomblog" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://blog.geomblog.org/" title="The Geomblog">The Geomblog</a>
<br>
<a class="feedlink" href="https://theorydish.blog/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://theorydish.blog" title="Theory Dish">Theory Dish: Stanford blog</a>
<br>
<a class="feedlink" href="https://thmatters.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://thmatters.wordpress.com" title="Theory Matters">Theory Matters</a>
<br>
<a class="feedlink" href="https://mycqstate.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://mycqstate.wordpress.com" title="MyCQstate">Thomas Vidick</a>
<br>
<a class="feedlink" href="https://agtb.wordpress.com/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://agtb.wordpress.com" title="Turing's Invisible Hand">Turing's invisible hand</a>
<br>
<a class="feedlink" href="https://windowsontheory.org/feed/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="https://windowsontheory.org" title="Windows On Theory">Windows on Theory</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CC" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.CG" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.DS">arXiv.org: Computational geometry</a>
<br>
<a class="feedlink" href="http://export.arxiv.org/rss/cs.DS" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://arxiv.org/" class="message" title="duplicate subscription: http://export.arxiv.org/rss/cs.CC">arXiv.org: Data structures and Algorithms</a>
<br>
<a class="feedlink" href="http://bit-player.org/feed/atom/" title="subscribe"> <img src="images/feed-icon.png" width=20 height=20 alt="(feed)" class="feedicon" border=0></a> 
<a href="http://bit-player.org" title="bit-player">bit-player</a>
<br>
</div>

<p>
Maintained by <A href="https://www.comp.nus.edu.sg/~arnab/">Arnab Bhattacharyya</A>, <a href="http://www.gautamkamath.com/">Gautam Kamath</a>, &amp; <A href="http://www.cs.utah.edu/~suresh/">Suresh Venkatasubramanian</a> (<a href="mailto:arbhat+cstheoryfeed@gmail.com">email</a>).
</p>

<p>
Last updated <span class="datestr">at March 10, 2020 12:21 AM UTC</span>.
<p>
Powered by<br>
<a href="http://www.intertwingly.net/code/venus/planet/"><img src="images/planet.png" alt="Planet Venus" border="0"></a>
<p/><br/><br/>
</div>
<div class="maincontent">
<h1 align=center>Theory of Computing Blog Aggregator</h1>








<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/030">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/030">TR20-030 |  Barriers for Rectangular Matrix Multiplication | 

	Matthias Christandl, 

	François Le Gall, 

	Vladimir Lysikov, 

	Jeroen Zuiddam</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We study the algorithmic problem of multiplying large matrices that are rectangular. We prove that the method that has been used to construct the fastest algorithms for rectangular matrix multiplication cannot give optimal algorithms. In fact, we prove a precise numerical barrier for this method. Our barrier improves the previously known barriers, both in the numerical sense, as well as in its generality. We prove our result using the asymptotic spectrum of tensors. More precisely, we crucially make use of two families of real tensor parameters with special algebraic properties: the quantum functionals and the support functionals. In particular, we prove that any lower bound on the dual exponent of matrix multiplication $\alpha$ via the big Coppersmith-Winograd tensors cannot exceed 0.625.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/030"><span class="datestr">at March 09, 2020 03:23 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4322">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/03/09/i-have-been-practicing-for-this-my-whole-life/">I have been practicing for this my whole life</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>As the coronavirus epidemic advances in Italy with a 25-30% growth rate (meaning that the numbers are doubling every 3-4 days), and after two weeks of “lockdown-lite” in Northern Italy seems to have made no difference, the Italian government imposed on Sunday morning a stricter lockdown on the region of Lombardy and some cities outside the region including Venice. Several people have reached out to ask how things are going, so here is a brief recap. </p>
<p><span id="more-4322"></span></p>
<p>First of all, I would like to give a shoutout to Taiwan, which is currently the country that has done the <a href="https://www.zmescience.com/other/pieces/how-taiwan-managed-to-avoid-a-coronavirus-outbreak/">best job stopping an outbreak</a>. The Taiwanese have several things going for them: the SARS scare made the government plan for the next epidemic, instead of making it up as it would go along, and their preparedness was impressive. The plan focused on isolation, contact-tracing, and people being careful: kudos to the Taiwanese for how well they complied. From the little that I have learned about Taiwan after living there for two months a couple of years ago, the Taiwanese are not rule-followers the way the Swiss or the Singaporean can be. But if they bend or break rules, they do that after a lot of consideration for how this impacts others. Basically, people <i>care about strangers</i>, a disposition that helps a lot in controlling an epidemic (and which is not a big part of the Italian national mood).</p>
<p>But let’s talk about me. This is my mood right now:<br />
<img src="https://lucatrevisan.files.wordpress.com/2020/03/self_isolate.png?w=584" alt="self_isolate" class="alignnone size-full wp-image-4326" /></p>
<p>(Image credit: <a href="https://xkcd.com/">xkcd</a> by Randall Munroe)</p>
<p>Since we are past isolation-and-contact-tracing, the main goal is to reduce person-to-person contact so that we can stop the exponential growth. For the past two weeks, besides the usual recommendations (do not kiss hello and goodbye, do not shake hands, wash hands frequently, do not touch your face) the government recommended keeping a one-meter distance from other people. There has been some inventive ways to keep going under these requirements. For example cinemas (in the regions in which they were not required to shut down) sold tickets for at most a third of the seats, asking people to leave two empty seats between any occupied seats. </p>
<p>Last Saturday, before the newest set of regulations were in place, I went out for a drink. The bar had cordoned off the counter area</p>
<p> <img src="https://lucatrevisan.files.wordpress.com/2020/03/img_9383.jpg?w=584" alt="IMG_9383" class="alignnone size-full wp-image-4328" /></p>
<p>They asked everybody who came in to seat down, at one of a few well-separated tables. Gloves-wearing servers took orders and brought some food (instead of the usual buffet). Once all tables were taken, a server stood outside preventing other people from coming in.</p>
<p>As we were drinking our aperitivi at a safe distance from each other, news began to leak of the new measures, which the government eventually announced at 2am Sunday morning. The leak suggested that Lombardy, Venice, and other places, would be included in the so-called <i>red zone</i>, which was a group of small towns that had been completely isolated for the past two weeks (nobody could go in and out except ambulances, trash collection trucks, and deliveries). In a development that might not have happened in Taiwan, a few hundred people rushed to train stations in Milan and Venice to flee South.</p>
<p>The actual regulations allowed travel in and out of the places affected by the new lockdown, but only for <i>demonstrated work or health reasons</i>. This is what the regulation said, but how would people prove their reason? The Italian genius for bureaucracy started cranking in the next few hours, and now, at train stations, people are required to sign an affidavit stating the existence of such a reason before boarding a train:</p>
<p><img src="https://lucatrevisan.files.wordpress.com/2020/03/affidavit.jpeg?w=584" alt="affidavit" class="alignnone size-full wp-image-4329" /></p>
<p>In the locked-down cities, all bars and restaurants have to close by 6pm, and all places where people may congregate (including churches, gyms, swimming pools, in addition to museums, schools and universities which were already closed) are closed all day. Even funeral and weddings are banned. Grocery stores will have to ensure that people stay within a meter of each other, making people wait outside and enter in small groups if necessary.</p>
<p>What about me? I am procrastinating on writing blog posts about online optimization and on reviewing papers for ICALP, I have started reading William Gibson’s latest novel <i>Agency</i> and watching the tv series <i>Pose</i>, and I am cooking every meal. Considering that I like to sleep and that I am spending a fair amount of time on the phone, I have got the whole day covered.</p>
<p>What is next? At this point in Lombardy about a person in 2,500, or 0.04% of the population, is infected, and we have run out of ICU beds. The rate of infection in Wuhan peaked at about 0.6% of the population, and this was well past the point at which they had run out of hospital beds in general. Hopefully, here we will peak well below that. On the other hand, left to its own devices, in the absence of any containment measures, I have seen estimates that the disease would peak a bit higher than a flu epidemic, at 20% or even 60% of the population.</p>
<p>So, find the Taiwanese in yourself, think about others, and wash those hands.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/03/09/i-have-been-practicing-for-this-my-whole-life/"><span class="datestr">at March 09, 2020 12:24 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16767">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/03/08/the-virtue-of-closed-problems/">The Virtue of Closed Problems</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>A new condition in property testing</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/03/aliakbarpoursilwal.png"><img src="https://rjlipton.files.wordpress.com/2020/03/aliakbarpoursilwal.png?w=181&amp;h=125" alt="" width="181" class="alignright wp-image-16769" height="125" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Composite crop of <a href="https://risingstars18-eecs.mit.edu/participant-aliakbarpour/">src1</a>, <a href="http://sandeepsilwal.com/">src2</a></font></td>
</tr>
</tbody>
</table>
<p>
Maryam Aliakbarpour and Sandeep Silwal are PhD students at MIT. They have a joint <a href="https://arxiv.org/pdf/1911.07324.pdf">paper</a> titled, “Testing Properties of Multiple Distributions with Few Samples.” Aliakbarpour is advised by Ronitt Rubinfeld. Silwal has a different advisor, Piotr Indyk. Could we test which advisor is better by sampling? Haha, not a chance…</p>
<p>
Today we will discuss this paper as an example of the power of computer science theory.</p>
<p>
Aliakbarpour and Silwal (AS) prove results on property testing, which is of course a long studied area in statistics, in mathematics, and in complexity theory. Many problems of property testing are open; many are very hard problems, and some are really impossible—such as distinguishing slight differences between distributions. With all due respect, the brilliance of their paper is not in solving open problems. Rather it is how they modify property testing in a novel manner. </p>
<p>
Their proofs are clever, are technically strong, but we feel more importantly is how they change the problems. That is, they show how to add a new constraint to property testing, where: </p>
<ol>
<li>
The constraint is reasonable and appears to be natural; <p></p>
</li><li>
The constraint is powerful and allows efficient algorithms where previously none were possible.
</li></ol>
<p>Let’s look at this more closely.</p>
<p>
</p><p></p><h2> Opening a Closed Problem </h2><p></p>
<p></p><p>
We all know about open problems and closed problems. There are however two kinds of closed problems: ones that have been settled and ones that have been proved impossible to settle. We also know that one can often take an open problem and define a meaningful subcase of it that can be solved. What may be less obvious is how one can do the same with the latter kind of closed problem.</p>
<p>
The work of AS is a perfect example of this phenomenon. They take a problem that is unsolvable and change it to one that is solvable. The details of their results are less important than their change to the underlying problem. One of the key insights throughout theory is that we often have made major progress by changing the ground rules. The AS work is a particularly clear case of this. </p>
<p></p><h2> The New Condition </h2><p></p>
<p></p><p>
AS call it the <i>structural condition</i>. They postulate a consistency type of condition on property testing. Suppose that one is interesting in testing whether or not a collection of slot-machines are fair. That is, are they set to cheat players or not? This is known to be hard to do with few tests. But after adding their new constraint it becomes quite efficient.</p>
<p>
Among some examples to convey their definition, they postulate a row of slot machines in a casino that are supposed to give the same distribution of prizes <img src="https://s0.wp.com/latex.php?latex=%7Bj%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{j}" class="latex" title="{j}" /> with known <em>fair</em> probabilities <img src="https://s0.wp.com/latex.php?latex=%7Bq%28j%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q(j)}" class="latex" title="{q(j)}" />. As usual with property testing we want to distinguish between two hypotheses that are some distance apart: one that the machines conform to the fair distribution <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> and an alternative hypothesis that each is far from fair. There are two relevant factors:</p>
<ol>
<li>
We do not get to make many tests on one machine of our choosing. The best we can do is watch people try the machines. They may try different machines and so give only a few sample results per machine. <p></p>
</li><li>
There are cases of this situation 1 where although each machine is far from fair the joint distribution of a few samples cannot be told apart from fair. The authors mention a trivial case where <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> is uniform and we get just one result from each machine, results all different from each other. These cannot be told apart. But there are less-trivial cases.
</li></ol>
<p>
Such situations are common with real-word data. The authors mention cases of medical data when one gets just one or a few blood readings from patients with disparate situational factors that can bias their samples. The joint effect of the biases may completely mask the systematic population tendency one is trying to test for. This is the setting in which the problem of distinguishing has been regarded as impossible, case closed. In the slot-machine example, Aliakbarpour and Silwal state their structural condition informally as follows:</p>
<blockquote><p><b> </b> <em> Our goal is to test whether all the machines were fair … or they are far from being fair. In this case, we can naturally assume that if the machines are unfair, the house will assign a lower probability to the expensive prizes, and higher probability to cheap ones. </em>
</p></blockquote>
<p></p><p>
Of course, the house <em>could</em> cheat players without cheating in this uniform manner. More subtle rigging of the machines in different ways could mask the lowered expectation. But what AS are saying is: <i>Provided the house cheats in this consistent manner, then they can be discovered quickly</i>. </p>
<p>
</p><p></p><h2> Formal Definition and Proof Idea </h2><p></p>
<p></p><p>
The formal definition is that each of the true source distributions is biased the same way in the same components as the expected (“fair”) distribution:</p>
<blockquote><p><b>Definition 1</b> <em> A sequence <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E1%2C%5Cdots%2C+p%5Em%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{p^1,\dots, p^m}" class="latex" title="{p^1,\dots, p^m}" /> of distributions on a discrete domain <img src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{[n]}" class="latex" title="{[n]}" /> obeys the structural condition relative to the distribution <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> if there is a subset <img src="https://s0.wp.com/latex.php?latex=%7BA+%5Csubset+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{A \subset [n]}" class="latex" title="{A \subset [n]}" /> such that for all <img src="https://s0.wp.com/latex.php?latex=%7Bi+%5Cin+%5Bm%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i \in [m]}" class="latex" title="{i \in [m]}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bj+%5Cin+%5Bn%5D%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{j \in [n]}" class="latex" title="{j \in [n]}" />: </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Bcases%7D+p%5Ei%28j%29+%5Cgeq+q%28j%29+%26+%5Ctext%7Bif+%7D+j+%5Cin+A%5C%5C+p%5Ei%28j%29+%5Cleq+q%28j%29+%26+%5Ctext%7Botherwise%7D.+%5Cend%7Bcases%7D+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{cases} p^i(j) \geq q(j) &amp; \text{if } j \in A\\ p^i(j) \leq q(j) &amp; \text{otherwise}. \end{cases} " class="latex" title="\displaystyle  \begin{cases} p^i(j) \geq q(j) &amp; \text{if } j \in A\\ p^i(j) \leq q(j) &amp; \text{otherwise}. \end{cases} " /></p>
</em><p><em></em>
</p></blockquote>
<p></p><p>
The term “structural condition” is vanilla and perhaps saying the <img src="https://s0.wp.com/latex.php?latex=%7Bp%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^i}" class="latex" title="{p^i}" /> are “conformally biased” relative to <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> would be more descriptive. A major point which the authors emphasize right afterward is that the set <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> is <em>unknown</em>. There are exponentially many possibilities for what <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> could be—so we cannot try to guess it. Rather, proofs using this condition need to exploit how all the <img src="https://s0.wp.com/latex.php?latex=%7Bp%5E%7Bi%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^{i}}" class="latex" title="{p^{i}}" /> distributions conform to the same <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />. The slot-machine example arguably does not reflect this point in full—because we can know in advance what the major and minor prizes of a slot machine are (including “no prize” among the latter). The medical-data examples and others certainly do, however.</p>
<p>
We can convey briefly and intuitively how this condition is used for the case where <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> is uniform distribution on <img src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[n]}" class="latex" title="{[n]}" />—which is quite general as testing for many distributions can be efficiently mapped into this case. A key property of uniform distribution is that among all distributions on <img src="https://s0.wp.com/latex.php?latex=%7B%5Bn%5D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{[n]}" class="latex" title="{[n]}" />, it minimizes the probability of getting <em>collisions</em> from repeated samples. This idea has yielded the most effective test statistics for problems when there is only one distribution <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" />. When there are multiple <img src="https://s0.wp.com/latex.php?latex=%7Bp%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^i}" class="latex" title="{p^i}" /> the effectiveness can be blunted in instances like the one in the previous section—the instances that are impossible. </p>
<p>
However, AS show that their structural condition is just what’s needed to bridge the gap that keeps the impossible cases from being distinguished. Realizing that the compounded complications of having multiple <img src="https://s0.wp.com/latex.php?latex=%7Bp%5Ei%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^i}" class="latex" title="{p^i}" /> can be resolved by this stroke is their act of brilliance. Their paper applies it successfully to two other problem settings—identity testing and closeness testing—and also shows meaningful instances that obey and are resolved by their definition but that escape an older condition involving product distributions. As usual, we say to see the <a href="https://arxiv.org/pdf/1911.07324.pdf">paper</a> for the details.</p>
<p>
</p><p></p><h2> Consequences in Crypto and Inference? </h2><p></p>
<p></p><p>
It remains our place to ask, in which other cases might the AS condition arise and what uses might it have? I can think first of one implication for adversarial strategies in cryptography. It goes like this:</p>
<p>
We can view the AS theorems as saying that anyone who wishes to cheat others should <b>not</b> be consistent. Being consistent according to some utility criterion—<em>even an unknown one</em>—makes it easier for others to detect that they are cheating. </p>
<p>
Following their slot-machine example suggests this: Arrange the machines in total to cheat players. But make it so that they are not consistent. They can set some prizes up in probability and some lower, and importantly, do this differently on different machines. They could even make some machines pay out more than the legal expectation—while still giving a small profit to the casino so it does not become too obvious to customers that those machines are “lucky.” There is safety in non-conformity alone. </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5CS+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \S " class="latex" title="\displaystyle  \S " /></p>
<p>
Ken notices a similarity to the chess-modeling situation he began describing in this recent <a href="https://rjlipton.wordpress.com/2019/11/29/predicating-predictivity/">post</a>. Instead of prizes of known value, in chess we have distributions over possible moves whose values are <em>not</em> so readily apparent to the player—that’s what makes chess challenging to play. </p>
<p>
In his case, giving any chess position <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> and a player <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> having that position, he postulates a true distribution <img src="https://s0.wp.com/latex.php?latex=%7Bp%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^t}" class="latex" title="{p^t}" /> of moves <img src="https://s0.wp.com/latex.php?latex=%7BP%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{P}" class="latex" title="{P}" /> would make and wants to compare that with the distribution <img src="https://s0.wp.com/latex.php?latex=%7Bq%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q^t}" class="latex" title="{q^t}" /> projected by his model. Now there can be many positions <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> with different characteristics, but Ken can treat the distributions <img src="https://s0.wp.com/latex.php?latex=%7Bq%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q^t}" class="latex" title="{q^t}" /> coming from his model as one fixed point of reference <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" />, and he can give different positions the same ranks of legal moves <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" /> (best), then <img src="https://s0.wp.com/latex.php?latex=%7B2%2C%5Cdots%2C+n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2,\dots, n}" class="latex" title="{2,\dots, n}" />. If positions have different numbers of legal moves he can pad them out by treating illegal moves the same as completely losing blunders. </p>
<p>
So he has a situation like this: different <img src="https://s0.wp.com/latex.php?latex=%7Bp%5Et%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p^t}" class="latex" title="{p^t}" /> and one <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> over a bunch of positions. Ken knows his model not only varies in accuracy but is biased in ways explained in that post. It appears that this bias is highly conformal. The model is trained to make the projection <img src="https://s0.wp.com/latex.php?latex=%7Bq%281%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q(1)}" class="latex" title="{q(1)}" /> of the probability of the first move accurate on average. Then the tendency is that the projections of the second-best and third-best moves are off one way, and the projections of all the other moves are off the other way. This is like having <img src="https://s0.wp.com/latex.php?latex=%7BA+%3D+%5C%7B2%2C3%5C%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A = \{2,3\}}" class="latex" title="{A = \{2,3\}}" /> or its complement most of the time. The new statistical tests that Ken is crafting also live under the specter of impossibility. A co-worker has demonstrated that they <em>fail</em> in cases randomly generated from normal distributions. But so far they are appearing to succeed in Ken’s more-structured situations from his real-world chess data. On this we will stay tuned.</p>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Does the AS paper say something about cryptography? How widely does their condition apply?</p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2020/03/08/the-virtue-of-closed-problems/"><span class="datestr">at March 09, 2020 03:58 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.03258">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.03258">Fast calculation of the variance of edge crossings in random linear arrangements</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/a/Alemany=Puig:Llu=iacute=s.html">Lluís Alemany-Puig</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Ferrer=i=Cancho:Ramon.html">Ramon Ferrer-i-Cancho</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.03258">PDF</a><br /><b>Abstract: </b>The interest in spatial networks where vertices are embedded in a
one-dimensional space is growing. Remarkable examples of these networks are
syntactic dependency trees and RNA structures. In this setup, the vertices of
the network are arranged linearly and then edges may cross when drawn above the
sequence of vertices. Recently, two aspects of the distribution of the number
of crossings in uniformly random linear arrangements have been investigated:
the expectation and the variance. While the computation of the expectation is
straightforward, that of the variance is not. Here we present fast algorithms
to calculate that variance in arbitrary graphs and forests. As for the latter,
the algorithm calculates variance in linear time with respect to the number of
vertices. This paves the way for many applications that rely on an exact but
fast calculation of that variance. These algorithms are based on novel
arithmetic expressions for the calculation of the variance that we develop from
previous theoretical work.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.03258"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.03222">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.03222">Generating a Gray code for prefix normal words in amortized polylogarithmic time per word</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/b/Burcsi:P=eacute=ter.html">Péter Burcsi</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/f/Fici:Gabriele.html">Gabriele Fici</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lipt=aacute=k:Zsuzsanna.html">Zsuzsanna Lipták</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Raman:Rajeev.html">Rajeev Raman</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sawada:Joe.html">Joe Sawada</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.03222">PDF</a><br /><b>Abstract: </b>A prefix normal word is a binary word with the property that no substring has
more 1s than the prefix of the same length. By proving that the set of prefix
normal words is a bubble language, we can exhaustively list all prefix normal
words of length n as a combinatorial Gray code, where successive strings differ
by at most two swaps or bit flips. This Gray code can be generated in O(log^2
n) amortized time per word, while the best generation algorithm hitherto has
O(n) running time per word. We also present a membership tester for prefix
normal words, as well as a novel characterization of bubble languages.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.03222"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.03108">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.03108">Algorithms for the rainbow vertex coloring problem on graph classes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lima:Paloma_T=.html">Paloma T. Lima</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Leeuwen:Erik_Jan_van.html">Erik Jan van Leeuwen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wegen:Marieke_van_der.html">Marieke van der Wegen</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.03108">PDF</a><br /><b>Abstract: </b>Given a vertex-colored graph, we say a path is a rainbow vertex path if all
its internal vertices have distinct colors. The graph is rainbow
vertex-connected if there is a rainbow vertex path between every pair of its
vertices. In the Rainbow Vertex Coloring (RVC) problem we want to decide
whether the vertices of a given graph can be colored with at most $k$ colors so
that the graph becomes rainbow vertex-connected. This problem is known to be
NP-complete even in very restricted scenarios, and very few efficient
algorithms are known for it. In this work, we give polynomial-time algorithms
for RVC on permutation graphs, powers of trees and split strongly chordal
graphs. The algorithm for the latter class also works for the strong variant of
the problem, where the rainbow vertex paths between each vertex pair must be
shortest paths. We complement the latter result by showing that, for any fixed
$p\geq 3$ the problem becomes NP-complete when restricted to split
$(S_3,\ldots,S_p)$-free graphs, where $S_q$ denotes the $q$-sun graph.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.03108"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.03058">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.03058">Exponentially Faster Shortest Paths in the Congested Clique</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/d/Dory:Michal.html">Michal Dory</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/p/Parter:Merav.html">Merav Parter</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.03058">PDF</a><br /><b>Abstract: </b>We present improved deterministic algorithms for approximating shortest paths
in the Congested Clique model of distributed computing. We obtain
$poly(\log\log n)$-round algorithms for the following problems in unweighted
undirected $n$-vertex graphs:
</p>
<p>-- $(1+\epsilon)$-approximation of multi-source shortest paths (MSSP) from
$O(\sqrt{n})$ sources.
</p>
<p>-- $(2+\epsilon)$-approximation of all pairs shortest paths (APSP).
</p>
<p>-- $(1+\epsilon,\beta)$-approximation of APSP where $\beta=O(\frac{\log\log
n}{\epsilon})^{\log\log n}$.
</p>
<p>These bounds improve exponentially over the state-of-the-art poly-logarithmic
bounds due to [Censor-Hillel et al., PODC19]. It also provides the first
nearly-additive bounds for the APSP problem in sub-polynomial time. Our
approach is based on distinguishing between short and long distances based on
some distance threshold $t = O(\frac{\beta}{\epsilon})$ where
$\beta=O(\frac{\log\log n}{\epsilon})^{\log\log n}$. Handling the long
distances is done by devising a new algorithm for computing sparse
$(1+\epsilon,\beta)$ emulator with $O(n\log\log n)$ edges. For the short
distances, we provide distance-sensitive variants for the distance tool-kit of
[Censor-Hillel et al., PODC19]. By exploiting the fact that this tool-kit
should be applied only on local balls of radius $t$, their round complexities
get improved from $poly(\log n)$ to $poly(\log t)$.
</p>
<p>Finally, our deterministic solutions for these problems are based on a
derandomization scheme of a novel variant of the hitting set problem, which
might be of independent interest.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.03058"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.03019">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.03019">Barriers for rectangular matrix multiplication</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.CC updates on arXiv.org">arXiv.org: Computational complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Christandl:Matthias.html">Matthias Christandl</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Gall:Fran=ccedil=ois_Le.html">François Le Gall</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/l/Lysikov:Vladimir.html">Vladimir Lysikov</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/z/Zuiddam:Jeroen.html">Jeroen Zuiddam</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.03019">PDF</a><br /><b>Abstract: </b>We study the algorithmic problem of multiplying large matrices that are
rectangular. We prove that the method that has been used to construct the
fastest algorithms for rectangular matrix multiplication cannot give optimal
algorithms. In fact, we prove a precise numerical barrier for this method. Our
barrier improves the previously known barriers, both in the numerical sense, as
well as in its generality. We prove our result using the asymptotic spectrum of
tensors. More precisely, we crucially make use of two families of real tensor
parameters with special algebraic properties: the quantum functionals and the
support functionals. In particular, we prove that any lower bound on the dual
exponent of matrix multiplication $\alpha$ via the big Coppersmith-Winograd
tensors cannot exceed 0.625.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.03019"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.02972">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.02972">LSF-Join: Locality Sensitive Filtering for Distributed All-Pairs Set Similarity Under Skew</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/r/Rashtchian:Cyrus.html">Cyrus Rashtchian</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/s/Sharma:Aneesh.html">Aneesh Sharma</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Woodruff:David_P=.html">David P. Woodruff</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.02972">PDF</a><br /><b>Abstract: </b>All-pairs set similarity is a widely used data mining task, even for large
and high-dimensional datasets. Traditionally, similarity search has focused on
discovering very similar pairs, for which a variety of efficient algorithms are
known. However, recent work highlights the importance of finding pairs of sets
with relatively small intersection sizes. For example, in a recommender system,
two users may be alike even though their interests only overlap on a small
percentage of items. In such systems, some dimensions are often highly skewed
because they are very popular. Together these two properties render previous
approaches infeasible for large input sizes. To address this problem, we
present a new distributed algorithm, LSF-Join, for approximate all-pairs set
similarity. The core of our algorithm is a randomized selection procedure based
on Locality Sensitive Filtering. Our method deviates from prior approximate
algorithms, which are based on Locality Sensitive Hashing. Theoretically, we
show that LSF-Join efficiently finds most close pairs, even for small
similarity thresholds and for skewed input sets. We prove guarantees on the
communication, work, and maximum load of LSF-Join, and we also experimentally
demonstrate its accuracy on multiple graphs.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.02972"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.02962">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.02962">Simultaneous robust subspace recovery and semi-stability of quiver representations</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b>Calin Chindris, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/k/Kline:Daniel.html">Daniel Kline</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.02962">PDF</a><br /><b>Abstract: </b>We consider the problem of simultaneously finding lower-dimensional subspace
structures in a given $m$-tuple of possibly corrupted, high-dimensional data
sets all of the same size. We refer to this problem as simultaneous robust
subspace recovery (SRSR) and provide a quiver invariant theoretic approach to
it. We show that SRSR is a particular case of the more general problem of
effectively deciding whether a quiver representation is semi-stable (in the
sense of Geometric Invariant Theory) and, in case it is not, finding a
subrepresentation certifying in an optimal way that the representation is not
semi-stable. In this paper, we show that SRSR and the more general quiver
semi-stability problem can be solved effectively.
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.02962"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://arxiv.org/abs/2003.02866">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/corr.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="http://arxiv.org/abs/2003.02866">Linear-Time Parameterized Algorithms with Limited Local Resources</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="http://arxiv.org/" title="cs.DS updates on arXiv.org">arXiv.org: Data structures and Algorithms</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p><b>Authors: </b><a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/c/Chen:Jianer.html">Jianer Chen</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/g/Guo:Ying.html">Ying Guo</a>, <a href="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/h/Huang:Qin.html">Qin Huang</a> <br /><b>Download:</b> <a href="http://arxiv.org/pdf/2003.02866">PDF</a><br /><b>Abstract: </b>We propose a new (theoretical) computational model for the study of massive
data processing with limited computational resources. Our model measures the
complexity of reading the very large data sets in terms of the data size N and
analyzes the computational cost in terms of a parameter k that characterizes
the computational power provided by limited local computing resources. We
develop new algorithmic techniques that implement algorithms for solving
well-known computational problems on the proposed model. In particular, we
present an algorithm that finds a k-matching in a general unweighted graph in
time O(N + k^{2.5}) and an algorithm that constructs a maximum weighted
k-matching in a general weighted graph in time O(N + k^3 log k). Both
algorithms have their space complexity bounded by O(k^2).
</p></div>







<p class="date">
<a href="http://arxiv.org/abs/2003.02866"><span class="datestr">at March 09, 2020 12:00 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/03/08/mathematics-books-women">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/03/08/mathematics-books-women.html">Mathematics books by women</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<p>It’s International Women’s Day, and <em>The Aperiodical</em> has a new piece up on “<a href="https://aperiodical.com/2020/03/iwd-2020-books-about-maths-by-women/">Books about Maths by Women</a>”. One of my own projects for the last few weeks has been to create Wikipedia articles on noteworthy mathematics books, and so far roughly half of the creations have included at least one woman among their authors. They are (alphabetical by title):</p>

<ul>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/The_Calculating_Machines">The Calculating Machines</a></em> (1992), by Ernst Martin, translated and edited by <a href="https://en.wikipedia.org/wiki/Peggy_A._Kidwell">Peggy A. Kidwell</a> and Michael R. Williams. A history of pre-World-War-II mechanical calculators.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Closing_the_Gap:_The_Quest_to_Understand_Prime_Numbers">Closing the Gap: The Quest to Understand Prime Numbers</a></em> (2017), by <a href="https://en.wikipedia.org/wiki/Vicky_Neale">Vicky Neale</a>. History and recent developments in the twin prime conjecture.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Combinatorics_of_Finite_Geometries">Combinatorics of Finite Geometries</a></em> (1986; 2nd ed. 1997), by <a href="https://en.wikipedia.org/wiki/Lynn_Batten">Lynn Batten</a>. An undergraduate textbook on finite projective planes, finite affine planes, and other finite geometries.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Complexities:_Women_in_Mathematics">Complexities: Women in Mathematics</a></em> (2005), edited by <a href="https://en.wikipedia.org/wiki/Bettye_Anne_Case">Bettye Anne Case</a> and <a href="https://en.wikipedia.org/wiki/Complexities:_Women_in_Mathematics">Anne M. Leggett</a>. A celebration of women in mathematics featuring the stories of over 80 women.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Crocheting_Adventures_with_Hyperbolic_Planes">Crocheting Adventures with Hyperbolic Planes</a></em> (2009; 2nd ed. 2018), by <a href="https://en.wikipedia.org/wiki/Daina_Taimina">Daina Taimina</a>. How to make hyperbolic surfaces out of crochet, and what we can learn mathematically from tactile interactions with these surfaces.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Difference_Equations:_From_Rabbits_to_Chaos">Difference Equations: From Rabbits to Chaos</a></em> (2005), by Paul Cull, <a href="https://en.wikipedia.org/wiki/Mary_Flahive">Mary Flahive</a>, and Robby Robson, an undergraduate textbook on finite difference equations, population dynamics, and related topics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/A_Guide_to_the_Classification_Theorem_for_Compact_Surfaces">A Guide to the Classification Theorem for Compact Surfaces</a></em> (2013), by Jean Gallier and <a href="https://en.wikipedia.org/wiki/Dianna_Xu">Dianna Xu</a>. An exposition of the result that the topology of a two-dimensional surface can be completely described by its orientability, Euler characteristic, and number of punctures.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Introduction_to_Tropical_Geometry">Introduction to Tropical Geometry</a></em> (2015) by <a href="https://en.wikipedia.org/wiki/Diane_Maclagan">Diane Maclagan</a> and Bernd Sturmfels. What happens if you do algebraic geometry in an arithmetic where the two basic operations are addition and minimization, instead of multiplication and addition?</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Mathematics_in_Ancient_Egypt:_A_Contextual_History">Mathematics in Ancient Egypt: A Contextual History</a></em> (2016), by <a href="https://en.wikipedia.org/wiki/Annette_Imhausen">Annette Imhausen</a>. The length of time covered by this history is greater than the length of time since it happened. Its focus is on putting Egyptian mathematics into the context of the society of the times, rather than (as in earlier studies) trying to translate it into modern mathematical concepts and analyze the mathematical foundations of Egyptian calculational methods.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Pearls_in_Graph_Theory">Pearls in Graph Theory: A Comprehensive Introduction</a></em> (1990), by Gerhard Ringel and <a href="https://www.legacy.com/obituaries/skagitvalleyherald/obituary.aspx?n=nora-anne-hartsfield&amp;pid=153284332&amp;fhid=5497">Nora Hartsfield</a>. A collection of the authors’ favorite topics in graph theory, although not as comprehensive as the title makes out.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Poincar%C3%A9_and_the_Three-Body_Problem">Poincaré and the Three-Body Problem</a></em> (1997), by <a href="https://en.wikipedia.org/wiki/June_Barrow-Green">June Barrow-Green</a>. The history surrounding Poincaré’s work on the the three-body problem, which led to chaos theory, began a long dispute between mathematicians and  astronomers over the convergence of series, and was a big part of Poincaré’s own fame.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Proofs_That_Really_Count">Proofs That Really Count: the Art of Combinatorial Proof</a></em> (2003), by Arthur Benjamin and <a href="https://en.wikipedia.org/wiki/Jennifer_Quinn">Jennifer Quinn</a>. An exposition of the concept of bijective proofs, in which one proves the equality of two integer formulas by showing that both count the same set of mathematical objects.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Quasicrystals_and_Geometry">Quasicrystals and Geometry</a></em> (1995), by <a href="https://en.wikipedia.org/wiki/Marjorie_Senechal">Marjorie Senechal</a>. An investigation of the relation between the mathematical properties of aperiodic tilings like the Penrose tiling, and physical quasicrystals whose X-ray diffraction patterns show systems of Bragg peaks with five-way symmetry.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Symmetry_in_Mechanics">Symmetry in Mechanics: A Gentle, Modern Introduction</a></em> (2001), by <a href="https://en.wikipedia.org/wiki/Stephanie_Singer">Stephanie Singer</a>. How to use symplectic geometry to reduce the solution of the two-body problem from twelve dimensions (three for the position and momentum of each body) to two, leading to an elegant derivation of Kepler’s laws of planetary motion.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Taking_Sudoku_Seriously">Taking Sudoku Seriously: The math behind the world’s most popular pencil puzzle</a></em> (2011), by Jason Rosenhouse and <a href="https://en.wikipedia.org/wiki/Laura_Taalman">Laura Taalman</a>. An exploration of various topics in mathematics related to Sudoku puzzles and their solution, including Latin squares, graph coloring, algorithms for solving systems of polynomials, and extremal combinatorics.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/De_numeris_triangularibus_et_inde_de_progressionibus_arithmeticis:_Magisteria_magna">Thomas Harriot’s Doctrine of Triangular Numbers</a></em> (2009), by Thomas Harriot, edited and translated by <a href="https://en.wikipedia.org/wiki/Janet_Beery">Janet Beery</a> and <a href="https://en.wikipedia.org/wiki/Jackie_Stedall">Jackie Stedall</a>. An important precursor to the invention of calculus by Newton, using finite differences instead of infinitesimal differences.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Treks_Into_Intuitive_Geometry">Treks into Intuitive Geometry: The World of Polygons and Polyhedra</a></em> (2015), by Jin Akiyama and Kiyoko Matsunaga. A Socratic dialogue on tessellations, polyhedra, polygonal dissections, and polyhedral unfoldings.</p>
  </li>
  <li>
    <p><em><a href="https://en.wikipedia.org/wiki/Viewpoints:_Mathematical_Perspective_and_Fractal_Geometry_in_Art">Viewpoints: Mathematical Perspective and Fractal Geometry in Art</a></em> (2011), by Marc Frantz and <a href="https://en.wikipedia.org/wiki/Annalisa_Crannell">Annalisa Crannell</a>. An undergraduate general-education textbook on perspective geometry and fractal structure in art.</p>
  </li>
</ul>

<p>There are many more I could include, but haven’t yet (including most of the <em>Aperiodical</em> list). Many of these books are award-winners, but to a large extent inclusion in this list is driven by my personal taste in books, so many of these are somewhat specialized rather than being general-audience books. But the main criterion for inclusion on Wikipedia is that everything must have multiple in-depth sources, and everything in the article must come from those sources. For books those sources are not the book itself, but (typically) published book reviews. The bare minimum is two reviews, but I’ve been aiming for books with at least four. So for instance I would have liked to include <em>Geometry: The Line and the Circle</em> (2019), by Maureen T. Carroll and Elyn Rykken, but I could find only <a href="https://www.maa.org/press/maa-reviews/geometry-the-line-and-the-circle">one review of it</a>, and that’s not enough. To all the book reviewers out there: your efforts are appreciated, and helpful.</p>

<p>(<a href="https://mathstodon.xyz/@11011110/103788964314558993">Discuss on Mastodon</a>)</p></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/03/08/mathematics-books-women.html"><span class="datestr">at March 08, 2020 11:40 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://ptreview.sublinear.info/?p=1270">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://ptreview.sublinear.info/?p=1270">News for February 2020</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://ptreview.sublinear.info" title="Property Testing Review">Property Testing Review</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Despite a wealth of February conference deadlines, papers were fairly sparse. We found <s>two</s> EDIT: three papers for the month of February, please share if we missed any relevant papers.</p>



<p><strong>Monotone probability distributions over the Boolean cube can be learned with sublinear samples</strong>, by Ronitt Rubinfeld and Arsen Vasilyan (<a href="https://arxiv.org/abs/2002.03415">arXiv</a>). By now, it is well known that assuming an (unknown) distribution enjoys some sort of structure can lead to more efficient algorithms for learning and testing. Often one proves that the structure permits a convenient representation, and exploits this representation to solve the problem at hand. This paper studies the learning of monotone distributions over the Boolean hypercube. The authors exploit and extend a structural statement about monotone Boolean <em>functions</em> by <a href="https://link.springer.com/chapter/10.1007/978-3-662-43948-7_20">Blais, Håstad, Servedio, and Tan</a>, using it to provide sublinear algorithms for estimating the support size, distance to uniformity, and the distribution itself.</p>



<p><strong>Locally Private Hypothesis Selection</strong>, by Sivakanth Gopi, Gautam Kamath, Janardhan Kulkarni, Aleksandar Nikolov, Zhiwei Steven Wu, and Huanyu Zhang (<a href="https://arxiv.org/abs/2002.09465">arXiv</a>). Given a collection of \(k\) distributions and a set of samples from one of them, can we identify which distribution it is? This paper studies this problem (and an agnostic generalization of it) under the constraint of <em>local differential privacy</em>. The authors show that this problem requires \(\Omega(k)\) samples, in contrast to the \(O(\log k)\) complexity in the non-private model. Furthermore, they give \(\tilde O(k)\)-sample upper bounds in various interactivity models.</p>



<p><strong>Efficient Distance Approximation for Structured High-Dimensional Distributions via Learning</strong>, by Arnab Bhattacharyya, Sutanu Gayen, Kuldeep S. Meel, and N. V. Vinodchandran (<a href="https://arxiv.org/abs/2002.05378">arXiv</a>). Given samples from two distributions, can you estimate the total variation distance between them? This paper gives a framework for solving this problem for <em>structured</em> distribution classes, including Ising models, Bayesian networks, Gaussians, and causal models. The approach can be decomposed properly learning the distributions, followed by estimating the distance between the two hypotheses. Challenges arise when densities are hard to compute exactly.</p></div>







<p class="date">
by Gautam Kamath <a href="https://ptreview.sublinear.info/?p=1270"><span class="datestr">at March 08, 2020 02:54 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4664">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4664">Coronavirus: the second-weirdest solution?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Many people have suggested coating handles, doorknobs and so forth with <a href="https://www.lesswrong.com/posts/LwcKYR8bykM6vDHyo/coronavirus-justified-practical-advice-thread">virus-killing copper tape</a>.  It’s a shame that this isn’t being tried on a wider scale.  In the meantime, though, here’s a related but different idea that I had last night.</p>



<p>Imagine we could coat every doorknob, every light switch, every railing, every other surface that people might touch in public buildings, with some long-lasting disgusting, sticky, slimy substance.  For a variety of reasons, one probably wouldn’t use actual excrement, although it wouldn’t hurt if the substance <em>looked like</em> that.  Or it could be a sickly neon green or red, to make it impossible to conceal when you’d gotten the substance on your hands.</p>



<p>What would be the result?  Of course, people would avoid touching these surfaces.  If they had to, they’d do so with a napkin or glove whenever possible.  If they had to touch them bare-handedly, they’d rush to wash their hands with soap as soon as possible afterwards.  Certainly they wouldn’t touch their faces before having washed their hands.</p>



<p>In short, they’d show exactly the behaviors that experts agree are among the most helpful, if our goal is to slow the spread of the coronavirus.  In effect, we’d be plugging an unfortunate gap in our evolutionary programming—namely, that the surfaces where viruses can thrive aren’t intuitively disgusting to us, as (say) vomit or putrid meat are—by <em>making</em> those surfaces disgusting, as they ought to be in the middle of a pandemic.</p>



<p>Note that, even if it <em>somehow</em> turns out to be infeasible to coat all the touchable surfaces in public buildings with disgusting goo, you might still derive great personal benefit from <em>imagining</em> them so covered.  If you manage to pull that off, it will yield just the right heuristic for when and how often you should now be washing your hands (and avoiding touching your face), without no need for additional conscious reflection.</p>



<p>Mostly, having the above thoughts made me grateful for my friend <a href="https://en.wikipedia.org/wiki/Robin_Hanson">Robin Hanson</a>.  For as long Robin is around, <a href="https://twitter.com/robinhanson/status/1235020994110205953">tweeting</a> and <a href="http://www.overcomingbias.com/2020/02/consider-controlled-infection.html">blogging</a> from his unique corner of mindspace, no one will ever be able to say that <em>my</em> ideas for how to control the coronavirus were the world’s weirdest or most politically tone-deaf.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4664"><span class="datestr">at March 06, 2020 10:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/029">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/029">TR20-029 |  Geometric Rank of Tensors and Subrank of Matrix Multiplication | 

	Guy Moshkovitz, 

	Swastik Kopparty, 

	Jeroen Zuiddam</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Motivated by problems in algebraic complexity theory (e.g., matrix multiplication) and extremal combinatorics (e.g., the cap set problem and the sunflower problem), we introduce the geometric rank as a new tool in the study of tensors and hypergraphs. We prove that the geometric rank is an upper bound on the subrank of tensors and the independence number of hypergraphs. We prove that the geometric rank is smaller than the slice rank of Tao, and relate geometric rank to the analytic rank of Gowers and Wolf in an asymptotic fashion. As a first application, we use geometric rank to prove a tight upper bound on the (border) subrank of the matrix multiplication tensors, matching Strassen's well-known lower bound from 1987.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/029"><span class="datestr">at March 06, 2020 03:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19462">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/03/06/a-new-polytcs-blog/">A new PolyTCS blog!</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>A new PolyTCS blog</p>
<div class="site-logo"><a href="https://polytcs.wordpress.com/" class="custom-logo-link" rel="home"><img src="https://polytcs.files.wordpress.com/2019/10/cropped-notequal.png?w=264&amp;h=96" alt="The PolyTCS Project" width="264" class="custom-logo" height="96" /></a></div>
<p class="site-title"><a href="https://polytcs.wordpress.com/" rel="home">The PolyTCS Project</a> is a new blog to run collaborative Theoretical Computer Science projects. The initiative is by two graduate students <a href="https://sites.google.com/site/xurupei/">Rupei Xu</a> and Chloe Yang. The logo was designed by Grigory Yaroslavtsev.</p>
<p>At this stage the blog raised possible projects to pursue.  A few days ago Rupei Xu discussed a second possible exciting project:   Project 2: <a href="https://polytcs.wordpress.com/2020/03/06/is-semi-definite-programming-sdp-polynomial-time-solvable/">Is Semi-Definite Programming (SDP) Polynomial-Time Solvable?</a> The first project-proposal (Nov 1, 2019 by Jiapeng Zhang) was <a href="https://polytcs.wordpress.com/2019/11/01/the-entropy-influence-conjecture/">Project 1: The Entropy-Influence Conjecture</a>.</p>
<p>(Here is a <a href="https://rjlipton.wordpress.com/2014/03/15/could-we-have-felt-evidence-for-sdp-p/">2014  post on GLL</a> on the problem of Project 2, and here is <a href="https://terrytao.wordpress.com/2007/08/16/gil-kalai-the-entropyinfluence-conjecture/">my 2007 post on WN</a> on the problem of Project 1.)</p>
<p class="site-title">Good luck!!!</p>
<p> </p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/03/06/a-new-polytcs-blog/"><span class="datestr">at March 06, 2020 02:05 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/03/06/postdoc-at-national-university-of-singapore-apply-by-april-15-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/03/06/postdoc-at-national-university-of-singapore-apply-by-april-15-2020/">Postdoc at National University of Singapore (apply by April 15, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Two post-doctoral positions are available for work on developing statistical and computational guarantees for causal inference algorithms. I am looking for candidates with strong publication records either in theoretical computer science and statistics or in causal inference. Please email me regarding your interest, along with your CV and names of two references. .</p>
<p>Website: <a href="https://www.comp.nus.edu.sg/~arnab/causal-postdoc.html">https://www.comp.nus.edu.sg/~arnab/causal-postdoc.html</a><br />
Email: arnabb@nus.edu.sg</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/03/06/postdoc-at-national-university-of-singapore-apply-by-april-15-2020/"><span class="datestr">at March 06, 2020 09:06 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4649">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4649">Turn down the quantum volume</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Several people asked me to comment on the recent announcement by Honeywell that they’ll soon have what they call “the most powerful” quantum computer (see <a href="https://www.honeywell.com/en-us/newsroom/news/2020/03/behind-the-scenes-of-a-major-quantum-breakthrough">here for press release</a>, <a href="https://www.forbes.com/sites/moorinsights/2020/03/03/honeywell-surprisingly-announces-it-will-be-releasing-the-most-powerful-quantum-computer-in-the-world/#c271c5114b4a">here for <em>Forbes</em> article</a>, <a href="https://www.honeywell.com/content/dam/honeywell/files/Beta_10_Quantum_3_3_2020.pdf">here for paper</a>).  </p>



<p>I’m glad that Honeywell, which many people might know as an air-conditioner manufacturer, has entered the race for trapped-ion QC.  I wish them success.  I’ve known about what they were doing in part because Drew Potter, my friend and colleague in UT Austin’s physics department, took a one-year leave from UT to contribute to their effort.</p>



<p>Here I wanted to comment about one detail in Honeywell’s announcement: namely, the huge emphasis on “quantum volume” as the central metric for judging quantum computing progress, and the basis for calling their own planned device the “most powerful.”  One journalist asked me to explain why quantum volume is such an important measure.  I had to give her an honest answer: I don’t know whether it is.</p>



<p>Quantum volume was invented a few years ago by a group at IBM.  According to one of <a href="https://arxiv.org/pdf/1811.12926.pdf">their papers</a>, it can be defined roughly as 2<sup>k</sup>, where k is the largest number such that you can run a k-qubit random quantum circuit, with depth k and with any-to-any connectivity, and have at least (say) 2/3 probability of measuring an answer that passes some statistical test.  (In the paper, they use what Lijie Chen and I named <a href="https://arxiv.org/abs/1612.05903">Heavy Output Generation</a>, though Google’s Linear Cross-Entropy Benchmark is similar.)</p>



<p>I don’t know why IBM takes the “volume” to be 2<sup>k</sup> rather than k itself.  Leaving that aside, though, the idea was to invent a single “goodness measure” for quantum computers that can’t be gamed <em>either</em> by building a huge number of qubits that don’t maintain nearly enough coherence (what one might call “the D-Wave approach”), <em>or</em> by building just one perfect qubit, <em>or</em> by building qubits that behave well in isolation but don’t interact easily.  Note that the any-to-any connectivity requirement makes things harder for architectures with nearest-neighbor interactions only, like the 2D superconducting chips being built by Google, Rigetti, or IBM itself.</p>



<p>You know the notion of a researcher’s <a href="https://en.wikipedia.org/wiki/H-index">h-index</a>—defined as the largest h such that she’s published h papers that garnered h citations each?  Quantum volume is basically an h-index for quantum computers.  It’s an attempt to take several different yardsticks of experimental progress, none terribly useful in isolation, and combine them into one “consumer index.”</p>



<p>Certainly I sympathize with the goal of broadening people’s focus beyond the “but how many qubits does it have?” question—since the answer to that question is meaningless without further information about what the qubits can <em>do</em>.  From that standpoint, quantum volume seems like a clear step in the right direction.</p>



<p>Alas, <a href="https://en.wikipedia.org/wiki/Goodhart%27s_law">Goodhart’s Law</a> states that “as soon as a measure becomes a target, it ceases to be a good measure.”  That happened years ago with the h-index, which now regularly pollutes academic hiring and promotion decisions, to the point where <a href="https://arxiv.org/abs/2001.09496">its inventor expressed regrets</a>.  Quantum volume is now looking to me like another example of Goodhart’s Law at work.</p>



<p>The position of Honeywell’s PR seems to be that, if they can build a device that can apply 6 layers of gates to 6 qubits, with full connectivity and good fidelity, that will then count as “the world’s most powerful quantum computer,” since it will have the largest volume.  One problem here is that such a device could be simulated by maintaining a vector of only 2<sup>6</sup>=64 amplitudes.  This is nowhere near quantum supremacy (i.e., beating classical computers at some well-defined task), which is a necessary though not sufficient condition for doing anything useful.</p>



<p>Think of a university that achieves an average faculty-to-student ratio of infinity by holding one class with zero students.  It gets the “best score” only by exploiting an obvious defect in the scoring system.</p>



<p>So what’s the alternative?  The policy <em>I</em> prefer is simply to tell the world all your system specs, as clearly as you can, with no attempts made to bury the lede.  How many qubits do you have?  With what coherence times?  With what connectivity?  What are the 1- and 2-qubit gate fidelities?  What depth of circuit can you do?  What resources do the standard classical algorithms need to simulate your system?  Most importantly: what’s the main drawback of your system, the spec that’s the <em>worst</em>, the one you most need to improve?  What prevents you from having a scalable quantum computer right now?  And are you going to tell me, or will you make me scour Appendix III.B in your paper, or worse yet, ask one of your competitors?</p>



<p>I confess that the answers to the above questions are hard to summarize in a single number (unless you, like, concatenated binary encodings of them or something).  But they <em>can</em> be ineffably combined, to produce a progress metric that one of my postdocs suggested calling “quantum scottness,” and which roughly equals the number of expressions of wide-eyed surprise minus the number of groans.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4649"><span class="datestr">at March 05, 2020 09:36 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-940496487994761300">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/03/a-new-college-of-computing-at-illinois.html">A New College of Computing at Illinois Tech</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div style="clear: both; text-align: center;" class="separator">
<a style="margin-left: 1em; margin-right: 1em;" href="https://1.bp.blogspot.com/-4o0elQGFp-c/XmAhjkpOpKI/AAAAAAABxio/I6qGUp1ot6UA8rJtL2GLvRDcZU3YEZhaQCLcBGAsYHQ/s1600/IllinoisTech_MiesCampus.jpg"><img width="400" src="https://1.bp.blogspot.com/-4o0elQGFp-c/XmAhjkpOpKI/AAAAAAABxio/I6qGUp1ot6UA8rJtL2GLvRDcZU3YEZhaQCLcBGAsYHQ/s400/IllinoisTech_MiesCampus.jpg" border="0" height="266" /></a></div>
<br />
In 1890, Chicago South Side pastor Frank Gunsaulus gave a sermon where he said that with a million dollars he could build a school where students of all backgrounds could prepare for meaningful roles in a changing industrial society. One of the congregants, Philip Armour, came up to him after the service and told Gunsaulus that "if you give me five years of your time, I will give you the money." Thus was born the Armour Institute of Technology, the forerunner of the Illinois Institute of Technology.<br />
<br />
Today Illinois Tech enters a new chapter, <a href="https://www.iit.edu/news/illinois-tech-creates-college-computing-fuel-chicagos-tech-rise">announcing a College of Computing</a>, and I am honored to have been asked to serve as its inaugural dean. The college will take on a horizontal mission, to infuse computation and data science thinking throughout the curriculum in every discipline, while understanding the power, limitations and social implications of the technologies they create. We will significantly grow computing to produce the talent needed for a growing Chicago tech community. The college will develop an agile curriculum to continually reevaluate our offerings as computing technology continues to advance, and develop education as a life-long process where our alumni can always count on Illinois Tech to continually reskill to advance their careers.<br />
<br />
We will do it all by keeping the core principle of the original "million-dollar sermon," as important as ever, to prepare students of all backgrounds for meaningful roles in a changing technological society.<br />
<div>
<br /></div></div>







<p class="date">
by Lance Fortnow (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/03/a-new-college-of-computing-at-illinois.html"><span class="datestr">at March 05, 2020 02:35 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://tcsplus.wordpress.com/?p=395">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/seminarseries.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://tcsplus.wordpress.com/2020/03/04/tcs-talk-wednesday-march-11-thomas-steinke-ibm-research-almaden/">TCS+ talk: Wednesday, March 11 — Thomas Steinke, IBM Research Almaden</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://tcsplus.wordpress.com" title="TCS+">TCS+ seminar series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The next TCS+ talk will take place this coming Wednesday, March 11th at 1:00 PM Eastern Time (10:00 AM Pacific Time, 18:00 Central European Time, 17:00 UTC). <strong>Thomas Steinke</strong> from IBM Research Almaden will speak about “<em>Reasoning About Generalization via Conditional Mutual Information</em>” (abstract below).</p>
<p>Please make sure you reserve a spot for your group to join us live by signing up on <a href="https://sites.google.com/site/plustcs/livetalk/live-seat-reservation">the online form</a>. In view of the recent travel restrictions and coronavirus precautions, in particular, do not hesitate to reserve a seat even for a group <i class="moz-txt-slash">of size one</i>: there should be enough room for everyone, so don’t be shy!</p>
<p>As usual, for more information about the TCS+ online seminar series and the upcoming talks, or to <a href="https://sites.google.com/site/plustcs/suggest">suggest</a> a possible topic or speaker, please see <a href="https://sites.google.com/site/plustcs/">the website</a>.</p>
<blockquote><p>Abstract: We provide an information-theoretic framework for studying the generalization properties of machine learning algorithms. Our framework ties together existing approaches, including uniform convergence bounds and recent methods for adaptive data analysis. Specifically, we use Conditional Mutual Information (CMI) to quantify how well the input (i.e., the training data) can be recognized given the output (i.e., the trained model) of the learning algorithm. We show that bounds on CMI can be obtained from VC dimension, compression schemes, differential privacy, and other methods. We then show that bounded CMI implies various forms of generalization.</p>
<p>Based on joint work with Lydia Zakynthinou.</p></blockquote></div>







<p class="date">
by plustcs <a href="https://tcsplus.wordpress.com/2020/03/04/tcs-talk-wednesday-march-11-thomas-steinke-ibm-research-almaden/"><span class="datestr">at March 05, 2020 01:16 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4643">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4643">A coronavirus poem</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>These next few months, every time I stop myself from touching my face by force of will,</p>



<p>Let me remind myself that the same willpower is available to diet, to exercise, to throw myself into a project, to keep calm amid screaming, to introduce myself to strangers, to decrease the fraction of my life spent getting upset that someone was mean to my ingroup on social media, or otherwise to better myself as a human specimen.</p>



<p>Yea, let all of these things be just as easy for me as it was not to touch my face.</p>



<p>Ah, but what if I forget, what if I do keep touching my face in the next few months?</p>



<p>In one plausible scenario, with at least ~0.1% probability and probably higher depending on my age, a cheap answer will be available to that question: namely, that I’ll no longer be around to ponder the implications.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4643"><span class="datestr">at March 04, 2020 02:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4635">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4635">Paperz</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Soon, all anyone will want to talk about is quarantines, food shortages, N95 masks, the suspension of universities and of scientific conferences.  (As many others have pointed out, this last might actually be a boon to scientific productivity—as it was for a young Isaac Newton when Cambridge was closed for the bubonic plague, so Newton went home and invented calculus and mechanics.)</p>



<p>Anyway, before that all happens, I figured I’d get in a last post about quantum information and complexity theory progress.</p>



<p>Hsin-Yuan Huang, Richard Kueng, and John Preskill have a nice preprint entitled <a href="https://arxiv.org/abs/2002.08953">Predicting Many Properties of a Quantum System from Very Few Measurements</a>.  In it they take <a href="https://arxiv.org/abs/1711.01053">shadow tomography</a>, which I proposed a couple years ago, and try to bring it closer to practicality on near-term devices, by restricting to the special case of non-adaptive, one-shot measurements, on separate copies of the state ρ that you’re trying to learn about.  They show that this is possible using a number of copies that depends logarithmically on the number of properties you’re trying to learn (the optimal dependence), not at all on the Hilbert space dimension, and linearly on a new “shadow norm” quantity that they introduce.</p>



<p>Rahul Ilango, Bruno Loff, and Igor Oliveira announced the pretty spectacular-sounding result that the <a href="https://eccc.weizmann.ac.il/report/2020/021/">Minimum Circuit Size Problem (MCSP) is NP-complete for multi-output functions</a>—that is, for Boolean functions f with not only many input bits but many outputs.  Given the 2<sup>n</sup>-sized truth table of a Boolean function f:{0,1}<sup>n</sup>→{0,1}, the original MCSP simply asks for the size of the smallest Boolean circuit that computes f.  This problem was studied in the USSR as early as the 1950s; whether it’s NP-complete has stood for decades as one of the big open problems of complexity theory.  We’ve known that if you could quickly solve MCSP then you could also invert any one-way function, but we’ve also known technical barriers to going beyond that to a flat-out NP-hardness result, at least via known routes.  Before seeing this paper, I’d never thought about whether MCSP for many-output functions might somehow be easier to classify, but apparently it is!</p>



<p>Hamoon Mousavi, Seyed Nezhadi, and Henry Yuen have now taken the MIP*=RE breakthrough even a tiny step further, by showing that <a href="https://arxiv.org/abs/2002.10490">“zero-gap MIP*”</a> (that is, quantum multi-prover interactive proofs with an arbitrarily small gap between the completeness and soundness probabilities) takes you <strong>even beyond the halting problem</strong> (i.e., beyond Recursively Enumerable or RE), and up to the second level of the arithmetical hierarchy (i.e., to the halting problem for Turing machines with oracles for the original halting problem).  This answers a question that someone asked <a href="https://www.scottaaronson.com/blog/?p=4512#comment-1829033">in the comments section of this blog</a>.</p>



<p>Several people asked me for comment on the paper <a href="https://arxiv.org/abs/2002.07730">What limits the simulation of quantum computers?</a>, by Yiqing Zhou, Miles Stoudenmire, and Xavier Waintal.  In particular, does this paper refute or weaken Google’s quantum supremacy claim, as the paper does <em>not</em> claim to do (but, rather coyly, also does not claim <em>not</em> to do)?  Short answer: No, it doesn’t, or not now anyway.</p>



<p>Longer, more technical answer: The quoted simulation times, just a few minutes for quantum circuits with 54 qubits and depth 20, <em>assume Controlled-Z gates rather than iSWAP-like gates.</em> Using tensor network methods, the classical simulation cost with the former is roughly the square root of the simulation cost with the latter (~2<sup>k</sup> versus ~4<sup>k</sup> for some parameter k related to the depth).  As it happens, Google switched its hardware from Controlled-Z to iSWAP-like gates a couple years ago precisely because they realized this—I had a conversation about it with Sergio Boixo at the time.  Once this issue is accounted for, the quoted simulation times in the new paper seem to be roughly in line with what was previously reported by, e.g., Johnnie Gray and Google itself.</p>



<p>Oh yeah, I enjoyed <a href="https://arxiv.org/abs/2002.09524">Quantum Homeopathy Works</a>.  Cool result, and the title is actually a pretty accurate description of the contents.</p>



<p>To end with a community announcement: as many of you might know, the American Physical Society’s March Meeting, which was planned for this week in Denver, was abruptly cancelled due to the coronavirus (leaving thousands of physicists out their flights and hotel rooms—many had even already arrived there).  However, my colleague Michael Biercuk kindly alerted me to a <a href="https://virtualmarchmeeting.com/">“virtual March Meeting”</a> that’s been set up online, with recorded talks and live webinars.  Even after the pandemic passes, is this a model that we should increasingly move to?  I wouldn’t have thought so ten or fifteen years ago, but today every schlep across the continent brings me a step closer to shouting “yes”…</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4635"><span class="datestr">at March 03, 2020 06:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16757">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/03/03/dyson-as-a-mathematician/">Dyson as a Mathematician</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>With a lemma from 1947 that might be useful today?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/03/dysonyoung.jpg"><img src="https://rjlipton.files.wordpress.com/2020/03/dysonyoung.jpg?w=148&amp;h=220" alt="" width="148" class="alignright wp-image-16759" height="220" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from <a href="https://www.nytimes.com/2018/04/17/books/review/freeman-dyson-maker-of-patterns.html">article</a> on his letters</font></td>
</tr>
</tbody>
</table>
<p>
Freeman Dyson passed away last February 28th, one day short of the leap day, February 29th. He was one of the great physicists, one of the great writers about science, and one of the great thinkers of all time. He is missed.</p>
<p>
Today we wish to discuss a tiny part of Dyson’s contributions to mathematics—and ask whether it has been developed further. </p>
<p><span id="more-16757"></span></p>
<p>
Dyson did so much in so many areas of science that we will leave it to others to discuss it. We covered a puzzle of his years ago <a href="https://rjlipton.wordpress.com/2014/09/09/a-challenge-from-dyson/">here</a>. He famously showed that quantum electrodynamics (QED) is a consistent theory—in particular showing that different theories connecting quantum mechanics and special relativity were the same. He published many interesting books about science in general. He speculated about aliens, about space travel, and much more.</p>
<p>
Our focus is on a beautiful result of his proved in 1947. A result about rational numbers. Nothing grandiose, nothing about infinite visions, nothing about worlds that we cannot easily imagine. </p>
<p>
</p><p></p><h2> Approximations To Numbers </h2><p></p>
<p></p><p>
For over 2000 years we have known that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{2}}" class="latex" title="{\sqrt{2}}" /> is not expressible as a rational fraction. This is sometimes credited to Hippasus of <a href="https://en.wikipedia.org/wiki/Hippasus">Metapontum</a>. The obvious question, at least to math types, is how close can we make it to a rational number? The answer is interesting, with many consequences. And includes some top mathematicians such as Johann Dirichlet, Joseph Liouville, Axel Thue, Carl Siegel, Dyson, and Klaus Roth.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Hippasus:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{2}}" class="latex" title="{\sqrt{2}}" /> is not rational.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Folklore:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{2}}" class="latex" title="{\sqrt{2}}" /> like all algebraic numbers <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> can be algorithmically approximated by rationals. Note that <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{2}}" class="latex" title="{\sqrt{2}}" /> is algebraic since it satisfies the equation 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++x%5E%7B2%7D+-+2+%3D+0%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  x^{2} - 2 = 0, " class="latex" title="\displaystyle  x^{2} - 2 = 0, " /></p>
<p>with <img src="https://s0.wp.com/latex.php?latex=%7BD%3D2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D=2}" class="latex" title="{D=2}" />. The number <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" /> is called the <em>degree</em> of <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" />.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Dirichlet:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> can be well approximated. That is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+%5Calpha+-+%5Cfrac%7Bp%7D%7Bq%7D+%5Cright%7C+%5Cle+%5Cfrac%7B1%7D%7Bq%5E%7B2%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{1}{q^{2}}, " class="latex" title="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{1}{q^{2}}, " /></p>
<p>can be done for infinitely many <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" />.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Liouville:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> cannot be too well approximated. That is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+%5Calpha+-+%5Cfrac%7Bp%7D%7Bq%7D+%5Cright%7C+%5Cle+%5Cfrac%7Bc%7D%7Bq%5E%7Bv%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " class="latex" title="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " /></p>
<p>cannot be done for infinitely many <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> and some constant <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c &gt; 0}" class="latex" title="{c &gt; 0}" /> provided <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> is larger than <img src="https://s0.wp.com/latex.php?latex=%7BD%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D}" class="latex" title="{D}" />.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Thue:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> cannot be too well approximated. That is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+%5Calpha+-+%5Cfrac%7Bp%7D%7Bq%7D+%5Cright%7C+%5Cle+%5Cfrac%7Bc%7D%7Bq%5E%7Bv%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " class="latex" title="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " /></p>
<p>cannot be done for infinitely many <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> and some constant <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c &gt; 0}" class="latex" title="{c &gt; 0}" /> provided <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> is larger than <img src="https://s0.wp.com/latex.php?latex=%7BD%2F2%2B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D/2+1}" class="latex" title="{D/2+1}" />.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Siegel:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> cannot be too well approximated. That is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+%5Calpha+-+%5Cfrac%7Bp%7D%7Bq%7D+%5Cright%7C+%5Cle+%5Cfrac%7Bc%7D%7Bq%5E%7Bv%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " class="latex" title="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " /></p>
<p>cannot be done for infinitely many <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> for some constant <img src="https://s0.wp.com/latex.php?latex=%7Bc%3E0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c&gt;0}" class="latex" title="{c&gt;0}" /> provided <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> is larger than <img src="https://s0.wp.com/latex.php?latex=%7B2%5Csqrt%7BD%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2\sqrt{D}}" class="latex" title="{2\sqrt{D}}" />.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Dyson:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> cannot be too well approximated. That is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+%5Calpha+-+%5Cfrac%7Bp%7D%7Bq%7D+%5Cright%7C+%5Cle+%5Cfrac%7Bc%7D%7Bq%5E%7Bv%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " class="latex" title="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{c}{q^{v}}, " /></p>
<p>cannot be done for infinitely many <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> for some constant <img src="https://s0.wp.com/latex.php?latex=%7Bc+%3E+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{c &gt; 0}" class="latex" title="{c &gt; 0}" /> provided <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> is larger than <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7B2D%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{2D}}" class="latex" title="{\sqrt{2D}}" />.</p>
<p>
<img src="https://s0.wp.com/latex.php?latex=%7B%5Cbullet+%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\bullet }" class="latex" title="{\bullet }" /> <b>Roth:</b> The value <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> cannot be too well approximated. That is 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cleft%7C+%5Calpha+-+%5Cfrac%7Bp%7D%7Bq%7D+%5Cright%7C+%5Cle+%5Cfrac%7B1%7D%7Bq%5E%7Bv%7D%7D%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{1}{q^{v}}, " class="latex" title="\displaystyle  \left| \alpha - \frac{p}{q} \right| \le \frac{1}{q^{v}}, " /></p>
<p>cannot be done for infinitely many <img src="https://s0.wp.com/latex.php?latex=%7Bp%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{p}" class="latex" title="{p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> provided <img src="https://s0.wp.com/latex.php?latex=%7BD+%5Cgeq+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{D \geq 2}" class="latex" title="{D \geq 2}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v}" class="latex" title="{v}" /> is larger than <img src="https://s0.wp.com/latex.php?latex=%7B2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2}" class="latex" title="{2}" />.</p>
<p>
Note that the last result is best possible in the sense that Dirichlet achieved <img src="https://s0.wp.com/latex.php?latex=%7Bv+%3D+D+%3D+2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{v = D = 2}" class="latex" title="{v = D = 2}" />, although slightly stronger statements than Roth can be made by using logarithms.</p>
<p>
To illustrate these formulas, Liouville proved that the following number is transcendental:</p>
<p></p><p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++%5Csum_%7Bk%3D1%7D%5E%7B%5Cinfty%7D+%5Cfrac%7B1%7D%7B10%5E%7Bk%21%7D%7D+%26%3D%26+0.110001000000000000000001000000000000000000000000000000000000%5C%5C+%09%26%26+00000000000000000000000000000000000000000000000000000000001%5Cdots+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}  \sum_{k=1}^{\infty} \frac{1}{10^{k!}} &amp;=&amp; 0.110001000000000000000001000000000000000000000000000000000000\\  &amp;&amp; 00000000000000000000000000000000000000000000000000000000001\dots \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}  \sum_{k=1}^{\infty} \frac{1}{10^{k!}} &amp;=&amp; 0.110001000000000000000001000000000000000000000000000000000000\\  &amp;&amp; 00000000000000000000000000000000000000000000000000000000001\dots \end{array} " /></p>
<p>
Note that the exponent in Liouville’s number grows as <img src="https://s0.wp.com/latex.php?latex=%7Bk%21+%5Capprox+%5Cexp%28k%5Clog+k%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k! \approx \exp(k\log k)}" class="latex" title="{k! \approx \exp(k\log k)}" />. The later formulas improve this to simply exponential in <img src="https://s0.wp.com/latex.php?latex=%7Bk%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{k}" class="latex" title="{k}" />. For instance, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Csum_%7Bk%3D1%7D%5E%7B%5Cinfty%7D%5Cfrac%7B1%7D%7B10%5E%7B2%5Ek%7D%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \sum_{k=1}^{\infty}\frac{1}{10^{2^k}} " class="latex" title="\displaystyle  \sum_{k=1}^{\infty}\frac{1}{10^{2^k}} " /></p>
<p>is transcendental. We’ll leave it to our readers to figure out which formula gives this consequence and will give the historical answer at the end. </p>
<p></p><h2> A Key Lemma </h2><p></p>
<p></p><p>
What we wish to highlight from Dyson’s 1947 <a href="https://projecteuclid.org/euclid.acta/1485888462">paper</a> is the main lemma for his proof. He called it the key new idea in his paper and also said it might have independent interest. We agree, and we abstract some of its statement into the following definitions. </p>
<p>
Suppose we have a polynomial <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" />. Call a point <img src="https://s0.wp.com/latex.php?latex=%7B%28x_0%2Cy_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(x_0,y_0)}" class="latex" title="{(x_0,y_0)}" /> a <em>zero of order <img src="https://s0.wp.com/latex.php?latex=%7B%28p%2Cq%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(p,q)}" class="latex" title="{(p,q)}" /></em> if <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+m+%5Cleq+p%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 \leq m \leq p}" class="latex" title="{0 \leq m \leq p}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+n+%5Cleq+q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{0 \leq n \leq q}" class="latex" title="{0 \leq n \leq q}" /> implies </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B%5Cpartial%5Em%7D%7B%5Cpartial+x%7D+%5Cfrac%7B%5Cpartial%5En%7D%7B%5Cpartial+y%7Df%28x+%3D+x_0%2C+y+%3D+y_0%29+%3D+0.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{\partial^m}{\partial x} \frac{\partial^n}{\partial y}f(x = x_0, y = y_0) = 0. " class="latex" title="\displaystyle  \frac{\partial^m}{\partial x} \frac{\partial^n}{\partial y}f(x = x_0, y = y_0) = 0. " /></p>
<p>Since this includes the case <img src="https://s0.wp.com/latex.php?latex=%7Bm+%3D+n+%3D+0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{m = n = 0}" class="latex" title="{m = n = 0}" />, the point <img src="https://s0.wp.com/latex.php?latex=%7B%28x_0%2Cy_0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(x_0,y_0)}" class="latex" title="{(x_0,y_0)}" /> must be a zero of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" /> as well as of all the partial derivatives. For example, when </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++f%28x%2Cy%29+%3D+xy+-+x+-+y+%2B+1%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  f(x,y) = xy - x - y + 1, " class="latex" title="\displaystyle  f(x,y) = xy - x - y + 1, " /></p>
<p>the point <img src="https://s0.wp.com/latex.php?latex=%7B%281%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1,1)}" class="latex" title="{(1,1)}" /> is a zero of order <img src="https://s0.wp.com/latex.php?latex=%7B%281%2C0%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1,0)}" class="latex" title="{(1,0)}" /> and of order <img src="https://s0.wp.com/latex.php?latex=%7B%280%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(0,1)}" class="latex" title="{(0,1)}" /> but not of order <img src="https://s0.wp.com/latex.php?latex=%7B%281%2C1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1,1)}" class="latex" title="{(1,1)}" />. The diagonal-step nature of this example plays into the next definition. We follow Dyson in numbering from zero.</p>
<blockquote><p><b>Definition 1</b> <em> A “<img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" />-staircase” for <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" /> is given by points <img src="https://s0.wp.com/latex.php?latex=%7B%28x_0%2Cy_0%29%2C%5Cdots%2C%28x_r%2Cy_r%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{(x_0,y_0),\dots,(x_r,y_r)}" class="latex" title="{(x_0,y_0),\dots,(x_r,y_r)}" /> and nonnegative reals <img src="https://s0.wp.com/latex.php?latex=%7Bt_0%2C%5Cdots%2Ct_r%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{t_0,\dots,t_r}" class="latex" title="{t_0,\dots,t_r}" /> such that for all <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bn+%5Cleq+t_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{n \leq t_i}" class="latex" title="{n \leq t_i}" />, </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%28x_i%2Cy_i%29+%5Cquad%5Ctext%7Bis+a+zero+of+order%7D+%5Cquad+%28%5Clfloor%5Clambda%28t_i+-+n%29%5Crfloor%2C+n%29.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  (x_i,y_i) \quad\text{is a zero of order} \quad (\lfloor\lambda(t_i - n)\rfloor, n). " class="latex" title="\displaystyle  (x_i,y_i) \quad\text{is a zero of order} \quad (\lfloor\lambda(t_i - n)\rfloor, n). " /></p>
</em><p><em>It is understood that the <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x_i}" class="latex" title="{x_i}" /> are distinct and the <img src="https://s0.wp.com/latex.php?latex=%7By_i%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{y_i}" class="latex" title="{y_i}" /> are distinct, but they need not be distinct from each other. </em>
</p></blockquote>
<p></p><p>
The parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> is the steepness of the staircase. The idea is to make the staircase quite steep by taking both <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> and the degree <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> to be large. This is controlled by a parameter <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> that is inverse to <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> and chosen to meet the hypotheses of the key lemma:</p>
<blockquote><p><b>Lemma 2</b> <em><a name="key"></a> Suppose <img src="https://s0.wp.com/latex.php?latex=%7B%28x_0%2Cy_0%29%2C%5Cdots%2C%28x_r%2Cy_r%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{(x_0,y_0),\dots,(x_r,y_r)}" class="latex" title="{(x_0,y_0),\dots,(x_r,y_r)}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bt_0%2C%5Cdots%2Ct_r%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{t_0,\dots,t_r}" class="latex" title="{t_0,\dots,t_r}" /> constitute a <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" />-staircase for a bivariate polynomial <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" /> of degree <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> in <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and degree <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> in <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />, where for each <img src="https://s0.wp.com/latex.php?latex=%7Bi%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{i}" class="latex" title="{i}" />, <img src="https://s0.wp.com/latex.php?latex=%7B0+%5Cleq+i+%5Cleq+r%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{0 \leq i \leq r}" class="latex" title="{0 \leq i \leq r}" />, </em></p><em>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clfloor+t_i+%5Crfloor+%5Cleq+%5Cmin%5C%7Bs%2C+%5Cfrac%7Bu%2B1%7D%7B%5Clambda%7D+-+1%5C%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \lfloor t_i \rfloor \leq \min\{s, \frac{u+1}{\lambda} - 1\}. " class="latex" title="\displaystyle  \lfloor t_i \rfloor \leq \min\{s, \frac{u+1}{\lambda} - 1\}. " /></p>
<p>Suppose <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> is a positive real number such that: </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda+%3E+%5Cfrac%7B2%7D%7B%5Cdelta%7D%2C+%5Cquad+%5Ctext%7Band%7D%5Cquad+%5Cdelta+%5Cgeq+%5Cfrac%7B2s%7D%7Br%28u%2B1%29%7D.+&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \lambda &gt; \frac{2}{\delta}, \quad \text{and}\quad \delta \geq \frac{2s}{r(u+1)}. " class="latex" title="\displaystyle  \lambda &gt; \frac{2}{\delta}, \quad \text{and}\quad \delta \geq \frac{2s}{r(u+1)}. " /></p>
<p>Then <a name="bound"></a></p><a name="bound">
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Clambda+%5Csum_%7Bi%3D0%7D%5Er+%281+%2B+%5Clfloor+t_i+%5Crfloor%29%28t_i+-+%5Cfrac%7B1%7D%7B2%7D%5Clfloor+t_i+%5Crfloor%29+%5Cleq+%28s%2B1%29%28u%2B1%29%281+%2B+%5Cfrac%7B1%7D%7B2%7Dr%28r%2B1%29%5Cdelta%29.+%5C+%5C+%5C+%5C+%5C+%281%29&amp;bg=e8e8e8&amp;fg=000000&amp;s=0" alt="\displaystyle  \lambda \sum_{i=0}^r (1 + \lfloor t_i \rfloor)(t_i - \frac{1}{2}\lfloor t_i \rfloor) \leq (s+1)(u+1)(1 + \frac{1}{2}r(r+1)\delta). \ \ \ \ \ (1)" class="latex" title="\displaystyle  \lambda \sum_{i=0}^r (1 + \lfloor t_i \rfloor)(t_i - \frac{1}{2}\lfloor t_i \rfloor) \leq (s+1)(u+1)(1 + \frac{1}{2}r(r+1)\delta). \ \ \ \ \ (1)" /></p>
</a></em><p><em><a name="bound"></a> </em>
</p></blockquote>
<p>
</p><p></p><h2> Interpretation and Application </h2><p></p>
<p></p><p>
Dyson supplied the following interpretation in his paper. The left-hand side of (<a href="https://rjlipton.wordpress.com/feed/#bound">1</a>) approximately counts the number of zeroes in the staircase—approximately because <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> is left as a real number. We want a good upper bound on this number</p>
<p>
A polynomial <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" /> of degree <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> in <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> in <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> may have up to <img src="https://s0.wp.com/latex.php?latex=%7B%28u%2B1%29%28s%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(u+1)(s+1)}" class="latex" title="{(u+1)(s+1)}" /> non-zero coefficieints. Thus <img src="https://s0.wp.com/latex.php?latex=%7B%28u%2B1%29%28s%2B1%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(u+1)(s+1)}" class="latex" title="{(u+1)(s+1)}" /> is intuitively the maximum number of zeroes that could be arranged “on purpose” by the choice of <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" />. </p>
<p>
We want to minimize the number af additional zeroes that could exist. Lemma <a href="https://rjlipton.wordpress.com/feed/#key">2</a> says that this is limited by the factor <img src="https://s0.wp.com/latex.php?latex=%7B%281+%2B+%5Cfrac%7B1%7D%7B2%7Dr%28r%2B1%29%5Cdelta%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{(1 + \frac{1}{2}r(r+1)\delta)}" class="latex" title="{(1 + \frac{1}{2}r(r+1)\delta)}" />. We want to make this factor approach <img src="https://s0.wp.com/latex.php?latex=%7B1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{1}" class="latex" title="{1}" />. We can do so by making <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> arbitrarily small. By the condition <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda+%3E+%5Cfrac%7B2%7D%7B%5Cdelta%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda &gt; \frac{2}{\delta}}" class="latex" title="{\lambda &gt; \frac{2}{\delta}}" /> this entails choosing <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> large. The other requirement to chooise <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> is that it must majorize </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B2s%7D%7Br%28u%2B1%29%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{2s}{r(u+1)}. " class="latex" title="\displaystyle  \frac{2s}{r(u+1)}. " /></p>
<p>We need <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta+r%5E2%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta r^2}" class="latex" title="{\delta r^2}" /> to be small yet bigger than </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cfrac%7B2sr%7D%7Bu%2B1%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \frac{2sr}{u+1}. " class="latex" title="\displaystyle  \frac{2sr}{u+1}. " /></p>
<p>This means making <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bu%7D%7Bs%7D+%3E+2r+-+%5Cfrac%7B1%7D%7Bs%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{u}{s} &gt; 2r - \frac{1}{s}}" class="latex" title="{\frac{u}{s} &gt; 2r - \frac{1}{s}}" />. For whatever number <img src="https://s0.wp.com/latex.php?latex=%7Br%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{r}" class="latex" title="{r}" /> of points we are concerned with, we can meet this by making the degree <img src="https://s0.wp.com/latex.php?latex=%7Bu%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u}" class="latex" title="{u}" /> in <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> be larger than the degree <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> in <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" /> by the factor <img src="https://s0.wp.com/latex.php?latex=%7B2r%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{2r}" class="latex" title="{2r}" />. That is all we need to do for <img src="https://s0.wp.com/latex.php?latex=%7B%5Cdelta%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\delta}" class="latex" title="{\delta}" /> and <img src="https://s0.wp.com/latex.php?latex=%7B%5Clambda%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\lambda}" class="latex" title="{\lambda}" /> to exist that will allow us to apply the lemma. </p>
<p>
Thus the upshot is that suitably “lopsided” polynomials, together with a connected region of their partial derivatives, cannot have too many more than the prescribed number of zeroes, counting multiplicity of the orders of the zeroes. The proof of the lemma works by successive applications of reasoning about determinants and linear independence of polynomials that serve as components of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" />. It is fairly long-winded and ends with some painstaking estimates. </p>
<p>
The application supposes for sake of contradiction that there are infinitely many fractions <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bp%7D%7Bq%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{p}{q}}" class="latex" title="{\frac{p}{q}}" /> giving closer approximations to <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> than the theorem statement allows. It suffices to consider the case where <img src="https://s0.wp.com/latex.php?latex=%7B%5Calpha%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\alpha}" class="latex" title="{\alpha}" /> is an algebraic integer—that is, a root of a univariate polynomial <img src="https://s0.wp.com/latex.php?latex=%7Bg%28z%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g(z)}" class="latex" title="{g(z)}" /> with integer coefficients. The supposition yields candidate polynomials <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" /> as differences of two polynomials, one derived from <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> and the other from the closely approximating fractions. The <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" /> have both a large staircase of zeroes and a bounded space of possible coefficients, which imposes constraints on the degrees in <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> and <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />. These elements can be manipulated, using the approximating fractions on one hand and the fact of <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" /> (and hence its degree) being fixed on the other hand, to create the lopsided form of <img src="https://s0.wp.com/latex.php?latex=%7Bf%28x%2Cy%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f(x,y)}" class="latex" title="{f(x,y)}" /> in which the hypotheses of lemma <a href="https://rjlipton.wordpress.com/feed/#key">2</a> take effect. The lemma then cranks out a contradiction.</p>
<p>
At the end of his proof, Dyson deftly explains how taking <img src="https://s0.wp.com/latex.php?latex=%7Bt+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t = 1}" class="latex" title="{t = 1}" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bt%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t}" class="latex" title="{t}" /> results from the process that selects the sequence <img src="https://s0.wp.com/latex.php?latex=%7Bt_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{t_i}" class="latex" title="{t_i}" /> for the lemma, yields Siegel’s theorem. Thus his framework affords an extra <a href="https://rjlipton.wordpress.com/2011/08/05/give-me-a-lever/">lever</a> for manipulating ratios, in his case the ratio <img src="https://s0.wp.com/latex.php?latex=%7B%5Cfrac%7Bs%7D%7Bt%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\frac{s}{t}}" class="latex" title="{\frac{s}{t}}" />. Tending the ratio to <img src="https://s0.wp.com/latex.php?latex=%7B%5Csqrt%7Br%2F2%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sqrt{r/2}}" class="latex" title="{\sqrt{r/2}}" /> rather than to <img src="https://s0.wp.com/latex.php?latex=%7Bs%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{s}" class="latex" title="{s}" /> produces his theorem.</p>
<p>
Our point of interest is whether Dyson’s setup can be used to attack other questions about polynomials in complexity theory. We have not yet formed an understanding of how specific it is to the approximation application. Perhaps for complexity we would want to generalize it from polynomials in 2 to <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> variables. There could be some relation to the <img src="https://s0.wp.com/latex.php?latex=%7Bd%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{d}" class="latex" title="{d}" />-variable techniques used for integer multiplication as we covered <a href="https://rjlipton.wordpress.com/2019/03/29/integer-multiplication-in-nlogn-time/">here</a>, but again we’re just at the point of asking. Dyson ends his paper with the opinion that</p>
<blockquote><p><b> </b> <em> “such an investigation … would not be in any way a hopeless undertaking.” </em>
</p></blockquote>
<p>
</p><p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
Have there been useful extensions of Dyson’s lemma, as opposed to improvements by Roth and others to his approximation bounds? Has Dyson’s “non-hopeless investigation” been brought to fruition? What other applications would it have? What are the closest techniques that have been used in complexity theory?</p>
<p>
The search for proving transcendental numbers has gone in other directions. These are represented in a survey <a href="http://www.its.caltech.edu/~matilde/NumberTheoryFormalLanguages.pdf">paper</a> by Jeffrey Shallit, which grew into the <a href="https://cs.uwaterloo.ca/~shallit/asas.html">book</a> <em>Automatic Sequences</em> with Jean-Paul Allouche. To answer our reader question above, in the book they trace the transcendence of <img src="https://s0.wp.com/latex.php?latex=%7B%5Csum_k+10%5E%7B-2%5Ek%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\sum_k 10^{-2^k}}" class="latex" title="{\sum_k 10^{-2^k}}" /> to a 1916 <a href="https://www.ams.org/journals/tran/1916-017-04/S0002-9947-1916-1501054-4/S0002-9947-1916-1501054-4.pdf">paper</a> by Aubrey Kempner which uses a different technique.</p>
<p>[Edit: Fixed Roth bound on degree.]</p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2020/03/03/dyson-as-a-mathematician/"><span class="datestr">at March 03, 2020 05:33 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://emanueleviola.wordpress.com/?p=736">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/viola.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://emanueleviola.wordpress.com/2020/03/02/conferences-in-an-era-of-expensive-carbon/">Conferences in an Era of Expensive Carbon</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://emanueleviola.wordpress.com" title="Thoughts">Emanuele Viola</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>At least there’s that: I live in a world where some people care about it and publish their <a href="https://cacm.acm.org/magazines/2020/3/243024-conferences-in-an-era-of-expensive-carbon/abstract">viewpoint in the latest CACM</a>. Read it on your next flight.  Some interesting things that won’t shock anyone:</p>



<p>There’s a nice picture with different environmental costs based on the location of the conference.  It also shows that people like to go to nearby conferences, one of the reasons why “The impulse to ignore the issue is entirely understandable.”  For more perspective see some of our earlier posts for example <a href="https://emanueleviola.wordpress.com/2020/02/18/working-remotely-will-be-the-most-significant-transformation-since-agriculture/">here</a> and <a href="https://emanueleviola.wordpress.com/2020/01/01/publish-and-perish/">here</a>.</p>



<p>The viewpoint also reports on a recent switch from in-person to online program committees for flagship conferences (POPL and ICFP), following a recent trend.  For starters we continue to suggest that <a href="https://emanueleviola.wordpress.com/2017/07/28/stocfocs-pc-meetings-does-nature-of-decisions-justify-cost/">STOC and FOCS do the same, because the nature of decisions does not justify the cost.</a> The latter post also includes hard numbers on the added value of a physical meeting (with respect to accept/reject decisions — of course one can value at infinity meeting in person luminaries in your field, but that can be done in other ways and should not be tied to PC meetings).</p>



<p></p></div>







<p class="date">
by Manu <a href="https://emanueleviola.wordpress.com/2020/03/02/conferences-in-an-era-of-expensive-carbon/"><span class="datestr">at March 02, 2020 03:44 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="tag:blogger.com,1999:blog-3722233.post-4788940302272898721">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/gasarch.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://blog.computationalcomplexity.org/2020/03/logic-examples-for-your-discrete-math.html">Logic examples for your Discrete Math class</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://blog.computationalcomplexity.org/" title="Computational Complexity">Computational Complexity</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<div>
<br />
<br />
(I injured my hand about a month ago so I have had a hard time typing. That is why<br />
I have not blogged for a while. I'm better now but still slow. This is a post I prepared<br />
a while back.)<br />
<br />
<br />
<br />
Here are some examples of English and logic for your discrete math class. Or for mine anyway.<br />
<br />
<br /></div>
<div>
1) <i>A computer programmer leaves work and heads for home. Being the good spouse that he is, he calls  his partner and asks if there's anything that needs to be picked up on the way.</i></div>
<div>
<i><br /></i></div>
<div>
<i>Yes, a gallon of milk and, oh, if they have <span class="il">eggs</span>, get a dozen.</i></div>
<div>
<i><br /></i></div>
<div>
<i>Later he arrives home and stumbles into the kitchen burdened with a dozen gallons of milk. His partner  perplexed, asks him ``why in the world did you buy 12 gallons of milk?''</i></div>
<div>
<i><br /></i></div>
<div>
<i>What did he answer?</i></div>
<div>
<br /></div>
<div>
When I told this to my class one student said that he should answer:</div>
<div>
<br />
                                                      <i>I love you too Darling</i></div>
<div>
<br /></div>
<div>
while that is always a good thing to tell Darling, it is not the answer I had in mind.<br />
<br /></div>
<div>
The  answer is  <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/eggs.txt">here</a>.</div>
<div>
<br /></div>
<div>
2) I saw a headline:</div>
<div>
<br /></div>
<div>
                                                 <i> Rise in faux-incest porn alarming</i></div>
<div>
<br /></div>
<div>
Give two different interpretations of this sentence. (Note- One you might agree with, the other you will likely disagree with.)<br />
<br />
My answer is  <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/faux.txt">here</a></div>
<div>
<br />
3) Recently someone was describing what I work on to someone else and he said the following wonderfully ambiguous sentence<br />
<br />
                           <i>Bill works on puzzles and games. He also work on cake cutting, to be fair.</i><br />
<br />
Give two different interpretations of this sentence.  My answer is <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/billcake.txt">here</a><br />
<br />
<br />
4) A common saying is<br />
<br />
                          <i> All that glitters is not gold</i><br />
<br />
What does this mean literally? What did they really mean to say? My answer is <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/gold.txt">here.</a><br />
<br />
(I had originally thought this was a quote from the Led Zeppelin song <i>Stairway to Heaven</i>;<br />
however, an astute reader left a comment reminding me that, in that song, they actually<br />
say that there is a lady who believes <i>All that Glitters is Gold. </i>The song implies that she is incorrect, so really<br />
NOT(All that Glitters is Gold) which means (exists x)[x glitters but x is not gold] which actually<br />
IS what they meant to say. Yeah!)<br />
<br />
5)When the chess player Bobby Fisher died I saw in one article about him the sentence<br />
<i><br /></i>
<i>                                Bobby Fisher was a terrible anti-semite.</i><br />
<br />
<i></i>This can be interpreted two ways. What are they? Which one did the writer probably mean? My answer is <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/fisher.txt">here</a><br />
<br />
6) When Donald Trump broke the Nuclear Treaty with Iran he said<br />
<br />
                             <i> Iran is the worse enabler of terrorist in the mideast</i><br />
<br />
This can be interpreted two ways. What are they? Which one did Trump mean? My answer is <a href="https://www.cs.umd.edu/users/gasarch/BLOGPAPERS/iran.txt">here.</a><br />
<br /></div>
<div>
<br />
7) I saw the headline (see <a href="https://www.dailykos.com/stories/2019/12/31/1905544/-There-was-actually-good-news-in-the-War-on-Women-in-2019-news-we-have-to-build-on-in-2020">here</a>)<br />
<br />
<i>There was actually good news in the War on Women in 2019, news we have to build on in 2020</i>.<br />
<br />
This can be interepreted in two ways. This one I leave to you, or read the article.<br />
<br />
<br />
<br />
<br /></div></div>







<p class="date">
by GASARCH (noreply@blogger.com) <a href="https://blog.computationalcomplexity.org/2020/03/logic-examples-for-your-discrete-math.html"><span class="datestr">at March 02, 2020 03:32 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-events.org/2020/03/02/prague-summer-school-on-discrete-mathematics/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/events.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-events.org/2020/03/02/prague-summer-school-on-discrete-mathematics/">Prague Summer School on Discrete Mathematics</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-events.org" title="CS Theory Events">CS Theory Events</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
August 24-28, 2020 Prague, Czech Republic http://pssdm.math.cas.cz/ Registration deadline: March 22, 2020 The third edition of Prague Summer School on Discrete Mathematics will feature two lecture series: Subhash Khot (New York University): Hardness of Approximation: From the PCP Theorem to the 2-to-2 Games Theorem, and Shayan Oveis Gharan (University of Washington): Polynomial Paradigm in Algorithm … <a href="https://cstheory-events.org/2020/03/02/prague-summer-school-on-discrete-mathematics/" class="more-link">Continue reading <span class="screen-reader-text">Prague Summer School on Discrete Mathematics</span></a></div>







<p class="date">
by shacharlovett <a href="https://cstheory-events.org/2020/03/02/prague-summer-school-on-discrete-mathematics/"><span class="datestr">at March 02, 2020 02:40 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://francisbach.com/?p=2386">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://francisbach.com/richardson-extrapolation/">On the unreasonable effectiveness of Richardson extrapolation</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://francisbach.com" title="Machine Learning Research Blog">Francis Bach</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p class="justify-text">This month, I will follow up on <a href="https://francisbach.com/acceleration-without-pain/">last month’s blog post</a>, and describe classical techniques from numerical analysis that aim at accelerating the convergence of a vector sequence to its limit, by only combining elements of the sequence, and without the detailed knowledge of the iterative process that has led to this sequence. </p>



<p class="justify-text">Last month, I focused on sequences that converge to their limit exponentially fast (which is referred to as <em>linear</em> convergence), and I described <a href="https://en.wikipedia.org/wiki/Aitken%27s_delta-squared_process">Aitken’s \(\Delta^2\) method</a>, the <a href="https://en.wikipedia.org/wiki/Shanks_transformation">Shanks transformation</a>, Anderson acceleration and its <a href="https://arxiv.org/pdf/1606.04133">regularized version</a>. These methods are called “non-linear” acceleration techniques, because, although they combine linearly iterates as \(c_0 x_k + c_1 x_{k+1} + \cdots + c_m x_{k+m}\), the scalar weights in the linear combination depend non-linearly on \(x_k,\dots,x_{k+m}\).</p>



<p class="justify-text">In this post, I will focus on sequences that converge sublinearly, that is, with a difference to their limit that goes to zero as an inverse power of \(k\), typically in \(O(1/k)\). </p>



<h2>Richardson extrapolation</h2>



<p class="justify-text">We consider a sequence \((x_k)_{k \geq 0} \in \mathbb{R}^d\), with an asymptotic expansion of the form $$ x_k = x_\ast + \frac{1}{k}\Delta + O\Big(\frac{1}{k^2}\Big), $$ where \(x_\ast \in \mathbb{R}^d\) is the limit of \((x_k)_k\) and \(\Delta\) a vector in \(\mathbb{R}^d\).</p>



<p class="justify-text">The idea behind <a href="https://en.wikipedia.org/wiki/Richardson_extrapolation">Richardson extrapolation</a> [<a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.1911.0009">1</a>] is to combine linearly two iterates taken at two different values of \(k\) so that the zero-th order term \(x_\ast\) is left unchanged, but the first order term in \(1/k\) cancels out. For \(k\) even, we can consider $$  2 x_k – x_{k/2} =  2 \Big( x_\ast + \frac{1}{k} \Delta  +O\Big(\frac{1}{k^2}\Big)  \Big) \, – \Big( x_\ast +  \frac{2}{k} \Delta  + O\Big(\frac{1}{k^2}\Big) \Big)  =  x_\ast +O\Big(\frac{1}{k^2}\Big).$$</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><a href="https://arxiv.org/pdf/1707.06386"><img src="https://francisbach.com/wp-content/uploads/2020/02/reg_k-1024x454.png" alt="" width="404" class="wp-image-2421" height="179" /></a>Illustration of Richardson extrapolation. Iterates (in black) with their first-order expansions (in red). The deviations (represented by circles) are of order \(O(1/k^2)\). Adapted from [<a href="https://arxiv.org/pdf/1707.06386">3</a>, <a href="https://arxiv.org/pdf/2002.02835">2</a>].  </figure></div>



<p class="justify-text">The key benefit of Richardson extrapolation is that we only need to know that the leading term in the asymptotic expansion is proportional to \(1/k\), <em>without the need to know the vector \(\Delta\)</em>. See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://francisbach.com/wp-content/uploads/2020/02/richardson_2d.gif" alt="" width="332" class="wp-image-2481" height="280" />Richardson extrapolation in two dimensions. The sequence is of the form \(x_k = \frac{1}{k} \Delta_1 + \frac{(-1)^k}{k^2} \Delta_2\). The extrapolated sequence \(2 x_k – x_{k/2}\) is only plotted for \(k\) even.</figure></div>



<p class="justify-text">In this post, following [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>], I will explore situations where Richardson extrapolation can be useful within machine learning. I identified three situations where Richardson extrapolation can be useful (there are probably more):</p>



<ol class="justify-text"><li>Iterates of an optimization algorithms \((x_k)_{k \geq 0}\), and the extrapolation is \( 2x_k – x_{k/2}.\)</li><li>Extrapolation on the step-size of stochastic gradient descent, where we will combine iterates obtained from two different values of the step-size.</li><li>Extrapolation on a regularization parameter.</li></ol>



<p class="justify-text">As we will show, extrapolation techniques come with no significant loss in performance, but in several situations strong gains. It is thus “<a href="https://en.wikipedia.org/wiki/The_Unreasonable_Effectiveness_of_Mathematics_in_the_Natural_Sciences">unreasonably effective</a>“.</p>



<h2>Application to optimization algorithms</h2>



<p class="justify-text">We consider an iterate \(x_k\) of an iterative optimization algorithm which is minimizing a function \(f\), thus converging to a global minimizer \(x_\ast\) of \(f\). Then so is \(x_{k/2}\), and thus also $$  x_k^{(1)} = 2x_k – x_{k/2}.$$ Therefore, performance is never significantly deteriorated (the risk is essentially to lose half of the iterations). The potential gains depend on the way \(x_k\) converges to \(x_\ast\). The existence of a convergence rate of the form \(f(x_k) -f(x_\ast) = O(1/k)\) or \(O(1/k^2)\) is not enough, as Richardson extrapolation requires a specific direction of asymptotic convergence. As illustrated below, some algorithms are oscillating around their solutions, while some converge with a specific direction. Only the latter ones can be accelerated with Richardson extrapolation, while the former ones are good candidates for <a href="https://francisbach.com/acceleration-without-pain/">Anderson acceleration</a>.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://francisbach.com/wp-content/uploads/2020/02/nonoscillating_oscillating-1024x350.png" alt="" width="476" class="wp-image-2395" height="162" /> Left: Oscillating convergence, where Richardson extrapolation does not lead to any gain. Right: non-oscillating  convergence, with a main direction \(\Delta\) (in red dotted), where Richardson extrapolation can be beneficial if the oscillations orthogonal to the direction \(\Delta\) are negligible compared to convergence along the direction \(\Delta\). </figure></div>



<p class="justify-text"><strong>Averaged gradient descent.</strong> We consider the usual gradient descent algorithm $$x_k = x_{k-1} – \gamma f'(x_{k-1}),$$ where \(\gamma &gt; 0 \) is a step-size, with Polyak-Ruppert averaging [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">4</a>]: $$ y_k = \frac{1}{k} \sum_{i=0}^{k-1} x_i.$$ Averaging is key to robustness to potential noise in the gradients [<a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">4</a>, <a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">5</a>]. However it comes with the unintended consequence of losing the exponential forgetting of initial conditions for strongly-convex problems [<a href="https://papers.nips.cc/paper/4316-non-asymptotic-analysis-of-stochastic-approximation-algorithms-for-machine-learning.pdf">6</a>].</p>



<p class="justify-text">A common way to restore exponential convergence (up to the noise level in the stochastic case) is to consider “tail-averaging”, that is, to replace \(y_k\) by the average of only the latest \(k/2\) iterates [<a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">7</a>]. As shown below for \(k\) even, this corresponds exactly to Richardson extrapolation on the sequence \((y_k)_k\): $$ \frac{2}{k} \sum_{i=k/2}^{k-1} x_i = \frac{2}{k} \sum_{i=0}^{k-1} x_i – \frac{2}{k} \sum_{i=0}^{k/2-1} x_i = 2 y_k – y_{k/2}. $$</p>



<p class="justify-text">With basic  assumptions on \(f\), it is shown in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>] that for locally strongly-convex problems: $$y_k = x_\ast + \frac{1}{k} \Delta + O(\rho^k), $$ where  \(\displaystyle \Delta = \sum_{i=0}^\infty (x_i – x_\ast)\) and \(\rho \in (0,1)\) depends on the condition number of \(f”(x_\ast)\). This is illustrated below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://francisbach.com/wp-content/uploads/2020/02/averaged_gradient.png" alt="" width="342" class="wp-image-2507" height="250" />Averaged gradient descent on a <a href="https://en.wikipedia.org/wiki/Logistic_regression">logistic regression</a> problem in dimension \(d=400\), and with \(n=4000\) observations. For the regular averaged recursion, the line in the log-log plot has slope \(-2\). See experimental details in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>].</figure></div>



<p class="justify-text">We can make the following observations:</p>



<ul class="justify-text"><li>Before Richardson extrapolation, the asymptotic convergence rate after averaging is of order \(O(1/k^2)\), which is better than the usual \(O(1/k)\) upper-bound for the rate of gradient descent, but with a stronger assumption that in fact leads to exponential convergence before averaging.</li><li>While \(\Delta\) has a simple expression, it cannot be computed in practice (but Richardson extrapolation does not need to know it).</li><li>Richardson extrapolation leads to an exponentially convergent algorithm from an algorithm converging asymptotically in \(O(1/k^2)\).</li></ul>



<p class="justify-text"><strong>Accelerated gradient descent.</strong> Above, we considered averaged gradient descent, which is asymptotically converging as \(O(1/k^2)\), and on which Richardson extrapolation could be used with strong gains. Is it possible also for the accelerated gradient descent method [<a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=dan&amp;paperid=46009&amp;what=fullt&amp;option_lang=eng">8</a>], which has a (non-asymptotic) convergence rate of \(O(1/k^2)\) for convex functions?</p>



<p class="justify-text">It turns out that the behavior of the iterates of accelerated gradient descent is exactly of the form depicted in the left plot of the figure above: that is, the iterates \(x_k\) oscillate around the optimum [<a href="http://jmlr.org/papers/volume17/15-084/15-084.pdf">9</a>, <a href="http://proceedings.mlr.press/v40/Flammarion15.pdf">10</a>], and Richardson extrapolation is of no help, but is not degrading performance too much. See below for an illustration. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://francisbach.com/wp-content/uploads/2020/02/accelerated_gradient.png" alt="" width="332" class="wp-image-2509" height="243" />Accelerated gradient descent on a quadratic optimization problem in dimension \(d=1000\). See experimental details in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>].  </figure></div>



<p class="justify-text"><strong>Other algorithms.</strong> It is tempting to test it on other optimization algorithms. For example, as explained in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>], Richardson extrapolation can be used to the <a href="https://en.wikipedia.org/wiki/Frank%E2%80%93Wolfe_algorithm">Frank-Wolfe</a> algorithm, where sometimes it helps, sometimes it doesn’t. Others could be tried.</p>



<h2>Extrapolation on the step-size of stochastic gradient descent</h2>



<p class="justify-text">While above we have focused on Richardson extrapolation applied to the number of iterations of an iterative algorithm, it is most often used in integration methods (for computing integrals or solving ordinary differential equations), and then often referred to as <a href="https://en.wikipedia.org/wiki/Romberg%27s_method">Romberg-Richardson extrapolation</a>. Within machine learning, in a similar spirit, this can be applied to the step-size of stochastic gradient descent [<a href="https://arxiv.org/pdf/1707.06386">3</a>, <a href="http://papers.nips.cc/paper/6514-stochastic-gradient-richardson-romberg-markov-chain-monte-carlo.pdf">11</a>], which I now describe.</p>



<p class="justify-text">We consider the minimization of a function \(F(x)\) defined on \(\mathbb{R}^d\), which can be written as an expectation as $$F(x) = \mathbb{E}_{z} f(x,z).$$ We assume that we have access to \(n\) independent and identically distributed observations (i.i.d.) \(z_1,\dots,z_n\). This is a typical scenario in machine learning, where \(f(x,z)\) represents the loss for the predictor parameterized by \(x\) on the observation \(z\). </p>



<p class="justify-text">The stochastic gradient method is particularly well adapted, and we consider here a single pass, as $$x_i= x_{i-1} – \gamma f'(x_{i-1},z_i),$$ where the gradient is taken with respect to the first variable, for \(i = 1,\dots,n\). It is known that with a constant step-size, when \(n\) tends to infinity, \(x_n\) will <em>not</em> converge to the minimizer \(x_\ast\) of \(F\), as the algorithm always moves [<a href="https://epubs.siam.org/doi/pdf/10.1137/0324039">16</a>], as illustrated below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://francisbach.com/wp-content/uploads/2020/02/logistic_2d-1.gif" alt="" width="403" class="wp-image-2488" height="279" />Stochastic gradient descent on a logistic regression problem: (blue) without averaging, (red) with averaging.</figure></div>



<p class="justify-text">One way to damp the oscillations is to consider averaging, that is, $$ y_n = \frac{1}{n+1} \sum_{i=0}^{n} x_i$$ (we consider uniform averaging for simplicity). For least-squares regression, this leads to a converging algorithm [<a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">12</a>] with attractive properties for ill-conditioned problems (see also <a href="https://francisbach.com/the-sum-of-a-geometric-series-is-all-you-need/">January’s blog post</a>). However, for general loss functions, it is shown in [<a href="https://arxiv.org/pdf/1707.06386">3</a>] that \(y_n\) converges to some \(y^{(\gamma)} \neq x_\ast\). There is a bias due to a step-size \(\gamma\) that does not go to zero. In order to apply Richardson extrapolation, together with Aymeric Dieuleveut and Alain Durmus [<a href="https://arxiv.org/pdf/1707.06386">3</a>], we showed that $$ y^{(\gamma)} = x_\ast + \gamma \Delta + O(\gamma^2),$$ for some \(\Delta \in \mathbb{R}^d\) with some complex expression. Thus, we have $$2 y^{(\gamma)} – y^{(2\gamma)} = x_\ast + O(\gamma^2),$$ thus gaining one order. If we consider the iterate \(y_n^{(\gamma)}\) and \(y_n^{(2 \gamma)}\) associated to the two step-sizes \(\gamma\) and \(2 \gamma\), the linear combination $$2 y_n^{(\gamma)} – y_n^{(2\gamma)} $$ has an improved behavior as it tends to \(2 y^{(\gamma)} – y^{(2\gamma)} = x_\ast + O(\gamma^2)\): it remains not convergent, but get to way smaller values. See an illustration below.</p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://francisbach.com/wp-content/uploads/2020/02/SGD_logistic-1.png" alt="" width="359" class="wp-image-2525" height="274" />Averaged stochastic gradient descent on a logistic regression problem in dimension 20.</figure></div>



<p class="justify-text"><strong>Higher-order extrapolation.</strong> If we can accelerate a sequence by extrapolation, why not extrapolate the extrapolated sequence? This is possible if we have an higher-order expansion of the form $$ y^{(\gamma)} = \theta_\ast + \gamma \Delta_1 + \gamma^2 \Delta_2 + O(\gamma^3),$$ for some (typically unknown) vectors \(\Delta_1\) and \(\Delta_2\). Then, the sharp reader can check that $$3 y_n^{(\gamma)} – 3 y_n^{(2\gamma)} +  y_n^{(3\gamma)}, $$ will lead to cancellation of the first two orders \(\gamma\) and \(\gamma^2\). This is illustrated above for SGD.</p>



<p class="justify-text">Then, why not extrapolate the extrapolation of the extrapolated sequence? One can check that $$4 y_n^{(\gamma)} – 6 y_n^{(2\gamma)} + 4  y_n^{(3\gamma)}  -y_n^{(4\gamma)}, $$ will lead to cancellation of the first three orders of an expansion of \(y^{(\gamma)}\). The <a href="https://en.wikipedia.org/wiki/Binomial_coefficient">binomial coefficient</a> aficionados have already noticed the pattern there, and checked that $$ \sum_{i=1}^{m+1} (-1)^{i-1} { m+1 \choose i} y_n^{(i\gamma)}$$ will lead to cancellations of the first \(m\) orders.</p>



<p class="justify-text">Then, why not go on forever? First because \(m+1\) recursions have to be run in parallel, and second, because the constant in front of the term in \(\gamma^{m+1}\) typically explodes, a phenomenon common to many expansion methods.</p>



<h2>Extrapolation on a regularization parameter</h2>



<p class="justify-text">We now explore the application of Richardson extrapolation to regularization methods. In a nutshell, regularization allows to make an estimation problem more stable (less subject to variations for statistical problems) or the algorithm faster (for optimization problems). However, regularization adds a bias that needs to be removed. In this section, we apply Richardson extrapolation to the regularization parameter to reduce this bias. I will only present an application to smoothing for non-smooth optimization (see an application to  ridge regression in [<a href="https://hal.archives-ouvertes.fr/hal-02470950/document">2</a>]).</p>



<p class="justify-text"><strong>Non-smooth optimization problems</strong>. We consider the minimization of a convex function of the form \(f = h + g\), where \(h\) is smooth and \(g\) is non-smooth. These optimization problems are ubiquitous in machine learning and signal processing, where the lack of smoothness can come from (a) non-smooth losses such as max-margin losses used in support vector machines and more generally structured output classification [<a href="https://icml.cc/Conferences/2005/proceedings/papers/113_StructuredPrediction_TaskarEtAl.pdf">13</a>], and (b) sparsity-inducing regularizers (see, e.g., [<a href="https://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">14</a>] and references therein). While many algorithms can be used to deal with this non-smoothness, we consider a classical smoothing technique below.</p>



<p class="justify-text"><strong>Nesterov smoothing</strong>. In this section, we consider the smoothing approach of Nesterov [<a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">15</a>] where the non-smooth term is “smoothed” into \(g_\lambda\), where \(\lambda\) is a regularization parameter, and accelerated gradient descent is used to minimize \(h+g_\lambda\). </p>



<p class="justify-text">A typical way of smoothing the function \(g\) is to add \(\lambda\) times a strongly convex regularizer (such as the squared Euclidean norm) to the Fenchel conjugate of \(g\); this leads to a function \(g_\lambda\) which has a smoothness constant (defined as the maximum of the largest eigenvalues of all Hessians) proportional to \(1/\lambda\), with a uniform error of \(O(\lambda)\) between \(g\) and \(g_\lambda\). Given that accelerated gradient descent leads to an iterate with excess function values proportional to \(1/(\lambda k^2)\) after \(k\) iterations, with the choice of \(\lambda \propto 1/k\), this leads to an excess in function values proportional to \(1/k\), which improves on the subgradient method which converges in \(O(1/\sqrt{k})\). Note that the amount of regularization depends on the number of iterations, so that this smoothing method is not “anytime”.</p>



<p class="justify-text"><strong>Richardson extrapolation.</strong> If we denote by \(x_\lambda\) the minimizer of \(h+g_\lambda\) and \( x_\ast\) the global minimizer of \( f=h+g\), if we can show that \( x_\lambda = x_\ast + \lambda \Delta + O(\lambda^2)\), then \( x^{(1)}_\lambda = 2 x_\lambda – x_{2\lambda} = O(\lambda^2)\) and we can expand \( f(x_\lambda^{(1)})  = f(x_\ast)  + O(\lambda^2)\), which is better than the \(O(\lambda)\) approximation without extrapolation. </p>



<p class="justify-text">Then, given a number of iterations \(k\), with \( \lambda \propto k^{-2/3}\), to balance the two terms \( 1/(\lambda k^2)\) and \( \lambda^2\),  we get an overall convergence rate for the non-smooth problem of \( k^{-4/3}\). </p>



<p class="justify-text"><strong>\(m\)-step Richardson extrapolation</strong>. Like above for the step-size, we can also consider \(m\)-step Richardson extrapolation \(x_{\lambda}^{(m)}\), which leads to a bias proportional to \(\lambda^{m+1}\). Thus, if we consider \(\lambda \propto 1/k^{2/(m+2)}\), to balance the terms \(1/(\lambda k^2)\) and \(\lambda^{m+1}\), we get an error for the non-smooth problem of \(1/k^{2(m+1)/(m+2)}\), which can get arbitrarily close to \(1/k^2\) when \(m\) gets large. The downsides (like for the extrapolation on the step-size above) are that (a) the constants in front of the asymptotic equivalent may blow up (a classical problem in high-order expansions), and (b) \(m\)-step extrapolation requires running the algorithm \(m\) times (this can be down in parallel). In the experiment below, 3-step extrapolation already brings in most of the benefits.</p>



<p class="justify-text">In order to experimentally study the benefits of extrapolation, for the <a href="https://en.wikipedia.org/wiki/Lasso_(statistics)">Lasso</a> optimization problem, and for a series of regularization parameters equal to \(2^{i}\) for \(i\) between \(-18\) and \(1\) (sampled every \(1/5\)), we run accelerated gradient descent on \(h+g_\lambda\) and we plot the value of \(f(x)-f(x_\ast)\) for the various estimates, where for each number of iterations, we minimize over the regularization parameter. This is an oracle version of varying \(\lambda\) as a function of the number of iterations. </p>



<div class="wp-block-image justify-text"><figure class="aligncenter size-large is-resized"><img src="https://francisbach.com/wp-content/uploads/2020/02/smoothing.png" alt="" width="351" class="wp-image-2530" height="255" />Excess function values as a function of the number of iterations, <em>taking into account that \(m\)-step Richardson extrapolation requires \(m\)-times more iterations</em>. There is indeed a strong improvement approaching the rate \(1/k^2\).</figure></div>



<h2>Conclusion</h2>



<p class="justify-text">These last two blog posts were dedicated to acceleration techniques coming from numerical analysis. They are cheap to implement, typically do not interfere with the underlying algorithm, and when used in the appropriate situation, can bring in significant speed-ups.</p>



<p class="justify-text">Next month, I will most probably host an invited post by my colleague <a href="https://www.di.ens.fr/~ataylor/">Adrien Taylor</a>, who will explain how machines can <s>replace</s> help researchers that prove bounds on optimization algorithms.</p>



<h2>References</h2>



<p class="justify-text">[1] Lewis Fry Richardson. <a href="https://royalsocietypublishing.org/doi/pdf/10.1098/rsta.1911.0009">The approximate arithmetical solution by finite differences of physical problems involving differential equations, with an application to the stresses in a masonry dam</a>. <em>Philosophical Transactions of the Royal Society of London, Series A</em>, 210(459-470):307–357, 1911.<br />[2] Francis Bach. <a href="https://arxiv.org/pdf/2002.02835">On the Effectiveness of Richardson Extrapolation in Machine Learning</a>. Technical report, arXiv:2002.02835, 2020.<br />[3] Aymeric Dieuleveut, Alain Durmus, Francis Bach. <a href="https://arxiv.org/pdf/1707.06386">Bridging the Gap between Constant Step Size Stochastic Gradient Descent and Markov Chains</a>. To appear in <em>The Annals of Statistics</em>, 2019.<br />[4] Boris T. Polyak,  Anatoli B. Juditsky. <a href="https://epubs.siam.org/doi/pdf/10.1137/0330046">Acceleration of stochastic approximation by averaging</a>. <em>SIAM journal on control and optimization</em> 30(4):838-855, 1992.<br />[5] Arkadi Nemirovski, Anatoli Juditsky, Guanghui Lan, Alexander Shapiro<em>. </em><a href="https://epubs.siam.org/doi/pdf/10.1137/070704277">Robust stochastic approximation approach to stochastic programming</a>. <em>SIAM Journal on optimization</em>, 19(4):1574-1609, 2009.<br />[6] Francis Bach, Eric Moulines. <a href="https://papers.nips.cc/paper/4316-non-asymptotic-analysis-of-stochastic-approximation-algorithms-for-machine-learning.pdf">Non-asymptotic analysis of stochastic approximation algorithms for machine learning</a>. <em>Advances in Neural Information Processing Systems</em>, 2011.<br />[7] Prateek Jain, Praneeth Netrapalli, Sham Kakade, Rahul Kidambi, Aaron Sidford. <a href="http://jmlr.org/papers/volume18/16-595/16-595.pdf">Parallelizing stochastic gradient descent for least squares regression: mini-batching, averaging, and model misspecification</a>. <em>The Journal of Machine Learning Research</em>, 18(1), 8258-8299, 2017.<br />[8] Yurii E. Nesterov. <a href="http://www.mathnet.ru/php/getFT.phtml?jrnid=dan&amp;paperid=46009&amp;what=fullt&amp;option_lang=eng">A method of solving a convex programming problem with convergence rate \(O(1/k^2)\)</a>, <em>Doklady Akademii Nauk SSSR</em>, 269(3):543–547, 1983.<br />[9] Weijie Su, Stephen Boyd, and Emmanuel J. Candes. <a href="http://jmlr.org/papers/volume17/15-084/15-084.pdf">A differential equation for modeling Nesterov’s accelerated gradient method: theory and insights</a>. <em>Journal of Machine Learning Research</em>, 17(1):5312-5354, 2016.<br />[10] Nicolas Flammarion, and Francis Bach. <a href="http://proceedings.mlr.press/v40/Flammarion15.pdf">From Averaging to Acceleration, There is Only a Step-size</a>. <em>Proceedings of the International Conference on Learning Theory (COLT)</em>, 2015. <br />[11] Alain Durmus, Umut Simsekli, Eric Moulines, Roland Badeau, and Gaël Richard. <a href="http://papers.nips.cc/paper/6514-stochastic-gradient-richardson-romberg-markov-chain-monte-carlo.pdf">Stochastic gradient Richardson-Romberg Markov chain Monte Carlo</a>. In <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2016.<br />[12] Francis Bach and Eric Moulines. <a href="https://papers.nips.cc/paper/4900-non-strongly-convex-smooth-stochastic-approximation-with-convergence-rate-o1n.pdf">Non-strongly-convex smooth stochastic approximation with convergence rate \(O(1/n)\)</a>. <em>Advances in Neural Information Processing Systems (NIPS)</em>, 2013.<br />[13] Ben Taskar, Vassil Chatalbashev, Daphne Koller, and Carlos Guestrin. <a href="https://icml.cc/Conferences/2005/proceedings/papers/113_StructuredPrediction_TaskarEtAl.pdf">Learning structured prediction models: A large margin approach</a>. <em>Proceedings of the International Conference on Machine Learning (ICML)</em>, 2005.<br />[14] Francis Bach, Rodolphe Jenatton, Julien Mairal, and Guillaume Obozinski. <a href="https://www.di.ens.fr/~fbach/bach_jenatton_mairal_obozinski_FOT.pdf">Optimization with sparsity-inducing penalties</a>. Foundations and Trends in Machine Learning, 4(1):1–106, 2012<br />[15] Yurii Nesterov. <a href="https://www.math.ucdavis.edu/~sqma/MAT258A_Files/Nesterov-2005.pdf">Smooth minimization of non-smooth functions</a>. Mathematical Programming , 103(1):127–152, 2005.<br />[16] Georg Ch. Pflug. <a href="https://epubs.siam.org/doi/pdf/10.1137/0324039">Stochastic minimization with constant step-size: asymptotic laws</a>. <em>SIAM Journal on Control and Optimization</em>, (24)4:655-666, 1986.</p>



<p></p></div>







<p class="date">
by Francis Bach <a href="https://francisbach.com/richardson-extrapolation/"><span class="datestr">at March 01, 2020 12:41 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://cstheory-jobs.org/2020/03/01/postdoc-at-uc-san-diego-apply-by-march-1-2020/">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://cstheory-jobs.org/2020/03/01/postdoc-at-uc-san-diego-apply-by-march-1-2020/">postdoc at UC San Diego (apply by March 1, 2020)</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://cstheory-jobs.org" title="Theoretical Computer Science Jobs">CCI: jobs</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>UCSD has several Postdoctoral Fellowships, aimed at preparing outstanding researchers for academic and leadership careers in Data Science. Areas of interest include both theoretical and practical aspects of machine learning, statistics, algorithms, and their applications. Applications will be reviewed until positions are filled.</p>
<p>Website: <a href="http://dsfellows.ucsd.edu/">http://dsfellows.ucsd.edu/</a><br />
Email: shachar.lovett@gmail.com</p></div>







<p class="date">
by shacharlovett <a href="https://cstheory-jobs.org/2020/03/01/postdoc-at-uc-san-diego-apply-by-march-1-2020/"><span class="datestr">at March 01, 2020 01:04 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://11011110.github.io/blog/2020/02/29/leap-day-linkage">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eppstein.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://11011110.github.io/blog/2020/02/29/leap-day-linkage.html">Leap day linkage</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://11011110.github.io/blog/" title="11011110">David Eppstein</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
<ul>
  <li>
    <p><a href="https://mathstodon.xyz/@jeffgerickson/103671508553971700">Jeff Erickson links</a> one of the first non-trivial <a href="https://en.wikipedia.org/wiki/Straight_skeleton">straight skeletons</a> (as a roof model), from <em>Kotirte Ebenen (Kotirte Projektionen) und deren Anwendung</em> by Gustav A. von Peschka (1877).</p>
  </li>
  <li>
    <p><a href="https://math.unice.fr/~indira/Mygifs.html">Indira Lara Chatterji has some nice open-licensed animated gifs of concepts in low-dimensional geometry and topology</a> (<a href="https://mathstodon.xyz/@11011110/103684262226520136"></a>).</p>
  </li>
  <li>
    <p><a href="https://harvardmagazine.com/2012/11/absolutely-beautiful">Geometric art of Morton C. Bradley, Jr.</a> (<a href="https://mathstodon.xyz/@11011110/103695425477296068"></a>, <a href="https://www.georgehart.com/rp/MortonBradley/Morton-Bradley.html">see also</a>). As <a href="https://joelcooper.wordpress.com/2012/06/21/geometric-art-of-morton-c-bradley-jr/">Joel Cooper writes</a>, “I was fascinated first by the complex yet harmonious geometry of these forms, but it is really the use of color that makes these sculptures so transcendent. These sculptures are really exercises in color theory in three dimensions.”</p>
  </li>
  <li>
    <p><a href="https://rjlipton.wordpress.com/2020/02/01/subliminal-graph-duals/">Subliminal graph duals</a> and <a href="https://rjlipton.wordpress.com/2020/02/11/using-negative-nodes-to-count/">using negative nodes to count</a> (<a href="https://mathstodon.xyz/@11011110/103701104439329493"></a>). These posts abstract a graph to a 2-polymatroid, the function that maps a subset of edges to the number of vertices it touches. This resembles matroid rank, but a single edge has rank 2. This leads to a notion of a dual, which usually does not come from a graph, with an interesting operation of “exploding” edges dual to edge deletion.</p>
  </li>
  <li>
    <p>The latest <em>Notices</em> has profiles of mathematicians <a href="http://www.ams.org/journals/notices/202003/rnoti-p327.pdf">Fan Chung</a>, <a href="http://www.ams.org/journals/notices/202003/rnoti-p345.pdf">Olga Taussky-Todd</a>, and <a href="http://www.ams.org/journals/notices/202003/rnoti-p368.pdf">Dorothy Hoover</a> (<a href="https://mathstodon.xyz/@mathcination/103690730215482537"></a>).</p>
  </li>
  <li>
    <p>My graph algorithm lectures on stable matching have shifted their terminology and metaphors to stable matching from stable marriage (outdated, sexist, heteronormative, potentially offensive, and not a good fit for the applications) but so far Wikipedia hasn’t. Maybe the ngram below explains why: there’s a base level of colloquial usage of “stable marriage” masking the popularity of “matching” in technical usage. Google Scholar shows a clearer picture: 3940 hits for “stable matching” since 2016, 2710 for “stable marriage”. (<a href="https://mathstodon.xyz/@11011110/103717212351898100"></a>).</p>

    <p style="text-align: center;"><img src="https://11011110.github.io/blog/assets/2020/stable-marriage-vs-matching.png" alt="Stable matching vs stable marriage Google ngram" /></p>
  </li>
  <li>
    <p><a href="https://divisbyzero.com/2019/05/01/braidtiles/">Braid tiles</a> (<a href="https://mathstodon.xyz/@11011110/103723728540456919"></a>). Print your own onto cardstock, cut out, and rearrange, for all your hands-on braid-group experimental-mathematics needs.</p>
  </li>
  <li>
    <p><a href="https://gendergapinscience.files.wordpress.com/2020/02/final_report_20200204-1.pdf">Final report of the international project “A Global Approach to the Gender Gap in Mathematical, Computing, and Natural Sciences: How to Measure It, How to Reduce It?”</a> (<a href="https://mathstodon.xyz/@11011110/103729947676143732"></a>, <a href="https://euro-math-soc.eu/news/20/02/26/preliminary-report-project-global-approach-gender-gap-mathematical-computing-and">via</a>), including recommendations for instructors and organizations.</p>
  </li>
  <li>
    <p><a href="https://www.vice.com/en_us/article/4agamm/the-worlds-second-largest-wikipedia-is-written-almost-entirely-by-one-bot">The world’s second largest Wikipedia is written almost entirely by one bot</a> (<a href="https://mathstodon.xyz/@11011110/103735065395757430"></a>, <a href="https://news.ycombinator.com/item?id=22403626">via</a>). The language is Cebuano, from the Philippines. Consensus on the English Wikipedia is that automatic translation and automatic content generation are not good enough, but the different languages of Wikipedia are run independently and have different standards from each other.</p>
  </li>
  <li>
    <p>You can encode complex numbers as pairs of real numbers, their real and imaginary parts, and perform complex arithmetic using only real-number operations. But can you go the other way, and encode real numbers somehow using complex arithmetic? <a href="http://jdh.hamkins.org/the-real-numbers-are-not-interpretable-in-the-complex-field/">Joel David Hamkins gives a simple proof of the folklore result that the answer is no</a> (<a href="https://mathstodon.xyz/@11011110/103738094179310308"></a>). The short reason why not: there are too few equivalence classes of k-tuples of them to use as representatives of the reals.</p>
  </li>
  <li>
    <p><a href="https://mathoverflow.net/q/351743/440">Polyhedra that can pack 3-space only in a non-vertex-to-vertex fashion</a> (<a href="https://mathstodon.xyz/@11011110/103744463137230104"></a>). The tiling by congruent convex polyhedra in Michael Korn’s answer is very pretty, but a proof that it is the only possible tiling by these polyhedra is still lacking (although it appears very likely to be true).</p>
  </li>
</ul></div>







<p class="date">
by David Eppstein <a href="https://11011110.github.io/blog/2020/02/29/leap-day-linkage.html"><span class="datestr">at February 29, 2020 02:46 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://www.scottaaronson.com/blog/?p=4626">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/aaronson.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-US"><a class="entryheader" href="https://www.scottaaronson.com/blog/?p=4626">Freeman Dyson and Boris Tsirelson</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://www.scottaaronson.com/blog" title="Shtetl-Optimized">Scott Aaronson</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en-US">
<p>Today, as the world braces for the possibility of losing millions of lives to the new coronavirus—to the <em>hunger for pangolin meat</em>, of all things (combined with the evisceration of competent public health agencies like the CDC)—we also mourn the loss of two incredibly special lives, those of Freeman Dyson (age 96) and Boris Tsirelson (age 69).</p>



<p>Freeman Dyson was sufficiently legendary, both within and beyond the worlds of math and physics, that there’s very little I can add to <a href="https://www.nytimes.com/2020/02/28/science/freeman-dyson-dead.html">what’s been said</a>.  It seemed like he was immortal, although I’d heard from mutual friends that his health was failing over the past year.  When I spent a year as a postdoc at the Institute for Advanced Study, in 2004-5, I often sat across from Dyson in the common room, while he drank tea and read the news.  That I never once struck up a conversation with him is a regret that I’ll now carry with me forever.</p>



<p>My only exchange with Dyson came when he gave a lecture at UC Berkeley, about how life might persist infinitely far into the future, even after the last stars had burnt out, by feeding off steadily dimishing negentropy flows in the nearly-thermal radiation.  During the Q&amp;A, I challenged Dyson that his proposal seemed to assume an analog model of computation.  But, I asked, once we took on board the quantum-gravity insights of Jacob Bekenstein and others, suggesting that nature behaves like a (quantum) digital computer at the Planck scale, with at most ~10<sup>43</sup> operations per second and ~10<sup>69</sup> qubits per square meter and so forth, wasn’t this sort of proposal ruled out?  “I’m not going to argue with you,” was Dyson’s response.  Yes, he’d assumed an analog computational model; if computation was digital then that surely changed the picture.</p>



<p>Sometimes—and not just with his climate skepticism, but also (e.g.) with his idea that general relativity and quantum mechanics <em>didn’t need to be reconciled</em>, that it was totally fine for the deepest layer of reality to be a patchwork of inconsistent theories—Dyson’s views struck me as not merely contrarian but as a high-level form of trolling.  Even so, Dyson’s book <em><a href="https://www.amazon.com/Disturbing-Universe-Sloan-Foundation-Science/dp/0465016774">Disturbing the Universe</a></em> had had a major impact on me as a teenager, for the sparkling prose as much as for the ideas.</p>



<p>With Dyson’s passing, the scientific world has lost one of its last direct links to a heroic era, of Einstein and Oppenheimer and von Neumann and a young Richard Feynman, when theoretical physics stood at the helm of civilization like never before or since.  Dyson, who apparently remained not only lucid but <em>mathematically powerful</em> (!) well into his last year, clearly remembered when the Golden Age of science fiction looked like simply sober forecasting; when the smartest young people, rather than denouncing each other on Twitter, dreamed of scouting the solar system in thermonuclear-explosion-powered spacecraft and seriously worked to make that happen.</p>



<p>Boris Tsirelson (<a href="http://www.math.tau.ac.il/~tsirel/">homepage</a>, <a href="https://en.wikipedia.org/wiki/Boris_Tsirelson">Wikipedia</a>), who emigrated from the Soviet Union and then worked at Tel Aviv University (where my wife Dana attended his math lectures), wasn’t nearly as well known as Dyson to the wider world, but was equally beloved within the quantum computing and information community.  <a href="https://en.wikipedia.org/wiki/Tsirelson%27s_bound">Tsirelson’s bound</a>, which he proved in the 1980s, showed that even quantum mechanics could only violate the Bell inequality by so much and by no more, could only let Alice and Bob win the <a href="https://www.cs.cmu.edu/~odonnell/quantum18/lecture07.pdf">CHSH game</a> with probability cos<sup>2</sup>(π/8).  This seminal result anticipated many of the questions that would only be asked decades later with the rise of quantum information.  Tsirelson’s investigations of quantum nonlocality also led him to pose the famous <a href="https://arxiv.org/abs/0812.4305">Tsirelson’s problem</a>: loosely speaking, can all sets of quantum correlations that can arise from an infinite amount of entanglement, be arbitrarily well approximated using <em>finite</em> amounts of entanglement?  The spectacular answer—no—was only announced one month ago, as a corollary of the <a href="https://www.scottaaronson.com/blog/?p=4512">MIP*=RE breakthrough</a>, something that Tsirelson happily lived to see although I don’t know what his reaction was (<font color="red"><strong>update:</strong></font> I’m told that he indeed learned of it in his final weeks, and was happy about it).  Sadly, for some reason, I never met Tsirelson in person, although I did have lively email exchanges with him 10-15 years ago about his problem and other topics.  This <a href="https://www.iqoqi-vienna.at/en/blog/article/boris-tsirelson/?fbclid=IwAR1PrVvK0u5XmnFLLoPMzMN3x9rY1WIdp1wrYZ_yYPlqSGRpXDkollYTCR0">amusing interview</a> with Tsirelson gives some sense for his personality (hat tip to Gil Kalai, who knew Tsirelson well).</p>



<p>Please share any memories of Dyson or Tsirelson in the comments section.</p></div>







<p class="date">
by Scott <a href="https://www.scottaaronson.com/blog/?p=4626"><span class="datestr">at February 29, 2020 01:53 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4315">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/02/29/lies-damn-lies-and-covid-19/">Lies, damn lies, and covid-19</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>In the past two weeks, in Italy, we have been drowning in information about the novel coronavirus infection, but the statistics that have been circulating were lacking proper context and interpretation. Is covid-19 just a stronger form of the flu or is it a threat to the world economy? Yes.</p>
<p>Now that the first community transmissions are happening in my adopted home in the San Francisco Bay Area, I would like to relay to my American readers what I learned from the Italian experience.</p>
<p><span id="more-4315"></span></p>
<p>The most quoted statistics concerned the mortality rate, which has been around 2-2.5% worldwide but only about 0.8% outside of Wuhan, while the flu has a mortality rate around 0.1% and measles around 0.2%. Furthermore, there are no reports of children and infants having died (<a href="http://weekly.chinacdc.cn/en/article/id/e53946e2-c6c4-41e9-9a9b-fea8db1a8f51">source</a>) or even having been in critical conditions. This means that it is an infection only somewhat more serious than the flu and that, in particular, parents should not be concerned about their small children.</p>
<p>The other important statistics, however, is the number of infected people that require intensive care. Some source give it at 5%, while the number circulating in Italy is 10%. </p>
<p>Now, developed countries have of the order of an ICU bed per 10,000 people: the European average is one bed per 9,000 people, Italy has one per 8,000, Germany has one per 3,400 (<a href="https://link.springer.com/article/10.1007/s00134-012-2627-8">source</a>) and the United States has one per 4,000 (<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4351597/">source</a>). </p>
<p>ICU beds tend to have high occupancy, and they are used for victims of stroke and heart attacks, patients recovering from difficult surgeries and so on.</p>
<p>This means that if a person in 1,000 is sick with covid-19 at a given time, the critical cases might overwhelm the capacity of intensive care units. So far, this has happened only in Wuhan, at which point the Chinese government started implementing increasingly strong measures, leading to the lockdown of Wuhan and other places in Hubei province. A ratio of 0.1% of infected people at a regional level has not occurred anywhere outside Hubei province. Even in Lombardy we have “only” about 500 cases out of 10 million people. Two nights ago, however, in the town of Lodi (which has about 50,000 residents) 17 people where brought to the hospital in critical condition from the nearby “red zone”, and many of them had to be routed to other cities because Lodi could not deal with them.</p>
<p>It has been estimated that a covid-19 infected person infects on average another 2-2.5 other people (the “R0” parameter of the disease), typically over a week or less, leading to a rather fast exponential growth. On the Diamond Princess, about 20% of passengers and crew were infected. The only way to reduce the R0 below 1, which would make the epidemic die down, or at least to a value not much bigger than 1 (which would make it grow more slowly) is to reduce person-to-person contact. This is why clusters are locked down, and in places too big to lock down there are measures to reduce such contact, such as closing schools, shutting down sports events, conferences, fairs, concerts etc., and encouraging people to work from home.</p>
<p>The latter “lockdown-lite” measures have stopped the growth of infections in cities like Shanghai, Hong Kong and Singapore, where there were relatively large clusters of cases (much more in Shanghai than in Hong Kong and Singapore). We haven’t seen the number of cases in Korea and Italy leveling off, but this is because testing tends to discover infections that happened one or two weeks prior to the test, so the effect of any measure is only seen in the test numbers a couple of weeks or more after they are implemented.</p>
<p>Meanwhile, Italy is building field hospitals in parking lots, using technology tested during earthquakes, to add hospital bed capacity to the system.</p>
<p>Finally, the measures introduced a week ago are starting to show dramatic economic consequences. The government first emphasized the gravity of the situation, in order to be seen as taking strong actions in a grave moment, and then realized it had caused a PR disaster and now is trying to sound a more optimistic note and to walk back some of the measures that are having the most negative economic consequences. Other governments are unlikely to repeat the same errors, so one should expect official government communication to be biased on the side of not creating alarm.</p>
<p>So here are the lessons for America, in brief:</p>
<ul>
<li>Don’t worry about your young children
</li>
<li>If the government follows public health best practices, prepare to see school closures and cancelations of big events wherever there are signs of community transmission</li>
<li>With containment efforts similar to Hong Kong’s and Singapore’s (and Italy’s, Japan’s and Korea’s), we might see as little as one infection per 10,000-100,000 people, meaning nearly zero risk on an individual basis and no major strain on hospitals, but with significant effects on daily life and on the economy
</li><li>There will be political pressure to send out optimistic messages (see how the White House is asking to pre-approve all communication out of the CDC and the NIH) and to avoid measures that could hurt the economy</li>
<li>If the containment efforts are too light, and infections reach even a person in 1,000 on a regional level, the individual risk is still extremely small, but the health care system will be unable to deal with the critically ill. Note that <em>this hasn’t happened anywhere outside of Wuhan</em> and whatever directives come from the top, it’s hard to imagine that local officials would let it happen in their jurisdiction</li>
<li>Try not to have a stroke, a heart attack, or serious surgery in the next few months</li>
</ul></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/02/29/lies-damn-lies-and-covid-19/"><span class="datestr">at February 29, 2020 12:38 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16744">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/02/28/reductions-and-jokes/">Reductions and Jokes</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
<font color="#0044cc"><br />
<em>Plus a teaching idea that’s no joke?</em><br />
<font color="#000000"></font></font></p><font color="#0044cc"><font color="#000000">
<table class="image alignright">
<tbody>
<tr>
<td>
<a href="https://rjlipton.files.wordpress.com/2020/02/postcropped.png"><img src="https://rjlipton.files.wordpress.com/2020/02/postcropped.png?w=600" alt="" class="alignright size-full wp-image-16746" /></a>
</td>
</tr>
<tr>
<td class="caption alignright"><font size="-2">Cropped from Maths History <a href="http://mathshistory.st-andrews.ac.uk/PictDisplay/Post.html">source</a></font></td>
</tr>
</tbody>
</table>
<p>
Emil Post was the first to use the formal notion of reduction between problems. We discussed Post’s wonderful work and its relevance to complexity earlier <a href="https://rjlipton.wordpress.com/2010/04/19/a-post-on-post/">here</a>.</p>
<p>
Today Ken and I want to discuss the notion of reduction, and also perhaps some jokes for your amusement.<br />
<span id="more-16744"></span></p>
<p>
Reductions are used throughout mathematics. We regard Post’s definition from 1944 as quintessential. His are called <a href="https://en.wikipedia.org/wiki/Many-one_reduction">many-one</a> reductions. Here is the definition in a functional style that we’ve tried to promote in other cases: A problem <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> reduces to a problem <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> if there is a computable function <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> such that for any instance <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> of problem <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++A%28x%29+%3D+B%28f%28x%29%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  A(x) = B(f(x)). " class="latex" title="\displaystyle  A(x) = B(f(x)). " /></p>
<p>If <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> are languages then this gives the familiar condition <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+A+%5Ciff+f%28x%29+%5Cin+B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \in A \iff f(x) \in B}" class="latex" title="{x \in A \iff f(x) \in B}" />. But the idea can be more general: <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> and <img src="https://s0.wp.com/latex.php?latex=%7BB%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B}" class="latex" title="{B}" /> can be functions.</p>
<p>
Alan Turing had earlier defined an even more general kind of reduction, in which given <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> one computes multiple <img src="https://s0.wp.com/latex.php?latex=%7By_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_i}" class="latex" title="{y_i}" />, gets the answer <img src="https://s0.wp.com/latex.php?latex=%7BB%28y_i%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{B(y_i)}" class="latex" title="{B(y_i)}" /> for each of them, and finally pieces together the answers to obtain <img src="https://s0.wp.com/latex.php?latex=%7BA%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A(x)}" class="latex" title="{A(x)}" />. But this feels more like “expanding” than “reducing.” We want it to be: one <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, one <img src="https://s0.wp.com/latex.php?latex=%7By%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y}" class="latex" title="{y}" />. That was Post’s notion.</p>
<p>
</p><p></p><h2> Dating Reductions and Jokes </h2><p></p>
<p></p><p>
The idea of reduction is simple: When confronted with some problem, be lazy: Instead of solving the problem, show that it can be changed and then solved by some previously known method. That is, show that your problem is reduced to someone’s already solved problem. Be lazy.</p>
<p>
In this form, we can think of two mathematical examples that are much older than Post’s:</p>
<ul>
<li>
<em>Logarithms</em>. Multiplying two numbers <img src="https://s0.wp.com/latex.php?latex=%7Ba%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{a}" class="latex" title="{a}" /> and <img src="https://s0.wp.com/latex.php?latex=%7Bb%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{b}" class="latex" title="{b}" /> with many digits or decimals can be cumbersome. If you can compute <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> and its inverse such that <p></p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a%5Ccdot+b+%3D+f%5E%7B-1%7D%28f%28a%29+%2B+f%28b%29%29%2C+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  a\cdot b = f^{-1}(f(a) + f(b)), " class="latex" title="\displaystyle  a\cdot b = f^{-1}(f(a) + f(b)), " /></p>
<p>then your multiplication is reduced to a much easier addition. John Napier gave <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> the name “logarithm” in 1614 and soon William Oughtred built a physical device to automate this reduction. If you are over 40, perhaps you have seen <a href="https://en.wikipedia.org/wiki/Slide_rule">one</a>. </p>
</li><li>
<em>Integration</em>. Do you have a hard integral <img src="https://s0.wp.com/latex.php?latex=%7B%5Cint+A%28x%29+dx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\int A(x) dx}" class="latex" title="{\int A(x) dx}" />? Often tricks of defining <img src="https://s0.wp.com/latex.php?latex=%7By+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y = f(x)}" class="latex" title="{y = f(x)}" />, so <img src="https://s0.wp.com/latex.php?latex=%7Bdy+%3D+f%27%28x%29+dx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{dy = f'(x) dx}" class="latex" title="{dy = f'(x) dx}" />, and/or integrating by parts, yields an integral <img src="https://s0.wp.com/latex.php?latex=%7B%5Cint+B%28y%29+dy%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\int B(y) dy}" class="latex" title="{\int B(y) dy}" /> that is easier to solve, and whose solution completes your answer.
</li></ul>
<p>
The latter example is in Wikipedia’s article on <a href="https://en.wikipedia.org/wiki/Reduction_(mathematics)">reduction</a>. The former, however, has the signature idea of reduction <em>between</em> problems, more than massaging instances of the same problem. What we really want to know is:</p>
<blockquote><p><b> </b> <em> When was the process of transforming between problems first known by the term <b>reduction</b>? </em>
</p></blockquote>
<p></p><p>
We wonder if tracing an old kind of joke can help. The point is that reductions are a neat source of jokes. Here is a classic one, taken from a big <a href="https://www.math.utah.edu/~cherk/mathjokes.html">list</a> of math jokes. The list gives a second form of the joke based on reductions and there are many others. More on the jokes later.</p>
<blockquote><p><b> </b> <em> A physicist and a mathematician are sitting in a faculty lounge. Suddenly, the coffee machine catches on fire. The physicist grabs a waste basket, empties the basket, leaps towards the sink, fills the basket with water, and puts out the fire. As this coffee machine has done this before they agree to keep a waste basket next to the coffee machine filled with water.</em></p><em>
</em><p><em>
The next day, the same two are sitting in the same lounge. Again, the coffee machine catches on fire. This time, the mathematician stands up, grabs the waste basket that is filled with water. Empties it, places some trash in the basket, and hands it to the physicist. Thus reducing the problem to a previously solved one. </em>
</p></blockquote>
<p></p><p>
Instead of putting out a fire, the following <a href="https://thumbs.gfycat.com/DifficultVapidAmericanredsquirrel-size_restricted.gif?fbclid=IwAR2AXbtag_WFTP9bmipr4JOhvViHAQbvEgE8h1oCdG_71IttR28EgcSTqhg">video</a> is about retrieving a shoe that is floating away.</p>
<p>
</p><p></p><h2> Another Example </h2><p></p>
<p></p><p>
Here is an example of reductions that are not so silly and a little less simple.</p>
<p>
Imagine that Alice and Bob are at it again. Bob wants to be able to multiply integers fast and he plans on building a hardware system that stores the answers in a table. Then his hardware system will be able to compute the product of two integers by just looking up the answers. Okay, there are really better ways to do this, but just play along for the moment. </p>
<p><a href="https://rjlipton.files.wordpress.com/2020/02/tables2.jpg"><img src="https://rjlipton.files.wordpress.com/2020/02/tables2.jpg?w=200&amp;h=200" alt="" width="200" class="aligncenter wp-image-16747" height="200" /></a></p>
<p>
Bob’s table is big and he is troubled. The above table has <img src="https://s0.wp.com/latex.php?latex=%7B100%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{100}" class="latex" title="{100}" /> entries just to multiply numbers less than <img src="https://s0.wp.com/latex.php?latex=%7B10%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{10}" class="latex" title="{10}" />. Clearly for a more extensive table the cost grows fast. He asks his friend Alice for some help. She says:”Just store the diagonal values and I can show you how to handle the general case.” Here is her old trick. 	</p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++a+%5Ctimes+b+%3D+%5Cfrac%7B%5Cleft%28%5Cleft%28a+%2B+b%5Cright%29%5E%7B2%7D+-+a%5E%7B2%7D+-+b%5E%7B2%7D%5Cright%29%7D%7B2%7D.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  a \times b = \frac{\left(\left(a + b\right)^{2} - a^{2} - b^{2}\right)}{2}. " class="latex" title="\displaystyle  a \times b = \frac{\left(\left(a + b\right)^{2} - a^{2} - b^{2}\right)}{2}. " /></p>
<p>Using this allows Bob to just store the diagonal of the multiplication table, and forget all the rest. It is a powerful reduction that shows:</p>
<blockquote><p><b> </b> <em> One can reduce integer multiplication to addition and taking the square of a number. </em>
</p></blockquote>
<p>
For example, </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cbegin%7Barray%7D%7Brcl%7D++++++++37+%5Ctimes+15+%26%3D%26+%28+52%5E%7B2%7D+-+37%5E%7B2%7D+-+15%5E%7B2%7D+%29%2F2+%5C%5C++++++++++++++%26%3D%26+%282704+-+1369+-+225%29%2F2+%5C%5C++++++++++++%26%3D%26+555.+%5Cend%7Barray%7D+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \begin{array}{rcl}        37 \times 15 &amp;=&amp; ( 52^{2} - 37^{2} - 15^{2} )/2 \\              &amp;=&amp; (2704 - 1369 - 225)/2 \\            &amp;=&amp; 555. \end{array} " class="latex" title="\displaystyle  \begin{array}{rcl}        37 \times 15 &amp;=&amp; ( 52^{2} - 37^{2} - 15^{2} )/2 \\              &amp;=&amp; (2704 - 1369 - 225)/2 \\            &amp;=&amp; 555. \end{array} " /></p>
<p>
</p><p></p><h2> Complexity Reductions: No Joke? </h2><p></p>
<p></p><p>
Wikipedia actually gives the above as the first example in its <a href="https://en.wikipedia.org/wiki/Reduction_(complexity)">article</a> on the <em>complexity</em> kind of reduction. These kind of reductions not only define NP hardness and completeness, they are really needed to understand what the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BP%3DNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{P=NP}}" class="latex" title="{\mathsf{P=NP}}" /> problem is really about. </p>
<p>
For example, once one accepts that a language <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" /> in <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> can be represented by a uniform family of Boolean circuits <img src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_n}" class="latex" title="{C_n}" />, one for each length <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" /> of instances <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> for <img src="https://s0.wp.com/latex.php?latex=%7BA%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{A}" class="latex" title="{A}" />, the reduction to SAT is quickly defined: The <img src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_n}" class="latex" title="{C_n}" /> have auxiliary inputs <img src="https://s0.wp.com/latex.php?latex=%7By_1%2C%5Cdots%2Cy_q%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_1,\dots,y_q}" class="latex" title="{y_1,\dots,y_q}" />, where <img src="https://s0.wp.com/latex.php?latex=%7Bq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{q}" class="latex" title="{q}" /> is polynomial in <img src="https://s0.wp.com/latex.php?latex=%7Bn%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{n}" class="latex" title="{n}" />, such that there is a <img src="https://s0.wp.com/latex.php?latex=%7By+%5Cin+%5C%7B0%2C1%5C%7D%5Eq%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y \in \{0,1\}^q}" class="latex" title="{y \in \{0,1\}^q}" /> making <img src="https://s0.wp.com/latex.php?latex=%7BC_n%28x%2Cy%29+%3D+1%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_n(x,y) = 1}" class="latex" title="{C_n(x,y) = 1}" /> if and only if <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \in A}" class="latex" title="{x \in A}" />. The circuit <img src="https://s0.wp.com/latex.php?latex=%7BC_n%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{C_n}" class="latex" title="{C_n}" /> can consist of binary NAND gates <img src="https://s0.wp.com/latex.php?latex=%7Bg%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{g}" class="latex" title="{g}" />, each with input wires <img src="https://s0.wp.com/latex.php?latex=%7Bu%2Cv%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{u,v}" class="latex" title="{u,v}" /> (which may be inputs <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_i}" class="latex" title="{x_i}" /> or <img src="https://s0.wp.com/latex.php?latex=%7By_j%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{y_j}" class="latex" title="{y_j}" />) and one or more output wires <img src="https://s0.wp.com/latex.php?latex=%7Bw%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w}" class="latex" title="{w}" /> (which may be the overall output <img src="https://s0.wp.com/latex.php?latex=%7Bw_0%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{w_0}" class="latex" title="{w_0}" />). The reduction <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> first constructs the Boolean formula </p>
<p align="center"><img src="https://s0.wp.com/latex.php?latex=%5Cdisplaystyle++%5Cphi_n+%3D+%28w_0%29+%5Cwedge+%5Cbigwedge_%7Bg%7D+%28u+%5Cvee+w%29+%5Cwedge+%28v+%5Cvee+w%29+%5Cwedge+%28%5Cbar%7Bu%7D+%5Cvee+%5Cbar%7Bv%7D+%5Cvee+%5Cbar%7Bw%7D%29.+&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="\displaystyle  \phi_n = (w_0) \wedge \bigwedge_{g} (u \vee w) \wedge (v \vee w) \wedge (\bar{u} \vee \bar{v} \vee \bar{w}). " class="latex" title="\displaystyle  \phi_n = (w_0) \wedge \bigwedge_{g} (u \vee w) \wedge (v \vee w) \wedge (\bar{u} \vee \bar{v} \vee \bar{w}). " /></p>
<p>To apply <img src="https://s0.wp.com/latex.php?latex=%7Bf%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{f}" class="latex" title="{f}" /> to a given <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" />, simply substitute the bits of <img src="https://s0.wp.com/latex.php?latex=%7Bx%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x}" class="latex" title="{x}" /> for the variables <img src="https://s0.wp.com/latex.php?latex=%7Bx_i%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x_i}" class="latex" title="{x_i}" /> and simplify to make the formula <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_x+%3D+f%28x%29%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_x = f(x)}" class="latex" title="{\phi_x = f(x)}" />. Then <img src="https://s0.wp.com/latex.php?latex=%7B%5Cphi_x%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\phi_x}" class="latex" title="{\phi_x}" /> is satisfiable if and only if <img src="https://s0.wp.com/latex.php?latex=%7Bx+%5Cin+A%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{x \in A}" class="latex" title="{x \in A}" />. The reduction not only proves the <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" />-completeness of SAT (indeed, 3SAT) instantly, it conveys the character both of SAT and what <img src="https://s0.wp.com/latex.php?latex=%7B%5Cmathsf%7BNP%7D%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{\mathsf{NP}}" class="latex" title="{\mathsf{NP}}" /> is all about.</p>
<p>
This leads us to wonder something about teaching complexity theory. Maybe <b>reductions</b>, not <em>languages</em>, should be the principal objects of study. </p>
<p>
This may seem like a joke but there are benefits. The reductions are composable in ways that languages are not. They carry the source and target problems with them, at least in the form of the function’s arguments and values. Emphasizing reductions highlights the greatest success of complexity theory to date, which is proving relations between problems, rather than its failure to classify languages via lower bounds.</p>
<p>
</p><p></p><h2> More Jokes </h2><p></p>
<p></p><p>
Here are a selection from a big <a href="https://www.math.utah.edu/~cherk/mathjokes.html">list</a> of math jokes that speak most to computing, plus one from <a href="https://www.quora.com/What-are-some-great-Computer-Science-jokes">here</a>. We have embellished a few of them: </p>
<ul>
<li>
A theory professor is one who talks in someone else’s sleep. <p></p>
</li><li>
Two is the oddest prime of all, because it’s the only one that’s even. <p></p>
</li><li>
A student comes to the department with a shiny new coffee cup, the sort of which you get when having won something. They explain: I won it in my Programming Class contest. They asked what <img src="https://s0.wp.com/latex.php?latex=%7B7+%2B+7%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{7 + 7}" class="latex" title="{7 + 7}" /> is. I said <img src="https://s0.wp.com/latex.php?latex=%7B12%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{12}" class="latex" title="{12}" /> and got 3rd place. <p></p>
</li><li>
There are 10 types of people in the world, those who see it in binary and those who don’t. <p></p>
</li><li>
An engineer thinks that his equations are an approximation to reality. A physicist thinks reality is an approximation to his equations. A mathematician doesn’t care. A computer scientist makes reality equal the equations. <p></p>
</li><li>
There is no logical foundation for mathematical proof, and Gödel proved it! <p></p>
</li><li>
Mathematics is like checkers in being suitable for the young, not too difficult, amusing, and<br />
<i>without peril to the state</i>. [Plato wrote that 2,400 years ago; they did have <a href="http://www.checkerslounge.com/ancient-checkers.html">checkers</a>.]<br />
Coding, on the other hand…<p></p>
</li></ul>
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
How should the concept of <em>reduction</em> be taught and emphasized? Can you trace the age of the classic reduction joke?</p>
<p>
There is a setting for multiplication where our Alice and Bob reduction example <em>fails</em>. Two of our latter list of jokes might suggest it to you. What is the issue? </p>
<p></p></font></font></div>







<p class="date">
by RJLipton+KWRegan <a href="https://rjlipton.wordpress.com/2020/02/28/reductions-and-jokes/"><span class="datestr">at February 28, 2020 05:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://gilkalai.wordpress.com/?p=19402">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/kalai.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://gilkalai.wordpress.com/2020/02/28/remarkable-new-stochastic-methods-in-abf-ronen-eldan-and-renan-gross-found-a-new-proof-for-kkl-and-settled-a-conjecture-by-talagrand/">Remarkable New Stochastic Methods in ABF: Ronen Eldan and Renan Gross Found a New Proof for KKL and Settled a Conjecture by Talagrand</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://gilkalai.wordpress.com" title="Combinatorics and more">Gil Kalai</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p> </p>
<p><a href="https://gilkalai.files.wordpress.com/2019/11/rr.png"><img src="https://gilkalai.files.wordpress.com/2019/11/rr.png?w=300&amp;h=282" alt="" width="300" class="alignnone size-medium wp-image-18565" height="282" /></a></p>
<p><span style="color: #ff0000;">The main conjecture from Talagrand’s paper on boundaries and influences was settled by Ronen Eldan and Renan Gross. Their paper introduces a new powerful method to the field of analysis of Boolean functions (ABF).</span></p>
<p>This post is devoted to a new breakthrough paper by Ronen Eldan and Renan Gross, <a href="https://arxiv.org/abs/1909.12067">Concentration on the Boolean hypercube via pathwise stochastic analysis.</a></p>
<p>The paper introduces remarkable new techniques based on stochastic calculus, (that bypass the use of hypercontractivity), that allow to settles several open problems on analysis of Boolean functions. (And on the way, to give a very different proof for KKL.)</p>
<p>Renan Gross recently wrote an excellent high-level explanation of the paper in his  blog: <a href="https://sarcasticresonance.wordpress.com/2020/02/06/new-paper-on-arxiv-concentration-on-the-boolean-hypercube-via-pathwise-stochastic-analysis/">New paper on arXiv: Concentration on the Boolean hypercube via pathwise stochastic analysis.</a> It is accompanied by a <a href="https://sarcasticresonance.wordpress.com/2020/02/05/catastrophic-cubic-crash-course">brief introduction to Boolean analysis, featuring the required Boolean material</a>:</p>
<p> </p>
<p>Before we move on, a trivia question:</p>
<h3><strong>Trivia question:</strong> Who invented the term hypercontractivity?</h3>
<p>(For a hint, see at the end of the post.)</p>
<p>Back to the paper by Ronen Eldan and Renan Gross. Perhaps the best way to explain what was achieved in this paper is to put one after the other the abstracts of the first version followed by the abstract of the second paper.</p>
<p> </p>
<h2>Ronen and Renan’s paper. Version 1, 26 Sept 2019.</h2>
<p><span style="color: #800080;">The title for version 1 was: Stability of Talagrand’s influence inequality</span></p>
<p><span style="color: #800080;">And here is the abstract: </span></p>
<p>We strengthen several classical inequalities concerning the influences of a Boolean function, showing that near-maximizers must have large vertex boundaries. An inequality due to Talagrand states that for a Boolean function</p>
<p><img src="https://s0.wp.com/latex.php?latex=%281%29%7E%7E%7E%7E%7E%5Cmathrm%7Bvar%7D%5Cleft%28f%5Cright%29%5Cleq+C%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cfrac%7B%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%7D%7B1%2B%5Clog%5Cleft%281%2F%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%5Cright%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(1)~~~~~\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}" class="latex" title="(1)~~~~~\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}" /></p>
<p>where  <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathrm{Inf}_{i}\left(f\right)" class="latex" title="\mathrm{Inf}_{i}\left(f\right)" /> denote the influence of the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />-th coordinate. We give a lower bound for the size of the vertex boundary of functions saturating this inequality. As a corollary, we show that for sets that satisfy the edge-isoperimetric inequality or the Kahn-Kalai-Linial (KKL) inequality up to a constant, a constant proportion of the mass is in the inner vertex boundary. Our proofs rely on new techniques, based on stochastic calculus, and bypass the use of hypercontractivity common to previous proofs.</p>
<p><span style="color: #800080;">Let me say a few words about it. KKL theorem asserts that the maximal influence of a balanced Boolean function is at least <img src="https://s0.wp.com/latex.php?latex=%5COmega+%28%5Clog+n%2Fn%29+var+%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\Omega (\log n/n) var (f)" class="latex" title="\Omega (\log n/n) var (f)" />. The famous tribe example of Ben-Or and Linial shows that this is tight.  The KKL paper gave some statements about other norms of the influence vector and Talagrand’s inequality stated above (from the paper “On Russo’s 0-1 law”) gives a sharp description of the influence vectors. Ronen and Renan found a new method that gave new proofs for KKL’s theorem and the stronger Talagrand’s inequality. This new methods led to new stability result.</span></p>
<p>Now, lets move to version 2.</p>
<h2>Ronen and Renan’s paper: Version 2: 12 Nov 2019,</h2>
<p>Ronen Eldan and Renan Gross, <a href="https://arxiv.org/abs/1909.12067">Concentration on the Boolean hypercube via pathwise stochastic analysis.</a></p>
<p>Abstract: We develop a new technique for proving concentration inequalities which relate between the variance and influences of Boolean functions. Using this technique, we</p>
<p><strong>1.</strong> Settle a conjecture of Talagrand [Tal97] proving that</p>
<p><img src="https://s0.wp.com/latex.php?latex=%282%29%7E%7E%7E%7E%7E%5Cint_%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%7D%7D%5Csqrt%7Bh_%7Bf%7D%5Cleft%28x%5Cright%29%7Dd%5Cmu%5Cgeq+C%5Ccdot%5Cmathrm%7Bvar%7D%5Cleft%28f%5Cright%29%5Ccdot%5Cleft%28%5Clog%5Cleft%28%5Cfrac%7B1%7D%7B%5Csum%5Cmathrm%7BInf%7D_%7Bi%7D%5E%7B2%7D%5Cleft%28f%5Cright%29%7D%5Cright%29%5Cright%29%5E%7B1%2F2%7D%2C&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(2)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}\left(f\right)\cdot\left(\log\left(\frac{1}{\sum\mathrm{Inf}_{i}^{2}\left(f\right)}\right)\right)^{1/2}," class="latex" title="(2)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}\left(f\right)\cdot\left(\log\left(\frac{1}{\sum\mathrm{Inf}_{i}^{2}\left(f\right)}\right)\right)^{1/2}," /></p>
<p>where <img src="https://s0.wp.com/latex.php?latex=h_f%28x%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="h_f(x)" class="latex" title="h_f(x)" /> is the number of edges at <img src="https://s0.wp.com/latex.php?latex=x&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="x" class="latex" title="x" />  along which <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /> changes its value, and <img src="https://s0.wp.com/latex.php?latex=Inf_i%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="Inf_i(f)" class="latex" title="Inf_i(f)" /> is the influence of the <img src="https://s0.wp.com/latex.php?latex=i&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="i" class="latex" title="i" />-th coordinate.</p>
<p><strong>2.</strong> Strengthen several classical inequalities concerning the influences of a Boolean function, showing that near-maximizers must have large vertex boundaries. An inequality due to Talagrand states that for a Boolean function <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="f" class="latex" title="f" /></p>
<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bvar%7D%5Cleft%28f%5Cright%29%5Cleq+C%5Csum_%7Bi%3D1%7D%5E%7Bn%7D%5Cfrac%7B%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%7D%7B1%2B%5Clog%5Cleft%281%2F%5Cmathrm%7BInf%7D_%7Bi%7D%5Cleft%28f%5Cright%29%5Cright%29%7D&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}" class="latex" title="\mathrm{var}\left(f\right)\leq C\sum_{i=1}^{n}\frac{\mathrm{Inf}_{i}\left(f\right)}{1+\log\left(1/\mathrm{Inf}_{i}\left(f\right)\right)}" /></p>
<p>We give a lower bound for the size of the vertex boundary of functions saturating this inequality. As a corollary, we show that for sets that satisfy the edge-isoperimetric inequality or the Kahn-Kalai-Linial inequality up to a constant, a constant proportion of the mass is in the inner vertex boundary.</p>
<p><strong>3.</strong> Improve a quantitative relation between influences and noise stability given by Keller and Kindler.</p>
<p>Our proofs rely on techniques based on stochastic calculus, and bypass the use of hypercontractivity common to previous proofs.</p>
<p><span style="color: #800080;">Let me explain in a few words the main inequality that verified a conjecture by Talagrand. For other advances look at the paper itself.</span></p>
<p><span style="color: #800080;">The famous Margulis-Talagrand inequality asserts that</span></p>
<p><img src="https://s0.wp.com/latex.php?latex=%283%29%7E%7E%7E%7E%7E%5Cint_%7B%5Cleft%5C%7B+-1%2C1%5Cright%5C%7D+%5E%7Bn%7D%7D%5Csqrt%7Bh_%7Bf%7D%5Cleft%28x%5Cright%29%7Dd%5Cmu%5Cgeq+C%5Ccdot%5Cmathrm%7Bvar%7D%28f%29.&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="(3)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}(f)." class="latex" title="(3)~~~~~\int_{\left\{ -1,1\right\} ^{n}}\sqrt{h_{f}\left(x\right)}d\mu\geq C\cdot\mathrm{var}(f)." /></p>
<p><span style="color: #800080;">Let me say a little more. Talagrand’s proved in  his paper on Influence and boundary asserts that the right hand is a constant only if <img src="https://s0.wp.com/latex.php?latex=II%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="II(f)" class="latex" title="II(f)" /> – the sum of squares of the influences is a constant. He conjectured that we can actually add the square root of <img src="https://s0.wp.com/latex.php?latex=%5Clog+II%28f%29&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="\log II(f)" class="latex" title="\log II(f)" /> to the RHS.</span></p>
<p>A few remarks:</p>
<ol>
<li> For more background see my old post “<a href="https://gilkalai.wordpress.com/2008/05/26/natis-influence/">Nati’s influence</a>“.</li>
<li>Let me mention that Talagrand’s influence inequality (Equation (1) above) is sharp up to a multiplicative constant. This is shown in a 2015 paper: <a href="https://arxiv.org/abs/1506.06325">On the Converse of Talagrand’s Influence Inequality</a> by Saleet Klein, Amit Levi, Muli Safra, Clara Shikhelman, and Yinon Spinka.</li>
<li> Finding the best constant in KKL’s theorem is a well known challenge. So is the question of understanding balanced Boolean functions on n variables where the maximum influence is <img src="https://s0.wp.com/latex.php?latex=C+%5Clog+n%2Fn&amp;bg=ffffff&amp;fg=333333&amp;s=0" alt="C \log n/n" class="latex" title="C \log n/n" />. Ehud Friedgit in his paper:<a href="http://www.ma.huji.ac.il/~ehudf/docs/kkl.ps"> Influences in Product Spaces, KKL and BKKKL Revisited</a>, have made important conjectures for such Boolean functions.</li>
<li> I expect that the new method will have many applications. Ronen Eldan in a paper <a href="https://arxiv.org/abs/1912.11641">Second-order bounds on correlations between increasing families</a>, found applicaions to correlation inequalities which I will discuss at some other time.</li>
<li> See the last part of <a href="https://gilkalai.wordpress.com/2019/09/22/jeff-kahn-and-jinyoung-park-maximal-independent-sets-and-a-new-isoperimetric-inequality-for-the-hamming-cube/">this post</a> for a description of Talagrand’s various relevant papers.</li>
<li>Renan Gross is building the <a href="https://booleanzoo.weizmann.ac.il/index.php/Main_Page">BooleanZoo</a> in a similar spirit to the famous complexityZoo.</li>
<li>I was in the process of writing a post about progress on ABS, mentioning twelve or so papers, apologizing for not mentioning others, promising to write in details about some of the papers, and making further apologetic remarks. But as this large post does not advance let me start with some of the promises.</li>
</ol>
<p><img src="https://gilkalai.files.wordpress.com/2020/02/talabb.png?w=640" alt="talabb" class="alignnone size-full wp-image-19444" /></p>
<h3>Hint to the trivia question:</h3>
<p><span id="more-19402"></span></p>
<p>The <strong>very same person</strong> also coined the terms: Berry’s phase, TKN^2 integers, almost Matthieu, HVZ, Birman-Schwinger, infrared bounds, diamagnetic inequality, Verblunsky coefficient, Maryland model, ultracontractivity, …</p></div>







<p class="date">
by Gil Kalai <a href="https://gilkalai.wordpress.com/2020/02/28/remarkable-new-stochastic-methods-in-abf-ronen-eldan-and-renan-gross-found-a-new-proof-for-kkl-and-settled-a-conjecture-by-talagrand/"><span class="datestr">at February 28, 2020 02:21 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://dstheory.wordpress.com/?p=26">
<div class="entryheader">
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/">Friday, February 28 — Jon Kleinberg from Cornell University</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://dstheory.wordpress.com" title="Foundation of Data Science – Virtual Talk Series">Foundation of Data Science - Virtual Talk Series</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>The first Foundations of Data Science virtual talk will take place this coming Friday, February 28th at 11:00 AM Pacific Time (2:00 pm Eastern Time, 20:00 Central European Time, 19:00 UTC). <strong>Jon Kleinberg</strong> from Cornell University will speak about “<em>Fairness and Bias in Algorithmic Decision-Making</em>”.</p>



<p><strong>Abstract</strong>: As data science has broadened its scope in recent years, a number of domains have applied computational methods for classification and prediction to evaluate individuals in high-stakes settings. These developments have led to an active line of recent discussion in the public sphere about the consequences of algorithmic prediction for notions of fairness and equity. In part, this discussion has involved a basic tension between competing notions of what it means for such classifications to be fair to different groups. We consider several of the key fairness conditions that lie at the heart of these debates, and in particular how these properties operate when the goal is to rank-order a set of applicants by some criterion of interest, and then to select the top-ranking applicants. The talk will be based on joint work with Sendhil Mullainathan and Manish Raghavan.</p>



<p><a href="https://sites.google.com/view/dstheory">Link to join the virtual talk.</a></p>



<p>The series is supported by the <a href="https://www.nsf.gov/awardsearch/showAward?AWD_ID=1934846&amp;HistoricalAwards=false">NSF HDR TRIPODS Grant 1934846</a>. </p></div>







<p class="date">
by dstheory <a href="https://dstheory.wordpress.com/2020/02/27/friday-february-28-jon-kleinberg-from-cornell-university/"><span class="datestr">at February 27, 2020 11:30 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/028">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/028">TR20-028 |  A Super-Quadratic Lower Bound for Depth Four Arithmetic Circuits | 

	Nikhil Gupta, 

	Chandan Saha, 

	Bhargav Thankey</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We show an $\widetilde{\Omega}(n^{2.5})$ lower bound for general depth four arithmetic circuits computing an explicit $n$-variate degree $\Theta(n)$ multilinear polynomial over any field of characteristic zero. To our knowledge, and as stated in the survey by Shpilka and Yehudayoff (FnT-TCS, 2010), no super-quadratic lower bound was known for depth four circuits over fields of characteristic other than 2 before this work. The previous best lower bound is $\widetilde{\Omega}(n^{1.5})$ shown in the work of Sharma (Master's Thesis, 2017), which is a slight quantitative improvement over the roughly $\Omega(n^{1.33})$ bound obtained by invoking the super-linear lower bound for constant depth circuits in the works of Raz (STOC, 2008) and Shoup and Smolensky (FOCS, 1991).

Our lower bound proof follows the approach of the almost cubic lower bound for depth three circuits in the work by Kayal, Saha and Tavenas (ICALP, 2016) by replacing the shifted partials measure with a suitable variant of the projected shifted partials measure, but it differs from their proof at a crucial step - namely, the way "heavy" product gates are handled. Loosely speaking, a heavy product gate has a relatively high fan-in. Product gates of a depth three circuit compute products of affine forms, and so, it is easy to prune $\Theta(n)$ many heavy product gates by projecting the circuit to a low-dimensional affine subspace as shown in the works by Kayal, Saha and Tavenas (ICALP, 2016) and Shpilka and Wigderson (CCC, 1999). However, in a depth four circuit, the second (from the top) layer of product gates compute products of polynomials having arbitrary degree, and hence it was not clear how to prune such heavy product gates from the circuit. We show that heavy product gates can also be eliminated from a depth four circuit by projecting the circuit to a low-dimensional affine subspace, unless the heavy gates together account for $\widetilde{\Omega}(n^{2.5})$ size. This part of our argument is inspired by a well-known greedy approximation algorithm for the weighted set-cover problem.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/028"><span class="datestr">at February 27, 2020 03:03 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/027">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/027">TR20-027 |  The Power of Many Samples in Query Complexity | 

	Mika Göös, 

	Andrew Bassilakis, 

	Andrew Drucker, 

	Li-Yang Tan, 

	Lunjia Hu, 

	Weiyun Ma</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
The randomized query complexity $R(f)$ of a boolean function $f\colon\{0,1\}^n\to\{0,1\}$ is famously characterized (via Yao's minimax) by the least number of queries needed to distinguish a distribution $D_0$ over $0$-inputs from a distribution $D_1$ over $1$-inputs, maximized over all pairs $(D_0,D_1)$. We ask: Does this task become easier if we allow query access to infinitely many samples from either $D_0$ or $D_1$? We show the answer is no: There exists a hard pair $(D_0,D_1)$ such that distinguishing $D_0^\infty$ from $D_1^\infty$ requires $\Theta(R(f))$ many queries. As an application, we show that for any composed function $f\circ g$ we have $R(f\circ g) \geq \Omega(\mathrm{fbs}(f)R(g))$ where $\mathrm{fbs}$ denotes fractional block sensitivity.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/027"><span class="datestr">at February 26, 2020 07:45 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://lucatrevisan.wordpress.com/?p=4301">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/trevisan.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://lucatrevisan.wordpress.com/2020/02/26/i-live-in-milan-ama/">This year, for Lent, Milan gave up nightlife</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://lucatrevisan.wordpress.com" title="in   theory">Luca Trevisan</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>Greetings from Milan, in Italy’s “yellow zone” of areas bordering clusters of coronavirus infections. This week, all schools, universities, museums, theaters  are closed, bars have to close by 6pm, and fairs and conferences are being postponed. The “red zone” of small towns with the clusters of infections is on lockdown.</p>
<p>Milan has been unseasonably warm and sunny in the past few days, and walking through the city, with very light car and pedestrian traffic, has been lovely. This is apparently what the city usually looks like in August, but without the heat and humidity.<br />
<span id="more-4301"></span></p>
<p>Italians have the well deserved fame of being very dramatic people, but we have been taking the inconvenience in stride and with a mix of stoicism and good humor. Maybe I am wrong, but, apart from New York City, if a large American city had a cluster of infections in the suburbs, and it were similarly shut down, we would see riots and looting on the first night.</p>
<p>Over the weekend, the lockdown of the small towns was announced before any announcement of what to do about Milan, and the news showed long lines of people in those small towns waiting to buy groceries in the few open supermarkets. This induced some panic-buying on Sunday and Monday in Milan.</p>
<p>While people in Hong Kong and Singapore panic-bought toilet paper, Italians have mostly been buying pasta. Except, that is, <i>penne lisce</i>, like this Twitter user noted in a broadly shared picture. (Short cuts of pasta, like penne, are usually ribbed, to better catch sauce. Smooth short pasta like penne lisce makes no sense)</p>
<blockquote class="twitter-tweet">
<p lang="it" dir="ltr">Continuo a guardare questa foto fatta prima al supermercato e penso al fatto che il grande sconfitto da questo virus sono le penne lisce che agli italiani fanno cagare pure quando sono presi dal panico e si preparano all’apocalisse. <a href="https://t.co/Lq9Y06jdho">pic.twitter.com/Lq9Y06jdho</a></p>
<p>— 𝚍𝚒𝚘𝚍𝚎𝚐𝚕𝚒𝚣𝚒𝚕𝚕𝚊 <img src="https://s0.wp.com/wp-content/mu-plugins/wpcom-smileys/twemoji/2/72x72/1f926-200d-2642-fe0f.png" alt="🤦‍♂️" style="height: 1em;" class="wp-smiley" /> (@diodeglizilla) <a href="https://twitter.com/diodeglizilla/status/1231680287815426049?ref_src=twsrc%5Etfw">February 23, 2020</a></p>
<p><img src="https://lucatrevisan.files.wordpress.com/2020/02/erfosjlw4ampqsc.jpeg?w=584" alt="ERfOsJlW4AMPQsc" class="alignnone size-full wp-image-4305" /></p>
</blockquote>
<p>By Sunday night, the government decided that Lombardy and Veneto would be subject to a series of measures with the goal of reducing person-to-person contact, such as the closures mentioned above of schools, universities, museums etc. The meme below is titled “Here in Milan we are going too far”.</p>
<p><img src="https://lucatrevisan.files.wordpress.com/2020/02/download.jpeg?w=584" alt="download" class="alignnone size-full wp-image-4306" /></p>
<p>So far, there has been no secondary infection in Rome. (The text says “This is why the coronavirus has not yet reached Rome”.)</p>
<p><img src="https://lucatrevisan.files.wordpress.com/2020/02/87384731_1300944790095464_2136089705354100736_n.png?w=638&amp;h=391" alt="87384731_1300944790095464_2136089705354100736_n" width="638" height="391" /></p>
<p>(Image credit: <a href="https://www.facebook.com/lepiubellefrasidiosho">facebook.com/lepiubellefrasidiosho</a>)</p>
<p>Most annoyingly, every other newspaper headline or tv news chyron has been of the form “X in the time of coronavirus”. I can’t take it any more. This is the Autumn of journalism, a foretold death of creativity. Journalists are lost in the labyrinth of cliches. I wish all those headline writers one hundred years of solitude. The real news is the kidnapping of new ideas. Anyways, I think I am going to live to tell the tale.</p>
<p>The silver linings are that I have not been paying attention to the Democratic primaries and that I have plenty of free time to restart my planned series of posts on applications of online convex optimization to computational complexity. The next post will be on Impagliazzo’s hard-core lemma, a milestone in the theory of average-case complexity and pseudorandomness.</p>
<p>I am happy to answer any questions in the comments.</p></div>







<p class="date">
by luca <a href="https://lucatrevisan.wordpress.com/2020/02/26/i-live-in-milan-ama/"><span class="datestr">at February 26, 2020 04:15 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://decentralizedthoughts.github.io/2020-02-26-selfish-mining/">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/ittai.jpg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3><a class="entryheader" href="https://decentralizedthoughts.github.io/2020-02-26-selfish-mining/">Blockchain Selfish Mining</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://decentralizedthoughts.github.io" title="Decentralized Thoughts">Decentralized Thoughts</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
Proof of Work (PoW) Blockchains implement a form of State Machine Replication (SMR). Unlike classical SMR protocols, they are open, i.e., anyone can join the system, and the system incentivizes participants, called miners, to follow the protocol. Therefore, unlike classical SMR protocols, reasoning about blockchain security relies not only on...</div>







<p class="date">
<a href="https://decentralizedthoughts.github.io/2020-02-26-selfish-mining/"><span class="datestr">at February 26, 2020 03:00 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="https://eccc.weizmann.ac.il/report/2020/026">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/eccc.png">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en-us"><a class="entryheader" href="https://eccc.weizmann.ac.il/report/2020/026">TR20-026 |  Spectral Sparsification via Bounded-Independence Sampling | 

	Dean Doron, 

	Jack Murtagh, 

	Salil Vadhan, 

	David Zuckerman</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://eccc.weizmann.ac.il/" title="ECCC - Reports">ECCC papers</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content">
We give a deterministic, nearly logarithmic-space algorithm for mild spectral sparsification of undirected graphs. Given a weighted, undirected graph $G$ on $n$ vertices described by a binary string of length $N$, an integer $k\leq \log n$ and an error parameter $\varepsilon &gt; 0$, our algorithm runs in space $\tilde{O}(k\log (N\cdot w_{\mathrm{max}}/w_{\mathrm{min}}))$ where $w_{\mathrm{max}}$ and $w_{\mathrm{min}}$ are the maximum and minimum edge weights in $G$, and produces a weighted graph $H$ with $\tilde{O}(n^{1+2/k}/\varepsilon^2)$ expected edges that spectrally approximates $G$, in the sense of Spielmen and Teng [ST04], up to an error of $\varepsilon$.

Our algorithm is based on a new bounded-independence analysis of Spielman and Srivastava's effective resistance based edge sampling algorithm [SS08] and uses results from recent work on space-bounded Laplacian solvers [MRSV17].  In particular, we demonstrate an inherent tradeoff (via upper and lower bounds) between the amount of (bounded) independence used in the edge sampling algorithm, denoted by $k$ above, and the resulting sparsity that can be achieved.</div>







<p class="date">
<a href="https://eccc.weizmann.ac.il/report/2020/026"><span class="datestr">at February 26, 2020 04:13 AM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>









<div class="channelgroup">
<div class="entrygroup" 
	id="http://rjlipton.wordpress.com/?p=16720">
<div class="entryheader">
<span class="face">
	<img class="face" src="images/lipton.jpeg">
</span>
<div class="entryheadertextcontainer">
<div class="entryheadertext">
<h3 lang="en"><a class="entryheader" href="https://rjlipton.wordpress.com/2020/02/24/should-we-teach-coding-in-high-school/">Should We Teach Coding in High School?</a></h3>
<p style="text-indent: 1.0em;">from 
<a class="entryheader" href="https://rjlipton.wordpress.com" title="Gödel’s Lost Letter and P=NP">Richard Lipton</a>
<p>
</div>
</div>
</div>
<div class="entry">
<div class="content" lang="en">
<p>
Robert Sedgewick and Larry Cuban faced off today in the Wall Street Journal (WSJ) on the issue: </p>
<p><a href="https://rjlipton.wordpress.com/2020/02/24/should-we-teach-coding-in-high-school/unknown-1-5/" rel="attachment wp-att-16723"><img width="150" alt="" class="alignright  wp-image-16723" src="https://rjlipton.files.wordpress.com/2020/02/unknown-1-1.jpeg?w=150" /></a><br />
<a href="https://rjlipton.wordpress.com/2020/02/24/should-we-teach-coding-in-high-school/unknown-136/" rel="attachment wp-att-16722"><img width="150" alt="" class="alignright wp-image-16722" src="https://rjlipton.files.wordpress.com/2020/02/unknown-3.jpeg?w=150" /></a></p>
<blockquote><p><b> </b> <em> 	Should everyone be taught coding in high school? </em>
</p></blockquote>
<p></p><p>
Today we will discuss their recent <a href="https://www.wsj.com/articles/should-all-children-learn-to-code-by-the-end-of-high-school-11582513441">comments</a> on this issue.<br />
<span id="more-16720"></span></p>
<p>
Bob is a long-time friend of mine, so I want to say that that up front. He is a professor of computer science at Princeton. Cuban is an emeritus professor of education at Stanford. Note, I do not know Cuban but will call him Larry—I hope that is fine. Besides what they say in the article, Larry wrote a <a href="https://larrycuban.wordpress.com/2017/07/11/coding-the-new-vocationalism-part-1/">three</a>–<a href="https://larrycuban.wordpress.com/2017/07/14/coding-the-new-vocationalism-part-2/">part</a> <a href="https://larrycuban.wordpress.com/2017/07/17/coding-the-new-vocationalism-part-3/">series</a> in 2017 on his own education blog, while Bob was <a href="https://www.washingtonpost.com/news/the-switch/wp/2013/12/11/president-obama-talks-about-teaching-everyone-to-code-this-professor-does-it/">associated</a> with a 2013 White House-led <a href="https://www.wired.com/2013/12/obama-code/">initiative</a> on coding in schools.</p>
<p>
The WSJ article consists of ten short paragraphs by Bob followed by eleven from Larry. This is sequential structure—like with statements <img src="https://s0.wp.com/latex.php?latex=%7BS_1%3B+S_2%3B%7D&amp;bg=ffffff&amp;fg=000000&amp;s=0" alt="{S_1; S_2;}" class="latex" title="{S_1; S_2;}" />—or like having candidate town-halls for consectuive hours on CNN and such. What we’d like to see is a debate—like having parallel processes that must sync and communicate. Below we imagine one based on statements in the article.</p>
<p>
</p><p></p><h2> A Conversation </h2><p></p>
<p></p><p>
The following is a paraphrase that tries to re-structure some of the article in debate format.</p>
<p></p><p>
<font color="#0044cc"><br />
<em>Bob:</em> <font color="#000000"> Teaching students to code will help them understand logical thinking and foster creativity.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Larry:</i> <font color="#000000"> You could say the same for teaching writing, math, history, and many other subjects. There is no research that shows that coding is better than other topics in this regard.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Bob:</i> <font color="#000000"> I am not aware of any research that shows that each topic that is taught now is better than coding.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Larry:</i> <font color="#000000"> Yes that is true, but consider how durable core education has been for our society. A century ago, industrial groups pushed the federal government to require vocational training in schools for particular industrial and agricultural skills and to establish separate vocational schools. Those undermined the broader goals of social development and civic engagement.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Bob:</i> <font color="#000000"> Technology is basic to much of society’s issues. Perhaps the Iowa caucus fiasco could have been avoided if they had a better understanding of computing.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Larry:</i> <font color="#000000"> I think the main argument for coding is being pushed by technology CEOs. They need more coders. The educational system should not just do what they need. Do you not agree Bob?</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Bob:</i> <font color="#000000">If we teach coding it seems that it may help in lessening economic and gender based gaps. In summary, in the last millennium, education was based on reading, writing, and arithmetic. Perhaps we should now switch to reading, writing, and computing. Coding includes arithmetic and a whole lot more.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Larry:</i> <font color="#000000"> I agree education should help students achieve their potential. I just do not see that coding will do this. And further, data and projections from the U.S. Bureau of Labor Statistics show only an 11 percent increase in IT jobs, from 4.5 to 5 million, between 2018 and 2028. That’s going out a whole decade and still IT will only be about 3 percent of all jobs. Health care will <em>grow</em> in that time by as many jobs as IT has total.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Bob:</i> <font color="#000000"> Those percentages hide much of the benefit. Only a fraction of the thousands I have taught—in person and online—work in tech companies. The rest have gone into a broad variety of careers. Coding literacy is becoming a necessity in health care, social assistance, business services, construction, entertainment, manufacturing, and even politics. </font></font></p><font color="#0044cc"><font color="#000000">
<p>
<font color="#0044cc"><br />
<i>Larry:</i> <font color="#000000"> But what would you cut to make room? Foreign language? History? Arts or music? Or decrease other aspects of math and science? Curricula are already crowded with required courses and frequent testing.</font></font></p><font color="#0044cc"><font color="#000000">
<p>
</p><p></p><h2> Open Problems </h2><p></p>
<p></p><p>
What should the role of coding be in our society? Who is right?</p>
<p></p><p><br />
[some word and grammar tweaks]</p></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></font></div>







<p class="date">
by rjlipton <a href="https://rjlipton.wordpress.com/2020/02/24/should-we-teach-coding-in-high-school/"><span class="datestr">at February 24, 2020 09:26 PM UTC</span></a>
</p>
<div class="comments">
</div>
</div>
</div>

</div>


</body>

</html>
